{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 775.3716945648193,
  "kg_co2_emissions": 0.045453785436951555,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.08794466403162056,
        "f1": 0.07143812762346662,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.07143812762346662,
        "precision": 0.06865351900994333,
        "recall": 0.08794466403162056
      },
      {
        "accuracy": 0.14031620553359683,
        "f1": 0.08312905403497135,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.08312905403497135,
        "precision": 0.07085374636711185,
        "recall": 0.14031620553359683
      },
      {
        "accuracy": 0.06027667984189723,
        "f1": 0.0480167066378109,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.0480167066378109,
        "precision": 0.0456361160155484,
        "recall": 0.06027667984189723
      },
      {
        "accuracy": 0.10770750988142293,
        "f1": 0.06670908297731262,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.06670908297731262,
        "precision": 0.058206533495000996,
        "recall": 0.10770750988142293
      },
      {
        "accuracy": 0.14031620553359683,
        "f1": 0.11054347769243676,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11054347769243676,
        "precision": 0.10518189473541044,
        "recall": 0.14031620553359683
      },
      {
        "accuracy": 0.21739130434782608,
        "f1": 0.1602763153154375,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.1602763153154375,
        "precision": 0.14665760833341931,
        "recall": 0.21739130434782608
      },
      {
        "accuracy": 0.0800395256916996,
        "f1": 0.06573801937554553,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.06573801937554553,
        "precision": 0.06238475796404048,
        "recall": 0.0800395256916996
      },
      {
        "accuracy": 0.13339920948616601,
        "f1": 0.08104799880985651,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.08104799880985651,
        "precision": 0.06921004939910348,
        "recall": 0.13339920948616601
      },
      {
        "accuracy": 0.07015810276679842,
        "f1": 0.054169436545122324,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.054169436545122324,
        "precision": 0.050071636751478646,
        "recall": 0.07015810276679842
      },
      {
        "accuracy": 0.12549407114624506,
        "f1": 0.08458177756528806,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.08458177756528806,
        "precision": 0.07616255616783327,
        "recall": 0.12549407114624506
      },
      {
        "accuracy": 0.10968379446640317,
        "f1": 0.08889654662653,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08889654662653,
        "precision": 0.08490371099568755,
        "recall": 0.10968379446640317
      },
      {
        "accuracy": 0.17094861660079053,
        "f1": 0.12145397822275292,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.12145397822275292,
        "precision": 0.1082552630182526,
        "recall": 0.17094861660079053
      },
      {
        "accuracy": 0.08893280632411067,
        "f1": 0.07422767753015308,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.07422767753015308,
        "precision": 0.07088563891792407,
        "recall": 0.08893280632411067
      },
      {
        "accuracy": 0.1442687747035573,
        "f1": 0.09258952962194905,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.09258952962194905,
        "precision": 0.08134555700633476,
        "recall": 0.1442687747035573
      },
      {
        "accuracy": 0.12845849802371542,
        "f1": 0.10985305030194349,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.10985305030194349,
        "precision": 0.1046413462862503,
        "recall": 0.12845849802371542
      },
      {
        "accuracy": 0.17391304347826086,
        "f1": 0.0993518567966012,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.0993518567966012,
        "precision": 0.0826383733264324,
        "recall": 0.17391304347826086
      },
      {
        "accuracy": 0.10474308300395258,
        "f1": 0.09028610533412428,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.09028610533412428,
        "precision": 0.08720652783953263,
        "recall": 0.10474308300395258
      },
      {
        "accuracy": 0.1551383399209486,
        "f1": 0.10939273308456918,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.10939273308456918,
        "precision": 0.09879194989726617,
        "recall": 0.1551383399209486
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.05074664103245871,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.05074664103245871,
        "precision": 0.04832998444592939,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.11363636363636363,
        "f1": 0.0646161504947685,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0646161504947685,
        "precision": 0.05432727766777987,
        "recall": 0.11363636363636363
      },
      {
        "accuracy": 0.1422924901185771,
        "f1": 0.11718028991162555,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11718028991162555,
        "precision": 0.11134981665858332,
        "recall": 0.1422924901185771
      },
      {
        "accuracy": 0.1976284584980237,
        "f1": 0.14323852315959903,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.14323852315959903,
        "precision": 0.12933932002655277,
        "recall": 0.1976284584980237
      },
      {
        "accuracy": 0.1482213438735178,
        "f1": 0.12589158437297396,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.12589158437297396,
        "precision": 0.12114982353353443,
        "recall": 0.1482213438735178
      },
      {
        "accuracy": 0.18774703557312253,
        "f1": 0.12663215834861505,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.12663215834861505,
        "precision": 0.11219044900674173,
        "recall": 0.18774703557312253
      },
      {
        "accuracy": 0.07608695652173914,
        "f1": 0.061145143718797,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.061145143718797,
        "precision": 0.057317099365261144,
        "recall": 0.07608695652173914
      },
      {
        "accuracy": 0.13636363636363635,
        "f1": 0.0793453114180748,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0793453114180748,
        "precision": 0.06686738589028754,
        "recall": 0.13636363636363635
      },
      {
        "accuracy": 0.08102766798418973,
        "f1": 0.06702389296854308,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.06702389296854308,
        "precision": 0.06328578071544823,
        "recall": 0.08102766798418973
      },
      {
        "accuracy": 0.1432806324110672,
        "f1": 0.09024504986391588,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.09024504986391588,
        "precision": 0.08030884586638112,
        "recall": 0.1432806324110672
      },
      {
        "accuracy": 0.17885375494071146,
        "f1": 0.16049676902914328,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.16049676902914328,
        "precision": 0.15547607052927323,
        "recall": 0.17885375494071146
      },
      {
        "accuracy": 0.20553359683794467,
        "f1": 0.1363236380770972,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.1363236380770972,
        "precision": 0.11942108093410116,
        "recall": 0.20553359683794467
      },
      {
        "accuracy": 0.11264822134387352,
        "f1": 0.09336068136957465,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09336068136957465,
        "precision": 0.08873839395898556,
        "recall": 0.11264822134387352
      },
      {
        "accuracy": 0.16403162055335968,
        "f1": 0.10726409125011241,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.10726409125011241,
        "precision": 0.09501970262072718,
        "recall": 0.16403162055335968
      },
      {
        "accuracy": 0.12549407114624506,
        "f1": 0.0987093296031326,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0987093296031326,
        "precision": 0.0941421840752756,
        "recall": 0.12549407114624506
      },
      {
        "accuracy": 0.2015810276679842,
        "f1": 0.1455250801265294,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.1455250801265294,
        "precision": 0.13060463070795342,
        "recall": 0.2015810276679842
      },
      {
        "accuracy": 0.11462450592885376,
        "f1": 0.09260031986163142,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09260031986163142,
        "precision": 0.08820527935550576,
        "recall": 0.11462450592885376
      },
      {
        "accuracy": 0.20553359683794467,
        "f1": 0.15586873348819802,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.15586873348819802,
        "precision": 0.14257847207180813,
        "recall": 0.20553359683794467
      },
      {
        "accuracy": 0.05434782608695652,
        "f1": 0.041927599445523885,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.041927599445523885,
        "precision": 0.03896523055732712,
        "recall": 0.05434782608695652
      },
      {
        "accuracy": 0.0958498023715415,
        "f1": 0.04730721067804725,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.04730721067804725,
        "precision": 0.03907504322370156,
        "recall": 0.0958498023715415
      },
      {
        "accuracy": 0.10770750988142293,
        "f1": 0.09020655297829211,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09020655297829211,
        "precision": 0.0857323839593457,
        "recall": 0.10770750988142293
      },
      {
        "accuracy": 0.17094861660079053,
        "f1": 0.11625505744791592,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.11625505744791592,
        "precision": 0.10506020631256499,
        "recall": 0.17094861660079053
      },
      {
        "accuracy": 0.12351778656126482,
        "f1": 0.097193546100591,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.097193546100591,
        "precision": 0.09248211662147404,
        "recall": 0.12351778656126482
      },
      {
        "accuracy": 0.1907114624505929,
        "f1": 0.13353980991743017,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.13353980991743017,
        "precision": 0.11959050289342006,
        "recall": 0.1907114624505929
      },
      {
        "accuracy": 0.16403162055335968,
        "f1": 0.13309529044524915,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.13309529044524915,
        "precision": 0.12667560701904948,
        "recall": 0.16403162055335968
      },
      {
        "accuracy": 0.2183794466403162,
        "f1": 0.15389913580641087,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.15389913580641087,
        "precision": 0.13905620473377162,
        "recall": 0.2183794466403162
      },
      {
        "accuracy": 0.10573122529644269,
        "f1": 0.08375660222076153,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08375660222076153,
        "precision": 0.08030313105382776,
        "recall": 0.10573122529644269
      },
      {
        "accuracy": 0.17786561264822134,
        "f1": 0.12570811560614875,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.12570811560614875,
        "precision": 0.11367957279430317,
        "recall": 0.17786561264822134
      },
      {
        "accuracy": 0.14031620553359683,
        "f1": 0.11680260198373518,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11680260198373518,
        "precision": 0.11139534103601104,
        "recall": 0.14031620553359683
      },
      {
        "accuracy": 0.20454545454545456,
        "f1": 0.1434693536147565,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.1434693536147565,
        "precision": 0.1279651448187264,
        "recall": 0.20454545454545456
      },
      {
        "accuracy": 0.14031620553359683,
        "f1": 0.11370946557195499,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11370946557195499,
        "precision": 0.10828539657628138,
        "recall": 0.14031620553359683
      },
      {
        "accuracy": 0.208498023715415,
        "f1": 0.14935787720117186,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.14935787720117186,
        "precision": 0.1342018037771932,
        "recall": 0.208498023715415
      },
      {
        "accuracy": 0.11956521739130435,
        "f1": 0.0964454347194795,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0964454347194795,
        "precision": 0.09017434722721283,
        "recall": 0.11956521739130435
      },
      {
        "accuracy": 0.16403162055335968,
        "f1": 0.10126487315159317,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.10126487315159317,
        "precision": 0.08787141787239267,
        "recall": 0.16403162055335968
      },
      {
        "accuracy": 0.116600790513834,
        "f1": 0.09326420112723535,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09326420112723535,
        "precision": 0.08826291453400098,
        "recall": 0.116600790513834
      },
      {
        "accuracy": 0.1966403162055336,
        "f1": 0.13886960252631028,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.13886960252631028,
        "precision": 0.12387712199965163,
        "recall": 0.1966403162055336
      },
      {
        "accuracy": 0.14031620553359683,
        "f1": 0.11570471309122479,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11570471309122479,
        "precision": 0.11112409805523728,
        "recall": 0.14031620553359683
      },
      {
        "accuracy": 0.21541501976284586,
        "f1": 0.15999255465658627,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.15999255465658627,
        "precision": 0.14597703992775635,
        "recall": 0.21541501976284586
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.007753714367608252,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.007753714367608252,
        "precision": 0.0064625244253082555,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.010969374562594747,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.010969374562594747,
        "precision": 0.008917371993003635,
        "recall": 0.02865612648221344
      }
    ],
    "validation": [
      {
        "accuracy": 0.06920762286860582,
        "f1": 0.05753485503184838,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.05753485503184838,
        "precision": 0.05470892178347274,
        "recall": 0.06920762286860582
      },
      {
        "accuracy": 0.1354062186559679,
        "f1": 0.08708324092029762,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.08708324092029762,
        "precision": 0.07690772706857882,
        "recall": 0.1354062186559679
      },
      {
        "accuracy": 0.05616850551654965,
        "f1": 0.04279441281151226,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.04279441281151226,
        "precision": 0.040365052589225105,
        "recall": 0.05616850551654965
      },
      {
        "accuracy": 0.09628886659979939,
        "f1": 0.05699494766207287,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.05699494766207287,
        "precision": 0.04797464675981806,
        "recall": 0.09628886659979939
      },
      {
        "accuracy": 0.15245737211634905,
        "f1": 0.12020379819491224,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.12020379819491224,
        "precision": 0.11371093988578018,
        "recall": 0.15245737211634905
      },
      {
        "accuracy": 0.22768304914744233,
        "f1": 0.1775445224552136,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.1775445224552136,
        "precision": 0.16409258805328591,
        "recall": 0.22768304914744233
      },
      {
        "accuracy": 0.06519558676028084,
        "f1": 0.05095930563952276,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.05095930563952276,
        "precision": 0.048098677089645894,
        "recall": 0.06519558676028084
      },
      {
        "accuracy": 0.13139418254764293,
        "f1": 0.07879985271017433,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.07879985271017433,
        "precision": 0.06792034048267998,
        "recall": 0.13139418254764293
      },
      {
        "accuracy": 0.0732196589769308,
        "f1": 0.054529920176675115,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.054529920176675115,
        "precision": 0.05049127183181389,
        "recall": 0.0732196589769308
      },
      {
        "accuracy": 0.13841524573721165,
        "f1": 0.0927584773526399,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.0927584773526399,
        "precision": 0.08332889900634863,
        "recall": 0.13841524573721165
      },
      {
        "accuracy": 0.11033099297893681,
        "f1": 0.09252673007415495,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09252673007415495,
        "precision": 0.08757376665404545,
        "recall": 0.11033099297893681
      },
      {
        "accuracy": 0.15947843530591777,
        "f1": 0.11348696085784832,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.11348696085784832,
        "precision": 0.10327940822644749,
        "recall": 0.15947843530591777
      },
      {
        "accuracy": 0.09127382146439318,
        "f1": 0.06891246509224934,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.06891246509224934,
        "precision": 0.06345550333280627,
        "recall": 0.09127382146439318
      },
      {
        "accuracy": 0.13640922768304914,
        "f1": 0.08485794291968193,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.08485794291968193,
        "precision": 0.07499055317009114,
        "recall": 0.13640922768304914
      },
      {
        "accuracy": 0.11534603811434303,
        "f1": 0.10087795369049579,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.10087795369049579,
        "precision": 0.09666749628094336,
        "recall": 0.11534603811434303
      },
      {
        "accuracy": 0.15646940822467403,
        "f1": 0.0882365049967703,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.0882365049967703,
        "precision": 0.07385243268365252,
        "recall": 0.15646940822467403
      },
      {
        "accuracy": 0.10732196589769308,
        "f1": 0.09163571262509772,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.09163571262509772,
        "precision": 0.08811858652109786,
        "recall": 0.10732196589769308
      },
      {
        "accuracy": 0.18355065195586762,
        "f1": 0.12457803415231547,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.12457803415231547,
        "precision": 0.11211219441170707,
        "recall": 0.18355065195586762
      },
      {
        "accuracy": 0.062186559679037114,
        "f1": 0.0509602282808859,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0509602282808859,
        "precision": 0.04814378262383569,
        "recall": 0.062186559679037114
      },
      {
        "accuracy": 0.12437311935807423,
        "f1": 0.07442572847871937,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.07442572847871937,
        "precision": 0.06374235495076279,
        "recall": 0.12437311935807423
      },
      {
        "accuracy": 0.14944834503510532,
        "f1": 0.1210180910237602,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.1210180910237602,
        "precision": 0.11441676448273379,
        "recall": 0.14944834503510532
      },
      {
        "accuracy": 0.19859578736208625,
        "f1": 0.13730165803503463,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.13730165803503463,
        "precision": 0.12146777132054991,
        "recall": 0.19859578736208625
      },
      {
        "accuracy": 0.1424272818455366,
        "f1": 0.11589220239563959,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11589220239563959,
        "precision": 0.10991946293807763,
        "recall": 0.1424272818455366
      },
      {
        "accuracy": 0.20561685055165496,
        "f1": 0.13880068456807734,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.13880068456807734,
        "precision": 0.12509157723725575,
        "recall": 0.20561685055165496
      },
      {
        "accuracy": 0.07522567703109329,
        "f1": 0.06013563000488133,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.06013563000488133,
        "precision": 0.057010703281999184,
        "recall": 0.07522567703109329
      },
      {
        "accuracy": 0.12637913741223672,
        "f1": 0.07114708382483255,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.07114708382483255,
        "precision": 0.059744584030658944,
        "recall": 0.12637913741223672
      },
      {
        "accuracy": 0.06519558676028084,
        "f1": 0.05262507087098508,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.05262507087098508,
        "precision": 0.05007007976109572,
        "recall": 0.06519558676028084
      },
      {
        "accuracy": 0.1334002006018054,
        "f1": 0.07675923125536203,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.07675923125536203,
        "precision": 0.06445683310362996,
        "recall": 0.1334002006018054
      },
      {
        "accuracy": 0.20661985957873621,
        "f1": 0.1911312435634399,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.1911312435634399,
        "precision": 0.18747104023738578,
        "recall": 0.20661985957873621
      },
      {
        "accuracy": 0.22668004012036108,
        "f1": 0.15624266780330878,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.15624266780330878,
        "precision": 0.13731498529790465,
        "recall": 0.22668004012036108
      },
      {
        "accuracy": 0.12437311935807423,
        "f1": 0.10460173357782593,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.10460173357782593,
        "precision": 0.09996640024354747,
        "recall": 0.12437311935807423
      },
      {
        "accuracy": 0.16950852557673018,
        "f1": 0.11323979234327927,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.11323979234327927,
        "precision": 0.10099586496456639,
        "recall": 0.16950852557673018
      },
      {
        "accuracy": 0.12036108324974924,
        "f1": 0.09772967285165367,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09772967285165367,
        "precision": 0.09319645225597771,
        "recall": 0.12036108324974924
      },
      {
        "accuracy": 0.21464393179538616,
        "f1": 0.16002344410577263,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.16002344410577263,
        "precision": 0.1472719432278925,
        "recall": 0.21464393179538616
      },
      {
        "accuracy": 0.1424272818455366,
        "f1": 0.11648759482787883,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11648759482787883,
        "precision": 0.11153095013783466,
        "recall": 0.1424272818455366
      },
      {
        "accuracy": 0.21063189568706117,
        "f1": 0.16216598179486846,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.16216598179486846,
        "precision": 0.15067577779007466,
        "recall": 0.21063189568706117
      },
      {
        "accuracy": 0.04212637913741224,
        "f1": 0.03289698251213662,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.03289698251213662,
        "precision": 0.030988184505506694,
        "recall": 0.04212637913741224
      },
      {
        "accuracy": 0.09729187562688064,
        "f1": 0.051999546302202465,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.051999546302202465,
        "precision": 0.044702698370494925,
        "recall": 0.09729187562688064
      },
      {
        "accuracy": 0.10230692076228685,
        "f1": 0.08081831120371852,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08081831120371852,
        "precision": 0.07720638935592684,
        "recall": 0.10230692076228685
      },
      {
        "accuracy": 0.1424272818455366,
        "f1": 0.09396672624988857,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.09396672624988857,
        "precision": 0.08357730298280208,
        "recall": 0.1424272818455366
      },
      {
        "accuracy": 0.1444332998996991,
        "f1": 0.11960997326569851,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11960997326569851,
        "precision": 0.11462569025361541,
        "recall": 0.1444332998996991
      },
      {
        "accuracy": 0.19859578736208625,
        "f1": 0.14446257303326962,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.14446257303326962,
        "precision": 0.1316228860110505,
        "recall": 0.19859578736208625
      },
      {
        "accuracy": 0.15947843530591777,
        "f1": 0.12869922530864183,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.12869922530864183,
        "precision": 0.1215520378534701,
        "recall": 0.15947843530591777
      },
      {
        "accuracy": 0.20260782347041123,
        "f1": 0.14139350706902742,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.14139350706902742,
        "precision": 0.1267369288818089,
        "recall": 0.20260782347041123
      },
      {
        "accuracy": 0.11735205616850551,
        "f1": 0.09303000008458014,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09303000008458014,
        "precision": 0.08853884971929567,
        "recall": 0.11735205616850551
      },
      {
        "accuracy": 0.19859578736208625,
        "f1": 0.14727398149825985,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.14727398149825985,
        "precision": 0.1357323278675105,
        "recall": 0.19859578736208625
      },
      {
        "accuracy": 0.13941825476429287,
        "f1": 0.11809572060058686,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11809572060058686,
        "precision": 0.11374412248906332,
        "recall": 0.13941825476429287
      },
      {
        "accuracy": 0.19358074222668004,
        "f1": 0.1362505327070378,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.1362505327070378,
        "precision": 0.12342558704963998,
        "recall": 0.19358074222668004
      },
      {
        "accuracy": 0.14744232698094284,
        "f1": 0.11994961752385021,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11994961752385021,
        "precision": 0.11409101246806173,
        "recall": 0.14744232698094284
      },
      {
        "accuracy": 0.22066198595787362,
        "f1": 0.15939525105501295,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.15939525105501295,
        "precision": 0.14492492620486444,
        "recall": 0.22066198595787362
      },
      {
        "accuracy": 0.11735205616850551,
        "f1": 0.09936106923692888,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.09936106923692888,
        "precision": 0.09483795495783072,
        "recall": 0.11735205616850551
      },
      {
        "accuracy": 0.17251755265797392,
        "f1": 0.11061646932021212,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.11061646932021212,
        "precision": 0.09788360410987774,
        "recall": 0.17251755265797392
      },
      {
        "accuracy": 0.13139418254764293,
        "f1": 0.10572118858865971,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.10572118858865971,
        "precision": 0.10052431501993525,
        "recall": 0.13139418254764293
      },
      {
        "accuracy": 0.1995987963891675,
        "f1": 0.15233330769079806,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.15233330769079806,
        "precision": 0.14241426837201418,
        "recall": 0.1995987963891675
      },
      {
        "accuracy": 0.13841524573721165,
        "f1": 0.1143779963433005,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.1143779963433005,
        "precision": 0.11020419648080881,
        "recall": 0.13841524573721165
      },
      {
        "accuracy": 0.20361083249749248,
        "f1": 0.14997614919442848,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.14997614919442848,
        "precision": 0.1365106109263942,
        "recall": 0.20361083249749248
      },
      {
        "accuracy": 0.014042126379137413,
        "f1": 0.011191002727056672,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.011191002727056672,
        "precision": 0.010615470103690865,
        "recall": 0.014042126379137413
      },
      {
        "accuracy": 0.025075225677031094,
        "f1": 0.007262737760217125,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.007262737760217125,
        "precision": 0.0052364741609249804,
        "recall": 0.025075225677031094
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}