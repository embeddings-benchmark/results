{
  "dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300",
  "task_name": "Banking77Classification",
  "mteb_version": "2.1.0",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.7100649350649351,
            "f1": 0.6995461001767057,
            "f1_weighted": 0.6995461001767059,
            "precision": 0.7332062729391389,
            "precision_weighted": 0.733206272939139,
            "recall": 0.7100649350649351,
            "recall_weighted": 0.7100649350649351,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7224025974025974,
            "f1": 0.7150382781273568,
            "f1_weighted": 0.7150382781273568,
            "precision": 0.744858654649443,
            "precision_weighted": 0.7448586546494435,
            "recall": 0.7224025974025973,
            "recall_weighted": 0.7224025974025974,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7298701298701299,
            "f1": 0.7208199927092682,
            "f1_weighted": 0.7208199927092679,
            "precision": 0.7550937761851764,
            "precision_weighted": 0.7550937761851763,
            "recall": 0.7298701298701298,
            "recall_weighted": 0.7298701298701299,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7292207792207792,
            "f1": 0.7226293526766335,
            "f1_weighted": 0.7226293526766338,
            "precision": 0.7467694439215772,
            "precision_weighted": 0.7467694439215772,
            "recall": 0.7292207792207792,
            "recall_weighted": 0.7292207792207792,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7227272727272728,
            "f1": 0.7169359204028584,
            "f1_weighted": 0.7169359204028585,
            "precision": 0.7441266534834512,
            "precision_weighted": 0.7441266534834513,
            "recall": 0.7227272727272727,
            "recall_weighted": 0.7227272727272728,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7142857142857143,
            "f1": 0.7094116680100649,
            "f1_weighted": 0.7094116680100652,
            "precision": 0.7333189816785802,
            "precision_weighted": 0.7333189816785805,
            "recall": 0.7142857142857143,
            "recall_weighted": 0.7142857142857143,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7048701298701299,
            "f1": 0.6971859604468887,
            "f1_weighted": 0.6971859604468887,
            "precision": 0.7291895733328386,
            "precision_weighted": 0.7291895733328387,
            "recall": 0.7048701298701299,
            "recall_weighted": 0.7048701298701299,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7136363636363636,
            "f1": 0.7030093079343817,
            "f1_weighted": 0.7030093079343818,
            "precision": 0.7363024177882893,
            "precision_weighted": 0.7363024177882894,
            "recall": 0.7136363636363635,
            "recall_weighted": 0.7136363636363636,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7224025974025974,
            "f1": 0.712908595069167,
            "f1_weighted": 0.7129085950691669,
            "precision": 0.7442426308466205,
            "precision_weighted": 0.7442426308466206,
            "recall": 0.7224025974025973,
            "recall_weighted": 0.7224025974025974,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7175324675324676,
            "f1": 0.7082295802820642,
            "f1_weighted": 0.708229580282064,
            "precision": 0.7475530280289211,
            "precision_weighted": 0.747553028028921,
            "recall": 0.7175324675324675,
            "recall_weighted": 0.7175324675324676,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.7187012987012986,
        "f1": 0.710571475583539,
        "f1_weighted": 0.710571475583539,
        "precision": 0.7414661432854036,
        "precision_weighted": 0.7414661432854037,
        "recall": 0.7187012987012986,
        "recall_weighted": 0.7187012987012986,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.7187012987012986,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6206.736694186926,
  "mteb_dataset_name": "Banking77Classification"
}