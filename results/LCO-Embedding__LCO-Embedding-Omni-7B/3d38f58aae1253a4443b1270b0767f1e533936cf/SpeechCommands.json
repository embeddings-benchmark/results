{
  "dataset_revision": "3ac713aa0829eeadda73182f38bbbd788d21254b",
  "task_name": "SpeechCommands",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.941513,
            "f1": 0.899271,
            "f1_weighted": 0.954545,
            "precision": 0.8978,
            "precision_weighted": 0.984663,
            "recall": 0.949396,
            "recall_weighted": 0.941513,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.969939,
            "f1": 0.929104,
            "f1_weighted": 0.97408,
            "precision": 0.915862,
            "precision_weighted": 0.980834,
            "recall": 0.964395,
            "recall_weighted": 0.969939,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.933947,
            "f1": 0.917884,
            "f1_weighted": 0.931343,
            "precision": 0.906055,
            "precision_weighted": 0.953138,
            "recall": 0.953912,
            "recall_weighted": 0.933947,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.949284,
            "f1": 0.901129,
            "f1_weighted": 0.954067,
            "precision": 0.883425,
            "precision_weighted": 0.970725,
            "recall": 0.963301,
            "recall_weighted": 0.949284,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.932924,
            "f1": 0.879751,
            "f1_weighted": 0.935952,
            "precision": 0.870202,
            "precision_weighted": 0.962843,
            "recall": 0.949005,
            "recall_weighted": 0.932924,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.931084,
            "f1": 0.928549,
            "f1_weighted": 0.926944,
            "precision": 0.924173,
            "precision_weighted": 0.953857,
            "recall": 0.953783,
            "recall_weighted": 0.931084,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.951125,
            "f1": 0.886534,
            "f1_weighted": 0.964457,
            "precision": 0.874621,
            "precision_weighted": 0.986485,
            "recall": 0.963656,
            "recall_weighted": 0.951125,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.937832,
            "f1": 0.877405,
            "f1_weighted": 0.950152,
            "precision": 0.865747,
            "precision_weighted": 0.981528,
            "recall": 0.951376,
            "recall_weighted": 0.937832,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.948057,
            "f1": 0.902819,
            "f1_weighted": 0.949486,
            "precision": 0.87824,
            "precision_weighted": 0.961749,
            "recall": 0.957427,
            "recall_weighted": 0.948057,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.925153,
            "f1": 0.92844,
            "f1_weighted": 0.921749,
            "precision": 0.930144,
            "precision_weighted": 0.950562,
            "recall": 0.949439,
            "recall_weighted": 0.925153,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.942086,
        "f1": 0.905089,
        "f1_weighted": 0.946278,
        "precision": 0.894627,
        "precision_weighted": 0.968638,
        "recall": 0.955569,
        "recall_weighted": 0.942086,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.942086,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 458.1948010921478,
  "kg_co2_emissions": null
}