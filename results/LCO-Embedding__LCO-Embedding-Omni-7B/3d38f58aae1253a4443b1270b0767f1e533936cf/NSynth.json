{
  "dataset_revision": "e32dfe9b65e121e64229a821fe1ff177e8962635",
  "task_name": "NSynth",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.654564,
            "f1": 0.648433,
            "f1_weighted": 0.655861,
            "precision": 0.653514,
            "precision_weighted": 0.660447,
            "recall": 0.646716,
            "recall_weighted": 0.654564,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.591606,
            "f1": 0.58567,
            "f1_weighted": 0.592164,
            "precision": 0.630989,
            "precision_weighted": 0.654639,
            "recall": 0.59434,
            "recall_weighted": 0.591606,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.524983,
            "f1": 0.51336,
            "f1_weighted": 0.527506,
            "precision": 0.523632,
            "precision_weighted": 0.544692,
            "recall": 0.51997,
            "recall_weighted": 0.524983,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.516322,
            "f1": 0.515262,
            "f1_weighted": 0.526944,
            "precision": 0.540634,
            "precision_weighted": 0.569465,
            "recall": 0.523401,
            "recall_weighted": 0.516322,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.594937,
            "f1": 0.563452,
            "f1_weighted": 0.588039,
            "precision": 0.579459,
            "precision_weighted": 0.603948,
            "recall": 0.570733,
            "recall_weighted": 0.594937,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.646902,
            "f1": 0.638608,
            "f1_weighted": 0.652865,
            "precision": 0.643429,
            "precision_weighted": 0.668291,
            "recall": 0.643152,
            "recall_weighted": 0.646902,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.52032,
            "f1": 0.509499,
            "f1_weighted": 0.491268,
            "precision": 0.52841,
            "precision_weighted": 0.52662,
            "recall": 0.547082,
            "recall_weighted": 0.52032,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.617255,
            "f1": 0.616865,
            "f1_weighted": 0.615949,
            "precision": 0.632707,
            "precision_weighted": 0.653231,
            "recall": 0.639382,
            "recall_weighted": 0.617255,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.63491,
            "f1": 0.625977,
            "f1_weighted": 0.633395,
            "precision": 0.629068,
            "precision_weighted": 0.638927,
            "recall": 0.630497,
            "recall_weighted": 0.63491,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.507328,
            "f1": 0.505981,
            "f1_weighted": 0.503077,
            "precision": 0.574855,
            "precision_weighted": 0.608875,
            "recall": 0.536803,
            "recall_weighted": 0.507328,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.580913,
        "f1": 0.572311,
        "f1_weighted": 0.578707,
        "precision": 0.59367,
        "precision_weighted": 0.612914,
        "recall": 0.585208,
        "recall_weighted": 0.580913,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.580913,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 382.2421658039093,
  "kg_co2_emissions": null
}