{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "task_name": "AmazonReviewsClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.2799,
        "f1": 0.278893,
        "f1_weighted": 0.278893,
        "scores_per_experiment": [
          {
            "accuracy": 0.3086,
            "f1": 0.307358,
            "f1_weighted": 0.307358
          },
          {
            "accuracy": 0.2832,
            "f1": 0.284651,
            "f1_weighted": 0.284651
          },
          {
            "accuracy": 0.2654,
            "f1": 0.265966,
            "f1_weighted": 0.265966
          },
          {
            "accuracy": 0.2648,
            "f1": 0.263803,
            "f1_weighted": 0.263803
          },
          {
            "accuracy": 0.2474,
            "f1": 0.247701,
            "f1_weighted": 0.247701
          },
          {
            "accuracy": 0.2908,
            "f1": 0.289865,
            "f1_weighted": 0.289865
          },
          {
            "accuracy": 0.2652,
            "f1": 0.26392,
            "f1_weighted": 0.26392
          },
          {
            "accuracy": 0.3278,
            "f1": 0.326103,
            "f1_weighted": 0.326103
          },
          {
            "accuracy": 0.2696,
            "f1": 0.267757,
            "f1_weighted": 0.267757
          },
          {
            "accuracy": 0.2762,
            "f1": 0.271801,
            "f1_weighted": 0.271801
          }
        ],
        "main_score": 0.2799,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.27812,
        "f1": 0.276852,
        "f1_weighted": 0.276852,
        "scores_per_experiment": [
          {
            "accuracy": 0.301,
            "f1": 0.297682,
            "f1_weighted": 0.297682
          },
          {
            "accuracy": 0.2686,
            "f1": 0.270187,
            "f1_weighted": 0.270187
          },
          {
            "accuracy": 0.2666,
            "f1": 0.267045,
            "f1_weighted": 0.267045
          },
          {
            "accuracy": 0.2744,
            "f1": 0.27204,
            "f1_weighted": 0.27204
          },
          {
            "accuracy": 0.2552,
            "f1": 0.255088,
            "f1_weighted": 0.255088
          },
          {
            "accuracy": 0.2764,
            "f1": 0.274639,
            "f1_weighted": 0.274639
          },
          {
            "accuracy": 0.2704,
            "f1": 0.269686,
            "f1_weighted": 0.269686
          },
          {
            "accuracy": 0.3208,
            "f1": 0.319454,
            "f1_weighted": 0.319454
          },
          {
            "accuracy": 0.2654,
            "f1": 0.264481,
            "f1_weighted": 0.264481
          },
          {
            "accuracy": 0.2824,
            "f1": 0.278223,
            "f1_weighted": 0.278223
          }
        ],
        "main_score": 0.27812,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 273.7725751399994,
  "kg_co2_emissions": null
}