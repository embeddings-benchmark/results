{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "task_name": "AmazonReviewsClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.25956,
        "f1": 0.256919,
        "f1_weighted": 0.256919,
        "scores_per_experiment": [
          {
            "accuracy": 0.2698,
            "f1": 0.27007,
            "f1_weighted": 0.27007
          },
          {
            "accuracy": 0.2536,
            "f1": 0.250413,
            "f1_weighted": 0.250413
          },
          {
            "accuracy": 0.2484,
            "f1": 0.246235,
            "f1_weighted": 0.246235
          },
          {
            "accuracy": 0.2752,
            "f1": 0.2732,
            "f1_weighted": 0.2732
          },
          {
            "accuracy": 0.2538,
            "f1": 0.251851,
            "f1_weighted": 0.251851
          },
          {
            "accuracy": 0.2474,
            "f1": 0.24828,
            "f1_weighted": 0.24828
          },
          {
            "accuracy": 0.233,
            "f1": 0.22861,
            "f1_weighted": 0.22861
          },
          {
            "accuracy": 0.2866,
            "f1": 0.284285,
            "f1_weighted": 0.284285
          },
          {
            "accuracy": 0.2714,
            "f1": 0.267627,
            "f1_weighted": 0.267627
          },
          {
            "accuracy": 0.2564,
            "f1": 0.248619,
            "f1_weighted": 0.248619
          }
        ],
        "main_score": 0.25956,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.25786,
        "f1": 0.255458,
        "f1_weighted": 0.255458,
        "scores_per_experiment": [
          {
            "accuracy": 0.2732,
            "f1": 0.274409,
            "f1_weighted": 0.274409
          },
          {
            "accuracy": 0.2528,
            "f1": 0.249276,
            "f1_weighted": 0.249276
          },
          {
            "accuracy": 0.252,
            "f1": 0.249166,
            "f1_weighted": 0.249166
          },
          {
            "accuracy": 0.2782,
            "f1": 0.276031,
            "f1_weighted": 0.276031
          },
          {
            "accuracy": 0.2426,
            "f1": 0.240549,
            "f1_weighted": 0.240549
          },
          {
            "accuracy": 0.2448,
            "f1": 0.246469,
            "f1_weighted": 0.246469
          },
          {
            "accuracy": 0.2306,
            "f1": 0.229802,
            "f1_weighted": 0.229802
          },
          {
            "accuracy": 0.2808,
            "f1": 0.277353,
            "f1_weighted": 0.277353
          },
          {
            "accuracy": 0.2656,
            "f1": 0.261481,
            "f1_weighted": 0.261481
          },
          {
            "accuracy": 0.258,
            "f1": 0.250045,
            "f1_weighted": 0.250045
          }
        ],
        "main_score": 0.25786,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 38.92843675613403,
  "kg_co2_emissions": null
}