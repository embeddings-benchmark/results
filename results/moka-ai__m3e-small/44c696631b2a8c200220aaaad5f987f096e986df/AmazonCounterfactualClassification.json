{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.584764,
        "f1": 0.562186,
        "f1_weighted": 0.600457,
        "ap": 0.738907,
        "ap_weighted": 0.738907,
        "scores_per_experiment": [
          {
            "accuracy": 0.626609,
            "f1": 0.591845,
            "f1_weighted": 0.638879,
            "ap": 0.746901,
            "ap_weighted": 0.746901
          },
          {
            "accuracy": 0.581545,
            "f1": 0.565704,
            "f1_weighted": 0.598454,
            "ap": 0.744604,
            "ap_weighted": 0.744604
          },
          {
            "accuracy": 0.575107,
            "f1": 0.562205,
            "f1_weighted": 0.591881,
            "ap": 0.745559,
            "ap_weighted": 0.745559
          },
          {
            "accuracy": 0.600858,
            "f1": 0.581591,
            "f1_weighted": 0.617043,
            "ap": 0.7506,
            "ap_weighted": 0.7506
          },
          {
            "accuracy": 0.577253,
            "f1": 0.539763,
            "f1_weighted": 0.591629,
            "ap": 0.719783,
            "ap_weighted": 0.719783
          },
          {
            "accuracy": 0.545064,
            "f1": 0.536866,
            "f1_weighted": 0.561196,
            "ap": 0.736755,
            "ap_weighted": 0.736755
          },
          {
            "accuracy": 0.61588,
            "f1": 0.584001,
            "f1_weighted": 0.629471,
            "ap": 0.74411,
            "ap_weighted": 0.74411
          },
          {
            "accuracy": 0.592275,
            "f1": 0.56434,
            "f1_weighted": 0.607899,
            "ap": 0.735729,
            "ap_weighted": 0.735729
          },
          {
            "accuracy": 0.542918,
            "f1": 0.525615,
            "f1_weighted": 0.561389,
            "ap": 0.721656,
            "ap_weighted": 0.721656
          },
          {
            "accuracy": 0.590129,
            "f1": 0.569926,
            "f1_weighted": 0.606731,
            "ap": 0.743375,
            "ap_weighted": 0.743375
          }
        ],
        "main_score": 0.584764,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.563062,
        "f1": 0.541308,
        "f1_weighted": 0.579814,
        "ap": 0.725919,
        "ap_weighted": 0.725919,
        "scores_per_experiment": [
          {
            "accuracy": 0.603854,
            "f1": 0.576346,
            "f1_weighted": 0.618649,
            "ap": 0.740515,
            "ap_weighted": 0.740515
          },
          {
            "accuracy": 0.525696,
            "f1": 0.508845,
            "f1_weighted": 0.544495,
            "ap": 0.711533,
            "ap_weighted": 0.711533
          },
          {
            "accuracy": 0.546039,
            "f1": 0.530103,
            "f1_weighted": 0.564012,
            "ap": 0.723146,
            "ap_weighted": 0.723146
          },
          {
            "accuracy": 0.594218,
            "f1": 0.568265,
            "f1_weighted": 0.609745,
            "ap": 0.737062,
            "ap_weighted": 0.737062
          },
          {
            "accuracy": 0.549251,
            "f1": 0.522002,
            "f1_weighted": 0.566724,
            "ap": 0.712863,
            "ap_weighted": 0.712863
          },
          {
            "accuracy": 0.550321,
            "f1": 0.539058,
            "f1_weighted": 0.567293,
            "ap": 0.732237,
            "ap_weighted": 0.732237
          },
          {
            "accuracy": 0.600642,
            "f1": 0.567929,
            "f1_weighted": 0.614517,
            "ap": 0.733733,
            "ap_weighted": 0.733733
          },
          {
            "accuracy": 0.571734,
            "f1": 0.543053,
            "f1_weighted": 0.587914,
            "ap": 0.722741,
            "ap_weighted": 0.722741
          },
          {
            "accuracy": 0.528908,
            "f1": 0.514296,
            "f1_weighted": 0.547308,
            "ap": 0.715861,
            "ap_weighted": 0.715861
          },
          {
            "accuracy": 0.559957,
            "f1": 0.543178,
            "f1_weighted": 0.577486,
            "ap": 0.729502,
            "ap_weighted": 0.729502
          }
        ],
        "main_score": 0.563062,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 37.46899175643921,
  "kg_co2_emissions": null
}