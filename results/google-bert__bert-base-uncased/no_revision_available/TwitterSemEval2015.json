{
    "mteb_version": "0.0.2",
    "test": {
        "cos_sim": {
            "accuracy": 0.812421767896525,
            "accuracy_threshold": 0.8061305284500122,
            "ap": 0.5589788752976392,
            "f1": 0.5427360489757476,
            "f1_threshold": 0.7357102632522583,
            "precision": 0.49000850340136054,
            "recall": 0.6081794195250659
        },
        "dot": {
            "accuracy": 0.7900101329200692,
            "accuracy_threshold": 70.70121765136719,
            "ap": 0.46200213218807057,
            "f1": 0.4882886286361919,
            "f1_threshold": 56.400611877441406,
            "precision": 0.3802588996763754,
            "recall": 0.6820580474934037
        },
        "euclidean": {
            "accuracy": 0.8075937295106396,
            "accuracy_threshold": 5.538182735443115,
            "ap": 0.5341916124334889,
            "f1": 0.5201457114471796,
            "f1_threshold": 6.618348598480225,
            "precision": 0.44714367052571646,
            "recall": 0.6216358839050132
        },
        "evaluation_time": 9.16,
        "manhattan": {
            "accuracy": 0.8077129403349824,
            "accuracy_threshold": 119.82992553710938,
            "ap": 0.5356047698432087,
            "f1": 0.5196175403890537,
            "f1_threshold": 145.68431091308594,
            "precision": 0.4452815972876248,
            "recall": 0.6237467018469657
        },
        "max": {
            "accuracy": 0.812421767896525,
            "ap": 0.5589788752976392,
            "f1": 0.5427360489757476
        }
    },
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}