{
  "dataset_revision": "87b7a0d1c402dbb481db649569c556d9aa27ac05",
  "task_name": "TweetTopicSingleClassification",
  "mteb_version": "1.38.9",
  "scores": {
    "test_2021": [
      {
        "accuracy": 0.81707,
        "f1": 0.663527,
        "f1_weighted": 0.828269,
        "scores_per_experiment": [
          {
            "accuracy": 0.828706,
            "f1": 0.670729,
            "f1_weighted": 0.838292
          },
          {
            "accuracy": 0.824572,
            "f1": 0.68017,
            "f1_weighted": 0.834797
          },
          {
            "accuracy": 0.813349,
            "f1": 0.657239,
            "f1_weighted": 0.82907
          },
          {
            "accuracy": 0.825753,
            "f1": 0.68992,
            "f1_weighted": 0.834865
          },
          {
            "accuracy": 0.829297,
            "f1": 0.684217,
            "f1_weighted": 0.839826
          },
          {
            "accuracy": 0.828116,
            "f1": 0.702897,
            "f1_weighted": 0.834107
          },
          {
            "accuracy": 0.793857,
            "f1": 0.614215,
            "f1_weighted": 0.800475
          },
          {
            "accuracy": 0.823981,
            "f1": 0.672096,
            "f1_weighted": 0.838044
          },
          {
            "accuracy": 0.786769,
            "f1": 0.605866,
            "f1_weighted": 0.80086
          },
          {
            "accuracy": 0.816302,
            "f1": 0.657925,
            "f1_weighted": 0.832352
          }
        ],
        "main_score": 0.81707,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.30490493774414,
  "kg_co2_emissions": null
}