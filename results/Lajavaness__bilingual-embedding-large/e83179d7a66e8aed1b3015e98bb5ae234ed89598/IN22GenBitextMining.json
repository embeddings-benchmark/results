{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.440379,
        "recall": 0.53125,
        "f1": 0.464569,
        "accuracy": 0.53125,
        "main_score": 0.464569,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.961589,
        "recall": 0.973633,
        "f1": 0.965495,
        "accuracy": 0.973633,
        "main_score": 0.965495,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.931803,
        "recall": 0.952148,
        "f1": 0.938314,
        "accuracy": 0.952148,
        "main_score": 0.938314,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.900716,
        "recall": 0.930664,
        "f1": 0.910319,
        "accuracy": 0.930664,
        "main_score": 0.910319,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003033,
        "recall": 0.011719,
        "f1": 0.00375,
        "accuracy": 0.011719,
        "main_score": 0.00375,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.978027,
        "recall": 0.985352,
        "f1": 0.980469,
        "accuracy": 0.985352,
        "main_score": 0.980469,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001594,
        "recall": 0.011719,
        "f1": 0.002092,
        "accuracy": 0.011719,
        "main_score": 0.002092,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.871477,
        "recall": 0.907227,
        "f1": 0.882471,
        "accuracy": 0.907227,
        "main_score": 0.882471,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.431497,
        "recall": 0.524414,
        "f1": 0.455393,
        "accuracy": 0.524414,
        "main_score": 0.455393,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.962728,
        "recall": 0.974609,
        "f1": 0.966634,
        "accuracy": 0.974609,
        "main_score": 0.966634,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.944092,
        "recall": 0.961914,
        "f1": 0.949935,
        "accuracy": 0.961914,
        "main_score": 0.949935,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.904541,
        "recall": 0.932617,
        "f1": 0.913477,
        "accuracy": 0.932617,
        "main_score": 0.913477,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00441,
        "recall": 0.019531,
        "f1": 0.00626,
        "accuracy": 0.019531,
        "main_score": 0.00626,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.988607,
        "recall": 0.992188,
        "f1": 0.989746,
        "accuracy": 0.992188,
        "main_score": 0.989746,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000598,
        "recall": 0.004883,
        "f1": 0.000984,
        "accuracy": 0.004883,
        "main_score": 0.000984,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.883984,
        "recall": 0.916016,
        "f1": 0.893848,
        "accuracy": 0.916016,
        "main_score": 0.893848,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.43,
        "recall": 0.482422,
        "f1": 0.442744,
        "accuracy": 0.482422,
        "main_score": 0.442744,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.414484,
        "recall": 0.479492,
        "f1": 0.429915,
        "accuracy": 0.479492,
        "main_score": 0.429915,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.472171,
        "recall": 0.525391,
        "f1": 0.485094,
        "accuracy": 0.525391,
        "main_score": 0.485094,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.356394,
        "recall": 0.416992,
        "f1": 0.369721,
        "accuracy": 0.416992,
        "main_score": 0.369721,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.452585,
        "recall": 0.505859,
        "f1": 0.465215,
        "accuracy": 0.505859,
        "main_score": 0.465215,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.411003,
        "recall": 0.467773,
        "f1": 0.424138,
        "accuracy": 0.467773,
        "main_score": 0.424138,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.437314,
        "recall": 0.503906,
        "f1": 0.453887,
        "accuracy": 0.503906,
        "main_score": 0.453887,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.396637,
        "recall": 0.469727,
        "f1": 0.413674,
        "accuracy": 0.469727,
        "main_score": 0.413674,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.397405,
        "recall": 0.455078,
        "f1": 0.411038,
        "accuracy": 0.455078,
        "main_score": 0.411038,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.435047,
        "recall": 0.503906,
        "f1": 0.452507,
        "accuracy": 0.503906,
        "main_score": 0.452507,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.413536,
        "recall": 0.467773,
        "f1": 0.427463,
        "accuracy": 0.467773,
        "main_score": 0.427463,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.419176,
        "recall": 0.492188,
        "f1": 0.437014,
        "accuracy": 0.492188,
        "main_score": 0.437014,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005554,
        "recall": 0.015625,
        "f1": 0.006474,
        "accuracy": 0.015625,
        "main_score": 0.006474,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.423172,
        "recall": 0.491211,
        "f1": 0.43963,
        "accuracy": 0.491211,
        "main_score": 0.43963,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.414959,
        "recall": 0.480469,
        "f1": 0.430605,
        "accuracy": 0.480469,
        "main_score": 0.430605,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.41861,
        "recall": 0.476562,
        "f1": 0.431368,
        "accuracy": 0.476562,
        "main_score": 0.431368,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.434271,
        "recall": 0.5,
        "f1": 0.450304,
        "accuracy": 0.5,
        "main_score": 0.450304,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003247,
        "recall": 0.010742,
        "f1": 0.003949,
        "accuracy": 0.010742,
        "main_score": 0.003949,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.482256,
        "recall": 0.541992,
        "f1": 0.496831,
        "accuracy": 0.541992,
        "main_score": 0.496831,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.380873,
        "recall": 0.445312,
        "f1": 0.39586,
        "accuracy": 0.445312,
        "main_score": 0.39586,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.431015,
        "recall": 0.496094,
        "f1": 0.447201,
        "accuracy": 0.496094,
        "main_score": 0.447201,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.398037,
        "recall": 0.454102,
        "f1": 0.410935,
        "accuracy": 0.454102,
        "main_score": 0.410935,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.960612,
        "recall": 0.972656,
        "f1": 0.964518,
        "accuracy": 0.972656,
        "main_score": 0.964518,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.96582,
        "recall": 0.976562,
        "f1": 0.969238,
        "accuracy": 0.976562,
        "main_score": 0.969238,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.467792,
        "recall": 0.553711,
        "f1": 0.489832,
        "accuracy": 0.553711,
        "main_score": 0.489832,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.953776,
        "recall": 0.96875,
        "f1": 0.958659,
        "accuracy": 0.96875,
        "main_score": 0.958659,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.913493,
        "recall": 0.94043,
        "f1": 0.922103,
        "accuracy": 0.94043,
        "main_score": 0.922103,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.979818,
        "recall": 0.986328,
        "f1": 0.981934,
        "accuracy": 0.986328,
        "main_score": 0.981934,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.87736,
        "recall": 0.913086,
        "f1": 0.888542,
        "accuracy": 0.913086,
        "main_score": 0.888542,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.967611,
        "recall": 0.977539,
        "f1": 0.970866,
        "accuracy": 0.977539,
        "main_score": 0.970866,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.971029,
        "recall": 0.980469,
        "f1": 0.974121,
        "accuracy": 0.980469,
        "main_score": 0.974121,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004842,
        "recall": 0.012695,
        "f1": 0.005412,
        "accuracy": 0.012695,
        "main_score": 0.005412,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.967285,
        "recall": 0.977539,
        "f1": 0.97054,
        "accuracy": 0.977539,
        "main_score": 0.97054,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.959798,
        "recall": 0.972656,
        "f1": 0.96403,
        "accuracy": 0.972656,
        "main_score": 0.96403,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.941732,
        "recall": 0.960938,
        "f1": 0.948079,
        "accuracy": 0.960938,
        "main_score": 0.948079,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002333,
        "recall": 0.010742,
        "f1": 0.00307,
        "accuracy": 0.010742,
        "main_score": 0.00307,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.877686,
        "recall": 0.911133,
        "f1": 0.887812,
        "accuracy": 0.911133,
        "main_score": 0.887812,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.964681,
        "recall": 0.975586,
        "f1": 0.968262,
        "accuracy": 0.975586,
        "main_score": 0.968262,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.972168,
        "recall": 0.981445,
        "f1": 0.97526,
        "accuracy": 0.981445,
        "main_score": 0.97526,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.387367,
        "recall": 0.498047,
        "f1": 0.415493,
        "accuracy": 0.498047,
        "main_score": 0.415493,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.946452,
        "recall": 0.963867,
        "f1": 0.952148,
        "accuracy": 0.963867,
        "main_score": 0.952148,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.923828,
        "recall": 0.947266,
        "f1": 0.931315,
        "accuracy": 0.947266,
        "main_score": 0.931315,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.871908,
        "recall": 0.90918,
        "f1": 0.883417,
        "accuracy": 0.90918,
        "main_score": 0.883417,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000899,
        "recall": 0.009766,
        "f1": 0.001554,
        "accuracy": 0.009766,
        "main_score": 0.001554,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.974772,
        "recall": 0.982422,
        "f1": 0.977214,
        "accuracy": 0.982422,
        "main_score": 0.977214,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.0012,
        "recall": 0.011719,
        "f1": 0.002011,
        "accuracy": 0.011719,
        "main_score": 0.002011,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.853223,
        "recall": 0.895508,
        "f1": 0.866178,
        "accuracy": 0.895508,
        "main_score": 0.866178,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.942627,
        "recall": 0.959961,
        "f1": 0.948145,
        "accuracy": 0.959961,
        "main_score": 0.948145,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.940592,
        "recall": 0.959961,
        "f1": 0.94694,
        "accuracy": 0.959961,
        "main_score": 0.94694,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.461941,
        "recall": 0.545898,
        "f1": 0.483756,
        "accuracy": 0.545898,
        "main_score": 0.483756,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.921387,
        "recall": 0.945312,
        "f1": 0.929004,
        "accuracy": 0.945312,
        "main_score": 0.929004,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.919922,
        "recall": 0.942383,
        "f1": 0.926679,
        "accuracy": 0.942383,
        "main_score": 0.926679,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.946045,
        "recall": 0.962891,
        "f1": 0.9514,
        "accuracy": 0.962891,
        "main_score": 0.9514,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.946077,
        "recall": 0.961914,
        "f1": 0.950911,
        "accuracy": 0.961914,
        "main_score": 0.950911,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.95166,
        "recall": 0.966797,
        "f1": 0.956543,
        "accuracy": 0.966797,
        "main_score": 0.956543,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.836263,
        "recall": 0.878906,
        "f1": 0.84974,
        "accuracy": 0.878906,
        "main_score": 0.84974,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.966146,
        "recall": 0.976562,
        "f1": 0.969564,
        "accuracy": 0.976562,
        "main_score": 0.969564,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.935628,
        "recall": 0.954102,
        "f1": 0.941276,
        "accuracy": 0.954102,
        "main_score": 0.941276,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.969271,
        "recall": 0.978516,
        "f1": 0.972168,
        "accuracy": 0.978516,
        "main_score": 0.972168,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004177,
        "recall": 0.014648,
        "f1": 0.004959,
        "accuracy": 0.014648,
        "main_score": 0.004959,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.962565,
        "recall": 0.974609,
        "f1": 0.966471,
        "accuracy": 0.974609,
        "main_score": 0.966471,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.935059,
        "recall": 0.954102,
        "f1": 0.941081,
        "accuracy": 0.954102,
        "main_score": 0.941081,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.911979,
        "recall": 0.935547,
        "f1": 0.919434,
        "accuracy": 0.935547,
        "main_score": 0.919434,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.915853,
        "recall": 0.939453,
        "f1": 0.923307,
        "accuracy": 0.939453,
        "main_score": 0.923307,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002425,
        "recall": 0.009766,
        "f1": 0.002825,
        "accuracy": 0.009766,
        "main_score": 0.002825,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.824056,
        "recall": 0.867188,
        "f1": 0.837291,
        "accuracy": 0.867188,
        "main_score": 0.837291,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.922119,
        "recall": 0.945312,
        "f1": 0.929427,
        "accuracy": 0.945312,
        "main_score": 0.929427,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.949984,
        "recall": 0.964844,
        "f1": 0.954655,
        "accuracy": 0.964844,
        "main_score": 0.954655,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.940348,
        "recall": 0.958008,
        "f1": 0.945866,
        "accuracy": 0.958008,
        "main_score": 0.945866,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.441361,
        "recall": 0.532227,
        "f1": 0.464163,
        "accuracy": 0.532227,
        "main_score": 0.464163,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.981445,
        "recall": 0.987305,
        "f1": 0.983398,
        "accuracy": 0.987305,
        "main_score": 0.983398,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.953451,
        "recall": 0.96875,
        "f1": 0.958496,
        "accuracy": 0.96875,
        "main_score": 0.958496,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.918457,
        "recall": 0.943359,
        "f1": 0.926595,
        "accuracy": 0.943359,
        "main_score": 0.926595,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995931,
        "recall": 0.99707,
        "f1": 0.996257,
        "accuracy": 0.99707,
        "main_score": 0.996257,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002867,
        "recall": 0.015625,
        "f1": 0.004218,
        "accuracy": 0.015625,
        "main_score": 0.004218,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.983561,
        "recall": 0.988281,
        "f1": 0.985026,
        "accuracy": 0.988281,
        "main_score": 0.985026,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002138,
        "recall": 0.012695,
        "f1": 0.002952,
        "accuracy": 0.012695,
        "main_score": 0.002952,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.898063,
        "recall": 0.925781,
        "f1": 0.906445,
        "accuracy": 0.925781,
        "main_score": 0.906445,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.997396,
        "recall": 0.998047,
        "f1": 0.997559,
        "accuracy": 0.998047,
        "main_score": 0.997559,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.419146,
        "recall": 0.524414,
        "f1": 0.445972,
        "accuracy": 0.524414,
        "main_score": 0.445972,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.976562,
        "recall": 0.984375,
        "f1": 0.979167,
        "accuracy": 0.984375,
        "main_score": 0.979167,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.940918,
        "recall": 0.959961,
        "f1": 0.947103,
        "accuracy": 0.959961,
        "main_score": 0.947103,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.896924,
        "recall": 0.926758,
        "f1": 0.906315,
        "accuracy": 0.926758,
        "main_score": 0.906315,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001385,
        "recall": 0.010742,
        "f1": 0.00221,
        "accuracy": 0.010742,
        "main_score": 0.00221,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.976156,
        "recall": 0.983398,
        "f1": 0.978418,
        "accuracy": 0.983398,
        "main_score": 0.978418,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002204,
        "recall": 0.008789,
        "f1": 0.002429,
        "accuracy": 0.008789,
        "main_score": 0.002429,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.880762,
        "recall": 0.915039,
        "f1": 0.891243,
        "accuracy": 0.915039,
        "main_score": 0.891243,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.387582,
        "recall": 0.485352,
        "f1": 0.412109,
        "accuracy": 0.485352,
        "main_score": 0.412109,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.96696,
        "recall": 0.977539,
        "f1": 0.970378,
        "accuracy": 0.977539,
        "main_score": 0.970378,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.995931,
        "recall": 0.99707,
        "f1": 0.996257,
        "accuracy": 0.99707,
        "main_score": 0.996257,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.932617,
        "recall": 0.954102,
        "f1": 0.939616,
        "accuracy": 0.954102,
        "main_score": 0.939616,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.903727,
        "recall": 0.931641,
        "f1": 0.912663,
        "accuracy": 0.931641,
        "main_score": 0.912663,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003065,
        "recall": 0.014648,
        "f1": 0.004177,
        "accuracy": 0.014648,
        "main_score": 0.004177,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001304,
        "recall": 0.010742,
        "f1": 0.001912,
        "accuracy": 0.010742,
        "main_score": 0.001912,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.869914,
        "recall": 0.904297,
        "f1": 0.88036,
        "accuracy": 0.904297,
        "main_score": 0.88036,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.905013,
        "recall": 0.932617,
        "f1": 0.913737,
        "accuracy": 0.932617,
        "main_score": 0.913737,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.903158,
        "recall": 0.930664,
        "f1": 0.911868,
        "accuracy": 0.930664,
        "main_score": 0.911868,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.423231,
        "recall": 0.500977,
        "f1": 0.443522,
        "accuracy": 0.500977,
        "main_score": 0.443522,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.897949,
        "recall": 0.926758,
        "f1": 0.907064,
        "accuracy": 0.926758,
        "main_score": 0.907064,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.896037,
        "recall": 0.925781,
        "f1": 0.905184,
        "accuracy": 0.925781,
        "main_score": 0.905184,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.840332,
        "recall": 0.882812,
        "f1": 0.853418,
        "accuracy": 0.882812,
        "main_score": 0.853418,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.91735,
        "recall": 0.942383,
        "f1": 0.925456,
        "accuracy": 0.942383,
        "main_score": 0.925456,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.914632,
        "recall": 0.939453,
        "f1": 0.922363,
        "accuracy": 0.939453,
        "main_score": 0.922363,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.913714,
        "recall": 0.9375,
        "f1": 0.921096,
        "accuracy": 0.9375,
        "main_score": 0.921096,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.929069,
        "recall": 0.949219,
        "f1": 0.935547,
        "accuracy": 0.949219,
        "main_score": 0.935547,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.910514,
        "recall": 0.936523,
        "f1": 0.918587,
        "accuracy": 0.936523,
        "main_score": 0.918587,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.911819,
        "recall": 0.935547,
        "f1": 0.919173,
        "accuracy": 0.935547,
        "main_score": 0.919173,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003206,
        "recall": 0.016602,
        "f1": 0.004449,
        "accuracy": 0.016602,
        "main_score": 0.004449,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.922428,
        "recall": 0.944336,
        "f1": 0.929036,
        "accuracy": 0.944336,
        "main_score": 0.929036,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.909049,
        "recall": 0.93457,
        "f1": 0.916913,
        "accuracy": 0.93457,
        "main_score": 0.916913,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.903597,
        "recall": 0.929688,
        "f1": 0.911361,
        "accuracy": 0.929688,
        "main_score": 0.911361,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.871582,
        "recall": 0.90918,
        "f1": 0.883268,
        "accuracy": 0.90918,
        "main_score": 0.883268,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005868,
        "recall": 0.017578,
        "f1": 0.007053,
        "accuracy": 0.017578,
        "main_score": 0.007053,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.797673,
        "recall": 0.84668,
        "f1": 0.812486,
        "accuracy": 0.84668,
        "main_score": 0.812486,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.87623,
        "recall": 0.90918,
        "f1": 0.886344,
        "accuracy": 0.90918,
        "main_score": 0.886344,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.90612,
        "recall": 0.930664,
        "f1": 0.913658,
        "accuracy": 0.930664,
        "main_score": 0.913658,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.938021,
        "recall": 0.957031,
        "f1": 0.94401,
        "accuracy": 0.957031,
        "main_score": 0.94401,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.442411,
        "recall": 0.537109,
        "f1": 0.466906,
        "accuracy": 0.537109,
        "main_score": 0.466906,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.995931,
        "recall": 0.99707,
        "f1": 0.996257,
        "accuracy": 0.99707,
        "main_score": 0.996257,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.96167,
        "recall": 0.972656,
        "f1": 0.965234,
        "accuracy": 0.972656,
        "main_score": 0.965234,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.92513,
        "recall": 0.947266,
        "f1": 0.932292,
        "accuracy": 0.947266,
        "main_score": 0.932292,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00409,
        "recall": 0.015625,
        "f1": 0.005199,
        "accuracy": 0.015625,
        "main_score": 0.005199,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.986003,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002267,
        "recall": 0.007812,
        "f1": 0.002522,
        "accuracy": 0.007812,
        "main_score": 0.002522,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.897282,
        "recall": 0.927734,
        "f1": 0.906803,
        "accuracy": 0.927734,
        "main_score": 0.906803,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.432908,
        "recall": 0.524414,
        "f1": 0.456366,
        "accuracy": 0.524414,
        "main_score": 0.456366,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.961914,
        "recall": 0.974609,
        "f1": 0.966146,
        "accuracy": 0.974609,
        "main_score": 0.966146,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.928548,
        "recall": 0.950195,
        "f1": 0.935547,
        "accuracy": 0.950195,
        "main_score": 0.935547,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.993001,
        "recall": 0.995117,
        "f1": 0.993652,
        "accuracy": 0.995117,
        "main_score": 0.993652,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991536,
        "recall": 0.994141,
        "f1": 0.99235,
        "accuracy": 0.994141,
        "main_score": 0.99235,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.902425,
        "recall": 0.929688,
        "f1": 0.911035,
        "accuracy": 0.929688,
        "main_score": 0.911035,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004585,
        "recall": 0.015625,
        "f1": 0.005633,
        "accuracy": 0.015625,
        "main_score": 0.005633,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.98584,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.975911,
        "recall": 0.983398,
        "f1": 0.978353,
        "accuracy": 0.983398,
        "main_score": 0.978353,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002067,
        "recall": 0.009766,
        "f1": 0.002696,
        "accuracy": 0.009766,
        "main_score": 0.002696,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.877686,
        "recall": 0.914062,
        "f1": 0.889225,
        "accuracy": 0.914062,
        "main_score": 0.889225,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.438145,
        "recall": 0.53418,
        "f1": 0.462302,
        "accuracy": 0.53418,
        "main_score": 0.462302,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.967122,
        "recall": 0.977539,
        "f1": 0.97054,
        "accuracy": 0.977539,
        "main_score": 0.97054,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.949707,
        "recall": 0.96582,
        "f1": 0.955078,
        "accuracy": 0.96582,
        "main_score": 0.955078,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.910189,
        "recall": 0.93457,
        "f1": 0.917969,
        "accuracy": 0.93457,
        "main_score": 0.917969,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.002121,
        "recall": 0.012695,
        "f1": 0.002837,
        "accuracy": 0.012695,
        "main_score": 0.002837,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.982747,
        "recall": 0.988281,
        "f1": 0.984538,
        "accuracy": 0.988281,
        "main_score": 0.984538,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000831,
        "recall": 0.007812,
        "f1": 0.001263,
        "accuracy": 0.007812,
        "main_score": 0.001263,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.876579,
        "recall": 0.910156,
        "f1": 0.887077,
        "accuracy": 0.910156,
        "main_score": 0.887077,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993652,
        "recall": 0.995117,
        "f1": 0.994141,
        "accuracy": 0.995117,
        "main_score": 0.994141,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000698,
        "recall": 0.005859,
        "f1": 0.001069,
        "accuracy": 0.005859,
        "main_score": 0.001069,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002127,
        "recall": 0.004883,
        "f1": 0.002273,
        "accuracy": 0.004883,
        "main_score": 0.002273,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.003374,
        "recall": 0.008789,
        "f1": 0.004044,
        "accuracy": 0.008789,
        "main_score": 0.004044,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.003492,
        "recall": 0.006836,
        "f1": 0.003823,
        "accuracy": 0.006836,
        "main_score": 0.003823,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001107,
        "recall": 0.00293,
        "f1": 0.001214,
        "accuracy": 0.00293,
        "main_score": 0.001214,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002793,
        "recall": 0.007812,
        "f1": 0.003365,
        "accuracy": 0.007812,
        "main_score": 0.003365,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.00223,
        "recall": 0.006836,
        "f1": 0.002436,
        "accuracy": 0.006836,
        "main_score": 0.002436,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002187,
        "recall": 0.005859,
        "f1": 0.002375,
        "accuracy": 0.005859,
        "main_score": 0.002375,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000284,
        "recall": 0.003906,
        "f1": 0.000515,
        "accuracy": 0.003906,
        "main_score": 0.000515,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001168,
        "recall": 0.003906,
        "f1": 0.001649,
        "accuracy": 0.003906,
        "main_score": 0.001649,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.001448,
        "recall": 0.005859,
        "f1": 0.001789,
        "accuracy": 0.005859,
        "main_score": 0.001789,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.001104,
        "recall": 0.003906,
        "f1": 0.001208,
        "accuracy": 0.003906,
        "main_score": 0.001208,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.002192,
        "recall": 0.005859,
        "f1": 0.002363,
        "accuracy": 0.005859,
        "main_score": 0.002363,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000136,
        "recall": 0.003906,
        "f1": 0.000251,
        "accuracy": 0.003906,
        "main_score": 0.000251,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001179,
        "recall": 0.003906,
        "f1": 0.001342,
        "accuracy": 0.003906,
        "main_score": 0.001342,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.000437,
        "recall": 0.005859,
        "f1": 0.000749,
        "accuracy": 0.005859,
        "main_score": 0.000749,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004132,
        "recall": 0.007812,
        "f1": 0.004618,
        "accuracy": 0.007812,
        "main_score": 0.004618,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.059606,
        "recall": 0.09082,
        "f1": 0.067407,
        "accuracy": 0.09082,
        "main_score": 0.067407,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.001718,
        "recall": 0.004883,
        "f1": 0.002036,
        "accuracy": 0.004883,
        "main_score": 0.002036,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.001859,
        "recall": 0.006836,
        "f1": 0.002402,
        "accuracy": 0.006836,
        "main_score": 0.002402,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000587,
        "recall": 0.00293,
        "f1": 0.000831,
        "accuracy": 0.00293,
        "main_score": 0.000831,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00035,
        "recall": 0.004883,
        "f1": 0.000644,
        "accuracy": 0.004883,
        "main_score": 0.000644,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.449359,
        "recall": 0.544922,
        "f1": 0.474005,
        "accuracy": 0.544922,
        "main_score": 0.474005,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.954915,
        "recall": 0.969727,
        "f1": 0.959798,
        "accuracy": 0.969727,
        "main_score": 0.959798,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.926921,
        "recall": 0.950195,
        "f1": 0.93457,
        "accuracy": 0.950195,
        "main_score": 0.93457,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002731,
        "recall": 0.010742,
        "f1": 0.00325,
        "accuracy": 0.010742,
        "main_score": 0.00325,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.984701,
        "recall": 0.989258,
        "f1": 0.986165,
        "accuracy": 0.989258,
        "main_score": 0.986165,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002382,
        "recall": 0.010742,
        "f1": 0.003067,
        "accuracy": 0.010742,
        "main_score": 0.003067,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.884254,
        "recall": 0.916016,
        "f1": 0.894092,
        "accuracy": 0.916016,
        "main_score": 0.894092,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.992025,
        "recall": 0.994141,
        "f1": 0.992676,
        "accuracy": 0.994141,
        "main_score": 0.992676,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.41576,
        "recall": 0.506836,
        "f1": 0.439542,
        "accuracy": 0.506836,
        "main_score": 0.439542,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.963704,
        "recall": 0.975586,
        "f1": 0.967611,
        "accuracy": 0.975586,
        "main_score": 0.967611,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.927572,
        "recall": 0.950195,
        "f1": 0.934896,
        "accuracy": 0.950195,
        "main_score": 0.934896,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.912109,
        "recall": 0.939453,
        "f1": 0.921061,
        "accuracy": 0.939453,
        "main_score": 0.921061,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002682,
        "recall": 0.013672,
        "f1": 0.003683,
        "accuracy": 0.013672,
        "main_score": 0.003683,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001418,
        "recall": 0.008789,
        "f1": 0.001774,
        "accuracy": 0.008789,
        "main_score": 0.001774,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.886768,
        "recall": 0.917969,
        "f1": 0.896239,
        "accuracy": 0.917969,
        "main_score": 0.896239,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.438622,
        "recall": 0.53418,
        "f1": 0.463622,
        "accuracy": 0.53418,
        "main_score": 0.463622,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.95459,
        "recall": 0.969727,
        "f1": 0.959635,
        "accuracy": 0.969727,
        "main_score": 0.959635,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.909993,
        "recall": 0.936523,
        "f1": 0.918424,
        "accuracy": 0.936523,
        "main_score": 0.918424,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.903564,
        "recall": 0.932617,
        "f1": 0.912663,
        "accuracy": 0.932617,
        "main_score": 0.912663,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.992188,
        "recall": 0.994141,
        "f1": 0.992839,
        "accuracy": 0.994141,
        "main_score": 0.992839,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.993001,
        "recall": 0.995117,
        "f1": 0.993652,
        "accuracy": 0.995117,
        "main_score": 0.993652,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004175,
        "recall": 0.014648,
        "f1": 0.00532,
        "accuracy": 0.014648,
        "main_score": 0.00532,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.971517,
        "recall": 0.980469,
        "f1": 0.974447,
        "accuracy": 0.980469,
        "main_score": 0.974447,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001908,
        "recall": 0.011719,
        "f1": 0.002455,
        "accuracy": 0.011719,
        "main_score": 0.002455,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.863363,
        "recall": 0.899414,
        "f1": 0.874484,
        "accuracy": 0.899414,
        "main_score": 0.874484,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.98877,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.977376,
        "recall": 0.984375,
        "f1": 0.979655,
        "accuracy": 0.984375,
        "main_score": 0.979655,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.461228,
        "recall": 0.550781,
        "f1": 0.484383,
        "accuracy": 0.550781,
        "main_score": 0.484383,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.94401,
        "recall": 0.961914,
        "f1": 0.94987,
        "accuracy": 0.961914,
        "main_score": 0.94987,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.980306,
        "recall": 0.986328,
        "f1": 0.982259,
        "accuracy": 0.986328,
        "main_score": 0.982259,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.90918,
        "recall": 0.936523,
        "f1": 0.917969,
        "accuracy": 0.936523,
        "main_score": 0.917969,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.978353,
        "recall": 0.985352,
        "f1": 0.980632,
        "accuracy": 0.985352,
        "main_score": 0.980632,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.983398,
        "recall": 0.988281,
        "f1": 0.984863,
        "accuracy": 0.988281,
        "main_score": 0.984863,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.874674,
        "recall": 0.911133,
        "f1": 0.886393,
        "accuracy": 0.911133,
        "main_score": 0.886393,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.987142,
        "recall": 0.991211,
        "f1": 0.988444,
        "accuracy": 0.991211,
        "main_score": 0.988444,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.98291,
        "recall": 0.988281,
        "f1": 0.984701,
        "accuracy": 0.988281,
        "main_score": 0.984701,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004005,
        "recall": 0.015625,
        "f1": 0.005115,
        "accuracy": 0.015625,
        "main_score": 0.005115,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.980306,
        "recall": 0.986328,
        "f1": 0.982259,
        "accuracy": 0.986328,
        "main_score": 0.982259,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.979004,
        "recall": 0.985352,
        "f1": 0.98112,
        "accuracy": 0.985352,
        "main_score": 0.98112,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004254,
        "recall": 0.013672,
        "f1": 0.005364,
        "accuracy": 0.013672,
        "main_score": 0.005364,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.85127,
        "recall": 0.890625,
        "f1": 0.863216,
        "accuracy": 0.890625,
        "main_score": 0.863216,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.975911,
        "recall": 0.983398,
        "f1": 0.978353,
        "accuracy": 0.983398,
        "main_score": 0.978353,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.003443,
        "recall": 0.006836,
        "f1": 0.00363,
        "accuracy": 0.006836,
        "main_score": 0.00363,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002164,
        "recall": 0.007812,
        "f1": 0.002673,
        "accuracy": 0.007812,
        "main_score": 0.002673,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.004471,
        "recall": 0.006836,
        "f1": 0.004702,
        "accuracy": 0.006836,
        "main_score": 0.004702,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.004728,
        "recall": 0.007812,
        "f1": 0.005061,
        "accuracy": 0.007812,
        "main_score": 0.005061,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001662,
        "recall": 0.003906,
        "f1": 0.001956,
        "accuracy": 0.003906,
        "main_score": 0.001956,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004457,
        "recall": 0.008789,
        "f1": 0.005104,
        "accuracy": 0.008789,
        "main_score": 0.005104,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.004513,
        "recall": 0.009766,
        "f1": 0.004786,
        "accuracy": 0.009766,
        "main_score": 0.004786,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000684,
        "recall": 0.001953,
        "f1": 0.000977,
        "accuracy": 0.001953,
        "main_score": 0.000977,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003351,
        "recall": 0.007812,
        "f1": 0.003677,
        "accuracy": 0.007812,
        "main_score": 0.003677,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001416,
        "recall": 0.004883,
        "f1": 0.001747,
        "accuracy": 0.004883,
        "main_score": 0.001747,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.001297,
        "recall": 0.005859,
        "f1": 0.001535,
        "accuracy": 0.005859,
        "main_score": 0.001535,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.002536,
        "recall": 0.007812,
        "f1": 0.002941,
        "accuracy": 0.007812,
        "main_score": 0.002941,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.002872,
        "recall": 0.006836,
        "f1": 0.003288,
        "accuracy": 0.006836,
        "main_score": 0.003288,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.052189,
        "recall": 0.089844,
        "f1": 0.061298,
        "accuracy": 0.089844,
        "main_score": 0.061298,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.003817,
        "recall": 0.006836,
        "f1": 0.004248,
        "accuracy": 0.006836,
        "main_score": 0.004248,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.002527,
        "recall": 0.007812,
        "f1": 0.002886,
        "accuracy": 0.007812,
        "main_score": 0.002886,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.001621,
        "recall": 0.005859,
        "f1": 0.001905,
        "accuracy": 0.005859,
        "main_score": 0.001905,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004191,
        "recall": 0.007812,
        "f1": 0.004413,
        "accuracy": 0.007812,
        "main_score": 0.004413,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002915,
        "recall": 0.007812,
        "f1": 0.00337,
        "accuracy": 0.007812,
        "main_score": 0.00337,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.002767,
        "recall": 0.003906,
        "f1": 0.003092,
        "accuracy": 0.003906,
        "main_score": 0.003092,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.004291,
        "recall": 0.006836,
        "f1": 0.004544,
        "accuracy": 0.006836,
        "main_score": 0.004544,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.0013,
        "recall": 0.004883,
        "f1": 0.001563,
        "accuracy": 0.004883,
        "main_score": 0.001563,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.86862,
        "recall": 0.90332,
        "f1": 0.879247,
        "accuracy": 0.90332,
        "main_score": 0.879247,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.894694,
        "recall": 0.926758,
        "f1": 0.904901,
        "accuracy": 0.926758,
        "main_score": 0.904901,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.48716,
        "recall": 0.569336,
        "f1": 0.509789,
        "accuracy": 0.569336,
        "main_score": 0.509789,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.89554,
        "recall": 0.923828,
        "f1": 0.904264,
        "accuracy": 0.923828,
        "main_score": 0.904264,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.857284,
        "recall": 0.895508,
        "f1": 0.868479,
        "accuracy": 0.895508,
        "main_score": 0.868479,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.831299,
        "recall": 0.874023,
        "f1": 0.84455,
        "accuracy": 0.874023,
        "main_score": 0.84455,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.897038,
        "recall": 0.926758,
        "f1": 0.906185,
        "accuracy": 0.926758,
        "main_score": 0.906185,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.914811,
        "recall": 0.9375,
        "f1": 0.921517,
        "accuracy": 0.9375,
        "main_score": 0.921517,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.891253,
        "recall": 0.920898,
        "f1": 0.900393,
        "accuracy": 0.920898,
        "main_score": 0.900393,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.801442,
        "recall": 0.849609,
        "f1": 0.81613,
        "accuracy": 0.849609,
        "main_score": 0.81613,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.910596,
        "recall": 0.9375,
        "f1": 0.919173,
        "accuracy": 0.9375,
        "main_score": 0.919173,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.888444,
        "recall": 0.916992,
        "f1": 0.896777,
        "accuracy": 0.916992,
        "main_score": 0.896777,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.893343,
        "recall": 0.924805,
        "f1": 0.903176,
        "accuracy": 0.924805,
        "main_score": 0.903176,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005283,
        "recall": 0.013672,
        "f1": 0.006387,
        "accuracy": 0.013672,
        "main_score": 0.006387,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.888298,
        "recall": 0.919922,
        "f1": 0.897949,
        "accuracy": 0.919922,
        "main_score": 0.897949,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.902165,
        "recall": 0.929688,
        "f1": 0.91071,
        "accuracy": 0.929688,
        "main_score": 0.91071,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.876855,
        "recall": 0.90918,
        "f1": 0.886849,
        "accuracy": 0.90918,
        "main_score": 0.886849,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.846875,
        "recall": 0.888672,
        "f1": 0.859784,
        "accuracy": 0.888672,
        "main_score": 0.859784,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001925,
        "recall": 0.010742,
        "f1": 0.002616,
        "accuracy": 0.010742,
        "main_score": 0.002616,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.861849,
        "recall": 0.898438,
        "f1": 0.872819,
        "accuracy": 0.898438,
        "main_score": 0.872819,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.895291,
        "recall": 0.922852,
        "f1": 0.903613,
        "accuracy": 0.922852,
        "main_score": 0.903613,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.898258,
        "recall": 0.927734,
        "f1": 0.907292,
        "accuracy": 0.927734,
        "main_score": 0.907292,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.388735,
        "recall": 0.484375,
        "f1": 0.412498,
        "accuracy": 0.484375,
        "main_score": 0.412498,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.95931,
        "recall": 0.972656,
        "f1": 0.963704,
        "accuracy": 0.972656,
        "main_score": 0.963704,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.922119,
        "recall": 0.946289,
        "f1": 0.929915,
        "accuracy": 0.946289,
        "main_score": 0.929915,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.88265,
        "recall": 0.917969,
        "f1": 0.893848,
        "accuracy": 0.917969,
        "main_score": 0.893848,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003658,
        "recall": 0.017578,
        "f1": 0.004697,
        "accuracy": 0.017578,
        "main_score": 0.004697,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.990072,
        "recall": 0.993164,
        "f1": 0.991048,
        "accuracy": 0.993164,
        "main_score": 0.991048,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001574,
        "recall": 0.009766,
        "f1": 0.002052,
        "accuracy": 0.009766,
        "main_score": 0.002052,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.849528,
        "recall": 0.890625,
        "f1": 0.86177,
        "accuracy": 0.890625,
        "main_score": 0.86177,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.424404,
        "recall": 0.515625,
        "f1": 0.447311,
        "accuracy": 0.515625,
        "main_score": 0.447311,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.95931,
        "recall": 0.972656,
        "f1": 0.963704,
        "accuracy": 0.972656,
        "main_score": 0.963704,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.932129,
        "recall": 0.953125,
        "f1": 0.938965,
        "accuracy": 0.953125,
        "main_score": 0.938965,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.903076,
        "recall": 0.931641,
        "f1": 0.912174,
        "accuracy": 0.931641,
        "main_score": 0.912174,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003789,
        "recall": 0.014648,
        "f1": 0.004778,
        "accuracy": 0.014648,
        "main_score": 0.004778,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000815,
        "recall": 0.009766,
        "f1": 0.001268,
        "accuracy": 0.009766,
        "main_score": 0.001268,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.879346,
        "recall": 0.913086,
        "f1": 0.889876,
        "accuracy": 0.913086,
        "main_score": 0.889876,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.409406,
        "recall": 0.511719,
        "f1": 0.436244,
        "accuracy": 0.511719,
        "main_score": 0.436244,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.976888,
        "recall": 0.984375,
        "f1": 0.979329,
        "accuracy": 0.984375,
        "main_score": 0.979329,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.931315,
        "recall": 0.953125,
        "f1": 0.938477,
        "accuracy": 0.953125,
        "main_score": 0.938477,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.923398,
        "recall": 0.945312,
        "f1": 0.930322,
        "accuracy": 0.945312,
        "main_score": 0.930322,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002645,
        "recall": 0.014648,
        "f1": 0.003691,
        "accuracy": 0.014648,
        "main_score": 0.003691,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002015,
        "recall": 0.013672,
        "f1": 0.002788,
        "accuracy": 0.013672,
        "main_score": 0.002788,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.891553,
        "recall": 0.921875,
        "f1": 0.900749,
        "accuracy": 0.921875,
        "main_score": 0.900749,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 63.23282599449158,
  "kg_co2_emissions": 0.003562236104235668
}