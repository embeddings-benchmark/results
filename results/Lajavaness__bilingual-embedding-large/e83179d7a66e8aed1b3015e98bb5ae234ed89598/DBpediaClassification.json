{
  "dataset_revision": "9abd46cf7fc8b4c64290f26993c540b92aa145ac",
  "task_name": "DBpediaClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.915332,
        "f1": 0.91215,
        "f1_weighted": 0.912144,
        "scores_per_experiment": [
          {
            "accuracy": 0.927246,
            "f1": 0.92505,
            "f1_weighted": 0.925051
          },
          {
            "accuracy": 0.92041,
            "f1": 0.916356,
            "f1_weighted": 0.91635
          },
          {
            "accuracy": 0.916504,
            "f1": 0.913548,
            "f1_weighted": 0.913551
          },
          {
            "accuracy": 0.902344,
            "f1": 0.899649,
            "f1_weighted": 0.899618
          },
          {
            "accuracy": 0.912598,
            "f1": 0.910347,
            "f1_weighted": 0.910323
          },
          {
            "accuracy": 0.92041,
            "f1": 0.917897,
            "f1_weighted": 0.91789
          },
          {
            "accuracy": 0.930664,
            "f1": 0.928511,
            "f1_weighted": 0.928517
          },
          {
            "accuracy": 0.899902,
            "f1": 0.897137,
            "f1_weighted": 0.897126
          },
          {
            "accuracy": 0.911621,
            "f1": 0.907115,
            "f1_weighted": 0.907099
          },
          {
            "accuracy": 0.911621,
            "f1": 0.90589,
            "f1_weighted": 0.905916
          }
        ],
        "main_score": 0.915332,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.621004819869995,
  "kg_co2_emissions": 0.0006651858250038959
}