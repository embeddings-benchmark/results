{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.8",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.536901,
            "f1": 0.517326,
            "f1_weighted": 0.517403,
            "precision": 0.531918,
            "precision_weighted": 0.531988,
            "recall": 0.536811,
            "recall_weighted": 0.536901,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.530881,
            "f1": 0.512078,
            "f1_weighted": 0.511969,
            "precision": 0.529898,
            "precision_weighted": 0.52983,
            "recall": 0.531004,
            "recall_weighted": 0.530881,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.544928,
            "f1": 0.51895,
            "f1_weighted": 0.51889,
            "precision": 0.528957,
            "precision_weighted": 0.528879,
            "recall": 0.544962,
            "recall_weighted": 0.544928,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.539799,
            "f1": 0.520167,
            "f1_weighted": 0.520143,
            "precision": 0.526213,
            "precision_weighted": 0.526231,
            "recall": 0.539859,
            "recall_weighted": 0.539799,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.523969,
            "f1": 0.506504,
            "f1_weighted": 0.506481,
            "precision": 0.518696,
            "precision_weighted": 0.518708,
            "recall": 0.523995,
            "recall_weighted": 0.523969,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.52107,
            "f1": 0.505929,
            "f1_weighted": 0.505853,
            "precision": 0.516859,
            "precision_weighted": 0.516862,
            "recall": 0.521221,
            "recall_weighted": 0.52107,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.527536,
            "f1": 0.506256,
            "f1_weighted": 0.506218,
            "precision": 0.520231,
            "precision_weighted": 0.52021,
            "recall": 0.527537,
            "recall_weighted": 0.527536,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.537793,
            "f1": 0.515242,
            "f1_weighted": 0.515173,
            "precision": 0.525603,
            "precision_weighted": 0.525563,
            "recall": 0.537863,
            "recall_weighted": 0.537793,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.504794,
            "f1": 0.480845,
            "f1_weighted": 0.480627,
            "precision": 0.497796,
            "precision_weighted": 0.497536,
            "recall": 0.504943,
            "recall_weighted": 0.504794,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.519287,
            "f1": 0.499114,
            "f1_weighted": 0.499051,
            "precision": 0.50451,
            "precision_weighted": 0.504473,
            "recall": 0.519349,
            "recall_weighted": 0.519287,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.528696,
        "f1": 0.508241,
        "f1_weighted": 0.508181,
        "precision": 0.520068,
        "precision_weighted": 0.520028,
        "recall": 0.528754,
        "recall_weighted": 0.528696,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.508241,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 75.77077436447144,
  "kg_co2_emissions": null
}