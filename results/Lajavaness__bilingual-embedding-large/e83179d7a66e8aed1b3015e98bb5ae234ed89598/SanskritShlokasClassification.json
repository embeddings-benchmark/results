{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.695561,
        "f1": 0.695949,
        "f1_weighted": 0.696365,
        "scores_per_experiment": [
          {
            "accuracy": 0.723238,
            "f1": 0.724116,
            "f1_weighted": 0.724989
          },
          {
            "accuracy": 0.710183,
            "f1": 0.708581,
            "f1_weighted": 0.709025
          },
          {
            "accuracy": 0.655352,
            "f1": 0.658172,
            "f1_weighted": 0.655813
          },
          {
            "accuracy": 0.663185,
            "f1": 0.659439,
            "f1_weighted": 0.656585
          },
          {
            "accuracy": 0.712794,
            "f1": 0.715872,
            "f1_weighted": 0.71698
          },
          {
            "accuracy": 0.715405,
            "f1": 0.71867,
            "f1_weighted": 0.719469
          },
          {
            "accuracy": 0.686684,
            "f1": 0.693867,
            "f1_weighted": 0.693389
          },
          {
            "accuracy": 0.73107,
            "f1": 0.733314,
            "f1_weighted": 0.734637
          },
          {
            "accuracy": 0.699739,
            "f1": 0.696178,
            "f1_weighted": 0.699064
          },
          {
            "accuracy": 0.657963,
            "f1": 0.65128,
            "f1_weighted": 0.653699
          }
        ],
        "main_score": 0.695561,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.686458,
        "f1": 0.691932,
        "f1_weighted": 0.685769,
        "scores_per_experiment": [
          {
            "accuracy": 0.625,
            "f1": 0.638046,
            "f1_weighted": 0.630096
          },
          {
            "accuracy": 0.71875,
            "f1": 0.717958,
            "f1_weighted": 0.714347
          },
          {
            "accuracy": 0.635417,
            "f1": 0.643832,
            "f1_weighted": 0.633737
          },
          {
            "accuracy": 0.677083,
            "f1": 0.680494,
            "f1_weighted": 0.670813
          },
          {
            "accuracy": 0.770833,
            "f1": 0.765407,
            "f1_weighted": 0.765704
          },
          {
            "accuracy": 0.75,
            "f1": 0.761829,
            "f1_weighted": 0.753223
          },
          {
            "accuracy": 0.625,
            "f1": 0.642641,
            "f1_weighted": 0.631766
          },
          {
            "accuracy": 0.708333,
            "f1": 0.715152,
            "f1_weighted": 0.708396
          },
          {
            "accuracy": 0.708333,
            "f1": 0.708668,
            "f1_weighted": 0.706171
          },
          {
            "accuracy": 0.645833,
            "f1": 0.645296,
            "f1_weighted": 0.643441
          }
        ],
        "main_score": 0.686458,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 14.018869161605835,
  "kg_co2_emissions": 0.00042808672129742017
}