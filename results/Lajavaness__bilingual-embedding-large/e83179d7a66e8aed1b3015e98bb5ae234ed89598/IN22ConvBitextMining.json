{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.8526,
        "recall": 0.89155,
        "f1": 0.864454,
        "accuracy": 0.89155,
        "main_score": 0.864454,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.151442,
        "recall": 0.206919,
        "f1": 0.163998,
        "accuracy": 0.206919,
        "main_score": 0.163998,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.614,
        "recall": 0.683965,
        "f1": 0.633097,
        "accuracy": 0.683965,
        "main_score": 0.633097,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.813803,
        "recall": 0.856953,
        "f1": 0.825975,
        "accuracy": 0.856953,
        "main_score": 0.825975,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.50737,
        "recall": 0.5835,
        "f1": 0.527502,
        "accuracy": 0.5835,
        "main_score": 0.527502,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.827817,
        "recall": 0.862941,
        "f1": 0.838046,
        "accuracy": 0.862941,
        "main_score": 0.838046,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.830856,
        "recall": 0.869594,
        "f1": 0.842155,
        "accuracy": 0.869594,
        "main_score": 0.842155,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.711258,
        "recall": 0.762475,
        "f1": 0.724664,
        "accuracy": 0.762475,
        "main_score": 0.724664,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.506265,
        "recall": 0.581504,
        "f1": 0.526538,
        "accuracy": 0.581504,
        "main_score": 0.526538,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.808108,
        "recall": 0.847638,
        "f1": 0.819574,
        "accuracy": 0.847638,
        "main_score": 0.819574,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.806167,
        "recall": 0.849634,
        "f1": 0.818652,
        "accuracy": 0.849634,
        "main_score": 0.818652,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.837303,
        "recall": 0.874251,
        "f1": 0.848072,
        "accuracy": 0.874251,
        "main_score": 0.848072,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003406,
        "recall": 0.013307,
        "f1": 0.004518,
        "accuracy": 0.013307,
        "main_score": 0.004518,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.847577,
        "recall": 0.882236,
        "f1": 0.857734,
        "accuracy": 0.882236,
        "main_score": 0.857734,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.849512,
        "recall": 0.888224,
        "f1": 0.8613,
        "accuracy": 0.888224,
        "main_score": 0.8613,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.784969,
        "recall": 0.832335,
        "f1": 0.798683,
        "accuracy": 0.832335,
        "main_score": 0.798683,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.687363,
        "recall": 0.75316,
        "f1": 0.706701,
        "accuracy": 0.75316,
        "main_score": 0.706701,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00201,
        "recall": 0.008649,
        "f1": 0.00246,
        "accuracy": 0.008649,
        "main_score": 0.00246,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.465809,
        "recall": 0.540253,
        "f1": 0.485792,
        "accuracy": 0.540253,
        "main_score": 0.485792,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.703634,
        "recall": 0.758483,
        "f1": 0.718905,
        "accuracy": 0.758483,
        "main_score": 0.718905,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.782809,
        "recall": 0.829674,
        "f1": 0.796303,
        "accuracy": 0.829674,
        "main_score": 0.796303,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.839838,
        "recall": 0.876913,
        "f1": 0.850504,
        "accuracy": 0.876913,
        "main_score": 0.850504,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.835646,
        "recall": 0.872921,
        "f1": 0.846068,
        "accuracy": 0.872921,
        "main_score": 0.846068,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.140961,
        "recall": 0.205589,
        "f1": 0.155281,
        "accuracy": 0.205589,
        "main_score": 0.155281,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.657093,
        "recall": 0.729208,
        "f1": 0.677609,
        "accuracy": 0.729208,
        "main_score": 0.677609,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.905179,
        "recall": 0.929474,
        "f1": 0.91253,
        "accuracy": 0.929474,
        "main_score": 0.91253,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.530165,
        "recall": 0.610778,
        "f1": 0.551719,
        "accuracy": 0.610778,
        "main_score": 0.551719,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.895238,
        "recall": 0.916833,
        "f1": 0.901564,
        "accuracy": 0.916833,
        "main_score": 0.901564,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.919661,
        "recall": 0.942116,
        "f1": 0.926591,
        "accuracy": 0.942116,
        "main_score": 0.926591,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.756952,
        "recall": 0.803061,
        "f1": 0.769398,
        "accuracy": 0.803061,
        "main_score": 0.769398,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.543696,
        "recall": 0.625416,
        "f1": 0.566171,
        "accuracy": 0.625416,
        "main_score": 0.566171,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.8501,
        "recall": 0.888224,
        "f1": 0.861857,
        "accuracy": 0.888224,
        "main_score": 0.861857,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.875922,
        "recall": 0.907518,
        "f1": 0.885508,
        "accuracy": 0.907518,
        "main_score": 0.885508,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.891883,
        "recall": 0.92016,
        "f1": 0.900488,
        "accuracy": 0.92016,
        "main_score": 0.900488,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002225,
        "recall": 0.010645,
        "f1": 0.002883,
        "accuracy": 0.010645,
        "main_score": 0.002883,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.881759,
        "recall": 0.91151,
        "f1": 0.890875,
        "accuracy": 0.91151,
        "main_score": 0.890875,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.896806,
        "recall": 0.923486,
        "f1": 0.905301,
        "accuracy": 0.923486,
        "main_score": 0.905301,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.853476,
        "recall": 0.888889,
        "f1": 0.863912,
        "accuracy": 0.888889,
        "main_score": 0.863912,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.742999,
        "recall": 0.80173,
        "f1": 0.760533,
        "accuracy": 0.80173,
        "main_score": 0.760533,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001831,
        "recall": 0.010645,
        "f1": 0.002557,
        "accuracy": 0.010645,
        "main_score": 0.002557,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.519054,
        "recall": 0.599468,
        "f1": 0.541294,
        "accuracy": 0.599468,
        "main_score": 0.541294,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.795454,
        "recall": 0.840985,
        "f1": 0.809337,
        "accuracy": 0.840985,
        "main_score": 0.809337,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.855939,
        "recall": 0.89155,
        "f1": 0.866589,
        "accuracy": 0.89155,
        "main_score": 0.866589,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.91344,
        "recall": 0.936793,
        "f1": 0.920692,
        "accuracy": 0.936793,
        "main_score": 0.920692,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.148785,
        "recall": 0.191617,
        "f1": 0.158642,
        "accuracy": 0.191617,
        "main_score": 0.158642,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.136515,
        "recall": 0.185629,
        "f1": 0.146427,
        "accuracy": 0.185629,
        "main_score": 0.146427,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.167253,
        "recall": 0.213573,
        "f1": 0.177973,
        "accuracy": 0.213573,
        "main_score": 0.177973,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.124694,
        "recall": 0.163673,
        "f1": 0.133078,
        "accuracy": 0.163673,
        "main_score": 0.133078,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.158173,
        "recall": 0.195609,
        "f1": 0.167685,
        "accuracy": 0.195609,
        "main_score": 0.167685,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.136265,
        "recall": 0.175649,
        "f1": 0.144781,
        "accuracy": 0.175649,
        "main_score": 0.144781,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.159666,
        "recall": 0.20825,
        "f1": 0.170832,
        "accuracy": 0.20825,
        "main_score": 0.170832,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.13554,
        "recall": 0.163673,
        "f1": 0.14239,
        "accuracy": 0.163673,
        "main_score": 0.14239,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.123409,
        "recall": 0.163007,
        "f1": 0.13203,
        "accuracy": 0.163007,
        "main_score": 0.13203,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.1576,
        "recall": 0.199601,
        "f1": 0.167137,
        "accuracy": 0.199601,
        "main_score": 0.167137,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.14302,
        "recall": 0.184298,
        "f1": 0.151696,
        "accuracy": 0.184298,
        "main_score": 0.151696,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.145655,
        "recall": 0.189621,
        "f1": 0.155349,
        "accuracy": 0.189621,
        "main_score": 0.155349,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002723,
        "recall": 0.011976,
        "f1": 0.003783,
        "accuracy": 0.011976,
        "main_score": 0.003783,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.158232,
        "recall": 0.204258,
        "f1": 0.168126,
        "accuracy": 0.204258,
        "main_score": 0.168126,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.148357,
        "recall": 0.196274,
        "f1": 0.159307,
        "accuracy": 0.196274,
        "main_score": 0.159307,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.13464,
        "recall": 0.167665,
        "f1": 0.141442,
        "accuracy": 0.167665,
        "main_score": 0.141442,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.13534,
        "recall": 0.180306,
        "f1": 0.145386,
        "accuracy": 0.180306,
        "main_score": 0.145386,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001693,
        "recall": 0.011976,
        "f1": 0.002359,
        "accuracy": 0.011976,
        "main_score": 0.002359,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.162767,
        "recall": 0.200931,
        "f1": 0.171574,
        "accuracy": 0.200931,
        "main_score": 0.171574,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.125975,
        "recall": 0.166999,
        "f1": 0.134864,
        "accuracy": 0.166999,
        "main_score": 0.134864,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.146622,
        "recall": 0.190286,
        "f1": 0.154965,
        "accuracy": 0.190286,
        "main_score": 0.154965,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.139983,
        "recall": 0.188955,
        "f1": 0.149701,
        "accuracy": 0.188955,
        "main_score": 0.149701,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.628655,
        "recall": 0.691949,
        "f1": 0.646254,
        "accuracy": 0.691949,
        "main_score": 0.646254,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.68275,
        "recall": 0.74185,
        "f1": 0.699387,
        "accuracy": 0.74185,
        "main_score": 0.699387,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.167586,
        "recall": 0.231537,
        "f1": 0.182735,
        "accuracy": 0.231537,
        "main_score": 0.182735,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.653693,
        "recall": 0.720559,
        "f1": 0.6719,
        "accuracy": 0.720559,
        "main_score": 0.6719,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.461788,
        "recall": 0.540253,
        "f1": 0.483738,
        "accuracy": 0.540253,
        "main_score": 0.483738,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.665277,
        "recall": 0.726547,
        "f1": 0.682577,
        "accuracy": 0.726547,
        "main_score": 0.682577,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.704118,
        "recall": 0.764471,
        "f1": 0.721235,
        "accuracy": 0.764471,
        "main_score": 0.721235,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.599434,
        "recall": 0.655356,
        "f1": 0.614032,
        "accuracy": 0.655356,
        "main_score": 0.614032,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.440923,
        "recall": 0.516301,
        "f1": 0.461693,
        "accuracy": 0.516301,
        "main_score": 0.461693,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.702674,
        "recall": 0.766467,
        "f1": 0.721284,
        "accuracy": 0.766467,
        "main_score": 0.721284,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.626418,
        "recall": 0.692615,
        "f1": 0.645,
        "accuracy": 0.692615,
        "main_score": 0.645,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.687214,
        "recall": 0.753826,
        "f1": 0.706502,
        "accuracy": 0.753826,
        "main_score": 0.706502,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000719,
        "recall": 0.006653,
        "f1": 0.001218,
        "accuracy": 0.006653,
        "main_score": 0.001218,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.688045,
        "recall": 0.748503,
        "f1": 0.705482,
        "accuracy": 0.748503,
        "main_score": 0.705482,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.678833,
        "recall": 0.738523,
        "f1": 0.695049,
        "accuracy": 0.738523,
        "main_score": 0.695049,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.674953,
        "recall": 0.7332,
        "f1": 0.690502,
        "accuracy": 0.7332,
        "main_score": 0.690502,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.552315,
        "recall": 0.629408,
        "f1": 0.574046,
        "accuracy": 0.629408,
        "main_score": 0.574046,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001491,
        "recall": 0.012641,
        "f1": 0.002323,
        "accuracy": 0.012641,
        "main_score": 0.002323,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.499742,
        "recall": 0.572854,
        "f1": 0.520263,
        "accuracy": 0.572854,
        "main_score": 0.520263,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.558475,
        "recall": 0.629408,
        "f1": 0.577908,
        "accuracy": 0.629408,
        "main_score": 0.577908,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.605363,
        "recall": 0.674651,
        "f1": 0.624335,
        "accuracy": 0.674651,
        "main_score": 0.624335,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.715071,
        "recall": 0.776447,
        "f1": 0.732828,
        "accuracy": 0.776447,
        "main_score": 0.732828,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.81296,
        "recall": 0.859614,
        "f1": 0.826958,
        "accuracy": 0.859614,
        "main_score": 0.826958,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.91522,
        "recall": 0.935462,
        "f1": 0.921296,
        "accuracy": 0.935462,
        "main_score": 0.921296,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.129945,
        "recall": 0.206254,
        "f1": 0.145623,
        "accuracy": 0.206254,
        "main_score": 0.145623,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.637255,
        "recall": 0.725216,
        "f1": 0.663013,
        "accuracy": 0.725216,
        "main_score": 0.663013,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.491524,
        "recall": 0.589488,
        "f1": 0.51772,
        "accuracy": 0.589488,
        "main_score": 0.51772,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.893586,
        "recall": 0.922821,
        "f1": 0.902362,
        "accuracy": 0.922821,
        "main_score": 0.902362,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.934176,
        "recall": 0.95143,
        "f1": 0.939432,
        "accuracy": 0.95143,
        "main_score": 0.939432,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.760264,
        "recall": 0.819029,
        "f1": 0.777828,
        "accuracy": 0.819029,
        "main_score": 0.777828,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.487528,
        "recall": 0.586826,
        "f1": 0.514834,
        "accuracy": 0.586826,
        "main_score": 0.514834,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.862858,
        "recall": 0.899534,
        "f1": 0.873889,
        "accuracy": 0.899534,
        "main_score": 0.873889,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.871065,
        "recall": 0.904192,
        "f1": 0.881095,
        "accuracy": 0.904192,
        "main_score": 0.881095,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.894856,
        "recall": 0.923486,
        "f1": 0.903486,
        "accuracy": 0.923486,
        "main_score": 0.903486,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000988,
        "recall": 0.007319,
        "f1": 0.001474,
        "accuracy": 0.007319,
        "main_score": 0.001474,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.882236,
        "recall": 0.914172,
        "f1": 0.892308,
        "accuracy": 0.914172,
        "main_score": 0.892308,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.897543,
        "recall": 0.923486,
        "f1": 0.905434,
        "accuracy": 0.923486,
        "main_score": 0.905434,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.876409,
        "recall": 0.908849,
        "f1": 0.886239,
        "accuracy": 0.908849,
        "main_score": 0.886239,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.700978,
        "recall": 0.773786,
        "f1": 0.722414,
        "accuracy": 0.773786,
        "main_score": 0.722414,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000897,
        "recall": 0.005988,
        "f1": 0.0013,
        "accuracy": 0.005988,
        "main_score": 0.0013,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.481382,
        "recall": 0.588157,
        "f1": 0.510396,
        "accuracy": 0.588157,
        "main_score": 0.510396,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.802347,
        "recall": 0.849634,
        "f1": 0.816863,
        "accuracy": 0.849634,
        "main_score": 0.816863,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.85983,
        "recall": 0.895542,
        "f1": 0.870807,
        "accuracy": 0.895542,
        "main_score": 0.870807,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.92933,
        "recall": 0.948769,
        "f1": 0.935253,
        "accuracy": 0.948769,
        "main_score": 0.935253,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.529007,
        "recall": 0.597472,
        "f1": 0.548015,
        "accuracy": 0.597472,
        "main_score": 0.548015,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.547504,
        "recall": 0.621424,
        "f1": 0.567397,
        "accuracy": 0.621424,
        "main_score": 0.567397,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.148845,
        "recall": 0.206919,
        "f1": 0.16201,
        "accuracy": 0.206919,
        "main_score": 0.16201,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.472083,
        "recall": 0.54491,
        "f1": 0.492409,
        "accuracy": 0.54491,
        "main_score": 0.492409,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.503642,
        "recall": 0.575516,
        "f1": 0.522754,
        "accuracy": 0.575516,
        "main_score": 0.522754,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.552403,
        "recall": 0.620758,
        "f1": 0.571152,
        "accuracy": 0.620758,
        "main_score": 0.571152,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.568752,
        "recall": 0.638723,
        "f1": 0.587818,
        "accuracy": 0.638723,
        "main_score": 0.587818,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.485554,
        "recall": 0.548902,
        "f1": 0.502794,
        "accuracy": 0.548902,
        "main_score": 0.502794,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.387402,
        "recall": 0.455755,
        "f1": 0.405971,
        "accuracy": 0.455755,
        "main_score": 0.405971,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.562611,
        "recall": 0.630073,
        "f1": 0.581056,
        "accuracy": 0.630073,
        "main_score": 0.581056,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.516136,
        "recall": 0.58483,
        "f1": 0.534657,
        "accuracy": 0.58483,
        "main_score": 0.534657,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.623056,
        "recall": 0.691949,
        "f1": 0.642358,
        "accuracy": 0.691949,
        "main_score": 0.642358,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002363,
        "recall": 0.011311,
        "f1": 0.0033,
        "accuracy": 0.011311,
        "main_score": 0.0033,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.567372,
        "recall": 0.634731,
        "f1": 0.585702,
        "accuracy": 0.634731,
        "main_score": 0.585702,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.539583,
        "recall": 0.604125,
        "f1": 0.556968,
        "accuracy": 0.604125,
        "main_score": 0.556968,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.500279,
        "recall": 0.562874,
        "f1": 0.516395,
        "accuracy": 0.562874,
        "main_score": 0.516395,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.469337,
        "recall": 0.545576,
        "f1": 0.490388,
        "accuracy": 0.545576,
        "main_score": 0.490388,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00259,
        "recall": 0.013972,
        "f1": 0.003706,
        "accuracy": 0.013972,
        "main_score": 0.003706,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.404114,
        "recall": 0.468397,
        "f1": 0.421873,
        "accuracy": 0.468397,
        "main_score": 0.421873,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.45303,
        "recall": 0.522954,
        "f1": 0.471416,
        "accuracy": 0.522954,
        "main_score": 0.471416,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.51532,
        "recall": 0.590818,
        "f1": 0.535579,
        "accuracy": 0.590818,
        "main_score": 0.535579,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.557878,
        "recall": 0.632069,
        "f1": 0.578497,
        "accuracy": 0.632069,
        "main_score": 0.578497,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.837993,
        "recall": 0.873586,
        "f1": 0.848236,
        "accuracy": 0.873586,
        "main_score": 0.848236,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.897738,
        "recall": 0.922821,
        "f1": 0.90539,
        "accuracy": 0.922821,
        "main_score": 0.90539,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.151298,
        "recall": 0.214904,
        "f1": 0.165849,
        "accuracy": 0.214904,
        "main_score": 0.165849,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.683786,
        "recall": 0.750499,
        "f1": 0.702517,
        "accuracy": 0.750499,
        "main_score": 0.702517,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.899602,
        "recall": 0.924152,
        "f1": 0.907008,
        "accuracy": 0.924152,
        "main_score": 0.907008,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.583535,
        "recall": 0.658683,
        "f1": 0.603891,
        "accuracy": 0.658683,
        "main_score": 0.603891,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.903034,
        "recall": 0.927478,
        "f1": 0.910723,
        "accuracy": 0.927478,
        "main_score": 0.910723,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.778488,
        "recall": 0.825682,
        "f1": 0.792181,
        "accuracy": 0.825682,
        "main_score": 0.792181,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.552028,
        "recall": 0.634731,
        "f1": 0.575797,
        "accuracy": 0.634731,
        "main_score": 0.575797,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.870448,
        "recall": 0.903526,
        "f1": 0.880642,
        "accuracy": 0.903526,
        "main_score": 0.880642,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.856061,
        "recall": 0.89022,
        "f1": 0.866213,
        "accuracy": 0.89022,
        "main_score": 0.866213,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.908833,
        "recall": 0.930805,
        "f1": 0.915371,
        "accuracy": 0.930805,
        "main_score": 0.915371,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002811,
        "recall": 0.010645,
        "f1": 0.003621,
        "accuracy": 0.010645,
        "main_score": 0.003621,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.88317,
        "recall": 0.909514,
        "f1": 0.890874,
        "accuracy": 0.909514,
        "main_score": 0.890874,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.882691,
        "recall": 0.91151,
        "f1": 0.891177,
        "accuracy": 0.91151,
        "main_score": 0.891177,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.882874,
        "recall": 0.912176,
        "f1": 0.891739,
        "accuracy": 0.912176,
        "main_score": 0.891739,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.739899,
        "recall": 0.796407,
        "f1": 0.756517,
        "accuracy": 0.796407,
        "main_score": 0.756517,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001847,
        "recall": 0.00998,
        "f1": 0.00258,
        "accuracy": 0.00998,
        "main_score": 0.00258,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.562434,
        "recall": 0.642049,
        "f1": 0.584452,
        "accuracy": 0.642049,
        "main_score": 0.584452,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.781134,
        "recall": 0.830339,
        "f1": 0.795957,
        "accuracy": 0.830339,
        "main_score": 0.795957,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.84872,
        "recall": 0.887558,
        "f1": 0.860202,
        "accuracy": 0.887558,
        "main_score": 0.860202,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.907241,
        "recall": 0.932136,
        "f1": 0.914961,
        "accuracy": 0.932136,
        "main_score": 0.914961,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.814647,
        "recall": 0.855622,
        "f1": 0.826291,
        "accuracy": 0.855622,
        "main_score": 0.826291,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.905761,
        "recall": 0.929474,
        "f1": 0.912723,
        "accuracy": 0.929474,
        "main_score": 0.912723,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.152714,
        "recall": 0.224884,
        "f1": 0.169299,
        "accuracy": 0.224884,
        "main_score": 0.169299,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.672649,
        "recall": 0.749168,
        "f1": 0.694611,
        "accuracy": 0.749168,
        "main_score": 0.694611,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.9278,
        "recall": 0.946773,
        "f1": 0.933489,
        "accuracy": 0.946773,
        "main_score": 0.933489,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.54987,
        "recall": 0.632735,
        "f1": 0.572242,
        "accuracy": 0.632735,
        "main_score": 0.572242,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.887387,
        "recall": 0.915502,
        "f1": 0.895775,
        "accuracy": 0.915502,
        "main_score": 0.895775,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.774243,
        "recall": 0.823021,
        "f1": 0.788097,
        "accuracy": 0.823021,
        "main_score": 0.788097,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.537384,
        "recall": 0.622089,
        "f1": 0.560676,
        "accuracy": 0.622089,
        "main_score": 0.560676,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.858367,
        "recall": 0.893546,
        "f1": 0.868842,
        "accuracy": 0.893546,
        "main_score": 0.868842,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.858415,
        "recall": 0.892216,
        "f1": 0.868785,
        "accuracy": 0.892216,
        "main_score": 0.868785,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.901752,
        "recall": 0.926813,
        "f1": 0.909571,
        "accuracy": 0.926813,
        "main_score": 0.909571,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001488,
        "recall": 0.007984,
        "f1": 0.002236,
        "accuracy": 0.007984,
        "main_score": 0.002236,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.877684,
        "recall": 0.906188,
        "f1": 0.88602,
        "accuracy": 0.906188,
        "main_score": 0.88602,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.877329,
        "recall": 0.905522,
        "f1": 0.885434,
        "accuracy": 0.905522,
        "main_score": 0.885434,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.859565,
        "recall": 0.893546,
        "f1": 0.869374,
        "accuracy": 0.893546,
        "main_score": 0.869374,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.712249,
        "recall": 0.779108,
        "f1": 0.732186,
        "accuracy": 0.779108,
        "main_score": 0.732186,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002239,
        "recall": 0.010645,
        "f1": 0.002797,
        "accuracy": 0.010645,
        "main_score": 0.002797,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.533399,
        "recall": 0.62342,
        "f1": 0.558121,
        "accuracy": 0.62342,
        "main_score": 0.558121,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.803598,
        "recall": 0.847638,
        "f1": 0.816668,
        "accuracy": 0.847638,
        "main_score": 0.816668,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.852817,
        "recall": 0.887558,
        "f1": 0.86269,
        "accuracy": 0.887558,
        "main_score": 0.86269,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.914582,
        "recall": 0.936128,
        "f1": 0.920904,
        "accuracy": 0.936128,
        "main_score": 0.920904,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.718766,
        "recall": 0.771124,
        "f1": 0.733237,
        "accuracy": 0.771124,
        "main_score": 0.733237,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.767631,
        "recall": 0.816367,
        "f1": 0.781069,
        "accuracy": 0.816367,
        "main_score": 0.781069,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.132242,
        "recall": 0.196274,
        "f1": 0.146087,
        "accuracy": 0.196274,
        "main_score": 0.146087,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.593984,
        "recall": 0.662009,
        "f1": 0.613427,
        "accuracy": 0.662009,
        "main_score": 0.613427,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.768564,
        "recall": 0.815037,
        "f1": 0.781747,
        "accuracy": 0.815037,
        "main_score": 0.781747,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.498446,
        "recall": 0.579508,
        "f1": 0.521103,
        "accuracy": 0.579508,
        "main_score": 0.521103,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.765245,
        "recall": 0.809049,
        "f1": 0.778068,
        "accuracy": 0.809049,
        "main_score": 0.778068,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.807141,
        "recall": 0.848303,
        "f1": 0.819448,
        "accuracy": 0.848303,
        "main_score": 0.819448,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.458264,
        "recall": 0.541583,
        "f1": 0.481696,
        "accuracy": 0.541583,
        "main_score": 0.481696,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.74104,
        "recall": 0.789754,
        "f1": 0.755568,
        "accuracy": 0.789754,
        "main_score": 0.755568,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.801308,
        "recall": 0.846307,
        "f1": 0.814907,
        "accuracy": 0.846307,
        "main_score": 0.814907,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.79745,
        "recall": 0.840319,
        "f1": 0.810272,
        "accuracy": 0.840319,
        "main_score": 0.810272,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000457,
        "recall": 0.005988,
        "f1": 0.000765,
        "accuracy": 0.005988,
        "main_score": 0.000765,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.766465,
        "recall": 0.812375,
        "f1": 0.779796,
        "accuracy": 0.812375,
        "main_score": 0.779796,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.787736,
        "recall": 0.836327,
        "f1": 0.802113,
        "accuracy": 0.836327,
        "main_score": 0.802113,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.747031,
        "recall": 0.799734,
        "f1": 0.761809,
        "accuracy": 0.799734,
        "main_score": 0.761809,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.650361,
        "recall": 0.714571,
        "f1": 0.669162,
        "accuracy": 0.714571,
        "main_score": 0.669162,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001375,
        "recall": 0.007319,
        "f1": 0.001834,
        "accuracy": 0.007319,
        "main_score": 0.001834,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.45951,
        "recall": 0.536926,
        "f1": 0.48053,
        "accuracy": 0.536926,
        "main_score": 0.48053,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.738768,
        "recall": 0.792415,
        "f1": 0.754675,
        "accuracy": 0.792415,
        "main_score": 0.754675,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.799452,
        "recall": 0.844977,
        "f1": 0.813273,
        "accuracy": 0.844977,
        "main_score": 0.813273,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.792921,
        "recall": 0.840319,
        "f1": 0.806535,
        "accuracy": 0.840319,
        "main_score": 0.806535,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.518182,
        "recall": 0.592149,
        "f1": 0.539125,
        "accuracy": 0.592149,
        "main_score": 0.539125,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.55037,
        "recall": 0.620093,
        "f1": 0.56877,
        "accuracy": 0.620093,
        "main_score": 0.56877,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.12476,
        "recall": 0.177645,
        "f1": 0.137099,
        "accuracy": 0.177645,
        "main_score": 0.137099,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.437662,
        "recall": 0.505655,
        "f1": 0.456156,
        "accuracy": 0.505655,
        "main_score": 0.456156,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.499077,
        "recall": 0.569528,
        "f1": 0.518478,
        "accuracy": 0.569528,
        "main_score": 0.518478,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.364922,
        "recall": 0.435795,
        "f1": 0.384232,
        "accuracy": 0.435795,
        "main_score": 0.384232,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.531359,
        "recall": 0.600133,
        "f1": 0.550029,
        "accuracy": 0.600133,
        "main_score": 0.550029,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.544807,
        "recall": 0.610778,
        "f1": 0.562629,
        "accuracy": 0.610778,
        "main_score": 0.562629,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.460257,
        "recall": 0.518297,
        "f1": 0.475597,
        "accuracy": 0.518297,
        "main_score": 0.475597,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.554734,
        "recall": 0.62342,
        "f1": 0.573516,
        "accuracy": 0.62342,
        "main_score": 0.573516,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.522682,
        "recall": 0.592149,
        "f1": 0.541909,
        "accuracy": 0.592149,
        "main_score": 0.541909,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.540938,
        "recall": 0.607452,
        "f1": 0.55939,
        "accuracy": 0.607452,
        "main_score": 0.55939,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000938,
        "recall": 0.007984,
        "f1": 0.001572,
        "accuracy": 0.007984,
        "main_score": 0.001572,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.555886,
        "recall": 0.617432,
        "f1": 0.572425,
        "accuracy": 0.617432,
        "main_score": 0.572425,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.559753,
        "recall": 0.626747,
        "f1": 0.577852,
        "accuracy": 0.626747,
        "main_score": 0.577852,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.541022,
        "recall": 0.604125,
        "f1": 0.557933,
        "accuracy": 0.604125,
        "main_score": 0.557933,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.449942,
        "recall": 0.526946,
        "f1": 0.471053,
        "accuracy": 0.526946,
        "main_score": 0.471053,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001706,
        "recall": 0.009315,
        "f1": 0.002341,
        "accuracy": 0.009315,
        "main_score": 0.002341,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.372829,
        "recall": 0.443114,
        "f1": 0.392102,
        "accuracy": 0.443114,
        "main_score": 0.392102,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.439539,
        "recall": 0.510313,
        "f1": 0.459338,
        "accuracy": 0.510313,
        "main_score": 0.459338,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.497659,
        "recall": 0.565536,
        "f1": 0.515813,
        "accuracy": 0.565536,
        "main_score": 0.515813,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.608731,
        "recall": 0.671989,
        "f1": 0.626035,
        "accuracy": 0.671989,
        "main_score": 0.626035,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.803368,
        "recall": 0.846307,
        "f1": 0.815608,
        "accuracy": 0.846307,
        "main_score": 0.815608,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.856577,
        "recall": 0.892216,
        "f1": 0.867123,
        "accuracy": 0.892216,
        "main_score": 0.867123,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.145304,
        "recall": 0.209581,
        "f1": 0.159705,
        "accuracy": 0.209581,
        "main_score": 0.159705,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.666365,
        "recall": 0.736527,
        "f1": 0.686549,
        "accuracy": 0.736527,
        "main_score": 0.686549,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.858585,
        "recall": 0.894212,
        "f1": 0.869273,
        "accuracy": 0.894212,
        "main_score": 0.869273,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.540792,
        "recall": 0.622754,
        "f1": 0.56364,
        "accuracy": 0.622754,
        "main_score": 0.56364,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.84372,
        "recall": 0.880905,
        "f1": 0.854807,
        "accuracy": 0.880905,
        "main_score": 0.854807,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.86989,
        "recall": 0.900865,
        "f1": 0.879145,
        "accuracy": 0.900865,
        "main_score": 0.879145,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.71496,
        "recall": 0.772455,
        "f1": 0.731392,
        "accuracy": 0.772455,
        "main_score": 0.731392,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.54319,
        "recall": 0.622089,
        "f1": 0.565814,
        "accuracy": 0.622089,
        "main_score": 0.565814,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.813914,
        "recall": 0.855622,
        "f1": 0.826078,
        "accuracy": 0.855622,
        "main_score": 0.826078,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.852207,
        "recall": 0.887558,
        "f1": 0.862963,
        "accuracy": 0.887558,
        "main_score": 0.862963,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002974,
        "recall": 0.00998,
        "f1": 0.003673,
        "accuracy": 0.00998,
        "main_score": 0.003673,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.87489,
        "recall": 0.906853,
        "f1": 0.884642,
        "accuracy": 0.906853,
        "main_score": 0.884642,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.84545,
        "recall": 0.88157,
        "f1": 0.856059,
        "accuracy": 0.88157,
        "main_score": 0.856059,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.820256,
        "recall": 0.860279,
        "f1": 0.831771,
        "accuracy": 0.860279,
        "main_score": 0.831771,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.722834,
        "recall": 0.783766,
        "f1": 0.741468,
        "accuracy": 0.783766,
        "main_score": 0.741468,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002059,
        "recall": 0.007984,
        "f1": 0.002451,
        "accuracy": 0.007984,
        "main_score": 0.002451,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.526436,
        "recall": 0.606786,
        "f1": 0.548379,
        "accuracy": 0.606786,
        "main_score": 0.548379,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.719643,
        "recall": 0.776447,
        "f1": 0.735991,
        "accuracy": 0.776447,
        "main_score": 0.735991,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.791058,
        "recall": 0.835662,
        "f1": 0.803931,
        "accuracy": 0.835662,
        "main_score": 0.803931,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.879896,
        "recall": 0.910845,
        "f1": 0.889424,
        "accuracy": 0.910845,
        "main_score": 0.889424,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.803054,
        "recall": 0.848303,
        "f1": 0.816722,
        "accuracy": 0.848303,
        "main_score": 0.816722,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.887138,
        "recall": 0.912841,
        "f1": 0.894988,
        "accuracy": 0.912841,
        "main_score": 0.894988,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.130182,
        "recall": 0.186959,
        "f1": 0.142499,
        "accuracy": 0.186959,
        "main_score": 0.142499,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.627218,
        "recall": 0.696607,
        "f1": 0.646691,
        "accuracy": 0.696607,
        "main_score": 0.646691,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.88941,
        "recall": 0.916833,
        "f1": 0.897738,
        "accuracy": 0.916833,
        "main_score": 0.897738,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.524359,
        "recall": 0.601464,
        "f1": 0.544796,
        "accuracy": 0.601464,
        "main_score": 0.544796,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.850177,
        "recall": 0.883566,
        "f1": 0.859893,
        "accuracy": 0.883566,
        "main_score": 0.859893,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.890669,
        "recall": 0.916168,
        "f1": 0.898284,
        "accuracy": 0.916168,
        "main_score": 0.898284,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.76358,
        "recall": 0.812375,
        "f1": 0.777058,
        "accuracy": 0.812375,
        "main_score": 0.777058,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.492827,
        "recall": 0.576181,
        "f1": 0.51564,
        "accuracy": 0.576181,
        "main_score": 0.51564,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.824746,
        "recall": 0.864271,
        "f1": 0.836462,
        "accuracy": 0.864271,
        "main_score": 0.836462,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.876442,
        "recall": 0.908849,
        "f1": 0.886327,
        "accuracy": 0.908849,
        "main_score": 0.886327,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000125,
        "recall": 0.003992,
        "f1": 0.000239,
        "accuracy": 0.003992,
        "main_score": 0.000239,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.848359,
        "recall": 0.883566,
        "f1": 0.858705,
        "accuracy": 0.883566,
        "main_score": 0.858705,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.870038,
        "recall": 0.9002,
        "f1": 0.879121,
        "accuracy": 0.9002,
        "main_score": 0.879121,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.820865,
        "recall": 0.86161,
        "f1": 0.832917,
        "accuracy": 0.86161,
        "main_score": 0.832917,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.730349,
        "recall": 0.790419,
        "f1": 0.748185,
        "accuracy": 0.790419,
        "main_score": 0.748185,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00052,
        "recall": 0.007984,
        "f1": 0.000892,
        "accuracy": 0.007984,
        "main_score": 0.000892,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.497086,
        "recall": 0.575516,
        "f1": 0.518599,
        "accuracy": 0.575516,
        "main_score": 0.518599,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.791839,
        "recall": 0.835662,
        "f1": 0.804847,
        "accuracy": 0.835662,
        "main_score": 0.804847,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.847456,
        "recall": 0.884232,
        "f1": 0.858551,
        "accuracy": 0.884232,
        "main_score": 0.858551,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.883533,
        "recall": 0.912841,
        "f1": 0.892428,
        "accuracy": 0.912841,
        "main_score": 0.892428,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.830834,
        "recall": 0.868929,
        "f1": 0.841637,
        "accuracy": 0.868929,
        "main_score": 0.841637,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.890885,
        "recall": 0.918164,
        "f1": 0.899101,
        "accuracy": 0.918164,
        "main_score": 0.899101,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.1352,
        "recall": 0.197605,
        "f1": 0.149423,
        "accuracy": 0.197605,
        "main_score": 0.149423,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.657205,
        "recall": 0.731204,
        "f1": 0.678269,
        "accuracy": 0.731204,
        "main_score": 0.678269,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.899091,
        "recall": 0.924817,
        "f1": 0.90703,
        "accuracy": 0.924817,
        "main_score": 0.90703,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.591682,
        "recall": 0.671324,
        "f1": 0.613816,
        "accuracy": 0.671324,
        "main_score": 0.613816,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.900909,
        "recall": 0.922821,
        "f1": 0.907442,
        "accuracy": 0.922821,
        "main_score": 0.907442,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.903493,
        "recall": 0.925482,
        "f1": 0.909926,
        "accuracy": 0.925482,
        "main_score": 0.909926,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.753268,
        "recall": 0.803726,
        "f1": 0.76763,
        "accuracy": 0.803726,
        "main_score": 0.76763,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.524736,
        "recall": 0.608782,
        "f1": 0.548388,
        "accuracy": 0.608782,
        "main_score": 0.548388,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.855185,
        "recall": 0.89022,
        "f1": 0.865702,
        "accuracy": 0.89022,
        "main_score": 0.865702,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.859207,
        "recall": 0.892216,
        "f1": 0.86923,
        "accuracy": 0.892216,
        "main_score": 0.86923,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003141,
        "recall": 0.013307,
        "f1": 0.004326,
        "accuracy": 0.013307,
        "main_score": 0.004326,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.885735,
        "recall": 0.913506,
        "f1": 0.894026,
        "accuracy": 0.913506,
        "main_score": 0.894026,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.874319,
        "recall": 0.904192,
        "f1": 0.883006,
        "accuracy": 0.904192,
        "main_score": 0.883006,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.840026,
        "recall": 0.878244,
        "f1": 0.851353,
        "accuracy": 0.878244,
        "main_score": 0.851353,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.74611,
        "recall": 0.803061,
        "f1": 0.763175,
        "accuracy": 0.803061,
        "main_score": 0.763175,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000937,
        "recall": 0.007984,
        "f1": 0.001544,
        "accuracy": 0.007984,
        "main_score": 0.001544,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.520992,
        "recall": 0.598137,
        "f1": 0.540943,
        "accuracy": 0.598137,
        "main_score": 0.540943,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.789815,
        "recall": 0.834997,
        "f1": 0.803354,
        "accuracy": 0.834997,
        "main_score": 0.803354,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.844433,
        "recall": 0.88024,
        "f1": 0.855068,
        "accuracy": 0.88024,
        "main_score": 0.855068,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.905489,
        "recall": 0.928809,
        "f1": 0.912508,
        "accuracy": 0.928809,
        "main_score": 0.912508,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002,
        "recall": 0.007984,
        "f1": 0.002587,
        "accuracy": 0.007984,
        "main_score": 0.002587,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002322,
        "recall": 0.007319,
        "f1": 0.00253,
        "accuracy": 0.007319,
        "main_score": 0.00253,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.00326,
        "recall": 0.008649,
        "f1": 0.00367,
        "accuracy": 0.008649,
        "main_score": 0.00367,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.001696,
        "recall": 0.005323,
        "f1": 0.002061,
        "accuracy": 0.005323,
        "main_score": 0.002061,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002127,
        "recall": 0.005323,
        "f1": 0.002227,
        "accuracy": 0.005323,
        "main_score": 0.002227,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001846,
        "recall": 0.007319,
        "f1": 0.002112,
        "accuracy": 0.007319,
        "main_score": 0.002112,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001504,
        "recall": 0.005323,
        "f1": 0.001651,
        "accuracy": 0.005323,
        "main_score": 0.001651,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001603,
        "recall": 0.005988,
        "f1": 0.001816,
        "accuracy": 0.005988,
        "main_score": 0.001816,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002144,
        "recall": 0.005323,
        "f1": 0.002264,
        "accuracy": 0.005323,
        "main_score": 0.002264,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000901,
        "recall": 0.005988,
        "f1": 0.001096,
        "accuracy": 0.005988,
        "main_score": 0.001096,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.002057,
        "recall": 0.005988,
        "f1": 0.002116,
        "accuracy": 0.005988,
        "main_score": 0.002116,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.001666,
        "recall": 0.005323,
        "f1": 0.001889,
        "accuracy": 0.005323,
        "main_score": 0.001889,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000848,
        "recall": 0.005323,
        "f1": 0.000999,
        "accuracy": 0.005323,
        "main_score": 0.000999,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001843,
        "recall": 0.007319,
        "f1": 0.002176,
        "accuracy": 0.007319,
        "main_score": 0.002176,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.002433,
        "recall": 0.005323,
        "f1": 0.002629,
        "accuracy": 0.005323,
        "main_score": 0.002629,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.002476,
        "recall": 0.006653,
        "f1": 0.002711,
        "accuracy": 0.006653,
        "main_score": 0.002711,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002835,
        "recall": 0.008649,
        "f1": 0.003282,
        "accuracy": 0.008649,
        "main_score": 0.003282,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.026297,
        "recall": 0.041916,
        "f1": 0.029725,
        "accuracy": 0.041916,
        "main_score": 0.029725,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.00234,
        "recall": 0.007319,
        "f1": 0.002607,
        "accuracy": 0.007319,
        "main_score": 0.002607,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.001526,
        "recall": 0.004657,
        "f1": 0.001683,
        "accuracy": 0.004657,
        "main_score": 0.001683,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000879,
        "recall": 0.005323,
        "f1": 0.001042,
        "accuracy": 0.005323,
        "main_score": 0.001042,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003791,
        "recall": 0.00998,
        "f1": 0.004099,
        "accuracy": 0.00998,
        "main_score": 0.004099,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.838604,
        "recall": 0.873586,
        "f1": 0.848452,
        "accuracy": 0.873586,
        "main_score": 0.848452,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.887066,
        "recall": 0.915502,
        "f1": 0.89561,
        "accuracy": 0.915502,
        "main_score": 0.89561,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.155039,
        "recall": 0.220892,
        "f1": 0.170604,
        "accuracy": 0.220892,
        "main_score": 0.170604,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.675203,
        "recall": 0.740519,
        "f1": 0.693698,
        "accuracy": 0.740519,
        "main_score": 0.693698,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.893136,
        "recall": 0.920825,
        "f1": 0.901663,
        "accuracy": 0.920825,
        "main_score": 0.901663,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.550792,
        "recall": 0.626747,
        "f1": 0.571183,
        "accuracy": 0.626747,
        "main_score": 0.571183,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.875383,
        "recall": 0.903526,
        "f1": 0.883823,
        "accuracy": 0.903526,
        "main_score": 0.883823,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.883389,
        "recall": 0.912176,
        "f1": 0.892041,
        "accuracy": 0.912176,
        "main_score": 0.892041,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.744122,
        "recall": 0.794411,
        "f1": 0.757929,
        "accuracy": 0.794411,
        "main_score": 0.757929,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.545756,
        "recall": 0.621424,
        "f1": 0.566797,
        "accuracy": 0.621424,
        "main_score": 0.566797,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.866345,
        "recall": 0.899534,
        "f1": 0.876358,
        "accuracy": 0.899534,
        "main_score": 0.876358,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.842396,
        "recall": 0.88024,
        "f1": 0.853495,
        "accuracy": 0.88024,
        "main_score": 0.853495,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.894123,
        "recall": 0.919494,
        "f1": 0.901819,
        "accuracy": 0.919494,
        "main_score": 0.901819,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001828,
        "recall": 0.009315,
        "f1": 0.002543,
        "accuracy": 0.009315,
        "main_score": 0.002543,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.890153,
        "recall": 0.917498,
        "f1": 0.898349,
        "accuracy": 0.917498,
        "main_score": 0.898349,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.850089,
        "recall": 0.887558,
        "f1": 0.861091,
        "accuracy": 0.887558,
        "main_score": 0.861091,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.736207,
        "recall": 0.795742,
        "f1": 0.753754,
        "accuracy": 0.795742,
        "main_score": 0.753754,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001312,
        "recall": 0.009315,
        "f1": 0.00198,
        "accuracy": 0.009315,
        "main_score": 0.00198,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.52696,
        "recall": 0.600798,
        "f1": 0.54684,
        "accuracy": 0.600798,
        "main_score": 0.54684,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.745063,
        "recall": 0.802395,
        "f1": 0.761382,
        "accuracy": 0.802395,
        "main_score": 0.761382,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.814737,
        "recall": 0.856287,
        "f1": 0.826914,
        "accuracy": 0.856287,
        "main_score": 0.826914,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.901708,
        "recall": 0.926813,
        "f1": 0.909327,
        "accuracy": 0.926813,
        "main_score": 0.909327,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.86105,
        "recall": 0.896873,
        "f1": 0.871751,
        "accuracy": 0.896873,
        "main_score": 0.871751,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.913639,
        "recall": 0.936128,
        "f1": 0.920416,
        "accuracy": 0.936128,
        "main_score": 0.920416,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.147785,
        "recall": 0.20825,
        "f1": 0.161365,
        "accuracy": 0.20825,
        "main_score": 0.161365,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.667929,
        "recall": 0.734531,
        "f1": 0.686727,
        "accuracy": 0.734531,
        "main_score": 0.686727,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.89679,
        "recall": 0.923486,
        "f1": 0.904805,
        "accuracy": 0.923486,
        "main_score": 0.904805,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.544295,
        "recall": 0.621424,
        "f1": 0.565405,
        "accuracy": 0.621424,
        "main_score": 0.565405,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.897383,
        "recall": 0.92016,
        "f1": 0.904125,
        "accuracy": 0.92016,
        "main_score": 0.904125,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.902362,
        "recall": 0.927478,
        "f1": 0.910335,
        "accuracy": 0.927478,
        "main_score": 0.910335,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.780308,
        "recall": 0.825682,
        "f1": 0.793199,
        "accuracy": 0.825682,
        "main_score": 0.793199,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.540547,
        "recall": 0.616101,
        "f1": 0.561702,
        "accuracy": 0.616101,
        "main_score": 0.561702,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.868674,
        "recall": 0.90153,
        "f1": 0.878842,
        "accuracy": 0.90153,
        "main_score": 0.878842,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.878232,
        "recall": 0.908849,
        "f1": 0.88747,
        "accuracy": 0.908849,
        "main_score": 0.88747,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.900266,
        "recall": 0.924152,
        "f1": 0.907617,
        "accuracy": 0.924152,
        "main_score": 0.907617,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002096,
        "recall": 0.009315,
        "f1": 0.002663,
        "accuracy": 0.009315,
        "main_score": 0.002663,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.894899,
        "recall": 0.919494,
        "f1": 0.902585,
        "accuracy": 0.919494,
        "main_score": 0.902585,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.864588,
        "recall": 0.896208,
        "f1": 0.87381,
        "accuracy": 0.896208,
        "main_score": 0.87381,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.748926,
        "recall": 0.800399,
        "f1": 0.764178,
        "accuracy": 0.800399,
        "main_score": 0.764178,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001849,
        "recall": 0.007319,
        "f1": 0.002221,
        "accuracy": 0.007319,
        "main_score": 0.002221,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.523674,
        "recall": 0.602129,
        "f1": 0.545108,
        "accuracy": 0.602129,
        "main_score": 0.545108,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.772872,
        "recall": 0.823021,
        "f1": 0.787427,
        "accuracy": 0.823021,
        "main_score": 0.787427,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.867487,
        "recall": 0.904192,
        "f1": 0.878975,
        "accuracy": 0.904192,
        "main_score": 0.878975,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.909514,
        "recall": 0.932136,
        "f1": 0.916367,
        "accuracy": 0.932136,
        "main_score": 0.916367,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.802084,
        "recall": 0.842315,
        "f1": 0.813851,
        "accuracy": 0.842315,
        "main_score": 0.813851,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.8742,
        "recall": 0.903526,
        "f1": 0.882823,
        "accuracy": 0.903526,
        "main_score": 0.882823,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.128352,
        "recall": 0.192282,
        "f1": 0.142643,
        "accuracy": 0.192282,
        "main_score": 0.142643,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.679578,
        "recall": 0.744511,
        "f1": 0.697922,
        "accuracy": 0.744511,
        "main_score": 0.697922,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.880861,
        "recall": 0.910845,
        "f1": 0.889778,
        "accuracy": 0.910845,
        "main_score": 0.889778,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.525108,
        "recall": 0.608117,
        "f1": 0.548488,
        "accuracy": 0.608117,
        "main_score": 0.548488,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.886028,
        "recall": 0.912841,
        "f1": 0.894034,
        "accuracy": 0.912841,
        "main_score": 0.894034,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.906565,
        "recall": 0.93014,
        "f1": 0.913611,
        "accuracy": 0.93014,
        "main_score": 0.913611,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.745283,
        "recall": 0.794411,
        "f1": 0.759277,
        "accuracy": 0.794411,
        "main_score": 0.759277,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.541131,
        "recall": 0.621424,
        "f1": 0.564241,
        "accuracy": 0.621424,
        "main_score": 0.564241,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.851786,
        "recall": 0.888889,
        "f1": 0.862878,
        "accuracy": 0.888889,
        "main_score": 0.862878,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.837511,
        "recall": 0.874917,
        "f1": 0.848594,
        "accuracy": 0.874917,
        "main_score": 0.848594,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.880634,
        "recall": 0.906188,
        "f1": 0.888412,
        "accuracy": 0.906188,
        "main_score": 0.888412,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002756,
        "recall": 0.008649,
        "f1": 0.003394,
        "accuracy": 0.008649,
        "main_score": 0.003394,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.876256,
        "recall": 0.906188,
        "f1": 0.885131,
        "accuracy": 0.906188,
        "main_score": 0.885131,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.867609,
        "recall": 0.898204,
        "f1": 0.876926,
        "accuracy": 0.898204,
        "main_score": 0.876926,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.705632,
        "recall": 0.770459,
        "f1": 0.725085,
        "accuracy": 0.770459,
        "main_score": 0.725085,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001606,
        "recall": 0.010645,
        "f1": 0.002212,
        "accuracy": 0.010645,
        "main_score": 0.002212,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.526892,
        "recall": 0.606121,
        "f1": 0.549059,
        "accuracy": 0.606121,
        "main_score": 0.549059,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.745693,
        "recall": 0.797073,
        "f1": 0.760604,
        "accuracy": 0.797073,
        "main_score": 0.760604,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.809762,
        "recall": 0.852295,
        "f1": 0.822224,
        "accuracy": 0.852295,
        "main_score": 0.822224,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.910886,
        "recall": 0.93147,
        "f1": 0.916988,
        "accuracy": 0.93147,
        "main_score": 0.916988,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.690376,
        "recall": 0.748503,
        "f1": 0.707692,
        "accuracy": 0.748503,
        "main_score": 0.707692,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.734839,
        "recall": 0.787092,
        "f1": 0.749583,
        "accuracy": 0.787092,
        "main_score": 0.749583,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.128734,
        "recall": 0.180971,
        "f1": 0.141024,
        "accuracy": 0.180971,
        "main_score": 0.141024,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.548187,
        "recall": 0.626081,
        "f1": 0.570027,
        "accuracy": 0.626081,
        "main_score": 0.570027,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.70404,
        "recall": 0.759148,
        "f1": 0.720011,
        "accuracy": 0.759148,
        "main_score": 0.720011,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.481412,
        "recall": 0.558882,
        "f1": 0.502376,
        "accuracy": 0.558882,
        "main_score": 0.502376,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.726683,
        "recall": 0.775782,
        "f1": 0.741121,
        "accuracy": 0.775782,
        "main_score": 0.741121,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.74291,
        "recall": 0.790419,
        "f1": 0.756758,
        "accuracy": 0.790419,
        "main_score": 0.756758,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.620058,
        "recall": 0.679308,
        "f1": 0.635731,
        "accuracy": 0.679308,
        "main_score": 0.635731,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.456278,
        "recall": 0.528277,
        "f1": 0.476057,
        "accuracy": 0.528277,
        "main_score": 0.476057,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.729902,
        "recall": 0.784431,
        "f1": 0.74573,
        "accuracy": 0.784431,
        "main_score": 0.74573,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.717799,
        "recall": 0.770459,
        "f1": 0.733059,
        "accuracy": 0.770459,
        "main_score": 0.733059,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.776342,
        "recall": 0.825017,
        "f1": 0.790827,
        "accuracy": 0.825017,
        "main_score": 0.790827,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002133,
        "recall": 0.007319,
        "f1": 0.002621,
        "accuracy": 0.007319,
        "main_score": 0.002621,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.765428,
        "recall": 0.810379,
        "f1": 0.778555,
        "accuracy": 0.810379,
        "main_score": 0.778555,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.72818,
        "recall": 0.7831,
        "f1": 0.743589,
        "accuracy": 0.7831,
        "main_score": 0.743589,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.675121,
        "recall": 0.730539,
        "f1": 0.690067,
        "accuracy": 0.730539,
        "main_score": 0.690067,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00336,
        "recall": 0.011976,
        "f1": 0.00417,
        "accuracy": 0.011976,
        "main_score": 0.00417,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.443832,
        "recall": 0.513639,
        "f1": 0.462648,
        "accuracy": 0.513639,
        "main_score": 0.462648,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.610209,
        "recall": 0.674651,
        "f1": 0.627854,
        "accuracy": 0.674651,
        "main_score": 0.627854,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.691382,
        "recall": 0.75183,
        "f1": 0.708281,
        "accuracy": 0.75183,
        "main_score": 0.708281,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.756012,
        "recall": 0.806387,
        "f1": 0.770422,
        "accuracy": 0.806387,
        "main_score": 0.770422,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.003992,
        "f1": 0.000765,
        "accuracy": 0.003992,
        "main_score": 0.000765,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002785,
        "recall": 0.006653,
        "f1": 0.003111,
        "accuracy": 0.006653,
        "main_score": 0.003111,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001354,
        "recall": 0.005988,
        "f1": 0.00195,
        "accuracy": 0.005988,
        "main_score": 0.00195,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.00044,
        "recall": 0.004657,
        "f1": 0.00073,
        "accuracy": 0.004657,
        "main_score": 0.00073,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000497,
        "recall": 0.003327,
        "f1": 0.000727,
        "accuracy": 0.003327,
        "main_score": 0.000727,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000461,
        "recall": 0.005323,
        "f1": 0.000688,
        "accuracy": 0.005323,
        "main_score": 0.000688,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001625,
        "recall": 0.005988,
        "f1": 0.002025,
        "accuracy": 0.005988,
        "main_score": 0.002025,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001098,
        "recall": 0.005988,
        "f1": 0.001303,
        "accuracy": 0.005988,
        "main_score": 0.001303,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002125,
        "recall": 0.005988,
        "f1": 0.002233,
        "accuracy": 0.005988,
        "main_score": 0.002233,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001124,
        "recall": 0.006653,
        "f1": 0.001352,
        "accuracy": 0.006653,
        "main_score": 0.001352,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.001097,
        "recall": 0.005323,
        "f1": 0.001298,
        "accuracy": 0.005323,
        "main_score": 0.001298,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.001366,
        "recall": 0.003327,
        "f1": 0.0014,
        "accuracy": 0.003327,
        "main_score": 0.0014,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001117,
        "recall": 0.005323,
        "f1": 0.001334,
        "accuracy": 0.005323,
        "main_score": 0.001334,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.024844,
        "recall": 0.040585,
        "f1": 0.028461,
        "accuracy": 0.040585,
        "main_score": 0.028461,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.001127,
        "recall": 0.005323,
        "f1": 0.001342,
        "accuracy": 0.005323,
        "main_score": 0.001342,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.00077,
        "recall": 0.005323,
        "f1": 0.000865,
        "accuracy": 0.005323,
        "main_score": 0.000865,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.001913,
        "recall": 0.005323,
        "f1": 0.002253,
        "accuracy": 0.005323,
        "main_score": 0.002253,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001234,
        "recall": 0.005988,
        "f1": 0.001607,
        "accuracy": 0.005988,
        "main_score": 0.001607,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001473,
        "recall": 0.005323,
        "f1": 0.0016,
        "accuracy": 0.005323,
        "main_score": 0.0016,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.001736,
        "recall": 0.005323,
        "f1": 0.001915,
        "accuracy": 0.005323,
        "main_score": 0.001915,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001387,
        "recall": 0.003992,
        "f1": 0.00144,
        "accuracy": 0.003992,
        "main_score": 0.00144,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002754,
        "recall": 0.007319,
        "f1": 0.00306,
        "accuracy": 0.007319,
        "main_score": 0.00306,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.50926,
        "recall": 0.570858,
        "f1": 0.52543,
        "accuracy": 0.570858,
        "main_score": 0.52543,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.528525,
        "recall": 0.595476,
        "f1": 0.545537,
        "accuracy": 0.595476,
        "main_score": 0.545537,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.157932,
        "recall": 0.220226,
        "f1": 0.172703,
        "accuracy": 0.220226,
        "main_score": 0.172703,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.507627,
        "recall": 0.570193,
        "f1": 0.523985,
        "accuracy": 0.570193,
        "main_score": 0.523985,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.476449,
        "recall": 0.548902,
        "f1": 0.49478,
        "accuracy": 0.548902,
        "main_score": 0.49478,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.416297,
        "recall": 0.490353,
        "f1": 0.435723,
        "accuracy": 0.490353,
        "main_score": 0.435723,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.537549,
        "recall": 0.606786,
        "f1": 0.555944,
        "accuracy": 0.606786,
        "main_score": 0.555944,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.56789,
        "recall": 0.630073,
        "f1": 0.584707,
        "accuracy": 0.630073,
        "main_score": 0.584707,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.451157,
        "recall": 0.50499,
        "f1": 0.464934,
        "accuracy": 0.50499,
        "main_score": 0.464934,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.362912,
        "recall": 0.43646,
        "f1": 0.382923,
        "accuracy": 0.43646,
        "main_score": 0.382923,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.542751,
        "recall": 0.609448,
        "f1": 0.560375,
        "accuracy": 0.609448,
        "main_score": 0.560375,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.497089,
        "recall": 0.566866,
        "f1": 0.515772,
        "accuracy": 0.566866,
        "main_score": 0.515772,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.5486,
        "recall": 0.620758,
        "f1": 0.568486,
        "accuracy": 0.620758,
        "main_score": 0.568486,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00276,
        "recall": 0.012641,
        "f1": 0.00392,
        "accuracy": 0.012641,
        "main_score": 0.00392,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.532904,
        "recall": 0.604125,
        "f1": 0.551872,
        "accuracy": 0.604125,
        "main_score": 0.551872,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.516971,
        "recall": 0.58483,
        "f1": 0.534675,
        "accuracy": 0.58483,
        "main_score": 0.534675,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.49237,
        "recall": 0.555556,
        "f1": 0.508838,
        "accuracy": 0.555556,
        "main_score": 0.508838,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.437939,
        "recall": 0.50499,
        "f1": 0.45578,
        "accuracy": 0.50499,
        "main_score": 0.45578,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000865,
        "recall": 0.007984,
        "f1": 0.001383,
        "accuracy": 0.007984,
        "main_score": 0.001383,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.433108,
        "recall": 0.497671,
        "f1": 0.44939,
        "accuracy": 0.497671,
        "main_score": 0.44939,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.482948,
        "recall": 0.547572,
        "f1": 0.500459,
        "accuracy": 0.547572,
        "main_score": 0.500459,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.541124,
        "recall": 0.608117,
        "f1": 0.558524,
        "accuracy": 0.608117,
        "main_score": 0.558524,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.702388,
        "recall": 0.761144,
        "f1": 0.719381,
        "accuracy": 0.761144,
        "main_score": 0.719381,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.795108,
        "recall": 0.840985,
        "f1": 0.808706,
        "accuracy": 0.840985,
        "main_score": 0.808706,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.132282,
        "recall": 0.191617,
        "f1": 0.144842,
        "accuracy": 0.191617,
        "main_score": 0.144842,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.556576,
        "recall": 0.636061,
        "f1": 0.578432,
        "accuracy": 0.636061,
        "main_score": 0.578432,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.80324,
        "recall": 0.848303,
        "f1": 0.816523,
        "accuracy": 0.848303,
        "main_score": 0.816523,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.444386,
        "recall": 0.532269,
        "f1": 0.468144,
        "accuracy": 0.532269,
        "main_score": 0.468144,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.766567,
        "recall": 0.814371,
        "f1": 0.780877,
        "accuracy": 0.814371,
        "main_score": 0.780877,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.806228,
        "recall": 0.852961,
        "f1": 0.820448,
        "accuracy": 0.852961,
        "main_score": 0.820448,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.716455,
        "recall": 0.77312,
        "f1": 0.732351,
        "accuracy": 0.77312,
        "main_score": 0.732351,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.445287,
        "recall": 0.530273,
        "f1": 0.468728,
        "accuracy": 0.530273,
        "main_score": 0.468728,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.739893,
        "recall": 0.795742,
        "f1": 0.756557,
        "accuracy": 0.795742,
        "main_score": 0.756557,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.779075,
        "recall": 0.826347,
        "f1": 0.793293,
        "accuracy": 0.826347,
        "main_score": 0.793293,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.784549,
        "recall": 0.833001,
        "f1": 0.799468,
        "accuracy": 0.833001,
        "main_score": 0.799468,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001506,
        "recall": 0.003992,
        "f1": 0.001653,
        "accuracy": 0.003992,
        "main_score": 0.001653,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.756207,
        "recall": 0.807718,
        "f1": 0.770856,
        "accuracy": 0.807718,
        "main_score": 0.770856,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.756291,
        "recall": 0.805057,
        "f1": 0.769898,
        "accuracy": 0.805057,
        "main_score": 0.769898,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.728829,
        "recall": 0.78177,
        "f1": 0.744336,
        "accuracy": 0.78177,
        "main_score": 0.744336,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.632453,
        "recall": 0.707917,
        "f1": 0.654493,
        "accuracy": 0.707917,
        "main_score": 0.654493,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000491,
        "recall": 0.005988,
        "f1": 0.000745,
        "accuracy": 0.005988,
        "main_score": 0.000745,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.449167,
        "recall": 0.527611,
        "f1": 0.469951,
        "accuracy": 0.527611,
        "main_score": 0.469951,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.789466,
        "recall": 0.840319,
        "f1": 0.804518,
        "accuracy": 0.840319,
        "main_score": 0.804518,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.78915,
        "recall": 0.838323,
        "f1": 0.804278,
        "accuracy": 0.838323,
        "main_score": 0.804278,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.768279,
        "recall": 0.816367,
        "f1": 0.781976,
        "accuracy": 0.816367,
        "main_score": 0.781976,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.846779,
        "recall": 0.882901,
        "f1": 0.857331,
        "accuracy": 0.882901,
        "main_score": 0.857331,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.140394,
        "recall": 0.202262,
        "f1": 0.15449,
        "accuracy": 0.202262,
        "main_score": 0.15449,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.611722,
        "recall": 0.684631,
        "f1": 0.632245,
        "accuracy": 0.684631,
        "main_score": 0.632245,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.85803,
        "recall": 0.888889,
        "f1": 0.867071,
        "accuracy": 0.888889,
        "main_score": 0.867071,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.533431,
        "recall": 0.611444,
        "f1": 0.554493,
        "accuracy": 0.611444,
        "main_score": 0.554493,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.834753,
        "recall": 0.866933,
        "f1": 0.843913,
        "accuracy": 0.866933,
        "main_score": 0.843913,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.873575,
        "recall": 0.903526,
        "f1": 0.882701,
        "accuracy": 0.903526,
        "main_score": 0.882701,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.771263,
        "recall": 0.818363,
        "f1": 0.784826,
        "accuracy": 0.818363,
        "main_score": 0.784826,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.507532,
        "recall": 0.580838,
        "f1": 0.527368,
        "accuracy": 0.580838,
        "main_score": 0.527368,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.805558,
        "recall": 0.849634,
        "f1": 0.818653,
        "accuracy": 0.849634,
        "main_score": 0.818653,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.833134,
        "recall": 0.869594,
        "f1": 0.844235,
        "accuracy": 0.869594,
        "main_score": 0.844235,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.846939,
        "recall": 0.882236,
        "f1": 0.857697,
        "accuracy": 0.882236,
        "main_score": 0.857697,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.008649,
        "f1": 0.001289,
        "accuracy": 0.008649,
        "main_score": 0.001289,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.821696,
        "recall": 0.86161,
        "f1": 0.83305,
        "accuracy": 0.86161,
        "main_score": 0.83305,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.84073,
        "recall": 0.878244,
        "f1": 0.852064,
        "accuracy": 0.878244,
        "main_score": 0.852064,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.767506,
        "recall": 0.816367,
        "f1": 0.781597,
        "accuracy": 0.816367,
        "main_score": 0.781597,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.705419,
        "recall": 0.765136,
        "f1": 0.722738,
        "accuracy": 0.765136,
        "main_score": 0.722738,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001018,
        "recall": 0.008649,
        "f1": 0.001655,
        "accuracy": 0.008649,
        "main_score": 0.001655,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.480585,
        "recall": 0.55356,
        "f1": 0.500254,
        "accuracy": 0.55356,
        "main_score": 0.500254,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.789111,
        "recall": 0.834331,
        "f1": 0.803042,
        "accuracy": 0.834331,
        "main_score": 0.803042,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.865729,
        "recall": 0.896208,
        "f1": 0.874895,
        "accuracy": 0.896208,
        "main_score": 0.874895,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.836445,
        "recall": 0.872921,
        "f1": 0.847146,
        "accuracy": 0.872921,
        "main_score": 0.847146,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.912586,
        "recall": 0.932801,
        "f1": 0.918545,
        "accuracy": 0.932801,
        "main_score": 0.918545,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.131181,
        "recall": 0.196274,
        "f1": 0.145543,
        "accuracy": 0.196274,
        "main_score": 0.145543,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.689868,
        "recall": 0.759814,
        "f1": 0.710005,
        "accuracy": 0.759814,
        "main_score": 0.710005,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.923509,
        "recall": 0.942781,
        "f1": 0.929319,
        "accuracy": 0.942781,
        "main_score": 0.929319,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.539179,
        "recall": 0.620758,
        "f1": 0.561377,
        "accuracy": 0.620758,
        "main_score": 0.561377,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.902218,
        "recall": 0.926813,
        "f1": 0.909793,
        "accuracy": 0.926813,
        "main_score": 0.909793,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.923564,
        "recall": 0.943446,
        "f1": 0.929709,
        "accuracy": 0.943446,
        "main_score": 0.929709,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.772447,
        "recall": 0.82169,
        "f1": 0.786616,
        "accuracy": 0.82169,
        "main_score": 0.786616,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.549771,
        "recall": 0.625416,
        "f1": 0.569779,
        "accuracy": 0.625416,
        "main_score": 0.569779,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.878066,
        "recall": 0.909514,
        "f1": 0.887736,
        "accuracy": 0.909514,
        "main_score": 0.887736,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.876913,
        "recall": 0.908184,
        "f1": 0.886437,
        "accuracy": 0.908184,
        "main_score": 0.886437,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.905711,
        "recall": 0.928144,
        "f1": 0.912375,
        "accuracy": 0.928144,
        "main_score": 0.912375,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002138,
        "recall": 0.011976,
        "f1": 0.003011,
        "accuracy": 0.011976,
        "main_score": 0.003011,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.892111,
        "recall": 0.919494,
        "f1": 0.900014,
        "accuracy": 0.919494,
        "main_score": 0.900014,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.889955,
        "recall": 0.914837,
        "f1": 0.897196,
        "accuracy": 0.914837,
        "main_score": 0.897196,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.88951,
        "recall": 0.918829,
        "f1": 0.898381,
        "accuracy": 0.918829,
        "main_score": 0.898381,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.73574,
        "recall": 0.793081,
        "f1": 0.752686,
        "accuracy": 0.793081,
        "main_score": 0.752686,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002464,
        "recall": 0.010645,
        "f1": 0.002853,
        "accuracy": 0.010645,
        "main_score": 0.002853,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.521933,
        "recall": 0.605456,
        "f1": 0.544423,
        "accuracy": 0.605456,
        "main_score": 0.544423,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.795117,
        "recall": 0.840319,
        "f1": 0.808886,
        "accuracy": 0.840319,
        "main_score": 0.808886,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.869982,
        "recall": 0.90153,
        "f1": 0.879321,
        "accuracy": 0.90153,
        "main_score": 0.879321,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 112.29980707168579,
  "kg_co2_emissions": 0.004191130342896898
}