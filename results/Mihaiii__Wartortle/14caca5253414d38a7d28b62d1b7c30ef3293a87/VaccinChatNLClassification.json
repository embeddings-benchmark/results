{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.248718,
            "f1": 0.273318,
            "f1_weighted": 0.224364,
            "precision": 0.301944,
            "precision_weighted": 0.360308,
            "recall": 0.433385,
            "recall_weighted": 0.248718,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.263248,
            "f1": 0.271288,
            "f1_weighted": 0.238285,
            "precision": 0.298148,
            "precision_weighted": 0.360501,
            "recall": 0.434793,
            "recall_weighted": 0.263248,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.273504,
            "f1": 0.302663,
            "f1_weighted": 0.252615,
            "precision": 0.336362,
            "precision_weighted": 0.432973,
            "recall": 0.43966,
            "recall_weighted": 0.273504,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.276923,
            "f1": 0.279742,
            "f1_weighted": 0.260556,
            "precision": 0.317883,
            "precision_weighted": 0.422219,
            "recall": 0.423202,
            "recall_weighted": 0.276923,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.255556,
            "f1": 0.271466,
            "f1_weighted": 0.226053,
            "precision": 0.318081,
            "precision_weighted": 0.429173,
            "recall": 0.430207,
            "recall_weighted": 0.255556,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.263248,
            "f1": 0.270923,
            "f1_weighted": 0.253452,
            "precision": 0.33316,
            "precision_weighted": 0.459844,
            "recall": 0.40499,
            "recall_weighted": 0.263248,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.27265,
            "f1": 0.281092,
            "f1_weighted": 0.244929,
            "precision": 0.312912,
            "precision_weighted": 0.411425,
            "recall": 0.414067,
            "recall_weighted": 0.27265,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.273504,
            "f1": 0.289574,
            "f1_weighted": 0.249295,
            "precision": 0.328116,
            "precision_weighted": 0.362518,
            "recall": 0.432512,
            "recall_weighted": 0.273504,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.281197,
            "f1": 0.284533,
            "f1_weighted": 0.253659,
            "precision": 0.307032,
            "precision_weighted": 0.38411,
            "recall": 0.448414,
            "recall_weighted": 0.281197,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.261538,
            "f1": 0.270735,
            "f1_weighted": 0.238216,
            "precision": 0.330334,
            "precision_weighted": 0.465275,
            "recall": 0.399055,
            "recall_weighted": 0.261538,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.267009,
        "f1": 0.279533,
        "f1_weighted": 0.244143,
        "precision": 0.318397,
        "precision_weighted": 0.408835,
        "recall": 0.426028,
        "recall_weighted": 0.267009,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.279533,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 34.38481426239014,
  "kg_co2_emissions": null
}