{
  "dataset_revision": "2269ed7d95d8abaab829f1592b4b2047372e9f81",
  "task_name": "DutchColaClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.549167,
            "f1": 0.548074,
            "f1_weighted": 0.548074,
            "precision": 0.549647,
            "precision_weighted": 0.549647,
            "recall": 0.549167,
            "recall_weighted": 0.549167,
            "ap": 0.526784,
            "ap_weighted": 0.526784
          },
          {
            "accuracy": 0.540417,
            "f1": 0.539665,
            "f1_weighted": 0.539665,
            "precision": 0.540682,
            "precision_weighted": 0.540682,
            "recall": 0.540417,
            "recall_weighted": 0.540417,
            "ap": 0.52172,
            "ap_weighted": 0.52172
          },
          {
            "accuracy": 0.508333,
            "f1": 0.50821,
            "f1_weighted": 0.50821,
            "precision": 0.508342,
            "precision_weighted": 0.508342,
            "recall": 0.508333,
            "recall_weighted": 0.508333,
            "ap": 0.504234,
            "ap_weighted": 0.504234
          },
          {
            "accuracy": 0.574583,
            "f1": 0.573704,
            "f1_weighted": 0.573704,
            "precision": 0.575204,
            "precision_weighted": 0.575204,
            "recall": 0.574583,
            "recall_weighted": 0.574583,
            "ap": 0.542391,
            "ap_weighted": 0.542391
          },
          {
            "accuracy": 0.549167,
            "f1": 0.549076,
            "f1_weighted": 0.549076,
            "precision": 0.549206,
            "precision_weighted": 0.549206,
            "recall": 0.549167,
            "recall_weighted": 0.549167,
            "ap": 0.527071,
            "ap_weighted": 0.527071
          },
          {
            "accuracy": 0.54875,
            "f1": 0.548693,
            "f1_weighted": 0.548693,
            "precision": 0.548775,
            "precision_weighted": 0.548775,
            "recall": 0.54875,
            "recall_weighted": 0.54875,
            "ap": 0.526806,
            "ap_weighted": 0.526806
          },
          {
            "accuracy": 0.54875,
            "f1": 0.548562,
            "f1_weighted": 0.548562,
            "precision": 0.548831,
            "precision_weighted": 0.548831,
            "recall": 0.54875,
            "recall_weighted": 0.54875,
            "ap": 0.526658,
            "ap_weighted": 0.526658
          },
          {
            "accuracy": 0.548333,
            "f1": 0.548308,
            "f1_weighted": 0.548308,
            "precision": 0.548344,
            "precision_weighted": 0.548344,
            "recall": 0.548333,
            "recall_weighted": 0.548333,
            "ap": 0.526538,
            "ap_weighted": 0.526538
          },
          {
            "accuracy": 0.539583,
            "f1": 0.539084,
            "f1_weighted": 0.539084,
            "precision": 0.539756,
            "precision_weighted": 0.539756,
            "recall": 0.539583,
            "recall_weighted": 0.539583,
            "ap": 0.521262,
            "ap_weighted": 0.521262
          },
          {
            "accuracy": 0.543333,
            "f1": 0.542227,
            "f1_weighted": 0.542227,
            "precision": 0.543756,
            "precision_weighted": 0.543756,
            "recall": 0.543333,
            "recall_weighted": 0.543333,
            "ap": 0.523376,
            "ap_weighted": 0.523376
          }
        ],
        "accuracy": 0.545042,
        "f1": 0.54456,
        "f1_weighted": 0.54456,
        "precision": 0.545254,
        "precision_weighted": 0.545254,
        "recall": 0.545042,
        "recall_weighted": 0.545042,
        "ap": 0.524684,
        "ap_weighted": 0.524684,
        "main_score": 0.54456,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 18.96227240562439,
  "kg_co2_emissions": null
}