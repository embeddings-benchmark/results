{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.722852,
        "f1": 0.721791,
        "f1_weighted": 0.721757,
        "ap": 0.667495,
        "ap_weighted": 0.667495,
        "scores_per_experiment": [
          {
            "accuracy": 0.740234,
            "f1": 0.740163,
            "f1_weighted": 0.740175,
            "ap": 0.677392,
            "ap_weighted": 0.677392
          },
          {
            "accuracy": 0.72168,
            "f1": 0.719839,
            "f1_weighted": 0.719773,
            "ap": 0.671237,
            "ap_weighted": 0.671237
          },
          {
            "accuracy": 0.705566,
            "f1": 0.70345,
            "f1_weighted": 0.703377,
            "ap": 0.655378,
            "ap_weighted": 0.655378
          },
          {
            "accuracy": 0.708984,
            "f1": 0.707843,
            "f1_weighted": 0.70779,
            "ap": 0.656075,
            "ap_weighted": 0.656075
          },
          {
            "accuracy": 0.708008,
            "f1": 0.705023,
            "f1_weighted": 0.704936,
            "ap": 0.659978,
            "ap_weighted": 0.659978
          },
          {
            "accuracy": 0.709961,
            "f1": 0.709695,
            "f1_weighted": 0.709721,
            "ap": 0.64793,
            "ap_weighted": 0.64793
          },
          {
            "accuracy": 0.72168,
            "f1": 0.721211,
            "f1_weighted": 0.721177,
            "ap": 0.665975,
            "ap_weighted": 0.665975
          },
          {
            "accuracy": 0.756348,
            "f1": 0.75624,
            "f1_weighted": 0.756255,
            "ap": 0.692641,
            "ap_weighted": 0.692641
          },
          {
            "accuracy": 0.717285,
            "f1": 0.716885,
            "f1_weighted": 0.716854,
            "ap": 0.661283,
            "ap_weighted": 0.661283
          },
          {
            "accuracy": 0.73877,
            "f1": 0.737561,
            "f1_weighted": 0.737508,
            "ap": 0.68706,
            "ap_weighted": 0.68706
          }
        ],
        "main_score": 0.722852,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.730322,
        "f1": 0.729173,
        "f1_weighted": 0.729149,
        "ap": 0.674684,
        "ap_weighted": 0.674684,
        "scores_per_experiment": [
          {
            "accuracy": 0.742676,
            "f1": 0.742447,
            "f1_weighted": 0.742462,
            "ap": 0.677835,
            "ap_weighted": 0.677835
          },
          {
            "accuracy": 0.73584,
            "f1": 0.734072,
            "f1_weighted": 0.734029,
            "ap": 0.685553,
            "ap_weighted": 0.685553
          },
          {
            "accuracy": 0.711426,
            "f1": 0.709,
            "f1_weighted": 0.708948,
            "ap": 0.661585,
            "ap_weighted": 0.661585
          },
          {
            "accuracy": 0.721191,
            "f1": 0.719748,
            "f1_weighted": 0.719708,
            "ap": 0.668862,
            "ap_weighted": 0.668862
          },
          {
            "accuracy": 0.716797,
            "f1": 0.714286,
            "f1_weighted": 0.714233,
            "ap": 0.66744,
            "ap_weighted": 0.66744
          },
          {
            "accuracy": 0.720215,
            "f1": 0.720067,
            "f1_weighted": 0.72008,
            "ap": 0.657407,
            "ap_weighted": 0.657407
          },
          {
            "accuracy": 0.724609,
            "f1": 0.723897,
            "f1_weighted": 0.72387,
            "ap": 0.669547,
            "ap_weighted": 0.669547
          },
          {
            "accuracy": 0.762207,
            "f1": 0.762023,
            "f1_weighted": 0.762036,
            "ap": 0.697149,
            "ap_weighted": 0.697149
          },
          {
            "accuracy": 0.732422,
            "f1": 0.731756,
            "f1_weighted": 0.73173,
            "ap": 0.677298,
            "ap_weighted": 0.677298
          },
          {
            "accuracy": 0.73584,
            "f1": 0.734434,
            "f1_weighted": 0.734396,
            "ap": 0.684162,
            "ap_weighted": 0.684162
          }
        ],
        "main_score": 0.730322,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 14.690783023834229,
  "kg_co2_emissions": 0.0004249511681596714
}