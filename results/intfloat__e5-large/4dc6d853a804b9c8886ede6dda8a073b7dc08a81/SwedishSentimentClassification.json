{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.718994,
        "f1": 0.71796,
        "f1_weighted": 0.718002,
        "ap": 0.654671,
        "ap_weighted": 0.654671,
        "scores_per_experiment": [
          {
            "accuracy": 0.732422,
            "f1": 0.728308,
            "f1_weighted": 0.728406,
            "ap": 0.660692,
            "ap_weighted": 0.660692
          },
          {
            "accuracy": 0.695312,
            "f1": 0.694431,
            "f1_weighted": 0.694479,
            "ap": 0.633428,
            "ap_weighted": 0.633428
          },
          {
            "accuracy": 0.719727,
            "f1": 0.719585,
            "f1_weighted": 0.719604,
            "ap": 0.65747,
            "ap_weighted": 0.65747
          },
          {
            "accuracy": 0.685059,
            "f1": 0.684741,
            "f1_weighted": 0.68477,
            "ap": 0.626116,
            "ap_weighted": 0.626116
          },
          {
            "accuracy": 0.740234,
            "f1": 0.740135,
            "f1_weighted": 0.74015,
            "ap": 0.677068,
            "ap_weighted": 0.677068
          },
          {
            "accuracy": 0.709473,
            "f1": 0.709453,
            "f1_weighted": 0.70946,
            "ap": 0.649343,
            "ap_weighted": 0.649343
          },
          {
            "accuracy": 0.742676,
            "f1": 0.74189,
            "f1_weighted": 0.741932,
            "ap": 0.675679,
            "ap_weighted": 0.675679
          },
          {
            "accuracy": 0.745117,
            "f1": 0.743815,
            "f1_weighted": 0.743869,
            "ap": 0.6764,
            "ap_weighted": 0.6764
          },
          {
            "accuracy": 0.692871,
            "f1": 0.692062,
            "f1_weighted": 0.692108,
            "ap": 0.631507,
            "ap_weighted": 0.631507
          },
          {
            "accuracy": 0.727051,
            "f1": 0.725179,
            "f1_weighted": 0.725246,
            "ap": 0.65901,
            "ap_weighted": 0.65901
          }
        ],
        "main_score": 0.718994,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.723242,
        "f1": 0.722059,
        "f1_weighted": 0.722089,
        "ap": 0.65771,
        "ap_weighted": 0.65771,
        "scores_per_experiment": [
          {
            "accuracy": 0.737305,
            "f1": 0.732588,
            "f1_weighted": 0.732657,
            "ap": 0.66388,
            "ap_weighted": 0.66388
          },
          {
            "accuracy": 0.718262,
            "f1": 0.716995,
            "f1_weighted": 0.717032,
            "ap": 0.652001,
            "ap_weighted": 0.652001
          },
          {
            "accuracy": 0.720215,
            "f1": 0.720103,
            "f1_weighted": 0.720114,
            "ap": 0.657674,
            "ap_weighted": 0.657674
          },
          {
            "accuracy": 0.722168,
            "f1": 0.721905,
            "f1_weighted": 0.721922,
            "ap": 0.6585,
            "ap_weighted": 0.6585
          },
          {
            "accuracy": 0.732422,
            "f1": 0.732033,
            "f1_weighted": 0.732053,
            "ap": 0.66731,
            "ap_weighted": 0.66731
          },
          {
            "accuracy": 0.714355,
            "f1": 0.714262,
            "f1_weighted": 0.714272,
            "ap": 0.652467,
            "ap_weighted": 0.652467
          },
          {
            "accuracy": 0.744629,
            "f1": 0.744006,
            "f1_weighted": 0.744031,
            "ap": 0.677663,
            "ap_weighted": 0.677663
          },
          {
            "accuracy": 0.758301,
            "f1": 0.75698,
            "f1_weighted": 0.757015,
            "ap": 0.688123,
            "ap_weighted": 0.688123
          },
          {
            "accuracy": 0.688477,
            "f1": 0.6879,
            "f1_weighted": 0.687927,
            "ap": 0.627853,
            "ap_weighted": 0.627853
          },
          {
            "accuracy": 0.696289,
            "f1": 0.693818,
            "f1_weighted": 0.693871,
            "ap": 0.631628,
            "ap_weighted": 0.631628
          }
        ],
        "main_score": 0.723242,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 25.881160020828247,
  "kg_co2_emissions": 0.0013053990466824498
}