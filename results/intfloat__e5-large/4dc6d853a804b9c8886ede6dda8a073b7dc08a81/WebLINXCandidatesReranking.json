{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.133822,
        "mrr": 0.114791,
        "nAUC_map_max": -0.099331,
        "nAUC_map_std": 0.036533,
        "nAUC_map_diff1": 0.170852,
        "nAUC_mrr_max": -0.100015,
        "nAUC_mrr_std": 0.032917,
        "nAUC_mrr_diff1": 0.177408,
        "main_score": 0.114791,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.112588,
        "mrr": 0.09536,
        "nAUC_map_max": -0.014366,
        "nAUC_map_std": 0.085201,
        "nAUC_map_diff1": 0.017877,
        "nAUC_mrr_max": -0.001812,
        "nAUC_mrr_std": 0.070194,
        "nAUC_mrr_diff1": 0.009886,
        "main_score": 0.09536,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.088608,
        "mrr": 0.072813,
        "nAUC_map_max": -0.016735,
        "nAUC_map_std": 0.364555,
        "nAUC_map_diff1": 0.183171,
        "nAUC_mrr_max": -0.015857,
        "nAUC_mrr_std": 0.339468,
        "nAUC_mrr_diff1": 0.182394,
        "main_score": 0.072813,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.107495,
        "mrr": 0.08911,
        "nAUC_map_max": 0.028362,
        "nAUC_map_std": 0.12321,
        "nAUC_map_diff1": 0.138757,
        "nAUC_mrr_max": 0.022812,
        "nAUC_mrr_std": 0.115723,
        "nAUC_mrr_diff1": 0.145036,
        "main_score": 0.08911,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.109473,
        "mrr": 0.090958,
        "nAUC_map_max": -0.013479,
        "nAUC_map_std": 0.144053,
        "nAUC_map_diff1": 0.117078,
        "nAUC_mrr_max": -0.00168,
        "nAUC_mrr_std": 0.125326,
        "nAUC_mrr_diff1": 0.118793,
        "main_score": 0.090958,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.091139,
        "mrr": 0.074709,
        "nAUC_map_max": -0.03223,
        "nAUC_map_std": 0.158801,
        "nAUC_map_diff1": 0.193514,
        "nAUC_mrr_max": -0.027757,
        "nAUC_mrr_std": 0.142277,
        "nAUC_mrr_diff1": 0.198861,
        "main_score": 0.074709,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6866.715813875198,
  "kg_co2_emissions": 0.6289422729993847
}