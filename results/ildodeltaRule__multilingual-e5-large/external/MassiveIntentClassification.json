{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.6238063214525892,
                "f1": 0.594646372344301,
                "main_score": 0.6238063214525892
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.5606926698049766,
                "f1": 0.5249084283283562,
                "main_score": 0.5606926698049766
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.6074983187626093,
                "f1": 0.569606406201659,
                "main_score": 0.6074983187626093
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.6486550100874243,
                "f1": 0.6247370548140688,
                "main_score": 0.6486550100874243
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.6397108271687963,
                "f1": 0.6103812421957381,
                "main_score": 0.6397108271687963
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.5498318762609282,
                "f1": 0.5151207916008392,
                "main_score": 0.5498318762609282
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.6945527908540686,
                "f1": 0.6616631905400319,
                "main_score": 0.6945527908540686
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.6932750504371217,
                "f1": 0.6616755288646591,
                "main_score": 0.6932750504371217
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.6909213180901144,
                "f1": 0.6695654394661507,
                "main_score": 0.6909213180901144
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.7375588433086752,
                "f1": 0.7179973779656923,
                "main_score": 0.7375588433086752
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.7049428379287154,
                "f1": 0.6837494379215734,
                "main_score": 0.7049428379287154
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.6990921318090115,
                "f1": 0.6679517376481645,
                "main_score": 0.6990921318090115
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.7012104909213182,
                "f1": 0.6729448842879584,
                "main_score": 0.7012104909213182
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.6934095494283793,
                "f1": 0.6701134288992947,
                "main_score": 0.6934095494283793
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.6761264290517822,
                "f1": 0.6468730512660756,
                "main_score": 0.6761264290517822
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.6779757901815738,
                "f1": 0.6524938539425598,
                "main_score": 0.6779757901815738
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.6968728984532616,
                "f1": 0.6704871697625531,
                "main_score": 0.6968728984532616
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.6207464694014795,
                "f1": 0.5918353227678929,
                "main_score": 0.6207464694014795
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.7004707464694014,
                "f1": 0.6766829629003849,
                "main_score": 0.7004707464694014
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.6242434431741762,
                "f1": 0.5901617226544758,
                "main_score": 0.6242434431741762
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.7053127101546738,
                "f1": 0.6810033760906254,
                "main_score": 0.7053127101546738
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.7250504371217216,
                "f1": 0.6974931103158923,
                "main_score": 0.7250504371217216
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.5791190316072629,
                "f1": 0.5405551136648796,
                "main_score": 0.5791190316072629
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.5178211163416275,
                "f1": 0.4987488854405854,
                "main_score": 0.5178211163416275
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.47017484868863485,
                "f1": 0.4453364263352014,
                "main_score": 0.47017484868863485
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.6216207128446537,
                "f1": 0.590118569232083,
                "main_score": 0.6216207128446537
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.6942501681237391,
                "f1": 0.6713169450166085,
                "main_score": 0.6942501681237391
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.670780094149294,
                "f1": 0.6441720167850707,
                "main_score": 0.670780094149294
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.6557162071284466,
                "f1": 0.6241413868380442,
                "main_score": 0.6557162071284466
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.6171149966375252,
                "f1": 0.5859480512508723,
                "main_score": 0.6171149966375252
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.6603900470746471,
                "f1": 0.6387937257883887,
                "main_score": 0.6603900470746471
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.608776059179556,
                "f1": 0.5748587618059131,
                "main_score": 0.608776059179556
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.6987895090786819,
                "f1": 0.6681412994303471,
                "main_score": 0.6987895090786819
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.7045057162071285,
                "f1": 0.6746444039673516,
                "main_score": 0.7045057162071285
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.71546738399462,
                "f1": 0.6863640876702655,
                "main_score": 0.71546738399462
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.7072965702757229,
                "f1": 0.6854119560379115,
                "main_score": 0.7072965702757229
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.6835574983187626,
                "f1": 0.6588844917691926,
                "main_score": 0.6835574983187626
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.7170477471418963,
                "f1": 0.6919665697061979,
                "main_score": 0.7170477471418963
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.670880968392737,
                "f1": 0.6476962317666086,
                "main_score": 0.670880968392737
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.6518493611297916,
                "f1": 0.6249984559035371,
                "main_score": 0.6518493611297916
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.7175857431069265,
                "f1": 0.6920053687623419,
                "main_score": 0.7175857431069265
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.5850033624747815,
                "f1": 0.552972398687929,
                "main_score": 0.5850033624747815
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.6268997982515132,
                "f1": 0.5936848202755348,
                "main_score": 0.6268997982515132
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.6301950235373235,
                "f1": 0.6009351954625423,
                "main_score": 0.6301950235373235
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.6829186281102892,
                "f1": 0.6757860496703446,
                "main_score": 0.6829186281102892
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.6477471418964358,
                "f1": 0.6191398314771384,
                "main_score": 0.6477471418964358
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.6987222595830532,
                "f1": 0.6603679033708141,
                "main_score": 0.6987222595830532
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.6404505716207127,
                "f1": 0.6128569169817908,
                "main_score": 0.6404505716207127
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.6938466711499663,
                "f1": 0.6720532357036844,
                "main_score": 0.6938466711499663
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.7112306657700067,
                "f1": 0.6891251226588182,
                "main_score": 0.7112306657700067
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6620040349697378,
                "f1": 0.6602657347714175,
                "main_score": 0.6620040349697378
            }
        ]
    }
}