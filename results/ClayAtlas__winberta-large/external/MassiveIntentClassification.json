{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.2579690652320108,
                "f1": 0.2409343878244007,
                "main_score": 0.2579690652320108
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.033389374579690656,
                "f1": 0.02404152046553366,
                "main_score": 0.033389374579690656
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.0648957632817754,
                "f1": 0.0462270646032821,
                "main_score": 0.0648957632817754
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.24767989240080696,
                "f1": 0.23495689794075475,
                "main_score": 0.24767989240080696
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.042972427706792195,
                "f1": 0.022466735164037934,
                "main_score": 0.042972427706792195
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.26388702084734367,
                "f1": 0.2386003112409349,
                "main_score": 0.26388702084734367
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.314694014794889,
                "f1": 0.2901755955481539,
                "main_score": 0.314694014794889
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.2809011432414256,
                "f1": 0.24796051996220103,
                "main_score": 0.2809011432414256
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.19240080699394752,
                "f1": 0.1613607169381968,
                "main_score": 0.19240080699394752
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.5340618695359785,
                "f1": 0.49555501145955566,
                "main_score": 0.5340618695359785
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.30615332885003366,
                "f1": 0.2913481030937436,
                "main_score": 0.30615332885003366
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.07205783456624076,
                "f1": 0.046018025134460586,
                "main_score": 0.07205783456624076
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.2720578345662407,
                "f1": 0.24177535740725417,
                "main_score": 0.2720578345662407
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.32636180228648276,
                "f1": 0.311901681400213,
                "main_score": 0.32636180228648276
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.026630800268997983,
                "f1": 0.01913464455449111,
                "main_score": 0.026630800268997983
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.045931405514458644,
                "f1": 0.026428594688121865,
                "main_score": 0.045931405514458644
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.25648957632817754,
                "f1": 0.2288249345748577,
                "main_score": 0.25648957632817754
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.048621385339609954,
                "f1": 0.02739262235100375,
                "main_score": 0.048621385339609954
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.2980833893745797,
                "f1": 0.29055301842025005,
                "main_score": 0.2980833893745797
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.23530598520511098,
                "f1": 0.21232935753763024,
                "main_score": 0.23530598520511098
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.3447209145931405,
                "f1": 0.32987844813265305,
                "main_score": 0.3447209145931405
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.3940147948890383,
                "f1": 0.37591350862164785,
                "main_score": 0.3940147948890383
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.28749159381304645,
                "f1": 0.261328148454731,
                "main_score": 0.28749159381304645
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.04344317417619368,
                "f1": 0.029377190150068958,
                "main_score": 0.04344317417619368
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.06102891728312036,
                "f1": 0.03962539148306579,
                "main_score": 0.06102891728312036
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.044620040349697375,
                "f1": 0.026188113612884457,
                "main_score": 0.044620040349697375
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.14156018829858777,
                "f1": 0.12032224251194693,
                "main_score": 0.14156018829858777
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.29855413584398116,
                "f1": 0.26493594829364897,
                "main_score": 0.29855413584398116
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.036919973100201744,
                "f1": 0.01945517764508852,
                "main_score": 0.036919973100201744
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.07864828513786146,
                "f1": 0.05890463192551815,
                "main_score": 0.07864828513786146
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.2805312710154674,
                "f1": 0.2516791968552097,
                "main_score": 0.2805312710154674
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.06980497646267653,
                "f1": 0.03578402802492296,
                "main_score": 0.06980497646267653
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.2864828513786147,
                "f1": 0.2631074892275346,
                "main_score": 0.2864828513786147
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.32921990585070615,
                "f1": 0.29644293217296747,
                "main_score": 0.32921990585070615
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.27622730329522527,
                "f1": 0.2446966823901481,
                "main_score": 0.27622730329522527
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.3352723604572966,
                "f1": 0.30925486052646933,
                "main_score": 0.3352723604572966
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.3132145258910558,
                "f1": 0.29330120833270007,
                "main_score": 0.3132145258910558
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.11271015467383994,
                "f1": 0.10062644252034658,
                "main_score": 0.11271015467383994
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.27942165433759253,
                "f1": 0.2533080090111651,
                "main_score": 0.27942165433759253
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.32895090786819103,
                "f1": 0.2843953906832353,
                "main_score": 0.32895090786819103
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.26852723604572964,
                "f1": 0.25395656180022463,
                "main_score": 0.26852723604572964
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.29404841963685274,
                "f1": 0.2621621146728871,
                "main_score": 0.29404841963685274
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.03325487558843308,
                "f1": 0.01603092746324846,
                "main_score": 0.03325487558843308
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.03463349024882313,
                "f1": 0.020928407358339736,
                "main_score": 0.03463349024882313
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.12982515131136513,
                "f1": 0.1101712677163494,
                "main_score": 0.12982515131136513
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.30729657027572294,
                "f1": 0.2683317869501593,
                "main_score": 0.30729657027572294
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.2357094821788837,
                "f1": 0.22401274254343811,
                "main_score": 0.2357094821788837
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.04983187626092804,
                "f1": 0.03718347039099332,
                "main_score": 0.04983187626092804
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.21893073301950236,
                "f1": 0.20675025999929755,
                "main_score": 0.21893073301950236
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.7082044384667114,
                "f1": 0.6845757969594843,
                "main_score": 0.7082044384667114
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6552790854068594,
                "f1": 0.6467811461805109,
                "main_score": 0.6552790854068594
            }
        ]
    }
}