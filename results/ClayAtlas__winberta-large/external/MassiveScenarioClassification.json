{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.3155346334902488,
                "f1": 0.29191252426466213,
                "main_score": 0.3155346334902488
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.07488231338264964,
                "f1": 0.050160562127811684,
                "main_score": 0.07488231338264964
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.14996637525218562,
                "f1": 0.11249193510499182,
                "main_score": 0.14996637525218562
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.291324815063887,
                "f1": 0.2638076542865094,
                "main_score": 0.291324815063887
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.09243443174176194,
                "f1": 0.0603853736932921,
                "main_score": 0.09243443174176194
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.2972091459314055,
                "f1": 0.2692887247878267,
                "main_score": 0.2972091459314055
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.3979152656355078,
                "f1": 0.3536833022538433,
                "main_score": 0.3979152656355078
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.34677202420981845,
                "f1": 0.3139329003485599,
                "main_score": 0.34677202420981845
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.2883322125084061,
                "f1": 0.25447170771092875,
                "main_score": 0.2883322125084061
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6177538668459988,
                "f1": 0.5863871338520991,
                "main_score": 0.6177538668459988
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.3596839273705447,
                "f1": 0.32763680461311945,
                "main_score": 0.3596839273705447
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.1112306657700067,
                "f1": 0.07872676893973923,
                "main_score": 0.1112306657700067
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.28614660390047075,
                "f1": 0.25645947438401856,
                "main_score": 0.28614660390047075
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.40655682582380626,
                "f1": 0.3766349602390266,
                "main_score": 0.40655682582380626
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.09008069939475453,
                "f1": 0.051554089293899964,
                "main_score": 0.09008069939475453
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.09915938130464022,
                "f1": 0.06413016136448915,
                "main_score": 0.09915938130464022
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.3207464694014795,
                "f1": 0.29435621484770175,
                "main_score": 0.3207464694014795
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.08439811701412239,
                "f1": 0.061576769360898516,
                "main_score": 0.08439811701412239
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.34899125756556826,
                "f1": 0.3161486571181394,
                "main_score": 0.34899125756556826
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.3095494283792871,
                "f1": 0.26844232924337497,
                "main_score": 0.3095494283792871
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.41059179556153325,
                "f1": 0.36924711150777445,
                "main_score": 0.41059179556153325
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.48732347007397453,
                "f1": 0.4689395011365762,
                "main_score": 0.48732347007397453
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.3508742434431742,
                "f1": 0.32314520222383586,
                "main_score": 0.3508742434431742
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.09287155346334904,
                "f1": 0.0713459214077311,
                "main_score": 0.09287155346334904
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.11193678547410894,
                "f1": 0.07329043540295746,
                "main_score": 0.11193678547410894
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.10097511768661734,
                "f1": 0.07212356186519867,
                "main_score": 0.10097511768661734
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.19196368527236046,
                "f1": 0.16798046606500283,
                "main_score": 0.19196368527236046
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.3249495628782785,
                "f1": 0.28359188240241445,
                "main_score": 0.3249495628782785
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.0636516476126429,
                "f1": 0.03719266559907991,
                "main_score": 0.0636516476126429
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.13076664425016812,
                "f1": 0.09572770203976713,
                "main_score": 0.13076664425016812
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.39179556153328854,
                "f1": 0.338253960820197,
                "main_score": 0.39179556153328854
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.12252858103564224,
                "f1": 0.09096519579346872,
                "main_score": 0.12252858103564224
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.3524209818426362,
                "f1": 0.32247569640628837,
                "main_score": 0.3524209818426362
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.38170813718897106,
                "f1": 0.34853946559992205,
                "main_score": 0.38170813718897106
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.3160390047074647,
                "f1": 0.2824199310436465,
                "main_score": 0.3160390047074647
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.4001008742434432,
                "f1": 0.3721826826542489,
                "main_score": 0.4001008742434432
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.39253530598520514,
                "f1": 0.35457426597271785,
                "main_score": 0.39253530598520514
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.16708137188971078,
                "f1": 0.14338767956114,
                "main_score": 0.16708137188971078
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.3394418291862811,
                "f1": 0.30577444242695695,
                "main_score": 0.3394418291862811
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.40396772024209826,
                "f1": 0.36028103018769436,
                "main_score": 0.40396772024209826
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.3072293207800942,
                "f1": 0.28494919871417457,
                "main_score": 0.3072293207800942
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.3714189643577674,
                "f1": 0.3252116385408168,
                "main_score": 0.3714189643577674
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.08214525891055818,
                "f1": 0.044483991099655326,
                "main_score": 0.08214525891055818
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.0796570275722932,
                "f1": 0.051286914647561146,
                "main_score": 0.0796570275722932
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.21556825823806322,
                "f1": 0.17110218757379614,
                "main_score": 0.21556825823806322
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.36701412239408204,
                "f1": 0.3296113533567822,
                "main_score": 0.36701412239408204
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.2880295897780767,
                "f1": 0.2777008973951413,
                "main_score": 0.2880295897780767
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.10460659045057163,
                "f1": 0.0790075042321315,
                "main_score": 0.10460659045057163
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.27720242098184267,
                "f1": 0.2676341970948208,
                "main_score": 0.27720242098184267
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.7521183591123066,
                "f1": 0.7455953469104787,
                "main_score": 0.7521183591123066
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.7152320107599192,
                "f1": 0.7116094498697193,
                "main_score": 0.7152320107599192
            }
        ]
    }
}