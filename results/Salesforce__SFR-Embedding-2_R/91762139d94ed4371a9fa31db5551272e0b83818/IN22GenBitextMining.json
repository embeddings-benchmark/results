{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 372.24044013023376,
  "kg_co2_emissions": 0.030334111406084864,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666666,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9830729166666666,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.5080529477415966,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.5080529477415966,
        "precision": 0.4925819328974487,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.8607421875,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.8607421875,
        "precision": 0.8492350260416667,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.9560546875,
        "f1": 0.9442382812500001,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9442382812500001,
        "precision": 0.938916015625,
        "recall": 0.9560546875
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7832542782738094,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.7832542782738094,
        "precision": 0.7679687500000001,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7930253286210317,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.7930253286210317,
        "precision": 0.7779471261160715,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9698893229166666,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9698893229166666,
        "precision": 0.9666341145833333,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.8723958333333333,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.8723958333333333,
        "precision": 0.861279296875,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.6962890625,
        "f1": 0.646661861359127,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.646661861359127,
        "precision": 0.6269968556833792,
        "recall": 0.6962890625
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9398437499999999,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9398437499999999,
        "precision": 0.9336751302083334,
        "recall": 0.953125
      },
      {
        "accuracy": 0.6982421875,
        "f1": 0.6517570374503969,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.6517570374503969,
        "precision": 0.6334674169146826,
        "recall": 0.6982421875
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9318684895833333,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9318684895833333,
        "precision": 0.9256998697916666,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009762139758407295,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.009762139758407295,
        "precision": 0.008080073680659619,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.966796875,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.966796875,
        "precision": 0.9632161458333333,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6571398274034993,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.6571398274034993,
        "precision": 0.6360688709077381,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6764508928571429,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.6764508928571429,
        "precision": 0.6579361556412338,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9450520833333332,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9450520833333332,
        "precision": 0.939697265625,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0035335604516086414,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0035335604516086414,
        "precision": 0.002549158626461258,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.796875,
        "f1": 0.7619326636904762,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.7619326636904762,
        "precision": 0.7472191220238096,
        "recall": 0.796875
      },
      {
        "accuracy": 0.78125,
        "f1": 0.737735615079365,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.737735615079365,
        "precision": 0.7195665147569444,
        "recall": 0.78125
      },
      {
        "accuracy": 0.8115234375,
        "f1": 0.7718284970238094,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.7718284970238094,
        "precision": 0.7549479166666666,
        "recall": 0.8115234375
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.930078125,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.930078125,
        "precision": 0.9229329427083333,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9713541666666666,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.9713541666666666,
        "precision": 0.9677734375,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.55859375,
        "f1": 0.5129076760912699,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.5129076760912699,
        "precision": 0.4970309846042268,
        "recall": 0.55859375
      },
      {
        "accuracy": 0.955078125,
        "f1": 0.9417317708333333,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9417317708333333,
        "precision": 0.9353841145833334,
        "recall": 0.955078125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.884765625,
        "f1": 0.8552083333333333,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8552083333333333,
        "precision": 0.8420247395833333,
        "recall": 0.884765625
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8581380208333333,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8581380208333333,
        "precision": 0.8459798177083333,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9287109375,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.9287109375,
        "precision": 0.92158203125,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.771484375,
        "f1": 0.7274180355235043,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.7274180355235043,
        "precision": 0.7085767341382576,
        "recall": 0.771484375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9879557291666666,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9879557291666666,
        "precision": 0.98681640625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.7626953125,
        "f1": 0.7169308393429488,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.7169308393429488,
        "precision": 0.698530505952381,
        "recall": 0.7626953125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9744466145833334,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9744466145833334,
        "precision": 0.9715169270833333,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009893938070336096,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.009893938070336096,
        "precision": 0.008069069602272728,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.73046875,
        "f1": 0.6746706039186507,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.6746706039186507,
        "precision": 0.6525913783482142,
        "recall": 0.73046875
      },
      {
        "accuracy": 0.7744140625,
        "f1": 0.7257672991071429,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.7257672991071429,
        "precision": 0.7050455729166667,
        "recall": 0.7744140625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833333,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005661450317172013,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.005661450317172013,
        "precision": 0.004713404542506105,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8430850074404761,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8430850074404761,
        "precision": 0.8309733072916666,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8648763020833333,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8648763020833333,
        "precision": 0.8517252604166666,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.86015625,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.86015625,
        "precision": 0.848046875,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9871419270833334,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9871419270833334,
        "precision": 0.9856770833333333,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.4579150322716499,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.4579150322716499,
        "precision": 0.44319190314422463,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.5068359375,
        "f1": 0.46089147835965627,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.46089147835965627,
        "precision": 0.4455174742474666,
        "recall": 0.5068359375
      },
      {
        "accuracy": 0.5869140625,
        "f1": 0.5439376702011546,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5439376702011546,
        "precision": 0.5292234502470807,
        "recall": 0.5869140625
      },
      {
        "accuracy": 0.5068359375,
        "f1": 0.4662153940352183,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.4662153940352183,
        "precision": 0.45431605752138765,
        "recall": 0.5068359375
      },
      {
        "accuracy": 0.5654296875,
        "f1": 0.5231386994082305,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5231386994082305,
        "precision": 0.5087973520494032,
        "recall": 0.5654296875
      },
      {
        "accuracy": 0.4384765625,
        "f1": 0.38194462680905694,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.38194462680905694,
        "precision": 0.3634364135942631,
        "recall": 0.4384765625
      },
      {
        "accuracy": 0.5263671875,
        "f1": 0.47909705312049056,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.47909705312049056,
        "precision": 0.46359483838604426,
        "recall": 0.5263671875
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.3889010512057387,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.3889010512057387,
        "precision": 0.37042468931374334,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.46484375,
        "f1": 0.4258442701095353,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.4258442701095353,
        "precision": 0.4156293415204129,
        "recall": 0.46484375
      },
      {
        "accuracy": 0.5595703125,
        "f1": 0.5123464698069348,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5123464698069348,
        "precision": 0.4982414124503968,
        "recall": 0.5595703125
      },
      {
        "accuracy": 0.4208984375,
        "f1": 0.3748849755929834,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3748849755929834,
        "precision": 0.3608488028898185,
        "recall": 0.4208984375
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.44761318383503584,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.44761318383503584,
        "precision": 0.43247811708633566,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007059132856415972,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007059132856415972,
        "precision": 0.005785848040486712,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.4688986264577946,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4688986264577946,
        "precision": 0.4530600063906638,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.361328125,
        "f1": 0.3057896683724639,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3057896683724639,
        "precision": 0.2883809533565393,
        "recall": 0.361328125
      },
      {
        "accuracy": 0.4365234375,
        "f1": 0.38739388866341995,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.38739388866341995,
        "precision": 0.3719017571770541,
        "recall": 0.4365234375
      },
      {
        "accuracy": 0.5126953125,
        "f1": 0.46011161626108776,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.46011161626108776,
        "precision": 0.44327362867890213,
        "recall": 0.5126953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00835024025453713,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00835024025453713,
        "precision": 0.00702529926847445,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.583984375,
        "f1": 0.548439120558261,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.548439120558261,
        "precision": 0.5354577795251623,
        "recall": 0.583984375
      },
      {
        "accuracy": 0.392578125,
        "f1": 0.34648023323295063,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.34648023323295063,
        "precision": 0.33084400137622794,
        "recall": 0.392578125
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.4376762993950494,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.4376762993950494,
        "precision": 0.4185693359375,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.4833984375,
        "f1": 0.4423713041877104,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.4423713041877104,
        "precision": 0.42993942846119204,
        "recall": 0.4833984375
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.8637858072916667,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8637858072916667,
        "precision": 0.8517345610119048,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9462890625,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9462890625,
        "precision": 0.9401041666666666,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.599609375,
        "f1": 0.5594266898466117,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5594266898466117,
        "precision": 0.5445642248376623,
        "recall": 0.599609375
      },
      {
        "accuracy": 0.96875,
        "f1": 0.96025390625,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.96025390625,
        "precision": 0.9565755208333333,
        "recall": 0.96875
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.8559895833333333,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8559895833333333,
        "precision": 0.843896484375,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.7594618055555555,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7594618055555555,
        "precision": 0.7410997178819445,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9767252604166667,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9767252604166667,
        "precision": 0.9739583333333334,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.865234375,
        "f1": 0.8341471354166667,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8341471354166667,
        "precision": 0.8211100260416667,
        "recall": 0.865234375
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7662217881944444,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7662217881944444,
        "precision": 0.7511664496527778,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9619140625,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9619140625,
        "precision": 0.9576822916666667,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.6611328125,
        "f1": 0.6125000704590549,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6125000704590549,
        "precision": 0.5940305679563491,
        "recall": 0.6611328125
      },
      {
        "accuracy": 0.935546875,
        "f1": 0.9193033854166667,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9193033854166667,
        "precision": 0.9121907552083333,
        "recall": 0.935546875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007187931025609354,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007187931025609354,
        "precision": 0.005781693892045454,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9651692708333333,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9651692708333333,
        "precision": 0.9617513020833334,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.580078125,
        "f1": 0.5155172681051587,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5155172681051587,
        "precision": 0.4913822234623016,
        "recall": 0.580078125
      },
      {
        "accuracy": 0.796875,
        "f1": 0.7544340587797619,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7544340587797619,
        "precision": 0.737216331845238,
        "recall": 0.796875
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9260416666666667,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9260416666666667,
        "precision": 0.9194661458333333,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.010637151020580295,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.010637151020580295,
        "precision": 0.009011954860722371,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8856305803571429,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8856305803571429,
        "precision": 0.8759765625,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.7529296875,
        "f1": 0.707483878968254,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.707483878968254,
        "precision": 0.6896267361111111,
        "recall": 0.7529296875
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.7657591540404041,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7657591540404041,
        "precision": 0.7488199869791666,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9490397135416666,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9490397135416666,
        "precision": 0.9442313058035714,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.95830078125,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.95830078125,
        "precision": 0.9539388020833333,
        "recall": 0.9677734375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.55859375,
        "f1": 0.502502178952162,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.502502178952162,
        "precision": 0.48361643781565655,
        "recall": 0.55859375
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.96923828125,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.96923828125,
        "precision": 0.9658203125,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.8674153645833333,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8674153645833333,
        "precision": 0.8544921875,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.850102306547619,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.850102306547619,
        "precision": 0.8362630208333334,
        "recall": 0.8818359375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.953125,
        "f1": 0.93935546875,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.93935546875,
        "precision": 0.9328938802083333,
        "recall": 0.953125
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.7800547542735042,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.7800547542735042,
        "precision": 0.7621500651041666,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7098089085393773,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.7098089085393773,
        "precision": 0.691730643488456,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9778645833333333,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9778645833333333,
        "precision": 0.97509765625,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005440178940682973,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.005440178940682973,
        "precision": 0.0045484138257575754,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5330648491048882,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.5330648491048882,
        "precision": 0.509166511656746,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.7919921875,
        "f1": 0.7469518003697692,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.7469518003697692,
        "precision": 0.7294456845238095,
        "recall": 0.7919921875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.005580271546818661,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.005580271546818661,
        "precision": 0.004420557897414996,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8738978794642857,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.8738978794642857,
        "precision": 0.8637044270833334,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9148763020833333,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9148763020833333,
        "precision": 0.90576171875,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8583984375,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8583984375,
        "precision": 0.8448404947916667,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.82421875,
        "f1": 0.7891927083333333,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7891927083333333,
        "precision": 0.7745605468750001,
        "recall": 0.82421875
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8616861979166666,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8616861979166666,
        "precision": 0.850732421875,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.587890625,
        "f1": 0.5452039930555554,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5452039930555554,
        "precision": 0.529889823175956,
        "recall": 0.587890625
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8703636532738095,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8703636532738095,
        "precision": 0.8598958333333333,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.8701171875,
        "f1": 0.8443909660218254,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8443909660218254,
        "precision": 0.8345896291208791,
        "recall": 0.8701171875
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.707377697172619,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.707377697172619,
        "precision": 0.6882579985119048,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.91015625,
        "f1": 0.8908589457417582,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8908589457417582,
        "precision": 0.8824055989583334,
        "recall": 0.91015625
      },
      {
        "accuracy": 0.82421875,
        "f1": 0.7900336371527777,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7900336371527777,
        "precision": 0.7762734064980159,
        "recall": 0.82421875
      },
      {
        "accuracy": 0.703125,
        "f1": 0.6582496984352453,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6582496984352453,
        "precision": 0.6411737351190476,
        "recall": 0.703125
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8854640151515152,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8854640151515152,
        "precision": 0.8766764322916667,
        "recall": 0.90625
      },
      {
        "accuracy": 0.634765625,
        "f1": 0.5821124151227974,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5821124151227974,
        "precision": 0.5621454148065476,
        "recall": 0.634765625
      },
      {
        "accuracy": 0.9404296875,
        "f1": 0.9251627604166666,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9251627604166666,
        "precision": 0.9183756510416667,
        "recall": 0.9404296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003149096996753247,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003149096996753247,
        "precision": 0.0023478456052559915,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8828636532738094,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8828636532738094,
        "precision": 0.8734375,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.521484375,
        "f1": 0.46211757751796817,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.46211757751796817,
        "precision": 0.43998755693091635,
        "recall": 0.521484375
      },
      {
        "accuracy": 0.662109375,
        "f1": 0.6111383083062771,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6111383083062771,
        "precision": 0.5929610103438229,
        "recall": 0.662109375
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8523111979166667,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8523111979166667,
        "precision": 0.8402018229166666,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.01112274836596856,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.01112274836596856,
        "precision": 0.00938309726151523,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7992094494047619,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7992094494047619,
        "precision": 0.786083984375,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.6904296875,
        "f1": 0.6457132006448412,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6457132006448412,
        "precision": 0.629067317545165,
        "recall": 0.6904296875
      },
      {
        "accuracy": 0.7587890625,
        "f1": 0.7181454613095237,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7181454613095237,
        "precision": 0.7017050495077839,
        "recall": 0.7587890625
      },
      {
        "accuracy": 0.857421875,
        "f1": 0.8271368117559523,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8271368117559523,
        "precision": 0.8145763578869047,
        "recall": 0.857421875
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.7987754216269841,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.7987754216269841,
        "precision": 0.7837972005208333,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8315158420138888,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.8315158420138888,
        "precision": 0.8203299386160714,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.4375,
        "f1": 0.4013044084821428,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.4013044084821428,
        "precision": 0.3880960836038961,
        "recall": 0.4375
      },
      {
        "accuracy": 0.7919921875,
        "f1": 0.7512974330357143,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.7512974330357143,
        "precision": 0.7356317185418748,
        "recall": 0.7919921875
      },
      {
        "accuracy": 0.814453125,
        "f1": 0.7761320304044913,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.7761320304044913,
        "precision": 0.7612002418154762,
        "recall": 0.814453125
      },
      {
        "accuracy": 0.7373046875,
        "f1": 0.693361580910409,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.693361580910409,
        "precision": 0.6767589750744047,
        "recall": 0.7373046875
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.841801525297619,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.841801525297619,
        "precision": 0.8301432291666666,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.8143763950892857,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.8143763950892857,
        "precision": 0.8003348214285715,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.568359375,
        "f1": 0.5120349702380952,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.5120349702380952,
        "precision": 0.492591300843254,
        "recall": 0.568359375
      },
      {
        "accuracy": 0.8095703125,
        "f1": 0.7746720347794567,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.7746720347794567,
        "precision": 0.7611332000248016,
        "recall": 0.8095703125
      },
      {
        "accuracy": 0.73828125,
        "f1": 0.6914213986967893,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.6914213986967893,
        "precision": 0.6725248790922619,
        "recall": 0.73828125
      },
      {
        "accuracy": 0.859375,
        "f1": 0.8320373311584249,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.8320373311584249,
        "precision": 0.8210123697916667,
        "recall": 0.859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006578820931417439,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.006578820931417439,
        "precision": 0.0058963448660714285,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.8671875,
        "f1": 0.8350632440476191,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.8350632440476191,
        "precision": 0.821817294034091,
        "recall": 0.8671875
      },
      {
        "accuracy": 0.7373046875,
        "f1": 0.6848818824404762,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.6848818824404762,
        "precision": 0.6624674479166667,
        "recall": 0.7373046875
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7813639322916667,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.7813639322916667,
        "precision": 0.7656668526785715,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.8291015625,
        "f1": 0.7899429563492064,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.7899429563492064,
        "precision": 0.7741048177083334,
        "recall": 0.8291015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008632572939213563,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.008632572939213563,
        "precision": 0.007163561992187183,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.705078125,
        "f1": 0.6630278087797619,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.6630278087797619,
        "precision": 0.6470090835813491,
        "recall": 0.705078125
      },
      {
        "accuracy": 0.7294921875,
        "f1": 0.6816461208062771,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.6816461208062771,
        "precision": 0.6619737413194444,
        "recall": 0.7294921875
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7808756510416667,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.7808756510416667,
        "precision": 0.7650158110119047,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.8027398003472223,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.8027398003472223,
        "precision": 0.7885048518105159,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9637044270833333,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9637044270833333,
        "precision": 0.9599609375,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.572265625,
        "f1": 0.5293850756448413,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5293850756448413,
        "precision": 0.514369067347583,
        "recall": 0.572265625
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.97412109375,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.97412109375,
        "precision": 0.9710286458333334,
        "recall": 0.98046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.890234375,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.890234375,
        "precision": 0.8798828125,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8791527157738095,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8791527157738095,
        "precision": 0.8681966145833333,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9458658854166667,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9458658854166667,
        "precision": 0.9403483072916667,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.758985220508658,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.758985220508658,
        "precision": 0.7401204427083333,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.748046875,
        "f1": 0.6986397879464286,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6986397879464286,
        "precision": 0.679609607514881,
        "recall": 0.748046875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333334,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9807942708333334,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007860423900462963,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007860423900462963,
        "precision": 0.006575526253260628,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.6611328125,
        "f1": 0.5938871837797619,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5938871837797619,
        "precision": 0.5684849330357142,
        "recall": 0.6611328125
      },
      {
        "accuracy": 0.828125,
        "f1": 0.7883138020833333,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7883138020833333,
        "precision": 0.7715494791666667,
        "recall": 0.828125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007270744332009268,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007270744332009268,
        "precision": 0.006413460807236344,
        "recall": 0.015625
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.89775390625,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.89775390625,
        "precision": 0.8875325520833334,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.8987630208333334,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8987630208333334,
        "precision": 0.8888346354166667,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8668805803571429,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8668805803571429,
        "precision": 0.8549641927083333,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8818684895833333,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.8818684895833333,
        "precision": 0.8716959635416667,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.939453125,
        "f1": 0.9223958333333333,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9223958333333333,
        "precision": 0.914794921875,
        "recall": 0.939453125
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.43373635912698416,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.43373635912698416,
        "precision": 0.4179721301804464,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.857421875,
        "f1": 0.8238754734848485,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.8238754734848485,
        "precision": 0.8097981770833333,
        "recall": 0.857421875
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9166829427083333,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9166829427083333,
        "precision": 0.9090262276785714,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.783837890625,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.783837890625,
        "precision": 0.7692909846230158,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.8564453125,
        "f1": 0.8218098958333333,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8218098958333333,
        "precision": 0.8068956163194445,
        "recall": 0.8564453125
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9440104166666666,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.9440104166666666,
        "precision": 0.9376627604166666,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.6328125,
        "f1": 0.5784303695436508,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.5784303695436508,
        "precision": 0.5580376519097222,
        "recall": 0.6328125
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.885942150297619,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.885942150297619,
        "precision": 0.8771484374999999,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.7880859375,
        "f1": 0.7444010416666667,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.7444010416666667,
        "precision": 0.7266644542523448,
        "recall": 0.7880859375
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9260602678571428,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.9260602678571428,
        "precision": 0.9184895833333333,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.008638998350439882,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.008638998350439882,
        "precision": 0.007110727813852813,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.9318684895833333,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.9318684895833333,
        "precision": 0.924560546875,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.65234375,
        "f1": 0.5877317398313492,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.5877317398313492,
        "precision": 0.5621023995535714,
        "recall": 0.65234375
      },
      {
        "accuracy": 0.7177734375,
        "f1": 0.6659274102633478,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.6659274102633478,
        "precision": 0.645816317471591,
        "recall": 0.7177734375
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9500325520833333,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9500325520833333,
        "precision": 0.9453450520833333,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.00737537379117712,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.00737537379117712,
        "precision": 0.006359391119656936,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.74609375,
        "f1": 0.7016624813988095,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.7016624813988095,
        "precision": 0.6843052455357141,
        "recall": 0.74609375
      },
      {
        "accuracy": 0.875,
        "f1": 0.8435694839015151,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.8435694839015151,
        "precision": 0.8299153645833334,
        "recall": 0.875
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9057291666666667,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.9057291666666667,
        "precision": 0.8963216145833334,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.9248046875,
        "f1": 0.9034179687499999,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.9034179687499999,
        "precision": 0.8942057291666667,
        "recall": 0.9248046875
      },
      {
        "accuracy": 0.6865234375,
        "f1": 0.6347672455582611,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6347672455582611,
        "precision": 0.6153076171874999,
        "recall": 0.6865234375
      },
      {
        "accuracy": 0.763671875,
        "f1": 0.7135316614808802,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7135316614808802,
        "precision": 0.6928327287946429,
        "recall": 0.763671875
      },
      {
        "accuracy": 0.5087890625,
        "f1": 0.4635610645864552,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.4635610645864552,
        "precision": 0.44690723501758656,
        "recall": 0.5087890625
      },
      {
        "accuracy": 0.7998046875,
        "f1": 0.763440910218254,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.763440910218254,
        "precision": 0.7481531479779411,
        "recall": 0.7998046875
      },
      {
        "accuracy": 0.8017578125,
        "f1": 0.7619613405257937,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7619613405257937,
        "precision": 0.746948664941829,
        "recall": 0.8017578125
      },
      {
        "accuracy": 0.728515625,
        "f1": 0.6857569839015152,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6857569839015152,
        "precision": 0.66930177569826,
        "recall": 0.728515625
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5421347478476385,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5421347478476385,
        "precision": 0.5207786327171093,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.791015625,
        "f1": 0.7504240225919914,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.7504240225919914,
        "precision": 0.7343118686868687,
        "recall": 0.791015625
      },
      {
        "accuracy": 0.6630859375,
        "f1": 0.6083179028003247,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.6083179028003247,
        "precision": 0.5874170696924603,
        "recall": 0.6630859375
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7850818452380952,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7850818452380952,
        "precision": 0.7714518229166667,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.4970703125,
        "f1": 0.44371551029265877,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.44371551029265877,
        "precision": 0.4243724956498194,
        "recall": 0.4970703125
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6977528456558062,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.6977528456558062,
        "precision": 0.6811496310763889,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006340761491245411,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.006340761491245411,
        "precision": 0.004914917439331502,
        "recall": 0.015625
      },
      {
        "accuracy": 0.796875,
        "f1": 0.7578039744543651,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7578039744543651,
        "precision": 0.7428234281994048,
        "recall": 0.796875
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.34650065104166666,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.34650065104166666,
        "precision": 0.32305897945115547,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.580078125,
        "f1": 0.5228233751696951,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.5228233751696951,
        "precision": 0.5012536779626623,
        "recall": 0.580078125
      },
      {
        "accuracy": 0.7353515625,
        "f1": 0.6889152405753968,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.6889152405753968,
        "precision": 0.6710558637517506,
        "recall": 0.7353515625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.007368394938798282,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007368394938798282,
        "precision": 0.006045633571521219,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.7157544332837301,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7157544332837301,
        "precision": 0.700106956845238,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.5703125,
        "f1": 0.5193367125496031,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.5193367125496031,
        "precision": 0.5003855275583791,
        "recall": 0.5703125
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5680245535714286,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.5680245535714286,
        "precision": 0.5479352678571427,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8947126116071429,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.8947126116071429,
        "precision": 0.8855305989583333,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9248046875,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9248046875,
        "precision": 0.9163411458333333,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9729817708333333,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9729817708333333,
        "precision": 0.9697265625,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.5869140625,
        "f1": 0.54314440071533,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.54314440071533,
        "precision": 0.5275316399095695,
        "recall": 0.5869140625
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9683268229166667,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9683268229166667,
        "precision": 0.9649251302083333,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9873046875,
        "precision": 0.9860026041666666,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8849934895833333,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8849934895833333,
        "precision": 0.8741373697916667,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.8408203125,
        "f1": 0.8016508556547619,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8016508556547619,
        "precision": 0.785107421875,
        "recall": 0.8408203125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.8696940104166666,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8696940104166666,
        "precision": 0.8577473958333333,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.7648297991071429,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7648297991071429,
        "precision": 0.74716796875,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.671875,
        "f1": 0.620050533234127,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.620050533234127,
        "precision": 0.6007340072037337,
        "recall": 0.671875
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9706054687500001,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9706054687500001,
        "precision": 0.9673665364583333,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.0072804601731138955,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0072804601731138955,
        "precision": 0.005985007973903187,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.6201171875,
        "f1": 0.5574179997519841,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5574179997519841,
        "precision": 0.534088619171627,
        "recall": 0.6201171875
      },
      {
        "accuracy": 0.765625,
        "f1": 0.7194103422619048,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7194103422619048,
        "precision": 0.700830078125,
        "recall": 0.765625
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9689127604166666,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.9689127604166666,
        "precision": 0.9651692708333334,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006808901946195145,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006808901946195145,
        "precision": 0.005710537905255976,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.91015625,
        "f1": 0.88798828125,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.88798828125,
        "precision": 0.878125,
        "recall": 0.91015625
      },
      {
        "accuracy": 0.8095703125,
        "f1": 0.7684756324404762,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7684756324404762,
        "precision": 0.7514582910579004,
        "recall": 0.8095703125
      },
      {
        "accuracy": 0.82421875,
        "f1": 0.78544921875,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.78544921875,
        "precision": 0.7691569010416667,
        "recall": 0.82421875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.97265625,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.97265625,
        "precision": 0.96923828125,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.6669921875,
        "f1": 0.6109587650847417,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.6109587650847417,
        "precision": 0.5918736049107143,
        "recall": 0.6669921875
      },
      {
        "accuracy": 0.6845703125,
        "f1": 0.6332244894108006,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.6332244894108006,
        "precision": 0.6151141329565043,
        "recall": 0.6845703125
      },
      {
        "accuracy": 0.435546875,
        "f1": 0.39928545746673827,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.39928545746673827,
        "precision": 0.38737095424107143,
        "recall": 0.435546875
      },
      {
        "accuracy": 0.62890625,
        "f1": 0.5800793737512487,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.5800793737512487,
        "precision": 0.5646670386904762,
        "recall": 0.62890625
      },
      {
        "accuracy": 0.66015625,
        "f1": 0.6088884921875897,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.6088884921875897,
        "precision": 0.5920812585851648,
        "recall": 0.66015625
      },
      {
        "accuracy": 0.5986328125,
        "f1": 0.5444917224702381,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.5444917224702381,
        "precision": 0.5260564621648606,
        "recall": 0.5986328125
      },
      {
        "accuracy": 0.7177734375,
        "f1": 0.6713730713730713,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.6713730713730713,
        "precision": 0.6530731069061146,
        "recall": 0.7177734375
      },
      {
        "accuracy": 0.7080078125,
        "f1": 0.6552571614583333,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.6552571614583333,
        "precision": 0.6365301166039332,
        "recall": 0.7080078125
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.7019492497519841,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.7019492497519841,
        "precision": 0.6821463448660714,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.4736328125,
        "f1": 0.4283017817685786,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.4283017817685786,
        "precision": 0.41461321881243757,
        "recall": 0.4736328125
      },
      {
        "accuracy": 0.6435546875,
        "f1": 0.59221422195312,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.59221422195312,
        "precision": 0.5741179935515873,
        "recall": 0.6435546875
      },
      {
        "accuracy": 0.6298828125,
        "f1": 0.5813616071428571,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.5813616071428571,
        "precision": 0.5640768103615645,
        "recall": 0.6298828125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007244462606939629,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.007244462606939629,
        "precision": 0.006033877418154762,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.6630859375,
        "f1": 0.6122440711205517,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.6122440711205517,
        "precision": 0.5950683946045274,
        "recall": 0.6630859375
      },
      {
        "accuracy": 0.6201171875,
        "f1": 0.5627549913194444,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.5627549913194444,
        "precision": 0.5412248883928572,
        "recall": 0.6201171875
      },
      {
        "accuracy": 0.638671875,
        "f1": 0.5861450940552503,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.5861450940552503,
        "precision": 0.5672442050328654,
        "recall": 0.638671875
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6492041649756493,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.6492041649756493,
        "precision": 0.6307094029017857,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.008195444963023088,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.008195444963023088,
        "precision": 0.006933206225198412,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.5537109375,
        "f1": 0.5072767429842782,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.5072767429842782,
        "precision": 0.49097483801463293,
        "recall": 0.5537109375
      },
      {
        "accuracy": 0.650390625,
        "f1": 0.6023341513087607,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.6023341513087607,
        "precision": 0.585057493932648,
        "recall": 0.650390625
      },
      {
        "accuracy": 0.7333984375,
        "f1": 0.6886505438777231,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.6886505438777231,
        "precision": 0.6709438131313131,
        "recall": 0.7333984375
      },
      {
        "accuracy": 0.6650390625,
        "f1": 0.6108504478377524,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.6108504478377524,
        "precision": 0.5918030510071526,
        "recall": 0.6650390625
      },
      {
        "accuracy": 0.935546875,
        "f1": 0.9167317708333333,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9167317708333333,
        "precision": 0.907958984375,
        "recall": 0.935546875
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.96728515625,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.96728515625,
        "precision": 0.9638671875,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.548828125,
        "f1": 0.5049642143880425,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5049642143880425,
        "precision": 0.4895443225033068,
        "recall": 0.548828125
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.92666015625,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.92666015625,
        "precision": 0.9195475260416666,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9681640624999999,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9681640624999999,
        "precision": 0.9647623697916667,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9267578125,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9267578125,
        "precision": 0.9191080729166666,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8392764136904762,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8392764136904762,
        "precision": 0.8253417968750001,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.92431640625,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.92431640625,
        "precision": 0.916015625,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.73828125,
        "f1": 0.6884486607142857,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6884486607142857,
        "precision": 0.6686221168154762,
        "recall": 0.73828125
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9716796875,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9716796875,
        "precision": 0.9684244791666667,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.645508658008658,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.645508658008658,
        "precision": 0.6270739251953273,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0053973809580625315,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0053973809580625315,
        "precision": 0.0041917170856829574,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166667,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9806315104166667,
        "precision": 0.9783528645833333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.615234375,
        "f1": 0.5516548013618325,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5516548013618325,
        "precision": 0.5274627201140873,
        "recall": 0.615234375
      },
      {
        "accuracy": 0.74609375,
        "f1": 0.6946033296130951,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6946033296130951,
        "precision": 0.6737095424107142,
        "recall": 0.74609375
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9685872395833333,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.9685872395833333,
        "precision": 0.9651692708333334,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006076197046479529,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006076197046479529,
        "precision": 0.00495204888300017,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.8589518229166667,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8589518229166667,
        "precision": 0.8480957031249999,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.7967936197916667,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7967936197916667,
        "precision": 0.7819266183035714,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8137230282738095,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8137230282738095,
        "precision": 0.79921875,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.95654296875,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.95654296875,
        "precision": 0.95166015625,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0022806428936605317,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0022806428936605317,
        "precision": 0.002149437052200614,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002139393254681855,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.002139393254681855,
        "precision": 0.0017721860109345467,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016562077096221829,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0016562077096221829,
        "precision": 0.001057435355342674,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001910858737475467,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.001910858737475467,
        "precision": 0.0016297271286231886,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009050343424040054,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0009050343424040054,
        "precision": 0.0005179917758237394,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0029611310903770146,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0029611310903770146,
        "precision": 0.0023113039926238345,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0031046947892276857,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0031046947892276857,
        "precision": 0.0027730716718282374,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0031969719082470564,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0031969719082470564,
        "precision": 0.0027757911733672746,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0033786336766862767,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0033786336766862767,
        "precision": 0.0028973940151883586,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001955821204079718,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.001955821204079718,
        "precision": 0.0016524650043300588,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00278230939030678,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.00278230939030678,
        "precision": 0.0024816850653393095,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016794286955577277,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0016794286955577277,
        "precision": 0.0013751369952541828,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0035498141483231056,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0035498141483231056,
        "precision": 0.003295598429724592,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0029322951435246996,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0029322951435246996,
        "precision": 0.0024427118148395723,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002931333227687701,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.002931333227687701,
        "precision": 0.0025559829143018643,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0019986312986907417,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0019986312986907417,
        "precision": 0.0016692670410297327,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003167659068006564,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.003167659068006564,
        "precision": 0.002696775283491561,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012011793489215314,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.012011793489215314,
        "precision": 0.009755438432700584,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003003030378758971,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.003003030378758971,
        "precision": 0.002663672223274038,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015716911764705882,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0015716911764705882,
        "precision": 0.0010643802472014925,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003233357833421423,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.003233357833421423,
        "precision": 0.0026047712800611215,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0034778576717439803,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0034778576717439803,
        "precision": 0.0032426371948333656,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.96435546875,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.96435546875,
        "precision": 0.96044921875,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.564453125,
        "f1": 0.5218680950126262,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5218680950126262,
        "precision": 0.5070870991625818,
        "recall": 0.564453125
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9625651041666667,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9625651041666667,
        "precision": 0.95849609375,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8855794270833333,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8855794270833333,
        "precision": 0.8749186197916667,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8569847470238094,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8569847470238094,
        "precision": 0.8432942708333333,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9382161458333333,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9382161458333333,
        "precision": 0.9317220052083334,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.7734375,
        "f1": 0.7285745287698413,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7285745287698413,
        "precision": 0.7102969215029762,
        "recall": 0.7734375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9923502604166666,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9923502604166666,
        "precision": 0.9915364583333333,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6702032180059523,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6702032180059523,
        "precision": 0.6497109064980159,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666666,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9791666666666666,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.007608221399853801,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007608221399853801,
        "precision": 0.0060229804540266494,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.66015625,
        "f1": 0.5996518834897742,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5996518834897742,
        "precision": 0.5772174169146825,
        "recall": 0.66015625
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7711286272321429,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7711286272321429,
        "precision": 0.7535249255952381,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.008365319613095662,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008365319613095662,
        "precision": 0.007077840461916749,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8793619791666667,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8793619791666667,
        "precision": 0.8693033854166666,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.87734375,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.87734375,
        "precision": 0.8641764322916666,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8650576636904762,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8650576636904762,
        "precision": 0.852490234375,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.6064453125,
        "f1": 0.5524934836214133,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.5524934836214133,
        "precision": 0.535308153751116,
        "recall": 0.6064453125
      },
      {
        "accuracy": 0.599609375,
        "f1": 0.5488063219874744,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.5488063219874744,
        "precision": 0.5326537625680771,
        "recall": 0.599609375
      },
      {
        "accuracy": 0.3056640625,
        "f1": 0.27790575214460783,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.27790575214460783,
        "precision": 0.2692730030577572,
        "recall": 0.3056640625
      },
      {
        "accuracy": 0.4599609375,
        "f1": 0.40943927229524507,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.40943927229524507,
        "precision": 0.39505911064795785,
        "recall": 0.4599609375
      },
      {
        "accuracy": 0.4765625,
        "f1": 0.4256293676324696,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.4256293676324696,
        "precision": 0.4110211525128517,
        "recall": 0.4765625
      },
      {
        "accuracy": 0.4365234375,
        "f1": 0.3869455377144745,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.3869455377144745,
        "precision": 0.3718524639423077,
        "recall": 0.4365234375
      },
      {
        "accuracy": 0.7138671875,
        "f1": 0.6681927393353174,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.6681927393353174,
        "precision": 0.6518937261625892,
        "recall": 0.7138671875
      },
      {
        "accuracy": 0.548828125,
        "f1": 0.4949266156108857,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.4949266156108857,
        "precision": 0.47874520905526763,
        "recall": 0.548828125
      },
      {
        "accuracy": 0.572265625,
        "f1": 0.5134965457719365,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.5134965457719365,
        "precision": 0.49381746454500364,
        "recall": 0.572265625
      },
      {
        "accuracy": 0.3125,
        "f1": 0.2672471993832862,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.2672471993832862,
        "precision": 0.25486958506675694,
        "recall": 0.3125
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.46178820166150547,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.46178820166150547,
        "precision": 0.44443786736267205,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.5654296875,
        "f1": 0.514934161401303,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.514934161401303,
        "precision": 0.4975321228250916,
        "recall": 0.5654296875
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.4507956370427746,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.4507956370427746,
        "precision": 0.4386942716539741,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.008558536679228314,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.008558536679228314,
        "precision": 0.006644764103060808,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.5419921875,
        "f1": 0.4886667815505976,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.4886667815505976,
        "precision": 0.4724747974087733,
        "recall": 0.5419921875
      },
      {
        "accuracy": 0.6376953125,
        "f1": 0.5871054509726384,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.5871054509726384,
        "precision": 0.5691389551204004,
        "recall": 0.6376953125
      },
      {
        "accuracy": 0.5244140625,
        "f1": 0.4665663093518701,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.4665663093518701,
        "precision": 0.44934759522161866,
        "recall": 0.5244140625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006252325148809523,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.006252325148809523,
        "precision": 0.005349517875216888,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.373046875,
        "f1": 0.3280423316163381,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.3280423316163381,
        "precision": 0.3152968830214924,
        "recall": 0.373046875
      },
      {
        "accuracy": 0.4267578125,
        "f1": 0.37704573089693744,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.37704573089693744,
        "precision": 0.36127290271577384,
        "recall": 0.4267578125
      },
      {
        "accuracy": 0.5673828125,
        "f1": 0.5117956324376385,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.5117956324376385,
        "precision": 0.4926871712272103,
        "recall": 0.5673828125
      },
      {
        "accuracy": 0.46484375,
        "f1": 0.4071939090040561,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.4071939090040561,
        "precision": 0.3898896323148104,
        "recall": 0.46484375
      },
      {
        "accuracy": 0.6572265625,
        "f1": 0.6031601878795547,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.6031601878795547,
        "precision": 0.5841722470238095,
        "recall": 0.6572265625
      },
      {
        "accuracy": 0.7392578125,
        "f1": 0.6891946459573413,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.6891946459573413,
        "precision": 0.6704031808035714,
        "recall": 0.7392578125
      },
      {
        "accuracy": 0.4326171875,
        "f1": 0.3970661404244765,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.3970661404244765,
        "precision": 0.3845287387120352,
        "recall": 0.4326171875
      },
      {
        "accuracy": 0.7568359375,
        "f1": 0.7177645948886183,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.7177645948886183,
        "precision": 0.7029966696714745,
        "recall": 0.7568359375
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6614133804563491,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.6614133804563491,
        "precision": 0.6444584657963564,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.6240234375,
        "f1": 0.5773419639448891,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.5773419639448891,
        "precision": 0.5607936686794108,
        "recall": 0.6240234375
      },
      {
        "accuracy": 0.8125,
        "f1": 0.7712456597222221,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.7712456597222221,
        "precision": 0.7541748046875,
        "recall": 0.8125
      },
      {
        "accuracy": 0.763671875,
        "f1": 0.7207431891025641,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.7207431891025641,
        "precision": 0.7049033865440115,
        "recall": 0.763671875
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.6611166069173882,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.6611166069173882,
        "precision": 0.6428679935515873,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.4956981224071067,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.4956981224071067,
        "precision": 0.48159596276661704,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.720703125,
        "f1": 0.6762013268849206,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.6762013268849206,
        "precision": 0.6610495614602921,
        "recall": 0.720703125
      },
      {
        "accuracy": 0.65234375,
        "f1": 0.6109902738320707,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.6109902738320707,
        "precision": 0.5950292145107945,
        "recall": 0.65234375
      },
      {
        "accuracy": 0.6796875,
        "f1": 0.6288508166951835,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.6288508166951835,
        "precision": 0.6120353686027513,
        "recall": 0.6796875
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.012406870744273088,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.012406870744273088,
        "precision": 0.01079530689614485,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6935022369506515,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.6935022369506515,
        "precision": 0.6758264318689123,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.6650390625,
        "f1": 0.6101896475919913,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.6101896475919913,
        "precision": 0.588037109375,
        "recall": 0.6650390625
      },
      {
        "accuracy": 0.7080078125,
        "f1": 0.6581325954861111,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.6581325954861111,
        "precision": 0.6398457228535352,
        "recall": 0.7080078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007083248782467532,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.007083248782467532,
        "precision": 0.005898042993056779,
        "recall": 0.015625
      },
      {
        "accuracy": 0.6337890625,
        "f1": 0.5915350491522366,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.5915350491522366,
        "precision": 0.5764275640623098,
        "recall": 0.6337890625
      },
      {
        "accuracy": 0.6171875,
        "f1": 0.5656637524801588,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.5656637524801588,
        "precision": 0.5470157942483884,
        "recall": 0.6171875
      },
      {
        "accuracy": 0.6923828125,
        "f1": 0.6384866381448412,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.6384866381448412,
        "precision": 0.6187131851438492,
        "recall": 0.6923828125
      },
      {
        "accuracy": 0.7685546875,
        "f1": 0.7238411816048536,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.7238411816048536,
        "precision": 0.7073497953869048,
        "recall": 0.7685546875
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9524739583333333,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9524739583333333,
        "precision": 0.94775390625,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.5537109375,
        "f1": 0.5095222594246032,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5095222594246032,
        "precision": 0.49379107762896823,
        "recall": 0.5537109375
      },
      {
        "accuracy": 0.939453125,
        "f1": 0.9230143229166667,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9230143229166667,
        "precision": 0.9153645833333334,
        "recall": 0.939453125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.8442243303571428,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8442243303571428,
        "precision": 0.8302734375,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.8132309422348485,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8132309422348485,
        "precision": 0.79833984375,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9380533854166666,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9380533854166666,
        "precision": 0.931396484375,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.7333984375,
        "f1": 0.6828970508658008,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6828970508658008,
        "precision": 0.6627061631944444,
        "recall": 0.7333984375
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9765625,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9765625,
        "precision": 0.9736328125,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.7431640625,
        "f1": 0.6927160838293651,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6927160838293651,
        "precision": 0.6732774522569445,
        "recall": 0.7431640625
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9742838541666667,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9742838541666667,
        "precision": 0.9716796875,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006605539827719706,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006605539827719706,
        "precision": 0.005652457812343542,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9899088541666666,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9899088541666666,
        "precision": 0.98876953125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.6142578125,
        "f1": 0.5503665984623016,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5503665984623016,
        "precision": 0.5264327144209957,
        "recall": 0.6142578125
      },
      {
        "accuracy": 0.734375,
        "f1": 0.6839804997519842,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6839804997519842,
        "precision": 0.6656207372271825,
        "recall": 0.734375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005661028250717149,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005661028250717149,
        "precision": 0.004646013708513709,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8130719866071429,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8130719866071429,
        "precision": 0.79755859375,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.8757161458333333,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8757161458333333,
        "precision": 0.8643391927083333,
        "recall": 0.900390625
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.85185546875,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.85185546875,
        "precision": 0.8382812500000001,
        "recall": 0.8818359375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9808593749999999,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9808593749999999,
        "precision": 0.978759765625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0031079198494642704,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0031079198494642704,
        "precision": 0.0027747022266390135,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005811687740239455,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.005811687740239455,
        "precision": 0.005221134443866543,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002501720502721874,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.002501720502721874,
        "precision": 0.001955525630547986,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004854191053144006,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.004854191053144006,
        "precision": 0.004557461513580762,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0034912847506062927,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0034912847506062927,
        "precision": 0.0029237356563419593,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003978183801673107,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.003978183801673107,
        "precision": 0.0035864775020188477,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004008891926246207,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.004008891926246207,
        "precision": 0.0036040804748793723,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004495743249200787,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.004495743249200787,
        "precision": 0.003942124168834605,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0045790014181480215,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0045790014181480215,
        "precision": 0.0037928571321270118,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0035100154216915263,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0035100154216915263,
        "precision": 0.00330317468989344,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003647047955675624,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.003647047955675624,
        "precision": 0.003345354976149678,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004001640067029622,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.004001640067029622,
        "precision": 0.00364102605993659,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030769232149846647,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0030769232149846647,
        "precision": 0.003005753321558617,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.01694998597226812,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.01694998597226812,
        "precision": 0.014949463855607708,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005993353097086556,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.005993353097086556,
        "precision": 0.005334378835650799,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006229959314213085,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.006229959314213085,
        "precision": 0.005429776077097506,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031569030270154038,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0031569030270154038,
        "precision": 0.0030488368966362133,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005389347254672897,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.005389347254672897,
        "precision": 0.0051710432109164425,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004079267891326863,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.004079267891326863,
        "precision": 0.003695234065681561,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004404530909586057,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.004404530909586057,
        "precision": 0.00423678448186279,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003494578678415379,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.003494578678415379,
        "precision": 0.002921911068124239,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002943703709033694,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.002943703709033694,
        "precision": 0.0029367210047478547,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.7890625,
        "f1": 0.7485723586309523,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7485723586309523,
        "precision": 0.7320312499999999,
        "recall": 0.7890625
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8306849888392858,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8306849888392858,
        "precision": 0.8189057849702381,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.6025390625,
        "f1": 0.5643802703373015,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5643802703373015,
        "precision": 0.5501128365098953,
        "recall": 0.6025390625
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8787295386904761,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8787295386904761,
        "precision": 0.8682779947916667,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8692708333333333,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8692708333333333,
        "precision": 0.8598407451923077,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.84375,
        "f1": 0.8132719494047619,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8132719494047619,
        "precision": 0.8007998511904761,
        "recall": 0.84375
      },
      {
        "accuracy": 0.748046875,
        "f1": 0.6965122767857143,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6965122767857143,
        "precision": 0.6760025618912338,
        "recall": 0.748046875
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8975911458333332,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8975911458333332,
        "precision": 0.8883463541666667,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.7685546875,
        "f1": 0.7230375744047619,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7230375744047619,
        "precision": 0.7042503720238095,
        "recall": 0.7685546875
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.700941755726912,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.700941755726912,
        "precision": 0.685977450284091,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8850911458333333,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8850911458333333,
        "precision": 0.8757649739583333,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.5986328125,
        "f1": 0.5415511842757936,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5415511842757936,
        "precision": 0.5204244946676587,
        "recall": 0.5986328125
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.8427056206597222,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8427056206597222,
        "precision": 0.8323742094494048,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004342731867844345,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004342731867844345,
        "precision": 0.0032852436667770496,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8627504114808802,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8627504114808802,
        "precision": 0.8516520182291667,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.5126953125,
        "f1": 0.4484509441296551,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.4484509441296551,
        "precision": 0.4255015482755602,
        "recall": 0.5126953125
      },
      {
        "accuracy": 0.6806640625,
        "f1": 0.6338402157738094,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6338402157738094,
        "precision": 0.6157110305059523,
        "recall": 0.6806640625
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8286606297348484,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.8286606297348484,
        "precision": 0.8164008246527777,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004972537989165848,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004972537989165848,
        "precision": 0.004078523850603838,
        "recall": 0.015625
      },
      {
        "accuracy": 0.67578125,
        "f1": 0.6250829303075397,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6250829303075397,
        "precision": 0.6063721055420275,
        "recall": 0.67578125
      },
      {
        "accuracy": 0.7431640625,
        "f1": 0.6965441242784993,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6965441242784993,
        "precision": 0.6790143694196429,
        "recall": 0.7431640625
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8559733072916667,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8559733072916667,
        "precision": 0.8446618810876623,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.78125,
        "f1": 0.7366962735615079,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7366962735615079,
        "precision": 0.718539574032738,
        "recall": 0.78125
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8682338169642857,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8682338169642857,
        "precision": 0.8582465277777778,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.4296875,
        "f1": 0.3929411165006868,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.3929411165006868,
        "precision": 0.38033437007615545,
        "recall": 0.4296875
      },
      {
        "accuracy": 0.76171875,
        "f1": 0.7180764818948413,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.7180764818948413,
        "precision": 0.7010265531994048,
        "recall": 0.76171875
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8657459077380951,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8657459077380951,
        "precision": 0.8541178385416667,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.693359375,
        "f1": 0.6488545471455627,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.6488545471455627,
        "precision": 0.6334502582806447,
        "recall": 0.693359375
      },
      {
        "accuracy": 0.7275390625,
        "f1": 0.6776390438988096,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.6776390438988096,
        "precision": 0.657283916170635,
        "recall": 0.7275390625
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8735700334821428,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.8735700334821428,
        "precision": 0.862606956845238,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8275065104166667,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.8275065104166667,
        "precision": 0.8136881510416667,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.55859375,
        "f1": 0.5131245138325216,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5131245138325216,
        "precision": 0.4973400297619047,
        "recall": 0.55859375
      },
      {
        "accuracy": 0.8017578125,
        "f1": 0.7613281249999999,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.7613281249999999,
        "precision": 0.7445250496031746,
        "recall": 0.8017578125
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.6138629951862374,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.6138629951862374,
        "precision": 0.5944293309771825,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.8271484375,
        "f1": 0.7940903172348485,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.7940903172348485,
        "precision": 0.7813445560515873,
        "recall": 0.8271484375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.0075757023780769666,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0075757023780769666,
        "precision": 0.006211369896094403,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.8727725074404762,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8727725074404762,
        "precision": 0.8626953125,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.5087890625,
        "f1": 0.448031831991793,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.448031831991793,
        "precision": 0.4259072307900433,
        "recall": 0.5087890625
      },
      {
        "accuracy": 0.6474609375,
        "f1": 0.5927238343253968,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.5927238343253968,
        "precision": 0.5711697048611111,
        "recall": 0.6474609375
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8431036086309525,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.8431036086309525,
        "precision": 0.8312825520833333,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0056411007889478094,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0056411007889478094,
        "precision": 0.0046039627881309855,
        "recall": 0.015625
      },
      {
        "accuracy": 0.6513671875,
        "f1": 0.605419716714811,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.605419716714811,
        "precision": 0.5898621574280754,
        "recall": 0.6513671875
      },
      {
        "accuracy": 0.79296875,
        "f1": 0.7531545928030303,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.7531545928030303,
        "precision": 0.7368435329861112,
        "recall": 0.79296875
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8681935143849207,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.8681935143849207,
        "precision": 0.858154296875,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.8095703125,
        "f1": 0.7681849888392858,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.7681849888392858,
        "precision": 0.7515392485119048,
        "recall": 0.8095703125
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8349283854166667,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.8349283854166667,
        "precision": 0.8207845052083333,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.51171875,
        "f1": 0.4732675589767157,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.4732675589767157,
        "precision": 0.4604772899084422,
        "recall": 0.51171875
      },
      {
        "accuracy": 0.7841796875,
        "f1": 0.7434554811507936,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.7434554811507936,
        "precision": 0.7280175363915599,
        "recall": 0.7841796875
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8161792309253246,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8161792309253246,
        "precision": 0.8049176897321428,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.7470703125,
        "f1": 0.7037619715354091,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.7037619715354091,
        "precision": 0.6872639973958332,
        "recall": 0.7470703125
      },
      {
        "accuracy": 0.80859375,
        "f1": 0.7650956411210317,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.7650956411210317,
        "precision": 0.7470389229910714,
        "recall": 0.80859375
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.8576737661210316,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.8576737661210316,
        "precision": 0.8472776382688493,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9031575520833333,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.9031575520833333,
        "precision": 0.8936197916666667,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.591796875,
        "f1": 0.5393507696730353,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.5393507696730353,
        "precision": 0.521235584077381,
        "recall": 0.591796875
      },
      {
        "accuracy": 0.8046875,
        "f1": 0.7662512400793651,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.7662512400793651,
        "precision": 0.7512962704613095,
        "recall": 0.8046875
      },
      {
        "accuracy": 0.7763671875,
        "f1": 0.7395818536931817,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.7395818536931817,
        "precision": 0.724512141504329,
        "recall": 0.7763671875
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8137393043154761,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8137393043154761,
        "precision": 0.8016965835813492,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.008187892294337607,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.008187892294337607,
        "precision": 0.007357396834935897,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8396833147321429,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8396833147321429,
        "precision": 0.8261811755952381,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.6484375,
        "f1": 0.5900236319669913,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.5900236319669913,
        "precision": 0.5669363839285714,
        "recall": 0.6484375
      },
      {
        "accuracy": 0.68359375,
        "f1": 0.6331921550671551,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.6331921550671551,
        "precision": 0.6139485677083334,
        "recall": 0.68359375
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8541341145833333,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.8541341145833333,
        "precision": 0.8420735677083333,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008618750317969067,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.008618750317969067,
        "precision": 0.00785505564314158,
        "recall": 0.015625
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.6727741279987374,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.6727741279987374,
        "precision": 0.6586545913938492,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7483677455357143,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.7483677455357143,
        "precision": 0.7313902243589743,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.845703125,
        "f1": 0.8113444010416666,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.8113444010416666,
        "precision": 0.7974702380952381,
        "recall": 0.845703125
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9501953125,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9501953125,
        "precision": 0.9451497395833333,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.49126330389492756,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.49126330389492756,
        "precision": 0.47445842731487264,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9606119791666666,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.9606119791666666,
        "precision": 0.9562174479166666,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.8701171875,
        "f1": 0.8390299479166666,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.8390299479166666,
        "precision": 0.825341796875,
        "recall": 0.8701171875
      },
      {
        "accuracy": 0.8740234375,
        "f1": 0.8401553199404761,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.8401553199404761,
        "precision": 0.8246256510416667,
        "recall": 0.8740234375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9923502604166667,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9923502604166667,
        "precision": 0.9915364583333333,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.920703125,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.920703125,
        "precision": 0.9124348958333333,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.8940104166666666,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.8940104166666666,
        "precision": 0.88330078125,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9694010416666667,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9694010416666667,
        "precision": 0.9659830729166666,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.6708868117559524,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.6708868117559524,
        "precision": 0.648886253720238,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.96923828125,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.96923828125,
        "precision": 0.9656575520833333,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006084976224443414,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.006084976224443414,
        "precision": 0.005169142067352372,
        "recall": 0.015625
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5280017671130952,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.5280017671130952,
        "precision": 0.4999007936507936,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.7958333333333334,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.7958333333333334,
        "precision": 0.7798828125,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9689127604166667,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.9689127604166667,
        "precision": 0.9651692708333333,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006246428982166628,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.006246428982166628,
        "precision": 0.005402932519156605,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8830078124999999,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.8830078124999999,
        "precision": 0.8724772135416667,
        "recall": 0.90625
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8852213541666667,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8852213541666667,
        "precision": 0.8746744791666666,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.8515625,
        "f1": 0.8119326636904761,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8119326636904761,
        "precision": 0.7936197916666667,
        "recall": 0.8515625
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}