{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.767624,
        "f1": 0.7651,
        "f1_weighted": 0.765708,
        "scores_per_experiment": [
          {
            "accuracy": 0.796345,
            "f1": 0.794159,
            "f1_weighted": 0.795224
          },
          {
            "accuracy": 0.73107,
            "f1": 0.729919,
            "f1_weighted": 0.728573
          },
          {
            "accuracy": 0.75718,
            "f1": 0.756571,
            "f1_weighted": 0.757307
          },
          {
            "accuracy": 0.75718,
            "f1": 0.754817,
            "f1_weighted": 0.754042
          },
          {
            "accuracy": 0.78329,
            "f1": 0.776681,
            "f1_weighted": 0.77856
          },
          {
            "accuracy": 0.830287,
            "f1": 0.830439,
            "f1_weighted": 0.830728
          },
          {
            "accuracy": 0.788512,
            "f1": 0.789795,
            "f1_weighted": 0.790559
          },
          {
            "accuracy": 0.754569,
            "f1": 0.744486,
            "f1_weighted": 0.745547
          },
          {
            "accuracy": 0.78329,
            "f1": 0.783631,
            "f1_weighted": 0.783109
          },
          {
            "accuracy": 0.694517,
            "f1": 0.690498,
            "f1_weighted": 0.693429
          }
        ],
        "main_score": 0.767624,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.747917,
        "f1": 0.747294,
        "f1_weighted": 0.743712,
        "scores_per_experiment": [
          {
            "accuracy": 0.78125,
            "f1": 0.780585,
            "f1_weighted": 0.779568
          },
          {
            "accuracy": 0.697917,
            "f1": 0.704493,
            "f1_weighted": 0.696926
          },
          {
            "accuracy": 0.770833,
            "f1": 0.771953,
            "f1_weighted": 0.768235
          },
          {
            "accuracy": 0.8125,
            "f1": 0.812998,
            "f1_weighted": 0.812178
          },
          {
            "accuracy": 0.802083,
            "f1": 0.798912,
            "f1_weighted": 0.798864
          },
          {
            "accuracy": 0.802083,
            "f1": 0.802946,
            "f1_weighted": 0.797678
          },
          {
            "accuracy": 0.802083,
            "f1": 0.805252,
            "f1_weighted": 0.801812
          },
          {
            "accuracy": 0.71875,
            "f1": 0.71432,
            "f1_weighted": 0.713598
          },
          {
            "accuracy": 0.65625,
            "f1": 0.656264,
            "f1_weighted": 0.641753
          },
          {
            "accuracy": 0.635417,
            "f1": 0.625221,
            "f1_weighted": 0.626506
          }
        ],
        "main_score": 0.747917,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 66.35566926002502,
  "kg_co2_emissions": 0.004766395555140949
}