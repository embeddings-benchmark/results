{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 1886.8552389144897,
  "kg_co2_emissions": 0.1537821945657869,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733859,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9947299077733859,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.8132411067193676,
        "f1": 0.7713063725909576,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.7713063725909576,
        "precision": 0.7554234111299328,
        "recall": 0.8132411067193676
      },
      {
        "accuracy": 0.8715415019762845,
        "f1": 0.8349472990777339,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.8349472990777339,
        "precision": 0.8186100131752306,
        "recall": 0.8715415019762845
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9169960474308301,
        "f1": 0.8942028985507247,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8942028985507247,
        "precision": 0.8845849802371542,
        "recall": 0.9169960474308301
      },
      {
        "accuracy": 0.9308300395256917,
        "f1": 0.9096508563899868,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9096508563899868,
        "precision": 0.8994894598155467,
        "recall": 0.9308300395256917
      },
      {
        "accuracy": 0.6926877470355731,
        "f1": 0.6388479519664886,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.6388479519664886,
        "precision": 0.6205317862308968,
        "recall": 0.6926877470355731
      },
      {
        "accuracy": 0.775691699604743,
        "f1": 0.7278103748803182,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.7278103748803182,
        "precision": 0.7079500538986705,
        "recall": 0.775691699604743
      },
      {
        "accuracy": 0.974308300395257,
        "f1": 0.9660737812911727,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9660737812911727,
        "precision": 0.9621212121212122,
        "recall": 0.974308300395257
      },
      {
        "accuracy": 0.9822134387351779,
        "f1": 0.9762845849802372,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9762845849802372,
        "precision": 0.9733201581027668,
        "recall": 0.9822134387351779
      },
      {
        "accuracy": 0.892292490118577,
        "f1": 0.8647397891963109,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8647397891963109,
        "precision": 0.8529620741577264,
        "recall": 0.892292490118577
      },
      {
        "accuracy": 0.9278656126482213,
        "f1": 0.9049736495388668,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9049736495388668,
        "precision": 0.8939393939393939,
        "recall": 0.9278656126482213
      },
      {
        "accuracy": 0.8468379446640316,
        "f1": 0.8095191040843215,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8095191040843215,
        "precision": 0.7943777237255497,
        "recall": 0.8468379446640316
      },
      {
        "accuracy": 0.8754940711462451,
        "f1": 0.8421136834180313,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8421136834180313,
        "precision": 0.8274374176548088,
        "recall": 0.8754940711462451
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733861,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9947299077733861,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.8893280632411067,
        "f1": 0.8594367588932806,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.8594367588932806,
        "precision": 0.8467979484283831,
        "recall": 0.8893280632411067
      },
      {
        "accuracy": 0.9407114624505929,
        "f1": 0.9225955204216072,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9225955204216072,
        "precision": 0.9141963109354413,
        "recall": 0.9407114624505929
      },
      {
        "accuracy": 0.9861660079051383,
        "f1": 0.9817193675889329,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9817193675889329,
        "precision": 0.979578392621871,
        "recall": 0.9861660079051383
      },
      {
        "accuracy": 0.9792490118577075,
        "f1": 0.9724967061923584,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9724967061923584,
        "precision": 0.9692028985507247,
        "recall": 0.9792490118577075
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9884716732542819,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9884716732542819,
        "precision": 0.9871541501976284,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9914361001317522,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9914361001317522,
        "precision": 0.9906126482213439,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.5059288537549407,
        "f1": 0.4541979869054968,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.4541979869054968,
        "precision": 0.4396454509362768,
        "recall": 0.5059288537549407
      },
      {
        "accuracy": 0.5948616600790514,
        "f1": 0.5252965139822847,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.5252965139822847,
        "precision": 0.4999361200942229,
        "recall": 0.5948616600790514
      },
      {
        "accuracy": 0.6867588932806324,
        "f1": 0.6335605597896191,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.6335605597896191,
        "precision": 0.6155881160451319,
        "recall": 0.6867588932806324
      },
      {
        "accuracy": 0.8033596837944664,
        "f1": 0.7523409561453039,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.7523409561453039,
        "precision": 0.7306912290607943,
        "recall": 0.8033596837944664
      },
      {
        "accuracy": 0.8241106719367589,
        "f1": 0.7878443526170799,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7878443526170799,
        "precision": 0.7746263453279263,
        "recall": 0.8241106719367589
      },
      {
        "accuracy": 0.8488142292490118,
        "f1": 0.8114483342744212,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.8114483342744212,
        "precision": 0.7957454984628898,
        "recall": 0.8488142292490118
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.9828722002635045,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9828722002635045,
        "precision": 0.9807312252964426,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 0.9851778656126482,
        "f1": 0.9805665349143611,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9805665349143611,
        "precision": 0.9782608695652174,
        "recall": 0.9851778656126482
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9874835309617918,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9874835309617918,
        "precision": 0.9861660079051383,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9850131752305664,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9850131752305664,
        "precision": 0.9835309617918314,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.994729907773386,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.994729907773386,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.9973649538866931,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9973649538866931,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.2618577075098814,
        "f1": 0.21421308310533982,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.21421308310533982,
        "precision": 0.20286536694150858,
        "recall": 0.2618577075098814
      },
      {
        "accuracy": 0.4189723320158103,
        "f1": 0.3458367317062969,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.3458367317062969,
        "precision": 0.32026480052665823,
        "recall": 0.4189723320158103
      },
      {
        "accuracy": 0.39031620553359686,
        "f1": 0.34925172422891604,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.34925172422891604,
        "precision": 0.33839640595705034,
        "recall": 0.39031620553359686
      },
      {
        "accuracy": 0.44664031620553357,
        "f1": 0.3981570952207958,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.3981570952207958,
        "precision": 0.38062902457665304,
        "recall": 0.44664031620553357
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.989459815546772,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.989459815546772,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034257,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9907773386034257,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.8843873517786561,
        "f1": 0.8567248572683355,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8567248572683355,
        "precision": 0.8456368812347073,
        "recall": 0.8843873517786561
      },
      {
        "accuracy": 0.9051383399209486,
        "f1": 0.8790513833992094,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8790513833992094,
        "precision": 0.8679841897233203,
        "recall": 0.9051383399209486
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9841897233201581,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9841897233201581,
        "precision": 0.9822134387351779,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9843544137022397,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9843544137022397,
        "precision": 0.9825428194993413,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034255,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9907773386034255,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9909420289855072,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9909420289855072,
        "precision": 0.9899538866930172,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9843544137022397,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9843544137022397,
        "precision": 0.9825428194993412,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.49604743083003955,
        "f1": 0.4605133076644058,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.4605133076644058,
        "precision": 0.4508754182203255,
        "recall": 0.49604743083003955
      },
      {
        "accuracy": 0.5741106719367589,
        "f1": 0.5219554762477767,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.5219554762477767,
        "precision": 0.5044432341258585,
        "recall": 0.5741106719367589
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9950592885375494,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9950592885375494,
        "precision": 0.9945652173913043,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9948945981554677,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9948945981554677,
        "precision": 0.9944005270092225,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9871541501976284,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9871541501976284,
        "precision": 0.9856719367588933,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.01978089258945871,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.01978089258945871,
        "precision": 0.018604575317383604,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.039525691699604744,
        "f1": 0.024463800072670107,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.024463800072670107,
        "precision": 0.021296530352920215,
        "recall": 0.039525691699604744
      }
    ],
    "validation": [
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.8324974924774323,
        "f1": 0.7981252058985258,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.7981252058985258,
        "precision": 0.7858141885975386,
        "recall": 0.8324974924774323
      },
      {
        "accuracy": 0.8936810431293881,
        "f1": 0.8632898696088265,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.8632898696088265,
        "precision": 0.8496322300234035,
        "recall": 0.8936810431293881
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9327983951855566,
        "f1": 0.9162344175383292,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9162344175383292,
        "precision": 0.9095787362086258,
        "recall": 0.9327983951855566
      },
      {
        "accuracy": 0.9408224674022067,
        "f1": 0.9246740220661985,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9246740220661985,
        "precision": 0.9173353393513874,
        "recall": 0.9408224674022067
      },
      {
        "accuracy": 0.6649949849548646,
        "f1": 0.6230198949607175,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.6230198949607175,
        "precision": 0.6096901724945061,
        "recall": 0.6649949849548646
      },
      {
        "accuracy": 0.7733199598796389,
        "f1": 0.726069478276098,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.726069478276098,
        "precision": 0.707044546337425,
        "recall": 0.7733199598796389
      },
      {
        "accuracy": 0.9739217652958877,
        "f1": 0.9655633567368772,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9655633567368772,
        "precision": 0.9615513206285524,
        "recall": 0.9739217652958877
      },
      {
        "accuracy": 0.9829488465396189,
        "f1": 0.9775994650618522,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9775994650618522,
        "precision": 0.9750919424941491,
        "recall": 0.9829488465396189
      },
      {
        "accuracy": 0.8896690070210632,
        "f1": 0.8651621531260447,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8651621531260447,
        "precision": 0.8557139672987216,
        "recall": 0.8896690070210632
      },
      {
        "accuracy": 0.9227683049147443,
        "f1": 0.8992978936810432,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.8992978936810432,
        "precision": 0.8884988298228018,
        "recall": 0.9227683049147443
      },
      {
        "accuracy": 0.8114343029087262,
        "f1": 0.7771883332314626,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.7771883332314626,
        "precision": 0.7651604998144618,
        "recall": 0.8114343029087262
      },
      {
        "accuracy": 0.8826479438314945,
        "f1": 0.8506853895018388,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8506853895018388,
        "precision": 0.8366098294884654,
        "recall": 0.8826479438314945
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222335,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222335,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.8896690070210632,
        "f1": 0.8640254095620193,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.8640254095620193,
        "precision": 0.8536769037270543,
        "recall": 0.8896690070210632
      },
      {
        "accuracy": 0.9127382146439318,
        "f1": 0.8868940153794718,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8868940153794718,
        "precision": 0.8752423938482113,
        "recall": 0.9127382146439318
      },
      {
        "accuracy": 0.9849548645937813,
        "f1": 0.9801069876295553,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9801069876295553,
        "precision": 0.9777666332330324,
        "recall": 0.9849548645937813
      },
      {
        "accuracy": 0.9819458375125376,
        "f1": 0.9759277833500501,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9759277833500501,
        "precision": 0.9729187562688064,
        "recall": 0.9819458375125376
      },
      {
        "accuracy": 0.9859578736208626,
        "f1": 0.9816115011701771,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9816115011701771,
        "precision": 0.9794383149448345,
        "recall": 0.9859578736208626
      },
      {
        "accuracy": 0.9839518555667001,
        "f1": 0.9789368104312939,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9789368104312939,
        "precision": 0.9764292878635907,
        "recall": 0.9839518555667001
      },
      {
        "accuracy": 0.4794383149448345,
        "f1": 0.4312444810672252,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.4312444810672252,
        "precision": 0.41741517331420647,
        "recall": 0.4794383149448345
      },
      {
        "accuracy": 0.6158475426278837,
        "f1": 0.5511035270313104,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.5511035270313104,
        "precision": 0.5276703125248763,
        "recall": 0.6158475426278837
      },
      {
        "accuracy": 0.7051153460381143,
        "f1": 0.6607441473711761,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.6607441473711761,
        "precision": 0.6457551336437997,
        "recall": 0.7051153460381143
      },
      {
        "accuracy": 0.8164493480441324,
        "f1": 0.7696199710241837,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.7696199710241837,
        "precision": 0.7497158141089937,
        "recall": 0.8164493480441324
      },
      {
        "accuracy": 0.8104312938816449,
        "f1": 0.7761168425912659,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7761168425912659,
        "precision": 0.7635955485504131,
        "recall": 0.8104312938816449
      },
      {
        "accuracy": 0.8244734202607823,
        "f1": 0.7853768375834574,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.7853768375834574,
        "precision": 0.7694337341027411,
        "recall": 0.8244734202607823
      },
      {
        "accuracy": 0.9769307923771314,
        "f1": 0.9692410565028418,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9692410565028418,
        "precision": 0.9653961885656971,
        "recall": 0.9769307923771314
      },
      {
        "accuracy": 0.9819458375125376,
        "f1": 0.9762621196924105,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9762621196924105,
        "precision": 0.973420260782347,
        "recall": 0.9819458375125376
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9886325643597459,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9886325643597459,
        "precision": 0.9874623871614845,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9879638916750251,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9869608826479438,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.2668004012036108,
        "f1": 0.22338164217136222,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.22338164217136222,
        "precision": 0.21441383504981754,
        "recall": 0.2668004012036108
      },
      {
        "accuracy": 0.4192577733199599,
        "f1": 0.3456052564790543,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.3456052564790543,
        "precision": 0.32045930359621433,
        "recall": 0.4192577733199599
      },
      {
        "accuracy": 0.39618856569709127,
        "f1": 0.36175327467955354,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.36175327467955354,
        "precision": 0.3511391805463474,
        "recall": 0.39618856569709127
      },
      {
        "accuracy": 0.45035105315947843,
        "f1": 0.39534498155360737,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.39534498155360737,
        "precision": 0.3751465648111468,
        "recall": 0.45035105315947843
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9899699097291875,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9899699097291875,
        "precision": 0.9889669007021064,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9894684052156469,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9894684052156469,
        "precision": 0.9882982280173855,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.8585757271815446,
        "f1": 0.8288475316058064,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8288475316058064,
        "precision": 0.8176903727054178,
        "recall": 0.8585757271815446
      },
      {
        "accuracy": 0.8946840521564694,
        "f1": 0.8687547490957721,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8687547490957721,
        "precision": 0.8577064526914076,
        "recall": 0.8946840521564694
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9867937144767636,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9867937144767636,
        "precision": 0.9852892009361418,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.9839518555667001,
        "f1": 0.9792711467736542,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9792711467736542,
        "precision": 0.9769307923771314,
        "recall": 0.9839518555667001
      },
      {
        "accuracy": 0.9839518555667001,
        "f1": 0.9791708458709462,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9791708458709462,
        "precision": 0.9770143764627215,
        "recall": 0.9839518555667001
      },
      {
        "accuracy": 0.9859578736208626,
        "f1": 0.9812771648278168,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9812771648278168,
        "precision": 0.9789368104312939,
        "recall": 0.9859578736208626
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9856904045469743,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9856904045469743,
        "precision": 0.9842026078234705,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.48946840521564694,
        "f1": 0.4590656529472979,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.4590656529472979,
        "precision": 0.44882286018743334,
        "recall": 0.48946840521564694
      },
      {
        "accuracy": 0.5887662988966901,
        "f1": 0.5373392182318963,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.5373392182318963,
        "precision": 0.519183906798065,
        "recall": 0.5887662988966901
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444667,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9893012370444667,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222335,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222335,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611167,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9973253092611167,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.020060180541624874,
        "f1": 0.015838082959123777,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.015838082959123777,
        "precision": 0.015610776649582242,
        "recall": 0.020060180541624874
      },
      {
        "accuracy": 0.03009027081243731,
        "f1": 0.01800663510620969,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.01800663510620969,
        "precision": 0.01528344050911754,
        "recall": 0.03009027081243731
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}