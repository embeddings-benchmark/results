{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.63675,
        "f1": 0.628819,
        "f1_weighted": 0.628819,
        "ap": 0.593294,
        "ap_weighted": 0.593294,
        "scores_per_experiment": [
          {
            "accuracy": 0.696667,
            "f1": 0.693176,
            "f1_weighted": 0.693176,
            "ap": 0.6475,
            "ap_weighted": 0.6475
          },
          {
            "accuracy": 0.646667,
            "f1": 0.626322,
            "f1_weighted": 0.626322,
            "ap": 0.588,
            "ap_weighted": 0.588
          },
          {
            "accuracy": 0.663333,
            "f1": 0.649788,
            "f1_weighted": 0.649788,
            "ap": 0.625641,
            "ap_weighted": 0.625641
          },
          {
            "accuracy": 0.694167,
            "f1": 0.692902,
            "f1_weighted": 0.692902,
            "ap": 0.640335,
            "ap_weighted": 0.640335
          },
          {
            "accuracy": 0.6925,
            "f1": 0.691986,
            "f1_weighted": 0.691986,
            "ap": 0.636602,
            "ap_weighted": 0.636602
          },
          {
            "accuracy": 0.611667,
            "f1": 0.578203,
            "f1_weighted": 0.578203,
            "ap": 0.56381,
            "ap_weighted": 0.56381
          },
          {
            "accuracy": 0.533333,
            "f1": 0.533287,
            "f1_weighted": 0.533287,
            "ap": 0.5178,
            "ap_weighted": 0.5178
          },
          {
            "accuracy": 0.493333,
            "f1": 0.492063,
            "f1_weighted": 0.492063,
            "ap": 0.496707,
            "ap_weighted": 0.496707
          },
          {
            "accuracy": 0.674167,
            "f1": 0.669339,
            "f1_weighted": 0.669339,
            "ap": 0.611513,
            "ap_weighted": 0.611513
          },
          {
            "accuracy": 0.661667,
            "f1": 0.661124,
            "f1_weighted": 0.661124,
            "ap": 0.605033,
            "ap_weighted": 0.605033
          }
        ],
        "main_score": 0.63675,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.629667,
        "f1": 0.620142,
        "f1_weighted": 0.620142,
        "ap": 0.587402,
        "ap_weighted": 0.587402,
        "scores_per_experiment": [
          {
            "accuracy": 0.679167,
            "f1": 0.674143,
            "f1_weighted": 0.674143,
            "ap": 0.632289,
            "ap_weighted": 0.632289
          },
          {
            "accuracy": 0.651667,
            "f1": 0.631912,
            "f1_weighted": 0.631912,
            "ap": 0.591553,
            "ap_weighted": 0.591553
          },
          {
            "accuracy": 0.65,
            "f1": 0.634384,
            "f1_weighted": 0.634384,
            "ap": 0.613352,
            "ap_weighted": 0.613352
          },
          {
            "accuracy": 0.675,
            "f1": 0.672144,
            "f1_weighted": 0.672144,
            "ap": 0.625154,
            "ap_weighted": 0.625154
          },
          {
            "accuracy": 0.686667,
            "f1": 0.685881,
            "f1_weighted": 0.685881,
            "ap": 0.632049,
            "ap_weighted": 0.632049
          },
          {
            "accuracy": 0.591667,
            "f1": 0.548254,
            "f1_weighted": 0.548254,
            "ap": 0.55102,
            "ap_weighted": 0.55102
          },
          {
            "accuracy": 0.544167,
            "f1": 0.544159,
            "f1_weighted": 0.544159,
            "ap": 0.52405,
            "ap_weighted": 0.52405
          },
          {
            "accuracy": 0.495,
            "f1": 0.49432,
            "f1_weighted": 0.49432,
            "ap": 0.497523,
            "ap_weighted": 0.497523
          },
          {
            "accuracy": 0.65,
            "f1": 0.643503,
            "f1_weighted": 0.643503,
            "ap": 0.592717,
            "ap_weighted": 0.592717
          },
          {
            "accuracy": 0.673333,
            "f1": 0.672719,
            "f1_weighted": 0.672719,
            "ap": 0.614315,
            "ap_weighted": 0.614315
          }
        ],
        "main_score": 0.629667,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 429.26287722587585,
  "kg_co2_emissions": 0.04075720698916443
}