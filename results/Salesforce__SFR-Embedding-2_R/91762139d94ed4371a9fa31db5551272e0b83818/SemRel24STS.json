{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 102.85572648048401,
  "kg_co2_emissions": 0.006825017916221639,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8246143613629303,
        "cosine_spearman": 0.8233848389834633,
        "euclidean_pearson": 0.8029423373165159,
        "euclidean_spearman": 0.8233848389834633,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.8233848389834633,
        "manhattan_pearson": 0.800377046736647,
        "manhattan_spearman": 0.8229595001335201,
        "pearson": 0.8246143613629303,
        "spearman": 0.8233848389834633
      },
      {
        "cosine_pearson": 0.7776033165090402,
        "cosine_spearman": 0.781424391059937,
        "euclidean_pearson": 0.7535536284756197,
        "euclidean_spearman": 0.781424391059937,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.781424391059937,
        "manhattan_pearson": 0.7536171209873386,
        "manhattan_spearman": 0.7810798863137212,
        "pearson": 0.7776033165090402,
        "spearman": 0.781424391059937
      },
      {
        "cosine_pearson": 0.6046296947641923,
        "cosine_spearman": 0.6047269652419568,
        "euclidean_pearson": 0.5938253108294547,
        "euclidean_spearman": 0.604723038727832,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.6047269652419568,
        "manhattan_pearson": 0.5845477606024778,
        "manhattan_spearman": 0.5941767884834103,
        "pearson": 0.6046296947641923,
        "spearman": 0.6047269652419568
      },
      {
        "cosine_pearson": 0.5398833169699356,
        "cosine_spearman": 0.4755060674515785,
        "euclidean_pearson": 0.5387093997933832,
        "euclidean_spearman": 0.4755060674515785,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.4755060674515785,
        "manhattan_pearson": 0.5383020270973777,
        "manhattan_spearman": 0.4767441641735377,
        "pearson": 0.5398833169699356,
        "spearman": 0.4755060674515785
      },
      {
        "cosine_pearson": 0.5545094225651088,
        "cosine_spearman": 0.5371270031065573,
        "euclidean_pearson": 0.5452060387590673,
        "euclidean_spearman": 0.5371270031065573,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.5371270031065573,
        "manhattan_pearson": 0.5440199678976534,
        "manhattan_spearman": 0.5358180947651452,
        "pearson": 0.5545094225651088,
        "spearman": 0.5371270031065573
      },
      {
        "cosine_pearson": 0.8404655562807426,
        "cosine_spearman": 0.8250373226758319,
        "euclidean_pearson": 0.8341274251504892,
        "euclidean_spearman": 0.8250373226758319,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8250373226758319,
        "manhattan_pearson": 0.8325039536898494,
        "manhattan_spearman": 0.8228025649314377,
        "pearson": 0.8404655562807426,
        "spearman": 0.8250373226758319
      },
      {
        "cosine_pearson": 0.5685887589489534,
        "cosine_spearman": 0.5513343650028013,
        "euclidean_pearson": 0.5576910192048089,
        "euclidean_spearman": 0.5513343650028013,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.5513343650028013,
        "manhattan_pearson": 0.5570273441584976,
        "manhattan_spearman": 0.5511007237194079,
        "pearson": 0.5685887589489534,
        "spearman": 0.5513343650028013
      },
      {
        "cosine_pearson": 0.764172300350115,
        "cosine_spearman": 0.776890476742145,
        "euclidean_pearson": 0.7385599169969365,
        "euclidean_spearman": 0.776890476742145,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.776890476742145,
        "manhattan_pearson": 0.7353356221166747,
        "manhattan_spearman": 0.774745117851172,
        "pearson": 0.764172300350115,
        "spearman": 0.776890476742145
      },
      {
        "cosine_pearson": 0.5421335319632608,
        "cosine_spearman": 0.5393249879480393,
        "euclidean_pearson": 0.5472265311929625,
        "euclidean_spearman": 0.5393249879480393,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.5393249879480393,
        "manhattan_pearson": 0.5453689818110699,
        "manhattan_spearman": 0.5356638451954118,
        "pearson": 0.5421335319632608,
        "spearman": 0.5393249879480393
      },
      {
        "cosine_pearson": 0.5524379642518712,
        "cosine_spearman": 0.5279616022556771,
        "euclidean_pearson": 0.5551192996710129,
        "euclidean_spearman": 0.5279616022556771,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.5279616022556771,
        "manhattan_pearson": 0.5570597329839929,
        "manhattan_spearman": 0.5292106699632682,
        "pearson": 0.5524379642518712,
        "spearman": 0.5279616022556771
      },
      {
        "cosine_pearson": 0.8063490013630564,
        "cosine_spearman": 0.784340268616547,
        "euclidean_pearson": 0.7956065270731529,
        "euclidean_spearman": 0.784340268616547,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.784340268616547,
        "manhattan_pearson": 0.7929966804433731,
        "manhattan_spearman": 0.7824380071227132,
        "pearson": 0.8063490013630564,
        "spearman": 0.784340268616547
      },
      {
        "cosine_pearson": 0.8083876894398365,
        "cosine_spearman": 0.7778277258270118,
        "euclidean_pearson": 0.7874332563250515,
        "euclidean_spearman": 0.7778277258270118,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7778277258270118,
        "manhattan_pearson": 0.7873955707505818,
        "manhattan_spearman": 0.7779172963297423,
        "pearson": 0.8083876894398365,
        "spearman": 0.7778277258270118
      }
    ]
  },
  "task_name": "SemRel24STS"
}