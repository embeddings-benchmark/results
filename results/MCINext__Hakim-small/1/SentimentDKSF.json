{
  "dataset_revision": "b4d5a8dd501db610b5ad89e9aa13f863b842b395",
  "task_name": "SentimentDKSF",
  "mteb_version": "1.38.27",
  "scores": {
    "test": [
      {
        "accuracy": 0.795248,
        "f1": 0.71129,
        "f1_weighted": 0.81219,
        "scores_per_experiment": [
          {
            "accuracy": 0.807775,
            "f1": 0.715174,
            "f1_weighted": 0.818196
          },
          {
            "accuracy": 0.807775,
            "f1": 0.723645,
            "f1_weighted": 0.819686
          },
          {
            "accuracy": 0.779698,
            "f1": 0.700856,
            "f1_weighted": 0.803689
          },
          {
            "accuracy": 0.799568,
            "f1": 0.715383,
            "f1_weighted": 0.815753
          },
          {
            "accuracy": 0.794384,
            "f1": 0.708421,
            "f1_weighted": 0.811132
          },
          {
            "accuracy": 0.8,
            "f1": 0.7152,
            "f1_weighted": 0.814624
          },
          {
            "accuracy": 0.774946,
            "f1": 0.693423,
            "f1_weighted": 0.798608
          },
          {
            "accuracy": 0.8,
            "f1": 0.71533,
            "f1_weighted": 0.815071
          },
          {
            "accuracy": 0.803888,
            "f1": 0.72316,
            "f1_weighted": 0.818831
          },
          {
            "accuracy": 0.784449,
            "f1": 0.702304,
            "f1_weighted": 0.806305
          }
        ],
        "main_score": 0.795248,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 27.034316539764404,
  "kg_co2_emissions": null
}