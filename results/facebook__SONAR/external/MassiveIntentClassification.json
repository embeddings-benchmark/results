{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.5814727639542704,
                "f1": 0.5558745169431752,
                "main_score": 0.5814727639542704
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.5791190316072629,
                "f1": 0.5546589962622107,
                "main_score": 0.5791190316072629
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.5722932078009414,
                "f1": 0.5366121804156133,
                "main_score": 0.5722932078009414
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.5716543375924681,
                "f1": 0.5516504653263189,
                "main_score": 0.5716543375924681
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.6223940820443847,
                "f1": 0.5894199170718387,
                "main_score": 0.6223940820443847
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.5118695359784801,
                "f1": 0.4959432722397084,
                "main_score": 0.5118695359784801
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.6203093476798924,
                "f1": 0.5883630205083097,
                "main_score": 0.6203093476798924
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.613147276395427,
                "f1": 0.5780700293522655,
                "main_score": 0.613147276395427
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.6420645595158037,
                "f1": 0.6136755812840151,
                "main_score": 0.6420645595158037
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6436785474108944,
                "f1": 0.6115645935863754,
                "main_score": 0.6436785474108944
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.6397108271687962,
                "f1": 0.6207352472659557,
                "main_score": 0.6397108271687962
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.6667114996637525,
                "f1": 0.6342017044712632,
                "main_score": 0.6667114996637525
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.6286482851378614,
                "f1": 0.5965586048886192,
                "main_score": 0.6286482851378614
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.5855077336919974,
                "f1": 0.5528215385204243,
                "main_score": 0.5855077336919974
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.63453261600538,
                "f1": 0.5999199882003918,
                "main_score": 0.63453261600538
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.6132145258910559,
                "f1": 0.589676667104426,
                "main_score": 0.6132145258910559
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.6290517821116343,
                "f1": 0.5964512648079168,
                "main_score": 0.6290517821116343
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.6003026227303295,
                "f1": 0.5668905593909442,
                "main_score": 0.6003026227303295
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.6328850033624749,
                "f1": 0.6021862015326402,
                "main_score": 0.6328850033624749
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.560221923335575,
                "f1": 0.5338847345159832,
                "main_score": 0.560221923335575
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.6444182918628111,
                "f1": 0.6214806714489123,
                "main_score": 0.6444182918628111
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.6369535978480162,
                "f1": 0.6240231098840202,
                "main_score": 0.6369535978480162
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.5200067249495628,
                "f1": 0.48871263427511985,
                "main_score": 0.5200067249495628
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.5408876933422999,
                "f1": 0.5268998451556,
                "main_score": 0.5408876933422999
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.43342299932750505,
                "f1": 0.40578510490463027,
                "main_score": 0.43342299932750505
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.5787491593813046,
                "f1": 0.5519579071673386,
                "main_score": 0.5787491593813046
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.6269334229993275,
                "f1": 0.6090210922623679,
                "main_score": 0.6269334229993275
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.5624075319435103,
                "f1": 0.5413751976115748,
                "main_score": 0.5624075319435103
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.6281439139206457,
                "f1": 0.6046554841337619,
                "main_score": 0.6281439139206457
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.5849361129791527,
                "f1": 0.5512919894175168,
                "main_score": 0.5849361129791527
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.6155682582380633,
                "f1": 0.5881763499302702,
                "main_score": 0.6155682582380633
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.593981170141224,
                "f1": 0.5631810441546048,
                "main_score": 0.593981170141224
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.5989576328177538,
                "f1": 0.5735130066022407,
                "main_score": 0.5989576328177538
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.6455951580363148,
                "f1": 0.6150868742463586,
                "main_score": 0.6455951580363148
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.6586079354404842,
                "f1": 0.6194702597578807,
                "main_score": 0.6586079354404842
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.6349024882313383,
                "f1": 0.6079641285153345,
                "main_score": 0.6349024882313383
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.6253194351042366,
                "f1": 0.599167382336848,
                "main_score": 0.6253194351042366
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.6262945527908541,
                "f1": 0.591954442306651,
                "main_score": 0.6262945527908541
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.6343308675184935,
                "f1": 0.6060574990131614,
                "main_score": 0.6343308675184935
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.6144586415601883,
                "f1": 0.586350665617294,
                "main_score": 0.6144586415601883
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.6286482851378615,
                "f1": 0.5975440194153033,
                "main_score": 0.6286482851378615
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.5625084061869536,
                "f1": 0.5484944007944625,
                "main_score": 0.5625084061869536
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.5974781439139207,
                "f1": 0.5683761137925043,
                "main_score": 0.5974781439139207
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.5960995292535306,
                "f1": 0.5710677645743071,
                "main_score": 0.5960995292535306
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.5942165433759247,
                "f1": 0.5781013790437749,
                "main_score": 0.5942165433759247
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.5812037659717552,
                "f1": 0.5527690756097837,
                "main_score": 0.5812037659717552
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.6090786819098857,
                "f1": 0.5743015543162361,
                "main_score": 0.6090786819098857
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.5949226630800271,
                "f1": 0.5688559056315645,
                "main_score": 0.5949226630800271
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.6047747141896436,
                "f1": 0.5787047944039945,
                "main_score": 0.6047747141896436
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.6207800941492938,
                "f1": 0.5934023290841026,
                "main_score": 0.6207800941492938
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.5673167451244117,
                "f1": 0.5529236319279749,
                "main_score": 0.5673167451244117
            }
        ]
    }
}