{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "evaluation_time": 79.32956218719482,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.89",
  "scores": {
    "test": [
      {
        "accuracy": 0.8627450980392156,
        "f1": 0.8500174048061325,
        "f1_weighted": 0.8609229218702279,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.8627450980392156,
        "scores_per_experiment": [
          {
            "accuracy": 0.8774509803921569,
            "f1": 0.8676024426263967,
            "f1_weighted": 0.8777251755730723
          },
          {
            "accuracy": 0.8431372549019608,
            "f1": 0.8265363406663836,
            "f1_weighted": 0.8398843993905333
          },
          {
            "accuracy": 0.8088235294117647,
            "f1": 0.800161609429657,
            "f1_weighted": 0.8069053832110433
          },
          {
            "accuracy": 0.8627450980392157,
            "f1": 0.8547560746478707,
            "f1_weighted": 0.8617055387840641
          },
          {
            "accuracy": 0.8774509803921569,
            "f1": 0.8654920168015406,
            "f1_weighted": 0.8771041579456611
          },
          {
            "accuracy": 0.8823529411764706,
            "f1": 0.8706854409280285,
            "f1_weighted": 0.8815750803125941
          },
          {
            "accuracy": 0.8774509803921569,
            "f1": 0.8624046415829743,
            "f1_weighted": 0.8740076796315313
          },
          {
            "accuracy": 0.8823529411764706,
            "f1": 0.8728392323325757,
            "f1_weighted": 0.8830889662259391
          },
          {
            "accuracy": 0.8480392156862745,
            "f1": 0.8249470454437808,
            "f1_weighted": 0.8404708515315163
          },
          {
            "accuracy": 0.8676470588235294,
            "f1": 0.8547492036021165,
            "f1_weighted": 0.8667619860963245
          }
        ]
      }
    ],
    "train": [
      {
        "accuracy": 0.8346647646219685,
        "f1": 0.8256381188249377,
        "f1_weighted": 0.8326254835254392,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.8346647646219685,
        "scores_per_experiment": [
          {
            "accuracy": 0.8373751783166904,
            "f1": 0.8251923096881463,
            "f1_weighted": 0.8366922777251189
          },
          {
            "accuracy": 0.8231098430813124,
            "f1": 0.8113104561757254,
            "f1_weighted": 0.8196060918777166
          },
          {
            "accuracy": 0.8002853067047075,
            "f1": 0.79728336104084,
            "f1_weighted": 0.7962854785525106
          },
          {
            "accuracy": 0.8487874465049928,
            "f1": 0.8343554818779636,
            "f1_weighted": 0.8452428201435928
          },
          {
            "accuracy": 0.8316690442225392,
            "f1": 0.8264033283761447,
            "f1_weighted": 0.8312307906995818
          },
          {
            "accuracy": 0.8473609129814551,
            "f1": 0.8389965098620226,
            "f1_weighted": 0.8461097095692309
          },
          {
            "accuracy": 0.8316690442225392,
            "f1": 0.8228963967767006,
            "f1_weighted": 0.8291484672009857
          },
          {
            "accuracy": 0.8359486447931527,
            "f1": 0.8282769174895731,
            "f1_weighted": 0.835667223748598
          },
          {
            "accuracy": 0.8302425106990015,
            "f1": 0.819553773542112,
            "f1_weighted": 0.8274595688378567
          },
          {
            "accuracy": 0.8601997146932953,
            "f1": 0.852112653420148,
            "f1_weighted": 0.8588124068991999
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8242424242424244,
        "f1": 0.8181070027175215,
        "f1_weighted": 0.8206526223717082,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.8242424242424244,
        "scores_per_experiment": [
          {
            "accuracy": 0.8181818181818182,
            "f1": 0.813449714536671,
            "f1_weighted": 0.8190565070999853
          },
          {
            "accuracy": 0.8484848484848485,
            "f1": 0.8457241979983844,
            "f1_weighted": 0.8449009913855615
          },
          {
            "accuracy": 0.7373737373737373,
            "f1": 0.7470028906499747,
            "f1_weighted": 0.73145835849778
          },
          {
            "accuracy": 0.8585858585858586,
            "f1": 0.8560287015961713,
            "f1_weighted": 0.8570347818592174
          },
          {
            "accuracy": 0.8181818181818182,
            "f1": 0.8106128922518384,
            "f1_weighted": 0.8121020675396409
          },
          {
            "accuracy": 0.8686868686868687,
            "f1": 0.8660730843330199,
            "f1_weighted": 0.8676794105365534
          },
          {
            "accuracy": 0.8181818181818182,
            "f1": 0.7900070263009925,
            "f1_weighted": 0.8004253792399109
          },
          {
            "accuracy": 0.8181818181818182,
            "f1": 0.8079580689426142,
            "f1_weighted": 0.8203202973081193
          },
          {
            "accuracy": 0.7878787878787878,
            "f1": 0.7794238135603058,
            "f1_weighted": 0.7846155364361044
          },
          {
            "accuracy": 0.8686868686868687,
            "f1": 0.8647896370052427,
            "f1_weighted": 0.8689328938142108
          }
        ]
      }
    ]
  },
  "task_name": "SIB200Classification"
}