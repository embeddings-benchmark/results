{
  "dataset_revision": "05027cfce1d20ab7c9f4755b064ea6958cdee96e",
  "task_name": "PerShopIntentClassification",
  "mteb_version": "1.38.38",
  "scores": {
    "test": [
      {
        "accuracy": 0.872417,
        "f1": 0.639473,
        "f1_weighted": 0.885621,
        "scores_per_experiment": [
          {
            "accuracy": 0.872758,
            "f1": 0.635093,
            "f1_weighted": 0.888351
          },
          {
            "accuracy": 0.874466,
            "f1": 0.637567,
            "f1_weighted": 0.886274
          },
          {
            "accuracy": 0.876174,
            "f1": 0.642365,
            "f1_weighted": 0.885693
          },
          {
            "accuracy": 0.871904,
            "f1": 0.639283,
            "f1_weighted": 0.889332
          },
          {
            "accuracy": 0.876174,
            "f1": 0.645093,
            "f1_weighted": 0.89079
          },
          {
            "accuracy": 0.851409,
            "f1": 0.61982,
            "f1_weighted": 0.86756
          },
          {
            "accuracy": 0.880444,
            "f1": 0.650824,
            "f1_weighted": 0.890753
          },
          {
            "accuracy": 0.846285,
            "f1": 0.618028,
            "f1_weighted": 0.86234
          },
          {
            "accuracy": 0.89667,
            "f1": 0.669737,
            "f1_weighted": 0.90471
          },
          {
            "accuracy": 0.877882,
            "f1": 0.636924,
            "f1_weighted": 0.890406
          }
        ],
        "main_score": 0.872417,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 61.6973991394043,
  "kg_co2_emissions": null
}