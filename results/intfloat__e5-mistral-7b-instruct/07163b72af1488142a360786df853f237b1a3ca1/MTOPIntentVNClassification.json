{
  "dataset_revision": "c4e81a5c9a813a0142d905e261e5a446cc6fbc4a",
  "task_name": "MTOPIntentVNClassification",
  "mteb_version": "1.38.42",
  "scores": {
    "test": [
      {
        "accuracy": 0.435422,
        "f1": 0.262558,
        "f1_weighted": 0.454063,
        "scores_per_experiment": [
          {
            "accuracy": 0.433225,
            "f1": 0.245972,
            "f1_weighted": 0.455676
          },
          {
            "accuracy": 0.45828,
            "f1": 0.270083,
            "f1_weighted": 0.474864
          },
          {
            "accuracy": 0.427884,
            "f1": 0.256621,
            "f1_weighted": 0.451811
          },
          {
            "accuracy": 0.45512,
            "f1": 0.265858,
            "f1_weighted": 0.488924
          },
          {
            "accuracy": 0.411557,
            "f1": 0.262039,
            "f1_weighted": 0.42104
          },
          {
            "accuracy": 0.447446,
            "f1": 0.262354,
            "f1_weighted": 0.472823
          },
          {
            "accuracy": 0.415544,
            "f1": 0.258951,
            "f1_weighted": 0.421322
          },
          {
            "accuracy": 0.430517,
            "f1": 0.279852,
            "f1_weighted": 0.445281
          },
          {
            "accuracy": 0.453314,
            "f1": 0.270068,
            "f1_weighted": 0.47266
          },
          {
            "accuracy": 0.421338,
            "f1": 0.253783,
            "f1_weighted": 0.436229
          }
        ],
        "main_score": 0.435422,
        "hf_subset": "default",
        "languages": [
          "vie-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 71.91790103912354,
  "kg_co2_emissions": null
}