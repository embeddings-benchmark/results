{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.6647948890383322,
                "f1": 0.6333487756313548,
                "main_score": 0.6647948890383322
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.442871553463349,
                "f1": 0.43176580506054274,
                "main_score": 0.442871553463349
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.6317417619367856,
                "f1": 0.5923665958704243,
                "main_score": 0.6317417619367856
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.64226630800269,
                "f1": 0.6095184269695618,
                "main_score": 0.64226630800269
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.6494283792871555,
                "f1": 0.6140057652844215,
                "main_score": 0.6494283792871555
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.554808338937458,
                "f1": 0.525298332072816,
                "main_score": 0.554808338937458
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.7252858103564224,
                "f1": 0.693770851919204,
                "main_score": 0.7252858103564224
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.7409213180901143,
                "f1": 0.7113518469365878,
                "main_score": 0.7409213180901143
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.6831203765971756,
                "f1": 0.6605906970865143,
                "main_score": 0.6831203765971756
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.8057162071284465,
                "f1": 0.7778661725988231,
                "main_score": 0.8057162071284465
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.750941492938803,
                "f1": 0.725712594833695,
                "main_score": 0.750941492938803
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.7220914593140553,
                "f1": 0.6890619124909186,
                "main_score": 0.7220914593140553
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.6874243443174176,
                "f1": 0.6472743141749955,
                "main_score": 0.6874243443174176
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.7511096166778749,
                "f1": 0.7261849933064695,
                "main_score": 0.7511096166778749
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.6622394082044384,
                "f1": 0.6243648797607235,
                "main_score": 0.6622394082044384
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.6944855413584399,
                "f1": 0.6656851670913659,
                "main_score": 0.6944855413584399
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.694149293880296,
                "f1": 0.6612960877904775,
                "main_score": 0.694149293880296
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.569166106254203,
                "f1": 0.5402534600927991,
                "main_score": 0.569166106254203
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.7271351714862138,
                "f1": 0.6970227985126316,
                "main_score": 0.7271351714862138
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.5991257565568258,
                "f1": 0.5706811572144974,
                "main_score": 0.5991257565568258
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.7525218560860794,
                "f1": 0.7248057563104247,
                "main_score": 0.7525218560860794
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.7635507733691997,
                "f1": 0.7303024649541128,
                "main_score": 0.7635507733691997
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.5791862811028918,
                "f1": 0.5475590124456177,
                "main_score": 0.5791862811028918
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.5254875588433087,
                "f1": 0.515356975360209,
                "main_score": 0.5254875588433087
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.46449226630800267,
                "f1": 0.44561114416830977,
                "main_score": 0.46449226630800267
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.5395763281775386,
                "f1": 0.5068367245122476,
                "main_score": 0.5395763281775386
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.7420645595158035,
                "f1": 0.7178450093258185,
                "main_score": 0.7420645595158035
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.59226630800269,
                "f1": 0.5753988988993337,
                "main_score": 0.59226630800269
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.5144922663080027,
                "f1": 0.4858809018065056,
                "main_score": 0.5144922663080027
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.513752521856086,
                "f1": 0.4991373941436425,
                "main_score": 0.513752521856086
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.6985205110961669,
                "f1": 0.6705660019588582,
                "main_score": 0.6985205110961669
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.491492938802959,
                "f1": 0.46717578025393197,
                "main_score": 0.491492938802959
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.7093140551445865,
                "f1": 0.6745406609372204,
                "main_score": 0.7093140551445865
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.7482851378614661,
                "f1": 0.7115951964393868,
                "main_score": 0.7482851378614661
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.7484868863483524,
                "f1": 0.7176056802364877,
                "main_score": 0.7484868863483524
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.7527236045729657,
                "f1": 0.7248733090101163,
                "main_score": 0.7527236045729657
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.6963012777404168,
                "f1": 0.6656444015346203,
                "main_score": 0.6963012777404168
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.7662743779421655,
                "f1": 0.7382720656992141,
                "main_score": 0.7662743779421655
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.6715198386012105,
                "f1": 0.6441418309797744,
                "main_score": 0.6715198386012105
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.588399462004035,
                "f1": 0.5605098951969388,
                "main_score": 0.588399462004035
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.7386684599865501,
                "f1": 0.7080682480844303,
                "main_score": 0.7386684599865501
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.5736718224613316,
                "f1": 0.5499874647101377,
                "main_score": 0.5736718224613316
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.5315063887020848,
                "f1": 0.4979179342620099,
                "main_score": 0.5315063887020848
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.5150638870208473,
                "f1": 0.49778960742003553,
                "main_score": 0.5150638870208473
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.66906523201076,
                "f1": 0.6675784022138245,
                "main_score": 0.66906523201076
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.6873234700739743,
                "f1": 0.6575016141148413,
                "main_score": 0.6873234700739743
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.7206792199058508,
                "f1": 0.6790334782594083,
                "main_score": 0.7206792199058508
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.6209145931405515,
                "f1": 0.5888703095210731,
                "main_score": 0.6209145931405515
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.7117014122394083,
                "f1": 0.6843676277921544,
                "main_score": 0.7117014122394083
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.7499327505043712,
                "f1": 0.7226813373392943,
                "main_score": 0.7499327505043712
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.7113987895090788,
                "f1": 0.7029309514467574,
                "main_score": 0.7113987895090788
            }
        ]
    }
}