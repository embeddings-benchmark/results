{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.891797,
        "f1": 0.891682,
        "f1_weighted": 0.891677,
        "ap": 0.855771,
        "ap_weighted": 0.855771,
        "scores_per_experiment": [
          {
            "accuracy": 0.880859,
            "f1": 0.880846,
            "f1_weighted": 0.880842,
            "ap": 0.84019,
            "ap_weighted": 0.84019
          },
          {
            "accuracy": 0.843262,
            "f1": 0.843084,
            "f1_weighted": 0.843068,
            "ap": 0.799593,
            "ap_weighted": 0.799593
          },
          {
            "accuracy": 0.904785,
            "f1": 0.904701,
            "f1_weighted": 0.904692,
            "ap": 0.878246,
            "ap_weighted": 0.878246
          },
          {
            "accuracy": 0.877441,
            "f1": 0.876772,
            "f1_weighted": 0.876745,
            "ap": 0.857681,
            "ap_weighted": 0.857681
          },
          {
            "accuracy": 0.905762,
            "f1": 0.905737,
            "f1_weighted": 0.905733,
            "ap": 0.874558,
            "ap_weighted": 0.874558
          },
          {
            "accuracy": 0.902344,
            "f1": 0.90232,
            "f1_weighted": 0.902315,
            "ap": 0.869823,
            "ap_weighted": 0.869823
          },
          {
            "accuracy": 0.894531,
            "f1": 0.894452,
            "f1_weighted": 0.894461,
            "ap": 0.846199,
            "ap_weighted": 0.846199
          },
          {
            "accuracy": 0.913086,
            "f1": 0.913082,
            "f1_weighted": 0.913084,
            "ap": 0.87632,
            "ap_weighted": 0.87632
          },
          {
            "accuracy": 0.900879,
            "f1": 0.900862,
            "f1_weighted": 0.900858,
            "ap": 0.867032,
            "ap_weighted": 0.867032
          },
          {
            "accuracy": 0.89502,
            "f1": 0.894964,
            "f1_weighted": 0.894971,
            "ap": 0.84807,
            "ap_weighted": 0.84807
          }
        ],
        "main_score": 0.891797,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.890088,
        "f1": 0.889925,
        "f1_weighted": 0.88992,
        "ap": 0.854715,
        "ap_weighted": 0.854715,
        "scores_per_experiment": [
          {
            "accuracy": 0.887695,
            "f1": 0.887694,
            "f1_weighted": 0.887694,
            "ap": 0.84603,
            "ap_weighted": 0.84603
          },
          {
            "accuracy": 0.848633,
            "f1": 0.848195,
            "f1_weighted": 0.848179,
            "ap": 0.811635,
            "ap_weighted": 0.811635
          },
          {
            "accuracy": 0.904785,
            "f1": 0.904671,
            "f1_weighted": 0.904664,
            "ap": 0.879549,
            "ap_weighted": 0.879549
          },
          {
            "accuracy": 0.873535,
            "f1": 0.872668,
            "f1_weighted": 0.872648,
            "ap": 0.855145,
            "ap_weighted": 0.855145
          },
          {
            "accuracy": 0.894531,
            "f1": 0.894473,
            "f1_weighted": 0.894468,
            "ap": 0.861632,
            "ap_weighted": 0.861632
          },
          {
            "accuracy": 0.896484,
            "f1": 0.896449,
            "f1_weighted": 0.896445,
            "ap": 0.86254,
            "ap_weighted": 0.86254
          },
          {
            "accuracy": 0.89502,
            "f1": 0.894954,
            "f1_weighted": 0.894959,
            "ap": 0.847052,
            "ap_weighted": 0.847052
          },
          {
            "accuracy": 0.913574,
            "f1": 0.913574,
            "f1_weighted": 0.913574,
            "ap": 0.878979,
            "ap_weighted": 0.878979
          },
          {
            "accuracy": 0.899414,
            "f1": 0.899392,
            "f1_weighted": 0.89939,
            "ap": 0.865081,
            "ap_weighted": 0.865081
          },
          {
            "accuracy": 0.887207,
            "f1": 0.887174,
            "f1_weighted": 0.887178,
            "ap": 0.839506,
            "ap_weighted": 0.839506
          }
        ],
        "main_score": 0.890088,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.316534519195557,
  "kg_co2_emissions": 0.00047594634289513176
}