{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.700282,
        "recall": 0.760281,
        "f1": 0.716478,
        "accuracy": 0.760281,
        "main_score": 0.716478,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.654281,
        "recall": 0.74323,
        "f1": 0.680396,
        "accuracy": 0.74323,
        "main_score": 0.680396,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.945838,
        "recall": 0.961886,
        "f1": 0.950819,
        "accuracy": 0.961886,
        "main_score": 0.950819,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.880558,
        "recall": 0.917753,
        "f1": 0.892411,
        "accuracy": 0.917753,
        "main_score": 0.892411,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.993982,
        "recall": 0.995988,
        "f1": 0.994651,
        "accuracy": 0.995988,
        "main_score": 0.994651,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.990973,
        "recall": 0.993982,
        "f1": 0.991976,
        "accuracy": 0.993982,
        "main_score": 0.991976,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.310268,
        "recall": 0.331996,
        "f1": 0.314685,
        "accuracy": 0.331996,
        "main_score": 0.314685,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.183726,
        "recall": 0.316951,
        "f1": 0.212113,
        "accuracy": 0.316951,
        "main_score": 0.212113,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.363452,
        "recall": 0.389168,
        "f1": 0.36846,
        "accuracy": 0.389168,
        "main_score": 0.36846,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.222842,
        "recall": 0.362086,
        "f1": 0.254462,
        "accuracy": 0.362086,
        "main_score": 0.254462,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.96991,
        "recall": 0.97994,
        "f1": 0.973253,
        "accuracy": 0.97994,
        "main_score": 0.973253,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.947175,
        "recall": 0.963892,
        "f1": 0.952524,
        "accuracy": 0.963892,
        "main_score": 0.952524,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.41055,
        "recall": 0.441324,
        "f1": 0.417457,
        "accuracy": 0.441324,
        "main_score": 0.417457,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.271543,
        "recall": 0.411234,
        "f1": 0.304915,
        "accuracy": 0.411234,
        "main_score": 0.304915,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.433747,
        "recall": 0.466399,
        "f1": 0.440969,
        "accuracy": 0.466399,
        "main_score": 0.440969,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.281909,
        "recall": 0.420261,
        "f1": 0.315216,
        "accuracy": 0.420261,
        "main_score": 0.315216,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.981946,
        "recall": 0.987964,
        "f1": 0.983952,
        "accuracy": 0.987964,
        "main_score": 0.983952,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.966901,
        "recall": 0.977934,
        "f1": 0.970578,
        "accuracy": 0.977934,
        "main_score": 0.970578,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.300561,
        "recall": 0.365095,
        "f1": 0.315501,
        "accuracy": 0.365095,
        "main_score": 0.315501,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.324117,
        "recall": 0.436309,
        "f1": 0.352271,
        "accuracy": 0.436309,
        "main_score": 0.352271,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.8668,
        "recall": 0.90672,
        "f1": 0.879438,
        "accuracy": 0.90672,
        "main_score": 0.879438,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.821999,
        "recall": 0.871615,
        "f1": 0.837398,
        "accuracy": 0.871615,
        "main_score": 0.837398,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.921741,
        "recall": 0.944835,
        "f1": 0.929037,
        "accuracy": 0.944835,
        "main_score": 0.929037,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881344,
        "recall": 0.917753,
        "f1": 0.893012,
        "accuracy": 0.917753,
        "main_score": 0.893012,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.460535,
        "recall": 0.507523,
        "f1": 0.471206,
        "accuracy": 0.507523,
        "main_score": 0.471206,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.348643,
        "recall": 0.482447,
        "f1": 0.382037,
        "accuracy": 0.482447,
        "main_score": 0.382037,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.583735,
        "recall": 0.640923,
        "f1": 0.598511,
        "accuracy": 0.640923,
        "main_score": 0.598511,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.496725,
        "recall": 0.612839,
        "f1": 0.528475,
        "accuracy": 0.612839,
        "main_score": 0.528475,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.660191,
        "recall": 0.737212,
        "f1": 0.682132,
        "accuracy": 0.737212,
        "main_score": 0.682132,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.609099,
        "recall": 0.704112,
        "f1": 0.635884,
        "accuracy": 0.704112,
        "main_score": 0.635884,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.687253,
        "recall": 0.758275,
        "f1": 0.707704,
        "accuracy": 0.758275,
        "main_score": 0.707704,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.640473,
        "recall": 0.730191,
        "f1": 0.666673,
        "accuracy": 0.730191,
        "main_score": 0.666673,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.975426,
        "recall": 0.982949,
        "f1": 0.977934,
        "accuracy": 0.982949,
        "main_score": 0.977934,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.967402,
        "recall": 0.976931,
        "f1": 0.970578,
        "accuracy": 0.976931,
        "main_score": 0.970578,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.939101,
        "recall": 0.957874,
        "f1": 0.945069,
        "accuracy": 0.957874,
        "main_score": 0.945069,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.910398,
        "recall": 0.938816,
        "f1": 0.919592,
        "accuracy": 0.938816,
        "main_score": 0.919592,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.019645,
        "recall": 0.027081,
        "f1": 0.02076,
        "accuracy": 0.027081,
        "main_score": 0.02076,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009462,
        "recall": 0.056169,
        "f1": 0.015004,
        "accuracy": 0.056169,
        "main_score": 0.015004,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.028593,
        "recall": 0.049147,
        "f1": 0.031285,
        "accuracy": 0.049147,
        "main_score": 0.031285,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.066258,
        "recall": 0.12337,
        "f1": 0.077059,
        "accuracy": 0.12337,
        "main_score": 0.077059,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.92444,
        "recall": 0.947844,
        "f1": 0.93213,
        "accuracy": 0.947844,
        "main_score": 0.93213,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.874407,
        "recall": 0.912738,
        "f1": 0.88656,
        "accuracy": 0.912738,
        "main_score": 0.88656,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.622056,
        "recall": 0.696088,
        "f1": 0.641834,
        "accuracy": 0.696088,
        "main_score": 0.641834,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.598283,
        "recall": 0.691073,
        "f1": 0.625059,
        "accuracy": 0.691073,
        "main_score": 0.625059,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.878719,
        "recall": 0.914744,
        "f1": 0.89019,
        "accuracy": 0.914744,
        "main_score": 0.89019,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.850802,
        "recall": 0.89669,
        "f1": 0.865296,
        "accuracy": 0.89669,
        "main_score": 0.865296,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.887362,
        "recall": 0.919759,
        "f1": 0.897325,
        "accuracy": 0.919759,
        "main_score": 0.897325,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.813082,
        "recall": 0.867603,
        "f1": 0.83004,
        "accuracy": 0.867603,
        "main_score": 0.83004,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.921765,
        "recall": 0.945838,
        "f1": 0.929455,
        "accuracy": 0.945838,
        "main_score": 0.929455,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.887579,
        "recall": 0.921765,
        "f1": 0.898429,
        "accuracy": 0.921765,
        "main_score": 0.898429,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.009323,
        "recall": 0.019057,
        "f1": 0.010664,
        "accuracy": 0.019057,
        "main_score": 0.010664,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024998,
        "recall": 0.065196,
        "f1": 0.032061,
        "accuracy": 0.065196,
        "main_score": 0.032061,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.929873,
        "recall": 0.951856,
        "f1": 0.936877,
        "accuracy": 0.951856,
        "main_score": 0.936877,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.895186,
        "recall": 0.927783,
        "f1": 0.905517,
        "accuracy": 0.927783,
        "main_score": 0.905517,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.930207,
        "recall": 0.951856,
        "f1": 0.937044,
        "accuracy": 0.951856,
        "main_score": 0.937044,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.892711,
        "recall": 0.925777,
        "f1": 0.90321,
        "accuracy": 0.925777,
        "main_score": 0.90321,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.004103,
        "recall": 0.005015,
        "f1": 0.004179,
        "accuracy": 0.005015,
        "main_score": 0.004179,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0002,
        "recall": 0.01003,
        "f1": 0.000389,
        "accuracy": 0.01003,
        "main_score": 0.000389,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.715466,
        "recall": 0.774704,
        "f1": 0.732277,
        "accuracy": 0.774704,
        "main_score": 0.732277,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.656522,
        "recall": 0.749012,
        "f1": 0.684201,
        "accuracy": 0.749012,
        "main_score": 0.684201,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.930089,
        "recall": 0.949605,
        "f1": 0.936119,
        "accuracy": 0.949605,
        "main_score": 0.936119,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.85779,
        "recall": 0.902174,
        "f1": 0.871904,
        "accuracy": 0.902174,
        "main_score": 0.871904,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.997036,
        "recall": 0.998024,
        "f1": 0.997365,
        "accuracy": 0.998024,
        "main_score": 0.997365,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.983696,
        "recall": 0.98913,
        "f1": 0.985507,
        "accuracy": 0.98913,
        "main_score": 0.985507,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.303584,
        "recall": 0.324111,
        "f1": 0.307323,
        "accuracy": 0.324111,
        "main_score": 0.307323,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.152617,
        "recall": 0.291502,
        "f1": 0.181837,
        "accuracy": 0.291502,
        "main_score": 0.181837,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.345457,
        "recall": 0.368577,
        "f1": 0.349532,
        "accuracy": 0.368577,
        "main_score": 0.349532,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.194495,
        "recall": 0.340909,
        "f1": 0.227158,
        "accuracy": 0.340909,
        "main_score": 0.227158,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.964592,
        "recall": 0.975296,
        "f1": 0.968003,
        "accuracy": 0.975296,
        "main_score": 0.968003,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.931818,
        "recall": 0.953557,
        "f1": 0.9389,
        "accuracy": 0.953557,
        "main_score": 0.9389,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.364051,
        "recall": 0.401186,
        "f1": 0.372931,
        "accuracy": 0.401186,
        "main_score": 0.372931,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.239055,
        "recall": 0.376482,
        "f1": 0.270486,
        "accuracy": 0.376482,
        "main_score": 0.270486,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.416481,
        "recall": 0.445652,
        "f1": 0.422999,
        "accuracy": 0.445652,
        "main_score": 0.422999,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.256122,
        "recall": 0.401186,
        "f1": 0.29036,
        "accuracy": 0.401186,
        "main_score": 0.29036,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.961792,
        "recall": 0.974308,
        "f1": 0.965909,
        "accuracy": 0.974308,
        "main_score": 0.965909,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.944829,
        "recall": 0.962451,
        "f1": 0.950593,
        "accuracy": 0.962451,
        "main_score": 0.950593,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.287181,
        "recall": 0.348814,
        "f1": 0.301132,
        "accuracy": 0.348814,
        "main_score": 0.301132,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.293306,
        "recall": 0.41502,
        "f1": 0.324377,
        "accuracy": 0.41502,
        "main_score": 0.324377,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.867918,
        "recall": 0.90415,
        "f1": 0.87899,
        "accuracy": 0.90415,
        "main_score": 0.87899,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.832002,
        "recall": 0.878458,
        "f1": 0.846113,
        "accuracy": 0.878458,
        "main_score": 0.846113,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.925478,
        "recall": 0.94664,
        "f1": 0.932002,
        "accuracy": 0.94664,
        "main_score": 0.932002,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.883811,
        "recall": 0.918972,
        "f1": 0.894829,
        "accuracy": 0.918972,
        "main_score": 0.894829,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.478031,
        "recall": 0.536561,
        "f1": 0.493074,
        "accuracy": 0.536561,
        "main_score": 0.493074,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.361977,
        "recall": 0.5,
        "f1": 0.397696,
        "accuracy": 0.5,
        "main_score": 0.397696,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.576075,
        "recall": 0.642292,
        "f1": 0.593437,
        "accuracy": 0.642292,
        "main_score": 0.593437,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.505783,
        "recall": 0.621542,
        "f1": 0.537524,
        "accuracy": 0.621542,
        "main_score": 0.537524,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.666176,
        "recall": 0.743083,
        "f1": 0.688617,
        "accuracy": 0.743083,
        "main_score": 0.688617,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.636086,
        "recall": 0.722332,
        "f1": 0.660208,
        "accuracy": 0.722332,
        "main_score": 0.660208,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.706516,
        "recall": 0.777668,
        "f1": 0.727344,
        "accuracy": 0.777668,
        "main_score": 0.727344,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.68559,
        "recall": 0.769763,
        "f1": 0.71158,
        "accuracy": 0.769763,
        "main_score": 0.71158,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.966074,
        "recall": 0.976285,
        "f1": 0.969368,
        "accuracy": 0.976285,
        "main_score": 0.969368,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.939312,
        "recall": 0.95751,
        "f1": 0.945224,
        "accuracy": 0.95751,
        "main_score": 0.945224,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.963274,
        "recall": 0.975296,
        "f1": 0.967227,
        "accuracy": 0.975296,
        "main_score": 0.967227,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.925066,
        "recall": 0.948617,
        "f1": 0.932642,
        "accuracy": 0.948617,
        "main_score": 0.932642,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.01933,
        "recall": 0.027668,
        "f1": 0.020675,
        "accuracy": 0.027668,
        "main_score": 0.020675,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009349,
        "recall": 0.056324,
        "f1": 0.014456,
        "accuracy": 0.056324,
        "main_score": 0.014456,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.032593,
        "recall": 0.051383,
        "f1": 0.034885,
        "accuracy": 0.051383,
        "main_score": 0.034885,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056713,
        "recall": 0.112648,
        "f1": 0.067172,
        "accuracy": 0.112648,
        "main_score": 0.067172,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.942029,
        "recall": 0.959486,
        "f1": 0.947628,
        "accuracy": 0.959486,
        "main_score": 0.947628,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.907691,
        "recall": 0.934783,
        "f1": 0.916238,
        "accuracy": 0.934783,
        "main_score": 0.916238,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.611397,
        "recall": 0.690711,
        "f1": 0.633237,
        "accuracy": 0.690711,
        "main_score": 0.633237,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.565706,
        "recall": 0.667984,
        "f1": 0.595111,
        "accuracy": 0.667984,
        "main_score": 0.595111,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.897398,
        "recall": 0.928854,
        "f1": 0.907444,
        "accuracy": 0.928854,
        "main_score": 0.907444,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.859931,
        "recall": 0.903162,
        "f1": 0.873584,
        "accuracy": 0.903162,
        "main_score": 0.873584,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.890714,
        "recall": 0.916996,
        "f1": 0.898405,
        "accuracy": 0.916996,
        "main_score": 0.898405,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.859931,
        "recall": 0.902174,
        "f1": 0.873221,
        "accuracy": 0.902174,
        "main_score": 0.873221,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.912961,
        "recall": 0.938735,
        "f1": 0.921179,
        "accuracy": 0.938735,
        "main_score": 0.921179,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.851861,
        "recall": 0.896245,
        "f1": 0.86581,
        "accuracy": 0.896245,
        "main_score": 0.86581,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.012302,
        "recall": 0.018775,
        "f1": 0.013679,
        "accuracy": 0.018775,
        "main_score": 0.013679,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023025,
        "recall": 0.057312,
        "f1": 0.028804,
        "accuracy": 0.057312,
        "main_score": 0.028804,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.91642,
        "recall": 0.9417,
        "f1": 0.924638,
        "accuracy": 0.9417,
        "main_score": 0.924638,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.9083,
        "recall": 0.936759,
        "f1": 0.917325,
        "accuracy": 0.936759,
        "main_score": 0.917325,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.936841,
        "recall": 0.956522,
        "f1": 0.943083,
        "accuracy": 0.956522,
        "main_score": 0.943083,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.90975,
        "recall": 0.937747,
        "f1": 0.918643,
        "accuracy": 0.937747,
        "main_score": 0.918643,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.003954,
        "recall": 0.004941,
        "f1": 0.003955,
        "accuracy": 0.004941,
        "main_score": 0.003955,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001683,
        "recall": 0.017787,
        "f1": 0.002298,
        "accuracy": 0.017787,
        "main_score": 0.002298,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 49.091121673583984,
  "kg_co2_emissions": 0.0024144667059118703
}