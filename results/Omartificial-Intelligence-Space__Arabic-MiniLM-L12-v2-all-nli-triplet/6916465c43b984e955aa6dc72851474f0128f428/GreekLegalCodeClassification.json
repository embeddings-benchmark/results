{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.273779,
        "f1": 0.213427,
        "f1_weighted": 0.277024,
        "scores_per_experiment": [
          {
            "accuracy": 0.279785,
            "f1": 0.220744,
            "f1_weighted": 0.285547
          },
          {
            "accuracy": 0.269043,
            "f1": 0.209404,
            "f1_weighted": 0.269736
          },
          {
            "accuracy": 0.267578,
            "f1": 0.204066,
            "f1_weighted": 0.268999
          },
          {
            "accuracy": 0.263184,
            "f1": 0.211122,
            "f1_weighted": 0.264629
          },
          {
            "accuracy": 0.270996,
            "f1": 0.209053,
            "f1_weighted": 0.276014
          },
          {
            "accuracy": 0.274902,
            "f1": 0.217388,
            "f1_weighted": 0.283836
          },
          {
            "accuracy": 0.289551,
            "f1": 0.222135,
            "f1_weighted": 0.296018
          },
          {
            "accuracy": 0.279785,
            "f1": 0.226836,
            "f1_weighted": 0.279347
          },
          {
            "accuracy": 0.271484,
            "f1": 0.200767,
            "f1_weighted": 0.277524
          },
          {
            "accuracy": 0.271484,
            "f1": 0.212755,
            "f1_weighted": 0.268589
          }
        ],
        "main_score": 0.273779,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.263428,
        "f1": 0.216538,
        "f1_weighted": 0.2676,
        "scores_per_experiment": [
          {
            "accuracy": 0.269043,
            "f1": 0.206544,
            "f1_weighted": 0.278176
          },
          {
            "accuracy": 0.271484,
            "f1": 0.228416,
            "f1_weighted": 0.273507
          },
          {
            "accuracy": 0.268555,
            "f1": 0.230146,
            "f1_weighted": 0.269845
          },
          {
            "accuracy": 0.263672,
            "f1": 0.212178,
            "f1_weighted": 0.265839
          },
          {
            "accuracy": 0.267578,
            "f1": 0.226117,
            "f1_weighted": 0.272407
          },
          {
            "accuracy": 0.266602,
            "f1": 0.217168,
            "f1_weighted": 0.267912
          },
          {
            "accuracy": 0.260254,
            "f1": 0.212015,
            "f1_weighted": 0.27117
          },
          {
            "accuracy": 0.25293,
            "f1": 0.208531,
            "f1_weighted": 0.252724
          },
          {
            "accuracy": 0.246094,
            "f1": 0.204563,
            "f1_weighted": 0.255031
          },
          {
            "accuracy": 0.268066,
            "f1": 0.219703,
            "f1_weighted": 0.26939
          }
        ],
        "main_score": 0.263428,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 289.44898080825806,
  "kg_co2_emissions": 0.008858278054082975
}