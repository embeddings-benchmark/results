{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.43605,
        "f1": 0.394945,
        "f1_weighted": 0.456326,
        "scores_per_experiment": [
          {
            "accuracy": 0.4845,
            "f1": 0.42906,
            "f1_weighted": 0.502504
          },
          {
            "accuracy": 0.4325,
            "f1": 0.391365,
            "f1_weighted": 0.446647
          },
          {
            "accuracy": 0.431,
            "f1": 0.381988,
            "f1_weighted": 0.451204
          },
          {
            "accuracy": 0.428,
            "f1": 0.387646,
            "f1_weighted": 0.451336
          },
          {
            "accuracy": 0.4495,
            "f1": 0.40883,
            "f1_weighted": 0.471938
          },
          {
            "accuracy": 0.3925,
            "f1": 0.361781,
            "f1_weighted": 0.41709
          },
          {
            "accuracy": 0.4295,
            "f1": 0.391171,
            "f1_weighted": 0.451022
          },
          {
            "accuracy": 0.402,
            "f1": 0.373268,
            "f1_weighted": 0.418108
          },
          {
            "accuracy": 0.478,
            "f1": 0.432665,
            "f1_weighted": 0.495751
          },
          {
            "accuracy": 0.433,
            "f1": 0.391678,
            "f1_weighted": 0.457657
          }
        ],
        "main_score": 0.43605,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.4353,
        "f1": 0.387665,
        "f1_weighted": 0.458035,
        "scores_per_experiment": [
          {
            "accuracy": 0.479,
            "f1": 0.423971,
            "f1_weighted": 0.498643
          },
          {
            "accuracy": 0.4215,
            "f1": 0.368678,
            "f1_weighted": 0.440373
          },
          {
            "accuracy": 0.4455,
            "f1": 0.389916,
            "f1_weighted": 0.4672
          },
          {
            "accuracy": 0.422,
            "f1": 0.37341,
            "f1_weighted": 0.451142
          },
          {
            "accuracy": 0.4425,
            "f1": 0.399642,
            "f1_weighted": 0.466065
          },
          {
            "accuracy": 0.3925,
            "f1": 0.350293,
            "f1_weighted": 0.422088
          },
          {
            "accuracy": 0.431,
            "f1": 0.385798,
            "f1_weighted": 0.453852
          },
          {
            "accuracy": 0.403,
            "f1": 0.366384,
            "f1_weighted": 0.421643
          },
          {
            "accuracy": 0.478,
            "f1": 0.421262,
            "f1_weighted": 0.497121
          },
          {
            "accuracy": 0.438,
            "f1": 0.397299,
            "f1_weighted": 0.462218
          }
        ],
        "main_score": 0.4353,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.856324672698975,
  "kg_co2_emissions": 0.0004960695266784522
}