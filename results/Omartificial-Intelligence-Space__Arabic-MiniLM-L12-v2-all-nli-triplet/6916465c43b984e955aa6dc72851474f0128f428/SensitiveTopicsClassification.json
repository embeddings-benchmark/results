{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "task_name": "SensitiveTopicsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.234668,
        "f1": 0.194596,
        "lrap": 0.352119,
        "scores_per_experiment": [
          {
            "accuracy": 0.23291,
            "f1": 0.172922,
            "lrap": 0.32586
          },
          {
            "accuracy": 0.208984,
            "f1": 0.174332,
            "lrap": 0.327799
          },
          {
            "accuracy": 0.219727,
            "f1": 0.171477,
            "lrap": 0.332967
          },
          {
            "accuracy": 0.219727,
            "f1": 0.156079,
            "lrap": 0.335137
          },
          {
            "accuracy": 0.23584,
            "f1": 0.204411,
            "lrap": 0.349121
          },
          {
            "accuracy": 0.216309,
            "f1": 0.190863,
            "lrap": 0.348728
          },
          {
            "accuracy": 0.27002,
            "f1": 0.200607,
            "lrap": 0.386414
          },
          {
            "accuracy": 0.22168,
            "f1": 0.204581,
            "lrap": 0.368747
          },
          {
            "accuracy": 0.268066,
            "f1": 0.256407,
            "lrap": 0.373494
          },
          {
            "accuracy": 0.253418,
            "f1": 0.214279,
            "lrap": 0.372925
          }
        ],
        "main_score": 0.234668,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 4.411022186279297,
  "kg_co2_emissions": 0.000135793136452666
}