{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.662141,
        "f1": 0.662475,
        "f1_weighted": 0.663026,
        "scores_per_experiment": [
          {
            "accuracy": 0.681462,
            "f1": 0.681462,
            "f1_weighted": 0.682022
          },
          {
            "accuracy": 0.671018,
            "f1": 0.67488,
            "f1_weighted": 0.677778
          },
          {
            "accuracy": 0.637076,
            "f1": 0.641417,
            "f1_weighted": 0.638926
          },
          {
            "accuracy": 0.592689,
            "f1": 0.594609,
            "f1_weighted": 0.593683
          },
          {
            "accuracy": 0.712794,
            "f1": 0.713774,
            "f1_weighted": 0.713988
          },
          {
            "accuracy": 0.663185,
            "f1": 0.661506,
            "f1_weighted": 0.657989
          },
          {
            "accuracy": 0.668407,
            "f1": 0.656836,
            "f1_weighted": 0.660352
          },
          {
            "accuracy": 0.689295,
            "f1": 0.693071,
            "f1_weighted": 0.69483
          },
          {
            "accuracy": 0.663185,
            "f1": 0.661626,
            "f1_weighted": 0.663036
          },
          {
            "accuracy": 0.642298,
            "f1": 0.645566,
            "f1_weighted": 0.64766
          }
        ],
        "main_score": 0.662141,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.679167,
        "f1": 0.682566,
        "f1_weighted": 0.681602,
        "scores_per_experiment": [
          {
            "accuracy": 0.645833,
            "f1": 0.65235,
            "f1_weighted": 0.64981
          },
          {
            "accuracy": 0.666667,
            "f1": 0.673775,
            "f1_weighted": 0.676048
          },
          {
            "accuracy": 0.666667,
            "f1": 0.679387,
            "f1_weighted": 0.66842
          },
          {
            "accuracy": 0.541667,
            "f1": 0.544048,
            "f1_weighted": 0.546615
          },
          {
            "accuracy": 0.739583,
            "f1": 0.747331,
            "f1_weighted": 0.745885
          },
          {
            "accuracy": 0.666667,
            "f1": 0.684482,
            "f1_weighted": 0.673613
          },
          {
            "accuracy": 0.708333,
            "f1": 0.673873,
            "f1_weighted": 0.68504
          },
          {
            "accuracy": 0.71875,
            "f1": 0.727208,
            "f1_weighted": 0.726763
          },
          {
            "accuracy": 0.697917,
            "f1": 0.706369,
            "f1_weighted": 0.706214
          },
          {
            "accuracy": 0.739583,
            "f1": 0.736835,
            "f1_weighted": 0.737609
          }
        ],
        "main_score": 0.679167,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 13.161132097244263,
  "kg_co2_emissions": 0.00036906761637278153
}