{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "task_name": "MassiveScenarioClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.881456,
            "f1": 0.875601,
            "f1_weighted": 0.882139,
            "precision": 0.862647,
            "precision_weighted": 0.889332,
            "recall": 0.897223,
            "recall_weighted": 0.881456,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.885883,
            "f1": 0.879675,
            "f1_weighted": 0.885535,
            "precision": 0.86543,
            "precision_weighted": 0.889773,
            "recall": 0.90015,
            "recall_weighted": 0.885883,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.878505,
            "f1": 0.870492,
            "f1_weighted": 0.877777,
            "precision": 0.855723,
            "precision_weighted": 0.884473,
            "recall": 0.895288,
            "recall_weighted": 0.878505,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.863256,
            "f1": 0.854126,
            "f1_weighted": 0.863848,
            "precision": 0.840868,
            "precision_weighted": 0.875079,
            "recall": 0.881336,
            "recall_weighted": 0.863256,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.875553,
            "f1": 0.865208,
            "f1_weighted": 0.873423,
            "precision": 0.854878,
            "precision_weighted": 0.881155,
            "recall": 0.888467,
            "recall_weighted": 0.875553,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.871126,
            "f1": 0.864488,
            "f1_weighted": 0.870645,
            "precision": 0.850171,
            "precision_weighted": 0.879647,
            "recall": 0.890345,
            "recall_weighted": 0.871126,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.838662,
            "f1": 0.838485,
            "f1_weighted": 0.840308,
            "precision": 0.823874,
            "precision_weighted": 0.859423,
            "recall": 0.875674,
            "recall_weighted": 0.838662,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.847516,
            "f1": 0.848407,
            "f1_weighted": 0.851244,
            "precision": 0.836891,
            "precision_weighted": 0.869474,
            "recall": 0.87686,
            "recall_weighted": 0.847516,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.873586,
            "f1": 0.865583,
            "f1_weighted": 0.873206,
            "precision": 0.858405,
            "precision_weighted": 0.876641,
            "recall": 0.878555,
            "recall_weighted": 0.873586,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.881456,
            "f1": 0.87527,
            "f1_weighted": 0.882667,
            "precision": 0.862031,
            "precision_weighted": 0.88948,
            "recall": 0.89689,
            "recall_weighted": 0.881456,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.8697,
        "f1": 0.863733,
        "f1_weighted": 0.870079,
        "precision": 0.851092,
        "precision_weighted": 0.879448,
        "recall": 0.888079,
        "recall_weighted": 0.8697,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.8697,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.872898,
            "f1": 0.865655,
            "f1_weighted": 0.873857,
            "precision": 0.851227,
            "precision_weighted": 0.880401,
            "recall": 0.888085,
            "recall_weighted": 0.872898,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.885676,
            "f1": 0.880051,
            "f1_weighted": 0.886386,
            "precision": 0.867113,
            "precision_weighted": 0.891308,
            "recall": 0.89823,
            "recall_weighted": 0.885676,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.87189,
            "f1": 0.865541,
            "f1_weighted": 0.87214,
            "precision": 0.849268,
            "precision_weighted": 0.878823,
            "recall": 0.890945,
            "recall_weighted": 0.87189,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.861802,
            "f1": 0.85406,
            "f1_weighted": 0.861919,
            "precision": 0.84037,
            "precision_weighted": 0.8718,
            "recall": 0.880265,
            "recall_weighted": 0.861802,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.873235,
            "f1": 0.861692,
            "f1_weighted": 0.870091,
            "precision": 0.84714,
            "precision_weighted": 0.877746,
            "recall": 0.889902,
            "recall_weighted": 0.873235,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.87996,
            "f1": 0.872891,
            "f1_weighted": 0.879291,
            "precision": 0.860246,
            "precision_weighted": 0.886044,
            "recall": 0.895131,
            "recall_weighted": 0.87996,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.847344,
            "f1": 0.846383,
            "f1_weighted": 0.84948,
            "precision": 0.83152,
            "precision_weighted": 0.867173,
            "recall": 0.882265,
            "recall_weighted": 0.847344,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.853396,
            "f1": 0.854978,
            "f1_weighted": 0.858452,
            "precision": 0.842972,
            "precision_weighted": 0.875717,
            "recall": 0.882259,
            "recall_weighted": 0.853396,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.878615,
            "f1": 0.871887,
            "f1_weighted": 0.878365,
            "precision": 0.860209,
            "precision_weighted": 0.882372,
            "recall": 0.889444,
            "recall_weighted": 0.878615,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.878951,
            "f1": 0.87349,
            "f1_weighted": 0.880589,
            "precision": 0.861032,
            "precision_weighted": 0.886742,
            "recall": 0.892415,
            "recall_weighted": 0.878951,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.870377,
        "f1": 0.864663,
        "f1_weighted": 0.871057,
        "precision": 0.85111,
        "precision_weighted": 0.879813,
        "recall": 0.888894,
        "recall_weighted": 0.870377,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.870377,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 12.336144208908081,
  "kg_co2_emissions": null
}