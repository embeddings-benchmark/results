{
  "dataset_revision": "78cfd586d70d2753fe7080a29dfbc5c278b1d54d",
  "task_name": "WRIMEClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.376953,
            "f1": 0.371874,
            "f1_weighted": 0.376418,
            "precision": 0.375456,
            "precision_weighted": 0.425841,
            "recall": 0.448235,
            "recall_weighted": 0.376953,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.350586,
            "f1": 0.338956,
            "f1_weighted": 0.355927,
            "precision": 0.364586,
            "precision_weighted": 0.433552,
            "recall": 0.421004,
            "recall_weighted": 0.350586,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.361328,
            "f1": 0.350916,
            "f1_weighted": 0.371094,
            "precision": 0.367278,
            "precision_weighted": 0.435277,
            "recall": 0.42482,
            "recall_weighted": 0.361328,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.381348,
            "f1": 0.364765,
            "f1_weighted": 0.386218,
            "precision": 0.367817,
            "precision_weighted": 0.42943,
            "recall": 0.424413,
            "recall_weighted": 0.381348,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.307617,
            "f1": 0.298288,
            "f1_weighted": 0.31585,
            "precision": 0.328378,
            "precision_weighted": 0.396399,
            "recall": 0.401826,
            "recall_weighted": 0.307617,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.336426,
            "f1": 0.315107,
            "f1_weighted": 0.339236,
            "precision": 0.327733,
            "precision_weighted": 0.389928,
            "recall": 0.386221,
            "recall_weighted": 0.336426,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.283691,
            "f1": 0.280742,
            "f1_weighted": 0.287991,
            "precision": 0.3058,
            "precision_weighted": 0.367172,
            "recall": 0.397482,
            "recall_weighted": 0.283691,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.402344,
            "f1": 0.383588,
            "f1_weighted": 0.411566,
            "precision": 0.395166,
            "precision_weighted": 0.462983,
            "recall": 0.466231,
            "recall_weighted": 0.402344,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.378906,
            "f1": 0.367576,
            "f1_weighted": 0.387782,
            "precision": 0.37184,
            "precision_weighted": 0.436942,
            "recall": 0.445721,
            "recall_weighted": 0.378906,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.334473,
            "f1": 0.331483,
            "f1_weighted": 0.333218,
            "precision": 0.353125,
            "precision_weighted": 0.412733,
            "recall": 0.448797,
            "recall_weighted": 0.334473,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.351367,
        "f1": 0.34033,
        "f1_weighted": 0.35653,
        "precision": 0.355718,
        "precision_weighted": 0.419026,
        "recall": 0.426475,
        "recall_weighted": 0.351367,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.351367,
        "hf_subset": "default",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 8.645178079605103,
  "kg_co2_emissions": null
}