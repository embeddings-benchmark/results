{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "task_name": "MassiveIntentClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.810625,
            "f1": 0.767281,
            "f1_weighted": 0.805324,
            "precision": 0.758509,
            "precision_weighted": 0.832078,
            "recall": 0.82199,
            "recall_weighted": 0.810625,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.828333,
            "f1": 0.786506,
            "f1_weighted": 0.827442,
            "precision": 0.775706,
            "precision_weighted": 0.852462,
            "recall": 0.836473,
            "recall_weighted": 0.828333,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.815544,
            "f1": 0.775751,
            "f1_weighted": 0.807582,
            "precision": 0.767029,
            "precision_weighted": 0.839349,
            "recall": 0.830937,
            "recall_weighted": 0.815544,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.812592,
            "f1": 0.754633,
            "f1_weighted": 0.806824,
            "precision": 0.741896,
            "precision_weighted": 0.841583,
            "recall": 0.81403,
            "recall_weighted": 0.812592,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.801771,
            "f1": 0.76658,
            "f1_weighted": 0.7913,
            "precision": 0.760356,
            "precision_weighted": 0.818526,
            "recall": 0.819842,
            "recall_weighted": 0.801771,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.799803,
            "f1": 0.775351,
            "f1_weighted": 0.794036,
            "precision": 0.764675,
            "precision_weighted": 0.8318,
            "recall": 0.835732,
            "recall_weighted": 0.799803,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.798819,
            "f1": 0.770318,
            "f1_weighted": 0.789242,
            "precision": 0.765089,
            "precision_weighted": 0.831172,
            "recall": 0.826294,
            "recall_weighted": 0.798819,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.795376,
            "f1": 0.76079,
            "f1_weighted": 0.7905,
            "precision": 0.746453,
            "precision_weighted": 0.820065,
            "recall": 0.821939,
            "recall_weighted": 0.795376,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.818987,
            "f1": 0.779636,
            "f1_weighted": 0.816517,
            "precision": 0.77153,
            "precision_weighted": 0.845939,
            "recall": 0.830058,
            "recall_weighted": 0.818987,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.8303,
            "f1": 0.802594,
            "f1_weighted": 0.828511,
            "precision": 0.789243,
            "precision_weighted": 0.850573,
            "recall": 0.856149,
            "recall_weighted": 0.8303,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.811215,
        "f1": 0.773944,
        "f1_weighted": 0.805728,
        "precision": 0.764049,
        "precision_weighted": 0.836355,
        "recall": 0.829344,
        "recall_weighted": 0.811215,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.811215,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.805649,
            "f1": 0.764049,
            "f1_weighted": 0.801958,
            "precision": 0.754949,
            "precision_weighted": 0.837656,
            "recall": 0.811938,
            "recall_weighted": 0.805649,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.816073,
            "f1": 0.7859,
            "f1_weighted": 0.814923,
            "precision": 0.767716,
            "precision_weighted": 0.843505,
            "recall": 0.846703,
            "recall_weighted": 0.816073,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.80195,
            "f1": 0.778738,
            "f1_weighted": 0.795255,
            "precision": 0.761768,
            "precision_weighted": 0.820786,
            "recall": 0.843305,
            "recall_weighted": 0.80195,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.803631,
            "f1": 0.769862,
            "f1_weighted": 0.799792,
            "precision": 0.755372,
            "precision_weighted": 0.832249,
            "recall": 0.835824,
            "recall_weighted": 0.803631,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.795562,
            "f1": 0.770758,
            "f1_weighted": 0.785886,
            "precision": 0.766625,
            "precision_weighted": 0.83458,
            "recall": 0.830278,
            "recall_weighted": 0.795562,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.786483,
            "f1": 0.771359,
            "f1_weighted": 0.782139,
            "precision": 0.761292,
            "precision_weighted": 0.82621,
            "recall": 0.838506,
            "recall_weighted": 0.786483,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.79119,
            "f1": 0.7697,
            "f1_weighted": 0.787232,
            "precision": 0.763871,
            "precision_weighted": 0.825077,
            "recall": 0.831855,
            "recall_weighted": 0.79119,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.796234,
            "f1": 0.778413,
            "f1_weighted": 0.792331,
            "precision": 0.76145,
            "precision_weighted": 0.823598,
            "recall": 0.83004,
            "recall_weighted": 0.796234,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.80733,
            "f1": 0.778942,
            "f1_weighted": 0.805593,
            "precision": 0.767618,
            "precision_weighted": 0.837445,
            "recall": 0.842855,
            "recall_weighted": 0.80733,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.822798,
            "f1": 0.791886,
            "f1_weighted": 0.823548,
            "precision": 0.779259,
            "precision_weighted": 0.851611,
            "recall": 0.851799,
            "recall_weighted": 0.822798,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.80269,
        "f1": 0.775961,
        "f1_weighted": 0.798866,
        "precision": 0.763992,
        "precision_weighted": 0.833272,
        "recall": 0.83631,
        "recall_weighted": 0.80269,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.80269,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 19.580408811569214,
  "kg_co2_emissions": null
}