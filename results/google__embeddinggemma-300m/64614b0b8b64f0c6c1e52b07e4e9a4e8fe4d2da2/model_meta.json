{
    "name": "google/embeddinggemma-300m",
    "revision": "64614b0b8b64f0c6c1e52b07e4e9a4e8fe4d2da2",
    "release_date": "2025-09-04",
    "languages": [
        "arb-Arab",
        "ben-Beng",
        "eng-Latn",
        "spa-Latn",
        "deu-Latn",
        "pes-Arab",
        "fin-Latn",
        "fra-Latn",
        "hin-Deva",
        "ind-Latn",
        "jpn-Jpan",
        "kor-Hang",
        "rus-Cyrl",
        "swh-Latn",
        "tel-Telu",
        "tha-Thai",
        "yor-Latn",
        "zho-Hant",
        "zho-Hans"
    ],
    "n_parameters": 307581696,
    "memory_usage_mb": 578,
    "max_tokens": 2048,
    "embed_dim": 768,
    "license": "gemma",
    "open_weights": true,
    "public_training_code": null,
    "public_training_data": null,
    "framework": [
        "Sentence Transformers",
        "PyTorch"
    ],
    "reference": null,
    "similarity_fn_name": "cosine",
    "use_instructions": true,
    "training_datasets": {
        "NQHardNegatives": [
            "train"
        ],
        "FEVERHardNegatives": [
            "train"
        ],
        "HotpotQAHardNegatives": [
            "train"
        ],
        "MIRACLRetrievalHardNegatives": [
            "train"
        ]
    },
    "adapted_from": null,
    "superseded_by": null,
    "modalities": [
        "text"
    ],
    "loader": null
}