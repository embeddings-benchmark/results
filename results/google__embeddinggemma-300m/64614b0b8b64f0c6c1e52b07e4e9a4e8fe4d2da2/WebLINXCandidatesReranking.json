{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.34.7",
  "scores": {
    "validation": [
      {
        "map": 0.145649,
        "mrr": 0.128179,
        "nAUC_map_max": 0.097464,
        "nAUC_map_std": -0.044595,
        "nAUC_map_diff1": 0.267673,
        "nAUC_mrr_max": 0.11057,
        "nAUC_mrr_std": -0.052074,
        "nAUC_mrr_diff1": 0.270065,
        "main_score": 0.128179,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.125878,
        "mrr": 0.109186,
        "nAUC_map_max": 0.093762,
        "nAUC_map_std": 0.029909,
        "nAUC_map_diff1": 0.172013,
        "nAUC_mrr_max": 0.104533,
        "nAUC_mrr_std": 0.007446,
        "nAUC_mrr_diff1": 0.172748,
        "main_score": 0.109186,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.099012,
        "mrr": 0.081794,
        "nAUC_map_max": 0.170317,
        "nAUC_map_std": 0.393146,
        "nAUC_map_diff1": 0.152788,
        "nAUC_mrr_max": 0.167222,
        "nAUC_mrr_std": 0.37252,
        "nAUC_mrr_diff1": 0.14188,
        "main_score": 0.081794,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.11447,
        "mrr": 0.095165,
        "nAUC_map_max": -0.049539,
        "nAUC_map_std": 0.046415,
        "nAUC_map_diff1": 0.097102,
        "nAUC_mrr_max": -0.050071,
        "nAUC_mrr_std": 0.044554,
        "nAUC_mrr_diff1": 0.091476,
        "main_score": 0.095165,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.125449,
        "mrr": 0.107047,
        "nAUC_map_max": -0.023632,
        "nAUC_map_std": 0.102413,
        "nAUC_map_diff1": 0.083642,
        "nAUC_mrr_max": -0.016466,
        "nAUC_mrr_std": 0.083972,
        "nAUC_mrr_diff1": 0.08449,
        "main_score": 0.107047,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.103768,
        "mrr": 0.088242,
        "nAUC_map_max": 0.022697,
        "nAUC_map_std": -0.001618,
        "nAUC_map_diff1": 0.11135,
        "nAUC_mrr_max": 0.049407,
        "nAUC_mrr_std": -0.021011,
        "nAUC_mrr_diff1": 0.127653,
        "main_score": 0.088242,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 4223.317302703857,
  "kg_co2_emissions": null
}