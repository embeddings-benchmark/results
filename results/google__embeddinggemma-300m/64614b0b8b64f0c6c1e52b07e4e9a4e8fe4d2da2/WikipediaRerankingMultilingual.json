{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.34.7",
  "scores": {
    "test": [
      {
        "map": 0.885177,
        "mrr": 0.885177,
        "nAUC_map_max": 0.556811,
        "nAUC_map_std": 0.430847,
        "nAUC_map_diff1": 0.804461,
        "nAUC_mrr_max": 0.556811,
        "nAUC_mrr_std": 0.430847,
        "nAUC_mrr_diff1": 0.804461,
        "main_score": 0.885177,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.879372,
        "mrr": 0.879372,
        "nAUC_map_max": 0.476903,
        "nAUC_map_std": 0.369457,
        "nAUC_map_diff1": 0.828487,
        "nAUC_mrr_max": 0.476903,
        "nAUC_mrr_std": 0.369457,
        "nAUC_mrr_diff1": 0.828487,
        "main_score": 0.879372,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.890469,
        "mrr": 0.890469,
        "nAUC_map_max": 0.487127,
        "nAUC_map_std": 0.414534,
        "nAUC_map_diff1": 0.790958,
        "nAUC_mrr_max": 0.487127,
        "nAUC_mrr_std": 0.414534,
        "nAUC_mrr_diff1": 0.790958,
        "main_score": 0.890469,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.898571,
        "mrr": 0.899016,
        "nAUC_map_max": 0.418184,
        "nAUC_map_std": 0.465206,
        "nAUC_map_diff1": 0.809371,
        "nAUC_mrr_max": 0.41935,
        "nAUC_mrr_std": 0.463145,
        "nAUC_mrr_diff1": 0.808134,
        "main_score": 0.898571,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.914975,
        "mrr": 0.914975,
        "nAUC_map_max": 0.55074,
        "nAUC_map_std": 0.357732,
        "nAUC_map_diff1": 0.795527,
        "nAUC_mrr_max": 0.55074,
        "nAUC_mrr_std": 0.357732,
        "nAUC_mrr_diff1": 0.795527,
        "main_score": 0.914975,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.93468,
        "mrr": 0.93468,
        "nAUC_map_max": 0.503591,
        "nAUC_map_std": 0.500246,
        "nAUC_map_diff1": 0.877235,
        "nAUC_mrr_max": 0.503591,
        "nAUC_mrr_std": 0.500246,
        "nAUC_mrr_diff1": 0.877235,
        "main_score": 0.93468,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.904108,
        "mrr": 0.904108,
        "nAUC_map_max": 0.554203,
        "nAUC_map_std": 0.402433,
        "nAUC_map_diff1": 0.805066,
        "nAUC_mrr_max": 0.554203,
        "nAUC_mrr_std": 0.402433,
        "nAUC_mrr_diff1": 0.805066,
        "main_score": 0.904108,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.902177,
        "mrr": 0.902177,
        "nAUC_map_max": 0.460616,
        "nAUC_map_std": 0.36671,
        "nAUC_map_diff1": 0.810037,
        "nAUC_mrr_max": 0.460616,
        "nAUC_mrr_std": 0.36671,
        "nAUC_mrr_diff1": 0.810037,
        "main_score": 0.902177,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.896335,
        "mrr": 0.897125,
        "nAUC_map_max": 0.470275,
        "nAUC_map_std": 0.35485,
        "nAUC_map_diff1": 0.821245,
        "nAUC_mrr_max": 0.475481,
        "nAUC_mrr_std": 0.362722,
        "nAUC_mrr_diff1": 0.819106,
        "main_score": 0.896335,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.919629,
        "mrr": 0.919629,
        "nAUC_map_max": 0.575484,
        "nAUC_map_std": 0.453095,
        "nAUC_map_diff1": 0.843025,
        "nAUC_mrr_max": 0.575484,
        "nAUC_mrr_std": 0.453095,
        "nAUC_mrr_diff1": 0.843025,
        "main_score": 0.919629,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.904709,
        "mrr": 0.905043,
        "nAUC_map_max": 0.475933,
        "nAUC_map_std": 0.362837,
        "nAUC_map_diff1": 0.8319,
        "nAUC_mrr_max": 0.474273,
        "nAUC_mrr_std": 0.368184,
        "nAUC_mrr_diff1": 0.830891,
        "main_score": 0.904709,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.904082,
        "mrr": 0.904082,
        "nAUC_map_max": 0.542613,
        "nAUC_map_std": 0.311151,
        "nAUC_map_diff1": 0.806589,
        "nAUC_mrr_max": 0.542613,
        "nAUC_mrr_std": 0.311151,
        "nAUC_mrr_diff1": 0.806589,
        "main_score": 0.904082,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.897948,
        "mrr": 0.898281,
        "nAUC_map_max": 0.528516,
        "nAUC_map_std": 0.350304,
        "nAUC_map_diff1": 0.82872,
        "nAUC_mrr_max": 0.528192,
        "nAUC_mrr_std": 0.350121,
        "nAUC_mrr_diff1": 0.827764,
        "main_score": 0.897948,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.87189,
        "mrr": 0.872223,
        "nAUC_map_max": 0.461343,
        "nAUC_map_std": 0.371236,
        "nAUC_map_diff1": 0.765927,
        "nAUC_mrr_max": 0.462733,
        "nAUC_mrr_std": 0.375148,
        "nAUC_mrr_diff1": 0.764696,
        "main_score": 0.87189,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.869882,
        "mrr": 0.869882,
        "nAUC_map_max": 0.474724,
        "nAUC_map_std": 0.367912,
        "nAUC_map_diff1": 0.765778,
        "nAUC_mrr_max": 0.474724,
        "nAUC_mrr_std": 0.367912,
        "nAUC_mrr_diff1": 0.765778,
        "main_score": 0.869882,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.906506,
        "mrr": 0.906506,
        "nAUC_map_max": 0.516104,
        "nAUC_map_std": 0.406158,
        "nAUC_map_diff1": 0.791835,
        "nAUC_mrr_max": 0.516104,
        "nAUC_mrr_std": 0.406158,
        "nAUC_mrr_diff1": 0.791835,
        "main_score": 0.906506,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 263.7958998680115,
  "kg_co2_emissions": null
}