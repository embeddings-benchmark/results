{
  "dataset_revision": "3db547359a8e0d077f0c9df3f50e11ede67501b7",
  "task_name": "ToxicConversationsClassificationHumanSubset",
  "mteb_version": "1.34.7",
  "scores": {
    "test": [
      {
        "accuracy": 0.622222,
        "f1": 0.618477,
        "f1_weighted": 0.620117,
        "ap": 0.529444,
        "ap_weighted": 0.529444,
        "scores_per_experiment": [
          {
            "accuracy": 0.577778,
            "f1": 0.570136,
            "f1_weighted": 0.576504,
            "ap": 0.48538,
            "ap_weighted": 0.48538
          },
          {
            "accuracy": 0.644444,
            "f1": 0.635628,
            "f1_weighted": 0.62933,
            "ap": 0.550694,
            "ap_weighted": 0.550694
          },
          {
            "accuracy": 0.555556,
            "f1": 0.553571,
            "f1_weighted": 0.556878,
            "ap": 0.475,
            "ap_weighted": 0.475
          },
          {
            "accuracy": 0.511111,
            "f1": 0.51087,
            "f1_weighted": 0.512077,
            "ap": 0.452083,
            "ap_weighted": 0.452083
          },
          {
            "accuracy": 0.622222,
            "f1": 0.609893,
            "f1_weighted": 0.617599,
            "ap": 0.51634,
            "ap_weighted": 0.51634
          },
          {
            "accuracy": 0.644444,
            "f1": 0.642857,
            "f1_weighted": 0.645503,
            "ap": 0.539646,
            "ap_weighted": 0.539646
          },
          {
            "accuracy": 0.577778,
            "f1": 0.576942,
            "f1_weighted": 0.574853,
            "ap": 0.496296,
            "ap_weighted": 0.496296
          },
          {
            "accuracy": 0.733333,
            "f1": 0.73,
            "f1_weighted": 0.733333,
            "ap": 0.623333,
            "ap_weighted": 0.623333
          },
          {
            "accuracy": 0.755556,
            "f1": 0.755072,
            "f1_weighted": 0.756281,
            "ap": 0.645411,
            "ap_weighted": 0.645411
          },
          {
            "accuracy": 0.6,
            "f1": 0.599802,
            "f1_weighted": 0.598814,
            "ap": 0.510256,
            "ap_weighted": 0.510256
          }
        ],
        "main_score": 0.622222,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 18.395313262939453,
  "kg_co2_emissions": null
}