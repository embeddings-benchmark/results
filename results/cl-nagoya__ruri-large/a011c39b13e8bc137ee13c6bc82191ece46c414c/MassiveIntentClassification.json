{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "task_name": "MassiveIntentClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.740285,
            "f1": 0.722673,
            "f1_weighted": 0.739564,
            "precision": 0.707754,
            "precision_weighted": 0.770555,
            "recall": 0.787751,
            "recall_weighted": 0.740285,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.733399,
            "f1": 0.712879,
            "f1_weighted": 0.733465,
            "precision": 0.694471,
            "precision_weighted": 0.763277,
            "recall": 0.781697,
            "recall_weighted": 0.733399,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.723069,
            "f1": 0.697296,
            "f1_weighted": 0.715533,
            "precision": 0.684059,
            "precision_weighted": 0.743114,
            "recall": 0.754991,
            "recall_weighted": 0.723069,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.733891,
            "f1": 0.704749,
            "f1_weighted": 0.727773,
            "precision": 0.684674,
            "precision_weighted": 0.750658,
            "recall": 0.767563,
            "recall_weighted": 0.733891,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.731923,
            "f1": 0.715643,
            "f1_weighted": 0.725033,
            "precision": 0.701734,
            "precision_weighted": 0.746165,
            "recall": 0.771703,
            "recall_weighted": 0.731923,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.711264,
            "f1": 0.696289,
            "f1_weighted": 0.706603,
            "precision": 0.674253,
            "precision_weighted": 0.74352,
            "recall": 0.769659,
            "recall_weighted": 0.711264,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.720118,
            "f1": 0.710595,
            "f1_weighted": 0.713299,
            "precision": 0.694541,
            "precision_weighted": 0.740717,
            "recall": 0.781361,
            "recall_weighted": 0.720118,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.732415,
            "f1": 0.721706,
            "f1_weighted": 0.728797,
            "precision": 0.700907,
            "precision_weighted": 0.747394,
            "recall": 0.784694,
            "recall_weighted": 0.732415,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.724053,
            "f1": 0.708779,
            "f1_weighted": 0.720904,
            "precision": 0.68841,
            "precision_weighted": 0.755267,
            "recall": 0.78575,
            "recall_weighted": 0.724053,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.741269,
            "f1": 0.728247,
            "f1_weighted": 0.737541,
            "precision": 0.710454,
            "precision_weighted": 0.764482,
            "recall": 0.791709,
            "recall_weighted": 0.741269,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.729169,
        "f1": 0.711886,
        "f1_weighted": 0.724851,
        "precision": 0.694126,
        "precision_weighted": 0.752515,
        "recall": 0.777688,
        "recall_weighted": 0.729169,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.729169,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.729657,
            "f1": 0.706921,
            "f1_weighted": 0.730715,
            "precision": 0.691559,
            "precision_weighted": 0.764765,
            "recall": 0.772599,
            "recall_weighted": 0.729657,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.728312,
            "f1": 0.710601,
            "f1_weighted": 0.731619,
            "precision": 0.693896,
            "precision_weighted": 0.764714,
            "recall": 0.767659,
            "recall_weighted": 0.728312,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.725286,
            "f1": 0.696634,
            "f1_weighted": 0.720598,
            "precision": 0.677515,
            "precision_weighted": 0.749963,
            "recall": 0.759028,
            "recall_weighted": 0.725286,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.736046,
            "f1": 0.707307,
            "f1_weighted": 0.735672,
            "precision": 0.687643,
            "precision_weighted": 0.76219,
            "recall": 0.76187,
            "recall_weighted": 0.736046,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.720915,
            "f1": 0.693441,
            "f1_weighted": 0.71778,
            "precision": 0.670335,
            "precision_weighted": 0.745269,
            "recall": 0.768411,
            "recall_weighted": 0.720915,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.70612,
            "f1": 0.696008,
            "f1_weighted": 0.7057,
            "precision": 0.678495,
            "precision_weighted": 0.74322,
            "recall": 0.777381,
            "recall_weighted": 0.70612,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.714526,
            "f1": 0.694348,
            "f1_weighted": 0.718451,
            "precision": 0.684376,
            "precision_weighted": 0.751676,
            "recall": 0.750512,
            "recall_weighted": 0.714526,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.717552,
            "f1": 0.700447,
            "f1_weighted": 0.717203,
            "precision": 0.68067,
            "precision_weighted": 0.744581,
            "recall": 0.76263,
            "recall_weighted": 0.717552,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.717216,
            "f1": 0.697496,
            "f1_weighted": 0.717848,
            "precision": 0.680865,
            "precision_weighted": 0.759119,
            "recall": 0.780845,
            "recall_weighted": 0.717216,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.735373,
            "f1": 0.713094,
            "f1_weighted": 0.735494,
            "precision": 0.698175,
            "precision_weighted": 0.765687,
            "recall": 0.782146,
            "recall_weighted": 0.735373,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.7231,
        "f1": 0.70163,
        "f1_weighted": 0.723108,
        "precision": 0.684353,
        "precision_weighted": 0.755118,
        "recall": 0.768308,
        "recall_weighted": 0.7231,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.7231,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 20.089261293411255,
  "kg_co2_emissions": null
}