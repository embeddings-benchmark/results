{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "1.34.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.533435,
        "f1": 0.439016,
        "f1_weighted": 0.605862,
        "ap": 0.881507,
        "ap_weighted": 0.881507,
        "scores_per_experiment": [
          {
            "accuracy": 0.632219,
            "f1": 0.475099,
            "f1_weighted": 0.690702,
            "ap": 0.877029,
            "ap_weighted": 0.877029
          },
          {
            "accuracy": 0.50152,
            "f1": 0.426488,
            "f1_weighted": 0.582226,
            "ap": 0.881356,
            "ap_weighted": 0.881356
          },
          {
            "accuracy": 0.483283,
            "f1": 0.411362,
            "f1_weighted": 0.565835,
            "ap": 0.876724,
            "ap_weighted": 0.876724
          },
          {
            "accuracy": 0.428571,
            "f1": 0.385609,
            "f1_weighted": 0.507583,
            "ap": 0.881414,
            "ap_weighted": 0.881414
          },
          {
            "accuracy": 0.574468,
            "f1": 0.471886,
            "f1_weighted": 0.646629,
            "ap": 0.888409,
            "ap_weighted": 0.888409
          },
          {
            "accuracy": 0.489362,
            "f1": 0.4125,
            "f1_weighted": 0.572036,
            "ap": 0.875195,
            "ap_weighted": 0.875195
          },
          {
            "accuracy": 0.404255,
            "f1": 0.369732,
            "f1_weighted": 0.480476,
            "ap": 0.880648,
            "ap_weighted": 0.880648
          },
          {
            "accuracy": 0.534954,
            "f1": 0.439111,
            "f1_weighted": 0.61318,
            "ap": 0.878617,
            "ap_weighted": 0.878617
          },
          {
            "accuracy": 0.62614,
            "f1": 0.506482,
            "f1_weighted": 0.688923,
            "ap": 0.895201,
            "ap_weighted": 0.895201
          },
          {
            "accuracy": 0.659574,
            "f1": 0.491892,
            "f1_weighted": 0.711033,
            "ap": 0.880475,
            "ap_weighted": 0.880475
          }
        ],
        "main_score": 0.533435,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1.3991012573242188,
  "kg_co2_emissions": null
}