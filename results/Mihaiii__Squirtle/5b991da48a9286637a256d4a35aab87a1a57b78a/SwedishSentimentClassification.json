{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.706738,
        "f1": 0.705071,
        "f1_weighted": 0.705023,
        "ap": 0.653855,
        "ap_weighted": 0.653855,
        "scores_per_experiment": [
          {
            "accuracy": 0.726562,
            "f1": 0.726328,
            "f1_weighted": 0.726304,
            "ap": 0.66937,
            "ap_weighted": 0.66937
          },
          {
            "accuracy": 0.696289,
            "f1": 0.69241,
            "f1_weighted": 0.692308,
            "ap": 0.649678,
            "ap_weighted": 0.649678
          },
          {
            "accuracy": 0.679688,
            "f1": 0.677866,
            "f1_weighted": 0.677795,
            "ap": 0.629539,
            "ap_weighted": 0.629539
          },
          {
            "accuracy": 0.701172,
            "f1": 0.698999,
            "f1_weighted": 0.698924,
            "ap": 0.651085,
            "ap_weighted": 0.651085
          },
          {
            "accuracy": 0.710449,
            "f1": 0.706783,
            "f1_weighted": 0.706687,
            "ap": 0.664131,
            "ap_weighted": 0.664131
          },
          {
            "accuracy": 0.674805,
            "f1": 0.673758,
            "f1_weighted": 0.673812,
            "ap": 0.616175,
            "ap_weighted": 0.616175
          },
          {
            "accuracy": 0.708984,
            "f1": 0.707152,
            "f1_weighted": 0.707084,
            "ap": 0.658104,
            "ap_weighted": 0.658104
          },
          {
            "accuracy": 0.741211,
            "f1": 0.741209,
            "f1_weighted": 0.741211,
            "ap": 0.679909,
            "ap_weighted": 0.679909
          },
          {
            "accuracy": 0.701172,
            "f1": 0.699517,
            "f1_weighted": 0.699451,
            "ap": 0.649816,
            "ap_weighted": 0.649816
          },
          {
            "accuracy": 0.727051,
            "f1": 0.726684,
            "f1_weighted": 0.726655,
            "ap": 0.67074,
            "ap_weighted": 0.67074
          }
        ],
        "main_score": 0.706738,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.712549,
        "f1": 0.710913,
        "f1_weighted": 0.710881,
        "ap": 0.659045,
        "ap_weighted": 0.659045,
        "scores_per_experiment": [
          {
            "accuracy": 0.719727,
            "f1": 0.71963,
            "f1_weighted": 0.71962,
            "ap": 0.661021,
            "ap_weighted": 0.661021
          },
          {
            "accuracy": 0.70752,
            "f1": 0.704074,
            "f1_weighted": 0.704011,
            "ap": 0.659902,
            "ap_weighted": 0.659902
          },
          {
            "accuracy": 0.700195,
            "f1": 0.697593,
            "f1_weighted": 0.697538,
            "ap": 0.650487,
            "ap_weighted": 0.650487
          },
          {
            "accuracy": 0.714355,
            "f1": 0.712206,
            "f1_weighted": 0.712157,
            "ap": 0.663901,
            "ap_weighted": 0.663901
          },
          {
            "accuracy": 0.710938,
            "f1": 0.707374,
            "f1_weighted": 0.707311,
            "ap": 0.6638,
            "ap_weighted": 0.6638
          },
          {
            "accuracy": 0.679688,
            "f1": 0.679148,
            "f1_weighted": 0.679173,
            "ap": 0.620591,
            "ap_weighted": 0.620591
          },
          {
            "accuracy": 0.70752,
            "f1": 0.705655,
            "f1_weighted": 0.705609,
            "ap": 0.656129,
            "ap_weighted": 0.656129
          },
          {
            "accuracy": 0.737793,
            "f1": 0.737765,
            "f1_weighted": 0.737771,
            "ap": 0.675263,
            "ap_weighted": 0.675263
          },
          {
            "accuracy": 0.710449,
            "f1": 0.708781,
            "f1_weighted": 0.708738,
            "ap": 0.658557,
            "ap_weighted": 0.658557
          },
          {
            "accuracy": 0.737305,
            "f1": 0.736903,
            "f1_weighted": 0.736883,
            "ap": 0.680804,
            "ap_weighted": 0.680804
          }
        ],
        "main_score": 0.712549,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 14.53947401046753,
  "kg_co2_emissions": 0.0004413690380453384
}