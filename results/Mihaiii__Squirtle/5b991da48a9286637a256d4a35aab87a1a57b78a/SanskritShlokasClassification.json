{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.612272,
        "f1": 0.615259,
        "f1_weighted": 0.616026,
        "scores_per_experiment": [
          {
            "accuracy": 0.610966,
            "f1": 0.611319,
            "f1_weighted": 0.614962
          },
          {
            "accuracy": 0.657963,
            "f1": 0.659198,
            "f1_weighted": 0.659749
          },
          {
            "accuracy": 0.639687,
            "f1": 0.643081,
            "f1_weighted": 0.643708
          },
          {
            "accuracy": 0.587467,
            "f1": 0.578995,
            "f1_weighted": 0.577405
          },
          {
            "accuracy": 0.655352,
            "f1": 0.661997,
            "f1_weighted": 0.661978
          },
          {
            "accuracy": 0.610966,
            "f1": 0.614963,
            "f1_weighted": 0.616407
          },
          {
            "accuracy": 0.631854,
            "f1": 0.627862,
            "f1_weighted": 0.628829
          },
          {
            "accuracy": 0.545692,
            "f1": 0.557007,
            "f1_weighted": 0.556182
          },
          {
            "accuracy": 0.616188,
            "f1": 0.622683,
            "f1_weighted": 0.623616
          },
          {
            "accuracy": 0.56658,
            "f1": 0.575482,
            "f1_weighted": 0.577422
          }
        ],
        "main_score": 0.612272,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.577083,
        "f1": 0.580583,
        "f1_weighted": 0.573027,
        "scores_per_experiment": [
          {
            "accuracy": 0.59375,
            "f1": 0.589466,
            "f1_weighted": 0.58994
          },
          {
            "accuracy": 0.5625,
            "f1": 0.559628,
            "f1_weighted": 0.55449
          },
          {
            "accuracy": 0.614583,
            "f1": 0.622917,
            "f1_weighted": 0.611719
          },
          {
            "accuracy": 0.5625,
            "f1": 0.568622,
            "f1_weighted": 0.552835
          },
          {
            "accuracy": 0.614583,
            "f1": 0.622452,
            "f1_weighted": 0.6084
          },
          {
            "accuracy": 0.53125,
            "f1": 0.537362,
            "f1_weighted": 0.533453
          },
          {
            "accuracy": 0.520833,
            "f1": 0.520734,
            "f1_weighted": 0.509614
          },
          {
            "accuracy": 0.604167,
            "f1": 0.614298,
            "f1_weighted": 0.603983
          },
          {
            "accuracy": 0.625,
            "f1": 0.630106,
            "f1_weighted": 0.627425
          },
          {
            "accuracy": 0.541667,
            "f1": 0.540248,
            "f1_weighted": 0.538415
          }
        ],
        "main_score": 0.577083,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 13.350868225097656,
  "kg_co2_emissions": 0.000382437601049348
}