{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.002008,
        "recall": 0.003009,
        "f1": 0.002011,
        "accuracy": 0.003009,
        "main_score": 0.002011,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007372,
        "recall": 0.028084,
        "f1": 0.009789,
        "accuracy": 0.028084,
        "main_score": 0.009789,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.006528,
        "recall": 0.01003,
        "f1": 0.007038,
        "accuracy": 0.01003,
        "main_score": 0.007038,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.02452,
        "recall": 0.056169,
        "f1": 0.027911,
        "accuracy": 0.056169,
        "main_score": 0.027911,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.00134,
        "recall": 0.003009,
        "f1": 0.001509,
        "accuracy": 0.003009,
        "main_score": 0.001509,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011533,
        "recall": 0.039117,
        "f1": 0.014687,
        "accuracy": 0.039117,
        "main_score": 0.014687,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.027287,
        "recall": 0.03009,
        "f1": 0.027759,
        "accuracy": 0.03009,
        "main_score": 0.027759,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022381,
        "recall": 0.062187,
        "f1": 0.027792,
        "accuracy": 0.062187,
        "main_score": 0.027792,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.023785,
        "recall": 0.028084,
        "f1": 0.024206,
        "accuracy": 0.028084,
        "main_score": 0.024206,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026068,
        "recall": 0.056169,
        "f1": 0.029861,
        "accuracy": 0.056169,
        "main_score": 0.029861,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012413,
        "recall": 0.034102,
        "f1": 0.015162,
        "accuracy": 0.034102,
        "main_score": 0.015162,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.006354,
        "recall": 0.013039,
        "f1": 0.006967,
        "accuracy": 0.013039,
        "main_score": 0.006967,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01534,
        "recall": 0.039117,
        "f1": 0.018218,
        "accuracy": 0.039117,
        "main_score": 0.018218,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.035814,
        "recall": 0.041123,
        "f1": 0.036589,
        "accuracy": 0.041123,
        "main_score": 0.036589,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027468,
        "recall": 0.080241,
        "f1": 0.034205,
        "accuracy": 0.080241,
        "main_score": 0.034205,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003866,
        "recall": 0.009027,
        "f1": 0.0043,
        "accuracy": 0.009027,
        "main_score": 0.0043,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015605,
        "recall": 0.038114,
        "f1": 0.018554,
        "accuracy": 0.038114,
        "main_score": 0.018554,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.003787,
        "recall": 0.007021,
        "f1": 0.004176,
        "accuracy": 0.007021,
        "main_score": 0.004176,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013721,
        "recall": 0.037111,
        "f1": 0.016805,
        "accuracy": 0.037111,
        "main_score": 0.016805,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002104,
        "recall": 0.005015,
        "f1": 0.002187,
        "accuracy": 0.005015,
        "main_score": 0.002187,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012991,
        "recall": 0.033099,
        "f1": 0.015599,
        "accuracy": 0.033099,
        "main_score": 0.015599,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.004158,
        "recall": 0.006018,
        "f1": 0.004269,
        "accuracy": 0.006018,
        "main_score": 0.004269,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022529,
        "recall": 0.05015,
        "f1": 0.027131,
        "accuracy": 0.05015,
        "main_score": 0.027131,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.01558,
        "recall": 0.022066,
        "f1": 0.016409,
        "accuracy": 0.022066,
        "main_score": 0.016409,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030655,
        "recall": 0.07322,
        "f1": 0.036869,
        "accuracy": 0.07322,
        "main_score": 0.036869,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.012455,
        "recall": 0.016048,
        "f1": 0.013028,
        "accuracy": 0.016048,
        "main_score": 0.013028,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025088,
        "recall": 0.059178,
        "f1": 0.029843,
        "accuracy": 0.059178,
        "main_score": 0.029843,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017228,
        "recall": 0.025075,
        "f1": 0.018153,
        "accuracy": 0.025075,
        "main_score": 0.018153,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.049947,
        "recall": 0.100301,
        "f1": 0.056979,
        "accuracy": 0.100301,
        "main_score": 0.056979,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.00925,
        "recall": 0.013039,
        "f1": 0.009405,
        "accuracy": 0.013039,
        "main_score": 0.009405,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015439,
        "recall": 0.045135,
        "f1": 0.019063,
        "accuracy": 0.045135,
        "main_score": 0.019063,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001811,
        "recall": 0.005015,
        "f1": 0.002178,
        "accuracy": 0.005015,
        "main_score": 0.002178,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01563,
        "recall": 0.036108,
        "f1": 0.018798,
        "accuracy": 0.036108,
        "main_score": 0.018798,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.003625,
        "recall": 0.006018,
        "f1": 0.003885,
        "accuracy": 0.006018,
        "main_score": 0.003885,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015585,
        "recall": 0.036108,
        "f1": 0.018102,
        "accuracy": 0.036108,
        "main_score": 0.018102,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 3e-06,
        "accuracy": 0.001003,
        "main_score": 3e-06,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003623,
        "recall": 0.013039,
        "f1": 0.004547,
        "accuracy": 0.013039,
        "main_score": 0.004547,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.00107,
        "recall": 0.003009,
        "f1": 0.001133,
        "accuracy": 0.003009,
        "main_score": 0.001133,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013973,
        "recall": 0.031093,
        "f1": 0.015979,
        "accuracy": 0.031093,
        "main_score": 0.015979,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.003012,
        "recall": 0.004012,
        "f1": 0.003014,
        "accuracy": 0.004012,
        "main_score": 0.003014,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015144,
        "recall": 0.037111,
        "f1": 0.018283,
        "accuracy": 0.037111,
        "main_score": 0.018283,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.002326,
        "recall": 0.005015,
        "f1": 0.002568,
        "accuracy": 0.005015,
        "main_score": 0.002568,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016132,
        "recall": 0.038114,
        "f1": 0.018543,
        "accuracy": 0.038114,
        "main_score": 0.018543,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001003,
        "f1": 6e-06,
        "accuracy": 0.001003,
        "main_score": 6e-06,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012932,
        "recall": 0.035105,
        "f1": 0.015488,
        "accuracy": 0.035105,
        "main_score": 0.015488,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001003,
        "f1": 3e-06,
        "accuracy": 0.001003,
        "main_score": 3e-06,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017725,
        "recall": 0.047141,
        "f1": 0.021851,
        "accuracy": 0.047141,
        "main_score": 0.021851,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.000253,
        "recall": 0.002006,
        "f1": 0.000406,
        "accuracy": 0.002006,
        "main_score": 0.000406,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020182,
        "recall": 0.048144,
        "f1": 0.024,
        "accuracy": 0.048144,
        "main_score": 0.024,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000385,
        "recall": 0.004012,
        "f1": 0.000655,
        "accuracy": 0.004012,
        "main_score": 0.000655,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015939,
        "recall": 0.043129,
        "f1": 0.019131,
        "accuracy": 0.043129,
        "main_score": 0.019131,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.002006,
        "recall": 0.002006,
        "f1": 0.002006,
        "accuracy": 0.002006,
        "main_score": 0.002006,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014322,
        "recall": 0.032096,
        "f1": 0.016865,
        "accuracy": 0.032096,
        "main_score": 0.016865,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.002006,
        "f1": 0.000673,
        "accuracy": 0.002006,
        "main_score": 0.000673,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016907,
        "recall": 0.036108,
        "f1": 0.019602,
        "accuracy": 0.036108,
        "main_score": 0.019602,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 3.8e-05,
        "recall": 0.002006,
        "f1": 7.4e-05,
        "accuracy": 0.002006,
        "main_score": 7.4e-05,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0023,
        "recall": 0.011033,
        "f1": 0.003001,
        "accuracy": 0.011033,
        "main_score": 0.003001,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.003037,
        "recall": 0.004941,
        "f1": 0.0031,
        "accuracy": 0.004941,
        "main_score": 0.0031,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010214,
        "recall": 0.032609,
        "f1": 0.013195,
        "accuracy": 0.032609,
        "main_score": 0.013195,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.008655,
        "recall": 0.012846,
        "f1": 0.009389,
        "accuracy": 0.012846,
        "main_score": 0.009389,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017618,
        "recall": 0.051383,
        "f1": 0.022319,
        "accuracy": 0.051383,
        "main_score": 0.022319,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.00333,
        "recall": 0.004941,
        "f1": 0.003529,
        "accuracy": 0.004941,
        "main_score": 0.003529,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013236,
        "recall": 0.040514,
        "f1": 0.016212,
        "accuracy": 0.040514,
        "main_score": 0.016212,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.009405,
        "recall": 0.01581,
        "f1": 0.01059,
        "accuracy": 0.01581,
        "main_score": 0.01059,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025002,
        "recall": 0.059289,
        "f1": 0.030074,
        "accuracy": 0.059289,
        "main_score": 0.030074,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.010383,
        "recall": 0.016798,
        "f1": 0.011482,
        "accuracy": 0.016798,
        "main_score": 0.011482,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023025,
        "recall": 0.067194,
        "f1": 0.028076,
        "accuracy": 0.067194,
        "main_score": 0.028076,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001991,
        "recall": 0.003953,
        "f1": 0.002006,
        "accuracy": 0.003953,
        "main_score": 0.002006,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011763,
        "recall": 0.035573,
        "f1": 0.015309,
        "accuracy": 0.035573,
        "main_score": 0.015309,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004602,
        "recall": 0.01087,
        "f1": 0.005035,
        "accuracy": 0.01087,
        "main_score": 0.005035,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011138,
        "recall": 0.02668,
        "f1": 0.01326,
        "accuracy": 0.02668,
        "main_score": 0.01326,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.026879,
        "recall": 0.032609,
        "f1": 0.027809,
        "accuracy": 0.032609,
        "main_score": 0.027809,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037348,
        "recall": 0.079051,
        "f1": 0.042808,
        "accuracy": 0.079051,
        "main_score": 0.042808,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000537,
        "recall": 0.005929,
        "f1": 0.000743,
        "accuracy": 0.005929,
        "main_score": 0.000743,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011036,
        "recall": 0.028656,
        "f1": 0.013042,
        "accuracy": 0.028656,
        "main_score": 0.013042,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002541,
        "recall": 0.005929,
        "f1": 0.002769,
        "accuracy": 0.005929,
        "main_score": 0.002769,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01002,
        "recall": 0.030632,
        "f1": 0.013094,
        "accuracy": 0.030632,
        "main_score": 0.013094,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.003191,
        "recall": 0.006917,
        "f1": 0.00368,
        "accuracy": 0.006917,
        "main_score": 0.00368,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020118,
        "recall": 0.031621,
        "f1": 0.022178,
        "accuracy": 0.031621,
        "main_score": 0.022178,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.006057,
        "recall": 0.009881,
        "f1": 0.006499,
        "accuracy": 0.009881,
        "main_score": 0.006499,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019897,
        "recall": 0.041502,
        "f1": 0.022632,
        "accuracy": 0.041502,
        "main_score": 0.022632,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.011216,
        "recall": 0.01581,
        "f1": 0.011894,
        "accuracy": 0.01581,
        "main_score": 0.011894,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027833,
        "recall": 0.060277,
        "f1": 0.032442,
        "accuracy": 0.060277,
        "main_score": 0.032442,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.009694,
        "recall": 0.013834,
        "f1": 0.010413,
        "accuracy": 0.013834,
        "main_score": 0.010413,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021088,
        "recall": 0.05336,
        "f1": 0.025773,
        "accuracy": 0.05336,
        "main_score": 0.025773,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.015156,
        "recall": 0.020751,
        "f1": 0.015709,
        "accuracy": 0.020751,
        "main_score": 0.015709,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030265,
        "recall": 0.070158,
        "f1": 0.035279,
        "accuracy": 0.070158,
        "main_score": 0.035279,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.003135,
        "recall": 0.004941,
        "f1": 0.003268,
        "accuracy": 0.004941,
        "main_score": 0.003268,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014753,
        "recall": 0.037549,
        "f1": 0.017677,
        "accuracy": 0.037549,
        "main_score": 0.017677,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003477,
        "recall": 0.004941,
        "f1": 0.00366,
        "accuracy": 0.004941,
        "main_score": 0.00366,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015644,
        "recall": 0.039526,
        "f1": 0.019033,
        "accuracy": 0.039526,
        "main_score": 0.019033,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.00137,
        "recall": 0.002964,
        "f1": 0.001581,
        "accuracy": 0.002964,
        "main_score": 0.001581,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008437,
        "recall": 0.032609,
        "f1": 0.01187,
        "accuracy": 0.032609,
        "main_score": 0.01187,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009602,
        "recall": 0.021739,
        "f1": 0.010942,
        "accuracy": 0.021739,
        "main_score": 0.010942,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.003175,
        "recall": 0.006917,
        "f1": 0.003319,
        "accuracy": 0.006917,
        "main_score": 0.003319,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010248,
        "recall": 0.030632,
        "f1": 0.012611,
        "accuracy": 0.030632,
        "main_score": 0.012611,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.003253,
        "recall": 0.004941,
        "f1": 0.003439,
        "accuracy": 0.004941,
        "main_score": 0.003439,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017133,
        "recall": 0.040514,
        "f1": 0.020059,
        "accuracy": 0.040514,
        "main_score": 0.020059,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.007119,
        "recall": 0.011858,
        "f1": 0.007273,
        "accuracy": 0.011858,
        "main_score": 0.007273,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016079,
        "recall": 0.043478,
        "f1": 0.019242,
        "accuracy": 0.043478,
        "main_score": 0.019242,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.003953,
        "f1": 0.001688,
        "accuracy": 0.003953,
        "main_score": 0.001688,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012673,
        "recall": 0.035573,
        "f1": 0.01558,
        "accuracy": 0.035573,
        "main_score": 0.01558,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.003501,
        "recall": 0.005929,
        "f1": 0.003706,
        "accuracy": 0.005929,
        "main_score": 0.003706,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016411,
        "recall": 0.039526,
        "f1": 0.019647,
        "accuracy": 0.039526,
        "main_score": 0.019647,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.004169,
        "recall": 0.005929,
        "f1": 0.004334,
        "accuracy": 0.005929,
        "main_score": 0.004334,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017572,
        "recall": 0.038538,
        "f1": 0.021028,
        "accuracy": 0.038538,
        "main_score": 0.021028,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.003077,
        "recall": 0.007905,
        "f1": 0.003609,
        "accuracy": 0.007905,
        "main_score": 0.003609,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010561,
        "recall": 0.030632,
        "f1": 0.012984,
        "accuracy": 0.030632,
        "main_score": 0.012984,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.00282,
        "recall": 0.004941,
        "f1": 0.003169,
        "accuracy": 0.004941,
        "main_score": 0.003169,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013599,
        "recall": 0.036561,
        "f1": 0.017075,
        "accuracy": 0.036561,
        "main_score": 0.017075,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.004306,
        "recall": 0.005929,
        "f1": 0.004494,
        "accuracy": 0.005929,
        "main_score": 0.004494,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016854,
        "recall": 0.038538,
        "f1": 0.020313,
        "accuracy": 0.038538,
        "main_score": 0.020313,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002837,
        "recall": 0.017787,
        "f1": 0.003943,
        "accuracy": 0.017787,
        "main_score": 0.003943,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 41.370349645614624,
  "kg_co2_emissions": 0.0013545159631819228
}