{
  "dataset_revision": "8ccc72e69e65f40c70e117d8b3c08306bb788b60",
  "task_name": "MasakhaNEWSClusteringS2S",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "v_measure": 0.45567,
        "v_measure_std": 0.447035,
        "v_measures": [
          1.0,
          0.045691,
          0.180454,
          0.052204,
          1.0
        ],
        "main_score": 0.45567,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ]
      },
      {
        "v_measure": 0.383198,
        "v_measure_std": 0.218146,
        "v_measures": [
          0.139059,
          0.586236,
          0.668042,
          0.375932,
          0.146721
        ],
        "main_score": 0.383198,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "v_measure": 0.48368,
        "v_measure_std": 0.289156,
        "v_measures": [
          1.0,
          0.150109,
          0.342112,
          0.561352,
          0.364826
        ],
        "main_score": 0.48368,
        "hf_subset": "fra",
        "languages": [
          "fra-Latn"
        ]
      },
      {
        "v_measure": 0.220577,
        "v_measure_std": 0.197352,
        "v_measures": [
          0.214429,
          0.006852,
          0.078211,
          0.224011,
          0.579383
        ],
        "main_score": 0.220577,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ]
      },
      {
        "v_measure": 0.349147,
        "v_measure_std": 0.363874,
        "v_measures": [
          0.046035,
          0.470545,
          0.010294,
          1.0,
          0.218861
        ],
        "main_score": 0.349147,
        "hf_subset": "ibo",
        "languages": [
          "ibo-Latn"
        ]
      },
      {
        "v_measure": 0.831844,
        "v_measure_std": 0.211269,
        "v_measures": [
          0.505118,
          0.654101,
          1.0,
          1.0,
          1.0
        ],
        "main_score": 0.831844,
        "hf_subset": "lin",
        "languages": [
          "lin-Latn"
        ]
      },
      {
        "v_measure": 0.435543,
        "v_measure_std": 0.464842,
        "v_measures": [
          0.006466,
          0.001437,
          1.0,
          1.0,
          0.169809
        ],
        "main_score": 0.435543,
        "hf_subset": "lug",
        "languages": [
          "lug-Latn"
        ]
      },
      {
        "v_measure": 0.254357,
        "v_measure_std": 0.377786,
        "v_measures": [
          0.184751,
          0.01376,
          1.0,
          0.029868,
          0.043407
        ],
        "main_score": 0.254357,
        "hf_subset": "orm",
        "languages": [
          "orm-Ethi"
        ]
      },
      {
        "v_measure": 0.799652,
        "v_measure_std": 0.225959,
        "v_measures": [
          0.401724,
          1.0,
          0.88953,
          0.707006,
          1.0
        ],
        "main_score": 0.799652,
        "hf_subset": "pcm",
        "languages": [
          "pcm-Latn"
        ]
      },
      {
        "v_measure": 0.55956,
        "v_measure_std": 0.369675,
        "v_measures": [
          0.248683,
          0.139973,
          1.0,
          0.409143,
          1.0
        ],
        "main_score": 0.55956,
        "hf_subset": "run",
        "languages": [
          "run-Latn"
        ]
      },
      {
        "v_measure": 0.469051,
        "v_measure_std": 0.444852,
        "v_measures": [
          1.0,
          0.295907,
          0.005543,
          0.043803,
          1.0
        ],
        "main_score": 0.469051,
        "hf_subset": "sna",
        "languages": [
          "sna-Latn"
        ]
      },
      {
        "v_measure": 0.308858,
        "v_measure_std": 0.358349,
        "v_measures": [
          0.215052,
          1.0,
          0.045301,
          0.018626,
          0.265312
        ],
        "main_score": 0.308858,
        "hf_subset": "som",
        "languages": [
          "som-Latn"
        ]
      },
      {
        "v_measure": 0.203623,
        "v_measure_std": 0.205715,
        "v_measures": [
          0.026281,
          0.08716,
          0.007175,
          0.511252,
          0.386245
        ],
        "main_score": 0.203623,
        "hf_subset": "swa",
        "languages": [
          "swa-Latn"
        ]
      },
      {
        "v_measure": 0.433011,
        "v_measure_std": 0.463483,
        "v_measures": [
          0.057043,
          1.0,
          0.018737,
          1.0,
          0.089273
        ],
        "main_score": 0.433011,
        "hf_subset": "tir",
        "languages": [
          "tir-Ethi"
        ]
      },
      {
        "v_measure": 0.229133,
        "v_measure_std": 0.385871,
        "v_measures": [
          0.027607,
          0.01833,
          0.028379,
          0.071351,
          1.0
        ],
        "main_score": 0.229133,
        "hf_subset": "xho",
        "languages": [
          "xho-Latn"
        ]
      },
      {
        "v_measure": 0.273114,
        "v_measure_std": 0.364562,
        "v_measures": [
          1.0,
          0.124324,
          0.067452,
          0.121349,
          0.052444
        ],
        "main_score": 0.273114,
        "hf_subset": "yor",
        "languages": [
          "yor-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 4.864746332168579,
  "kg_co2_emissions": 0.0002250271538859278
}