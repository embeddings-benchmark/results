{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "task_name": "MassiveScenarioClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.768323,
            "f1": 0.771952,
            "f1_weighted": 0.76642,
            "precision": 0.753226,
            "precision_weighted": 0.785861,
            "recall": 0.811371,
            "recall_weighted": 0.768323,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.732415,
            "f1": 0.73783,
            "f1_weighted": 0.730716,
            "precision": 0.721327,
            "precision_weighted": 0.764431,
            "recall": 0.791387,
            "recall_weighted": 0.732415,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.749631,
            "f1": 0.755306,
            "f1_weighted": 0.752668,
            "precision": 0.737492,
            "precision_weighted": 0.790673,
            "recall": 0.809679,
            "recall_weighted": 0.749631,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.70487,
            "f1": 0.718787,
            "f1_weighted": 0.707769,
            "precision": 0.707442,
            "precision_weighted": 0.753048,
            "recall": 0.768996,
            "recall_weighted": 0.70487,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.761928,
            "f1": 0.759966,
            "f1_weighted": 0.760272,
            "precision": 0.738462,
            "precision_weighted": 0.773722,
            "recall": 0.798539,
            "recall_weighted": 0.761928,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.739302,
            "f1": 0.744331,
            "f1_weighted": 0.735499,
            "precision": 0.721386,
            "precision_weighted": 0.758112,
            "recall": 0.796157,
            "recall_weighted": 0.739302,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.747664,
            "f1": 0.744069,
            "f1_weighted": 0.745615,
            "precision": 0.724606,
            "precision_weighted": 0.764801,
            "recall": 0.789279,
            "recall_weighted": 0.747664,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.706837,
            "f1": 0.72595,
            "f1_weighted": 0.704972,
            "precision": 0.706044,
            "precision_weighted": 0.743795,
            "recall": 0.786017,
            "recall_weighted": 0.706837,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.779636,
            "f1": 0.777405,
            "f1_weighted": 0.777166,
            "precision": 0.761764,
            "precision_weighted": 0.785863,
            "recall": 0.806096,
            "recall_weighted": 0.779636,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.740777,
            "f1": 0.752807,
            "f1_weighted": 0.739692,
            "precision": 0.733501,
            "precision_weighted": 0.779848,
            "recall": 0.809389,
            "recall_weighted": 0.740777,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.743138,
        "f1": 0.74884,
        "f1_weighted": 0.742079,
        "precision": 0.730525,
        "precision_weighted": 0.770015,
        "recall": 0.796691,
        "recall_weighted": 0.743138,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.743138,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.778077,
            "f1": 0.780803,
            "f1_weighted": 0.776709,
            "precision": 0.761258,
            "precision_weighted": 0.789327,
            "recall": 0.814249,
            "recall_weighted": 0.778077,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.735709,
            "f1": 0.744529,
            "f1_weighted": 0.732969,
            "precision": 0.730994,
            "precision_weighted": 0.763984,
            "recall": 0.790911,
            "recall_weighted": 0.735709,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.741089,
            "f1": 0.74877,
            "f1_weighted": 0.74019,
            "precision": 0.7253,
            "precision_weighted": 0.774752,
            "recall": 0.808118,
            "recall_weighted": 0.741089,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.710491,
            "f1": 0.720136,
            "f1_weighted": 0.710446,
            "precision": 0.705042,
            "precision_weighted": 0.745354,
            "recall": 0.765905,
            "recall_weighted": 0.710491,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.751513,
            "f1": 0.742866,
            "f1_weighted": 0.747482,
            "precision": 0.724275,
            "precision_weighted": 0.758469,
            "recall": 0.778739,
            "recall_weighted": 0.751513,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.751849,
            "f1": 0.750823,
            "f1_weighted": 0.748844,
            "precision": 0.72935,
            "precision_weighted": 0.76639,
            "recall": 0.794577,
            "recall_weighted": 0.751849,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.750168,
            "f1": 0.750869,
            "f1_weighted": 0.750229,
            "precision": 0.732359,
            "precision_weighted": 0.770288,
            "recall": 0.792257,
            "recall_weighted": 0.750168,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.714526,
            "f1": 0.725541,
            "f1_weighted": 0.713853,
            "precision": 0.705392,
            "precision_weighted": 0.752633,
            "recall": 0.785911,
            "recall_weighted": 0.714526,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.773033,
            "f1": 0.770559,
            "f1_weighted": 0.770938,
            "precision": 0.75411,
            "precision_weighted": 0.777107,
            "recall": 0.796555,
            "recall_weighted": 0.773033,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.737054,
            "f1": 0.747689,
            "f1_weighted": 0.734237,
            "precision": 0.729619,
            "precision_weighted": 0.765333,
            "recall": 0.799597,
            "recall_weighted": 0.737054,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.744351,
        "f1": 0.748258,
        "f1_weighted": 0.74259,
        "precision": 0.72977,
        "precision_weighted": 0.766364,
        "recall": 0.792682,
        "recall_weighted": 0.744351,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.744351,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 8.866099119186401,
  "kg_co2_emissions": null
}