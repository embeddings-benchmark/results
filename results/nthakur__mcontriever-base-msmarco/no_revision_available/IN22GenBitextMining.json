{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 38.759145736694336,
  "kg_co2_emissions": 0.001794438609347993,
  "mteb_version": "1.16.5",
  "scores": {
    "test": [
      {
        "accuracy": 0.8115234375,
        "f1": 0.7677364174836601,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.7677364174836601,
        "precision": 0.7501858181423611,
        "recall": 0.8115234375
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.1342617798867799,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.1342617798867799,
        "precision": 0.12304055662522231,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.3603515625,
        "f1": 0.29822607034778087,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.29822607034778087,
        "precision": 0.27942596708407597,
        "recall": 0.3603515625
      },
      {
        "accuracy": 0.640625,
        "f1": 0.5733282884650073,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.5733282884650073,
        "precision": 0.5485164777527859,
        "recall": 0.640625
      },
      {
        "accuracy": 0.3193359375,
        "f1": 0.2653834428736772,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.2653834428736772,
        "precision": 0.2487017377154096,
        "recall": 0.3193359375
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.22421927798833668,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.22421927798833668,
        "precision": 0.20805787365845957,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.5986328125,
        "f1": 0.5357669403079559,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.5357669403079559,
        "precision": 0.5152584015376984,
        "recall": 0.5986328125
      },
      {
        "accuracy": 0.3671875,
        "f1": 0.2939634791536966,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.2939634791536966,
        "precision": 0.2703767040629601,
        "recall": 0.3671875
      },
      {
        "accuracy": 0.171875,
        "f1": 0.12406376211657841,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.12406376211657841,
        "precision": 0.1114399893103456,
        "recall": 0.171875
      },
      {
        "accuracy": 0.474609375,
        "f1": 0.4072117804453512,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.4072117804453512,
        "precision": 0.3841877925020657,
        "recall": 0.474609375
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.2673250179023387,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.2673250179023387,
        "precision": 0.24978301835967853,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.427734375,
        "f1": 0.3624995464264765,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.3624995464264765,
        "precision": 0.3410855434170864,
        "recall": 0.427734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004358362268518518,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.004358362268518518,
        "precision": 0.003903119991987179,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.4743552291892135,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.4743552291892135,
        "precision": 0.45321416593389247,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0034313089977152478,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0034313089977152478,
        "precision": 0.0025936765907973738,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.3037109375,
        "f1": 0.24557700329184703,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.24557700329184703,
        "precision": 0.22677493405032467,
        "recall": 0.3037109375
      },
      {
        "accuracy": 0.369140625,
        "f1": 0.2990472100981637,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.2990472100981637,
        "precision": 0.27591263581253817,
        "recall": 0.369140625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.169600938967136e-06,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 9.169600938967136e-06,
        "precision": 4.606426886792453e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.240234375,
        "f1": 0.19131772632749194,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.19131772632749194,
        "precision": 0.17704253201997736,
        "recall": 0.240234375
      },
      {
        "accuracy": 0.3115234375,
        "f1": 0.2481215832778333,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.2481215832778333,
        "precision": 0.22931932704881924,
        "recall": 0.3115234375
      },
      {
        "accuracy": 0.630859375,
        "f1": 0.566803462921627,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.566803462921627,
        "precision": 0.5427501860119047,
        "recall": 0.630859375
      },
      {
        "accuracy": 0.3740234375,
        "f1": 0.3085855558669782,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.3085855558669782,
        "precision": 0.28775138029288416,
        "recall": 0.3740234375
      },
      {
        "accuracy": 0.783203125,
        "f1": 0.7361180865575396,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.7361180865575396,
        "precision": 0.7184826078869047,
        "recall": 0.783203125
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.1194609574225117,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.1194609574225117,
        "precision": 0.10909704092470618,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.4833984375,
        "f1": 0.41865597265700666,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.41865597265700666,
        "precision": 0.3977494516117563,
        "recall": 0.4833984375
      },
      {
        "accuracy": 0.935546875,
        "f1": 0.91650390625,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.91650390625,
        "precision": 0.90771484375,
        "recall": 0.935546875
      },
      {
        "accuracy": 0.3896484375,
        "f1": 0.32321042062084626,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.32321042062084626,
        "precision": 0.3027749756753663,
        "recall": 0.3896484375
      },
      {
        "accuracy": 0.4375,
        "f1": 0.37621807346185426,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.37621807346185426,
        "precision": 0.3575707293951023,
        "recall": 0.4375
      },
      {
        "accuracy": 0.7998046875,
        "f1": 0.7555262860352474,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.7555262860352474,
        "precision": 0.7380597795758929,
        "recall": 0.7998046875
      },
      {
        "accuracy": 0.5537109375,
        "f1": 0.4847345742365273,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.4847345742365273,
        "precision": 0.46175177042881543,
        "recall": 0.5537109375
      },
      {
        "accuracy": 0.248046875,
        "f1": 0.17768638741982556,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.17768638741982556,
        "precision": 0.15633432271200015,
        "recall": 0.248046875
      },
      {
        "accuracy": 0.62890625,
        "f1": 0.562204494724026,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.562204494724026,
        "precision": 0.5389385625225469,
        "recall": 0.62890625
      },
      {
        "accuracy": 0.421875,
        "f1": 0.3562814227974523,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.3562814227974523,
        "precision": 0.3351738032847293,
        "recall": 0.421875
      },
      {
        "accuracy": 0.5859375,
        "f1": 0.519021279104287,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.519021279104287,
        "precision": 0.4976012268981018,
        "recall": 0.5859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015453296703296703,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0015453296703296703,
        "precision": 0.0012958233173076923,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.70703125,
        "f1": 0.6440662202380953,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.6440662202380953,
        "precision": 0.6192760901915114,
        "recall": 0.70703125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004752604166666667,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.004752604166666667,
        "precision": 0.004503038194444444,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.4765625,
        "f1": 0.3949832862832633,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.3949832862832633,
        "precision": 0.36981624643547323,
        "recall": 0.4765625
      },
      {
        "accuracy": 0.4150390625,
        "f1": 0.3429175788917,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.3429175788917,
        "precision": 0.3187027152430063,
        "recall": 0.4150390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0022113045669705468,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0022113045669705468,
        "precision": 0.0017935295279045277,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.3271484375,
        "f1": 0.2697489383510179,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.2697489383510179,
        "precision": 0.2525515495132837,
        "recall": 0.3271484375
      },
      {
        "accuracy": 0.5478515625,
        "f1": 0.477997187274531,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.477997187274531,
        "precision": 0.45415468862734487,
        "recall": 0.5478515625
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.88564453125,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.88564453125,
        "precision": 0.873779296875,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.578125,
        "f1": 0.5115928766659066,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.5115928766659066,
        "precision": 0.4878315206928488,
        "recall": 0.578125
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.06694156567436645,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06694156567436645,
        "precision": 0.062434379371083114,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06658310033489927,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.06658310033489927,
        "precision": 0.06280855119191159,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.16965812711144965,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.16965812711144965,
        "precision": 0.162392321070375,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.04432438562073493,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.04432438562073493,
        "precision": 0.0418855424527055,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.14392216674280078,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.14392216674280078,
        "precision": 0.13723770531843216,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.06163466292547028,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.06163466292547028,
        "precision": 0.05793143728372621,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.12723163772123924,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.12723163772123924,
        "precision": 0.12285208499570245,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.029915985878156928,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.029915985878156928,
        "precision": 0.027182171455991673,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.060256440391041,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.060256440391041,
        "precision": 0.055495696201317606,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.11421894217802143,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.11421894217802143,
        "precision": 0.10950457665494605,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.05148655047134569,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.05148655047134569,
        "precision": 0.04878379528057441,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.0934421556432598,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.0934421556432598,
        "precision": 0.08983184536469734,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001978985229331846,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001978985229331846,
        "precision": 0.0015960141799878235,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.11106943201410499,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.11106943201410499,
        "precision": 0.10684949598536668,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00517578125,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00517578125,
        "precision": 0.004743303571428572,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.061844190296178235,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.061844190296178235,
        "precision": 0.05895493681545114,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.11920039318994644,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.11920039318994644,
        "precision": 0.11128346528042933,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004741753472222223,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004741753472222223,
        "precision": 0.004423595610119047,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.13993941771239235,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.13993941771239235,
        "precision": 0.1360283392950907,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.05525482711958131,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.05525482711958131,
        "precision": 0.04962039658521034,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.06377005741233822,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.06377005741233822,
        "precision": 0.060358674253939176,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.06239679905319494,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.06239679905319494,
        "precision": 0.058715220253167735,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.26427561584529646,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.26427561584529646,
        "precision": 0.24640950121040847,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.4013671875,
        "f1": 0.34731502915168466,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.34731502915168466,
        "precision": 0.33185019180894487,
        "recall": 0.4013671875
      },
      {
        "accuracy": 0.3212890625,
        "f1": 0.27343027794687946,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.27343027794687946,
        "precision": 0.25962111347853534,
        "recall": 0.3212890625
      },
      {
        "accuracy": 0.3701171875,
        "f1": 0.3221376524489317,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.3221376524489317,
        "precision": 0.30874732349581296,
        "recall": 0.3701171875
      },
      {
        "accuracy": 0.533203125,
        "f1": 0.47828295510912705,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.47828295510912705,
        "precision": 0.46006250422754325,
        "recall": 0.533203125
      },
      {
        "accuracy": 0.3388671875,
        "f1": 0.2815137987942138,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2815137987942138,
        "precision": 0.26532545816185826,
        "recall": 0.3388671875
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7888827589511183,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7888827589511183,
        "precision": 0.7779853591389878,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.294921875,
        "f1": 0.2343776788243473,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.2343776788243473,
        "precision": 0.21850779445191937,
        "recall": 0.294921875
      },
      {
        "accuracy": 0.2119140625,
        "f1": 0.16643429084093775,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.16643429084093775,
        "precision": 0.15503558527948966,
        "recall": 0.2119140625
      },
      {
        "accuracy": 0.7783203125,
        "f1": 0.7383572157009657,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7383572157009657,
        "precision": 0.7229735553075397,
        "recall": 0.7783203125
      },
      {
        "accuracy": 0.255859375,
        "f1": 0.20840937631008924,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.20840937631008924,
        "precision": 0.1958487142899482,
        "recall": 0.255859375
      },
      {
        "accuracy": 0.59765625,
        "f1": 0.5443965637067947,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5443965637067947,
        "precision": 0.5270499601747238,
        "recall": 0.59765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002201426588762115,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002201426588762115,
        "precision": 0.001689995659722222,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.685546875,
        "f1": 0.6420073342838738,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6420073342838738,
        "precision": 0.6280681288357357,
        "recall": 0.685546875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005309370303430763,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.005309370303430763,
        "precision": 0.004716486213406428,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.3994140625,
        "f1": 0.3523462011495083,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.3523462011495083,
        "precision": 0.33791356609932627,
        "recall": 0.3994140625
      },
      {
        "accuracy": 0.5126953125,
        "f1": 0.4524211044914919,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4524211044914919,
        "precision": 0.4315353704306802,
        "recall": 0.5126953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004015069068492781,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004015069068492781,
        "precision": 0.003317775974025974,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.6650390625,
        "f1": 0.6213013792847777,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6213013792847777,
        "precision": 0.6049455915178571,
        "recall": 0.6650390625
      },
      {
        "accuracy": 0.2724609375,
        "f1": 0.21402488730218786,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.21402488730218786,
        "precision": 0.19728179462845163,
        "recall": 0.2724609375
      },
      {
        "accuracy": 0.4423828125,
        "f1": 0.3915141082877063,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.3915141082877063,
        "precision": 0.3753265254168574,
        "recall": 0.4423828125
      },
      {
        "accuracy": 0.42578125,
        "f1": 0.3637911482862455,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.3637911482862455,
        "precision": 0.34526947468144453,
        "recall": 0.42578125
      },
      {
        "accuracy": 0.568359375,
        "f1": 0.48534388246302307,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.48534388246302307,
        "precision": 0.45646778893849205,
        "recall": 0.568359375
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.8930989583333333,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.8930989583333333,
        "precision": 0.882275390625,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.0894628208308945,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.0894628208308945,
        "precision": 0.07836582447968019,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.51171875,
        "f1": 0.43511523912171524,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.43511523912171524,
        "precision": 0.41013898278912925,
        "recall": 0.51171875
      },
      {
        "accuracy": 0.384765625,
        "f1": 0.3141822910317129,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.3141822910317129,
        "precision": 0.29222186640399533,
        "recall": 0.384765625
      },
      {
        "accuracy": 0.3935546875,
        "f1": 0.3221948038007766,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.3221948038007766,
        "precision": 0.3000957104485579,
        "recall": 0.3935546875
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.7983096168154762,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.7983096168154762,
        "precision": 0.7813732328869047,
        "recall": 0.83984375
      },
      {
        "accuracy": 0.529296875,
        "f1": 0.45369854866756804,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.45369854866756804,
        "precision": 0.42779357742652463,
        "recall": 0.529296875
      },
      {
        "accuracy": 0.306640625,
        "f1": 0.2314985345974368,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.2314985345974368,
        "precision": 0.20855656648811338,
        "recall": 0.306640625
      },
      {
        "accuracy": 0.609375,
        "f1": 0.5360468524531024,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.5360468524531024,
        "precision": 0.5097799986471861,
        "recall": 0.609375
      },
      {
        "accuracy": 0.4267578125,
        "f1": 0.35392914536699005,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.35392914536699005,
        "precision": 0.3309502097429306,
        "recall": 0.4267578125
      },
      {
        "accuracy": 0.572265625,
        "f1": 0.4986275633878331,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.4986275633878331,
        "precision": 0.4741513559140512,
        "recall": 0.572265625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004619436553030303,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.004619436553030303,
        "precision": 0.0037368122329059826,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.6962890625,
        "f1": 0.6389666719770544,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.6389666719770544,
        "precision": 0.6185942150297619,
        "recall": 0.6962890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003054295149383864,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.003054295149383864,
        "precision": 0.0026130445075757576,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.4638671875,
        "f1": 0.38268437020878426,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.38268437020878426,
        "precision": 0.3575071972489826,
        "recall": 0.4638671875
      },
      {
        "accuracy": 0.4462890625,
        "f1": 0.3644190421485343,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.3644190421485343,
        "precision": 0.33714034717452684,
        "recall": 0.4462890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0018105847434713275,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0018105847434713275,
        "precision": 0.0011579241071428571,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.2572312985738597,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.2572312985738597,
        "precision": 0.23656416283369408,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.5869140625,
        "f1": 0.5138392857142857,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.5138392857142857,
        "precision": 0.4889610596842904,
        "recall": 0.5869140625
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.948046875,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.948046875,
        "precision": 0.9427083333333334,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.71484375,
        "f1": 0.6544517169028888,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.6544517169028888,
        "precision": 0.6309364924355159,
        "recall": 0.71484375
      },
      {
        "accuracy": 0.2548828125,
        "f1": 0.20179631848493876,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.20179631848493876,
        "precision": 0.1886721499039036,
        "recall": 0.2548828125
      },
      {
        "accuracy": 0.3037109375,
        "f1": 0.2508697400144856,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2508697400144856,
        "precision": 0.23729090281181814,
        "recall": 0.3037109375
      },
      {
        "accuracy": 0.294921875,
        "f1": 0.24690888709700387,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.24690888709700387,
        "precision": 0.2319449024283009,
        "recall": 0.294921875
      },
      {
        "accuracy": 0.5419921875,
        "f1": 0.49189931513288593,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.49189931513288593,
        "precision": 0.4745452748748647,
        "recall": 0.5419921875
      },
      {
        "accuracy": 0.26171875,
        "f1": 0.21780494354794677,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.21780494354794677,
        "precision": 0.20626142244923082,
        "recall": 0.26171875
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.24683709640320245,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.24683709640320245,
        "precision": 0.23222819876807985,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.5498046875,
        "f1": 0.4994182297014328,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4994182297014328,
        "precision": 0.4850363971616991,
        "recall": 0.5498046875
      },
      {
        "accuracy": 0.24609375,
        "f1": 0.18581118976395497,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.18581118976395497,
        "precision": 0.16971305499727943,
        "recall": 0.24609375
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.12756361688321874,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.12756361688321874,
        "precision": 0.11617530101159829,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.54296875,
        "f1": 0.49234115788605276,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.49234115788605276,
        "precision": 0.47562262770820735,
        "recall": 0.54296875
      },
      {
        "accuracy": 0.255859375,
        "f1": 0.21114676625499795,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.21114676625499795,
        "precision": 0.19876135827063562,
        "recall": 0.255859375
      },
      {
        "accuracy": 0.724609375,
        "f1": 0.6807578299521659,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6807578299521659,
        "precision": 0.6654645051129426,
        "recall": 0.724609375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0027879637063570484,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0027879637063570484,
        "precision": 0.0018109386273448772,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.45703125,
        "f1": 0.4093314354995251,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4093314354995251,
        "precision": 0.39504291646683076,
        "recall": 0.45703125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004776278409090909,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.004776278409090909,
        "precision": 0.0034812264749649858,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.2763671875,
        "f1": 0.22918036865525399,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.22918036865525399,
        "precision": 0.21651475286436916,
        "recall": 0.2763671875
      },
      {
        "accuracy": 0.435546875,
        "f1": 0.38032599047409205,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.38032599047409205,
        "precision": 0.36380826273865935,
        "recall": 0.435546875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0025788326539855073,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0025788326539855073,
        "precision": 0.001984959859871749,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.43359375,
        "f1": 0.3820637408213035,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3820637408213035,
        "precision": 0.36596803098024916,
        "recall": 0.43359375
      },
      {
        "accuracy": 0.234375,
        "f1": 0.18507155506327808,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.18507155506327808,
        "precision": 0.17292035322014251,
        "recall": 0.234375
      },
      {
        "accuracy": 0.3369140625,
        "f1": 0.28157471979996107,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.28157471979996107,
        "precision": 0.2676073935868224,
        "recall": 0.3369140625
      },
      {
        "accuracy": 0.306640625,
        "f1": 0.24719735322950417,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.24719735322950417,
        "precision": 0.22917960488889763,
        "recall": 0.306640625
      },
      {
        "accuracy": 0.2958984375,
        "f1": 0.23618611152302557,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.23618611152302557,
        "precision": 0.21894737925377575,
        "recall": 0.2958984375
      },
      {
        "accuracy": 0.4130859375,
        "f1": 0.3412366640882266,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.3412366640882266,
        "precision": 0.320534661990889,
        "recall": 0.4130859375
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.11823946134726533,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.11823946134726533,
        "precision": 0.1070121632547329,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.3740234375,
        "f1": 0.3150791194807475,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.3150791194807475,
        "precision": 0.29748567058761977,
        "recall": 0.3740234375
      },
      {
        "accuracy": 0.359375,
        "f1": 0.2974411186330842,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.2974411186330842,
        "precision": 0.28024967124512357,
        "recall": 0.359375
      },
      {
        "accuracy": 0.3095703125,
        "f1": 0.2475136344966308,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.2475136344966308,
        "precision": 0.22996525772404677,
        "recall": 0.3095703125
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5475805634252899,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.5475805634252899,
        "precision": 0.5272462732418476,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.5126953125,
        "f1": 0.45017138794251255,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.45017138794251255,
        "precision": 0.4288918714935686,
        "recall": 0.5126953125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.10998268210275933,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.10998268210275933,
        "precision": 0.09978731443190395,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.392578125,
        "f1": 0.3272023394739962,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.3272023394739962,
        "precision": 0.3071438611843885,
        "recall": 0.392578125
      },
      {
        "accuracy": 0.4091796875,
        "f1": 0.34172432289677235,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.34172432289677235,
        "precision": 0.32108569503158196,
        "recall": 0.4091796875
      },
      {
        "accuracy": 0.501953125,
        "f1": 0.44271190550941303,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.44271190550941303,
        "precision": 0.4240759010849422,
        "recall": 0.501953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0028324839042395905,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0028324839042395905,
        "precision": 0.002312069847470238,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.4833984375,
        "f1": 0.42089919709805607,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.42089919709805607,
        "precision": 0.40127261760684474,
        "recall": 0.4833984375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001761658522917714,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.001761658522917714,
        "precision": 0.0014581293294164582,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.513671875,
        "f1": 0.4433211751510658,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.4433211751510658,
        "precision": 0.420023430329755,
        "recall": 0.513671875
      },
      {
        "accuracy": 0.3173828125,
        "f1": 0.25498603342673254,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.25498603342673254,
        "precision": 0.23568327018034047,
        "recall": 0.3173828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002956751476741324,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.002956751476741324,
        "precision": 0.0026503917948861935,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.291015625,
        "f1": 0.24450212692400194,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.24450212692400194,
        "precision": 0.2308155648243539,
        "recall": 0.291015625
      },
      {
        "accuracy": 0.3642578125,
        "f1": 0.3024938759217203,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.3024938759217203,
        "precision": 0.2833214864915994,
        "recall": 0.3642578125
      },
      {
        "accuracy": 0.3740234375,
        "f1": 0.31626154883514235,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.31626154883514235,
        "precision": 0.30063924132337383,
        "recall": 0.3740234375
      },
      {
        "accuracy": 0.4013671875,
        "f1": 0.34066373378049913,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.34066373378049913,
        "precision": 0.32152457997191886,
        "recall": 0.4013671875
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5495046945242258,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5495046945242258,
        "precision": 0.5218936011904762,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8069661458333334,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8069661458333334,
        "precision": 0.7897534919507576,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.25950736546439673,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.25950736546439673,
        "precision": 0.23749024740151492,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.86064453125,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.86064453125,
        "precision": 0.8460286458333334,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8396182105654761,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8396182105654761,
        "precision": 0.8256677404626623,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.6953125,
        "f1": 0.6342416914682539,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6342416914682539,
        "precision": 0.6108258928571428,
        "recall": 0.6953125
      },
      {
        "accuracy": 0.685546875,
        "f1": 0.6293534536210317,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6293534536210317,
        "precision": 0.6073687841021825,
        "recall": 0.685546875
      },
      {
        "accuracy": 0.6669921875,
        "f1": 0.6104195977633478,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6104195977633478,
        "precision": 0.5897999596974206,
        "recall": 0.6669921875
      },
      {
        "accuracy": 0.318359375,
        "f1": 0.24223305990884114,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.24223305990884114,
        "precision": 0.21867890087490388,
        "recall": 0.318359375
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9254557291666667,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9254557291666667,
        "precision": 0.9166666666666666,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.51953125,
        "f1": 0.4573888866125195,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4573888866125195,
        "precision": 0.43751440887671356,
        "recall": 0.51953125
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.8678571428571429,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8678571428571429,
        "precision": 0.8545735677083334,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0021182105654761903,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0021182105654761903,
        "precision": 0.0013811383928571427,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.93310546875,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.93310546875,
        "precision": 0.92529296875,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018117804276315788,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0018117804276315788,
        "precision": 0.0012028769841269842,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.7021484375,
        "f1": 0.6437695586046919,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6437695586046919,
        "precision": 0.6210958813864087,
        "recall": 0.7021484375
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6507533482142857,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.6507533482142857,
        "precision": 0.6262966579861111,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003143067185007974,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003143067185007974,
        "precision": 0.0024815312322125547,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6377108134920635,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6377108134920635,
        "precision": 0.6131618923611111,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5343046114042207,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5343046114042207,
        "precision": 0.5097559368799602,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8346214657738096,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8346214657738096,
        "precision": 0.8198513454861112,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6873458355880231,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6873458355880231,
        "precision": 0.6670817057291667,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.365234375,
        "f1": 0.2984546223612345,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.2984546223612345,
        "precision": 0.27807020543836947,
        "recall": 0.365234375
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.47284583252098183,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.47284583252098183,
        "precision": 0.4517780694782648,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.07359767699048456,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.07359767699048456,
        "precision": 0.06702397120795951,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.3125,
        "f1": 0.2570762604170758,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.2570762604170758,
        "precision": 0.23937766365861643,
        "recall": 0.3125
      },
      {
        "accuracy": 0.5849609375,
        "f1": 0.5218984943864158,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.5218984943864158,
        "precision": 0.5008118996888529,
        "recall": 0.5849609375
      },
      {
        "accuracy": 0.2509765625,
        "f1": 0.19841700910968363,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.19841700910968363,
        "precision": 0.18324976374034435,
        "recall": 0.2509765625
      },
      {
        "accuracy": 0.5498046875,
        "f1": 0.47668293620442054,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.47668293620442054,
        "precision": 0.449740393612464,
        "recall": 0.5498046875
      },
      {
        "accuracy": 0.625,
        "f1": 0.5606248441611492,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.5606248441611492,
        "precision": 0.537653556702629,
        "recall": 0.625
      },
      {
        "accuracy": 0.154296875,
        "f1": 0.1035444895566727,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.1035444895566727,
        "precision": 0.09225390213857403,
        "recall": 0.154296875
      },
      {
        "accuracy": 0.4150390625,
        "f1": 0.351868406116453,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.351868406116453,
        "precision": 0.3302372979854795,
        "recall": 0.4150390625
      },
      {
        "accuracy": 0.546875,
        "f1": 0.48392523275335775,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.48392523275335775,
        "precision": 0.4619048323638167,
        "recall": 0.546875
      },
      {
        "accuracy": 0.4970703125,
        "f1": 0.43389174372456407,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.43389174372456407,
        "precision": 0.41354764349149115,
        "recall": 0.4970703125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0020923768354984386,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0020923768354984386,
        "precision": 0.001612574106180315,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.45248958483950263,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.45248958483950263,
        "precision": 0.4308655060822092,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031985620905241293,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.0031985620905241293,
        "precision": 0.0027246973536036037,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.4326171875,
        "f1": 0.36551689759523726,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.36551689759523726,
        "precision": 0.34525239571626287,
        "recall": 0.4326171875
      },
      {
        "accuracy": 0.3486328125,
        "f1": 0.2839083646837791,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.2839083646837791,
        "precision": 0.26260663977949134,
        "recall": 0.3486328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001702796852752729,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.001702796852752729,
        "precision": 0.0013907169787627642,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.19389407614961446,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.19389407614961446,
        "precision": 0.17783793530433006,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.53515625,
        "f1": 0.4758623690953654,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.4758623690953654,
        "precision": 0.4554045374113734,
        "recall": 0.53515625
      },
      {
        "accuracy": 0.6962890625,
        "f1": 0.6397674581608006,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.6397674581608006,
        "precision": 0.6192154027804304,
        "recall": 0.6962890625
      },
      {
        "accuracy": 0.3740234375,
        "f1": 0.3069363193921618,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.3069363193921618,
        "precision": 0.28749572315852306,
        "recall": 0.3740234375
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.13119080472364805,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.13119080472364805,
        "precision": 0.12050087446620897,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.21875,
        "f1": 0.16921109556212982,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.16921109556212982,
        "precision": 0.15591823003420469,
        "recall": 0.21875
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.10544550775877201,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.10544550775877201,
        "precision": 0.09839545905763145,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.224609375,
        "f1": 0.18705857230007214,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.18705857230007214,
        "precision": 0.17588668810554092,
        "recall": 0.224609375
      },
      {
        "accuracy": 0.3115234375,
        "f1": 0.24928642546337942,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.24928642546337942,
        "precision": 0.2316841192609054,
        "recall": 0.3115234375
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.14693983613532097,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.14693983613532097,
        "precision": 0.13681111504597832,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.166015625,
        "f1": 0.12436436556573403,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.12436436556573403,
        "precision": 0.11370579778294623,
        "recall": 0.166015625
      },
      {
        "accuracy": 0.2587890625,
        "f1": 0.21144369024641296,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.21144369024641296,
        "precision": 0.19717537217769748,
        "recall": 0.2587890625
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.09083908250527047,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.09083908250527047,
        "precision": 0.08418991848952212,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.17825098219666688,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.17825098219666688,
        "precision": 0.1666676007196132,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.14006169661964601,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.14006169661964601,
        "precision": 0.13109709434565806,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.13834863549169066,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.13834863549169066,
        "precision": 0.1290018700688931,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004868861607142857,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.004868861607142857,
        "precision": 0.004503038194444445,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.17099525445831742,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.17099525445831742,
        "precision": 0.15771002440540308,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022624708850931675,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0022624708850931675,
        "precision": 0.001869035912004662,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1943359375,
        "f1": 0.14747625171592793,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.14747625171592793,
        "precision": 0.13501073449001563,
        "recall": 0.1943359375
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.13301827295967922,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.13301827295967922,
        "precision": 0.12328055800281215,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003888494318181818,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.003888494318181818,
        "precision": 0.00322265625,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.14058203361378763,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.14058203361378763,
        "precision": 0.13357190583881579,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.1669921875,
        "f1": 0.1251377552251038,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.1251377552251038,
        "precision": 0.11397823413204272,
        "recall": 0.1669921875
      },
      {
        "accuracy": 0.236328125,
        "f1": 0.19089058530062664,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.19089058530062664,
        "precision": 0.17801835187596715,
        "recall": 0.236328125
      },
      {
        "accuracy": 0.6640625,
        "f1": 0.6242071745838487,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.6242071745838487,
        "precision": 0.6108592804929633,
        "recall": 0.6640625
      },
      {
        "accuracy": 0.4404296875,
        "f1": 0.3627066200624335,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.3627066200624335,
        "precision": 0.33915206429854866,
        "recall": 0.4404296875
      },
      {
        "accuracy": 0.5400390625,
        "f1": 0.478157433748254,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.478157433748254,
        "precision": 0.45864470201384266,
        "recall": 0.5400390625
      },
      {
        "accuracy": 0.294921875,
        "f1": 0.24012331707249585,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.24012331707249585,
        "precision": 0.2236069679332683,
        "recall": 0.294921875
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8052408854166666,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8052408854166666,
        "precision": 0.7879882812500001,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.5400390625,
        "f1": 0.482610754958435,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.482610754958435,
        "precision": 0.46564586353189297,
        "recall": 0.5400390625
      },
      {
        "accuracy": 0.5966796875,
        "f1": 0.535960046897547,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.535960046897547,
        "precision": 0.5135342440762363,
        "recall": 0.5966796875
      },
      {
        "accuracy": 0.376953125,
        "f1": 0.31537376697904823,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.31537376697904823,
        "precision": 0.29872263598455695,
        "recall": 0.376953125
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8849469866071429,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8849469866071429,
        "precision": 0.8752224392361112,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.3623046875,
        "f1": 0.29797229983507767,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.29797229983507767,
        "precision": 0.28046729819776456,
        "recall": 0.3623046875
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.1520260900278557,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1520260900278557,
        "precision": 0.13858571752428026,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.296875,
        "f1": 0.23440905010410787,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.23440905010410787,
        "precision": 0.21720937568234033,
        "recall": 0.296875
      },
      {
        "accuracy": 0.7509765625,
        "f1": 0.7048619566197691,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7048619566197691,
        "precision": 0.688047016530797,
        "recall": 0.7509765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0021775891680782984,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0021775891680782984,
        "precision": 0.0016907935049019608,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.8475144159226191,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8475144159226191,
        "precision": 0.836182063379329,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004759657996061669,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.004759657996061669,
        "precision": 0.0041740657370335,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.375,
        "f1": 0.3115357422267887,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.3115357422267887,
        "precision": 0.29291954033080786,
        "recall": 0.375
      },
      {
        "accuracy": 0.6552734375,
        "f1": 0.5895508517090549,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.5895508517090549,
        "precision": 0.5658881645698052,
        "recall": 0.6552734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00114940009322652,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00114940009322652,
        "precision": 0.0007669132745893117,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.59375,
        "f1": 0.5342873706154956,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5342873706154956,
        "precision": 0.5138455669317916,
        "recall": 0.59375
      },
      {
        "accuracy": 0.3154296875,
        "f1": 0.2506196068854042,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.2506196068854042,
        "precision": 0.2321453897314134,
        "recall": 0.3154296875
      },
      {
        "accuracy": 0.5634765625,
        "f1": 0.5003899033581185,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5003899033581185,
        "precision": 0.48028102435701636,
        "recall": 0.5634765625
      },
      {
        "accuracy": 0.4716796875,
        "f1": 0.4081188948132307,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.4081188948132307,
        "precision": 0.38882391448165804,
        "recall": 0.4716796875
      },
      {
        "accuracy": 0.28125,
        "f1": 0.21914939108875775,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.21914939108875775,
        "precision": 0.20227807240502554,
        "recall": 0.28125
      },
      {
        "accuracy": 0.3955078125,
        "f1": 0.32970421819956486,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.32970421819956486,
        "precision": 0.3099559900180427,
        "recall": 0.3955078125
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.11113221981500933,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.11113221981500933,
        "precision": 0.09974866753000369,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.2919921875,
        "f1": 0.23043277232125675,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.23043277232125675,
        "precision": 0.21220785728970865,
        "recall": 0.2919921875
      },
      {
        "accuracy": 0.4345703125,
        "f1": 0.37392355565523794,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.37392355565523794,
        "precision": 0.3557192370172233,
        "recall": 0.4345703125
      },
      {
        "accuracy": 0.2509765625,
        "f1": 0.20869420423432944,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.20869420423432944,
        "precision": 0.19699570583637602,
        "recall": 0.2509765625
      },
      {
        "accuracy": 0.4326171875,
        "f1": 0.36639792611303923,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.36639792611303923,
        "precision": 0.34362196360799646,
        "recall": 0.4326171875
      },
      {
        "accuracy": 0.4931640625,
        "f1": 0.4376197552601928,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.4376197552601928,
        "precision": 0.41911745973153763,
        "recall": 0.4931640625
      },
      {
        "accuracy": 0.541015625,
        "f1": 0.4745308898298902,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.4745308898298902,
        "precision": 0.45223401313058365,
        "recall": 0.541015625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.11839283790537658,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.11839283790537658,
        "precision": 0.10759922437701513,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.298828125,
        "f1": 0.24055039184527374,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.24055039184527374,
        "precision": 0.22406635692245103,
        "recall": 0.298828125
      },
      {
        "accuracy": 0.3857421875,
        "f1": 0.33006553450889387,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.33006553450889387,
        "precision": 0.31278980893238706,
        "recall": 0.3857421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010208901383810364,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.0010208901383810364,
        "precision": 0.00099898614873581,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.369140625,
        "f1": 0.3135036958065421,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.3135036958065421,
        "precision": 0.29759515375174345,
        "recall": 0.369140625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003074781174966882,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.0003074781174966882,
        "precision": 0.00016808356868940725,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.34375,
        "f1": 0.29188163761675345,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.29188163761675345,
        "precision": 0.27575371416103345,
        "recall": 0.34375
      },
      {
        "accuracy": 0.2734375,
        "f1": 0.21809067948180852,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.21809067948180852,
        "precision": 0.20208572803787647,
        "recall": 0.2734375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001988002232142857,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.001988002232142857,
        "precision": 0.0019708806818181817,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.1705075245127934,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.1705075245127934,
        "precision": 0.1595226017381779,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.4833984375,
        "f1": 0.42622767857142857,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.42622767857142857,
        "precision": 0.4066541264164408,
        "recall": 0.4833984375
      },
      {
        "accuracy": 0.5185546875,
        "f1": 0.4670774895018626,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.4670774895018626,
        "precision": 0.4502675725125719,
        "recall": 0.5185546875
      },
      {
        "accuracy": 0.314453125,
        "f1": 0.25914638592646194,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.25914638592646194,
        "precision": 0.24340076299175184,
        "recall": 0.314453125
      },
      {
        "accuracy": 0.431640625,
        "f1": 0.3625881131130155,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.3625881131130155,
        "precision": 0.34031458590272856,
        "recall": 0.431640625
      },
      {
        "accuracy": 0.5595703125,
        "f1": 0.4937032347367073,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.4937032347367073,
        "precision": 0.4721946483421092,
        "recall": 0.5595703125
      },
      {
        "accuracy": 0.2724609375,
        "f1": 0.21747421957382895,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.21747421957382895,
        "precision": 0.20039107931743502,
        "recall": 0.2724609375
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.6149373372395833,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6149373372395833,
        "precision": 0.592804939516129,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.599609375,
        "f1": 0.5500530312786172,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5500530312786172,
        "precision": 0.5333609738536009,
        "recall": 0.599609375
      },
      {
        "accuracy": 0.794921875,
        "f1": 0.7474934895833333,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7474934895833333,
        "precision": 0.7286156063988095,
        "recall": 0.794921875
      },
      {
        "accuracy": 0.5791015625,
        "f1": 0.521816378066378,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.521816378066378,
        "precision": 0.5021386873547868,
        "recall": 0.5791015625
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8386695498511905,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8386695498511905,
        "precision": 0.8268530839819903,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.5224609375,
        "f1": 0.45961610355279936,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.45961610355279936,
        "precision": 0.4380971961333575,
        "recall": 0.5224609375
      },
      {
        "accuracy": 0.2080078125,
        "f1": 0.15053649854503534,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.15053649854503534,
        "precision": 0.13470050535655548,
        "recall": 0.2080078125
      },
      {
        "accuracy": 0.7626953125,
        "f1": 0.7103469826614358,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7103469826614358,
        "precision": 0.6892454117063491,
        "recall": 0.7626953125
      },
      {
        "accuracy": 0.416015625,
        "f1": 0.35233701745189205,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.35233701745189205,
        "precision": 0.33218830232990393,
        "recall": 0.416015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012788318452380952,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0012788318452380952,
        "precision": 0.0011404611013986013,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.8017578125,
        "f1": 0.7636058765453296,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7636058765453296,
        "precision": 0.7491535862141331,
        "recall": 0.8017578125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0033814817994505496,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0033814817994505496,
        "precision": 0.0024016584429824564,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.4775390625,
        "f1": 0.4104290891400266,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4104290891400266,
        "precision": 0.3887695420898546,
        "recall": 0.4775390625
      },
      {
        "accuracy": 0.650390625,
        "f1": 0.5901228309833549,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.5901228309833549,
        "precision": 0.5668819366939484,
        "recall": 0.650390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0028215049026150945,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0028215049026150945,
        "precision": 0.002186654747113841,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.45962520769161397,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.45962520769161397,
        "precision": 0.4392550998263889,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.4384765625,
        "f1": 0.3757024848989182,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3757024848989182,
        "precision": 0.3556841839800824,
        "recall": 0.4384765625
      },
      {
        "accuracy": 0.6103515625,
        "f1": 0.5535107924977374,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5535107924977374,
        "precision": 0.5336359603937729,
        "recall": 0.6103515625
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.4512635348974963,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.4512635348974963,
        "precision": 0.4285284019206641,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006385216346153846,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0006385216346153846,
        "precision": 0.00040690104166666663,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010669097583160083,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0010669097583160083,
        "precision": 0.0010228375204248364,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003876218933990036,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.003876218933990036,
        "precision": 0.003503721992014909,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002887384792626728,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.002887384792626728,
        "precision": 0.0025197692875999714,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0027437065972222225,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0027437065972222225,
        "precision": 0.002445132424041924,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0026225799663299664,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0026225799663299664,
        "precision": 0.0023781138876004947,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0029994419642857145,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0029994419642857145,
        "precision": 0.0029658564814814816,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0021158854166666665,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0021158854166666665,
        "precision": 0.0017903645833333333,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0025859757965686274,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0025859757965686274,
        "precision": 0.002075413573595147,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016424046331272892,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0016424046331272892,
        "precision": 0.0014722778755377802,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009112672252120025,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0009112672252120025,
        "precision": 0.0006281224808872478,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008843016229281768,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0008843016229281768,
        "precision": 0.0005723666176131116,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009353240116801437,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0009353240116801437,
        "precision": 0.0006536810247747748,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001953125,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.001953125,
        "precision": 0.001953125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.08021840897817459,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.08021840897817459,
        "precision": 0.07270856584821428,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012588795547779923,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0012588795547779923,
        "precision": 0.0008480065566835871,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009822733918128654,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0009822733918128654,
        "precision": 0.0009794263196480938,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.0668563544034988,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.0668563544034988,
        "precision": 0.06014462425595238,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015021932922694393,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0015021932922694393,
        "precision": 0.0012800695670378418,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007134331597222222,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0007134331597222222,
        "precision": 0.0005202690712791392,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001956143740340031,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.001956143740340031,
        "precision": 0.0019546367066563468,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007028674450549451,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0007028674450549451,
        "precision": 0.0005144518120633075,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.54296875,
        "f1": 0.470343501984127,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.470343501984127,
        "precision": 0.44429757254464286,
        "recall": 0.54296875
      },
      {
        "accuracy": 0.6806640625,
        "f1": 0.6185887051316739,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6185887051316739,
        "precision": 0.5952229817708333,
        "recall": 0.6806640625
      },
      {
        "accuracy": 0.3037109375,
        "f1": 0.24268684332160895,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.24268684332160895,
        "precision": 0.2235389790522488,
        "recall": 0.3037109375
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.7544596354166666,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7544596354166666,
        "precision": 0.7335774739583334,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.7255859375,
        "f1": 0.6719826831154956,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6719826831154956,
        "precision": 0.6523836650545635,
        "recall": 0.7255859375
      },
      {
        "accuracy": 0.59765625,
        "f1": 0.5338112435524545,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5338112435524545,
        "precision": 0.510149662078373,
        "recall": 0.59765625
      },
      {
        "accuracy": 0.5439453125,
        "f1": 0.47896864149305557,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.47896864149305557,
        "precision": 0.45691192759063853,
        "recall": 0.5439453125
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9253580729166666,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9253580729166666,
        "precision": 0.9175618489583333,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.544921875,
        "f1": 0.4720622954849347,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.4720622954849347,
        "precision": 0.4466536185054894,
        "recall": 0.544921875
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.17940576809102146,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.17940576809102146,
        "precision": 0.1627727807961034,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8864583333333333,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8864583333333333,
        "precision": 0.8744303385416666,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.4267578125,
        "f1": 0.3600935693378823,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3600935693378823,
        "precision": 0.33822015522454973,
        "recall": 0.4267578125
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.800530014690171,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.800530014690171,
        "precision": 0.7821858723958334,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0037977430555555555,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0037977430555555555,
        "precision": 0.003140536221590909,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003865610442546584,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.003865610442546584,
        "precision": 0.003205558186026936,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.5478515625,
        "f1": 0.48386117712289584,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.48386117712289584,
        "precision": 0.4619241733743687,
        "recall": 0.5478515625
      },
      {
        "accuracy": 0.6787109375,
        "f1": 0.6127533924408926,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.6127533924408926,
        "precision": 0.5856445312499999,
        "recall": 0.6787109375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002691033181179775,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002691033181179775,
        "precision": 0.0024209056421864517,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.548828125,
        "f1": 0.4841230600996226,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4841230600996226,
        "precision": 0.4594509657009657,
        "recall": 0.548828125
      },
      {
        "accuracy": 0.4931640625,
        "f1": 0.42111089323003387,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.42111089323003387,
        "precision": 0.39523499503968257,
        "recall": 0.4931640625
      },
      {
        "accuracy": 0.7294921875,
        "f1": 0.6741593295304233,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6741593295304233,
        "precision": 0.6532001500019078,
        "recall": 0.7294921875
      },
      {
        "accuracy": 0.603515625,
        "f1": 0.5346730770314754,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5346730770314754,
        "precision": 0.5080108286895396,
        "recall": 0.603515625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005426738336894586,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0005426738336894586,
        "precision": 0.000353351076007326,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008525661518788117,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0008525661518788117,
        "precision": 0.0005956484156162464,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019052542892156862,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0019052542892156862,
        "precision": 0.0015584309895833332,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00047940340909090914,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.00047940340909090914,
        "precision": 0.0002906436011904762,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0023763694789510005,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0023763694789510005,
        "precision": 0.0021933701670857394,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0030581405739379085,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0030581405739379085,
        "precision": 0.0029975517646416085,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.831000932960149e-05,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 5.831000932960149e-05,
        "precision": 2.9779790521978025e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00036554290589520537,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.00036554290589520537,
        "precision": 0.00019506451868883933,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0017864330432224961,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.0017864330432224961,
        "precision": 0.0011207601584022038,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001299305061640588,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.001299305061640588,
        "precision": 0.0011543547997598161,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00033182720173550377,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.00033182720173550377,
        "precision": 0.00018423338312455677,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.7870710784313725e-05,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 4.7870710784313725e-05,
        "precision": 2.4341902709359607e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008160784527972028,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0008160784527972028,
        "precision": 0.0005045572916666666,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.0817778087797619,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0817778087797619,
        "precision": 0.07455662003699506,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00120541351010101,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.00120541351010101,
        "precision": 0.0010968314743882738,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0023414687219227314,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.0023414687219227314,
        "precision": 0.0018670972040112665,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0033245218211206897,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0033245218211206897,
        "precision": 0.0031759373312634986,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.05359459550865801,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.05359459550865801,
        "precision": 0.04746533748255582,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003071376255580357,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.003071376255580357,
        "precision": 0.0030058988235926085,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002932937292013311,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.002932937292013311,
        "precision": 0.0029313151041666665,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009995404411764705,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0009995404411764705,
        "precision": 0.000988188244047619,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.330078125,
        "f1": 0.2623734635218611,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.2623734635218611,
        "precision": 0.24306058239465295,
        "recall": 0.330078125
      },
      {
        "accuracy": 0.431640625,
        "f1": 0.3666162866358179,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.3666162866358179,
        "precision": 0.34682921787413973,
        "recall": 0.431640625
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.14145386294541856,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.14145386294541856,
        "precision": 0.12781363002631507,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.48828125,
        "f1": 0.41789238200628004,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.41789238200628004,
        "precision": 0.3942122574690934,
        "recall": 0.48828125
      },
      {
        "accuracy": 0.4912109375,
        "f1": 0.4217511473284681,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.4217511473284681,
        "precision": 0.39912171026672977,
        "recall": 0.4912109375
      },
      {
        "accuracy": 0.33984375,
        "f1": 0.27718911034597715,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.27718911034597715,
        "precision": 0.25782539034061325,
        "recall": 0.33984375
      },
      {
        "accuracy": 0.6025390625,
        "f1": 0.5337999131944444,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.5337999131944444,
        "precision": 0.5074831039186508,
        "recall": 0.6025390625
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.6042538949765512,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.6042538949765512,
        "precision": 0.5800940135168651,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.458984375,
        "f1": 0.3865015348640542,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.3865015348640542,
        "precision": 0.36177302904982434,
        "recall": 0.458984375
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.16966068178527965,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.16966068178527965,
        "precision": 0.15421297277196866,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.4326171875,
        "f1": 0.3656504324668387,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.3656504324668387,
        "precision": 0.34363253770968616,
        "recall": 0.4326171875
      },
      {
        "accuracy": 0.421875,
        "f1": 0.3518934814100829,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.3518934814100829,
        "precision": 0.3280127041306008,
        "recall": 0.421875
      },
      {
        "accuracy": 0.5009765625,
        "f1": 0.43302309478205614,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.43302309478205614,
        "precision": 0.4095929827008929,
        "recall": 0.5009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001522841475938967,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.001522841475938967,
        "precision": 0.0013317298243226898,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.470582069668031,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.470582069668031,
        "precision": 0.4479379561410811,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011345880681818182,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.0011345880681818182,
        "precision": 0.0007080078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.2291593513589148,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.2291593513589148,
        "precision": 0.21110046908386754,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012989027183249566,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0012989027183249566,
        "precision": 0.0011611889365208757,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.359375,
        "f1": 0.3002968873574342,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.3002968873574342,
        "precision": 0.2822831763505591,
        "recall": 0.359375
      },
      {
        "accuracy": 0.4091796875,
        "f1": 0.3458924095424404,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.3458924095424404,
        "precision": 0.3249876903886555,
        "recall": 0.4091796875
      },
      {
        "accuracy": 0.458984375,
        "f1": 0.3966788154967503,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.3966788154967503,
        "precision": 0.377066056358623,
        "recall": 0.458984375
      },
      {
        "accuracy": 0.5068359375,
        "f1": 0.43497504174491763,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.43497504174491763,
        "precision": 0.41048368406766844,
        "recall": 0.5068359375
      },
      {
        "accuracy": 0.2578125,
        "f1": 0.20753130792308183,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.20753130792308183,
        "precision": 0.19516935458675416,
        "recall": 0.2578125
      },
      {
        "accuracy": 0.3046875,
        "f1": 0.25001129282676315,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.25001129282676315,
        "precision": 0.23461024300068598,
        "recall": 0.3046875
      },
      {
        "accuracy": 0.2255859375,
        "f1": 0.18329058725122455,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.18329058725122455,
        "precision": 0.17240729211432673,
        "recall": 0.2255859375
      },
      {
        "accuracy": 0.455078125,
        "f1": 0.4062804869965003,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4062804869965003,
        "precision": 0.39098791376221836,
        "recall": 0.455078125
      },
      {
        "accuracy": 0.2548828125,
        "f1": 0.22409858521983314,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.22409858521983314,
        "precision": 0.21493642186044395,
        "recall": 0.2548828125
      },
      {
        "accuracy": 0.376953125,
        "f1": 0.3266465077039901,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3266465077039901,
        "precision": 0.31317688827216356,
        "recall": 0.376953125
      },
      {
        "accuracy": 0.240234375,
        "f1": 0.19211883797279777,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.19211883797279777,
        "precision": 0.18110544156267558,
        "recall": 0.240234375
      },
      {
        "accuracy": 0.5419921875,
        "f1": 0.4910768226431513,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4910768226431513,
        "precision": 0.47637578725501095,
        "recall": 0.5419921875
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.19296975149493606,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.19296975149493606,
        "precision": 0.18023725298148696,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.140625,
        "f1": 0.10693835554438272,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.10693835554438272,
        "precision": 0.09900193719846638,
        "recall": 0.140625
      },
      {
        "accuracy": 0.5146484375,
        "f1": 0.459089983167808,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.459089983167808,
        "precision": 0.4421048249939078,
        "recall": 0.5146484375
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.15515995676266814,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.15515995676266814,
        "precision": 0.14518905903481022,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.51953125,
        "f1": 0.46953518859771093,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.46953518859771093,
        "precision": 0.4541790215184631,
        "recall": 0.51953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001519097222222222,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001519097222222222,
        "precision": 0.0010986328125,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.5166015625,
        "f1": 0.4702289702912904,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4702289702912904,
        "precision": 0.45695569424240934,
        "recall": 0.5166015625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004316638764880952,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.004316638764880952,
        "precision": 0.003529011630802949,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.2021484375,
        "f1": 0.16025180057789307,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.16025180057789307,
        "precision": 0.15052046167588418,
        "recall": 0.2021484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0025260743089457714,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0025260743089457714,
        "precision": 0.0019991629464285714,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.298828125,
        "f1": 0.2639798179668222,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2639798179668222,
        "precision": 0.25460873797742345,
        "recall": 0.298828125
      },
      {
        "accuracy": 0.1884765625,
        "f1": 0.1484013498067842,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1484013498067842,
        "precision": 0.13893117921995857,
        "recall": 0.1884765625
      },
      {
        "accuracy": 0.3203125,
        "f1": 0.2715977131797027,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.2715977131797027,
        "precision": 0.2588072873130355,
        "recall": 0.3203125
      },
      {
        "accuracy": 0.28125,
        "f1": 0.2227818076704396,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2227818076704396,
        "precision": 0.2063686073774826,
        "recall": 0.28125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012562144886363636,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0012562144886363636,
        "precision": 0.0011341559193121693,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001085119983310045,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.001085119983310045,
        "precision": 0.0010337052103879026,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003768382352941176,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.003768382352941176,
        "precision": 0.003517316017316017,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003909254807692308,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.003909254807692308,
        "precision": 0.003907754718798151,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0031497579225352114,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0031497579225352114,
        "precision": 0.0030532884747257053,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018479172531906906,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0018479172531906906,
        "precision": 0.0015885664525169204,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004561369171885873,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.004561369171885873,
        "precision": 0.004396574267782427,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001953125,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.001953125,
        "precision": 0.001953125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0034089527419599117,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0034089527419599117,
        "precision": 0.003219495970222715,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010389926527524418,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0010389926527524418,
        "precision": 0.0010084325218857634,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0028353585498296424,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0028353585498296424,
        "precision": 0.002524452947241183,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0026086566091954025,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0026086566091954025,
        "precision": 0.002118135560675883,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019725126378676468,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0019725126378676468,
        "precision": 0.00196287045417624,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05439712468521062,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.05439712468521062,
        "precision": 0.046942429315476195,
        "recall": 0.078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0029972926792976237,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0029972926792976237,
        "precision": 0.0029640527005021376,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.049138532366071436,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.049138532366071436,
        "precision": 0.044709934163059156,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030959481406810036,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0030959481406810036,
        "precision": 0.002531937913130406,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001372119633838384,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.001372119633838384,
        "precision": 0.0012231754351265823,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003094627743675595,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.003094627743675595,
        "precision": 0.003019557040375825,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000986328125,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.000986328125,
        "precision": 0.000981469849246231,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019558414464534075,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0019558414464534075,
        "precision": 0.001954485114902507,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0023698651760511065,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0023698651760511065,
        "precision": 0.0022104261510681347,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.20703125,
        "f1": 0.15916074893163465,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.15916074893163465,
        "precision": 0.14746113012968523,
        "recall": 0.20703125
      },
      {
        "accuracy": 0.25,
        "f1": 0.20772429084371222,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.20772429084371222,
        "precision": 0.19675536466954208,
        "recall": 0.25
      },
      {
        "accuracy": 0.2890625,
        "f1": 0.2526452162141275,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2526452162141275,
        "precision": 0.24096873991893522,
        "recall": 0.2890625
      },
      {
        "accuracy": 0.634765625,
        "f1": 0.5845017323532948,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5845017323532948,
        "precision": 0.5673771644644606,
        "recall": 0.634765625
      },
      {
        "accuracy": 0.25,
        "f1": 0.21146291071092754,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.21146291071092754,
        "precision": 0.2024925213527446,
        "recall": 0.25
      },
      {
        "accuracy": 0.4189453125,
        "f1": 0.37313097649028937,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.37313097649028937,
        "precision": 0.35904264762865246,
        "recall": 0.4189453125
      },
      {
        "accuracy": 0.2685546875,
        "f1": 0.21621781847571292,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.21621781847571292,
        "precision": 0.20263818507057002,
        "recall": 0.2685546875
      },
      {
        "accuracy": 0.576171875,
        "f1": 0.5268482332789954,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5268482332789954,
        "precision": 0.5119592047733323,
        "recall": 0.576171875
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.1676754272521851,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.1676754272521851,
        "precision": 0.1546172214064851,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.13715484541348028,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.13715484541348028,
        "precision": 0.12772394283857513,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.4755859375,
        "f1": 0.43197736107693296,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.43197736107693296,
        "precision": 0.41940552078491533,
        "recall": 0.4755859375
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.14488998117456434,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.14488998117456434,
        "precision": 0.13596457519169214,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.4296875,
        "f1": 0.37856442040407673,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.37856442040407673,
        "precision": 0.3630486457665604,
        "recall": 0.4296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001443938358000858,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001443938358000858,
        "precision": 0.0008820021898983952,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.4189453125,
        "f1": 0.36887984905992355,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.36887984905992355,
        "precision": 0.354896214453478,
        "recall": 0.4189453125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003977339477956254,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.003977339477956254,
        "precision": 0.0035698784722222225,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.2763671875,
        "f1": 0.22667612737120435,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.22667612737120435,
        "precision": 0.21258150572243908,
        "recall": 0.2763671875
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.29859236896325037,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.29859236896325037,
        "precision": 0.2828669066366233,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00499906994047619,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00499906994047619,
        "precision": 0.0037760416666666663,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1884765625,
        "f1": 0.14401018496698742,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.14401018496698742,
        "precision": 0.13174114058177613,
        "recall": 0.1884765625
      },
      {
        "accuracy": 0.2880859375,
        "f1": 0.24040283518676694,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.24040283518676694,
        "precision": 0.22653347389904865,
        "recall": 0.2880859375
      },
      {
        "accuracy": 0.294921875,
        "f1": 0.2477093832557275,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2477093832557275,
        "precision": 0.23566948225422718,
        "recall": 0.294921875
      },
      {
        "accuracy": 0.326171875,
        "f1": 0.25843699294986056,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.25843699294986056,
        "precision": 0.23754846720063105,
        "recall": 0.326171875
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.45853550204136134,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.45853550204136134,
        "precision": 0.43060906920770203,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.10838403039065403,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.10838403039065403,
        "precision": 0.09738026188221502,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.353515625,
        "f1": 0.29211704094516594,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.29211704094516594,
        "precision": 0.27287401454881927,
        "recall": 0.353515625
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.5617644889313484,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.5617644889313484,
        "precision": 0.5415470028018856,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.2822265625,
        "f1": 0.22472753212499308,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.22472753212499308,
        "precision": 0.20573421816643322,
        "recall": 0.2822265625
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.342921106129114,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.342921106129114,
        "precision": 0.3197776561546093,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.59375,
        "f1": 0.5275451182703443,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.5275451182703443,
        "precision": 0.5037547630321068,
        "recall": 0.59375
      },
      {
        "accuracy": 0.5712890625,
        "f1": 0.5067149105235043,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.5067149105235043,
        "precision": 0.4822687430841727,
        "recall": 0.5712890625
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.11854889101293117,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.11854889101293117,
        "precision": 0.10571093816791037,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.361328125,
        "f1": 0.2932304628263383,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.2932304628263383,
        "precision": 0.27073015999587113,
        "recall": 0.361328125
      },
      {
        "accuracy": 0.5166015625,
        "f1": 0.4523971568476968,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.4523971568476968,
        "precision": 0.43127477719762874,
        "recall": 0.5166015625
      },
      {
        "accuracy": 0.4658203125,
        "f1": 0.3932071698917402,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.3932071698917402,
        "precision": 0.3679371920020273,
        "recall": 0.4658203125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017708000319693095,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0017708000319693095,
        "precision": 0.0012147192861519608,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.5126953125,
        "f1": 0.4466572110615079,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.4466572110615079,
        "precision": 0.42225713468389253,
        "recall": 0.5126953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009957449776785716,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.0009957449776785716,
        "precision": 0.0006298859009329538,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.419921875,
        "f1": 0.34681243235930737,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.34681243235930737,
        "precision": 0.3222435360863095,
        "recall": 0.419921875
      },
      {
        "accuracy": 0.296875,
        "f1": 0.239894820872542,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.239894820872542,
        "precision": 0.22284186824196642,
        "recall": 0.296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003191654265873016,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.003191654265873016,
        "precision": 0.0027142857142857142,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.2392578125,
        "f1": 0.18624250369855838,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.18624250369855838,
        "precision": 0.17094215063009371,
        "recall": 0.2392578125
      },
      {
        "accuracy": 0.662109375,
        "f1": 0.5995209001068376,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.5995209001068376,
        "precision": 0.5782400948660714,
        "recall": 0.662109375
      },
      {
        "accuracy": 0.41015625,
        "f1": 0.3515630340898057,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.3515630340898057,
        "precision": 0.3332988498429675,
        "recall": 0.41015625
      },
      {
        "accuracy": 0.626953125,
        "f1": 0.5546287371482683,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.5546287371482683,
        "precision": 0.5273182085926227,
        "recall": 0.626953125
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8884114583333333,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.8884114583333333,
        "precision": 0.8765462239583333,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.13577255535263347,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.13577255535263347,
        "precision": 0.12162582872601255,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.47159598214285714,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.47159598214285714,
        "precision": 0.4433404215142496,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9703776041666667,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9703776041666667,
        "precision": 0.966796875,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.4326171875,
        "f1": 0.35572381177849927,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.35572381177849927,
        "precision": 0.3302886918853716,
        "recall": 0.4326171875
      },
      {
        "accuracy": 0.48828125,
        "f1": 0.414831505427783,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.414831505427783,
        "precision": 0.3893110443159271,
        "recall": 0.48828125
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.794091796875,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.794091796875,
        "precision": 0.7767345610119047,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.6552743534677128,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.6552743534677128,
        "precision": 0.6363071986607143,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.287109375,
        "f1": 0.21557212860923797,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.21557212860923797,
        "precision": 0.19312615186207788,
        "recall": 0.287109375
      },
      {
        "accuracy": 0.646484375,
        "f1": 0.5776832921852453,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.5776832921852453,
        "precision": 0.5516276041666666,
        "recall": 0.646484375
      },
      {
        "accuracy": 0.5478515625,
        "f1": 0.48446824508068215,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.48446824508068215,
        "precision": 0.4630248007201132,
        "recall": 0.5478515625
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5387007341999299,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.5387007341999299,
        "precision": 0.5155410764907835,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002651803861788618,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.002651803861788618,
        "precision": 0.0024658203125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.6920130650599401,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.6920130650599401,
        "precision": 0.6670735677083334,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003679523601398601,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.003679523601398601,
        "precision": 0.0030749317956349207,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.5068359375,
        "f1": 0.43167361779781355,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.43167361779781355,
        "precision": 0.4065109681442689,
        "recall": 0.5068359375
      },
      {
        "accuracy": 0.46484375,
        "f1": 0.38875925181589244,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.38875925181589244,
        "precision": 0.36326775618767804,
        "recall": 0.46484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0030947730654761908,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0030947730654761908,
        "precision": 0.002344172754329004,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.28101550493266947,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.28101550493266947,
        "precision": 0.2592432896693151,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.650390625,
        "f1": 0.5855934411024025,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.5855934411024025,
        "precision": 0.5612996419270834,
        "recall": 0.650390625
      },
      {
        "accuracy": 0.6416015625,
        "f1": 0.5724168301316739,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.5724168301316739,
        "precision": 0.5473567285579004,
        "recall": 0.6416015625
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.34178405958191116,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.34178405958191116,
        "precision": 0.31782466123286435,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.5966796875,
        "f1": 0.5311381389176081,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.5311381389176081,
        "precision": 0.5086435821665314,
        "recall": 0.5966796875
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.13022159760698,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.13022159760698,
        "precision": 0.11902602334731241,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.5244140625,
        "f1": 0.46127363305097685,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.46127363305097685,
        "precision": 0.4382936860231782,
        "recall": 0.5244140625
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6888443939957611,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.6888443939957611,
        "precision": 0.6688755336460415,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.365234375,
        "f1": 0.30532353017961567,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.30532353017961567,
        "precision": 0.28684416526341894,
        "recall": 0.365234375
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.41038949115120993,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.41038949115120993,
        "precision": 0.38731706390397797,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.7470703125,
        "f1": 0.6960664181036998,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.6960664181036998,
        "precision": 0.6756318591889882,
        "recall": 0.7470703125
      },
      {
        "accuracy": 0.4365234375,
        "f1": 0.36116084069754795,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.36116084069754795,
        "precision": 0.335608632361562,
        "recall": 0.4365234375
      },
      {
        "accuracy": 0.728515625,
        "f1": 0.6678610885642136,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.6678610885642136,
        "precision": 0.6431396484375,
        "recall": 0.728515625
      },
      {
        "accuracy": 0.5244140625,
        "f1": 0.4567401700946623,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.4567401700946623,
        "precision": 0.4320249068308793,
        "recall": 0.5244140625
      },
      {
        "accuracy": 0.3955078125,
        "f1": 0.3296350259754865,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.3296350259754865,
        "precision": 0.30824663346636005,
        "recall": 0.3955078125
      },
      {
        "accuracy": 0.5068359375,
        "f1": 0.44105448316874096,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.44105448316874096,
        "precision": 0.4196459573412698,
        "recall": 0.5068359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003231412950779727,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.003231412950779727,
        "precision": 0.0025001345369122492,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.6181640625,
        "f1": 0.5521826101415945,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.5521826101415945,
        "precision": 0.5280408474988554,
        "recall": 0.6181640625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0035979626225490194,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0035979626225490194,
        "precision": 0.003042120682565789,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.47071075625763126,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.47071075625763126,
        "precision": 0.44635647545501456,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.4013671875,
        "f1": 0.3292367913975644,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.3292367913975644,
        "precision": 0.30524759975012733,
        "recall": 0.4013671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020872790404040404,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0020872790404040404,
        "precision": 0.0016357421875,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.3671875,
        "f1": 0.3139757124157823,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.3139757124157823,
        "precision": 0.2979375559222393,
        "recall": 0.3671875
      },
      {
        "accuracy": 0.44921875,
        "f1": 0.37906439512884826,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.37906439512884826,
        "precision": 0.35543811115100177,
        "recall": 0.44921875
      },
      {
        "accuracy": 0.63671875,
        "f1": 0.5739374701202595,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.5739374701202595,
        "precision": 0.5507291279141866,
        "recall": 0.63671875
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}