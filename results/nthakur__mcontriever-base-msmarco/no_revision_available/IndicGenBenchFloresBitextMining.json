{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 295.2810814380646,
  "kg_co2_emissions": 0.014234545749038537,
  "mteb_version": "1.16.5",
  "scores": {
    "test": [
      {
        "accuracy": 0.9535573122529645,
        "f1": 0.9387351778656127,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9387351778656127,
        "precision": 0.9314888010540185,
        "recall": 0.9535573122529645
      },
      {
        "accuracy": 0.8932806324110671,
        "f1": 0.8624505928853754,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.8624505928853754,
        "precision": 0.8484299516908212,
        "recall": 0.8932806324110671
      },
      {
        "accuracy": 0.3784584980237154,
        "f1": 0.3207111565058551,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.3207111565058551,
        "precision": 0.305289288746346,
        "recall": 0.3784584980237154
      },
      {
        "accuracy": 0.4061264822134387,
        "f1": 0.3232516073832047,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.3232516073832047,
        "precision": 0.2985949358805962,
        "recall": 0.4061264822134387
      },
      {
        "accuracy": 0.8705533596837944,
        "f1": 0.8363142292490119,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8363142292490119,
        "precision": 0.8213862224731789,
        "recall": 0.8705533596837944
      },
      {
        "accuracy": 0.7430830039525692,
        "f1": 0.6794169104939856,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.6794169104939856,
        "precision": 0.6542199949808646,
        "recall": 0.7430830039525692
      },
      {
        "accuracy": 0.599802371541502,
        "f1": 0.5356139742997451,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.5356139742997451,
        "precision": 0.5148895543411354,
        "recall": 0.599802371541502
      },
      {
        "accuracy": 0.5365612648221344,
        "f1": 0.4577767451038202,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.4577767451038202,
        "precision": 0.43270630884267247,
        "recall": 0.5365612648221344
      },
      {
        "accuracy": 0.45849802371541504,
        "f1": 0.39055185854427377,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.39055185854427377,
        "precision": 0.37002444145607755,
        "recall": 0.45849802371541504
      },
      {
        "accuracy": 0.4367588932806324,
        "f1": 0.34835420571846615,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.34835420571846615,
        "precision": 0.32006669825260525,
        "recall": 0.4367588932806324
      },
      {
        "accuracy": 0.5592885375494071,
        "f1": 0.500973313028649,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.500973313028649,
        "precision": 0.48168996956052296,
        "recall": 0.5592885375494071
      },
      {
        "accuracy": 0.5355731225296443,
        "f1": 0.45343389944419016,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.45343389944419016,
        "precision": 0.4248512439470937,
        "recall": 0.5355731225296443
      },
      {
        "accuracy": 0.6600790513833992,
        "f1": 0.5980126866984574,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.5980126866984574,
        "precision": 0.5752097841771754,
        "recall": 0.6600790513833992
      },
      {
        "accuracy": 0.5642292490118577,
        "f1": 0.48537605071695983,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.48537605071695983,
        "precision": 0.45982616965818546,
        "recall": 0.5642292490118577
      },
      {
        "accuracy": 0.9733201581027668,
        "f1": 0.9645915678524374,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9645915678524374,
        "precision": 0.9603096179183136,
        "recall": 0.9733201581027668
      },
      {
        "accuracy": 0.9219367588932806,
        "f1": 0.8990636175418784,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8990636175418784,
        "precision": 0.8889163372859025,
        "recall": 0.9219367588932806
      },
      {
        "accuracy": 0.6482213438735178,
        "f1": 0.5862645843783951,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.5862645843783951,
        "precision": 0.5639474323985193,
        "recall": 0.6482213438735178
      },
      {
        "accuracy": 0.591897233201581,
        "f1": 0.5123542739649459,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.5123542739649459,
        "precision": 0.48376460496025714,
        "recall": 0.591897233201581
      },
      {
        "accuracy": 0.4881422924901186,
        "f1": 0.41433597693479113,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.41433597693479113,
        "precision": 0.38847189488730133,
        "recall": 0.4881422924901186
      },
      {
        "accuracy": 0.4308300395256917,
        "f1": 0.34552732291862726,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.34552732291862726,
        "precision": 0.31869588744588745,
        "recall": 0.4308300395256917
      },
      {
        "accuracy": 0.49407114624505927,
        "f1": 0.4417496834420044,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.4417496834420044,
        "precision": 0.4254197036272864,
        "recall": 0.49407114624505927
      },
      {
        "accuracy": 0.5227272727272727,
        "f1": 0.4395469594086195,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.4395469594086195,
        "precision": 0.4103045276173618,
        "recall": 0.5227272727272727
      },
      {
        "accuracy": 0.7361660079051383,
        "f1": 0.6820041892670351,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6820041892670351,
        "precision": 0.6605303814542944,
        "recall": 0.7361660079051383
      },
      {
        "accuracy": 0.6363636363636364,
        "f1": 0.5571835169661257,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.5571835169661257,
        "precision": 0.5275844982860792,
        "recall": 0.6363636363636364
      },
      {
        "accuracy": 0.07707509881422925,
        "f1": 0.06220147827154074,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.06220147827154074,
        "precision": 0.05774170658063939,
        "recall": 0.07707509881422925
      },
      {
        "accuracy": 0.09683794466403162,
        "f1": 0.05495867840755504,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.05495867840755504,
        "precision": 0.046222630711450295,
        "recall": 0.09683794466403162
      },
      {
        "accuracy": 0.5069169960474308,
        "f1": 0.4452540015978751,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.4452540015978751,
        "precision": 0.4249967195739108,
        "recall": 0.5069169960474308
      },
      {
        "accuracy": 0.4515810276679842,
        "f1": 0.3728576923735026,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.3728576923735026,
        "precision": 0.34861664369627626,
        "recall": 0.4515810276679842
      },
      {
        "accuracy": 0.283596837944664,
        "f1": 0.24386661500599627,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.24386661500599627,
        "precision": 0.23105719808478634,
        "recall": 0.283596837944664
      },
      {
        "accuracy": 0.3181818181818182,
        "f1": 0.23517406861396634,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.23517406861396634,
        "precision": 0.20947996036681807,
        "recall": 0.3181818181818182
      },
      {
        "accuracy": 0.4209486166007905,
        "f1": 0.3538532554714532,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.3538532554714532,
        "precision": 0.33426867806124505,
        "recall": 0.4209486166007905
      },
      {
        "accuracy": 0.41798418972332013,
        "f1": 0.3303389271027611,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.3303389271027611,
        "precision": 0.3026346046355928,
        "recall": 0.41798418972332013
      },
      {
        "accuracy": 0.6936758893280632,
        "f1": 0.6425124557041553,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6425124557041553,
        "precision": 0.6247693602943759,
        "recall": 0.6936758893280632
      },
      {
        "accuracy": 0.6324110671936759,
        "f1": 0.5546583850931677,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.5546583850931677,
        "precision": 0.5261775115530056,
        "recall": 0.6324110671936759
      },
      {
        "accuracy": 0.6758893280632411,
        "f1": 0.6245440341767179,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6245440341767179,
        "precision": 0.6061833715446248,
        "recall": 0.6758893280632411
      },
      {
        "accuracy": 0.6472332015810277,
        "f1": 0.5690380875163484,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.5690380875163484,
        "precision": 0.5394186429512516,
        "recall": 0.6472332015810277
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.0237183603023038,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.0237183603023038,
        "precision": 0.02286310024663452,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.05533596837944664,
        "f1": 0.022166853368369217,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.022166853368369217,
        "precision": 0.0172986361631987,
        "recall": 0.05533596837944664
      },
      {
        "accuracy": 0.06422924901185771,
        "f1": 0.0455618754739268,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0455618754739268,
        "precision": 0.04259230833940452,
        "recall": 0.06422924901185771
      },
      {
        "accuracy": 0.11462450592885376,
        "f1": 0.0704331189335282,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.0704331189335282,
        "precision": 0.05994821219623591,
        "recall": 0.11462450592885376
      },
      {
        "accuracy": 0.6037549407114624,
        "f1": 0.5535199890111787,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5535199890111787,
        "precision": 0.5361224906471334,
        "recall": 0.6037549407114624
      },
      {
        "accuracy": 0.6017786561264822,
        "f1": 0.5228473327287557,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.5228473327287557,
        "precision": 0.4954072268504958,
        "recall": 0.6017786561264822
      },
      {
        "accuracy": 0.26679841897233203,
        "f1": 0.22256508287466312,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.22256508287466312,
        "precision": 0.21050014506169729,
        "recall": 0.26679841897233203
      },
      {
        "accuracy": 0.3231225296442688,
        "f1": 0.2414298914743579,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.2414298914743579,
        "precision": 0.21793462442730055,
        "recall": 0.3231225296442688
      },
      {
        "accuracy": 0.6393280632411067,
        "f1": 0.5901918931916107,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5901918931916107,
        "precision": 0.5735051458945611,
        "recall": 0.6393280632411067
      },
      {
        "accuracy": 0.5928853754940712,
        "f1": 0.5148457949373281,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.5148457949373281,
        "precision": 0.4867059927336607,
        "recall": 0.5928853754940712
      },
      {
        "accuracy": 0.5938735177865613,
        "f1": 0.5401172580388548,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5401172580388548,
        "precision": 0.5225643200557388,
        "recall": 0.5938735177865613
      },
      {
        "accuracy": 0.5770750988142292,
        "f1": 0.49387672604075766,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.49387672604075766,
        "precision": 0.4633404053320933,
        "recall": 0.5770750988142292
      },
      {
        "accuracy": 0.5869565217391305,
        "f1": 0.5366326555580103,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5366326555580103,
        "precision": 0.5203786812733985,
        "recall": 0.5869565217391305
      },
      {
        "accuracy": 0.558300395256917,
        "f1": 0.47605487397977514,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.47605487397977514,
        "precision": 0.4482625877635759,
        "recall": 0.558300395256917
      },
      {
        "accuracy": 0.09189723320158102,
        "f1": 0.06889323605348947,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.06889323605348947,
        "precision": 0.06350264380776803,
        "recall": 0.09189723320158102
      },
      {
        "accuracy": 0.11363636363636363,
        "f1": 0.06924326693105919,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.06924326693105919,
        "precision": 0.058804251013911554,
        "recall": 0.11363636363636363
      },
      {
        "accuracy": 0.6274703557312253,
        "f1": 0.5771562280269784,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5771562280269784,
        "precision": 0.5598010958440598,
        "recall": 0.6274703557312253
      },
      {
        "accuracy": 0.607707509881423,
        "f1": 0.528678107136605,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.528678107136605,
        "precision": 0.5003774163530995,
        "recall": 0.607707509881423
      },
      {
        "accuracy": 0.6571146245059288,
        "f1": 0.6098252982553145,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6098252982553145,
        "precision": 0.5938884539723386,
        "recall": 0.6571146245059288
      },
      {
        "accuracy": 0.6294466403162056,
        "f1": 0.5520202239569829,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.5520202239569829,
        "precision": 0.5233856421356422,
        "recall": 0.6294466403162056
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.019297096828881585,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.019297096828881585,
        "precision": 0.018549452767712957,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.018168557397806408,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.018168557397806408,
        "precision": 0.015974967061923584,
        "recall": 0.025691699604743084
      }
    ],
    "validation": [
      {
        "accuracy": 0.954864593781344,
        "f1": 0.940320962888666,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.940320962888666,
        "precision": 0.933132731527917,
        "recall": 0.954864593781344
      },
      {
        "accuracy": 0.8906720160481444,
        "f1": 0.8588288675550461,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.8588288675550461,
        "precision": 0.8447007689735874,
        "recall": 0.8906720160481444
      },
      {
        "accuracy": 0.3640922768304915,
        "f1": 0.3065119830917223,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.3065119830917223,
        "precision": 0.2904778596365121,
        "recall": 0.3640922768304915
      },
      {
        "accuracy": 0.3921765295887663,
        "f1": 0.31365432423913714,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.31365432423913714,
        "precision": 0.29115088863573446,
        "recall": 0.3921765295887663
      },
      {
        "accuracy": 0.8405215646940822,
        "f1": 0.8042150260304725,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8042150260304725,
        "precision": 0.7889031071341159,
        "recall": 0.8405215646940822
      },
      {
        "accuracy": 0.7221664994984955,
        "f1": 0.6696043780267039,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.6696043780267039,
        "precision": 0.6492806336844335,
        "recall": 0.7221664994984955
      },
      {
        "accuracy": 0.5817452357071213,
        "f1": 0.5209058752563408,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.5209058752563408,
        "precision": 0.500070263534795,
        "recall": 0.5817452357071213
      },
      {
        "accuracy": 0.5295887662988967,
        "f1": 0.44858368534396614,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.44858368534396614,
        "precision": 0.4218199502433784,
        "recall": 0.5295887662988967
      },
      {
        "accuracy": 0.42527582748244735,
        "f1": 0.3663168728767822,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.3663168728767822,
        "precision": 0.3475132179952523,
        "recall": 0.42527582748244735
      },
      {
        "accuracy": 0.38415245737211634,
        "f1": 0.3029165641899003,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.3029165641899003,
        "precision": 0.2788466622173625,
        "recall": 0.38415245737211634
      },
      {
        "accuracy": 0.5777331995987964,
        "f1": 0.5205743551642071,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5205743551642071,
        "precision": 0.5016565340098439,
        "recall": 0.5777331995987964
      },
      {
        "accuracy": 0.5175526579739218,
        "f1": 0.43842357631224227,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.43842357631224227,
        "precision": 0.41302972713822916,
        "recall": 0.5175526579739218
      },
      {
        "accuracy": 0.5747241725175527,
        "f1": 0.5109192557520299,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.5109192557520299,
        "precision": 0.48967057404870845,
        "recall": 0.5747241725175527
      },
      {
        "accuracy": 0.555667001003009,
        "f1": 0.4779330276321249,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.4779330276321249,
        "precision": 0.45225557625256724,
        "recall": 0.555667001003009
      },
      {
        "accuracy": 0.9789368104312939,
        "f1": 0.9722500835840856,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9722500835840856,
        "precision": 0.9690738883316617,
        "recall": 0.9789368104312939
      },
      {
        "accuracy": 0.9207622868605817,
        "f1": 0.8973921765295888,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8973921765295888,
        "precision": 0.8869441658308258,
        "recall": 0.9207622868605817
      },
      {
        "accuracy": 0.6489468405215647,
        "f1": 0.5932617554758951,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.5932617554758951,
        "precision": 0.5734210415128169,
        "recall": 0.6489468405215647
      },
      {
        "accuracy": 0.6108324974924775,
        "f1": 0.5365396555968271,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.5365396555968271,
        "precision": 0.5099564890894763,
        "recall": 0.6108324974924775
      },
      {
        "accuracy": 0.5055165496489469,
        "f1": 0.4300356037980676,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.4300356037980676,
        "precision": 0.40389345363148355,
        "recall": 0.5055165496489469
      },
      {
        "accuracy": 0.44433299899699097,
        "f1": 0.3552750464736422,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.3552750464736422,
        "precision": 0.325703551758031,
        "recall": 0.44433299899699097
      },
      {
        "accuracy": 0.49648946840521563,
        "f1": 0.44086007986117404,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.44086007986117404,
        "precision": 0.42304718817975984,
        "recall": 0.49648946840521563
      },
      {
        "accuracy": 0.5055165496489469,
        "f1": 0.4270395463223949,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.4270395463223949,
        "precision": 0.40180647343876164,
        "recall": 0.5055165496489469
      },
      {
        "accuracy": 0.7352056168505516,
        "f1": 0.6828860318328724,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6828860318328724,
        "precision": 0.6643465500285962,
        "recall": 0.7352056168505516
      },
      {
        "accuracy": 0.6670010030090271,
        "f1": 0.5934541720399292,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.5934541720399292,
        "precision": 0.5654961276325368,
        "recall": 0.6670010030090271
      },
      {
        "accuracy": 0.07522567703109329,
        "f1": 0.060884515573582765,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.060884515573582765,
        "precision": 0.05665641613485144,
        "recall": 0.07522567703109329
      },
      {
        "accuracy": 0.09127382146439318,
        "f1": 0.04745952892008706,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.04745952892008706,
        "precision": 0.03846446270826188,
        "recall": 0.09127382146439318
      },
      {
        "accuracy": 0.4864593781344032,
        "f1": 0.4216655561967815,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.4216655561967815,
        "precision": 0.4023886492304905,
        "recall": 0.4864593781344032
      },
      {
        "accuracy": 0.4282848545636911,
        "f1": 0.35239598315539694,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.35239598315539694,
        "precision": 0.32852280379231946,
        "recall": 0.4282848545636911
      },
      {
        "accuracy": 0.2958876629889669,
        "f1": 0.24532893359552418,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.24532893359552418,
        "precision": 0.23083890681379585,
        "recall": 0.2958876629889669
      },
      {
        "accuracy": 0.3460381143430291,
        "f1": 0.2602113263258463,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.2602113263258463,
        "precision": 0.23400377205542702,
        "recall": 0.3460381143430291
      },
      {
        "accuracy": 0.3781344032096289,
        "f1": 0.3333475337888077,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.3333475337888077,
        "precision": 0.3206669500940764,
        "recall": 0.3781344032096289
      },
      {
        "accuracy": 0.45035105315947843,
        "f1": 0.3618921700165431,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.3618921700165431,
        "precision": 0.331922426731855,
        "recall": 0.45035105315947843
      },
      {
        "accuracy": 0.6569709127382146,
        "f1": 0.6098547816112274,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6098547816112274,
        "precision": 0.593140369883098,
        "recall": 0.6569709127382146
      },
      {
        "accuracy": 0.629889669007021,
        "f1": 0.5569898952045391,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.5569898952045391,
        "precision": 0.5313603508939517,
        "recall": 0.629889669007021
      },
      {
        "accuracy": 0.6058174523570712,
        "f1": 0.5510249210455092,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5510249210455092,
        "precision": 0.5322725064528698,
        "recall": 0.6058174523570712
      },
      {
        "accuracy": 0.6068204613841525,
        "f1": 0.5324320447189053,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.5324320447189053,
        "precision": 0.5063890444783123,
        "recall": 0.6068204613841525
      },
      {
        "accuracy": 0.03811434302908726,
        "f1": 0.03139311170355523,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.03139311170355523,
        "precision": 0.030461800972095523,
        "recall": 0.03811434302908726
      },
      {
        "accuracy": 0.07021063189568706,
        "f1": 0.03166348657202022,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.03166348657202022,
        "precision": 0.02494745591421515,
        "recall": 0.07021063189568706
      },
      {
        "accuracy": 0.05215646940822467,
        "f1": 0.04188747726235049,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.04188747726235049,
        "precision": 0.03992228451131476,
        "recall": 0.05215646940822467
      },
      {
        "accuracy": 0.1424272818455366,
        "f1": 0.0970383492951196,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.0970383492951196,
        "precision": 0.08587398696844682,
        "recall": 0.1424272818455366
      },
      {
        "accuracy": 0.5667001003009027,
        "f1": 0.5208523927802816,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5208523927802816,
        "precision": 0.5061278500345585,
        "recall": 0.5667001003009027
      },
      {
        "accuracy": 0.5917753259779338,
        "f1": 0.5171838404885372,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.5171838404885372,
        "precision": 0.4908864038001451,
        "recall": 0.5917753259779338
      },
      {
        "accuracy": 0.2657973921765296,
        "f1": 0.2257954600655337,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2257954600655337,
        "precision": 0.2143774260674885,
        "recall": 0.2657973921765296
      },
      {
        "accuracy": 0.33099297893681046,
        "f1": 0.25354860311347416,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.25354860311347416,
        "precision": 0.23067783520391347,
        "recall": 0.33099297893681046
      },
      {
        "accuracy": 0.6058174523570712,
        "f1": 0.5534929895867973,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5534929895867973,
        "precision": 0.5352484655014585,
        "recall": 0.6058174523570712
      },
      {
        "accuracy": 0.5767301905717152,
        "f1": 0.4973036574099354,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.4973036574099354,
        "precision": 0.46974894741945894,
        "recall": 0.5767301905717152
      },
      {
        "accuracy": 0.5526579739217653,
        "f1": 0.5029625271423721,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5029625271423721,
        "precision": 0.4866310133173313,
        "recall": 0.5526579739217653
      },
      {
        "accuracy": 0.5656970912738215,
        "f1": 0.49271476937897246,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.49271476937897246,
        "precision": 0.4654618005420412,
        "recall": 0.5656970912738215
      },
      {
        "accuracy": 0.5757271815446339,
        "f1": 0.5274475476339893,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5274475476339893,
        "precision": 0.5111973548165973,
        "recall": 0.5757271815446339
      },
      {
        "accuracy": 0.6038114343029087,
        "f1": 0.526431024675759,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.526431024675759,
        "precision": 0.499665204404422,
        "recall": 0.6038114343029087
      },
      {
        "accuracy": 0.0732196589769308,
        "f1": 0.054985869478282885,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.054985869478282885,
        "precision": 0.0509715222047383,
        "recall": 0.0732196589769308
      },
      {
        "accuracy": 0.1123370110330993,
        "f1": 0.07280696441672015,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.07280696441672015,
        "precision": 0.06355827249759044,
        "recall": 0.1123370110330993
      },
      {
        "accuracy": 0.5937813440320963,
        "f1": 0.5465699714193396,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5465699714193396,
        "precision": 0.5306252023362165,
        "recall": 0.5937813440320963
      },
      {
        "accuracy": 0.6018054162487463,
        "f1": 0.5307764627385254,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.5307764627385254,
        "precision": 0.5062864570512514,
        "recall": 0.6018054162487463
      },
      {
        "accuracy": 0.6308926780341023,
        "f1": 0.5774018764189209,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5774018764189209,
        "precision": 0.558636020170624,
        "recall": 0.6308926780341023
      },
      {
        "accuracy": 0.6268806419257773,
        "f1": 0.5525091870126977,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.5525091870126977,
        "precision": 0.5257148791251097,
        "recall": 0.6268806419257773
      },
      {
        "accuracy": 0.014042126379137413,
        "f1": 0.01139737620822667,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.01139737620822667,
        "precision": 0.010747393696240235,
        "recall": 0.014042126379137413
      },
      {
        "accuracy": 0.020060180541624874,
        "f1": 0.010132729189900705,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.010132729189900705,
        "precision": 0.008252535383929567,
        "recall": 0.020060180541624874
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}