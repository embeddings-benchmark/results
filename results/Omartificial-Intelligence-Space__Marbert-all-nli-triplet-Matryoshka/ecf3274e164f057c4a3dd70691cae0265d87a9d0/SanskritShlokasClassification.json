{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.658486,
        "f1": 0.639587,
        "f1_weighted": 0.641924,
        "scores_per_experiment": [
          {
            "accuracy": 0.642298,
            "f1": 0.635516,
            "f1_weighted": 0.638218
          },
          {
            "accuracy": 0.715405,
            "f1": 0.677588,
            "f1_weighted": 0.68483
          },
          {
            "accuracy": 0.70235,
            "f1": 0.625009,
            "f1_weighted": 0.636969
          },
          {
            "accuracy": 0.686684,
            "f1": 0.671883,
            "f1_weighted": 0.676203
          },
          {
            "accuracy": 0.707572,
            "f1": 0.680229,
            "f1_weighted": 0.687389
          },
          {
            "accuracy": 0.618799,
            "f1": 0.62031,
            "f1_weighted": 0.618131
          },
          {
            "accuracy": 0.67624,
            "f1": 0.675252,
            "f1_weighted": 0.677704
          },
          {
            "accuracy": 0.579634,
            "f1": 0.571242,
            "f1_weighted": 0.564807
          },
          {
            "accuracy": 0.616188,
            "f1": 0.603798,
            "f1_weighted": 0.597354
          },
          {
            "accuracy": 0.639687,
            "f1": 0.635046,
            "f1_weighted": 0.637635
          }
        ],
        "main_score": 0.658486,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.671875,
        "f1": 0.658572,
        "f1_weighted": 0.653988,
        "scores_per_experiment": [
          {
            "accuracy": 0.677083,
            "f1": 0.666933,
            "f1_weighted": 0.667195
          },
          {
            "accuracy": 0.75,
            "f1": 0.72639,
            "f1_weighted": 0.730803
          },
          {
            "accuracy": 0.708333,
            "f1": 0.623186,
            "f1_weighted": 0.640244
          },
          {
            "accuracy": 0.6875,
            "f1": 0.66949,
            "f1_weighted": 0.671363
          },
          {
            "accuracy": 0.75,
            "f1": 0.72639,
            "f1_weighted": 0.730803
          },
          {
            "accuracy": 0.614583,
            "f1": 0.620081,
            "f1_weighted": 0.613118
          },
          {
            "accuracy": 0.677083,
            "f1": 0.691267,
            "f1_weighted": 0.678379
          },
          {
            "accuracy": 0.59375,
            "f1": 0.605157,
            "f1_weighted": 0.581766
          },
          {
            "accuracy": 0.583333,
            "f1": 0.587046,
            "f1_weighted": 0.557239
          },
          {
            "accuracy": 0.677083,
            "f1": 0.669785,
            "f1_weighted": 0.668964
          }
        ],
        "main_score": 0.671875,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 12.300233602523804,
  "kg_co2_emissions": 0.00034730474456261707
}