{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.103665,
        "recall": 0.140625,
        "f1": 0.113624,
        "accuracy": 0.140625,
        "main_score": 0.113624,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.074761,
        "recall": 0.124023,
        "f1": 0.086234,
        "accuracy": 0.124023,
        "main_score": 0.086234,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.046144,
        "recall": 0.083008,
        "f1": 0.054718,
        "accuracy": 0.083008,
        "main_score": 0.054718,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000977,
        "f1": 5e-06,
        "accuracy": 0.000977,
        "main_score": 5e-06,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037006,
        "recall": 0.066406,
        "f1": 0.042777,
        "accuracy": 0.066406,
        "main_score": 0.042777,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.066696,
        "recall": 0.104492,
        "f1": 0.075532,
        "accuracy": 0.104492,
        "main_score": 0.075532,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.053201,
        "recall": 0.09668,
        "f1": 0.063196,
        "accuracy": 0.09668,
        "main_score": 0.063196,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.057978,
        "recall": 0.079102,
        "f1": 0.062802,
        "accuracy": 0.079102,
        "main_score": 0.062802,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.099499,
        "recall": 0.141602,
        "f1": 0.110647,
        "accuracy": 0.141602,
        "main_score": 0.110647,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.010882,
        "recall": 0.029297,
        "f1": 0.013931,
        "accuracy": 0.029297,
        "main_score": 0.013931,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.06519,
        "recall": 0.099609,
        "f1": 0.072425,
        "accuracy": 0.099609,
        "main_score": 0.072425,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.099049,
        "recall": 0.140625,
        "f1": 0.109689,
        "accuracy": 0.140625,
        "main_score": 0.109689,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.097746,
        "recall": 0.136719,
        "f1": 0.107017,
        "accuracy": 0.136719,
        "main_score": 0.107017,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.107605,
        "recall": 0.148438,
        "f1": 0.118498,
        "accuracy": 0.148438,
        "main_score": 0.118498,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010534,
        "recall": 0.022461,
        "f1": 0.011511,
        "accuracy": 0.022461,
        "main_score": 0.011511,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.027065,
        "recall": 0.042969,
        "f1": 0.030024,
        "accuracy": 0.042969,
        "main_score": 0.030024,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.066415,
        "recall": 0.09668,
        "f1": 0.073132,
        "accuracy": 0.09668,
        "main_score": 0.073132,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.039225,
        "recall": 0.071289,
        "f1": 0.046328,
        "accuracy": 0.071289,
        "main_score": 0.046328,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.016715,
        "recall": 0.03418,
        "f1": 0.019814,
        "accuracy": 0.03418,
        "main_score": 0.019814,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.025171,
        "recall": 0.051758,
        "f1": 0.029104,
        "accuracy": 0.051758,
        "main_score": 0.029104,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 3.1e-05,
        "recall": 0.000977,
        "f1": 5.9e-05,
        "accuracy": 0.000977,
        "main_score": 5.9e-05,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.104481,
        "recall": 0.139648,
        "f1": 0.113639,
        "accuracy": 0.139648,
        "main_score": 0.113639,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.045778,
        "recall": 0.078125,
        "f1": 0.053203,
        "accuracy": 0.078125,
        "main_score": 0.053203,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.035013,
        "recall": 0.063477,
        "f1": 0.041782,
        "accuracy": 0.063477,
        "main_score": 0.041782,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000977,
        "f1": 5e-06,
        "accuracy": 0.000977,
        "main_score": 5e-06,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028922,
        "recall": 0.055664,
        "f1": 0.034255,
        "accuracy": 0.055664,
        "main_score": 0.034255,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.059801,
        "recall": 0.100586,
        "f1": 0.068172,
        "accuracy": 0.100586,
        "main_score": 0.068172,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.035336,
        "recall": 0.05957,
        "f1": 0.041905,
        "accuracy": 0.05957,
        "main_score": 0.041905,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.045254,
        "recall": 0.069336,
        "f1": 0.050705,
        "accuracy": 0.069336,
        "main_score": 0.050705,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.090162,
        "recall": 0.123047,
        "f1": 0.098286,
        "accuracy": 0.123047,
        "main_score": 0.098286,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.015596,
        "recall": 0.03125,
        "f1": 0.018625,
        "accuracy": 0.03125,
        "main_score": 0.018625,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.069035,
        "recall": 0.102539,
        "f1": 0.07597,
        "accuracy": 0.102539,
        "main_score": 0.07597,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.075224,
        "recall": 0.112305,
        "f1": 0.084458,
        "accuracy": 0.112305,
        "main_score": 0.084458,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.093493,
        "recall": 0.128906,
        "f1": 0.10296,
        "accuracy": 0.128906,
        "main_score": 0.10296,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.078682,
        "recall": 0.111328,
        "f1": 0.087214,
        "accuracy": 0.111328,
        "main_score": 0.087214,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010686,
        "recall": 0.018555,
        "f1": 0.011606,
        "accuracy": 0.018555,
        "main_score": 0.011606,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.02477,
        "recall": 0.039062,
        "f1": 0.026942,
        "accuracy": 0.039062,
        "main_score": 0.026942,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.104547,
        "recall": 0.15332,
        "f1": 0.115784,
        "accuracy": 0.15332,
        "main_score": 0.115784,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.028136,
        "recall": 0.051758,
        "f1": 0.033284,
        "accuracy": 0.051758,
        "main_score": 0.033284,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.017468,
        "recall": 0.03418,
        "f1": 0.0204,
        "accuracy": 0.03418,
        "main_score": 0.0204,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.026833,
        "recall": 0.052734,
        "f1": 0.03117,
        "accuracy": 0.052734,
        "main_score": 0.03117,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 3.1e-05,
        "recall": 0.000977,
        "f1": 5.9e-05,
        "accuracy": 0.000977,
        "main_score": 5.9e-05,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.084637,
        "recall": 0.133789,
        "f1": 0.09655,
        "accuracy": 0.133789,
        "main_score": 0.09655,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.052804,
        "recall": 0.09375,
        "f1": 0.062507,
        "accuracy": 0.09375,
        "main_score": 0.062507,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.280291,
        "recall": 0.311523,
        "f1": 0.28846,
        "accuracy": 0.311523,
        "main_score": 0.28846,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.023891,
        "recall": 0.039062,
        "f1": 0.026409,
        "accuracy": 0.039062,
        "main_score": 0.026409,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.271662,
        "recall": 0.310547,
        "f1": 0.282279,
        "accuracy": 0.310547,
        "main_score": 0.282279,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.075591,
        "recall": 0.128906,
        "f1": 0.086502,
        "accuracy": 0.128906,
        "main_score": 0.086502,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.291588,
        "recall": 0.331055,
        "f1": 0.302756,
        "accuracy": 0.331055,
        "main_score": 0.302756,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.049831,
        "recall": 0.078125,
        "f1": 0.056553,
        "accuracy": 0.078125,
        "main_score": 0.056553,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.016532,
        "recall": 0.027344,
        "f1": 0.017867,
        "accuracy": 0.027344,
        "main_score": 0.017867,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.057954,
        "recall": 0.100586,
        "f1": 0.06705,
        "accuracy": 0.100586,
        "main_score": 0.06705,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.144933,
        "recall": 0.19043,
        "f1": 0.156123,
        "accuracy": 0.19043,
        "main_score": 0.156123,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.047842,
        "recall": 0.082031,
        "f1": 0.056091,
        "accuracy": 0.082031,
        "main_score": 0.056091,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.065344,
        "recall": 0.107422,
        "f1": 0.075097,
        "accuracy": 0.107422,
        "main_score": 0.075097,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.058287,
        "recall": 0.089844,
        "f1": 0.065553,
        "accuracy": 0.089844,
        "main_score": 0.065553,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.069889,
        "recall": 0.111328,
        "f1": 0.080354,
        "accuracy": 0.111328,
        "main_score": 0.080354,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.234095,
        "recall": 0.256836,
        "f1": 0.239139,
        "accuracy": 0.256836,
        "main_score": 0.239139,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.015718,
        "recall": 0.02832,
        "f1": 0.017807,
        "accuracy": 0.02832,
        "main_score": 0.017807,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.024842,
        "recall": 0.056641,
        "f1": 0.030941,
        "accuracy": 0.056641,
        "main_score": 0.030941,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.293255,
        "recall": 0.328125,
        "f1": 0.303022,
        "accuracy": 0.328125,
        "main_score": 0.303022,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.167431,
        "recall": 0.210938,
        "f1": 0.177683,
        "accuracy": 0.210938,
        "main_score": 0.177683,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.206846,
        "recall": 0.259766,
        "f1": 0.220741,
        "accuracy": 0.259766,
        "main_score": 0.220741,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010002,
        "recall": 0.015625,
        "f1": 0.011011,
        "accuracy": 0.015625,
        "main_score": 0.011011,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.04464,
        "recall": 0.072266,
        "f1": 0.051224,
        "accuracy": 0.072266,
        "main_score": 0.051224,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.040862,
        "recall": 0.063477,
        "f1": 0.046425,
        "accuracy": 0.063477,
        "main_score": 0.046425,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.274263,
        "recall": 0.308594,
        "f1": 0.282899,
        "accuracy": 0.308594,
        "main_score": 0.282899,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.019721,
        "recall": 0.03418,
        "f1": 0.022327,
        "accuracy": 0.03418,
        "main_score": 0.022327,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.234377,
        "recall": 0.263672,
        "f1": 0.241968,
        "accuracy": 0.263672,
        "main_score": 0.241968,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.041922,
        "recall": 0.076172,
        "f1": 0.047339,
        "accuracy": 0.076172,
        "main_score": 0.047339,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.317622,
        "recall": 0.362305,
        "f1": 0.329637,
        "accuracy": 0.362305,
        "main_score": 0.329637,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.013458,
        "recall": 0.029297,
        "f1": 0.015925,
        "accuracy": 0.029297,
        "main_score": 0.015925,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.01107,
        "recall": 0.019531,
        "f1": 0.012203,
        "accuracy": 0.019531,
        "main_score": 0.012203,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.07587,
        "recall": 0.106445,
        "f1": 0.082322,
        "accuracy": 0.106445,
        "main_score": 0.082322,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.13151,
        "recall": 0.164062,
        "f1": 0.140062,
        "accuracy": 0.164062,
        "main_score": 0.140062,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024679,
        "recall": 0.041992,
        "f1": 0.02767,
        "accuracy": 0.041992,
        "main_score": 0.02767,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.037279,
        "recall": 0.063477,
        "f1": 0.043315,
        "accuracy": 0.063477,
        "main_score": 0.043315,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.05116,
        "recall": 0.074219,
        "f1": 0.056362,
        "accuracy": 0.074219,
        "main_score": 0.056362,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.034859,
        "recall": 0.060547,
        "f1": 0.040392,
        "accuracy": 0.060547,
        "main_score": 0.040392,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.248952,
        "recall": 0.271484,
        "f1": 0.253516,
        "accuracy": 0.271484,
        "main_score": 0.253516,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.007951,
        "recall": 0.017578,
        "f1": 0.009093,
        "accuracy": 0.017578,
        "main_score": 0.009093,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.053785,
        "recall": 0.088867,
        "f1": 0.06225,
        "accuracy": 0.088867,
        "main_score": 0.06225,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.31514,
        "recall": 0.364258,
        "f1": 0.328056,
        "accuracy": 0.364258,
        "main_score": 0.328056,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.159683,
        "recall": 0.191406,
        "f1": 0.167491,
        "accuracy": 0.191406,
        "main_score": 0.167491,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.207304,
        "recall": 0.234375,
        "f1": 0.214593,
        "accuracy": 0.234375,
        "main_score": 0.214593,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010339,
        "recall": 0.014648,
        "f1": 0.011226,
        "accuracy": 0.014648,
        "main_score": 0.011226,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001193,
        "recall": 0.004883,
        "f1": 0.001794,
        "accuracy": 0.004883,
        "main_score": 0.001794,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.000269,
        "recall": 0.006836,
        "f1": 0.000503,
        "accuracy": 0.006836,
        "main_score": 0.000503,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.061363,
        "recall": 0.091797,
        "f1": 0.066627,
        "accuracy": 0.091797,
        "main_score": 0.066627,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.057714,
        "recall": 0.083984,
        "f1": 0.063498,
        "accuracy": 0.083984,
        "main_score": 0.063498,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.053734,
        "recall": 0.091797,
        "f1": 0.06031,
        "accuracy": 0.091797,
        "main_score": 0.06031,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.007711,
        "recall": 0.024414,
        "f1": 0.009504,
        "accuracy": 0.024414,
        "main_score": 0.009504,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.056185,
        "recall": 0.094727,
        "f1": 0.062726,
        "accuracy": 0.094727,
        "main_score": 0.062726,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001147,
        "recall": 0.004883,
        "f1": 0.0013,
        "accuracy": 0.004883,
        "main_score": 0.0013,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.05631,
        "recall": 0.09082,
        "f1": 0.06226,
        "accuracy": 0.09082,
        "main_score": 0.06226,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000541,
        "recall": 0.006836,
        "f1": 0.000951,
        "accuracy": 0.006836,
        "main_score": 0.000951,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.039442,
        "recall": 0.057617,
        "f1": 0.042882,
        "accuracy": 0.057617,
        "main_score": 0.042882,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000449,
        "recall": 0.005859,
        "f1": 0.000765,
        "accuracy": 0.005859,
        "main_score": 0.000765,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000755,
        "recall": 0.006836,
        "f1": 0.001257,
        "accuracy": 0.006836,
        "main_score": 0.001257,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.000524,
        "recall": 0.005859,
        "f1": 0.000862,
        "accuracy": 0.005859,
        "main_score": 0.000862,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.00093,
        "recall": 0.008789,
        "f1": 0.001454,
        "accuracy": 0.008789,
        "main_score": 0.001454,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.05805,
        "recall": 0.083008,
        "f1": 0.063029,
        "accuracy": 0.083008,
        "main_score": 0.063029,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00187,
        "recall": 0.006836,
        "f1": 0.002269,
        "accuracy": 0.006836,
        "main_score": 0.002269,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000158,
        "recall": 0.003906,
        "f1": 0.000294,
        "accuracy": 0.003906,
        "main_score": 0.000294,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.050835,
        "recall": 0.078125,
        "f1": 0.055224,
        "accuracy": 0.078125,
        "main_score": 0.055224,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.042926,
        "recall": 0.071289,
        "f1": 0.047709,
        "accuracy": 0.071289,
        "main_score": 0.047709,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.059841,
        "recall": 0.089844,
        "f1": 0.0655,
        "accuracy": 0.089844,
        "main_score": 0.0655,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.090398,
        "recall": 0.128906,
        "f1": 0.098155,
        "accuracy": 0.128906,
        "main_score": 0.098155,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.038503,
        "recall": 0.080078,
        "f1": 0.046955,
        "accuracy": 0.080078,
        "main_score": 0.046955,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.030381,
        "recall": 0.05957,
        "f1": 0.036586,
        "accuracy": 0.05957,
        "main_score": 0.036586,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.286427,
        "recall": 0.332031,
        "f1": 0.297369,
        "accuracy": 0.332031,
        "main_score": 0.297369,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.250652,
        "recall": 0.289062,
        "f1": 0.260019,
        "accuracy": 0.289062,
        "main_score": 0.260019,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.025947,
        "recall": 0.040039,
        "f1": 0.028428,
        "accuracy": 0.040039,
        "main_score": 0.028428,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.091002,
        "recall": 0.146484,
        "f1": 0.102355,
        "accuracy": 0.146484,
        "main_score": 0.102355,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.263148,
        "recall": 0.300781,
        "f1": 0.272845,
        "accuracy": 0.300781,
        "main_score": 0.272845,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.077207,
        "recall": 0.117188,
        "f1": 0.087403,
        "accuracy": 0.117188,
        "main_score": 0.087403,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.01447,
        "recall": 0.025391,
        "f1": 0.015833,
        "accuracy": 0.025391,
        "main_score": 0.015833,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.034163,
        "recall": 0.068359,
        "f1": 0.041259,
        "accuracy": 0.068359,
        "main_score": 0.041259,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.162887,
        "recall": 0.210938,
        "f1": 0.175101,
        "accuracy": 0.210938,
        "main_score": 0.175101,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.075428,
        "recall": 0.121094,
        "f1": 0.086944,
        "accuracy": 0.121094,
        "main_score": 0.086944,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.036614,
        "recall": 0.070312,
        "f1": 0.04271,
        "accuracy": 0.070312,
        "main_score": 0.04271,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.037756,
        "recall": 0.073242,
        "f1": 0.045099,
        "accuracy": 0.073242,
        "main_score": 0.045099,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.047113,
        "recall": 0.084961,
        "f1": 0.055509,
        "accuracy": 0.084961,
        "main_score": 0.055509,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.23382,
        "recall": 0.260742,
        "f1": 0.240482,
        "accuracy": 0.260742,
        "main_score": 0.240482,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.022471,
        "recall": 0.042969,
        "f1": 0.026578,
        "accuracy": 0.042969,
        "main_score": 0.026578,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.017538,
        "recall": 0.044922,
        "f1": 0.022061,
        "accuracy": 0.044922,
        "main_score": 0.022061,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.265205,
        "recall": 0.298828,
        "f1": 0.274458,
        "accuracy": 0.298828,
        "main_score": 0.274458,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.197993,
        "recall": 0.248047,
        "f1": 0.210552,
        "accuracy": 0.248047,
        "main_score": 0.210552,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.234941,
        "recall": 0.287109,
        "f1": 0.249346,
        "accuracy": 0.287109,
        "main_score": 0.249346,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.011047,
        "recall": 0.016602,
        "f1": 0.012062,
        "accuracy": 0.016602,
        "main_score": 0.012062,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.074106,
        "recall": 0.118164,
        "f1": 0.083997,
        "accuracy": 0.118164,
        "main_score": 0.083997,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.055592,
        "recall": 0.09375,
        "f1": 0.065012,
        "accuracy": 0.09375,
        "main_score": 0.065012,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.075905,
        "recall": 0.110352,
        "f1": 0.08305,
        "accuracy": 0.110352,
        "main_score": 0.08305,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.054414,
        "recall": 0.078125,
        "f1": 0.059319,
        "accuracy": 0.078125,
        "main_score": 0.059319,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.005809,
        "recall": 0.009766,
        "f1": 0.006226,
        "accuracy": 0.009766,
        "main_score": 0.006226,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.094095,
        "recall": 0.131836,
        "f1": 0.103132,
        "accuracy": 0.131836,
        "main_score": 0.103132,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.065588,
        "recall": 0.094727,
        "f1": 0.07138,
        "accuracy": 0.094727,
        "main_score": 0.07138,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.089288,
        "recall": 0.125977,
        "f1": 0.098636,
        "accuracy": 0.125977,
        "main_score": 0.098636,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004378,
        "recall": 0.007812,
        "f1": 0.004666,
        "accuracy": 0.007812,
        "main_score": 0.004666,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.06193,
        "recall": 0.101562,
        "f1": 0.070586,
        "accuracy": 0.101562,
        "main_score": 0.070586,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.053153,
        "recall": 0.072266,
        "f1": 0.057413,
        "accuracy": 0.072266,
        "main_score": 0.057413,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.091173,
        "recall": 0.137695,
        "f1": 0.103029,
        "accuracy": 0.137695,
        "main_score": 0.103029,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.0478,
        "recall": 0.09082,
        "f1": 0.057435,
        "accuracy": 0.09082,
        "main_score": 0.057435,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.059188,
        "recall": 0.087891,
        "f1": 0.065461,
        "accuracy": 0.087891,
        "main_score": 0.065461,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.079493,
        "recall": 0.12207,
        "f1": 0.089032,
        "accuracy": 0.12207,
        "main_score": 0.089032,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.037588,
        "recall": 0.048828,
        "f1": 0.038837,
        "accuracy": 0.048828,
        "main_score": 0.038837,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.024349,
        "recall": 0.048828,
        "f1": 0.028539,
        "accuracy": 0.048828,
        "main_score": 0.028539,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.031276,
        "recall": 0.05957,
        "f1": 0.037225,
        "accuracy": 0.05957,
        "main_score": 0.037225,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.068488,
        "recall": 0.095703,
        "f1": 0.073651,
        "accuracy": 0.095703,
        "main_score": 0.073651,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.059799,
        "recall": 0.076172,
        "f1": 0.063843,
        "accuracy": 0.076172,
        "main_score": 0.063843,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.066421,
        "recall": 0.097656,
        "f1": 0.072884,
        "accuracy": 0.097656,
        "main_score": 0.072884,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001962,
        "recall": 0.00293,
        "f1": 0.001971,
        "accuracy": 0.00293,
        "main_score": 0.001971,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.051065,
        "recall": 0.077148,
        "f1": 0.057093,
        "accuracy": 0.077148,
        "main_score": 0.057093,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.038398,
        "recall": 0.0625,
        "f1": 0.044051,
        "accuracy": 0.0625,
        "main_score": 0.044051,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.268256,
        "recall": 0.301758,
        "f1": 0.277432,
        "accuracy": 0.301758,
        "main_score": 0.277432,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.303663,
        "recall": 0.353516,
        "f1": 0.31746,
        "accuracy": 0.353516,
        "main_score": 0.31746,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.01975,
        "recall": 0.029297,
        "f1": 0.021498,
        "accuracy": 0.029297,
        "main_score": 0.021498,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.235087,
        "recall": 0.266602,
        "f1": 0.243558,
        "accuracy": 0.266602,
        "main_score": 0.243558,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.050712,
        "recall": 0.09082,
        "f1": 0.057969,
        "accuracy": 0.09082,
        "main_score": 0.057969,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.017396,
        "recall": 0.03418,
        "f1": 0.020547,
        "accuracy": 0.03418,
        "main_score": 0.020547,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.009801,
        "recall": 0.019531,
        "f1": 0.010952,
        "accuracy": 0.019531,
        "main_score": 0.010952,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.064846,
        "recall": 0.099609,
        "f1": 0.073373,
        "accuracy": 0.099609,
        "main_score": 0.073373,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.119323,
        "recall": 0.15625,
        "f1": 0.128429,
        "accuracy": 0.15625,
        "main_score": 0.128429,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.023995,
        "recall": 0.044922,
        "f1": 0.027973,
        "accuracy": 0.044922,
        "main_score": 0.027973,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.04731,
        "recall": 0.074219,
        "f1": 0.053692,
        "accuracy": 0.074219,
        "main_score": 0.053692,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.031255,
        "recall": 0.048828,
        "f1": 0.034847,
        "accuracy": 0.048828,
        "main_score": 0.034847,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.053269,
        "recall": 0.081055,
        "f1": 0.060295,
        "accuracy": 0.081055,
        "main_score": 0.060295,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.227113,
        "recall": 0.258789,
        "f1": 0.234025,
        "accuracy": 0.258789,
        "main_score": 0.234025,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.008022,
        "recall": 0.019531,
        "f1": 0.009679,
        "accuracy": 0.019531,
        "main_score": 0.009679,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.044419,
        "recall": 0.070312,
        "f1": 0.050274,
        "accuracy": 0.070312,
        "main_score": 0.050274,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.354133,
        "recall": 0.395508,
        "f1": 0.365521,
        "accuracy": 0.395508,
        "main_score": 0.365521,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.143096,
        "recall": 0.175781,
        "f1": 0.151425,
        "accuracy": 0.175781,
        "main_score": 0.151425,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.177934,
        "recall": 0.214844,
        "f1": 0.187661,
        "accuracy": 0.214844,
        "main_score": 0.187661,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006096,
        "recall": 0.009766,
        "f1": 0.006649,
        "accuracy": 0.009766,
        "main_score": 0.006649,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.071303,
        "recall": 0.109375,
        "f1": 0.0797,
        "accuracy": 0.109375,
        "main_score": 0.0797,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.050391,
        "recall": 0.084961,
        "f1": 0.058098,
        "accuracy": 0.084961,
        "main_score": 0.058098,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.044022,
        "recall": 0.084961,
        "f1": 0.052796,
        "accuracy": 0.084961,
        "main_score": 0.052796,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.016903,
        "recall": 0.036133,
        "f1": 0.020114,
        "accuracy": 0.036133,
        "main_score": 0.020114,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.000977,
        "f1": 5e-06,
        "accuracy": 0.000977,
        "main_score": 5e-06,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.064962,
        "recall": 0.114258,
        "f1": 0.076833,
        "accuracy": 0.114258,
        "main_score": 0.076833,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.089851,
        "recall": 0.131836,
        "f1": 0.101064,
        "accuracy": 0.131836,
        "main_score": 0.101064,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.016398,
        "recall": 0.039062,
        "f1": 0.020219,
        "accuracy": 0.039062,
        "main_score": 0.020219,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.04624,
        "recall": 0.076172,
        "f1": 0.052519,
        "accuracy": 0.076172,
        "main_score": 0.052519,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.046554,
        "recall": 0.081055,
        "f1": 0.054312,
        "accuracy": 0.081055,
        "main_score": 0.054312,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.112077,
        "recall": 0.147461,
        "f1": 0.121598,
        "accuracy": 0.147461,
        "main_score": 0.121598,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.053645,
        "recall": 0.086914,
        "f1": 0.060578,
        "accuracy": 0.086914,
        "main_score": 0.060578,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.075041,
        "recall": 0.105469,
        "f1": 0.080942,
        "accuracy": 0.105469,
        "main_score": 0.080942,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.078143,
        "recall": 0.117188,
        "f1": 0.08689,
        "accuracy": 0.117188,
        "main_score": 0.08689,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01011,
        "recall": 0.019531,
        "f1": 0.011636,
        "accuracy": 0.019531,
        "main_score": 0.011636,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.042574,
        "recall": 0.068359,
        "f1": 0.047487,
        "accuracy": 0.068359,
        "main_score": 0.047487,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.025351,
        "recall": 0.051758,
        "f1": 0.030488,
        "accuracy": 0.051758,
        "main_score": 0.030488,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.020793,
        "recall": 0.043945,
        "f1": 0.025415,
        "accuracy": 0.043945,
        "main_score": 0.025415,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.054125,
        "recall": 0.094727,
        "f1": 0.064263,
        "accuracy": 0.094727,
        "main_score": 0.064263,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.06384,
        "recall": 0.103516,
        "f1": 0.073396,
        "accuracy": 0.103516,
        "main_score": 0.073396,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 8e-06,
        "recall": 0.000977,
        "f1": 1.7e-05,
        "accuracy": 0.000977,
        "main_score": 1.7e-05,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000613,
        "recall": 0.004883,
        "f1": 0.000889,
        "accuracy": 0.004883,
        "main_score": 0.000889,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001548,
        "recall": 0.003906,
        "f1": 0.001859,
        "accuracy": 0.003906,
        "main_score": 0.001859,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.045946,
        "recall": 0.067383,
        "f1": 0.049346,
        "accuracy": 0.067383,
        "main_score": 0.049346,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.04653,
        "recall": 0.063477,
        "f1": 0.049803,
        "accuracy": 0.063477,
        "main_score": 0.049803,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.030806,
        "recall": 0.051758,
        "f1": 0.033614,
        "accuracy": 0.051758,
        "main_score": 0.033614,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045599,
        "recall": 0.068359,
        "f1": 0.048927,
        "accuracy": 0.068359,
        "main_score": 0.048927,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.003973,
        "recall": 0.021484,
        "f1": 0.005644,
        "accuracy": 0.021484,
        "main_score": 0.005644,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.045882,
        "recall": 0.066406,
        "f1": 0.048958,
        "accuracy": 0.066406,
        "main_score": 0.048958,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000242,
        "recall": 0.004883,
        "f1": 0.000451,
        "accuracy": 0.004883,
        "main_score": 0.000451,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001233,
        "recall": 0.004883,
        "f1": 0.001454,
        "accuracy": 0.004883,
        "main_score": 0.001454,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.024613,
        "recall": 0.045898,
        "f1": 0.027434,
        "accuracy": 0.045898,
        "main_score": 0.027434,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.002587,
        "recall": 0.005859,
        "f1": 0.002872,
        "accuracy": 0.005859,
        "main_score": 0.002872,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002161,
        "recall": 0.007812,
        "f1": 0.002673,
        "accuracy": 0.007812,
        "main_score": 0.002673,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.00013,
        "recall": 0.005859,
        "f1": 0.000253,
        "accuracy": 0.005859,
        "main_score": 0.000253,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.000633,
        "recall": 0.00293,
        "f1": 0.000905,
        "accuracy": 0.00293,
        "main_score": 0.000905,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03915,
        "recall": 0.060547,
        "f1": 0.042674,
        "accuracy": 0.060547,
        "main_score": 0.042674,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000623,
        "recall": 0.005859,
        "f1": 0.000908,
        "accuracy": 0.005859,
        "main_score": 0.000908,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001296,
        "recall": 0.007812,
        "f1": 0.001996,
        "accuracy": 0.007812,
        "main_score": 0.001996,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.047755,
        "recall": 0.068359,
        "f1": 0.051443,
        "accuracy": 0.068359,
        "main_score": 0.051443,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.024462,
        "recall": 0.042969,
        "f1": 0.026695,
        "accuracy": 0.042969,
        "main_score": 0.026695,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.029974,
        "recall": 0.049805,
        "f1": 0.032946,
        "accuracy": 0.049805,
        "main_score": 0.032946,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.36699,
        "recall": 0.417969,
        "f1": 0.37804,
        "accuracy": 0.417969,
        "main_score": 0.37804,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.093263,
        "recall": 0.131836,
        "f1": 0.102503,
        "accuracy": 0.131836,
        "main_score": 0.102503,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.085692,
        "recall": 0.123047,
        "f1": 0.095699,
        "accuracy": 0.123047,
        "main_score": 0.095699,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.042049,
        "recall": 0.078125,
        "f1": 0.049626,
        "accuracy": 0.078125,
        "main_score": 0.049626,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.060301,
        "recall": 0.095703,
        "f1": 0.068771,
        "accuracy": 0.095703,
        "main_score": 0.068771,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000978,
        "recall": 0.001953,
        "f1": 0.00098,
        "accuracy": 0.001953,
        "main_score": 0.00098,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022946,
        "recall": 0.047852,
        "f1": 0.027717,
        "accuracy": 0.047852,
        "main_score": 0.027717,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.060292,
        "recall": 0.091797,
        "f1": 0.066667,
        "accuracy": 0.091797,
        "main_score": 0.066667,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.053044,
        "recall": 0.083008,
        "f1": 0.061013,
        "accuracy": 0.083008,
        "main_score": 0.061013,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.048729,
        "recall": 0.067383,
        "f1": 0.052825,
        "accuracy": 0.067383,
        "main_score": 0.052825,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.012727,
        "recall": 0.022461,
        "f1": 0.014782,
        "accuracy": 0.022461,
        "main_score": 0.014782,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.060391,
        "recall": 0.084961,
        "f1": 0.065197,
        "accuracy": 0.084961,
        "main_score": 0.065197,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.074347,
        "recall": 0.112305,
        "f1": 0.083628,
        "accuracy": 0.112305,
        "main_score": 0.083628,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.104077,
        "recall": 0.134766,
        "f1": 0.111557,
        "accuracy": 0.134766,
        "main_score": 0.111557,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.08255,
        "recall": 0.115234,
        "f1": 0.090325,
        "accuracy": 0.115234,
        "main_score": 0.090325,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.012234,
        "recall": 0.024414,
        "f1": 0.013124,
        "accuracy": 0.024414,
        "main_score": 0.013124,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019853,
        "recall": 0.036133,
        "f1": 0.022421,
        "accuracy": 0.036133,
        "main_score": 0.022421,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.059644,
        "recall": 0.09082,
        "f1": 0.067793,
        "accuracy": 0.09082,
        "main_score": 0.067793,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.041301,
        "recall": 0.067383,
        "f1": 0.04758,
        "accuracy": 0.067383,
        "main_score": 0.04758,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.017393,
        "recall": 0.035156,
        "f1": 0.020663,
        "accuracy": 0.035156,
        "main_score": 0.020663,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.02295,
        "recall": 0.043945,
        "f1": 0.026785,
        "accuracy": 0.043945,
        "main_score": 0.026785,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 2.7e-05,
        "recall": 0.000977,
        "f1": 5.3e-05,
        "accuracy": 0.000977,
        "main_score": 5.3e-05,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.017769,
        "recall": 0.037109,
        "f1": 0.02118,
        "accuracy": 0.037109,
        "main_score": 0.02118,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.020059,
        "recall": 0.045898,
        "f1": 0.024522,
        "accuracy": 0.045898,
        "main_score": 0.024522,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.167162,
        "recall": 0.192383,
        "f1": 0.174079,
        "accuracy": 0.192383,
        "main_score": 0.174079,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.148893,
        "recall": 0.170898,
        "f1": 0.154376,
        "accuracy": 0.170898,
        "main_score": 0.154376,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.012861,
        "recall": 0.022461,
        "f1": 0.014232,
        "accuracy": 0.022461,
        "main_score": 0.014232,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.175548,
        "recall": 0.210938,
        "f1": 0.185498,
        "accuracy": 0.210938,
        "main_score": 0.185498,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.055196,
        "recall": 0.092773,
        "f1": 0.063193,
        "accuracy": 0.092773,
        "main_score": 0.063193,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.146349,
        "recall": 0.175781,
        "f1": 0.153646,
        "accuracy": 0.175781,
        "main_score": 0.153646,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.058498,
        "recall": 0.087891,
        "f1": 0.06574,
        "accuracy": 0.087891,
        "main_score": 0.06574,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.010283,
        "recall": 0.019531,
        "f1": 0.011437,
        "accuracy": 0.019531,
        "main_score": 0.011437,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.0125,
        "recall": 0.03125,
        "f1": 0.01567,
        "accuracy": 0.03125,
        "main_score": 0.01567,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.04116,
        "recall": 0.066406,
        "f1": 0.046577,
        "accuracy": 0.066406,
        "main_score": 0.046577,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.021102,
        "recall": 0.042969,
        "f1": 0.024857,
        "accuracy": 0.042969,
        "main_score": 0.024857,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.018215,
        "recall": 0.039062,
        "f1": 0.022255,
        "accuracy": 0.039062,
        "main_score": 0.022255,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.019077,
        "recall": 0.035156,
        "f1": 0.022365,
        "accuracy": 0.035156,
        "main_score": 0.022365,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.137928,
        "recall": 0.15918,
        "f1": 0.143625,
        "accuracy": 0.15918,
        "main_score": 0.143625,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.015336,
        "recall": 0.03418,
        "f1": 0.018342,
        "accuracy": 0.03418,
        "main_score": 0.018342,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007061,
        "recall": 0.020508,
        "f1": 0.00919,
        "accuracy": 0.020508,
        "main_score": 0.00919,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.144111,
        "recall": 0.167969,
        "f1": 0.149928,
        "accuracy": 0.167969,
        "main_score": 0.149928,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.186002,
        "recall": 0.220703,
        "f1": 0.195544,
        "accuracy": 0.220703,
        "main_score": 0.195544,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.173104,
        "recall": 0.206055,
        "f1": 0.182094,
        "accuracy": 0.206055,
        "main_score": 0.182094,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007736,
        "recall": 0.013672,
        "f1": 0.00898,
        "accuracy": 0.013672,
        "main_score": 0.00898,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.07254,
        "recall": 0.113281,
        "f1": 0.080608,
        "accuracy": 0.113281,
        "main_score": 0.080608,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.069891,
        "recall": 0.107422,
        "f1": 0.077934,
        "accuracy": 0.107422,
        "main_score": 0.077934,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.040782,
        "recall": 0.083984,
        "f1": 0.050668,
        "accuracy": 0.083984,
        "main_score": 0.050668,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.022264,
        "recall": 0.043945,
        "f1": 0.026402,
        "accuracy": 0.043945,
        "main_score": 0.026402,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000977,
        "f1": 4e-06,
        "accuracy": 0.000977,
        "main_score": 4e-06,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060414,
        "recall": 0.108398,
        "f1": 0.071399,
        "accuracy": 0.108398,
        "main_score": 0.071399,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.096047,
        "recall": 0.146484,
        "f1": 0.109001,
        "accuracy": 0.146484,
        "main_score": 0.109001,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.01911,
        "recall": 0.041992,
        "f1": 0.023161,
        "accuracy": 0.041992,
        "main_score": 0.023161,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.10514,
        "recall": 0.140625,
        "f1": 0.115199,
        "accuracy": 0.140625,
        "main_score": 0.115199,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.066398,
        "recall": 0.098633,
        "f1": 0.073516,
        "accuracy": 0.098633,
        "main_score": 0.073516,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.029717,
        "recall": 0.057617,
        "f1": 0.035805,
        "accuracy": 0.057617,
        "main_score": 0.035805,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.059772,
        "recall": 0.097656,
        "f1": 0.067267,
        "accuracy": 0.097656,
        "main_score": 0.067267,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.06666,
        "recall": 0.103516,
        "f1": 0.07436,
        "accuracy": 0.103516,
        "main_score": 0.07436,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.078909,
        "recall": 0.116211,
        "f1": 0.087558,
        "accuracy": 0.116211,
        "main_score": 0.087558,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.00829,
        "recall": 0.018555,
        "f1": 0.00955,
        "accuracy": 0.018555,
        "main_score": 0.00955,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.032824,
        "recall": 0.054688,
        "f1": 0.037292,
        "accuracy": 0.054688,
        "main_score": 0.037292,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.034182,
        "recall": 0.0625,
        "f1": 0.039334,
        "accuracy": 0.0625,
        "main_score": 0.039334,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.025027,
        "recall": 0.049805,
        "f1": 0.029418,
        "accuracy": 0.049805,
        "main_score": 0.029418,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.030013,
        "recall": 0.054688,
        "f1": 0.03643,
        "accuracy": 0.054688,
        "main_score": 0.03643,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.046114,
        "recall": 0.074219,
        "f1": 0.052997,
        "accuracy": 0.074219,
        "main_score": 0.052997,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.000977,
        "f1": 1.4e-05,
        "accuracy": 0.000977,
        "main_score": 1.4e-05,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.093796,
        "recall": 0.135742,
        "f1": 0.104039,
        "accuracy": 0.135742,
        "main_score": 0.104039,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.073219,
        "recall": 0.099609,
        "f1": 0.079569,
        "accuracy": 0.099609,
        "main_score": 0.079569,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.051257,
        "recall": 0.088867,
        "f1": 0.059862,
        "accuracy": 0.088867,
        "main_score": 0.059862,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.041526,
        "recall": 0.06543,
        "f1": 0.047171,
        "accuracy": 0.06543,
        "main_score": 0.047171,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000977,
        "f1": 4e-06,
        "accuracy": 0.000977,
        "main_score": 4e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031579,
        "recall": 0.061523,
        "f1": 0.036283,
        "accuracy": 0.061523,
        "main_score": 0.036283,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.057706,
        "recall": 0.094727,
        "f1": 0.065754,
        "accuracy": 0.094727,
        "main_score": 0.065754,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.043047,
        "recall": 0.080078,
        "f1": 0.051671,
        "accuracy": 0.080078,
        "main_score": 0.051671,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.047493,
        "recall": 0.069336,
        "f1": 0.052615,
        "accuracy": 0.069336,
        "main_score": 0.052615,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.085948,
        "recall": 0.118164,
        "f1": 0.094097,
        "accuracy": 0.118164,
        "main_score": 0.094097,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.011884,
        "recall": 0.025391,
        "f1": 0.014296,
        "accuracy": 0.025391,
        "main_score": 0.014296,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.058046,
        "recall": 0.083008,
        "f1": 0.063354,
        "accuracy": 0.083008,
        "main_score": 0.063354,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.090681,
        "recall": 0.125,
        "f1": 0.099318,
        "accuracy": 0.125,
        "main_score": 0.099318,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.079454,
        "recall": 0.109375,
        "f1": 0.087161,
        "accuracy": 0.109375,
        "main_score": 0.087161,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010629,
        "recall": 0.023438,
        "f1": 0.011926,
        "accuracy": 0.023438,
        "main_score": 0.011926,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.028274,
        "recall": 0.041016,
        "f1": 0.030202,
        "accuracy": 0.041016,
        "main_score": 0.030202,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.055376,
        "recall": 0.080078,
        "f1": 0.061149,
        "accuracy": 0.080078,
        "main_score": 0.061149,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.038566,
        "recall": 0.064453,
        "f1": 0.044496,
        "accuracy": 0.064453,
        "main_score": 0.044496,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.017416,
        "recall": 0.033203,
        "f1": 0.020342,
        "accuracy": 0.033203,
        "main_score": 0.020342,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.02609,
        "recall": 0.054688,
        "f1": 0.030876,
        "accuracy": 0.054688,
        "main_score": 0.030876,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 3.8e-05,
        "recall": 0.000977,
        "f1": 7.2e-05,
        "accuracy": 0.000977,
        "main_score": 7.2e-05,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.093218,
        "recall": 0.132812,
        "f1": 0.102849,
        "accuracy": 0.132812,
        "main_score": 0.102849,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.093486,
        "recall": 0.126953,
        "f1": 0.10221,
        "accuracy": 0.126953,
        "main_score": 0.10221,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.045628,
        "recall": 0.079102,
        "f1": 0.053728,
        "accuracy": 0.079102,
        "main_score": 0.053728,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.036196,
        "recall": 0.064453,
        "f1": 0.042662,
        "accuracy": 0.064453,
        "main_score": 0.042662,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000977,
        "f1": 5e-06,
        "accuracy": 0.000977,
        "main_score": 5e-06,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032426,
        "recall": 0.060547,
        "f1": 0.037518,
        "accuracy": 0.060547,
        "main_score": 0.037518,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.056218,
        "recall": 0.095703,
        "f1": 0.063495,
        "accuracy": 0.095703,
        "main_score": 0.063495,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.026982,
        "recall": 0.048828,
        "f1": 0.031836,
        "accuracy": 0.048828,
        "main_score": 0.031836,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.062562,
        "recall": 0.086914,
        "f1": 0.068226,
        "accuracy": 0.086914,
        "main_score": 0.068226,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.098837,
        "recall": 0.140625,
        "f1": 0.109285,
        "accuracy": 0.140625,
        "main_score": 0.109285,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.012357,
        "recall": 0.026367,
        "f1": 0.01492,
        "accuracy": 0.026367,
        "main_score": 0.01492,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.068827,
        "recall": 0.097656,
        "f1": 0.074069,
        "accuracy": 0.097656,
        "main_score": 0.074069,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.087037,
        "recall": 0.12793,
        "f1": 0.097979,
        "accuracy": 0.12793,
        "main_score": 0.097979,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.09439,
        "recall": 0.132812,
        "f1": 0.103674,
        "accuracy": 0.132812,
        "main_score": 0.103674,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010645,
        "recall": 0.020508,
        "f1": 0.011549,
        "accuracy": 0.020508,
        "main_score": 0.011549,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026675,
        "recall": 0.042969,
        "f1": 0.029408,
        "accuracy": 0.042969,
        "main_score": 0.029408,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.062161,
        "recall": 0.09082,
        "f1": 0.069034,
        "accuracy": 0.09082,
        "main_score": 0.069034,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.02235,
        "recall": 0.041016,
        "f1": 0.026138,
        "accuracy": 0.041016,
        "main_score": 0.026138,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.029653,
        "recall": 0.056641,
        "f1": 0.034559,
        "accuracy": 0.056641,
        "main_score": 0.034559,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.038965,
        "recall": 0.068359,
        "f1": 0.044538,
        "accuracy": 0.068359,
        "main_score": 0.044538,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 3.2e-05,
        "recall": 0.000977,
        "f1": 6.1e-05,
        "accuracy": 0.000977,
        "main_score": 6.1e-05,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.109557,
        "recall": 0.166992,
        "f1": 0.124199,
        "accuracy": 0.166992,
        "main_score": 0.124199,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.078422,
        "recall": 0.12207,
        "f1": 0.089634,
        "accuracy": 0.12207,
        "main_score": 0.089634,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.05717,
        "recall": 0.104492,
        "f1": 0.068692,
        "accuracy": 0.104492,
        "main_score": 0.068692,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.045164,
        "recall": 0.078125,
        "f1": 0.052428,
        "accuracy": 0.078125,
        "main_score": 0.052428,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000977,
        "f1": 4e-06,
        "accuracy": 0.000977,
        "main_score": 4e-06,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033812,
        "recall": 0.067383,
        "f1": 0.040314,
        "accuracy": 0.067383,
        "main_score": 0.040314,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.070372,
        "recall": 0.119141,
        "f1": 0.081348,
        "accuracy": 0.119141,
        "main_score": 0.081348,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.039804,
        "recall": 0.084961,
        "f1": 0.049794,
        "accuracy": 0.084961,
        "main_score": 0.049794,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.070737,
        "recall": 0.100586,
        "f1": 0.077997,
        "accuracy": 0.100586,
        "main_score": 0.077997,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.086174,
        "recall": 0.136719,
        "f1": 0.098384,
        "accuracy": 0.136719,
        "main_score": 0.098384,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.011148,
        "recall": 0.022461,
        "f1": 0.012955,
        "accuracy": 0.022461,
        "main_score": 0.012955,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.075138,
        "recall": 0.109375,
        "f1": 0.082908,
        "accuracy": 0.109375,
        "main_score": 0.082908,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.07602,
        "recall": 0.120117,
        "f1": 0.086846,
        "accuracy": 0.120117,
        "main_score": 0.086846,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.093664,
        "recall": 0.137695,
        "f1": 0.104839,
        "accuracy": 0.137695,
        "main_score": 0.104839,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.010318,
        "recall": 0.026367,
        "f1": 0.012033,
        "accuracy": 0.026367,
        "main_score": 0.012033,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.030672,
        "recall": 0.052734,
        "f1": 0.034924,
        "accuracy": 0.052734,
        "main_score": 0.034924,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.053358,
        "recall": 0.083984,
        "f1": 0.06042,
        "accuracy": 0.083984,
        "main_score": 0.06042,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.048636,
        "recall": 0.091797,
        "f1": 0.058068,
        "accuracy": 0.091797,
        "main_score": 0.058068,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.014368,
        "recall": 0.03418,
        "f1": 0.018061,
        "accuracy": 0.03418,
        "main_score": 0.018061,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.018378,
        "recall": 0.045898,
        "f1": 0.023089,
        "accuracy": 0.045898,
        "main_score": 0.023089,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.000977,
        "f1": 3.4e-05,
        "accuracy": 0.000977,
        "main_score": 3.4e-05,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.02569,
        "recall": 0.046875,
        "f1": 0.030235,
        "accuracy": 0.046875,
        "main_score": 0.030235,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.027717,
        "recall": 0.046875,
        "f1": 0.031721,
        "accuracy": 0.046875,
        "main_score": 0.031721,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.265053,
        "recall": 0.291016,
        "f1": 0.27198,
        "accuracy": 0.291016,
        "main_score": 0.27198,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.28335,
        "recall": 0.319336,
        "f1": 0.291701,
        "accuracy": 0.319336,
        "main_score": 0.291701,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.02764,
        "recall": 0.041016,
        "f1": 0.02997,
        "accuracy": 0.041016,
        "main_score": 0.02997,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.233734,
        "recall": 0.262695,
        "f1": 0.242004,
        "accuracy": 0.262695,
        "main_score": 0.242004,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.041804,
        "recall": 0.076172,
        "f1": 0.048152,
        "accuracy": 0.076172,
        "main_score": 0.048152,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.280624,
        "recall": 0.318359,
        "f1": 0.290483,
        "accuracy": 0.318359,
        "main_score": 0.290483,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015311,
        "recall": 0.03125,
        "f1": 0.018,
        "accuracy": 0.03125,
        "main_score": 0.018,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.015573,
        "recall": 0.025391,
        "f1": 0.016729,
        "accuracy": 0.025391,
        "main_score": 0.016729,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.035554,
        "recall": 0.05957,
        "f1": 0.040416,
        "accuracy": 0.05957,
        "main_score": 0.040416,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.122117,
        "recall": 0.154297,
        "f1": 0.130622,
        "accuracy": 0.154297,
        "main_score": 0.130622,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.014099,
        "recall": 0.025391,
        "f1": 0.015872,
        "accuracy": 0.025391,
        "main_score": 0.015872,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.024296,
        "recall": 0.043945,
        "f1": 0.027493,
        "accuracy": 0.043945,
        "main_score": 0.027493,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.027843,
        "recall": 0.045898,
        "f1": 0.031736,
        "accuracy": 0.045898,
        "main_score": 0.031736,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.019706,
        "recall": 0.03418,
        "f1": 0.021923,
        "accuracy": 0.03418,
        "main_score": 0.021923,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.006391,
        "recall": 0.019531,
        "f1": 0.008345,
        "accuracy": 0.019531,
        "main_score": 0.008345,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.019582,
        "recall": 0.037109,
        "f1": 0.022884,
        "accuracy": 0.037109,
        "main_score": 0.022884,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.28633,
        "recall": 0.322266,
        "f1": 0.295242,
        "accuracy": 0.322266,
        "main_score": 0.295242,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.151031,
        "recall": 0.185547,
        "f1": 0.159947,
        "accuracy": 0.185547,
        "main_score": 0.159947,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.190546,
        "recall": 0.22168,
        "f1": 0.199284,
        "accuracy": 0.22168,
        "main_score": 0.199284,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009926,
        "recall": 0.014648,
        "f1": 0.010792,
        "accuracy": 0.014648,
        "main_score": 0.010792,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.034468,
        "recall": 0.057617,
        "f1": 0.038598,
        "accuracy": 0.057617,
        "main_score": 0.038598,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.026157,
        "recall": 0.047852,
        "f1": 0.030376,
        "accuracy": 0.047852,
        "main_score": 0.030376,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.018447,
        "recall": 0.040039,
        "f1": 0.022129,
        "accuracy": 0.040039,
        "main_score": 0.022129,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.006344,
        "recall": 0.016602,
        "f1": 0.008321,
        "accuracy": 0.016602,
        "main_score": 0.008321,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.000977,
        "f1": 6e-06,
        "accuracy": 0.000977,
        "main_score": 6e-06,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019449,
        "recall": 0.038086,
        "f1": 0.022649,
        "accuracy": 0.038086,
        "main_score": 0.022649,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.030138,
        "recall": 0.048828,
        "f1": 0.032624,
        "accuracy": 0.048828,
        "main_score": 0.032624,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.009407,
        "recall": 0.025391,
        "f1": 0.012006,
        "accuracy": 0.025391,
        "main_score": 0.012006,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.035964,
        "recall": 0.057617,
        "f1": 0.03972,
        "accuracy": 0.057617,
        "main_score": 0.03972,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.027532,
        "recall": 0.046875,
        "f1": 0.030818,
        "accuracy": 0.046875,
        "main_score": 0.030818,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.011876,
        "recall": 0.029297,
        "f1": 0.014496,
        "accuracy": 0.029297,
        "main_score": 0.014496,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.030222,
        "recall": 0.050781,
        "f1": 0.03399,
        "accuracy": 0.050781,
        "main_score": 0.03399,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.024572,
        "recall": 0.047852,
        "f1": 0.028784,
        "accuracy": 0.047852,
        "main_score": 0.028784,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.037163,
        "recall": 0.054688,
        "f1": 0.040074,
        "accuracy": 0.054688,
        "main_score": 0.040074,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.042686,
        "recall": 0.069336,
        "f1": 0.047674,
        "accuracy": 0.069336,
        "main_score": 0.047674,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.003483,
        "recall": 0.010742,
        "f1": 0.004322,
        "accuracy": 0.010742,
        "main_score": 0.004322,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.014763,
        "recall": 0.035156,
        "f1": 0.018181,
        "accuracy": 0.035156,
        "main_score": 0.018181,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.010113,
        "recall": 0.027344,
        "f1": 0.01281,
        "accuracy": 0.027344,
        "main_score": 0.01281,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.012524,
        "recall": 0.023438,
        "f1": 0.014602,
        "accuracy": 0.023438,
        "main_score": 0.014602,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010917,
        "recall": 0.026367,
        "f1": 0.012672,
        "accuracy": 0.026367,
        "main_score": 0.012672,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 2.9e-05,
        "recall": 0.001953,
        "f1": 5.7e-05,
        "accuracy": 0.001953,
        "main_score": 5.7e-05,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.047043,
        "recall": 0.077148,
        "f1": 0.05323,
        "accuracy": 0.077148,
        "main_score": 0.05323,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.075578,
        "recall": 0.108398,
        "f1": 0.083496,
        "accuracy": 0.108398,
        "main_score": 0.083496,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.02166,
        "recall": 0.040039,
        "f1": 0.02495,
        "accuracy": 0.040039,
        "main_score": 0.02495,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.03942,
        "recall": 0.074219,
        "f1": 0.047409,
        "accuracy": 0.074219,
        "main_score": 0.047409,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000977,
        "f1": 3e-06,
        "accuracy": 0.000977,
        "main_score": 3e-06,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013089,
        "recall": 0.026367,
        "f1": 0.015036,
        "accuracy": 0.026367,
        "main_score": 0.015036,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.026715,
        "recall": 0.048828,
        "f1": 0.030728,
        "accuracy": 0.048828,
        "main_score": 0.030728,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.027741,
        "recall": 0.054688,
        "f1": 0.033613,
        "accuracy": 0.054688,
        "main_score": 0.033613,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.021635,
        "recall": 0.036133,
        "f1": 0.024004,
        "accuracy": 0.036133,
        "main_score": 0.024004,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.059654,
        "recall": 0.086914,
        "f1": 0.066476,
        "accuracy": 0.086914,
        "main_score": 0.066476,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.005338,
        "recall": 0.011719,
        "f1": 0.006326,
        "accuracy": 0.011719,
        "main_score": 0.006326,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.027448,
        "recall": 0.040039,
        "f1": 0.029908,
        "accuracy": 0.040039,
        "main_score": 0.029908,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.038123,
        "recall": 0.073242,
        "f1": 0.046319,
        "accuracy": 0.073242,
        "main_score": 0.046319,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.049057,
        "recall": 0.076172,
        "f1": 0.055146,
        "accuracy": 0.076172,
        "main_score": 0.055146,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.035266,
        "recall": 0.053711,
        "f1": 0.039355,
        "accuracy": 0.053711,
        "main_score": 0.039355,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.004193,
        "recall": 0.010742,
        "f1": 0.004767,
        "accuracy": 0.010742,
        "main_score": 0.004767,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.011809,
        "recall": 0.018555,
        "f1": 0.01239,
        "accuracy": 0.018555,
        "main_score": 0.01239,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.019852,
        "recall": 0.039062,
        "f1": 0.023906,
        "accuracy": 0.039062,
        "main_score": 0.023906,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.009487,
        "recall": 0.016602,
        "f1": 0.011004,
        "accuracy": 0.016602,
        "main_score": 0.011004,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.011077,
        "recall": 0.021484,
        "f1": 0.012874,
        "accuracy": 0.021484,
        "main_score": 0.012874,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 3.2e-05,
        "recall": 0.000977,
        "f1": 6.1e-05,
        "accuracy": 0.000977,
        "main_score": 6.1e-05,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.045811,
        "recall": 0.069336,
        "f1": 0.051311,
        "accuracy": 0.069336,
        "main_score": 0.051311,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.031322,
        "recall": 0.057617,
        "f1": 0.036863,
        "accuracy": 0.057617,
        "main_score": 0.036863,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.277149,
        "recall": 0.308594,
        "f1": 0.285791,
        "accuracy": 0.308594,
        "main_score": 0.285791,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.319948,
        "recall": 0.361328,
        "f1": 0.331138,
        "accuracy": 0.361328,
        "main_score": 0.331138,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.017865,
        "recall": 0.03125,
        "f1": 0.020173,
        "accuracy": 0.03125,
        "main_score": 0.020173,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.250573,
        "recall": 0.27832,
        "f1": 0.258116,
        "accuracy": 0.27832,
        "main_score": 0.258116,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.052162,
        "recall": 0.094727,
        "f1": 0.061095,
        "accuracy": 0.094727,
        "main_score": 0.061095,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.361408,
        "recall": 0.40918,
        "f1": 0.374661,
        "accuracy": 0.40918,
        "main_score": 0.374661,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.026409,
        "recall": 0.043945,
        "f1": 0.029681,
        "accuracy": 0.043945,
        "main_score": 0.029681,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.009729,
        "recall": 0.019531,
        "f1": 0.010899,
        "accuracy": 0.019531,
        "main_score": 0.010899,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.050709,
        "recall": 0.076172,
        "f1": 0.05665,
        "accuracy": 0.076172,
        "main_score": 0.05665,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.123122,
        "recall": 0.164062,
        "f1": 0.133425,
        "accuracy": 0.164062,
        "main_score": 0.133425,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.029013,
        "recall": 0.052734,
        "f1": 0.03431,
        "accuracy": 0.052734,
        "main_score": 0.03431,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.043876,
        "recall": 0.068359,
        "f1": 0.049416,
        "accuracy": 0.068359,
        "main_score": 0.049416,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.029049,
        "recall": 0.045898,
        "f1": 0.032645,
        "accuracy": 0.045898,
        "main_score": 0.032645,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.056963,
        "recall": 0.089844,
        "f1": 0.064521,
        "accuracy": 0.089844,
        "main_score": 0.064521,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.235229,
        "recall": 0.266602,
        "f1": 0.241386,
        "accuracy": 0.266602,
        "main_score": 0.241386,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.013274,
        "recall": 0.023438,
        "f1": 0.014838,
        "accuracy": 0.023438,
        "main_score": 0.014838,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.03072,
        "recall": 0.051758,
        "f1": 0.034702,
        "accuracy": 0.051758,
        "main_score": 0.034702,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.149055,
        "recall": 0.182617,
        "f1": 0.157239,
        "accuracy": 0.182617,
        "main_score": 0.157239,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.187687,
        "recall": 0.226562,
        "f1": 0.19756,
        "accuracy": 0.226562,
        "main_score": 0.19756,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007467,
        "recall": 0.009766,
        "f1": 0.007738,
        "accuracy": 0.009766,
        "main_score": 0.007738,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.018307,
        "recall": 0.043945,
        "f1": 0.02298,
        "accuracy": 0.043945,
        "main_score": 0.02298,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.021635,
        "recall": 0.048828,
        "f1": 0.026572,
        "accuracy": 0.048828,
        "main_score": 0.026572,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.176054,
        "recall": 0.208984,
        "f1": 0.184548,
        "accuracy": 0.208984,
        "main_score": 0.184548,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.173166,
        "recall": 0.199219,
        "f1": 0.179697,
        "accuracy": 0.199219,
        "main_score": 0.179697,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.017576,
        "recall": 0.027344,
        "f1": 0.019199,
        "accuracy": 0.027344,
        "main_score": 0.019199,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.200421,
        "recall": 0.241211,
        "f1": 0.210546,
        "accuracy": 0.241211,
        "main_score": 0.210546,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.049933,
        "recall": 0.089844,
        "f1": 0.058042,
        "accuracy": 0.089844,
        "main_score": 0.058042,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.155246,
        "recall": 0.1875,
        "f1": 0.163103,
        "accuracy": 0.1875,
        "main_score": 0.163103,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.048186,
        "recall": 0.081055,
        "f1": 0.05566,
        "accuracy": 0.081055,
        "main_score": 0.05566,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00991,
        "recall": 0.019531,
        "f1": 0.011195,
        "accuracy": 0.019531,
        "main_score": 0.011195,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.021566,
        "recall": 0.046875,
        "f1": 0.026223,
        "accuracy": 0.046875,
        "main_score": 0.026223,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.175498,
        "recall": 0.211914,
        "f1": 0.185019,
        "accuracy": 0.211914,
        "main_score": 0.185019,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.041484,
        "recall": 0.06543,
        "f1": 0.046902,
        "accuracy": 0.06543,
        "main_score": 0.046902,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.020306,
        "recall": 0.047852,
        "f1": 0.025075,
        "accuracy": 0.047852,
        "main_score": 0.025075,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.024958,
        "recall": 0.055664,
        "f1": 0.030329,
        "accuracy": 0.055664,
        "main_score": 0.030329,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.023565,
        "recall": 0.043945,
        "f1": 0.027236,
        "accuracy": 0.043945,
        "main_score": 0.027236,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.164297,
        "recall": 0.183594,
        "f1": 0.168883,
        "accuracy": 0.183594,
        "main_score": 0.168883,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.009927,
        "recall": 0.03418,
        "f1": 0.013522,
        "accuracy": 0.03418,
        "main_score": 0.013522,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.015676,
        "recall": 0.040039,
        "f1": 0.019296,
        "accuracy": 0.040039,
        "main_score": 0.019296,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.16227,
        "recall": 0.185547,
        "f1": 0.1687,
        "accuracy": 0.185547,
        "main_score": 0.1687,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.228381,
        "recall": 0.271484,
        "f1": 0.239684,
        "accuracy": 0.271484,
        "main_score": 0.239684,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010649,
        "recall": 0.016602,
        "f1": 0.011891,
        "accuracy": 0.016602,
        "main_score": 0.011891,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.026798,
        "recall": 0.053711,
        "f1": 0.032043,
        "accuracy": 0.053711,
        "main_score": 0.032043,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.028273,
        "recall": 0.057617,
        "f1": 0.03431,
        "accuracy": 0.057617,
        "main_score": 0.03431,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.232348,
        "recall": 0.267578,
        "f1": 0.240491,
        "accuracy": 0.267578,
        "main_score": 0.240491,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.214252,
        "recall": 0.241211,
        "f1": 0.221137,
        "accuracy": 0.241211,
        "main_score": 0.221137,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.020419,
        "recall": 0.03418,
        "f1": 0.022952,
        "accuracy": 0.03418,
        "main_score": 0.022952,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.234482,
        "recall": 0.275391,
        "f1": 0.24585,
        "accuracy": 0.275391,
        "main_score": 0.24585,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.056758,
        "recall": 0.107422,
        "f1": 0.067735,
        "accuracy": 0.107422,
        "main_score": 0.067735,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.20983,
        "recall": 0.236328,
        "f1": 0.216714,
        "accuracy": 0.236328,
        "main_score": 0.216714,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.070004,
        "recall": 0.110352,
        "f1": 0.079924,
        "accuracy": 0.110352,
        "main_score": 0.079924,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.010061,
        "recall": 0.020508,
        "f1": 0.011518,
        "accuracy": 0.020508,
        "main_score": 0.011518,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.029154,
        "recall": 0.056641,
        "f1": 0.034277,
        "accuracy": 0.056641,
        "main_score": 0.034277,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.173242,
        "recall": 0.210938,
        "f1": 0.184133,
        "accuracy": 0.210938,
        "main_score": 0.184133,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.053411,
        "recall": 0.083984,
        "f1": 0.061015,
        "accuracy": 0.083984,
        "main_score": 0.061015,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.022382,
        "recall": 0.047852,
        "f1": 0.027151,
        "accuracy": 0.047852,
        "main_score": 0.027151,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.040689,
        "recall": 0.078125,
        "f1": 0.048204,
        "accuracy": 0.078125,
        "main_score": 0.048204,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.032112,
        "recall": 0.055664,
        "f1": 0.036366,
        "accuracy": 0.055664,
        "main_score": 0.036366,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.192974,
        "recall": 0.213867,
        "f1": 0.198265,
        "accuracy": 0.213867,
        "main_score": 0.198265,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.013128,
        "recall": 0.035156,
        "f1": 0.0167,
        "accuracy": 0.035156,
        "main_score": 0.0167,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.017442,
        "recall": 0.041992,
        "f1": 0.022141,
        "accuracy": 0.041992,
        "main_score": 0.022141,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.205835,
        "recall": 0.232422,
        "f1": 0.212178,
        "accuracy": 0.232422,
        "main_score": 0.212178,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.220125,
        "recall": 0.269531,
        "f1": 0.234012,
        "accuracy": 0.269531,
        "main_score": 0.234012,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.01043,
        "recall": 0.014648,
        "f1": 0.011156,
        "accuracy": 0.014648,
        "main_score": 0.011156,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001037,
        "recall": 0.00293,
        "f1": 0.001092,
        "accuracy": 0.00293,
        "main_score": 0.001092,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001098,
        "recall": 0.003906,
        "f1": 0.001202,
        "accuracy": 0.003906,
        "main_score": 0.001202,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.039593,
        "recall": 0.071289,
        "f1": 0.045163,
        "accuracy": 0.071289,
        "main_score": 0.045163,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.046912,
        "recall": 0.071289,
        "f1": 0.051732,
        "accuracy": 0.071289,
        "main_score": 0.051732,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.076519,
        "recall": 0.120117,
        "f1": 0.083925,
        "accuracy": 0.120117,
        "main_score": 0.083925,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.047298,
        "recall": 0.074219,
        "f1": 0.051726,
        "accuracy": 0.074219,
        "main_score": 0.051726,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.005728,
        "recall": 0.018555,
        "f1": 0.006795,
        "accuracy": 0.018555,
        "main_score": 0.006795,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.04472,
        "recall": 0.078125,
        "f1": 0.050731,
        "accuracy": 0.078125,
        "main_score": 0.050731,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 2.6e-05,
        "recall": 0.001953,
        "f1": 5e-05,
        "accuracy": 0.001953,
        "main_score": 5e-05,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.448201,
        "recall": 0.529297,
        "f1": 0.467352,
        "accuracy": 0.529297,
        "main_score": 0.467352,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 9.7e-05,
        "recall": 0.003906,
        "f1": 0.000188,
        "accuracy": 0.003906,
        "main_score": 0.000188,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.030167,
        "recall": 0.050781,
        "f1": 0.033455,
        "accuracy": 0.050781,
        "main_score": 0.033455,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000977,
        "recall": 0.000977,
        "f1": 0.000977,
        "accuracy": 0.000977,
        "main_score": 0.000977,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.001953,
        "f1": 0.001031,
        "accuracy": 0.001953,
        "main_score": 0.001031,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.000977,
        "f1": 1.8e-05,
        "accuracy": 0.000977,
        "main_score": 1.8e-05,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.000217,
        "recall": 0.00293,
        "f1": 0.000388,
        "accuracy": 0.00293,
        "main_score": 0.000388,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.046887,
        "recall": 0.075195,
        "f1": 0.050948,
        "accuracy": 0.075195,
        "main_score": 0.050948,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001027,
        "recall": 0.003906,
        "f1": 0.001074,
        "accuracy": 0.003906,
        "main_score": 0.001074,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001308,
        "recall": 0.00293,
        "f1": 0.001477,
        "accuracy": 0.00293,
        "main_score": 0.001477,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.040817,
        "recall": 0.061523,
        "f1": 0.044929,
        "accuracy": 0.061523,
        "main_score": 0.044929,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.028261,
        "recall": 0.048828,
        "f1": 0.032057,
        "accuracy": 0.048828,
        "main_score": 0.032057,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.032653,
        "recall": 0.054688,
        "f1": 0.035984,
        "accuracy": 0.054688,
        "main_score": 0.035984,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 72.63286995887756,
  "kg_co2_emissions": 0.002331266137014285
}