{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.676953,
        "f1": 0.67498,
        "f1_weighted": 0.674988,
        "ap": 0.62139,
        "ap_weighted": 0.62139,
        "scores_per_experiment": [
          {
            "accuracy": 0.668945,
            "f1": 0.658511,
            "f1_weighted": 0.658685,
            "ap": 0.60669,
            "ap_weighted": 0.60669
          },
          {
            "accuracy": 0.692871,
            "f1": 0.692862,
            "f1_weighted": 0.692867,
            "ap": 0.634693,
            "ap_weighted": 0.634693
          },
          {
            "accuracy": 0.708496,
            "f1": 0.707542,
            "f1_weighted": 0.707591,
            "ap": 0.644572,
            "ap_weighted": 0.644572
          },
          {
            "accuracy": 0.689453,
            "f1": 0.68945,
            "f1_weighted": 0.689448,
            "ap": 0.632308,
            "ap_weighted": 0.632308
          },
          {
            "accuracy": 0.652832,
            "f1": 0.651986,
            "f1_weighted": 0.651935,
            "ap": 0.603928,
            "ap_weighted": 0.603928
          },
          {
            "accuracy": 0.681152,
            "f1": 0.678529,
            "f1_weighted": 0.678614,
            "ap": 0.619613,
            "ap_weighted": 0.619613
          },
          {
            "accuracy": 0.681641,
            "f1": 0.681621,
            "f1_weighted": 0.681628,
            "ap": 0.624754,
            "ap_weighted": 0.624754
          },
          {
            "accuracy": 0.681641,
            "f1": 0.681402,
            "f1_weighted": 0.681377,
            "ap": 0.627268,
            "ap_weighted": 0.627268
          },
          {
            "accuracy": 0.633789,
            "f1": 0.63273,
            "f1_weighted": 0.632672,
            "ap": 0.58855,
            "ap_weighted": 0.58855
          },
          {
            "accuracy": 0.678711,
            "f1": 0.675164,
            "f1_weighted": 0.675065,
            "ap": 0.631523,
            "ap_weighted": 0.631523
          }
        ],
        "main_score": 0.676953,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.685986,
        "f1": 0.683887,
        "f1_weighted": 0.683896,
        "ap": 0.628846,
        "ap_weighted": 0.628846,
        "scores_per_experiment": [
          {
            "accuracy": 0.662598,
            "f1": 0.650893,
            "f1_weighted": 0.651018,
            "ap": 0.601354,
            "ap_weighted": 0.601354
          },
          {
            "accuracy": 0.722656,
            "f1": 0.722571,
            "f1_weighted": 0.72258,
            "ap": 0.660164,
            "ap_weighted": 0.660164
          },
          {
            "accuracy": 0.708496,
            "f1": 0.707993,
            "f1_weighted": 0.708017,
            "ap": 0.645287,
            "ap_weighted": 0.645287
          },
          {
            "accuracy": 0.699707,
            "f1": 0.699662,
            "f1_weighted": 0.699669,
            "ap": 0.639741,
            "ap_weighted": 0.639741
          },
          {
            "accuracy": 0.680664,
            "f1": 0.680073,
            "f1_weighted": 0.680047,
            "ap": 0.6271,
            "ap_weighted": 0.6271
          },
          {
            "accuracy": 0.6875,
            "f1": 0.684491,
            "f1_weighted": 0.684551,
            "ap": 0.623975,
            "ap_weighted": 0.623975
          },
          {
            "accuracy": 0.675293,
            "f1": 0.675163,
            "f1_weighted": 0.675175,
            "ap": 0.618134,
            "ap_weighted": 0.618134
          },
          {
            "accuracy": 0.691895,
            "f1": 0.691688,
            "f1_weighted": 0.691672,
            "ap": 0.635809,
            "ap_weighted": 0.635809
          },
          {
            "accuracy": 0.637695,
            "f1": 0.636759,
            "f1_weighted": 0.636723,
            "ap": 0.591014,
            "ap_weighted": 0.591014
          },
          {
            "accuracy": 0.693359,
            "f1": 0.689579,
            "f1_weighted": 0.689512,
            "ap": 0.645876,
            "ap_weighted": 0.645876
          }
        ],
        "main_score": 0.685986,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 18.642114877700806,
  "kg_co2_emissions": 0.0007651926581570788
}