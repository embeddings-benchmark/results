{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.810911,
        "f1": 0.681434,
        "f1_weighted": 0.833015,
        "ap": 0.294944,
        "ap_weighted": 0.294944,
        "scores_per_experiment": [
          {
            "accuracy": 0.743986,
            "f1": 0.617137,
            "f1_weighted": 0.78223,
            "ap": 0.230262,
            "ap_weighted": 0.230262
          },
          {
            "accuracy": 0.859107,
            "f1": 0.722954,
            "f1_weighted": 0.86845,
            "ap": 0.333385,
            "ap_weighted": 0.333385
          },
          {
            "accuracy": 0.824742,
            "f1": 0.696875,
            "f1_weighted": 0.844362,
            "ap": 0.309786,
            "ap_weighted": 0.309786
          },
          {
            "accuracy": 0.81701,
            "f1": 0.696759,
            "f1_weighted": 0.839814,
            "ap": 0.317319,
            "ap_weighted": 0.317319
          },
          {
            "accuracy": 0.774055,
            "f1": 0.628235,
            "f1_weighted": 0.802659,
            "ap": 0.226832,
            "ap_weighted": 0.226832
          },
          {
            "accuracy": 0.850515,
            "f1": 0.710164,
            "f1_weighted": 0.861258,
            "ap": 0.314838,
            "ap_weighted": 0.314838
          },
          {
            "accuracy": 0.847079,
            "f1": 0.694952,
            "f1_weighted": 0.856332,
            "ap": 0.289956,
            "ap_weighted": 0.289956
          },
          {
            "accuracy": 0.739691,
            "f1": 0.639789,
            "f1_weighted": 0.7819,
            "ap": 0.278938,
            "ap_weighted": 0.278938
          },
          {
            "accuracy": 0.80756,
            "f1": 0.677026,
            "f1_weighted": 0.830845,
            "ap": 0.285897,
            "ap_weighted": 0.285897
          },
          {
            "accuracy": 0.845361,
            "f1": 0.73045,
            "f1_weighted": 0.862295,
            "ap": 0.362224,
            "ap_weighted": 0.362224
          }
        ],
        "main_score": 0.810911,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.20588493347168,
  "kg_co2_emissions": 0.0004331351031458671
}