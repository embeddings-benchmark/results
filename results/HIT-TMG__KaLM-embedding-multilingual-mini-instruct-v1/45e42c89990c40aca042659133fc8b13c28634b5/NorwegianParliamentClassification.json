{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.560917,
        "f1": 0.558788,
        "f1_weighted": 0.558788,
        "ap": 0.535367,
        "ap_weighted": 0.535367,
        "scores_per_experiment": [
          {
            "accuracy": 0.560833,
            "f1": 0.558404,
            "f1_weighted": 0.558404,
            "ap": 0.534762,
            "ap_weighted": 0.534762
          },
          {
            "accuracy": 0.529167,
            "f1": 0.527513,
            "f1_weighted": 0.527513,
            "ap": 0.515344,
            "ap_weighted": 0.515344
          },
          {
            "accuracy": 0.5825,
            "f1": 0.582465,
            "f1_weighted": 0.582465,
            "ap": 0.547934,
            "ap_weighted": 0.547934
          },
          {
            "accuracy": 0.553333,
            "f1": 0.550807,
            "f1_weighted": 0.550807,
            "ap": 0.52914,
            "ap_weighted": 0.52914
          },
          {
            "accuracy": 0.605,
            "f1": 0.601653,
            "f1_weighted": 0.601653,
            "ap": 0.566,
            "ap_weighted": 0.566
          },
          {
            "accuracy": 0.5025,
            "f1": 0.492913,
            "f1_weighted": 0.492913,
            "ap": 0.501255,
            "ap_weighted": 0.501255
          },
          {
            "accuracy": 0.555,
            "f1": 0.554939,
            "f1_weighted": 0.554939,
            "ap": 0.530597,
            "ap_weighted": 0.530597
          },
          {
            "accuracy": 0.5525,
            "f1": 0.551625,
            "f1_weighted": 0.551625,
            "ap": 0.528783,
            "ap_weighted": 0.528783
          },
          {
            "accuracy": 0.6,
            "f1": 0.599461,
            "f1_weighted": 0.599461,
            "ap": 0.560791,
            "ap_weighted": 0.560791
          },
          {
            "accuracy": 0.568333,
            "f1": 0.568098,
            "f1_weighted": 0.568098,
            "ap": 0.539065,
            "ap_weighted": 0.539065
          }
        ],
        "main_score": 0.560917,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.558417,
        "f1": 0.555872,
        "f1_weighted": 0.555872,
        "ap": 0.534411,
        "ap_weighted": 0.534411,
        "scores_per_experiment": [
          {
            "accuracy": 0.555,
            "f1": 0.552134,
            "f1_weighted": 0.552134,
            "ap": 0.531101,
            "ap_weighted": 0.531101
          },
          {
            "accuracy": 0.53,
            "f1": 0.528899,
            "f1_weighted": 0.528899,
            "ap": 0.515821,
            "ap_weighted": 0.515821
          },
          {
            "accuracy": 0.586667,
            "f1": 0.586662,
            "f1_weighted": 0.586662,
            "ap": 0.550895,
            "ap_weighted": 0.550895
          },
          {
            "accuracy": 0.596667,
            "f1": 0.593373,
            "f1_weighted": 0.593373,
            "ap": 0.556252,
            "ap_weighted": 0.556252
          },
          {
            "accuracy": 0.5925,
            "f1": 0.587276,
            "f1_weighted": 0.587276,
            "ap": 0.55729,
            "ap_weighted": 0.55729
          },
          {
            "accuracy": 0.495833,
            "f1": 0.484096,
            "f1_weighted": 0.484096,
            "ap": 0.49793,
            "ap_weighted": 0.49793
          },
          {
            "accuracy": 0.5525,
            "f1": 0.55187,
            "f1_weighted": 0.55187,
            "ap": 0.52923,
            "ap_weighted": 0.52923
          },
          {
            "accuracy": 0.51,
            "f1": 0.509864,
            "f1_weighted": 0.509864,
            "ap": 0.505097,
            "ap_weighted": 0.505097
          },
          {
            "accuracy": 0.624167,
            "f1": 0.623916,
            "f1_weighted": 0.623916,
            "ap": 0.578341,
            "ap_weighted": 0.578341
          },
          {
            "accuracy": 0.540833,
            "f1": 0.540634,
            "f1_weighted": 0.540634,
            "ap": 0.522157,
            "ap_weighted": 0.522157
          }
        ],
        "main_score": 0.558417,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 66.93500065803528,
  "kg_co2_emissions": 0.005246057917901408
}