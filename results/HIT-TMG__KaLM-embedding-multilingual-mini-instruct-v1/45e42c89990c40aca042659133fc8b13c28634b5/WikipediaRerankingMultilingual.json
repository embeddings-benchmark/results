{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.836891,
        "mrr": 0.836891,
        "nAUC_map_max": 0.48352,
        "nAUC_map_std": 0.412857,
        "nAUC_map_diff1": 0.724668,
        "nAUC_mrr_max": 0.48352,
        "nAUC_mrr_std": 0.412857,
        "nAUC_mrr_diff1": 0.724668,
        "main_score": 0.836891,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.744476,
        "mrr": 0.744476,
        "nAUC_map_max": 0.380497,
        "nAUC_map_std": 0.408145,
        "nAUC_map_diff1": 0.585315,
        "nAUC_mrr_max": 0.380497,
        "nAUC_mrr_std": 0.408145,
        "nAUC_mrr_diff1": 0.585315,
        "main_score": 0.744476,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.835347,
        "mrr": 0.835347,
        "nAUC_map_max": 0.389235,
        "nAUC_map_std": 0.365206,
        "nAUC_map_diff1": 0.702052,
        "nAUC_mrr_max": 0.389235,
        "nAUC_mrr_std": 0.365206,
        "nAUC_mrr_diff1": 0.702052,
        "main_score": 0.835347,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.847278,
        "mrr": 0.847445,
        "nAUC_map_max": 0.450496,
        "nAUC_map_std": 0.444636,
        "nAUC_map_diff1": 0.733829,
        "nAUC_mrr_max": 0.451191,
        "nAUC_mrr_std": 0.443928,
        "nAUC_mrr_diff1": 0.733591,
        "main_score": 0.847278,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.878841,
        "mrr": 0.878841,
        "nAUC_map_max": 0.442799,
        "nAUC_map_std": 0.340643,
        "nAUC_map_diff1": 0.762445,
        "nAUC_mrr_max": 0.442799,
        "nAUC_mrr_std": 0.340643,
        "nAUC_mrr_diff1": 0.762445,
        "main_score": 0.878841,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.908081,
        "mrr": 0.908081,
        "nAUC_map_max": 0.602485,
        "nAUC_map_std": 0.481987,
        "nAUC_map_diff1": 0.859828,
        "nAUC_mrr_max": 0.602485,
        "nAUC_mrr_std": 0.481987,
        "nAUC_mrr_diff1": 0.859828,
        "main_score": 0.908081,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.833915,
        "mrr": 0.833915,
        "nAUC_map_max": 0.441345,
        "nAUC_map_std": 0.493479,
        "nAUC_map_diff1": 0.702282,
        "nAUC_mrr_max": 0.441345,
        "nAUC_mrr_std": 0.493479,
        "nAUC_mrr_diff1": 0.702282,
        "main_score": 0.833915,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.840619,
        "mrr": 0.840619,
        "nAUC_map_max": 0.352224,
        "nAUC_map_std": 0.390607,
        "nAUC_map_diff1": 0.733313,
        "nAUC_mrr_max": 0.352224,
        "nAUC_mrr_std": 0.390607,
        "nAUC_mrr_diff1": 0.733313,
        "main_score": 0.840619,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.790736,
        "mrr": 0.79143,
        "nAUC_map_max": 0.442797,
        "nAUC_map_std": 0.368875,
        "nAUC_map_diff1": 0.652314,
        "nAUC_mrr_max": 0.445882,
        "nAUC_mrr_std": 0.374877,
        "nAUC_mrr_diff1": 0.649903,
        "main_score": 0.790736,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.875181,
        "mrr": 0.875181,
        "nAUC_map_max": 0.519116,
        "nAUC_map_std": 0.452453,
        "nAUC_map_diff1": 0.809666,
        "nAUC_mrr_max": 0.519116,
        "nAUC_mrr_std": 0.452453,
        "nAUC_mrr_diff1": 0.809666,
        "main_score": 0.875181,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.865417,
        "mrr": 0.86575,
        "nAUC_map_max": 0.297496,
        "nAUC_map_std": 0.368964,
        "nAUC_map_diff1": 0.724848,
        "nAUC_mrr_max": 0.295401,
        "nAUC_mrr_std": 0.369347,
        "nAUC_mrr_diff1": 0.723577,
        "main_score": 0.865417,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.863736,
        "mrr": 0.863736,
        "nAUC_map_max": 0.4276,
        "nAUC_map_std": 0.400498,
        "nAUC_map_diff1": 0.716385,
        "nAUC_mrr_max": 0.4276,
        "nAUC_mrr_std": 0.400498,
        "nAUC_mrr_diff1": 0.716385,
        "main_score": 0.863736,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.833681,
        "mrr": 0.834015,
        "nAUC_map_max": 0.382718,
        "nAUC_map_std": 0.412258,
        "nAUC_map_diff1": 0.733662,
        "nAUC_mrr_max": 0.3821,
        "nAUC_mrr_std": 0.411312,
        "nAUC_mrr_diff1": 0.732614,
        "main_score": 0.833681,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.827829,
        "mrr": 0.828162,
        "nAUC_map_max": 0.366277,
        "nAUC_map_std": 0.38984,
        "nAUC_map_diff1": 0.691428,
        "nAUC_mrr_max": 0.366583,
        "nAUC_mrr_std": 0.392934,
        "nAUC_mrr_diff1": 0.690347,
        "main_score": 0.827829,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.831302,
        "mrr": 0.831302,
        "nAUC_map_max": 0.419332,
        "nAUC_map_std": 0.347217,
        "nAUC_map_diff1": 0.677878,
        "nAUC_mrr_max": 0.419332,
        "nAUC_mrr_std": 0.347217,
        "nAUC_mrr_diff1": 0.677878,
        "main_score": 0.831302,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.865939,
        "mrr": 0.865939,
        "nAUC_map_max": 0.378052,
        "nAUC_map_std": 0.402739,
        "nAUC_map_diff1": 0.708315,
        "nAUC_mrr_max": 0.378052,
        "nAUC_mrr_std": 0.402739,
        "nAUC_mrr_diff1": 0.708315,
        "main_score": 0.865939,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 913.9794547557831,
  "kg_co2_emissions": 0.08561689192491276
}