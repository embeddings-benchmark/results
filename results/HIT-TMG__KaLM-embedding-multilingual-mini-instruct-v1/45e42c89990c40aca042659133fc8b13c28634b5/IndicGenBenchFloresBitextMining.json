{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.981946,
        "recall": 0.987964,
        "f1": 0.983952,
        "accuracy": 0.987964,
        "main_score": 0.983952,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978937,
        "recall": 0.985958,
        "f1": 0.981277,
        "accuracy": 0.985958,
        "main_score": 0.981277,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.694712,
        "recall": 0.755266,
        "f1": 0.710984,
        "accuracy": 0.755266,
        "main_score": 0.710984,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.76248,
        "recall": 0.822467,
        "f1": 0.780473,
        "accuracy": 0.822467,
        "main_score": 0.780473,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.98228,
        "recall": 0.987964,
        "f1": 0.984119,
        "accuracy": 0.987964,
        "main_score": 0.984119,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.992477,
        "recall": 0.994985,
        "f1": 0.993313,
        "accuracy": 0.994985,
        "main_score": 0.993313,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.675978,
        "recall": 0.741224,
        "f1": 0.692771,
        "accuracy": 0.741224,
        "main_score": 0.692771,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.751087,
        "recall": 0.812437,
        "f1": 0.769628,
        "accuracy": 0.812437,
        "main_score": 0.769628,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.695427,
        "recall": 0.760281,
        "f1": 0.713099,
        "accuracy": 0.760281,
        "main_score": 0.713099,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.767813,
        "recall": 0.82347,
        "f1": 0.784107,
        "accuracy": 0.82347,
        "main_score": 0.784107,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.931461,
        "recall": 0.953862,
        "f1": 0.938816,
        "accuracy": 0.953862,
        "main_score": 0.938816,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.953862,
        "recall": 0.967904,
        "f1": 0.958208,
        "accuracy": 0.967904,
        "main_score": 0.958208,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.677914,
        "recall": 0.748245,
        "f1": 0.696516,
        "accuracy": 0.748245,
        "main_score": 0.696516,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.762354,
        "recall": 0.824473,
        "f1": 0.78111,
        "accuracy": 0.824473,
        "main_score": 0.78111,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.938649,
        "recall": 0.956871,
        "f1": 0.9443,
        "accuracy": 0.956871,
        "main_score": 0.9443,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.962889,
        "recall": 0.974925,
        "f1": 0.966901,
        "accuracy": 0.974925,
        "main_score": 0.966901,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.926028,
        "recall": 0.948847,
        "f1": 0.9332,
        "accuracy": 0.948847,
        "main_score": 0.9332,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.947175,
        "recall": 0.963892,
        "f1": 0.952524,
        "accuracy": 0.963892,
        "main_score": 0.952524,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.825543,
        "recall": 0.874624,
        "f1": 0.840221,
        "accuracy": 0.874624,
        "main_score": 0.840221,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.884186,
        "recall": 0.91675,
        "f1": 0.894316,
        "accuracy": 0.91675,
        "main_score": 0.894316,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.975928,
        "recall": 0.983952,
        "f1": 0.978602,
        "accuracy": 0.983952,
        "main_score": 0.978602,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.977432,
        "recall": 0.984955,
        "f1": 0.97994,
        "accuracy": 0.984955,
        "main_score": 0.97994,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.910064,
        "recall": 0.937813,
        "f1": 0.91889,
        "accuracy": 0.937813,
        "main_score": 0.91889,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.938315,
        "recall": 0.956871,
        "f1": 0.9445,
        "accuracy": 0.956871,
        "main_score": 0.9445,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.506893,
        "recall": 0.580742,
        "f1": 0.525196,
        "accuracy": 0.580742,
        "main_score": 0.525196,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.586753,
        "recall": 0.669007,
        "f1": 0.609465,
        "accuracy": 0.669007,
        "main_score": 0.609465,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.602591,
        "recall": 0.681043,
        "f1": 0.623071,
        "accuracy": 0.681043,
        "main_score": 0.623071,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.714577,
        "recall": 0.777332,
        "f1": 0.732784,
        "accuracy": 0.777332,
        "main_score": 0.732784,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.687324,
        "recall": 0.75326,
        "f1": 0.705523,
        "accuracy": 0.75326,
        "main_score": 0.705523,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.711812,
        "recall": 0.781344,
        "f1": 0.732234,
        "accuracy": 0.781344,
        "main_score": 0.732234,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.784563,
        "recall": 0.837513,
        "f1": 0.799768,
        "accuracy": 0.837513,
        "main_score": 0.799768,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.820369,
        "recall": 0.863591,
        "f1": 0.833389,
        "accuracy": 0.863591,
        "main_score": 0.833389,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.972752,
        "recall": 0.980943,
        "f1": 0.975426,
        "accuracy": 0.980943,
        "main_score": 0.975426,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.979438,
        "recall": 0.984955,
        "f1": 0.981277,
        "accuracy": 0.984955,
        "main_score": 0.981277,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.972501,
        "recall": 0.980943,
        "f1": 0.975159,
        "accuracy": 0.980943,
        "main_score": 0.975159,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978937,
        "recall": 0.985958,
        "f1": 0.981277,
        "accuracy": 0.985958,
        "main_score": 0.981277,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.052892,
        "recall": 0.066199,
        "f1": 0.055724,
        "accuracy": 0.066199,
        "main_score": 0.055724,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.05022,
        "recall": 0.089268,
        "f1": 0.057447,
        "accuracy": 0.089268,
        "main_score": 0.057447,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.333012,
        "recall": 0.385155,
        "f1": 0.345794,
        "accuracy": 0.385155,
        "main_score": 0.345794,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.397354,
        "recall": 0.472417,
        "f1": 0.416948,
        "accuracy": 0.472417,
        "main_score": 0.416948,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.969074,
        "recall": 0.978937,
        "f1": 0.97225,
        "accuracy": 0.978937,
        "main_score": 0.97225,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.987964,
        "recall": 0.991976,
        "f1": 0.989301,
        "accuracy": 0.991976,
        "main_score": 0.989301,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.790265,
        "recall": 0.842528,
        "f1": 0.805985,
        "accuracy": 0.842528,
        "main_score": 0.805985,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.838382,
        "recall": 0.881645,
        "f1": 0.851607,
        "accuracy": 0.881645,
        "main_score": 0.851607,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.966148,
        "recall": 0.976931,
        "f1": 0.969642,
        "accuracy": 0.976931,
        "main_score": 0.969642,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.975259,
        "recall": 0.982949,
        "f1": 0.977767,
        "accuracy": 0.982949,
        "main_score": 0.977767,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.968572,
        "recall": 0.977934,
        "f1": 0.971414,
        "accuracy": 0.977934,
        "main_score": 0.971414,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.969408,
        "recall": 0.978937,
        "f1": 0.972417,
        "accuracy": 0.978937,
        "main_score": 0.972417,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.975593,
        "recall": 0.982949,
        "f1": 0.977934,
        "accuracy": 0.982949,
        "main_score": 0.977934,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98345,
        "recall": 0.988967,
        "f1": 0.985289,
        "accuracy": 0.988967,
        "main_score": 0.985289,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.315905,
        "recall": 0.353059,
        "f1": 0.325137,
        "accuracy": 0.353059,
        "main_score": 0.325137,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.3704,
        "recall": 0.454363,
        "f1": 0.391405,
        "accuracy": 0.454363,
        "main_score": 0.391405,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.97225,
        "recall": 0.980943,
        "f1": 0.975092,
        "accuracy": 0.980943,
        "main_score": 0.975092,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97342,
        "recall": 0.981946,
        "f1": 0.976262,
        "accuracy": 0.981946,
        "main_score": 0.976262,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.964978,
        "recall": 0.975928,
        "f1": 0.968472,
        "accuracy": 0.975928,
        "main_score": 0.968472,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.973755,
        "recall": 0.981946,
        "f1": 0.976429,
        "accuracy": 0.981946,
        "main_score": 0.976429,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.011698,
        "recall": 0.016048,
        "f1": 0.011992,
        "accuracy": 0.016048,
        "main_score": 0.011992,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004264,
        "recall": 0.02006,
        "f1": 0.006454,
        "accuracy": 0.02006,
        "main_score": 0.006454,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.977767,
        "recall": 0.985178,
        "f1": 0.980237,
        "accuracy": 0.985178,
        "main_score": 0.980237,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980731,
        "recall": 0.987154,
        "f1": 0.982872,
        "accuracy": 0.987154,
        "main_score": 0.982872,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.710671,
        "recall": 0.77668,
        "f1": 0.729089,
        "accuracy": 0.77668,
        "main_score": 0.729089,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.771772,
        "recall": 0.831028,
        "f1": 0.789723,
        "accuracy": 0.831028,
        "main_score": 0.789723,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.997036,
        "recall": 0.998024,
        "f1": 0.997365,
        "accuracy": 0.998024,
        "main_score": 0.997365,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.992589,
        "recall": 0.995059,
        "f1": 0.993412,
        "accuracy": 0.995059,
        "main_score": 0.993412,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.663974,
        "recall": 0.729249,
        "f1": 0.681328,
        "accuracy": 0.729249,
        "main_score": 0.681328,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.771245,
        "recall": 0.831028,
        "f1": 0.789592,
        "accuracy": 0.831028,
        "main_score": 0.789592,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.691612,
        "recall": 0.759881,
        "f1": 0.710523,
        "accuracy": 0.759881,
        "main_score": 0.710523,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.774202,
        "recall": 0.832016,
        "f1": 0.79109,
        "accuracy": 0.832016,
        "main_score": 0.79109,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.938076,
        "recall": 0.95751,
        "f1": 0.944335,
        "accuracy": 0.95751,
        "main_score": 0.944335,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.949275,
        "recall": 0.965415,
        "f1": 0.954545,
        "accuracy": 0.965415,
        "main_score": 0.954545,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.652077,
        "recall": 0.725296,
        "f1": 0.671696,
        "accuracy": 0.725296,
        "main_score": 0.671696,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.763356,
        "recall": 0.821146,
        "f1": 0.780717,
        "accuracy": 0.821146,
        "main_score": 0.780717,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.943511,
        "recall": 0.961462,
        "f1": 0.949275,
        "accuracy": 0.961462,
        "main_score": 0.949275,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.957839,
        "recall": 0.971344,
        "f1": 0.962286,
        "accuracy": 0.971344,
        "main_score": 0.962286,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.923123,
        "recall": 0.94664,
        "f1": 0.930501,
        "accuracy": 0.94664,
        "main_score": 0.930501,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.941403,
        "recall": 0.959486,
        "f1": 0.947299,
        "accuracy": 0.959486,
        "main_score": 0.947299,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.826805,
        "recall": 0.874506,
        "f1": 0.840977,
        "accuracy": 0.874506,
        "main_score": 0.840977,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.873271,
        "recall": 0.911067,
        "f1": 0.885112,
        "accuracy": 0.911067,
        "main_score": 0.885112,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.967227,
        "recall": 0.977273,
        "f1": 0.97052,
        "accuracy": 0.977273,
        "main_score": 0.97052,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.979249,
        "recall": 0.986166,
        "f1": 0.981555,
        "accuracy": 0.986166,
        "main_score": 0.981555,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.929513,
        "recall": 0.950593,
        "f1": 0.936265,
        "accuracy": 0.950593,
        "main_score": 0.936265,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.951746,
        "recall": 0.965415,
        "f1": 0.956192,
        "accuracy": 0.965415,
        "main_score": 0.956192,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.471451,
        "recall": 0.549407,
        "f1": 0.489965,
        "accuracy": 0.549407,
        "main_score": 0.489965,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.590168,
        "recall": 0.66996,
        "f1": 0.612703,
        "accuracy": 0.66996,
        "main_score": 0.612703,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.608594,
        "recall": 0.677866,
        "f1": 0.627313,
        "accuracy": 0.677866,
        "main_score": 0.627313,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.704464,
        "recall": 0.772727,
        "f1": 0.724366,
        "accuracy": 0.772727,
        "main_score": 0.724366,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.699838,
        "recall": 0.767787,
        "f1": 0.718657,
        "accuracy": 0.767787,
        "main_score": 0.718657,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.756959,
        "recall": 0.814229,
        "f1": 0.773784,
        "accuracy": 0.814229,
        "main_score": 0.773784,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.786497,
        "recall": 0.840909,
        "f1": 0.801723,
        "accuracy": 0.840909,
        "main_score": 0.801723,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.841551,
        "recall": 0.881423,
        "f1": 0.853576,
        "accuracy": 0.881423,
        "main_score": 0.853576,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.971838,
        "recall": 0.980237,
        "f1": 0.974638,
        "accuracy": 0.980237,
        "main_score": 0.974638,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972661,
        "recall": 0.980237,
        "f1": 0.975132,
        "accuracy": 0.980237,
        "main_score": 0.975132,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.982213,
        "recall": 0.988142,
        "f1": 0.98419,
        "accuracy": 0.988142,
        "main_score": 0.98419,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980731,
        "recall": 0.987154,
        "f1": 0.982872,
        "accuracy": 0.987154,
        "main_score": 0.982872,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.044774,
        "recall": 0.057312,
        "f1": 0.047595,
        "accuracy": 0.057312,
        "main_score": 0.047595,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.047516,
        "recall": 0.08498,
        "f1": 0.054181,
        "accuracy": 0.08498,
        "main_score": 0.054181,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.329581,
        "recall": 0.391304,
        "f1": 0.344609,
        "accuracy": 0.391304,
        "main_score": 0.344609,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.373049,
        "recall": 0.437747,
        "f1": 0.390027,
        "accuracy": 0.437747,
        "main_score": 0.390027,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.985178,
        "recall": 0.990119,
        "f1": 0.986825,
        "accuracy": 0.990119,
        "main_score": 0.986825,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98666,
        "recall": 0.991107,
        "f1": 0.988142,
        "accuracy": 0.991107,
        "main_score": 0.988142,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.78608,
        "recall": 0.836957,
        "f1": 0.801335,
        "accuracy": 0.836957,
        "main_score": 0.801335,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.848238,
        "recall": 0.891304,
        "f1": 0.861693,
        "accuracy": 0.891304,
        "main_score": 0.861693,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.978426,
        "recall": 0.985178,
        "f1": 0.980567,
        "accuracy": 0.985178,
        "main_score": 0.980567,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.975461,
        "recall": 0.983202,
        "f1": 0.977931,
        "accuracy": 0.983202,
        "main_score": 0.977931,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.971838,
        "recall": 0.981225,
        "f1": 0.974967,
        "accuracy": 0.981225,
        "main_score": 0.974967,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.979908,
        "recall": 0.986166,
        "f1": 0.981884,
        "accuracy": 0.986166,
        "main_score": 0.981884,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.984025,
        "recall": 0.98913,
        "f1": 0.985672,
        "accuracy": 0.98913,
        "main_score": 0.985672,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.991107,
        "recall": 0.994071,
        "f1": 0.992095,
        "accuracy": 0.994071,
        "main_score": 0.992095,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.293561,
        "recall": 0.333004,
        "f1": 0.303111,
        "accuracy": 0.333004,
        "main_score": 0.303111,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.354095,
        "recall": 0.433794,
        "f1": 0.374463,
        "accuracy": 0.433794,
        "main_score": 0.374463,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.984025,
        "recall": 0.98913,
        "f1": 0.985672,
        "accuracy": 0.98913,
        "main_score": 0.985672,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.984025,
        "recall": 0.98913,
        "f1": 0.985672,
        "accuracy": 0.98913,
        "main_score": 0.985672,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.980072,
        "recall": 0.986166,
        "f1": 0.982049,
        "accuracy": 0.986166,
        "main_score": 0.982049,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.981225,
        "recall": 0.987154,
        "f1": 0.983202,
        "accuracy": 0.987154,
        "main_score": 0.983202,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.008678,
        "recall": 0.012846,
        "f1": 0.009376,
        "accuracy": 0.012846,
        "main_score": 0.009376,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008704,
        "recall": 0.018775,
        "f1": 0.010476,
        "accuracy": 0.018775,
        "main_score": 0.010476,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 484.44627952575684,
  "kg_co2_emissions": 0.04288531887206118
}