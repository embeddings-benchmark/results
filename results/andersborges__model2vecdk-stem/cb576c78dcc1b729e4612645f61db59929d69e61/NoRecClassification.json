{
  "dataset_revision": "5b740b7c42c73d586420812a35745fc37118862f",
  "task_name": "NoRecClassification",
  "mteb_version": "2.1.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.376465,
            "f1": 0.372907,
            "f1_weighted": 0.395519,
            "precision": 0.421017,
            "precision_weighted": 0.490278,
            "recall": 0.415102,
            "recall_weighted": 0.376465,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.391113,
            "f1": 0.34599,
            "f1_weighted": 0.399114,
            "precision": 0.348597,
            "precision_weighted": 0.409636,
            "recall": 0.346328,
            "recall_weighted": 0.391113,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.418457,
            "f1": 0.382213,
            "f1_weighted": 0.432316,
            "precision": 0.395,
            "precision_weighted": 0.462305,
            "recall": 0.393588,
            "recall_weighted": 0.418457,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.424316,
            "f1": 0.398794,
            "f1_weighted": 0.437312,
            "precision": 0.422595,
            "precision_weighted": 0.495256,
            "recall": 0.41465,
            "recall_weighted": 0.424316,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.362305,
            "f1": 0.342867,
            "f1_weighted": 0.370241,
            "precision": 0.395389,
            "precision_weighted": 0.472569,
            "recall": 0.368398,
            "recall_weighted": 0.362305,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.442871,
            "f1": 0.398234,
            "f1_weighted": 0.446087,
            "precision": 0.397744,
            "precision_weighted": 0.450665,
            "recall": 0.399976,
            "recall_weighted": 0.442871,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.419922,
            "f1": 0.401625,
            "f1_weighted": 0.444009,
            "precision": 0.432689,
            "precision_weighted": 0.511804,
            "recall": 0.417725,
            "recall_weighted": 0.419922,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.384277,
            "f1": 0.363257,
            "f1_weighted": 0.395093,
            "precision": 0.368192,
            "precision_weighted": 0.419749,
            "recall": 0.377876,
            "recall_weighted": 0.384277,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.367188,
            "f1": 0.350335,
            "f1_weighted": 0.378398,
            "precision": 0.360279,
            "precision_weighted": 0.412774,
            "recall": 0.363938,
            "recall_weighted": 0.367188,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.39209,
            "f1": 0.362685,
            "f1_weighted": 0.403398,
            "precision": 0.376206,
            "precision_weighted": 0.439637,
            "recall": 0.370395,
            "recall_weighted": 0.39209,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.3979,
        "f1": 0.371891,
        "f1_weighted": 0.410149,
        "precision": 0.391771,
        "precision_weighted": 0.456467,
        "recall": 0.386798,
        "recall_weighted": 0.3979,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.3979,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5.571957111358643,
  "kg_co2_emissions": null
}