{
  "dataset_revision": "de7ba3406ee55ea2cc52a0a41408fa6aede6d3c6",
  "task_name": "LccSentimentClassification",
  "mteb_version": "2.1.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.44,
            "f1": 0.435709,
            "f1_weighted": 0.446367,
            "precision": 0.451405,
            "precision_weighted": 0.52207,
            "recall": 0.478541,
            "recall_weighted": 0.44,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.393333,
            "f1": 0.382727,
            "f1_weighted": 0.409845,
            "precision": 0.41549,
            "precision_weighted": 0.506157,
            "recall": 0.413169,
            "recall_weighted": 0.393333,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.473333,
            "f1": 0.447376,
            "f1_weighted": 0.48093,
            "precision": 0.443489,
            "precision_weighted": 0.497657,
            "recall": 0.461362,
            "recall_weighted": 0.473333,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.38,
            "f1": 0.372533,
            "f1_weighted": 0.383931,
            "precision": 0.384381,
            "precision_weighted": 0.445975,
            "recall": 0.410841,
            "recall_weighted": 0.38,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.42,
            "f1": 0.407029,
            "f1_weighted": 0.438531,
            "precision": 0.441894,
            "precision_weighted": 0.542118,
            "recall": 0.441653,
            "recall_weighted": 0.42,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.473333,
            "f1": 0.46291,
            "f1_weighted": 0.490966,
            "precision": 0.491273,
            "precision_weighted": 0.560738,
            "recall": 0.496274,
            "recall_weighted": 0.473333,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.44,
            "f1": 0.406838,
            "f1_weighted": 0.460606,
            "precision": 0.419279,
            "precision_weighted": 0.511003,
            "recall": 0.423158,
            "recall_weighted": 0.44,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.433333,
            "f1": 0.422728,
            "f1_weighted": 0.443133,
            "precision": 0.432067,
            "precision_weighted": 0.502426,
            "recall": 0.457574,
            "recall_weighted": 0.433333,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.466667,
            "f1": 0.422266,
            "f1_weighted": 0.479275,
            "precision": 0.440885,
            "precision_weighted": 0.505492,
            "recall": 0.423445,
            "recall_weighted": 0.466667,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.473333,
            "f1": 0.432889,
            "f1_weighted": 0.482072,
            "precision": 0.431878,
            "precision_weighted": 0.495754,
            "recall": 0.438869,
            "recall_weighted": 0.473333,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.439333,
        "f1": 0.4193,
        "f1_weighted": 0.451566,
        "precision": 0.435204,
        "precision_weighted": 0.508939,
        "recall": 0.444489,
        "recall_weighted": 0.439333,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.439333,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 0.7599191665649414,
  "kg_co2_emissions": null
}