{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 310.4263563156128,
  "kg_co2_emissions": 0.01412741070411873,
  "mteb_version": "1.16.5",
  "scores": {
    "test": [
      {
        "accuracy": 0.6620553359683794,
        "f1": 0.6030765951220496,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.6030765951220496,
        "precision": 0.5840301661447906,
        "recall": 0.6620553359683794
      },
      {
        "accuracy": 0.6768774703557312,
        "f1": 0.6077639751552795,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.6077639751552795,
        "precision": 0.5816640786749482,
        "recall": 0.6768774703557312
      },
      {
        "accuracy": 0.4950592885375494,
        "f1": 0.42289587894914715,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.42289587894914715,
        "precision": 0.40161741794341005,
        "recall": 0.4950592885375494
      },
      {
        "accuracy": 0.5138339920948617,
        "f1": 0.4347322966888184,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.4347322966888184,
        "precision": 0.4095037620482284,
        "recall": 0.5138339920948617
      },
      {
        "accuracy": 0.8428853754940712,
        "f1": 0.8071816770186336,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8071816770186336,
        "precision": 0.7923355629877369,
        "recall": 0.8428853754940712
      },
      {
        "accuracy": 0.8102766798418972,
        "f1": 0.7612507058159232,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.7612507058159232,
        "precision": 0.7408761528326746,
        "recall": 0.8102766798418972
      },
      {
        "accuracy": 0.6037549407114624,
        "f1": 0.539440827298944,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.539440827298944,
        "precision": 0.5182950339076821,
        "recall": 0.6037549407114624
      },
      {
        "accuracy": 0.6057312252964426,
        "f1": 0.5307142278398963,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.5307142278398963,
        "precision": 0.5040998102139407,
        "recall": 0.6057312252964426
      },
      {
        "accuracy": 0.5079051383399209,
        "f1": 0.4487415937858453,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.4487415937858453,
        "precision": 0.4310258339863497,
        "recall": 0.5079051383399209
      },
      {
        "accuracy": 0.5237154150197628,
        "f1": 0.4426967063824771,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.4426967063824771,
        "precision": 0.4157107303105327,
        "recall": 0.5237154150197628
      },
      {
        "accuracy": 0.6788537549407114,
        "f1": 0.6226937287357408,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6226937287357408,
        "precision": 0.6027377815421293,
        "recall": 0.6788537549407114
      },
      {
        "accuracy": 0.6857707509881423,
        "f1": 0.620527238462021,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.620527238462021,
        "precision": 0.5967618733923081,
        "recall": 0.6857707509881423
      },
      {
        "accuracy": 0.674901185770751,
        "f1": 0.6125392339325145,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.6125392339325145,
        "precision": 0.5900522484761616,
        "recall": 0.674901185770751
      },
      {
        "accuracy": 0.700592885375494,
        "f1": 0.6344389909607301,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.6344389909607301,
        "precision": 0.6090685582533408,
        "recall": 0.700592885375494
      },
      {
        "accuracy": 0.650197628458498,
        "f1": 0.591907815558986,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.591907815558986,
        "precision": 0.5717271620446679,
        "recall": 0.650197628458498
      },
      {
        "accuracy": 0.6254940711462451,
        "f1": 0.5506962843919366,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.5506962843919366,
        "precision": 0.5239807357656328,
        "recall": 0.6254940711462451
      },
      {
        "accuracy": 0.7420948616600791,
        "f1": 0.6948059790451094,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.6948059790451094,
        "precision": 0.6768420287442027,
        "recall": 0.7420948616600791
      },
      {
        "accuracy": 0.7470355731225297,
        "f1": 0.6866867432084823,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.6866867432084823,
        "precision": 0.6624423583662714,
        "recall": 0.7470355731225297
      },
      {
        "accuracy": 0.16699604743083005,
        "f1": 0.13412754413675942,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.13412754413675942,
        "precision": 0.1270764155403268,
        "recall": 0.16699604743083005
      },
      {
        "accuracy": 0.20355731225296442,
        "f1": 0.13486642717118427,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.13486642717118427,
        "precision": 0.11829976331663725,
        "recall": 0.20355731225296442
      },
      {
        "accuracy": 0.4762845849802372,
        "f1": 0.4101045118840647,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.4101045118840647,
        "precision": 0.3907157583497388,
        "recall": 0.4762845849802372
      },
      {
        "accuracy": 0.4397233201581028,
        "f1": 0.35829718709117536,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.35829718709117536,
        "precision": 0.3342411586192103,
        "recall": 0.4397233201581028
      },
      {
        "accuracy": 0.7490118577075099,
        "f1": 0.6944168753951363,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6944168753951363,
        "precision": 0.6743777056277056,
        "recall": 0.7490118577075099
      },
      {
        "accuracy": 0.7322134387351779,
        "f1": 0.6693488384693919,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.6693488384693919,
        "precision": 0.644684421858335,
        "recall": 0.7322134387351779
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.014988837279194138,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.014988837279194138,
        "precision": 0.014164380139649385,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.045454545454545456,
        "f1": 0.023561864108496616,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.023561864108496616,
        "precision": 0.019874447708905316,
        "recall": 0.045454545454545456
      },
      {
        "accuracy": 0.525691699604743,
        "f1": 0.46222944377821157,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.46222944377821157,
        "precision": 0.4426121871678338,
        "recall": 0.525691699604743
      },
      {
        "accuracy": 0.5830039525691699,
        "f1": 0.5063320243656212,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.5063320243656212,
        "precision": 0.47859812837579635,
        "recall": 0.5830039525691699
      },
      {
        "accuracy": 0.17984189723320157,
        "f1": 0.14347952985140072,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.14347952985140072,
        "precision": 0.134777225721258,
        "recall": 0.17984189723320157
      },
      {
        "accuracy": 0.21640316205533597,
        "f1": 0.1480846725988244,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.1480846725988244,
        "precision": 0.13163666827516113,
        "recall": 0.21640316205533597
      },
      {
        "accuracy": 0.3142292490118577,
        "f1": 0.2625565657561699,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2625565657561699,
        "precision": 0.24868364270360532,
        "recall": 0.3142292490118577
      },
      {
        "accuracy": 0.2974308300395257,
        "f1": 0.22043648667027188,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.22043648667027188,
        "precision": 0.20054806450592866,
        "recall": 0.2974308300395257
      },
      {
        "accuracy": 0.6808300395256917,
        "f1": 0.6199668414589362,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6199668414589362,
        "precision": 0.5986769872639438,
        "recall": 0.6808300395256917
      },
      {
        "accuracy": 0.6205533596837944,
        "f1": 0.5450607363650843,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.5450607363650843,
        "precision": 0.5179806606437041,
        "recall": 0.6205533596837944
      },
      {
        "accuracy": 0.6650197628458498,
        "f1": 0.6004211368341803,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6004211368341803,
        "precision": 0.5772816966739892,
        "recall": 0.6650197628458498
      },
      {
        "accuracy": 0.567193675889328,
        "f1": 0.4855658230658231,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.4855658230658231,
        "precision": 0.45801400322281327,
        "recall": 0.567193675889328
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004020617064095324,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.004020617064095324,
        "precision": 0.003706620662066207,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.009428163289959724,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.009428163289959724,
        "precision": 0.00817047113797195,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.02019481545589508,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.02019481545589508,
        "precision": 0.01887707436666969,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.06422924901185771,
        "f1": 0.036301957145288506,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.036301957145288506,
        "precision": 0.03177932967080947,
        "recall": 0.06422924901185771
      },
      {
        "accuracy": 0.5810276679841897,
        "f1": 0.5133285320070217,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5133285320070217,
        "precision": 0.49191051592237367,
        "recall": 0.5810276679841897
      },
      {
        "accuracy": 0.5237154150197628,
        "f1": 0.44501955727512205,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.44501955727512205,
        "precision": 0.41893451247082286,
        "recall": 0.5237154150197628
      },
      {
        "accuracy": 0.2924901185770751,
        "f1": 0.23920381078886904,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.23920381078886904,
        "precision": 0.22571175927500453,
        "recall": 0.2924901185770751
      },
      {
        "accuracy": 0.28063241106719367,
        "f1": 0.21017563779681525,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.21017563779681525,
        "precision": 0.1918230364689719,
        "recall": 0.28063241106719367
      },
      {
        "accuracy": 0.5830039525691699,
        "f1": 0.5191263638645062,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5191263638645062,
        "precision": 0.4988482348673216,
        "recall": 0.5830039525691699
      },
      {
        "accuracy": 0.5187747035573123,
        "f1": 0.43499493011961043,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.43499493011961043,
        "precision": 0.407133257462396,
        "recall": 0.5187747035573123
      },
      {
        "accuracy": 0.5177865612648221,
        "f1": 0.45176740977396274,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.45176740977396274,
        "precision": 0.43216142195013385,
        "recall": 0.5177865612648221
      },
      {
        "accuracy": 0.45454545454545453,
        "f1": 0.37711595124355557,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.37711595124355557,
        "precision": 0.35432040816061167,
        "recall": 0.45454545454545453
      },
      {
        "accuracy": 0.5286561264822134,
        "f1": 0.46389722293000596,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.46389722293000596,
        "precision": 0.4441308595335275,
        "recall": 0.5286561264822134
      },
      {
        "accuracy": 0.4851778656126482,
        "f1": 0.4027266366359019,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.4027266366359019,
        "precision": 0.3769285871682117,
        "recall": 0.4851778656126482
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.023091689203390803,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.023091689203390803,
        "precision": 0.021630342845038307,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.05434782608695652,
        "f1": 0.029291405103666592,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.029291405103666592,
        "precision": 0.02483848281193122,
        "recall": 0.05434782608695652
      },
      {
        "accuracy": 0.6136363636363636,
        "f1": 0.5580493397687074,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5580493397687074,
        "precision": 0.5393000472298891,
        "recall": 0.6136363636363636
      },
      {
        "accuracy": 0.5187747035573123,
        "f1": 0.43693344070266243,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.43693344070266243,
        "precision": 0.4105074780840592,
        "recall": 0.5187747035573123
      },
      {
        "accuracy": 0.6373517786561265,
        "f1": 0.5719982367215569,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5719982367215569,
        "precision": 0.5491298858146684,
        "recall": 0.6373517786561265
      },
      {
        "accuracy": 0.549407114624506,
        "f1": 0.4723118776417275,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.4723118776417275,
        "precision": 0.4467944805690767,
        "recall": 0.549407114624506
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019782413023911086,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0019782413023911086,
        "precision": 0.00197726391331769,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.005779841291855021,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.005779841291855021,
        "precision": 0.004417235085108084,
        "recall": 0.017786561264822136
      }
    ],
    "validation": [
      {
        "accuracy": 0.6349047141424273,
        "f1": 0.5756104234952546,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.5756104234952546,
        "precision": 0.5567728368254947,
        "recall": 0.6349047141424273
      },
      {
        "accuracy": 0.6599799398194583,
        "f1": 0.5897685842520346,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.5897685842520346,
        "precision": 0.5631573291302479,
        "recall": 0.6599799398194583
      },
      {
        "accuracy": 0.4653961885656971,
        "f1": 0.4060861103087628,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.4060861103087628,
        "precision": 0.3889580017356299,
        "recall": 0.4653961885656971
      },
      {
        "accuracy": 0.5055165496489469,
        "f1": 0.4295651601268452,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.4295651601268452,
        "precision": 0.4049421463413439,
        "recall": 0.5055165496489469
      },
      {
        "accuracy": 0.8525576730190572,
        "f1": 0.8144433299899699,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8144433299899699,
        "precision": 0.7986650427472894,
        "recall": 0.8525576730190572
      },
      {
        "accuracy": 0.8074222668004012,
        "f1": 0.7586784162009839,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.7586784162009839,
        "precision": 0.7380904618617757,
        "recall": 0.8074222668004012
      },
      {
        "accuracy": 0.5697091273821464,
        "f1": 0.5151454499885697,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.5151454499885697,
        "precision": 0.49844094736290673,
        "recall": 0.5697091273821464
      },
      {
        "accuracy": 0.5807422266800402,
        "f1": 0.5013088327030152,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.5013088327030152,
        "precision": 0.473383617942294,
        "recall": 0.5807422266800402
      },
      {
        "accuracy": 0.4934804413239719,
        "f1": 0.43920926542694283,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.43920926542694283,
        "precision": 0.4221839185533978,
        "recall": 0.4934804413239719
      },
      {
        "accuracy": 0.5255767301905717,
        "f1": 0.45063214952883957,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.45063214952883957,
        "precision": 0.4262472184399732,
        "recall": 0.5255767301905717
      },
      {
        "accuracy": 0.6489468405215647,
        "f1": 0.5880537057228897,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5880537057228897,
        "precision": 0.5667439589831765,
        "recall": 0.6489468405215647
      },
      {
        "accuracy": 0.6760280842527583,
        "f1": 0.6063516668331111,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.6063516668331111,
        "precision": 0.5796584197035551,
        "recall": 0.6760280842527583
      },
      {
        "accuracy": 0.6479438314944834,
        "f1": 0.5893602818603539,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.5893602818603539,
        "precision": 0.5687333520708645,
        "recall": 0.6479438314944834
      },
      {
        "accuracy": 0.6389167502507522,
        "f1": 0.5715941475219308,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.5715941475219308,
        "precision": 0.5458631184558969,
        "recall": 0.6389167502507522
      },
      {
        "accuracy": 0.6028084252758275,
        "f1": 0.544737414858956,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.544737414858956,
        "precision": 0.5255051797499262,
        "recall": 0.6028084252758275
      },
      {
        "accuracy": 0.6108324974924775,
        "f1": 0.5342846721984134,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.5342846721984134,
        "precision": 0.5064168446064133,
        "recall": 0.6108324974924775
      },
      {
        "accuracy": 0.7362086258776329,
        "f1": 0.6845307631578208,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.6845307631578208,
        "precision": 0.6652391698906243,
        "recall": 0.7362086258776329
      },
      {
        "accuracy": 0.7512537612838516,
        "f1": 0.6936027380386774,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.6936027380386774,
        "precision": 0.6700362993743134,
        "recall": 0.7512537612838516
      },
      {
        "accuracy": 0.1624874623871615,
        "f1": 0.12203473347399636,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.12203473347399636,
        "precision": 0.11427954232709242,
        "recall": 0.1624874623871615
      },
      {
        "accuracy": 0.19558676028084251,
        "f1": 0.12918869673919237,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.12918869673919237,
        "precision": 0.11369957075321323,
        "recall": 0.19558676028084251
      },
      {
        "accuracy": 0.4764292878635908,
        "f1": 0.41133999358411555,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.41133999358411555,
        "precision": 0.391334234296609,
        "recall": 0.4764292878635908
      },
      {
        "accuracy": 0.43029087261785354,
        "f1": 0.35220539360221564,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.35220539360221564,
        "precision": 0.3281027518001598,
        "recall": 0.43029087261785354
      },
      {
        "accuracy": 0.7121364092276831,
        "f1": 0.66224492102125,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.66224492102125,
        "precision": 0.6445765072996767,
        "recall": 0.7121364092276831
      },
      {
        "accuracy": 0.7221664994984955,
        "f1": 0.6594079858623489,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.6594079858623489,
        "precision": 0.6344724650140899,
        "recall": 0.7221664994984955
      },
      {
        "accuracy": 0.020060180541624874,
        "f1": 0.01571585796548355,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.01571585796548355,
        "precision": 0.015229268547634366,
        "recall": 0.020060180541624874
      },
      {
        "accuracy": 0.048144433299899696,
        "f1": 0.02544340885157052,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.02544340885157052,
        "precision": 0.02158654940187682,
        "recall": 0.048144433299899696
      },
      {
        "accuracy": 0.49147442326980945,
        "f1": 0.4344625335424047,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.4344625335424047,
        "precision": 0.4172875533376989,
        "recall": 0.49147442326980945
      },
      {
        "accuracy": 0.5877632898696088,
        "f1": 0.5072184808393435,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.5072184808393435,
        "precision": 0.4781236316341632,
        "recall": 0.5877632898696088
      },
      {
        "accuracy": 0.18856569709127383,
        "f1": 0.14622741886832932,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.14622741886832932,
        "precision": 0.1367337533417113,
        "recall": 0.18856569709127383
      },
      {
        "accuracy": 0.24072216649949849,
        "f1": 0.1627268491888668,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.1627268491888668,
        "precision": 0.14173367397598916,
        "recall": 0.24072216649949849
      },
      {
        "accuracy": 0.31093279839518556,
        "f1": 0.2670008281340048,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2670008281340048,
        "precision": 0.25590451424067673,
        "recall": 0.31093279839518556
      },
      {
        "accuracy": 0.30992978936810434,
        "f1": 0.2321074100214152,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.2321074100214152,
        "precision": 0.2117977918285513,
        "recall": 0.30992978936810434
      },
      {
        "accuracy": 0.6700100300902708,
        "f1": 0.6050866886373406,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6050866886373406,
        "precision": 0.5820222934315212,
        "recall": 0.6700100300902708
      },
      {
        "accuracy": 0.6248746238716149,
        "f1": 0.5536283453535209,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.5536283453535209,
        "precision": 0.5284723940942597,
        "recall": 0.6248746238716149
      },
      {
        "accuracy": 0.6118355065195586,
        "f1": 0.5470620374833012,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5470620374833012,
        "precision": 0.5259923710525516,
        "recall": 0.6118355065195586
      },
      {
        "accuracy": 0.5426278836509528,
        "f1": 0.46096292540625544,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.46096292540625544,
        "precision": 0.43302010779443073,
        "recall": 0.5426278836509528
      },
      {
        "accuracy": 0.004012036108324975,
        "f1": 0.0024101205350154507,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.0024101205350154507,
        "precision": 0.0022582218435334947,
        "recall": 0.004012036108324975
      },
      {
        "accuracy": 0.013039117352056168,
        "f1": 0.006479702808128507,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.006479702808128507,
        "precision": 0.005406216034618269,
        "recall": 0.013039117352056168
      },
      {
        "accuracy": 0.03811434302908726,
        "f1": 0.024745254307582596,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.024745254307582596,
        "precision": 0.023710476737847066,
        "recall": 0.03811434302908726
      },
      {
        "accuracy": 0.05015045135406219,
        "f1": 0.02897958245666969,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.02897958245666969,
        "precision": 0.02521504952488252,
        "recall": 0.05015045135406219
      },
      {
        "accuracy": 0.551654964894684,
        "f1": 0.4831175641599902,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.4831175641599902,
        "precision": 0.4602974720784031,
        "recall": 0.551654964894684
      },
      {
        "accuracy": 0.5195586760280843,
        "f1": 0.440672291600075,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.440672291600075,
        "precision": 0.41557038421872056,
        "recall": 0.5195586760280843
      },
      {
        "accuracy": 0.2888665997993982,
        "f1": 0.23777632801827148,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.23777632801827148,
        "precision": 0.2232107480936056,
        "recall": 0.2888665997993982
      },
      {
        "accuracy": 0.2978936810431294,
        "f1": 0.22800527470799897,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.22800527470799897,
        "precision": 0.21000139617700142,
        "recall": 0.2978936810431294
      },
      {
        "accuracy": 0.5456369107321966,
        "f1": 0.47722610949171584,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.47722610949171584,
        "precision": 0.45430170700540634,
        "recall": 0.5456369107321966
      },
      {
        "accuracy": 0.48244734202607825,
        "f1": 0.4016311661421915,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.4016311661421915,
        "precision": 0.3757050660235214,
        "recall": 0.48244734202607825
      },
      {
        "accuracy": 0.4974924774322969,
        "f1": 0.43548882481659074,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.43548882481659074,
        "precision": 0.4156522327285286,
        "recall": 0.4974924774322969
      },
      {
        "accuracy": 0.4724172517552658,
        "f1": 0.4000080622194791,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.4000080622194791,
        "precision": 0.3780995221285131,
        "recall": 0.4724172517552658
      },
      {
        "accuracy": 0.5115346038114343,
        "f1": 0.44679336277365655,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.44679336277365655,
        "precision": 0.426575157818889,
        "recall": 0.5115346038114343
      },
      {
        "accuracy": 0.4724172517552658,
        "f1": 0.3969130326613493,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.3969130326613493,
        "precision": 0.3726695674576273,
        "recall": 0.4724172517552658
      },
      {
        "accuracy": 0.031093279839518557,
        "f1": 0.016842709931998576,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.016842709931998576,
        "precision": 0.01546230115721233,
        "recall": 0.031093279839518557
      },
      {
        "accuracy": 0.05917753259779338,
        "f1": 0.03283064621187122,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.03283064621187122,
        "precision": 0.028013205059024215,
        "recall": 0.05917753259779338
      },
      {
        "accuracy": 0.6158475426278837,
        "f1": 0.5484195842207957,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5484195842207957,
        "precision": 0.525903305153556,
        "recall": 0.6158475426278837
      },
      {
        "accuracy": 0.5406218655967904,
        "f1": 0.45921416152108224,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.45921416152108224,
        "precision": 0.43106159101442915,
        "recall": 0.5406218655967904
      },
      {
        "accuracy": 0.6198595787362087,
        "f1": 0.5513198325134132,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5513198325134132,
        "precision": 0.5281822017278387,
        "recall": 0.6198595787362087
      },
      {
        "accuracy": 0.5546639919759278,
        "f1": 0.48121648949395346,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.48121648949395346,
        "precision": 0.4568931743894131,
        "recall": 0.5546639919759278
      },
      {
        "accuracy": 0.0050150451354062184,
        "f1": 0.0040140872515296395,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0040140872515296395,
        "precision": 0.004013062729642356,
        "recall": 0.0050150451354062184
      },
      {
        "accuracy": 0.013039117352056168,
        "f1": 0.005483860736545293,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.005483860736545293,
        "precision": 0.004432047036497077,
        "recall": 0.013039117352056168
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}