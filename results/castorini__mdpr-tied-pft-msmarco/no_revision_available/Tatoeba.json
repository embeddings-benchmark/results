{
  "dataset_revision": "69e8f12da6e31d59addadda9a9c8a2e601a0e282",
  "evaluation_time": 228.04493832588196,
  "kg_co2_emissions": 0.008123009359604543,
  "mteb_version": "1.16.5",
  "scores": {
    "test": [
      {
        "accuracy": 0.639,
        "f1": 0.5781047519530279,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5781047519530279,
        "precision": 0.5550992063492064,
        "recall": 0.639
      },
      {
        "accuracy": 0.018,
        "f1": 0.011164686237962101,
        "hf_subset": "kab-eng",
        "languages": [
          "kab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011164686237962101,
        "precision": 0.010658463194056413,
        "recall": 0.018
      },
      {
        "accuracy": 0.663,
        "f1": 0.6168078559926387,
        "hf_subset": "fra-eng",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.6168078559926387,
        "precision": 0.6010335553335553,
        "recall": 0.663
      },
      {
        "accuracy": 0.547,
        "f1": 0.4818984126984127,
        "hf_subset": "pol-eng",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4818984126984127,
        "precision": 0.4564218253968254,
        "recall": 0.547
      },
      {
        "accuracy": 0.415,
        "f1": 0.3589852156615314,
        "hf_subset": "yue-eng",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ],
        "main_score": 0.3589852156615314,
        "precision": 0.34078480327855326,
        "recall": 0.415
      },
      {
        "accuracy": 0.23,
        "f1": 0.17759214324611167,
        "hf_subset": "est-eng",
        "languages": [
          "est-Latn",
          "eng-Latn"
        ],
        "main_score": 0.17759214324611167,
        "precision": 0.1626248209538999,
        "recall": 0.23
      },
      {
        "accuracy": 0.398,
        "f1": 0.33009768067890294,
        "hf_subset": "ido-eng",
        "languages": [
          "ido-Latn",
          "eng-Latn"
        ],
        "main_score": 0.33009768067890294,
        "precision": 0.30931429653679654,
        "recall": 0.398
      },
      {
        "accuracy": 0.22077922077922077,
        "f1": 0.16202104773533343,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.16202104773533343,
        "precision": 0.14909148261402413,
        "recall": 0.22077922077922077
      },
      {
        "accuracy": 0.4641555285540705,
        "f1": 0.39974387208776563,
        "hf_subset": "slv-eng",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.39974387208776563,
        "precision": 0.3787124962110573,
        "recall": 0.4641555285540705
      },
      {
        "accuracy": 0.323,
        "f1": 0.2745547905397906,
        "hf_subset": "isl-eng",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2745547905397906,
        "precision": 0.25956211090496806,
        "recall": 0.323
      },
      {
        "accuracy": 0.678,
        "f1": 0.621936694677871,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.621936694677871,
        "precision": 0.5998116452991453,
        "recall": 0.678
      },
      {
        "accuracy": 0.439,
        "f1": 0.3866763994175759,
        "hf_subset": "afr-eng",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3866763994175759,
        "precision": 0.36823615689865685,
        "recall": 0.439
      },
      {
        "accuracy": 0.671,
        "f1": 0.6194567401960784,
        "hf_subset": "nob-eng",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.6194567401960784,
        "precision": 0.598150937950938,
        "recall": 0.671
      },
      {
        "accuracy": 0.044,
        "f1": 0.027405124650258714,
        "hf_subset": "ber-eng",
        "languages": [
          "ber-Tfng",
          "eng-Latn"
        ],
        "main_score": 0.027405124650258714,
        "precision": 0.024344558011831392,
        "recall": 0.044
      },
      {
        "accuracy": 0.17184265010351968,
        "f1": 0.1386935266157592,
        "hf_subset": "hsb-eng",
        "languages": [
          "hsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1386935266157592,
        "precision": 0.12970963497842916,
        "recall": 0.17184265010351968
      },
      {
        "accuracy": 0.5649717514124294,
        "f1": 0.5086975844951918,
        "hf_subset": "bos-eng",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5086975844951918,
        "precision": 0.4905143036498969,
        "recall": 0.5649717514124294
      },
      {
        "accuracy": 0.558,
        "f1": 0.49042539682539676,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.49042539682539676,
        "precision": 0.4662630952380953,
        "recall": 0.558
      },
      {
        "accuracy": 0.2180293501048218,
        "f1": 0.1692486874876812,
        "hf_subset": "arz-eng",
        "languages": [
          "arz-Arab",
          "eng-Latn"
        ],
        "main_score": 0.1692486874876812,
        "precision": 0.1539324814482047,
        "recall": 0.2180293501048218
      },
      {
        "accuracy": 0.30434782608695654,
        "f1": 0.2450149068322981,
        "hf_subset": "kaz-eng",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.2450149068322981,
        "precision": 0.22758471150004325,
        "recall": 0.30434782608695654
      },
      {
        "accuracy": 0.655,
        "f1": 0.5942011904761905,
        "hf_subset": "ita-eng",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5942011904761905,
        "precision": 0.5711075396825397,
        "recall": 0.655
      },
      {
        "accuracy": 0.387,
        "f1": 0.31951336996336993,
        "hf_subset": "mkd-eng",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.31951336996336993,
        "precision": 0.296465122785711,
        "recall": 0.387
      },
      {
        "accuracy": 0.20422535211267606,
        "f1": 0.16635169439576528,
        "hf_subset": "max-eng",
        "languages": [
          "max-Deva",
          "eng-Latn"
        ],
        "main_score": 0.16635169439576528,
        "precision": 0.15899983158943098,
        "recall": 0.20422535211267606
      },
      {
        "accuracy": 0.25892857142857145,
        "f1": 0.18357780612244895,
        "hf_subset": "swg-eng",
        "languages": [
          "swg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.18357780612244895,
        "precision": 0.1603528911564626,
        "recall": 0.25892857142857145
      },
      {
        "accuracy": 0.426,
        "f1": 0.3636300467076783,
        "hf_subset": "nds-eng",
        "languages": [
          "nds-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3636300467076783,
        "precision": 0.3425374883286648,
        "recall": 0.426
      },
      {
        "accuracy": 0.366,
        "f1": 0.2983942402425161,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.2983942402425161,
        "precision": 0.27549963924963927,
        "recall": 0.366
      },
      {
        "accuracy": 0.639,
        "f1": 0.5897906593406594,
        "hf_subset": "nld-eng",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5897906593406594,
        "precision": 0.5703430420711973,
        "recall": 0.639
      },
      {
        "accuracy": 0.413,
        "f1": 0.35317261904761904,
        "hf_subset": "hun-eng",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.35317261904761904,
        "precision": 0.3323758297258297,
        "recall": 0.413
      },
      {
        "accuracy": 0.378,
        "f1": 0.3213596388596388,
        "hf_subset": "fin-eng",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3213596388596388,
        "precision": 0.3031108598022981,
        "recall": 0.378
      },
      {
        "accuracy": 0.4163424124513619,
        "f1": 0.3512824727397339,
        "hf_subset": "nov-eng",
        "languages": [
          "nov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3512824727397339,
        "precision": 0.32987592822223166,
        "recall": 0.4163424124513619
      },
      {
        "accuracy": 0.594,
        "f1": 0.5264987978524743,
        "hf_subset": "glg-eng",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5264987978524743,
        "precision": 0.5020265401712982,
        "recall": 0.594
      },
      {
        "accuracy": 0.513,
        "f1": 0.4397626984126984,
        "hf_subset": "wuu-eng",
        "languages": [
          "wuu-Hans",
          "eng-Latn"
        ],
        "main_score": 0.4397626984126984,
        "precision": 0.4131075396825397,
        "recall": 0.513
      },
      {
        "accuracy": 0.223,
        "f1": 0.18448277905218008,
        "hf_subset": "eus-eng",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.18448277905218008,
        "precision": 0.1733594315553437,
        "recall": 0.223
      },
      {
        "accuracy": 0.14613778705636743,
        "f1": 0.1115224513271243,
        "hf_subset": "dsb-eng",
        "languages": [
          "dsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1115224513271243,
        "precision": 0.10071277737212515,
        "recall": 0.14613778705636743
      },
      {
        "accuracy": 0.61,
        "f1": 0.5429141636141636,
        "hf_subset": "vie-eng",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5429141636141636,
        "precision": 0.5178536435786436,
        "recall": 0.61
      },
      {
        "accuracy": 0.467,
        "f1": 0.3999183261183261,
        "hf_subset": "pes-eng",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 0.3999183261183261,
        "precision": 0.376785989010989,
        "recall": 0.467
      },
      {
        "accuracy": 0.486,
        "f1": 0.4215295518207283,
        "hf_subset": "ron-eng",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4215295518207283,
        "precision": 0.3993874389499389,
        "recall": 0.486
      },
      {
        "accuracy": 0.27350427350427353,
        "f1": 0.201024901024901,
        "hf_subset": "gsw-eng",
        "languages": [
          "gsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.201024901024901,
        "precision": 0.17851252061778378,
        "recall": 0.27350427350427353
      },
      {
        "accuracy": 0.714,
        "f1": 0.6647909885436202,
        "hf_subset": "spa-eng",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.6647909885436202,
        "precision": 0.6446565204678363,
        "recall": 0.714
      },
      {
        "accuracy": 0.758,
        "f1": 0.7025705128205129,
        "hf_subset": "cmn-eng",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.7025705128205129,
        "precision": 0.6801115440115441,
        "recall": 0.758
      },
      {
        "accuracy": 0.509,
        "f1": 0.4369195526695527,
        "hf_subset": "bel-eng",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.4369195526695527,
        "precision": 0.410597557997558,
        "recall": 0.509
      },
      {
        "accuracy": 0.449,
        "f1": 0.38733270308123247,
        "hf_subset": "kor-eng",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ],
        "main_score": 0.38733270308123247,
        "precision": 0.3668679190978104,
        "recall": 0.449
      },
      {
        "accuracy": 0.379,
        "f1": 0.31603788864052024,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ],
        "main_score": 0.31603788864052024,
        "precision": 0.2954881145600186,
        "recall": 0.379
      },
      {
        "accuracy": 0.381,
        "f1": 0.32642521672227554,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ],
        "main_score": 0.32642521672227554,
        "precision": 0.3091636704167221,
        "recall": 0.381
      },
      {
        "accuracy": 0.43,
        "f1": 0.35852681207681203,
        "hf_subset": "heb-eng",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.35852681207681203,
        "precision": 0.3344123949579832,
        "recall": 0.43
      },
      {
        "accuracy": 0.46,
        "f1": 0.38955362554112555,
        "hf_subset": "ile-eng",
        "languages": [
          "ile-Latn",
          "eng-Latn"
        ],
        "main_score": 0.38955362554112555,
        "precision": 0.3662314144636725,
        "recall": 0.46
      },
      {
        "accuracy": 0.099,
        "f1": 0.06733124637484045,
        "hf_subset": "gle-eng",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06733124637484045,
        "precision": 0.06169405587769718,
        "recall": 0.099
      },
      {
        "accuracy": 0.27099236641221375,
        "f1": 0.20785714285714288,
        "hf_subset": "fao-eng",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.20785714285714288,
        "precision": 0.1899581016947429,
        "recall": 0.27099236641221375
      },
      {
        "accuracy": 0.374,
        "f1": 0.31992372738964253,
        "hf_subset": "sqi-eng",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.31992372738964253,
        "precision": 0.3036039497293959,
        "recall": 0.374
      },
      {
        "accuracy": 0.27611940298507465,
        "f1": 0.1988547238743625,
        "hf_subset": "ang-eng",
        "languages": [
          "ang-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1988547238743625,
        "precision": 0.1753524046434494,
        "recall": 0.27611940298507465
      },
      {
        "accuracy": 0.1826086956521739,
        "f1": 0.1438990021986731,
        "hf_subset": "cym-eng",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1438990021986731,
        "precision": 0.133855435480277,
        "recall": 0.1826086956521739
      },
      {
        "accuracy": 0.2975871313672922,
        "f1": 0.2333876876772319,
        "hf_subset": "kat-eng",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ],
        "main_score": 0.2333876876772319,
        "precision": 0.2129068503733383,
        "recall": 0.2975871313672922
      },
      {
        "accuracy": 0.425,
        "f1": 0.36621649350649355,
        "hf_subset": "slk-eng",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.36621649350649355,
        "precision": 0.3449988455988456,
        "recall": 0.425
      },
      {
        "accuracy": 0.5984251968503937,
        "f1": 0.5436185861382711,
        "hf_subset": "ast-eng",
        "languages": [
          "ast-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5436185861382711,
        "precision": 0.5258092738407698,
        "recall": 0.5984251968503937
      },
      {
        "accuracy": 0.28338762214983715,
        "f1": 0.21760273747244432,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.21760273747244432,
        "precision": 0.19789836475504227,
        "recall": 0.28338762214983715
      },
      {
        "accuracy": 0.036,
        "f1": 0.01952135159919698,
        "hf_subset": "cor-eng",
        "languages": [
          "cor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01952135159919698,
        "precision": 0.016642984180851826,
        "recall": 0.036
      },
      {
        "accuracy": 0.11025641025641025,
        "f1": 0.07882817941239237,
        "hf_subset": "swh-eng",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07882817941239237,
        "precision": 0.07283507145440979,
        "recall": 0.11025641025641025
      },
      {
        "accuracy": 0.38461538461538464,
        "f1": 0.31168769502102833,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.31168769502102833,
        "precision": 0.28703703703703703,
        "recall": 0.38461538461538464
      },
      {
        "accuracy": 0.317,
        "f1": 0.26626479400372594,
        "hf_subset": "oci-eng",
        "languages": [
          "oci-Latn",
          "eng-Latn"
        ],
        "main_score": 0.26626479400372594,
        "precision": 0.24866178124671504,
        "recall": 0.317
      },
      {
        "accuracy": 0.004155124653739612,
        "f1": 0.0027740011832603916,
        "hf_subset": "khm-eng",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ],
        "main_score": 0.0027740011832603916,
        "precision": 0.0027720449177214695,
        "recall": 0.004155124653739612
      },
      {
        "accuracy": 0.464,
        "f1": 0.39574340659340657,
        "hf_subset": "srp-eng",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.39574340659340657,
        "precision": 0.3720496342737722,
        "recall": 0.464
      },
      {
        "accuracy": 0.623,
        "f1": 0.5634335497835498,
        "hf_subset": "ina-eng",
        "languages": [
          "ina-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5634335497835498,
        "precision": 0.5429108076563959,
        "recall": 0.623
      },
      {
        "accuracy": 0.005952380952380952,
        "f1": 7.044237813468582e-05,
        "hf_subset": "amh-eng",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ],
        "main_score": 7.044237813468582e-05,
        "precision": 3.5430839002267575e-05,
        "recall": 0.005952380952380952
      },
      {
        "accuracy": 0.489,
        "f1": 0.4403655051416661,
        "hf_subset": "zsm-eng",
        "languages": [
          "zsm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4403655051416661,
        "precision": 0.42433374658894457,
        "recall": 0.489
      },
      {
        "accuracy": 0.343,
        "f1": 0.2861487666827936,
        "hf_subset": "lfn-eng",
        "languages": [
          "lfn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2861487666827936,
        "precision": 0.2701998950696212,
        "recall": 0.343
      },
      {
        "accuracy": 0.184,
        "f1": 0.1442012272318876,
        "hf_subset": "epo-eng",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1442012272318876,
        "precision": 0.13446315606663722,
        "recall": 0.184
      },
      {
        "accuracy": 0.116,
        "f1": 0.08079278023019441,
        "hf_subset": "bre-eng",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08079278023019441,
        "precision": 0.07211205129579742,
        "recall": 0.116
      },
      {
        "accuracy": 0.3173216885007278,
        "f1": 0.25998709361154776,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.25998709361154776,
        "precision": 0.24170773024484815,
        "recall": 0.3173216885007278
      },
      {
        "accuracy": 0.1225296442687747,
        "f1": 0.08373559396889195,
        "hf_subset": "csb-eng",
        "languages": [
          "csb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08373559396889195,
        "precision": 0.07710316034426706,
        "recall": 0.1225296442687747
      },
      {
        "accuracy": 0.145985401459854,
        "f1": 0.09748717005050195,
        "hf_subset": "cha-eng",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09748717005050195,
        "precision": 0.08527642606109759,
        "recall": 0.145985401459854
      },
      {
        "accuracy": 0.242,
        "f1": 0.2072621966318435,
        "hf_subset": "lvs-eng",
        "languages": [
          "lvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2072621966318435,
        "precision": 0.19617954057954057,
        "recall": 0.242
      },
      {
        "accuracy": 0.19230769230769232,
        "f1": 0.14407051282051284,
        "hf_subset": "tzl-eng",
        "languages": [
          "tzl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.14407051282051284,
        "precision": 0.13430631868131868,
        "recall": 0.19230769230769232
      },
      {
        "accuracy": 0.346,
        "f1": 0.27640331890331893,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ],
        "main_score": 0.27640331890331893,
        "precision": 0.25204880952380954,
        "recall": 0.346
      },
      {
        "accuracy": 0.407,
        "f1": 0.33086209346209344,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.33086209346209344,
        "precision": 0.3041087214284475,
        "recall": 0.407
      },
      {
        "accuracy": 0.563,
        "f1": 0.5045334015657545,
        "hf_subset": "hrv-eng",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5045334015657545,
        "precision": 0.48310730424546217,
        "recall": 0.563
      },
      {
        "accuracy": 0.226,
        "f1": 0.165076998001998,
        "hf_subset": "lat-eng",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.165076998001998,
        "precision": 0.14677681649294552,
        "recall": 0.226
      },
      {
        "accuracy": 0.723,
        "f1": 0.6600269841269841,
        "hf_subset": "por-eng",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.6600269841269841,
        "precision": 0.6341083333333334,
        "recall": 0.723
      },
      {
        "accuracy": 0.247,
        "f1": 0.19093440081950516,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.19093440081950516,
        "precision": 0.17473950216450218,
        "recall": 0.247
      },
      {
        "accuracy": 0.473,
        "f1": 0.40229824064824066,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.40229824064824066,
        "precision": 0.37708482025221157,
        "recall": 0.473
      },
      {
        "accuracy": 0.045,
        "f1": 0.021539952401622882,
        "hf_subset": "pam-eng",
        "languages": [
          "pam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021539952401622882,
        "precision": 0.01852853715606529,
        "recall": 0.045
      },
      {
        "accuracy": 0.203,
        "f1": 0.16171171936934536,
        "hf_subset": "tat-eng",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.16171171936934536,
        "precision": 0.15050934243176178,
        "recall": 0.203
      },
      {
        "accuracy": 0.06,
        "f1": 0.03664327105642896,
        "hf_subset": "mhr-eng",
        "languages": [
          "mhr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.03664327105642896,
        "precision": 0.032223298827149256,
        "recall": 0.06
      },
      {
        "accuracy": 0.12,
        "f1": 0.09789481161080216,
        "hf_subset": "tgl-eng",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09789481161080216,
        "precision": 0.09283714603184337,
        "recall": 0.12
      },
      {
        "accuracy": 0.507,
        "f1": 0.4361728821015586,
        "hf_subset": "ind-eng",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4361728821015586,
        "precision": 0.410742773937532,
        "recall": 0.507
      },
      {
        "accuracy": 0.34476190476190477,
        "f1": 0.28973572459286745,
        "hf_subset": "pms-eng",
        "languages": [
          "pms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.28973572459286745,
        "precision": 0.2731837421837422,
        "recall": 0.34476190476190477
      },
      {
        "accuracy": 0.20437956204379562,
        "f1": 0.1557718453271661,
        "hf_subset": "tha-eng",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 0.1557718453271661,
        "precision": 0.14196743091923425,
        "recall": 0.20437956204379562
      },
      {
        "accuracy": 0.043,
        "f1": 0.02588350632255143,
        "hf_subset": "dtp-eng",
        "languages": [
          "dtp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02588350632255143,
        "precision": 0.023307626791922293,
        "recall": 0.043
      },
      {
        "accuracy": 0.1,
        "f1": 0.07218216742606985,
        "hf_subset": "kur-eng",
        "languages": [
          "kur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07218216742606985,
        "precision": 0.06548173371344103,
        "recall": 0.1
      },
      {
        "accuracy": 0.38140161725067384,
        "f1": 0.31801954035781527,
        "hf_subset": "hye-eng",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ],
        "main_score": 0.31801954035781527,
        "precision": 0.29786610500478966,
        "recall": 0.38140161725067384
      },
      {
        "accuracy": 0.09813084112149532,
        "f1": 0.061490179430758345,
        "hf_subset": "uzb-eng",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.061490179430758345,
        "precision": 0.05580238492037557,
        "recall": 0.09813084112149532
      },
      {
        "accuracy": 0.06338028169014084,
        "f1": 0.036442258013792486,
        "hf_subset": "xho-eng",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.036442258013792486,
        "precision": 0.03181757209926224,
        "recall": 0.06338028169014084
      },
      {
        "accuracy": 0.06666666666666667,
        "f1": 0.044688335200099905,
        "hf_subset": "ceb-eng",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.044688335200099905,
        "precision": 0.04147615551216927,
        "recall": 0.06666666666666667
      },
      {
        "accuracy": 0.4277456647398844,
        "f1": 0.34656661578626896,
        "hf_subset": "fry-eng",
        "languages": [
          "fry-Latn",
          "eng-Latn"
        ],
        "main_score": 0.34656661578626896,
        "precision": 0.32052023121387285,
        "recall": 0.4277456647398844
      },
      {
        "accuracy": 0.578,
        "f1": 0.517543827371459,
        "hf_subset": "jpn-eng",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.517543827371459,
        "precision": 0.49479289321789327,
        "recall": 0.578
      },
      {
        "accuracy": 0.571,
        "f1": 0.5052362637362637,
        "hf_subset": "ukr-eng",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.5052362637362637,
        "precision": 0.4801888888888889,
        "recall": 0.571
      },
      {
        "accuracy": 0.07,
        "f1": 0.04658339822139197,
        "hf_subset": "war-eng",
        "languages": [
          "war-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04658339822139197,
        "precision": 0.04307851442466776,
        "recall": 0.07
      },
      {
        "accuracy": 0.349,
        "f1": 0.28874213564213563,
        "hf_subset": "tur-eng",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.28874213564213563,
        "precision": 0.2686686507936508,
        "recall": 0.349
      },
      {
        "accuracy": 0.57,
        "f1": 0.5176127705627704,
        "hf_subset": "swe-eng",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5176127705627704,
        "precision": 0.49896183261183263,
        "recall": 0.57
      },
      {
        "accuracy": 0.328,
        "f1": 0.26979342303723103,
        "hf_subset": "cbk-eng",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.26979342303723103,
        "precision": 0.25151236489545314,
        "recall": 0.328
      },
      {
        "accuracy": 0.019,
        "f1": 0.011504726304058466,
        "hf_subset": "uig-eng",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ],
        "main_score": 0.011504726304058466,
        "precision": 0.01071311612364244,
        "recall": 0.019
      },
      {
        "accuracy": 0.732,
        "f1": 0.6925485008818343,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.6925485008818343,
        "precision": 0.6774041666666667,
        "recall": 0.732
      },
      {
        "accuracy": 0.02240566037735849,
        "f1": 0.010096652825023622,
        "hf_subset": "yid-eng",
        "languages": [
          "yid-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.010096652825023622,
        "precision": 0.008363152550166977,
        "recall": 0.02240566037735849
      },
      {
        "accuracy": 0.042,
        "f1": 0.024348667625591076,
        "hf_subset": "kzj-eng",
        "languages": [
          "kzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024348667625591076,
        "precision": 0.02191394860611703,
        "recall": 0.042
      },
      {
        "accuracy": 0.1951219512195122,
        "f1": 0.1519428809672712,
        "hf_subset": "jav-eng",
        "languages": [
          "jav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1519428809672712,
        "precision": 0.14234857283637772,
        "recall": 0.1951219512195122
      },
      {
        "accuracy": 0.312,
        "f1": 0.24730117562176382,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.24730117562176382,
        "precision": 0.22726605339105338,
        "recall": 0.312
      },
      {
        "accuracy": 0.567,
        "f1": 0.5107025974025974,
        "hf_subset": "nno-eng",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5107025974025974,
        "precision": 0.49130753470667266,
        "recall": 0.567
      },
      {
        "accuracy": 0.059113300492610835,
        "f1": 0.03100986335674961,
        "hf_subset": "tuk-eng",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03100986335674961,
        "precision": 0.0256925340669183,
        "recall": 0.059113300492610835
      },
      {
        "accuracy": 0.2409090909090909,
        "f1": 0.19684705371383002,
        "hf_subset": "mon-eng",
        "languages": [
          "mon-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.19684705371383002,
        "precision": 0.1853908128908129,
        "recall": 0.2409090909090909
      },
      {
        "accuracy": 0.0718562874251497,
        "f1": 0.051096129419482716,
        "hf_subset": "orv-eng",
        "languages": [
          "orv-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.051096129419482716,
        "precision": 0.04585608716591602,
        "recall": 0.0718562874251497
      },
      {
        "accuracy": 0.07793633369923161,
        "f1": 0.04520294089425001,
        "hf_subset": "arq-eng",
        "languages": [
          "arq-Arab",
          "eng-Latn"
        ],
        "main_score": 0.04520294089425001,
        "precision": 0.03850709621166712,
        "recall": 0.07793633369923161
      },
      {
        "accuracy": 0.292,
        "f1": 0.24288441293183938,
        "hf_subset": "lit-eng",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.24288441293183938,
        "precision": 0.2275666602069012,
        "recall": 0.292
      },
      {
        "accuracy": 0.64,
        "f1": 0.5668626984126983,
        "hf_subset": "rus-eng",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.5668626984126983,
        "precision": 0.5387845238095238,
        "recall": 0.64
      },
      {
        "accuracy": 0.039806996381182146,
        "f1": 0.025892084810069823,
        "hf_subset": "gla-eng",
        "languages": [
          "gla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025892084810069823,
        "precision": 0.023995744267576828,
        "recall": 0.039806996381182146
      }
    ]
  },
  "task_name": "Tatoeba"
}