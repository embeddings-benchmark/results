{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 17.757463693618774,
  "kg_co2_emissions": 0.0007334749209049547,
  "mteb_version": "1.16.5",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.79678398174488,
        "cosine_spearman": 0.7841434297132657,
        "euclidean_pearson": 0.7523779997456834,
        "euclidean_spearman": 0.7592677689253896,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7841434297132657,
        "manhattan_pearson": 0.7532675642159437,
        "manhattan_spearman": 0.7611329965085805,
        "pearson": 0.79678398174488,
        "spearman": 0.7841434297132657
      },
      {
        "cosine_pearson": -0.040538531069630956,
        "cosine_spearman": -0.019327239204895385,
        "euclidean_pearson": 0.009893685869102407,
        "euclidean_spearman": -0.012986911925329404,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": -0.019327239204895385,
        "manhattan_pearson": 0.009105323927564744,
        "manhattan_spearman": -0.012830855791947761,
        "pearson": -0.040538531069630956,
        "spearman": -0.019327239204895385
      },
      {
        "cosine_pearson": 0.514138408073153,
        "cosine_spearman": 0.511708436232088,
        "euclidean_pearson": 0.47169642279048013,
        "euclidean_spearman": 0.46398070151504356,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.511708436232088,
        "manhattan_pearson": 0.46690257229711213,
        "manhattan_spearman": 0.4586920965290625,
        "pearson": 0.514138408073153,
        "spearman": 0.511708436232088
      },
      {
        "cosine_pearson": 0.4688911737266882,
        "cosine_spearman": 0.4569502626328808,
        "euclidean_pearson": 0.42273707394193494,
        "euclidean_spearman": 0.40391586558832887,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.4569502626328808,
        "manhattan_pearson": 0.4225657418147628,
        "manhattan_spearman": 0.4020774593321478,
        "pearson": 0.4688911737266882,
        "spearman": 0.4569502626328808
      },
      {
        "cosine_pearson": 0.35725493378534184,
        "cosine_spearman": 0.35044236883950164,
        "euclidean_pearson": 0.36804000413209137,
        "euclidean_spearman": 0.3455308372367447,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.35044236883950164,
        "manhattan_pearson": 0.37009252007274684,
        "manhattan_spearman": 0.34671193736020783,
        "pearson": 0.35725493378534184,
        "spearman": 0.35044236883950164
      },
      {
        "cosine_pearson": 0.8091061539705682,
        "cosine_spearman": 0.805889304645576,
        "euclidean_pearson": 0.7867062595246089,
        "euclidean_spearman": 0.7825776851524335,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.805889304645576,
        "manhattan_pearson": 0.7861680952699255,
        "manhattan_spearman": 0.782406612069518,
        "pearson": 0.8091061539705682,
        "spearman": 0.805889304645576
      },
      {
        "cosine_pearson": 0.3611531892192428,
        "cosine_spearman": 0.326423053677153,
        "euclidean_pearson": 0.39771835047814363,
        "euclidean_spearman": 0.3528712644077362,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.326423053677153,
        "manhattan_pearson": 0.39590771268104646,
        "manhattan_spearman": 0.35126238125532894,
        "pearson": 0.3611531892192428,
        "spearman": 0.326423053677153
      },
      {
        "cosine_pearson": 0.6944397458796115,
        "cosine_spearman": 0.6780988208780563,
        "euclidean_pearson": 0.6573967413276189,
        "euclidean_spearman": 0.6459481496279188,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.6780988208780563,
        "manhattan_pearson": 0.6554498619174345,
        "manhattan_spearman": 0.64263270504315,
        "pearson": 0.6944397458796115,
        "spearman": 0.6780988208780563
      },
      {
        "cosine_pearson": 0.4521098048055496,
        "cosine_spearman": 0.45817501911802294,
        "euclidean_pearson": 0.4788751630536227,
        "euclidean_spearman": 0.45681886939495253,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.45817501911802294,
        "manhattan_pearson": 0.4808461486411121,
        "manhattan_spearman": 0.459012443220232,
        "pearson": 0.4521098048055496,
        "spearman": 0.45817501911802294
      },
      {
        "cosine_pearson": 0.3371456934826131,
        "cosine_spearman": 0.27394096361688597,
        "euclidean_pearson": 0.3192298926986508,
        "euclidean_spearman": 0.2647343028688415,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.27394096361688597,
        "manhattan_pearson": 0.3176482245120257,
        "manhattan_spearman": 0.26318613942283325,
        "pearson": 0.3371456934826131,
        "spearman": 0.27394096361688597
      },
      {
        "cosine_pearson": 0.7377041584987306,
        "cosine_spearman": 0.7060563224071481,
        "euclidean_pearson": 0.7435530479028991,
        "euclidean_spearman": 0.7165211421357754,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7060563224071481,
        "manhattan_pearson": 0.7442180014316094,
        "manhattan_spearman": 0.7180625477768979,
        "pearson": 0.7377041584987306,
        "spearman": 0.7060563224071481
      },
      {
        "cosine_pearson": 0.7695739727858445,
        "cosine_spearman": 0.7427188377234186,
        "euclidean_pearson": 0.7716546482405829,
        "euclidean_spearman": 0.738647388759141,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7427188377234186,
        "manhattan_pearson": 0.771761961800537,
        "manhattan_spearman": 0.739987281010987,
        "pearson": 0.7695739727858445,
        "spearman": 0.7427188377234186
      }
    ]
  },
  "task_name": "SemRel24STS"
}