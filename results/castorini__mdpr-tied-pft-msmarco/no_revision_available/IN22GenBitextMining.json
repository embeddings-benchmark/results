{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 46.668763160705566,
  "kg_co2_emissions": 0.002029106084407636,
  "mteb_version": "1.16.5",
  "scores": {
    "test": [
      {
        "accuracy": 0.5546875,
        "f1": 0.49969552937272893,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.49969552937272893,
        "precision": 0.48378109479705667,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04809602239916489,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.04809602239916489,
        "precision": 0.043250988400459274,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.17337922846109574,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.17337922846109574,
        "precision": 0.16162672229415592,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.17277031007143348,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.17277031007143348,
        "precision": 0.161937457918578,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.2255859375,
        "f1": 0.174757027282514,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.174757027282514,
        "precision": 0.16181494226056314,
        "recall": 0.2255859375
      },
      {
        "accuracy": 0.236328125,
        "f1": 0.18347973371814966,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.18347973371814966,
        "precision": 0.17085215348405097,
        "recall": 0.236328125
      },
      {
        "accuracy": 0.361328125,
        "f1": 0.298154243122074,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.298154243122074,
        "precision": 0.2809957775531273,
        "recall": 0.361328125
      },
      {
        "accuracy": 0.2236328125,
        "f1": 0.18539814996278603,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.18539814996278603,
        "precision": 0.1761769532096208,
        "recall": 0.2236328125
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09458263384768675,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.09458263384768675,
        "precision": 0.08497098486851005,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.2744140625,
        "f1": 0.2244270368688927,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.2244270368688927,
        "precision": 0.21069845238614543,
        "recall": 0.2744140625
      },
      {
        "accuracy": 0.2236328125,
        "f1": 0.17893301282239407,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.17893301282239407,
        "precision": 0.16871884661448291,
        "recall": 0.2236328125
      },
      {
        "accuracy": 0.302734375,
        "f1": 0.25510022130922383,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.25510022130922383,
        "precision": 0.24258007914462626,
        "recall": 0.302734375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0008038274739115283,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0008038274739115283,
        "precision": 0.0004979160222318056,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.2722451676387193,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.2722451676387193,
        "precision": 0.2590073708387637,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003616898148148148,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0003616898148148148,
        "precision": 0.0001971905048076923,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.18442657802854268,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.18442657802854268,
        "precision": 0.17350049094847103,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.2333984375,
        "f1": 0.17715706943617887,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.17715706943617887,
        "precision": 0.16234126197318893,
        "recall": 0.2333984375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009784698486328125,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0009784698486328125,
        "precision": 0.0009775171065493646,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.1109495826786165,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.1109495826786165,
        "precision": 0.10446784357434388,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.2216796875,
        "f1": 0.1764304331821625,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.1764304331821625,
        "precision": 0.16529403768301795,
        "recall": 0.2216796875
      },
      {
        "accuracy": 0.2353515625,
        "f1": 0.19326290159473758,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.19326290159473758,
        "precision": 0.18198296447455653,
        "recall": 0.2353515625
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.17961900394958613,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.17961900394958613,
        "precision": 0.16720427525312648,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.6064453125,
        "f1": 0.5376255688755689,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.5376255688755689,
        "precision": 0.5130835348462301,
        "recall": 0.6064453125
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.03726444469445851,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.03726444469445851,
        "precision": 0.032405061042315005,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.345703125,
        "f1": 0.2873625419844819,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.2873625419844819,
        "precision": 0.2715545955514648,
        "recall": 0.345703125
      },
      {
        "accuracy": 0.64453125,
        "f1": 0.5811225341498779,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.5811225341498779,
        "precision": 0.5596122112479534,
        "recall": 0.64453125
      },
      {
        "accuracy": 0.322265625,
        "f1": 0.2689631366579728,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.2689631366579728,
        "precision": 0.25353404934069096,
        "recall": 0.322265625
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.445847428369571,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.445847428369571,
        "precision": 0.4269034128848582,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7083402600004162,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.7083402600004162,
        "precision": 0.6892535497271826,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.5791015625,
        "f1": 0.5141354468014625,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.5141354468014625,
        "precision": 0.49429217876052667,
        "recall": 0.5791015625
      },
      {
        "accuracy": 0.197265625,
        "f1": 0.14471717387412636,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.14471717387412636,
        "precision": 0.13073909143376206,
        "recall": 0.197265625
      },
      {
        "accuracy": 0.5068359375,
        "f1": 0.43479513762548516,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.43479513762548516,
        "precision": 0.4128200231728706,
        "recall": 0.5068359375
      },
      {
        "accuracy": 0.4599609375,
        "f1": 0.40691027134406127,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.40691027134406127,
        "precision": 0.39132230916596616,
        "recall": 0.4599609375
      },
      {
        "accuracy": 0.6513671875,
        "f1": 0.5899676603778167,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.5899676603778167,
        "precision": 0.567781938655962,
        "recall": 0.6513671875
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.5088141025641026e-05,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 5.5088141025641026e-05,
        "precision": 2.8209456602624814e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.7031066101866883,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.7031066101866883,
        "precision": 0.6835379464285714,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006768615725127505,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0006768615725127505,
        "precision": 0.00042870499480662897,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.529296875,
        "f1": 0.4691411868657962,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.4691411868657962,
        "precision": 0.4493554167373874,
        "recall": 0.529296875
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.2187531174210302,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.2187531174210302,
        "precision": 0.20350299308364564,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001972501240079365,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0001972501240079365,
        "precision": 0.00010947671852587443,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.17330593475409473,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.17330593475409473,
        "precision": 0.16034139204548983,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.5625,
        "f1": 0.4995871902949858,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.4995871902949858,
        "precision": 0.4788265824886918,
        "recall": 0.5625
      },
      {
        "accuracy": 0.5830078125,
        "f1": 0.5226880691373117,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.5226880691373117,
        "precision": 0.5034768481301684,
        "recall": 0.5830078125
      },
      {
        "accuracy": 0.65234375,
        "f1": 0.5949139094184324,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.5949139094184324,
        "precision": 0.5758084679184173,
        "recall": 0.65234375
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.048974628990533196,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.048974628990533196,
        "precision": 0.04654353259707674,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03393997058138288,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.03393997058138288,
        "precision": 0.02989609928247569,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.07210865296991442,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.07210865296991442,
        "precision": 0.06771010664513519,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.026113226448001476,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.026113226448001476,
        "precision": 0.02510342365502454,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.05964515023859803,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.05964515023859803,
        "precision": 0.05638512147851007,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.040388613374285925,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.040388613374285925,
        "precision": 0.03734665596309183,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.05142254953658049,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.05142254953658049,
        "precision": 0.048897389593436716,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02994564703385757,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.02994564703385757,
        "precision": 0.027852256507041664,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.033576636193047044,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.033576636193047044,
        "precision": 0.030665010948086213,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.0536051265057976,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.0536051265057976,
        "precision": 0.05009344192288223,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03591095358334666,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.03591095358334666,
        "precision": 0.03258218991526293,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.04585911963585393,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04585911963585393,
        "precision": 0.04349262891524047,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.001953125,
        "f1": 7.972661919448476e-05,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 7.972661919448476e-05,
        "precision": 4.1371158392434986e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.04479094173008477,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04479094173008477,
        "precision": 0.04160665372009206,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002545032698871898,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0002545032698871898,
        "precision": 0.0001410895072565543,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.03762345202015142,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.03762345202015142,
        "precision": 0.03524589923332599,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.054181125246882504,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.054181125246882504,
        "precision": 0.049909499210792296,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019724628712871288,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00019724628712871288,
        "precision": 0.00010947479627794295,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.07740620057282385,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.07740620057282385,
        "precision": 0.0726159184444054,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.030836301497264143,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.030836301497264143,
        "precision": 0.028748782307738766,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.03332935483342045,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.03332935483342045,
        "precision": 0.03155265014219048,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.031440158606242566,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.031440158606242566,
        "precision": 0.029930191540405514,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.25,
        "f1": 0.1987858820866633,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.1987858820866633,
        "precision": 0.1845754482147634,
        "recall": 0.25
      },
      {
        "accuracy": 0.36328125,
        "f1": 0.2945792750647709,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2945792750647709,
        "precision": 0.27704031103445165,
        "recall": 0.36328125
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.12019774401741792,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.12019774401741792,
        "precision": 0.10942152147463799,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.333984375,
        "f1": 0.28632609369266915,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.28632609369266915,
        "precision": 0.27366536730889135,
        "recall": 0.333984375
      },
      {
        "accuracy": 0.4873046875,
        "f1": 0.4243448790464927,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4243448790464927,
        "precision": 0.4025798688616071,
        "recall": 0.4873046875
      },
      {
        "accuracy": 0.3154296875,
        "f1": 0.2581231154753386,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2581231154753386,
        "precision": 0.24215292351685133,
        "recall": 0.3154296875
      },
      {
        "accuracy": 0.6376953125,
        "f1": 0.5868417469310001,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5868417469310001,
        "precision": 0.5708511078842173,
        "recall": 0.6376953125
      },
      {
        "accuracy": 0.2802734375,
        "f1": 0.22498078878460973,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.22498078878460973,
        "precision": 0.21117080054505494,
        "recall": 0.2802734375
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.17260132100115916,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.17260132100115916,
        "precision": 0.15859582939230227,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.708984375,
        "f1": 0.6623737435907129,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6623737435907129,
        "precision": 0.6456089970281355,
        "recall": 0.708984375
      },
      {
        "accuracy": 0.265625,
        "f1": 0.21080484355619658,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.21080484355619658,
        "precision": 0.1960732365878593,
        "recall": 0.265625
      },
      {
        "accuracy": 0.5146484375,
        "f1": 0.4570258212099928,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4570258212099928,
        "precision": 0.43939649432813493,
        "recall": 0.5146484375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000982924470684039,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.000982924470684039,
        "precision": 0.0009797538807189542,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.5732421875,
        "f1": 0.5190635388981958,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5190635388981958,
        "precision": 0.5020561823049663,
        "recall": 0.5732421875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004974080023364486,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0004974080023364486,
        "precision": 0.0003301056338028169,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.3564453125,
        "f1": 0.30287251677411475,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.30287251677411475,
        "precision": 0.28886617640729484,
        "recall": 0.3564453125
      },
      {
        "accuracy": 0.373046875,
        "f1": 0.30737936144109046,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.30737936144109046,
        "precision": 0.2891230292767317,
        "recall": 0.373046875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015191290167997462,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0015191290167997462,
        "precision": 0.0013296568097101048,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.529296875,
        "f1": 0.46616368115391554,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.46616368115391554,
        "precision": 0.44469172049738454,
        "recall": 0.529296875
      },
      {
        "accuracy": 0.2900390625,
        "f1": 0.23737669106663697,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.23737669106663697,
        "precision": 0.22371153056329596,
        "recall": 0.2900390625
      },
      {
        "accuracy": 0.353515625,
        "f1": 0.29135452459205624,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.29135452459205624,
        "precision": 0.2732236428229848,
        "recall": 0.353515625
      },
      {
        "accuracy": 0.404296875,
        "f1": 0.350251606168534,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.350251606168534,
        "precision": 0.3357599659375423,
        "recall": 0.404296875
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.18505704986776908,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.18505704986776908,
        "precision": 0.16682651915859845,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.6689453125,
        "f1": 0.5976283482142857,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.5976283482142857,
        "precision": 0.5702862187725469,
        "recall": 0.6689453125
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.04158867899350853,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.04158867899350853,
        "precision": 0.03520164852675752,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.3583984375,
        "f1": 0.2834318146913529,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.2834318146913529,
        "precision": 0.26319480304227183,
        "recall": 0.3583984375
      },
      {
        "accuracy": 0.318359375,
        "f1": 0.24635412139433277,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.24635412139433277,
        "precision": 0.22804673377644682,
        "recall": 0.318359375
      },
      {
        "accuracy": 0.51953125,
        "f1": 0.4443627471703644,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.4443627471703644,
        "precision": 0.41905704605469085,
        "recall": 0.51953125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8435872395833334,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.8435872395833334,
        "precision": 0.8286946614583333,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.638671875,
        "f1": 0.5618737599206349,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.5618737599206349,
        "precision": 0.5339867001488094,
        "recall": 0.638671875
      },
      {
        "accuracy": 0.2314453125,
        "f1": 0.1609842096036173,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.1609842096036173,
        "precision": 0.14419638896233142,
        "recall": 0.2314453125
      },
      {
        "accuracy": 0.529296875,
        "f1": 0.45562606364479064,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.45562606364479064,
        "precision": 0.4325194395097601,
        "recall": 0.529296875
      },
      {
        "accuracy": 0.5068359375,
        "f1": 0.42961221079153855,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.42961221079153855,
        "precision": 0.40441457499691463,
        "recall": 0.5068359375
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.6728507874503968,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.6728507874503968,
        "precision": 0.6501883370535714,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00010490525889507786,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.00010490525889507786,
        "precision": 5.5309215465465465e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.76953125,
        "f1": 0.7141508556547619,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.7141508556547619,
        "precision": 0.6914299242424242,
        "recall": 0.76953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006551448704481792,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0006551448704481792,
        "precision": 0.0004903371710526316,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.537109375,
        "f1": 0.456745137458028,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.456745137458028,
        "precision": 0.4283589222078633,
        "recall": 0.537109375
      },
      {
        "accuracy": 0.2822265625,
        "f1": 0.21545064079337428,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.21545064079337428,
        "precision": 0.1986624984744003,
        "recall": 0.2822265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009844256202836711,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0009844256202836711,
        "precision": 0.0009805021889330084,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.25390625,
        "f1": 0.1854432139631107,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.1854432139631107,
        "precision": 0.16792199627162543,
        "recall": 0.25390625
      },
      {
        "accuracy": 0.6923828125,
        "f1": 0.6289186507936508,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.6289186507936508,
        "precision": 0.605378104425956,
        "recall": 0.6923828125
      },
      {
        "accuracy": 0.6513671875,
        "f1": 0.5809771337603369,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.5809771337603369,
        "precision": 0.5541976686507937,
        "recall": 0.6513671875
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.78955078125,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.78955078125,
        "precision": 0.7707845052083333,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.2177734375,
        "f1": 0.17954229553851925,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.17954229553851925,
        "precision": 0.16904030296472264,
        "recall": 0.2177734375
      },
      {
        "accuracy": 0.3388671875,
        "f1": 0.2862909142609492,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2862909142609492,
        "precision": 0.27219243210454147,
        "recall": 0.3388671875
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.1203226618693008,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1203226618693008,
        "precision": 0.10905447077330496,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.4697265625,
        "f1": 0.40789060386228354,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.40789060386228354,
        "precision": 0.38804969043711834,
        "recall": 0.4697265625
      },
      {
        "accuracy": 0.3076171875,
        "f1": 0.2543443583818531,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2543443583818531,
        "precision": 0.24050965084393858,
        "recall": 0.3076171875
      },
      {
        "accuracy": 0.3173828125,
        "f1": 0.26362975076713013,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.26362975076713013,
        "precision": 0.24901186529047348,
        "recall": 0.3173828125
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.4193635816378083,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4193635816378083,
        "precision": 0.40328784327675077,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.3076171875,
        "f1": 0.250986002468193,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.250986002468193,
        "precision": 0.23670694294514455,
        "recall": 0.3076171875
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.13554174312589984,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.13554174312589984,
        "precision": 0.12500451440784344,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.4769324669471154,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4769324669471154,
        "precision": 0.4575912233382936,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.29296875,
        "f1": 0.24391629400790343,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.24391629400790343,
        "precision": 0.2294138478708791,
        "recall": 0.29296875
      },
      {
        "accuracy": 0.640625,
        "f1": 0.5842994024749539,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5842994024749539,
        "precision": 0.564734485620716,
        "recall": 0.640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004906954959826947,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0004906954959826947,
        "precision": 0.00032672945028877886,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.4365234375,
        "f1": 0.3880772715708807,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.3880772715708807,
        "precision": 0.3737062874733773,
        "recall": 0.4365234375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.1451288244766506e-06,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 3.1451288244766506e-06,
        "precision": 1.575100806451613e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.2822265625,
        "f1": 0.2373811297863841,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.2373811297863841,
        "precision": 0.22346395514469294,
        "recall": 0.2822265625
      },
      {
        "accuracy": 0.3486328125,
        "f1": 0.2834710647040391,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.2834710647040391,
        "precision": 0.26464549170336094,
        "recall": 0.3486328125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.5900820375474543e-05,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 2.5900820375474543e-05,
        "precision": 1.3098549679170454e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.33984375,
        "f1": 0.29448647612704554,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.29448647612704554,
        "precision": 0.28172030174387397,
        "recall": 0.33984375
      },
      {
        "accuracy": 0.2900390625,
        "f1": 0.23884340671381563,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.23884340671381563,
        "precision": 0.22410818914497366,
        "recall": 0.2900390625
      },
      {
        "accuracy": 0.3359375,
        "f1": 0.27757653493472106,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.27757653493472106,
        "precision": 0.26011171346761686,
        "recall": 0.3359375
      },
      {
        "accuracy": 0.322265625,
        "f1": 0.26856803179482375,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.26856803179482375,
        "precision": 0.2540426724308394,
        "recall": 0.322265625
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.1816685345005088,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.1816685345005088,
        "precision": 0.16856750408113075,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.42730077868581373,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.42730077868581373,
        "precision": 0.406398379723575,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.039915926449143976,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.039915926449143976,
        "precision": 0.03412641961115222,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.283203125,
        "f1": 0.22441695542720896,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.22441695542720896,
        "precision": 0.20960148907795606,
        "recall": 0.283203125
      },
      {
        "accuracy": 0.44140625,
        "f1": 0.3883372147892691,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.3883372147892691,
        "precision": 0.3730857587713188,
        "recall": 0.44140625
      },
      {
        "accuracy": 0.2861328125,
        "f1": 0.22292895768122406,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.22292895768122406,
        "precision": 0.2069395100793342,
        "recall": 0.2861328125
      },
      {
        "accuracy": 0.6552734375,
        "f1": 0.5960282447587135,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.5960282447587135,
        "precision": 0.5761248417267126,
        "recall": 0.6552734375
      },
      {
        "accuracy": 0.5693359375,
        "f1": 0.5089688178957481,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.5089688178957481,
        "precision": 0.4903930206626181,
        "recall": 0.5693359375
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.10666013831212533,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.10666013831212533,
        "precision": 0.09709118954763693,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.3779296875,
        "f1": 0.31861642833623727,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.31861642833623727,
        "precision": 0.30206117777958724,
        "recall": 0.3779296875
      },
      {
        "accuracy": 0.5517578125,
        "f1": 0.4861294972160515,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.4861294972160515,
        "precision": 0.46511836528758,
        "recall": 0.5517578125
      },
      {
        "accuracy": 0.6015625,
        "f1": 0.5413398599555825,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.5413398599555825,
        "precision": 0.5218554544309018,
        "recall": 0.6015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9708627648839556e-06,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 1.9708627648839556e-06,
        "precision": 9.864267676767677e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.5615234375,
        "f1": 0.49882796999007933,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.49882796999007933,
        "precision": 0.4782152469522755,
        "recall": 0.5615234375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004958029123876765,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.0004958029123876765,
        "precision": 0.00029958648122710625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.59765625,
        "f1": 0.535558307338221,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.535558307338221,
        "precision": 0.514706988974567,
        "recall": 0.59765625
      },
      {
        "accuracy": 0.2587890625,
        "f1": 0.19559911962722765,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.19559911962722765,
        "precision": 0.18077212564465306,
        "recall": 0.2587890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.8846766366060746e-05,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 1.8846766366060746e-05,
        "precision": 9.496525795463196e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1962890625,
        "f1": 0.15325039394965867,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.15325039394965867,
        "precision": 0.14293115961791678,
        "recall": 0.1962890625
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.44085924383775943,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.44085924383775943,
        "precision": 0.4220978023712399,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.5048828125,
        "f1": 0.4413877769748634,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.4413877769748634,
        "precision": 0.4235553941639857,
        "recall": 0.5048828125
      },
      {
        "accuracy": 0.5908203125,
        "f1": 0.5302106097027972,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.5302106097027972,
        "precision": 0.5105664716029128,
        "recall": 0.5908203125
      },
      {
        "accuracy": 0.3505859375,
        "f1": 0.2728613461819157,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.2728613461819157,
        "precision": 0.2512298490427921,
        "recall": 0.3505859375
      },
      {
        "accuracy": 0.767578125,
        "f1": 0.7146329365079365,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7146329365079365,
        "precision": 0.6941487630208334,
        "recall": 0.767578125
      },
      {
        "accuracy": 0.154296875,
        "f1": 0.10322365954609987,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.10322365954609987,
        "precision": 0.09206091249066978,
        "recall": 0.154296875
      },
      {
        "accuracy": 0.7060546875,
        "f1": 0.6422034589759199,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6422034589759199,
        "precision": 0.6177761501736111,
        "recall": 0.7060546875
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.8433779761904762,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8433779761904762,
        "precision": 0.829248046875,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.5888671875,
        "f1": 0.5122572902358059,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5122572902358059,
        "precision": 0.48496868799603177,
        "recall": 0.5888671875
      },
      {
        "accuracy": 0.6953125,
        "f1": 0.634392826140873,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.634392826140873,
        "precision": 0.6116218687996031,
        "recall": 0.6953125
      },
      {
        "accuracy": 0.720703125,
        "f1": 0.6615408761160715,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6615408761160715,
        "precision": 0.6395398709363553,
        "recall": 0.720703125
      },
      {
        "accuracy": 0.2333984375,
        "f1": 0.1687442536555045,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1687442536555045,
        "precision": 0.1521819898087538,
        "recall": 0.2333984375
      },
      {
        "accuracy": 0.8896484375,
        "f1": 0.8603376116071428,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8603376116071428,
        "precision": 0.8477701822916667,
        "recall": 0.8896484375
      },
      {
        "accuracy": 0.595703125,
        "f1": 0.5198623370986653,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5198623370986653,
        "precision": 0.4937125365060797,
        "recall": 0.595703125
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8940755208333333,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8940755208333333,
        "precision": 0.883251953125,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008976421468303946,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0008976421468303946,
        "precision": 0.0006290216571338497,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9446614583333333,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9446614583333333,
        "precision": 0.9381510416666667,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00013503138699793796,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00013503138699793796,
        "precision": 6.997718786857805e-05,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.6626449342757936,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6626449342757936,
        "precision": 0.6400115482390873,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.5322265625,
        "f1": 0.45093168008207074,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.45093168008207074,
        "precision": 0.4244378631542579,
        "recall": 0.5322265625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.678998713913426e-05,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 1.678998713913426e-05,
        "precision": 8.45104567605165e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.5185546875,
        "f1": 0.4452723383387446,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4452723383387446,
        "precision": 0.4212284297733516,
        "recall": 0.5185546875
      },
      {
        "accuracy": 0.71484375,
        "f1": 0.6537225632440475,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6537225632440475,
        "precision": 0.63082098565497,
        "recall": 0.71484375
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.7050437372728697,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7050437372728697,
        "precision": 0.684943111359127,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.7920921688988095,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7920921688988095,
        "precision": 0.7739133804563493,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.16762875008946773,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.16762875008946773,
        "precision": 0.15143718737788894,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5345483751552065,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.5345483751552065,
        "precision": 0.512013279689061,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.023329309431920943,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.023329309431920943,
        "precision": 0.019831754612236636,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.236328125,
        "f1": 0.17958552330870134,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.17958552330870134,
        "precision": 0.16658121261582812,
        "recall": 0.236328125
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.5153623979867661,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.5153623979867661,
        "precision": 0.4957244144744145,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.2783203125,
        "f1": 0.21375653692023924,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.21375653692023924,
        "precision": 0.19751940139611823,
        "recall": 0.2783203125
      },
      {
        "accuracy": 0.5712890625,
        "f1": 0.5049731806593443,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.5049731806593443,
        "precision": 0.4839509651186386,
        "recall": 0.5712890625
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.637553612007886,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.637553612007886,
        "precision": 0.6181964208209325,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.07516308454372056,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.07516308454372056,
        "precision": 0.0671343270247395,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.3623046875,
        "f1": 0.3014263193794682,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.3014263193794682,
        "precision": 0.2857295478417431,
        "recall": 0.3623046875
      },
      {
        "accuracy": 0.6240234375,
        "f1": 0.5631560368428172,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.5631560368428172,
        "precision": 0.5433609603287337,
        "recall": 0.6240234375
      },
      {
        "accuracy": 0.6103515625,
        "f1": 0.5625812362362709,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.5625812362362709,
        "precision": 0.5447504936907526,
        "recall": 0.6103515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00011045811827061827,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.00011045811827061827,
        "precision": 5.842141544117647e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.6416015625,
        "f1": 0.5809565850093193,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.5809565850093193,
        "precision": 0.56118051870005,
        "recall": 0.6416015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0052618069815196e-06,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 2.0052618069815196e-06,
        "precision": 1.0036613566289826e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.4267578125,
        "f1": 0.3636446049951382,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.3636446049951382,
        "precision": 0.3463104258272164,
        "recall": 0.4267578125
      },
      {
        "accuracy": 0.212890625,
        "f1": 0.1635496339177288,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.1635496339177288,
        "precision": 0.15200103590579306,
        "recall": 0.212890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.1154625990826505e-05,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 1.1154625990826505e-05,
        "precision": 5.598383186935613e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.10903025417619158,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.10903025417619158,
        "precision": 0.1002457453352875,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.6376953125,
        "f1": 0.5810178834837038,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.5810178834837038,
        "precision": 0.561686515109941,
        "recall": 0.6376953125
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6595389735377847,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.6595389735377847,
        "precision": 0.6414057215570887,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.556640625,
        "f1": 0.49584732662915104,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.49584732662915104,
        "precision": 0.47498554415058325,
        "recall": 0.556640625
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09896133755135508,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.09896133755135508,
        "precision": 0.0927588369040773,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.1630859375,
        "f1": 0.12463055753712347,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.12463055753712347,
        "precision": 0.11645086376770311,
        "recall": 0.1630859375
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.04427481200396015,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.04427481200396015,
        "precision": 0.039974601223208506,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.1532891695109453,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.1532891695109453,
        "precision": 0.144686758902617,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.16450140804775387,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.16450140804775387,
        "precision": 0.15558479702673006,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.11688176349749403,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.11688176349749403,
        "precision": 0.10752647164175008,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.10817675633983229,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.10817675633983229,
        "precision": 0.10156525923093182,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.244140625,
        "f1": 0.19227720774047302,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.19227720774047302,
        "precision": 0.17885314875257596,
        "recall": 0.244140625
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.07920159590730622,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.07920159590730622,
        "precision": 0.07333429185123781,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.1595849464391945,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.1595849464391945,
        "precision": 0.15071963466192753,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.1281346312601886,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.1281346312601886,
        "precision": 0.11946223178060825,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.14956490556677798,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.14956490556677798,
        "precision": 0.13896590096963798,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018655486299561767,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0018655486299561767,
        "precision": 0.0015948713125271362,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.17177174845743792,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.17177174845743792,
        "precision": 0.16023083529745558,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0010777964786271093,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0010777964786271093,
        "precision": 0.0007350309013419278,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.12076629450767778,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.12076629450767778,
        "precision": 0.1147478058538607,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.10141969073967075,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.10141969073967075,
        "precision": 0.0946969746158953,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006055519545708498,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0006055519545708498,
        "precision": 0.000349512141504329,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.10068318790660068,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.10068318790660068,
        "precision": 0.09541389111156445,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.1669921875,
        "f1": 0.12358535517156437,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.12358535517156437,
        "precision": 0.11461147185517323,
        "recall": 0.1669921875
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.14792740640327917,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.14792740640327917,
        "precision": 0.13878368059276264,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.4521484375,
        "f1": 0.40390932956362646,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.40390932956362646,
        "precision": 0.3896806976376282,
        "recall": 0.4521484375
      },
      {
        "accuracy": 0.3486328125,
        "f1": 0.28378507052218777,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.28378507052218777,
        "precision": 0.2628894682971831,
        "recall": 0.3486328125
      },
      {
        "accuracy": 0.544921875,
        "f1": 0.47703961525717636,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.47703961525717636,
        "precision": 0.45569095346927374,
        "recall": 0.544921875
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.09856143258574011,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.09856143258574011,
        "precision": 0.08796905465131448,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.6780304439484127,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6780304439484127,
        "precision": 0.6575183686755952,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.5244140625,
        "f1": 0.4646300765683566,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.4646300765683566,
        "precision": 0.4458793615945875,
        "recall": 0.5244140625
      },
      {
        "accuracy": 0.5576171875,
        "f1": 0.49038771558302807,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.49038771558302807,
        "precision": 0.4674084243664322,
        "recall": 0.5576171875
      },
      {
        "accuracy": 0.4423828125,
        "f1": 0.38096736691904287,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.38096736691904287,
        "precision": 0.361853228279584,
        "recall": 0.4423828125
      },
      {
        "accuracy": 0.865234375,
        "f1": 0.8336201016865079,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8336201016865079,
        "precision": 0.8213406032986111,
        "recall": 0.865234375
      },
      {
        "accuracy": 0.4267578125,
        "f1": 0.35970577289809674,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.35970577289809674,
        "precision": 0.34130987194009293,
        "recall": 0.4267578125
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.16704740011028618,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.16704740011028618,
        "precision": 0.15145060382253928,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.40625,
        "f1": 0.3399907980474387,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3399907980474387,
        "precision": 0.3200479469723495,
        "recall": 0.40625
      },
      {
        "accuracy": 0.7265625,
        "f1": 0.671409835536961,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.671409835536961,
        "precision": 0.6504718114459325,
        "recall": 0.7265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0022819173994974872,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0022819173994974872,
        "precision": 0.0019547635276845636,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8083736359126983,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8083736359126983,
        "precision": 0.7952584655635351,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00016721472473088853,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00016721472473088853,
        "precision": 8.90814124659231e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.4375,
        "f1": 0.3728625441367459,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.3728625441367459,
        "precision": 0.35325694542003133,
        "recall": 0.4375
      },
      {
        "accuracy": 0.5234375,
        "f1": 0.44997375165343917,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.44997375165343917,
        "precision": 0.4252693314906091,
        "recall": 0.5234375
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.507807558507274e-05,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 2.507807558507274e-05,
        "precision": 1.2676941571838637e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.4318921893367947,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4318921893367947,
        "precision": 0.41204096961938186,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.408203125,
        "f1": 0.33834380783538426,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.33834380783538426,
        "precision": 0.31621910567223066,
        "recall": 0.408203125
      },
      {
        "accuracy": 0.494140625,
        "f1": 0.43023668753742883,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.43023668753742883,
        "precision": 0.40946576887738995,
        "recall": 0.494140625
      },
      {
        "accuracy": 0.5341796875,
        "f1": 0.46982889072732825,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.46982889072732825,
        "precision": 0.44979190857608825,
        "recall": 0.5341796875
      },
      {
        "accuracy": 0.2607421875,
        "f1": 0.19182292895183517,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.19182292895183517,
        "precision": 0.1736791997979383,
        "recall": 0.2607421875
      },
      {
        "accuracy": 0.4697265625,
        "f1": 0.4060717231118415,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.4060717231118415,
        "precision": 0.38724146879191523,
        "recall": 0.4697265625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03614856014097391,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.03614856014097391,
        "precision": 0.030779598512694052,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.2236328125,
        "f1": 0.17989129090687517,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.17989129090687517,
        "precision": 0.16970927927894375,
        "recall": 0.2236328125
      },
      {
        "accuracy": 0.4462890625,
        "f1": 0.39801664011435345,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.39801664011435345,
        "precision": 0.38290606713464204,
        "recall": 0.4462890625
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.17515516660162467,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.17515516660162467,
        "precision": 0.16289613814487058,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.462890625,
        "f1": 0.4053429623672561,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.4053429623672561,
        "precision": 0.3875919895869673,
        "recall": 0.462890625
      },
      {
        "accuracy": 0.5634765625,
        "f1": 0.5031716429517041,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.5031716429517041,
        "precision": 0.484020781935307,
        "recall": 0.5634765625
      },
      {
        "accuracy": 0.5341796875,
        "f1": 0.4859075541116252,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.4859075541116252,
        "precision": 0.47020865938474904,
        "recall": 0.5341796875
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.09922144355007967,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.09922144355007967,
        "precision": 0.08780238898834215,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.328125,
        "f1": 0.271884597884517,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.271884597884517,
        "precision": 0.25445814010496987,
        "recall": 0.328125
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.4161774033327577,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.4161774033327577,
        "precision": 0.39646658141080415,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.951173826173826e-06,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 1.951173826173826e-06,
        "precision": 9.765625e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.472541050993897,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.472541050993897,
        "precision": 0.4520897627220869,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1920594837261506e-06,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 2.1920594837261506e-06,
        "precision": 1.0972612359550563e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.41796875,
        "f1": 0.3612824581443934,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.3612824581443934,
        "precision": 0.3446600154190805,
        "recall": 0.41796875
      },
      {
        "accuracy": 0.234375,
        "f1": 0.1793751148028011,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.1793751148028011,
        "precision": 0.1664403786265398,
        "recall": 0.234375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009848707961486222,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0009848707961486222,
        "precision": 0.000980726205083306,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.197265625,
        "f1": 0.14115772778155963,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.14115772778155963,
        "precision": 0.1280264221590129,
        "recall": 0.197265625
      },
      {
        "accuracy": 0.51171875,
        "f1": 0.45537476693461054,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.45537476693461054,
        "precision": 0.43835852592084606,
        "recall": 0.51171875
      },
      {
        "accuracy": 0.5576171875,
        "f1": 0.5049822194336461,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.5049822194336461,
        "precision": 0.48819048444923724,
        "recall": 0.5576171875
      },
      {
        "accuracy": 0.4794921875,
        "f1": 0.4212583954354979,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.4212583954354979,
        "precision": 0.40308394713545703,
        "recall": 0.4794921875
      },
      {
        "accuracy": 0.318359375,
        "f1": 0.2487055661024922,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.2487055661024922,
        "precision": 0.23020728723625816,
        "recall": 0.318359375
      },
      {
        "accuracy": 0.650390625,
        "f1": 0.5940440120860042,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5940440120860042,
        "precision": 0.575445932648081,
        "recall": 0.650390625
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.08375028345611822,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.08375028345611822,
        "precision": 0.07498160815545862,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.541015625,
        "f1": 0.4784786890988063,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4784786890988063,
        "precision": 0.4574323643184149,
        "recall": 0.541015625
      },
      {
        "accuracy": 0.673828125,
        "f1": 0.6180393011935981,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6180393011935981,
        "precision": 0.5995546264602083,
        "recall": 0.673828125
      },
      {
        "accuracy": 0.654296875,
        "f1": 0.5945419773910985,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5945419773910985,
        "precision": 0.5739262216628018,
        "recall": 0.654296875
      },
      {
        "accuracy": 0.63671875,
        "f1": 0.5763738990815471,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5763738990815471,
        "precision": 0.5551314701631023,
        "recall": 0.63671875
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8807965959821429,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8807965959821429,
        "precision": 0.8705659412202381,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.6201171875,
        "f1": 0.5620122085499386,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5620122085499386,
        "precision": 0.5429959042779807,
        "recall": 0.6201171875
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.15343755180369467,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.15343755180369467,
        "precision": 0.14041306477813859,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.724609375,
        "f1": 0.664703853546627,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.664703853546627,
        "precision": 0.6415519945549242,
        "recall": 0.724609375
      },
      {
        "accuracy": 0.556640625,
        "f1": 0.49204817620473457,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.49204817620473457,
        "precision": 0.47016178770085015,
        "recall": 0.556640625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0451570680628274e-06,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 2.0451570680628274e-06,
        "precision": 1.0236504192872118e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.8454334077380952,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8454334077380952,
        "precision": 0.8325032552083333,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.063881082972192e-05,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 3.063881082972192e-05,
        "precision": 1.5518408908507223e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.583984375,
        "f1": 0.5283173863097794,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5283173863097794,
        "precision": 0.5094326636904762,
        "recall": 0.583984375
      },
      {
        "accuracy": 0.4990234375,
        "f1": 0.42558778103037853,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.42558778103037853,
        "precision": 0.4024670162622465,
        "recall": 0.4990234375
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.8436578171091445e-05,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 1.8436578171091445e-05,
        "precision": 9.287872125594423e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.41015625,
        "f1": 0.34929233647583985,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.34929233647583985,
        "precision": 0.33204256665675264,
        "recall": 0.41015625
      },
      {
        "accuracy": 0.6064453125,
        "f1": 0.5412128263446623,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5412128263446623,
        "precision": 0.5194072881328741,
        "recall": 0.6064453125
      },
      {
        "accuracy": 0.6591796875,
        "f1": 0.6045488365800866,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6045488365800866,
        "precision": 0.5852845559388529,
        "recall": 0.6591796875
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.6156309619200243,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6156309619200243,
        "precision": 0.5965475415426588,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.030275467775468e-06,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 2.030275467775468e-06,
        "precision": 1.01619406867846e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.4912308673469386e-06,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 2.4912308673469386e-06,
        "precision": 1.2472062579821201e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9828680203045686e-06,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 1.9828680203045686e-06,
        "precision": 9.924415650406505e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.968876008064516e-06,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 1.968876008064516e-06,
        "precision": 9.854313824419778e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00100045103894488,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.00100045103894488,
        "precision": 0.0009886299133685193,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002127905216512907,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0002127905216512907,
        "precision": 0.00011229090947429763,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 8.98827993864001e-06,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 8.98827993864001e-06,
        "precision": 4.505747742240709e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000989369091646697,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.000989369091646697,
        "precision": 0.0009829894497863248,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009882200895456076,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0009882200895456076,
        "precision": 0.000982414217197248,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.9134714374640873e-05,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 1.9134714374640873e-05,
        "precision": 9.643032868140583e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010568932075083225,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0010568932075083225,
        "precision": 0.0010181271837569924,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 4.5100692899336e-05,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 4.5100692899336e-05,
        "precision": 2.2822796157228878e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 5.380509641873278e-06,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 5.380509641873278e-06,
        "precision": 2.6976864640883977e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002895762251861042,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0002895762251861042,
        "precision": 0.00016261090721713786,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.078125,
        "f1": 0.06233197844153551,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.06233197844153551,
        "precision": 0.05839286880504553,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9073486328125e-06,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 1.9073486328125e-06,
        "precision": 9.546065493646139e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013692944309600863,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0013692944309600863,
        "precision": 0.0012217577281317495,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07638799460088522,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.07638799460088522,
        "precision": 0.06862209242580336,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00015242508819480297,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.00015242508819480297,
        "precision": 8.247378336132886e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.211919592298981e-06,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 2.211919592298981e-06,
        "precision": 1.1072137188208617e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009784943743818002,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0009784943743818002,
        "precision": 0.0009775293935643564,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.004807692307692e-05,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 3.004807692307692e-05,
        "precision": 1.522740589276319e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.361328125,
        "f1": 0.28508198962126674,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.28508198962126674,
        "precision": 0.26351547476733417,
        "recall": 0.361328125
      },
      {
        "accuracy": 0.7333984375,
        "f1": 0.6763470362103174,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6763470362103174,
        "precision": 0.6544523429044913,
        "recall": 0.7333984375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.09171928449892319,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.09171928449892319,
        "precision": 0.0801849420887212,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.623046875,
        "f1": 0.5541108143158924,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5541108143158924,
        "precision": 0.530581942471591,
        "recall": 0.623046875
      },
      {
        "accuracy": 0.73828125,
        "f1": 0.6825660559058996,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6825660559058996,
        "precision": 0.6619237858495671,
        "recall": 0.73828125
      },
      {
        "accuracy": 0.5302734375,
        "f1": 0.4546614301497114,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4546614301497114,
        "precision": 0.4294278339932637,
        "recall": 0.5302734375
      },
      {
        "accuracy": 0.595703125,
        "f1": 0.5286588664518352,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5286588664518352,
        "precision": 0.5061480863971097,
        "recall": 0.595703125
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.92431640625,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.92431640625,
        "precision": 0.9158528645833334,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.63671875,
        "f1": 0.5684609986367799,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5684609986367799,
        "precision": 0.5442088645946067,
        "recall": 0.63671875
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.15307441343519945,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.15307441343519945,
        "precision": 0.13988270393472496,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8065824962797619,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8065824962797619,
        "precision": 0.791064875879329,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.578125,
        "f1": 0.5021872821189227,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5021872821189227,
        "precision": 0.47659776475694443,
        "recall": 0.578125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8439964657738095,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8439964657738095,
        "precision": 0.8286458333333333,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1871500559910414e-06,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 2.1871500559910414e-06,
        "precision": 1.0948010089686098e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000634266242834343,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.000634266242834343,
        "precision": 0.0004031956685822878,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.6259765625,
        "f1": 0.5614892756982601,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5614892756982601,
        "precision": 0.5387927160729896,
        "recall": 0.6259765625
      },
      {
        "accuracy": 0.5478515625,
        "f1": 0.4716785466053044,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4716785466053044,
        "precision": 0.44656653025793647,
        "recall": 0.5478515625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010239790320569163,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0010239790320569163,
        "precision": 0.0010008125182588371,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.404296875,
        "f1": 0.3314542753285168,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3314542753285168,
        "precision": 0.3099870699681132,
        "recall": 0.404296875
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5518207324359669,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5518207324359669,
        "precision": 0.5274967030582265,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.701171875,
        "f1": 0.6477401377217553,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6477401377217553,
        "precision": 0.628910776994273,
        "recall": 0.701171875
      },
      {
        "accuracy": 0.71875,
        "f1": 0.6624402019421551,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6624402019421551,
        "precision": 0.6426416790674603,
        "recall": 0.71875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.139238773274918e-06,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 2.139238773274918e-06,
        "precision": 1.0707922149122806e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.3477996738132704e-05,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 1.3477996738132704e-05,
        "precision": 6.769651330720033e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015482500216113416,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0015482500216113416,
        "precision": 0.0013123980121643674,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9668932527693857e-06,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 1.9668932527693857e-06,
        "precision": 9.84438004032258e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.1804798411388758e-05,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 1.1804798411388758e-05,
        "precision": 5.925384165623559e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00011085447866992846,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.00011085447866992846,
        "precision": 5.638836058860589e-05,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.6293356604609928e-05,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 1.6293356604609928e-05,
        "precision": 8.19767734221348e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0020783263792055074,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0020783263792055074,
        "precision": 0.0020180333127849206,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00016563973753887224,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.00016563973753887224,
        "precision": 8.638916529849313e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0933815648445873e-06,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 2.0933815648445873e-06,
        "precision": 1.0478138412017167e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00039524731247332477,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.00039524731247332477,
        "precision": 0.0002311165072918276,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00016757133929773768,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.00016757133929773768,
        "precision": 8.812487076095947e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010879290710915895,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0010879290710915895,
        "precision": 0.001033980213525063,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.058505458842372904,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.058505458842372904,
        "precision": 0.04954857967553279,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00037360285795132994,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.00037360285795132994,
        "precision": 0.00021960772328634244,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.914828431372549e-06,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 1.914828431372549e-06,
        "precision": 9.583537782139352e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010126876649504608,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0010126876649504608,
        "precision": 0.0009949220127501543,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.0244731071174037,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0244731071174037,
        "precision": 0.01988364610422435,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00028107161634369833,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.00028107161634369833,
        "precision": 0.00016378837719298244,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.779047376834762e-05,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 5.779047376834762e-05,
        "precision": 2.9716889301545464e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00037296630869181025,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.00037296630869181025,
        "precision": 0.00021957701973424225,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.7479031385281387e-05,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 2.7479031385281387e-05,
        "precision": 1.3907537456520499e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2333984375,
        "f1": 0.18144223317084007,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.18144223317084007,
        "precision": 0.16683190413671473,
        "recall": 0.2333984375
      },
      {
        "accuracy": 0.5458984375,
        "f1": 0.4752501785114247,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.4752501785114247,
        "precision": 0.45208217075892854,
        "recall": 0.5458984375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.04822616711681547,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.04822616711681547,
        "precision": 0.04222956102250568,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.34765625,
        "f1": 0.2739892435400248,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.2739892435400248,
        "precision": 0.2546135904607504,
        "recall": 0.34765625
      },
      {
        "accuracy": 0.4892578125,
        "f1": 0.4292886224832026,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.4292886224832026,
        "precision": 0.41068974791392,
        "recall": 0.4892578125
      },
      {
        "accuracy": 0.27734375,
        "f1": 0.21374399774311925,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.21374399774311925,
        "precision": 0.19689233161014574,
        "recall": 0.27734375
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.558817683223129,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.558817683223129,
        "precision": 0.5364167096466901,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.673828125,
        "f1": 0.6154800386245699,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.6154800386245699,
        "precision": 0.5953903437057733,
        "recall": 0.673828125
      },
      {
        "accuracy": 0.435546875,
        "f1": 0.3754035215156387,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.3754035215156387,
        "precision": 0.358292231727078,
        "recall": 0.435546875
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.12926077033369315,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.12926077033369315,
        "precision": 0.1174114002007711,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.3955078125,
        "f1": 0.3292597796982691,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.3292597796982691,
        "precision": 0.30851339134728195,
        "recall": 0.3955078125
      },
      {
        "accuracy": 0.470703125,
        "f1": 0.39984879197086465,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.39984879197086465,
        "precision": 0.37811641483516484,
        "recall": 0.470703125
      },
      {
        "accuracy": 0.583984375,
        "f1": 0.5164975866147742,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.5164975866147742,
        "precision": 0.4927945489725918,
        "recall": 0.583984375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019740140374331552,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.00019740140374331552,
        "precision": 0.00010955251457292409,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.58984375,
        "f1": 0.5236008674485237,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.5236008674485237,
        "precision": 0.5030908138085872,
        "recall": 0.58984375
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.651256307821699e-05,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 2.651256307821699e-05,
        "precision": 1.3405170392538025e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.1743527424582559,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.1743527424582559,
        "precision": 0.15980663381784505,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.867865716003864e-06,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 9.867865716003864e-06,
        "precision": 4.94928679180786e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.17086107212116994,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.17086107212116994,
        "precision": 0.15821144100734874,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.4814453125,
        "f1": 0.41389010717276303,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.41389010717276303,
        "precision": 0.3927669837215736,
        "recall": 0.4814453125
      },
      {
        "accuracy": 0.453125,
        "f1": 0.3940165131217944,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.3940165131217944,
        "precision": 0.3756730587358714,
        "recall": 0.453125
      },
      {
        "accuracy": 0.6201171875,
        "f1": 0.5591451194587684,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.5591451194587684,
        "precision": 0.538048094212645,
        "recall": 0.6201171875
      },
      {
        "accuracy": 0.212890625,
        "f1": 0.1733564889843612,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.1733564889843612,
        "precision": 0.16425192891525653,
        "recall": 0.212890625
      },
      {
        "accuracy": 0.26171875,
        "f1": 0.2158184914639659,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2158184914639659,
        "precision": 0.20462778573868712,
        "recall": 0.26171875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06714468713978158,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.06714468713978158,
        "precision": 0.06225225605456048,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.267578125,
        "f1": 0.22111610656996994,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.22111610656996994,
        "precision": 0.20821970632314027,
        "recall": 0.267578125
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.17656560476114833,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.17656560476114833,
        "precision": 0.16868153614171505,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.2744140625,
        "f1": 0.2328468053347268,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2328468053347268,
        "precision": 0.22220969326823015,
        "recall": 0.2744140625
      },
      {
        "accuracy": 0.224609375,
        "f1": 0.17625460989609784,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.17625460989609784,
        "precision": 0.16475933142321403,
        "recall": 0.224609375
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.2963050824449889,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2963050824449889,
        "precision": 0.2836886735413473,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.16692261814856918,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.16692261814856918,
        "precision": 0.15616159437630006,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10848040318084035,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.10848040318084035,
        "precision": 0.10026324567914642,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.380859375,
        "f1": 0.32752394838194604,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.32752394838194604,
        "precision": 0.3141385901022322,
        "recall": 0.380859375
      },
      {
        "accuracy": 0.2392578125,
        "f1": 0.1934332244936645,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1934332244936645,
        "precision": 0.18181252529291886,
        "recall": 0.2392578125
      },
      {
        "accuracy": 0.3515625,
        "f1": 0.30939858353104244,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.30939858353104244,
        "precision": 0.29741597853574686,
        "recall": 0.3515625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018660835597826089,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0018660835597826089,
        "precision": 0.0015913326477053288,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.4150390625,
        "f1": 0.3627685427561127,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.3627685427561127,
        "precision": 0.3483097726942709,
        "recall": 0.4150390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011046570616883116,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0011046570616883116,
        "precision": 0.0007435068867663344,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.14023562034781928,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.14023562034781928,
        "precision": 0.13265071345994595,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004071298213688086,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0004071298213688086,
        "precision": 0.000252442678338818,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.15704905337301986,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.15704905337301986,
        "precision": 0.14871608579349177,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.21875,
        "f1": 0.17111492220262536,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.17111492220262536,
        "precision": 0.15995149101242864,
        "recall": 0.21875
      },
      {
        "accuracy": 0.2509765625,
        "f1": 0.20736598387730273,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.20736598387730273,
        "precision": 0.19665963295518069,
        "recall": 0.2509765625
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.17484512928186885,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.17484512928186885,
        "precision": 0.1633413673402427,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006529754537953795,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0006529754537953795,
        "precision": 0.0004892491018334985,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785843685300207,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0009785843685300207,
        "precision": 0.000977574481865285,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9492265469061875e-06,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 1.9492265469061875e-06,
        "precision": 9.75586913086913e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785698227132579,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0009785698227132579,
        "precision": 0.0009775671939300412,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019802742703660626,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0019802742703660626,
        "precision": 0.0019668633731133728,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010804478616719924,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0010804478616719924,
        "precision": 0.0010306610551457256,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000979234353625171,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.000979234353625171,
        "precision": 0.0009779002568493151,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0021123485409857757,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0021123485409857757,
        "precision": 0.0020356354225839523,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010288273317845466,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0010288273317845466,
        "precision": 0.0010033550881858903,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00099173435923549,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.00099173435923549,
        "precision": 0.0009841928277905198,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002028894295570448,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.002028894295570448,
        "precision": 0.0019922216932721218,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001045846038624084,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.001045846038624084,
        "precision": 0.001012021743239637,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000999659981284101,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.000999659981284101,
        "precision": 0.0009881989920390345,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06136300223214285,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.06136300223214285,
        "precision": 0.05227167038690476,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002881825294244252,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.002881825294244252,
        "precision": 0.0025978280393822023,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.03566989224810388,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.03566989224810388,
        "precision": 0.0337942470057858,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9073486328125e-06,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 1.9073486328125e-06,
        "precision": 9.546065493646139e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007253584796802882,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0007253584796802882,
        "precision": 0.000526831774652832,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013693314352360045,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0013693314352360045,
        "precision": 0.0012217762706043956,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009925313288460923,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0009925313288460923,
        "precision": 0.0009845969456653866,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019550530602171767,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0019550530602171767,
        "precision": 0.00195408998270751,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009949336236744783,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0009949336236744783,
        "precision": 0.0009858165922619047,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.11261292038288719,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.11261292038288719,
        "precision": 0.10350530145434575,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.1636262887739539,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.1636262887739539,
        "precision": 0.15286774389796715,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.171875,
        "f1": 0.12744131299888697,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.12744131299888697,
        "precision": 0.11580304996438502,
        "recall": 0.171875
      },
      {
        "accuracy": 0.501953125,
        "f1": 0.44176645200549747,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.44176645200549747,
        "precision": 0.4203847909902597,
        "recall": 0.501953125
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.17173051171534995,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.17173051171534995,
        "precision": 0.16380222991710108,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.2987710186778937,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2987710186778937,
        "precision": 0.2810305024294282,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.17028657792459279,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.17028657792459279,
        "precision": 0.1567447992482343,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.40625,
        "f1": 0.3575990145191087,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3575990145191087,
        "precision": 0.34317829843472014,
        "recall": 0.40625
      },
      {
        "accuracy": 0.171875,
        "f1": 0.12893923853289982,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.12893923853289982,
        "precision": 0.11831693076418419,
        "recall": 0.171875
      },
      {
        "accuracy": 0.1875,
        "f1": 0.14338043741478942,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.14338043741478942,
        "precision": 0.1326155044246463,
        "recall": 0.1875
      },
      {
        "accuracy": 0.41015625,
        "f1": 0.3598653881602477,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3598653881602477,
        "precision": 0.3448288703495381,
        "recall": 0.41015625
      },
      {
        "accuracy": 0.2119140625,
        "f1": 0.1640009915008278,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1640009915008278,
        "precision": 0.1522525565816149,
        "recall": 0.2119140625
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.301957233163081,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.301957233163081,
        "precision": 0.28787919166337134,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002395795863152169,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002395795863152169,
        "precision": 0.0022237381048568093,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.3046875,
        "f1": 0.2551018775311322,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2551018775311322,
        "precision": 0.24187477298957394,
        "recall": 0.3046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001146610696517413,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.001146610696517413,
        "precision": 0.0010689984465440925,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2216796875,
        "f1": 0.1823839882150775,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1823839882150775,
        "precision": 0.17326056116955946,
        "recall": 0.2216796875
      },
      {
        "accuracy": 0.271484375,
        "f1": 0.2167612107944139,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.2167612107944139,
        "precision": 0.20271765289985158,
        "recall": 0.271484375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004999635386864316,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0004999635386864316,
        "precision": 0.0003313795056440007,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.15658506917678766,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.15658506917678766,
        "precision": 0.14622201520950523,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.18027861095606212,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.18027861095606212,
        "precision": 0.17024561877467148,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.2451171875,
        "f1": 0.19613209955042965,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.19613209955042965,
        "precision": 0.18379055012595366,
        "recall": 0.2451171875
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.17105898719566412,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.17105898719566412,
        "precision": 0.15545643440454582,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.5712890625,
        "f1": 0.5011100200797467,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.5011100200797467,
        "precision": 0.4767376331542232,
        "recall": 0.5712890625
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.03010942515459824,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.03010942515459824,
        "precision": 0.025242237105760918,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.2958984375,
        "f1": 0.22521362460699185,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.22521362460699185,
        "precision": 0.2077515257441931,
        "recall": 0.2958984375
      },
      {
        "accuracy": 0.6923828125,
        "f1": 0.6312630566048535,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.6312630566048535,
        "precision": 0.6095141214037698,
        "recall": 0.6923828125
      },
      {
        "accuracy": 0.2705078125,
        "f1": 0.19926818224553386,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.19926818224553386,
        "precision": 0.18083420293881816,
        "recall": 0.2705078125
      },
      {
        "accuracy": 0.501953125,
        "f1": 0.43705512298190463,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.43705512298190463,
        "precision": 0.4160987901710558,
        "recall": 0.501953125
      },
      {
        "accuracy": 0.6826171875,
        "f1": 0.6221548633658008,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.6221548633658008,
        "precision": 0.5998488057081807,
        "recall": 0.6826171875
      },
      {
        "accuracy": 0.650390625,
        "f1": 0.5861617928512459,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.5861617928512459,
        "precision": 0.5628133647921888,
        "recall": 0.650390625
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.12117595238892497,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.12117595238892497,
        "precision": 0.10828546832144316,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.3984375,
        "f1": 0.3265482868179904,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.3265482868179904,
        "precision": 0.3059211466384437,
        "recall": 0.3984375
      },
      {
        "accuracy": 0.568359375,
        "f1": 0.4952048949314574,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.4952048949314574,
        "precision": 0.4712819442812761,
        "recall": 0.568359375
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.5544855353362936,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.5544855353362936,
        "precision": 0.530918472532242,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00028116650950809366,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.00028116650950809366,
        "precision": 0.00016383592602790015,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.5838511892136662,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.5838511892136662,
        "precision": 0.5589302730147457,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.363778034830666e-05,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 3.363778034830666e-05,
        "precision": 1.7070687118570183e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.4873046875,
        "f1": 0.41226075636672915,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.41226075636672915,
        "precision": 0.38797168814258653,
        "recall": 0.4873046875
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.1517413111462172,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.1517413111462172,
        "precision": 0.1410322436743941,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.706513554216867e-05,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 6.706513554216867e-05,
        "precision": 3.465603881476347e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.1262538403183754,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.1262538403183754,
        "precision": 0.11627749411672324,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.703125,
        "f1": 0.6479167371257215,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.6479167371257215,
        "precision": 0.6279428949063599,
        "recall": 0.703125
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5594655615651709,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.5594655615651709,
        "precision": 0.5382541584934163,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.2734375,
        "f1": 0.20743806092532563,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.20743806092532563,
        "precision": 0.19069043481326092,
        "recall": 0.2734375
      },
      {
        "accuracy": 0.5751953125,
        "f1": 0.5145158107855989,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.5145158107855989,
        "precision": 0.4946780677005287,
        "recall": 0.5751953125
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.04648554399561106,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.04648554399561106,
        "precision": 0.04146955874239647,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.326171875,
        "f1": 0.258771453807719,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.258771453807719,
        "precision": 0.24146141586435688,
        "recall": 0.326171875
      },
      {
        "accuracy": 0.6181640625,
        "f1": 0.5587333356046017,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.5587333356046017,
        "precision": 0.5388765286501591,
        "recall": 0.6181640625
      },
      {
        "accuracy": 0.3271484375,
        "f1": 0.26213233744198966,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.26213233744198966,
        "precision": 0.24530874510130962,
        "recall": 0.3271484375
      },
      {
        "accuracy": 0.5224609375,
        "f1": 0.45721118899918456,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.45721118899918456,
        "precision": 0.43757812087716363,
        "recall": 0.5224609375
      },
      {
        "accuracy": 0.7333984375,
        "f1": 0.6805578807043651,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.6805578807043651,
        "precision": 0.6615048363095238,
        "recall": 0.7333984375
      },
      {
        "accuracy": 0.7265625,
        "f1": 0.681093461659868,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.681093461659868,
        "precision": 0.6659059554811508,
        "recall": 0.7265625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.11348126905061223,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.11348126905061223,
        "precision": 0.1024102585849081,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.39890903997905225,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.39890903997905225,
        "precision": 0.37501748960617687,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.6240234375,
        "f1": 0.5650858744120463,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.5650858744120463,
        "precision": 0.5451770611180078,
        "recall": 0.6240234375
      },
      {
        "accuracy": 0.65625,
        "f1": 0.6039763919890873,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.6039763919890873,
        "precision": 0.5851148200757575,
        "recall": 0.65625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.170138888888889e-06,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 2.170138888888889e-06,
        "precision": 1.0862764182424916e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.6037454976663962,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.6037454976663962,
        "precision": 0.5792767237103174,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012773779827895682,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.0012773779827895682,
        "precision": 0.0011502958023983923,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.4921875,
        "f1": 0.4269706484219926,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.4269706484219926,
        "precision": 0.40617463359952444,
        "recall": 0.4921875
      },
      {
        "accuracy": 0.2734375,
        "f1": 0.20330024046620587,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.20330024046620587,
        "precision": 0.18472204202986328,
        "recall": 0.2734375
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.9580200501253132e-05,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 1.9580200501253132e-05,
        "precision": 9.869827978362555e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.18362018460355187,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.18362018460355187,
        "precision": 0.16982584369045034,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.6159020629749454,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.6159020629749454,
        "precision": 0.5961827474448483,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.6083984375,
        "f1": 0.547531790296611,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.547531790296611,
        "precision": 0.5256877083515697,
        "recall": 0.6083984375
      },
      {
        "accuracy": 0.2822265625,
        "f1": 0.20811551338547393,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.20811551338547393,
        "precision": 0.18868196231110893,
        "recall": 0.2822265625
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.6037503457913613,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.6037503457913613,
        "precision": 0.5788585844494047,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.03873909486350162,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.03873909486350162,
        "precision": 0.03379879805707856,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.4072265625,
        "f1": 0.3389766919820631,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.3389766919820631,
        "precision": 0.31716749562780466,
        "recall": 0.4072265625
      },
      {
        "accuracy": 0.7998046875,
        "f1": 0.7566460503472222,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7566460503472222,
        "precision": 0.7407610212053571,
        "recall": 0.7998046875
      },
      {
        "accuracy": 0.27734375,
        "f1": 0.22206460474603978,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.22206460474603978,
        "precision": 0.2059351220299776,
        "recall": 0.27734375
      },
      {
        "accuracy": 0.630859375,
        "f1": 0.5679949497271841,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5679949497271841,
        "precision": 0.5469321002890339,
        "recall": 0.630859375
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.794189453125,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.794189453125,
        "precision": 0.7765989273313492,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.5791015625,
        "f1": 0.5083242015528895,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.5083242015528895,
        "precision": 0.4844980147348311,
        "recall": 0.5791015625
      },
      {
        "accuracy": 0.4501953125,
        "f1": 0.3697723382612212,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.3697723382612212,
        "precision": 0.3460752399918301,
        "recall": 0.4501953125
      },
      {
        "accuracy": 0.5048828125,
        "f1": 0.4368659664775706,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.4368659664775706,
        "precision": 0.4158573672316427,
        "recall": 0.5048828125
      },
      {
        "accuracy": 0.583984375,
        "f1": 0.5140137423340547,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.5140137423340547,
        "precision": 0.48957284577401766,
        "recall": 0.583984375
      },
      {
        "accuracy": 0.6630859375,
        "f1": 0.5983387831558062,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.5983387831558062,
        "precision": 0.574282691592262,
        "recall": 0.6630859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.723079691734417e-05,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 5.723079691734417e-05,
        "precision": 2.939272082878953e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.7255859375,
        "f1": 0.666242784992785,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.666242784992785,
        "precision": 0.6437852647569444,
        "recall": 0.7255859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00019455984131818408,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.00019455984131818408,
        "precision": 0.00010095678108004695,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.6611328125,
        "f1": 0.6001324142437424,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.6001324142437424,
        "precision": 0.5773495628720238,
        "recall": 0.6611328125
      },
      {
        "accuracy": 0.2802734375,
        "f1": 0.2209762482220676,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.2209762482220676,
        "precision": 0.20588504371337074,
        "recall": 0.2802734375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004975952796217756,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0004975952796217756,
        "precision": 0.0003301900865551884,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.25,
        "f1": 0.18826812240262875,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.18826812240262875,
        "precision": 0.1734082360102987,
        "recall": 0.25
      },
      {
        "accuracy": 0.67578125,
        "f1": 0.6100349547371031,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.6100349547371031,
        "precision": 0.5858014787946428,
        "recall": 0.67578125
      },
      {
        "accuracy": 0.64453125,
        "f1": 0.5780851554044913,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.5780851554044913,
        "precision": 0.5542039042771465,
        "recall": 0.64453125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}