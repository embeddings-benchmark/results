{
  "dataset_revision": "c54a95d9b9d62c891a03bd5da60715df7176b097",
  "evaluation_time": 57.05410933494568,
  "kg_co2_emissions": 0.0024617538854544343,
  "mteb_version": "1.16.5",
  "scores": {
    "test": [
      {
        "accuracy": 0.9212670129528568,
        "f1": 0.91625519627598,
        "f1_weighted": 0.9208259295820603,
        "hf_subset": "default",
        "languages": [
          "asm-Beng",
          "brx-Deva",
          "ben-Beng",
          "doi-Deva",
          "gom-Deva",
          "guj-Gujr",
          "hin-Deva",
          "kan-Knda",
          "kas-Arab",
          "kas-Deva",
          "mai-Deva",
          "mal-Mlym",
          "mar-Deva",
          "mni-Beng",
          "mni-Mtei",
          "npi-Deva",
          "ory-Orya",
          "pan-Guru",
          "san-Deva",
          "sat-Olck",
          "snd-Arab",
          "tam-Taml",
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.9212670129528568,
        "scores_per_experiment": [
          {
            "accuracy": 0.9193569596949175,
            "f1": 0.9148684411875895,
            "f1_weighted": 0.9199368515416823
          },
          {
            "accuracy": 0.9186665789992767,
            "f1": 0.9132552724829607,
            "f1_weighted": 0.9179231895242878
          },
          {
            "accuracy": 0.9221184824774804,
            "f1": 0.9163900821766661,
            "f1_weighted": 0.9218872087369416
          },
          {
            "accuracy": 0.9122559011111842,
            "f1": 0.9079110957947665,
            "f1_weighted": 0.9112692014962789
          },
          {
            "accuracy": 0.9290551647051088,
            "f1": 0.924639855631874,
            "f1_weighted": 0.9293648164851989
          },
          {
            "accuracy": 0.9324413176408706,
            "f1": 0.9275399405579183,
            "f1_weighted": 0.9321634051118606
          },
          {
            "accuracy": 0.9188967058978237,
            "f1": 0.9126117649108103,
            "f1_weighted": 0.9186313561896111
          },
          {
            "accuracy": 0.9230718653428891,
            "f1": 0.9191282583155955,
            "f1_weighted": 0.9223300517922635
          },
          {
            "accuracy": 0.9236636202248668,
            "f1": 0.9180463333912204,
            "f1_weighted": 0.922542833799993
          },
          {
            "accuracy": 0.9131435334341508,
            "f1": 0.908160918310399,
            "f1_weighted": 0.9122103811424864
          }
        ]
      }
    ]
  },
  "task_name": "IndicLangClassification"
}