{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "task_name": "MTOPIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.255537,
        "f1": 0.157516,
        "f1_weighted": 0.30356,
        "scores_per_experiment": [
          {
            "accuracy": 0.250689,
            "f1": 0.152513,
            "f1_weighted": 0.29401
          },
          {
            "accuracy": 0.270523,
            "f1": 0.154503,
            "f1_weighted": 0.312392
          },
          {
            "accuracy": 0.300275,
            "f1": 0.176514,
            "f1_weighted": 0.353864
          },
          {
            "accuracy": 0.234711,
            "f1": 0.15258,
            "f1_weighted": 0.279961
          },
          {
            "accuracy": 0.225895,
            "f1": 0.138536,
            "f1_weighted": 0.274981
          },
          {
            "accuracy": 0.254545,
            "f1": 0.155695,
            "f1_weighted": 0.301082
          },
          {
            "accuracy": 0.252342,
            "f1": 0.159031,
            "f1_weighted": 0.303535
          },
          {
            "accuracy": 0.27989,
            "f1": 0.163354,
            "f1_weighted": 0.334749
          },
          {
            "accuracy": 0.224242,
            "f1": 0.156201,
            "f1_weighted": 0.270562
          },
          {
            "accuracy": 0.262259,
            "f1": 0.166228,
            "f1_weighted": 0.310463
          }
        ],
        "main_score": 0.255537,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.264807,
        "f1": 0.191945,
        "f1_weighted": 0.31561,
        "scores_per_experiment": [
          {
            "accuracy": 0.261764,
            "f1": 0.188622,
            "f1_weighted": 0.307666
          },
          {
            "accuracy": 0.266554,
            "f1": 0.192796,
            "f1_weighted": 0.314571
          },
          {
            "accuracy": 0.288814,
            "f1": 0.190026,
            "f1_weighted": 0.343204
          },
          {
            "accuracy": 0.240068,
            "f1": 0.184547,
            "f1_weighted": 0.287081
          },
          {
            "accuracy": 0.247394,
            "f1": 0.182461,
            "f1_weighted": 0.298364
          },
          {
            "accuracy": 0.270499,
            "f1": 0.1885,
            "f1_weighted": 0.317211
          },
          {
            "accuracy": 0.255001,
            "f1": 0.187415,
            "f1_weighted": 0.307853
          },
          {
            "accuracy": 0.295013,
            "f1": 0.204889,
            "f1_weighted": 0.351694
          },
          {
            "accuracy": 0.244576,
            "f1": 0.19512,
            "f1_weighted": 0.296881
          },
          {
            "accuracy": 0.278388,
            "f1": 0.20507,
            "f1_weighted": 0.331573
          }
        ],
        "main_score": 0.264807,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 53.45886731147766,
  "kg_co2_emissions": null
}