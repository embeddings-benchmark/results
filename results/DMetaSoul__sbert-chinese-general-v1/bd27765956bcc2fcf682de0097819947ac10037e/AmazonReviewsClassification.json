{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "task_name": "AmazonReviewsClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.25518,
        "f1": 0.255254,
        "f1_weighted": 0.255254,
        "scores_per_experiment": [
          {
            "accuracy": 0.2578,
            "f1": 0.26009,
            "f1_weighted": 0.26009
          },
          {
            "accuracy": 0.2518,
            "f1": 0.2518,
            "f1_weighted": 0.2518
          },
          {
            "accuracy": 0.2554,
            "f1": 0.25471,
            "f1_weighted": 0.25471
          },
          {
            "accuracy": 0.244,
            "f1": 0.243356,
            "f1_weighted": 0.243356
          },
          {
            "accuracy": 0.254,
            "f1": 0.255377,
            "f1_weighted": 0.255377
          },
          {
            "accuracy": 0.267,
            "f1": 0.269483,
            "f1_weighted": 0.269483
          },
          {
            "accuracy": 0.2432,
            "f1": 0.241026,
            "f1_weighted": 0.241026
          },
          {
            "accuracy": 0.287,
            "f1": 0.286792,
            "f1_weighted": 0.286792
          },
          {
            "accuracy": 0.2392,
            "f1": 0.239011,
            "f1_weighted": 0.239011
          },
          {
            "accuracy": 0.2524,
            "f1": 0.250898,
            "f1_weighted": 0.250898
          }
        ],
        "main_score": 0.25518,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.253,
        "f1": 0.252632,
        "f1_weighted": 0.252632,
        "scores_per_experiment": [
          {
            "accuracy": 0.2722,
            "f1": 0.275169,
            "f1_weighted": 0.275169
          },
          {
            "accuracy": 0.2506,
            "f1": 0.250005,
            "f1_weighted": 0.250005
          },
          {
            "accuracy": 0.2534,
            "f1": 0.252572,
            "f1_weighted": 0.252572
          },
          {
            "accuracy": 0.2428,
            "f1": 0.241734,
            "f1_weighted": 0.241734
          },
          {
            "accuracy": 0.2578,
            "f1": 0.258156,
            "f1_weighted": 0.258156
          },
          {
            "accuracy": 0.2482,
            "f1": 0.249167,
            "f1_weighted": 0.249167
          },
          {
            "accuracy": 0.2394,
            "f1": 0.237149,
            "f1_weighted": 0.237149
          },
          {
            "accuracy": 0.278,
            "f1": 0.276795,
            "f1_weighted": 0.276795
          },
          {
            "accuracy": 0.2356,
            "f1": 0.235522,
            "f1_weighted": 0.235522
          },
          {
            "accuracy": 0.252,
            "f1": 0.250049,
            "f1_weighted": 0.250049
          }
        ],
        "main_score": 0.253,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 76.56843090057373,
  "kg_co2_emissions": null
}