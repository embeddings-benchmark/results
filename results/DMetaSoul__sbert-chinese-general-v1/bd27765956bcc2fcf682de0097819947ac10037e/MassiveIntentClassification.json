{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "task_name": "MassiveIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.371471,
        "f1": 0.35509,
        "f1_weighted": 0.375487,
        "scores_per_experiment": [
          {
            "accuracy": 0.372356,
            "f1": 0.352049,
            "f1_weighted": 0.378269
          },
          {
            "accuracy": 0.376783,
            "f1": 0.363377,
            "f1_weighted": 0.382346
          },
          {
            "accuracy": 0.366454,
            "f1": 0.350021,
            "f1_weighted": 0.373187
          },
          {
            "accuracy": 0.386129,
            "f1": 0.358196,
            "f1_weighted": 0.39233
          },
          {
            "accuracy": 0.390556,
            "f1": 0.363869,
            "f1_weighted": 0.395434
          },
          {
            "accuracy": 0.380718,
            "f1": 0.361624,
            "f1_weighted": 0.381997
          },
          {
            "accuracy": 0.377767,
            "f1": 0.377132,
            "f1_weighted": 0.379172
          },
          {
            "accuracy": 0.354156,
            "f1": 0.345912,
            "f1_weighted": 0.352605
          },
          {
            "accuracy": 0.349238,
            "f1": 0.335816,
            "f1_weighted": 0.356398
          },
          {
            "accuracy": 0.360551,
            "f1": 0.3429,
            "f1_weighted": 0.36313
          }
        ],
        "main_score": 0.371471,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.37384,
        "f1": 0.347402,
        "f1_weighted": 0.379639,
        "scores_per_experiment": [
          {
            "accuracy": 0.376261,
            "f1": 0.351632,
            "f1_weighted": 0.385367
          },
          {
            "accuracy": 0.376261,
            "f1": 0.35046,
            "f1_weighted": 0.380203
          },
          {
            "accuracy": 0.373907,
            "f1": 0.346716,
            "f1_weighted": 0.380211
          },
          {
            "accuracy": 0.377942,
            "f1": 0.344474,
            "f1_weighted": 0.388248
          },
          {
            "accuracy": 0.381305,
            "f1": 0.350413,
            "f1_weighted": 0.379874
          },
          {
            "accuracy": 0.372226,
            "f1": 0.35231,
            "f1_weighted": 0.382779
          },
          {
            "accuracy": 0.366174,
            "f1": 0.338396,
            "f1_weighted": 0.372231
          },
          {
            "accuracy": 0.368863,
            "f1": 0.342185,
            "f1_weighted": 0.372057
          },
          {
            "accuracy": 0.36651,
            "f1": 0.339098,
            "f1_weighted": 0.373814
          },
          {
            "accuracy": 0.378951,
            "f1": 0.358337,
            "f1_weighted": 0.381601
          }
        ],
        "main_score": 0.37384,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 33.8385546207428,
  "kg_co2_emissions": null
}