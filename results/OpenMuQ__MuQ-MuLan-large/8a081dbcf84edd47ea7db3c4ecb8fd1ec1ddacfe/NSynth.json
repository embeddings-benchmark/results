{
  "dataset_revision": "e32dfe9b65e121e64229a821fe1ff177e8962635",
  "task_name": "NSynth",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.550633,
            "f1": 0.545008,
            "f1_weighted": 0.553707,
            "precision": 0.548737,
            "precision_weighted": 0.565576,
            "recall": 0.549192,
            "recall_weighted": 0.550633,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.497668,
            "f1": 0.493763,
            "f1_weighted": 0.510235,
            "precision": 0.563157,
            "precision_weighted": 0.60896,
            "recall": 0.497725,
            "recall_weighted": 0.497668,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.500999,
            "f1": 0.490703,
            "f1_weighted": 0.503772,
            "precision": 0.497256,
            "precision_weighted": 0.516761,
            "recall": 0.496041,
            "recall_weighted": 0.500999,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.496003,
            "f1": 0.473259,
            "f1_weighted": 0.493237,
            "precision": 0.475018,
            "precision_weighted": 0.491636,
            "recall": 0.472846,
            "recall_weighted": 0.496003,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.546636,
            "f1": 0.519316,
            "f1_weighted": 0.545669,
            "precision": 0.530455,
            "precision_weighted": 0.556533,
            "recall": 0.520379,
            "recall_weighted": 0.546636,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.584277,
            "f1": 0.565953,
            "f1_weighted": 0.585024,
            "precision": 0.566046,
            "precision_weighted": 0.585854,
            "recall": 0.565959,
            "recall_weighted": 0.584277,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.46469,
            "f1": 0.46328,
            "f1_weighted": 0.455385,
            "precision": 0.515956,
            "precision_weighted": 0.52997,
            "recall": 0.482479,
            "recall_weighted": 0.46469,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.551632,
            "f1": 0.551032,
            "f1_weighted": 0.560098,
            "precision": 0.585879,
            "precision_weighted": 0.61743,
            "recall": 0.567262,
            "recall_weighted": 0.551632,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.574617,
            "f1": 0.563559,
            "f1_weighted": 0.575473,
            "precision": 0.562892,
            "precision_weighted": 0.577091,
            "recall": 0.565138,
            "recall_weighted": 0.574617,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.529647,
            "f1": 0.510985,
            "f1_weighted": 0.533755,
            "precision": 0.513657,
            "precision_weighted": 0.540519,
            "recall": 0.510673,
            "recall_weighted": 0.529647,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.52968,
        "f1": 0.517686,
        "f1_weighted": 0.531636,
        "precision": 0.535905,
        "precision_weighted": 0.559033,
        "recall": 0.522769,
        "recall_weighted": 0.52968,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.52968,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 366.3434829711914,
  "kg_co2_emissions": null
}