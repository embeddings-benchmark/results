{
  "dataset_revision": "3ac713aa0829eeadda73182f38bbbd788d21254b",
  "task_name": "SpeechCommands",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.097955,
            "f1": 0.041515,
            "f1_weighted": 0.10207,
            "precision": 0.056786,
            "precision_weighted": 0.158278,
            "recall": 0.100684,
            "recall_weighted": 0.097955,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.133742,
            "f1": 0.05833,
            "f1_weighted": 0.13402,
            "precision": 0.078376,
            "precision_weighted": 0.200517,
            "recall": 0.113065,
            "recall_weighted": 0.133742,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.127403,
            "f1": 0.048342,
            "f1_weighted": 0.126413,
            "precision": 0.069495,
            "precision_weighted": 0.197658,
            "recall": 0.099658,
            "recall_weighted": 0.127403,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.128834,
            "f1": 0.063701,
            "f1_weighted": 0.137368,
            "precision": 0.115198,
            "precision_weighted": 0.27662,
            "recall": 0.119261,
            "recall_weighted": 0.128834,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.113497,
            "f1": 0.051632,
            "f1_weighted": 0.119412,
            "precision": 0.111479,
            "precision_weighted": 0.311193,
            "recall": 0.120939,
            "recall_weighted": 0.113497,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.096933,
            "f1": 0.052652,
            "f1_weighted": 0.107871,
            "precision": 0.093605,
            "precision_weighted": 0.232842,
            "recall": 0.101836,
            "recall_weighted": 0.096933,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.104499,
            "f1": 0.05459,
            "f1_weighted": 0.105933,
            "precision": 0.075375,
            "precision_weighted": 0.189512,
            "recall": 0.125975,
            "recall_weighted": 0.104499,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.091002,
            "f1": 0.034028,
            "f1_weighted": 0.088513,
            "precision": 0.037974,
            "precision_weighted": 0.106294,
            "recall": 0.097858,
            "recall_weighted": 0.091002,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.106135,
            "f1": 0.046027,
            "f1_weighted": 0.111834,
            "precision": 0.095685,
            "precision_weighted": 0.273322,
            "recall": 0.112487,
            "recall_weighted": 0.106135,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.109816,
            "f1": 0.044168,
            "f1_weighted": 0.119204,
            "precision": 0.073244,
            "precision_weighted": 0.213859,
            "recall": 0.097709,
            "recall_weighted": 0.109816,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.110982,
        "f1": 0.049498,
        "f1_weighted": 0.115264,
        "precision": 0.080722,
        "precision_weighted": 0.216009,
        "recall": 0.108947,
        "recall_weighted": 0.110982,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.110982,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 181.20018005371094,
  "kg_co2_emissions": null
}