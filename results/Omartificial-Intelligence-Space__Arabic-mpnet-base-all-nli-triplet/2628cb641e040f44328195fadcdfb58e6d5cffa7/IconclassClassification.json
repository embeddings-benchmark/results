{
  "dataset_revision": "1cd02f1579dab39fedc95de8cc15fd620557a9f2",
  "task_name": "IconclassClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.316832,
            "f1": 0.30981,
            "f1_weighted": 0.310755,
            "precision": 0.319071,
            "precision_weighted": 0.320587,
            "recall": 0.316206,
            "recall_weighted": 0.316832,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.361386,
            "f1": 0.352118,
            "f1_weighted": 0.353129,
            "precision": 0.349163,
            "precision_weighted": 0.349885,
            "recall": 0.360123,
            "recall_weighted": 0.361386,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.371287,
            "f1": 0.367964,
            "f1_weighted": 0.36878,
            "precision": 0.367866,
            "precision_weighted": 0.3689,
            "recall": 0.370663,
            "recall_weighted": 0.371287,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.341584,
            "f1": 0.333446,
            "f1_weighted": 0.335278,
            "precision": 0.342297,
            "precision_weighted": 0.344366,
            "recall": 0.339701,
            "recall_weighted": 0.341584,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.351485,
            "f1": 0.346969,
            "f1_weighted": 0.347799,
            "precision": 0.35134,
            "precision_weighted": 0.351869,
            "recall": 0.350461,
            "recall_weighted": 0.351485,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.306931,
            "f1": 0.296794,
            "f1_weighted": 0.297556,
            "precision": 0.303538,
            "precision_weighted": 0.304333,
            "recall": 0.306105,
            "recall_weighted": 0.306931,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.371287,
            "f1": 0.361607,
            "f1_weighted": 0.362414,
            "precision": 0.36849,
            "precision_weighted": 0.368373,
            "recall": 0.369565,
            "recall_weighted": 0.371287,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.331683,
            "f1": 0.319903,
            "f1_weighted": 0.319993,
            "precision": 0.321714,
            "precision_weighted": 0.321641,
            "recall": 0.331137,
            "recall_weighted": 0.331683,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.356436,
            "f1": 0.348784,
            "f1_weighted": 0.349968,
            "precision": 0.35168,
            "precision_weighted": 0.352629,
            "recall": 0.355072,
            "recall_weighted": 0.356436,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.341584,
            "f1": 0.32757,
            "f1_weighted": 0.328871,
            "precision": 0.331243,
            "precision_weighted": 0.332036,
            "recall": 0.339701,
            "recall_weighted": 0.341584,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.34505,
        "f1": 0.336496,
        "f1_weighted": 0.337454,
        "precision": 0.34064,
        "precision_weighted": 0.341462,
        "recall": 0.343874,
        "recall_weighted": 0.34505,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.336496,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.132243156433105,
  "kg_co2_emissions": null
}