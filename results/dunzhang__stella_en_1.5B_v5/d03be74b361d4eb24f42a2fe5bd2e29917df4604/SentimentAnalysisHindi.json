{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 31.413410425186157,
  "kg_co2_emissions": 0.00226309672342562,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.514013671875,
        "f1": 0.5002558031630425,
        "f1_weighted": 0.522959282905159,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.5002558031630425,
        "scores_per_experiment": [
          {
            "accuracy": 0.5458984375,
            "f1": 0.5326274413853259,
            "f1_weighted": 0.5551055926300777
          },
          {
            "accuracy": 0.52734375,
            "f1": 0.5070680113191083,
            "f1_weighted": 0.5492734997514445
          },
          {
            "accuracy": 0.5361328125,
            "f1": 0.5103651449802857,
            "f1_weighted": 0.5389224036403739
          },
          {
            "accuracy": 0.46630859375,
            "f1": 0.45846961832824423,
            "f1_weighted": 0.47112188756359685
          },
          {
            "accuracy": 0.53369140625,
            "f1": 0.5159131161699354,
            "f1_weighted": 0.5426922714227478
          },
          {
            "accuracy": 0.46435546875,
            "f1": 0.45160158460667804,
            "f1_weighted": 0.47400793519206275
          },
          {
            "accuracy": 0.5517578125,
            "f1": 0.5422482556355958,
            "f1_weighted": 0.5575372571979136
          },
          {
            "accuracy": 0.52490234375,
            "f1": 0.5074882364656074,
            "f1_weighted": 0.5311070548974575
          },
          {
            "accuracy": 0.4248046875,
            "f1": 0.42349694696973117,
            "f1_weighted": 0.4419617689909823
          },
          {
            "accuracy": 0.56494140625,
            "f1": 0.5532796757699123,
            "f1_weighted": 0.5678631577649338
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}