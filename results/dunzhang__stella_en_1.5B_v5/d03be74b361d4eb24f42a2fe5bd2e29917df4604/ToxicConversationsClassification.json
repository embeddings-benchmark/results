{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 35.23225116729736,
  "kg_co2_emissions": 0.0026593194060499322,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.867626953125,
        "ap": 0.3209286351697977,
        "ap_weighted": 0.3209286351697977,
        "f1": 0.7156384263173008,
        "f1_weighted": 0.8904994147341864,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.867626953125,
        "scores_per_experiment": [
          {
            "accuracy": 0.888671875,
            "ap": 0.35793230624641115,
            "ap_weighted": 0.35793230624641115,
            "f1": 0.7429486826604423,
            "f1_weighted": 0.9058713698156936
          },
          {
            "accuracy": 0.8544921875,
            "ap": 0.30839676332755545,
            "ap_weighted": 0.30839676332755545,
            "f1": 0.7024370455892908,
            "f1_weighted": 0.8814965159814101
          },
          {
            "accuracy": 0.8505859375,
            "ap": 0.26724494022000433,
            "ap_weighted": 0.26724494022000433,
            "f1": 0.6835164835164835,
            "f1_weighted": 0.8770835121909341
          },
          {
            "accuracy": 0.89306640625,
            "ap": 0.35722029099770647,
            "ap_weighted": 0.35722029099770647,
            "f1": 0.7457159817056473,
            "f1_weighted": 0.9086615441908712
          },
          {
            "accuracy": 0.90673828125,
            "ap": 0.37916454955904505,
            "ap_weighted": 0.37916454955904505,
            "f1": 0.7629685647093613,
            "f1_weighted": 0.918366051427895
          },
          {
            "accuracy": 0.8349609375,
            "ap": 0.2824989780827455,
            "ap_weighted": 0.2824989780827455,
            "f1": 0.6804915514592934,
            "f1_weighted": 0.8675036452332949
          },
          {
            "accuracy": 0.8798828125,
            "ap": 0.3309802039194915,
            "ap_weighted": 0.3309802039194915,
            "f1": 0.7272703650773029,
            "f1_weighted": 0.8990091766678576
          },
          {
            "accuracy": 0.82958984375,
            "ap": 0.2867735700946374,
            "ap_weighted": 0.2867735700946374,
            "f1": 0.6788923107334353,
            "f1_weighted": 0.864068751874246
          },
          {
            "accuracy": 0.845703125,
            "ap": 0.28290335062233185,
            "ap_weighted": 0.28290335062233185,
            "f1": 0.6871377880050664,
            "f1_weighted": 0.8746320547946861
          },
          {
            "accuracy": 0.892578125,
            "ap": 0.35617139862804875,
            "ap_weighted": 0.35617139862804875,
            "f1": 0.7450054897166853,
            "f1_weighted": 0.9083015251649745
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}