{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "evaluation_time": 2654.506878376007,
  "kg_co2_emissions": 0.21845467878529515,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.1880859375,
        "f1": 0.1455612825801814,
        "f1_weighted": 0.17356626185243718,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.1880859375,
        "scores_per_experiment": [
          {
            "accuracy": 0.19091796875,
            "f1": 0.14889719690400255,
            "f1_weighted": 0.1826264415200644
          },
          {
            "accuracy": 0.1943359375,
            "f1": 0.15376187536823627,
            "f1_weighted": 0.17754619773277347
          },
          {
            "accuracy": 0.1875,
            "f1": 0.14221978119035172,
            "f1_weighted": 0.173302961586705
          },
          {
            "accuracy": 0.19287109375,
            "f1": 0.1456081255756492,
            "f1_weighted": 0.174006253408253
          },
          {
            "accuracy": 0.1845703125,
            "f1": 0.14977709357428473,
            "f1_weighted": 0.17162952696165523
          },
          {
            "accuracy": 0.19921875,
            "f1": 0.1527969954965975,
            "f1_weighted": 0.18947444563254748
          },
          {
            "accuracy": 0.19287109375,
            "f1": 0.15045627827326286,
            "f1_weighted": 0.17748818745783101
          },
          {
            "accuracy": 0.18115234375,
            "f1": 0.14001484171858516,
            "f1_weighted": 0.16205084188863048
          },
          {
            "accuracy": 0.17822265625,
            "f1": 0.1300576780897245,
            "f1_weighted": 0.16394902467582237
          },
          {
            "accuracy": 0.17919921875,
            "f1": 0.14202295961111952,
            "f1_weighted": 0.1635887376600894
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.20263671875,
        "f1": 0.15253225560137929,
        "f1_weighted": 0.18610220040483608,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.20263671875,
        "scores_per_experiment": [
          {
            "accuracy": 0.203125,
            "f1": 0.1518213535611117,
            "f1_weighted": 0.1916486450008277
          },
          {
            "accuracy": 0.20166015625,
            "f1": 0.1599256965980409,
            "f1_weighted": 0.18255088328511115
          },
          {
            "accuracy": 0.18994140625,
            "f1": 0.1437411785636674,
            "f1_weighted": 0.17660728477661597
          },
          {
            "accuracy": 0.19287109375,
            "f1": 0.13698409176288429,
            "f1_weighted": 0.1706102395879991
          },
          {
            "accuracy": 0.20849609375,
            "f1": 0.15470668215833858,
            "f1_weighted": 0.19710030198237474
          },
          {
            "accuracy": 0.201171875,
            "f1": 0.15525366796718554,
            "f1_weighted": 0.18826590923520092
          },
          {
            "accuracy": 0.2138671875,
            "f1": 0.15383324038613277,
            "f1_weighted": 0.19301104379190623
          },
          {
            "accuracy": 0.1953125,
            "f1": 0.14150666587228516,
            "f1_weighted": 0.1699038405138654
          },
          {
            "accuracy": 0.22314453125,
            "f1": 0.16951526762387512,
            "f1_weighted": 0.20755028087202004
          },
          {
            "accuracy": 0.19677734375,
            "f1": 0.15803471152027135,
            "f1_weighted": 0.1837735750024396
          }
        ]
      }
    ]
  },
  "task_name": "GreekLegalCodeClassification"
}