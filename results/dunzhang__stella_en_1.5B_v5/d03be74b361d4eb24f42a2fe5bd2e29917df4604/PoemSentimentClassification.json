{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 15.726895093917847,
  "kg_co2_emissions": 0.0005510260787861751,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5971153846153846,
        "f1": 0.46614686774254127,
        "f1_weighted": 0.6530492177270169,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5971153846153846,
        "scores_per_experiment": [
          {
            "accuracy": 0.5769230769230769,
            "f1": 0.45378317334839074,
            "f1_weighted": 0.6514159753290188
          },
          {
            "accuracy": 0.5673076923076923,
            "f1": 0.4623384632635327,
            "f1_weighted": 0.6166962085093446
          },
          {
            "accuracy": 0.625,
            "f1": 0.4917471042471042,
            "f1_weighted": 0.6813261063261064
          },
          {
            "accuracy": 0.6153846153846154,
            "f1": 0.4743856837606838,
            "f1_weighted": 0.6838264299802762
          },
          {
            "accuracy": 0.6153846153846154,
            "f1": 0.43951612903225806,
            "f1_weighted": 0.666408188585608
          },
          {
            "accuracy": 0.6730769230769231,
            "f1": 0.5129240412979351,
            "f1_weighted": 0.7189939301111867
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.42709534368070956,
            "f1_weighted": 0.5604997441582807
          },
          {
            "accuracy": 0.6346153846153846,
            "f1": 0.463927815970386,
            "f1_weighted": 0.6885441667005654
          },
          {
            "accuracy": 0.5673076923076923,
            "f1": 0.4438511976448548,
            "f1_weighted": 0.5992439448681921
          },
          {
            "accuracy": 0.5865384615384616,
            "f1": 0.49189972517955705,
            "f1_weighted": 0.6635374827015897
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6019047619047619,
        "f1": 0.4566419137064955,
        "f1_weighted": 0.654942390317005,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6019047619047619,
        "scores_per_experiment": [
          {
            "accuracy": 0.5904761904761905,
            "f1": 0.45945945945945943,
            "f1_weighted": 0.6493350493350493
          },
          {
            "accuracy": 0.580952380952381,
            "f1": 0.4769895984518626,
            "f1_weighted": 0.6388220793881171
          },
          {
            "accuracy": 0.6190476190476191,
            "f1": 0.47327694235588974,
            "f1_weighted": 0.675108008115527
          },
          {
            "accuracy": 0.6,
            "f1": 0.44809758896446206,
            "f1_weighted": 0.6604549074252746
          },
          {
            "accuracy": 0.5904761904761905,
            "f1": 0.4332147376719291,
            "f1_weighted": 0.6344519161522252
          },
          {
            "accuracy": 0.5904761904761905,
            "f1": 0.4313656180040061,
            "f1_weighted": 0.6350238740482642
          },
          {
            "accuracy": 0.638095238095238,
            "f1": 0.5189393939393939,
            "f1_weighted": 0.7005772005772006
          },
          {
            "accuracy": 0.6666666666666666,
            "f1": 0.4797619047619047,
            "f1_weighted": 0.701360544217687
          },
          {
            "accuracy": 0.5333333333333333,
            "f1": 0.37611788617886177,
            "f1_weighted": 0.5830313588850174
          },
          {
            "accuracy": 0.6095238095238096,
            "f1": 0.4691960072771849,
            "f1_weighted": 0.6712589650256865
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}