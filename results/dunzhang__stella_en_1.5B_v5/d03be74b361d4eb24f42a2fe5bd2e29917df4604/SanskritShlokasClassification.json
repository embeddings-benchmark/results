{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.765535,
        "f1": 0.760022,
        "f1_weighted": 0.759678,
        "scores_per_experiment": [
          {
            "accuracy": 0.754569,
            "f1": 0.754318,
            "f1_weighted": 0.753951
          },
          {
            "accuracy": 0.738903,
            "f1": 0.731833,
            "f1_weighted": 0.730509
          },
          {
            "accuracy": 0.73107,
            "f1": 0.725208,
            "f1_weighted": 0.72462
          },
          {
            "accuracy": 0.684073,
            "f1": 0.660606,
            "f1_weighted": 0.656321
          },
          {
            "accuracy": 0.788512,
            "f1": 0.784949,
            "f1_weighted": 0.783843
          },
          {
            "accuracy": 0.81201,
            "f1": 0.809723,
            "f1_weighted": 0.810707
          },
          {
            "accuracy": 0.806789,
            "f1": 0.805015,
            "f1_weighted": 0.804877
          },
          {
            "accuracy": 0.775457,
            "f1": 0.773242,
            "f1_weighted": 0.773861
          },
          {
            "accuracy": 0.746736,
            "f1": 0.739883,
            "f1_weighted": 0.742373
          },
          {
            "accuracy": 0.817232,
            "f1": 0.815442,
            "f1_weighted": 0.81572
          }
        ],
        "main_score": 0.765535,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7375,
        "f1": 0.74025,
        "f1_weighted": 0.733311,
        "scores_per_experiment": [
          {
            "accuracy": 0.6875,
            "f1": 0.699736,
            "f1_weighted": 0.689728
          },
          {
            "accuracy": 0.739583,
            "f1": 0.74164,
            "f1_weighted": 0.736146
          },
          {
            "accuracy": 0.71875,
            "f1": 0.723933,
            "f1_weighted": 0.716262
          },
          {
            "accuracy": 0.65625,
            "f1": 0.647868,
            "f1_weighted": 0.631208
          },
          {
            "accuracy": 0.78125,
            "f1": 0.784913,
            "f1_weighted": 0.778792
          },
          {
            "accuracy": 0.78125,
            "f1": 0.781607,
            "f1_weighted": 0.77935
          },
          {
            "accuracy": 0.739583,
            "f1": 0.748577,
            "f1_weighted": 0.738313
          },
          {
            "accuracy": 0.78125,
            "f1": 0.782122,
            "f1_weighted": 0.778856
          },
          {
            "accuracy": 0.802083,
            "f1": 0.799512,
            "f1_weighted": 0.798343
          },
          {
            "accuracy": 0.6875,
            "f1": 0.692593,
            "f1_weighted": 0.686111
          }
        ],
        "main_score": 0.7375,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 39.17784023284912,
  "kg_co2_emissions": 0.0016366132881939354
}