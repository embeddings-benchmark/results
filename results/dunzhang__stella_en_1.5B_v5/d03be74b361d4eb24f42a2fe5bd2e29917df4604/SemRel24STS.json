{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 101.40942358970642,
  "kg_co2_emissions": 0.0075341699091629145,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8018748482734416,
        "cosine_spearman": 0.7911939193726168,
        "euclidean_pearson": 0.7798504972516904,
        "euclidean_spearman": 0.7911939193726168,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7911939193726168,
        "manhattan_pearson": 0.7802470480567606,
        "manhattan_spearman": 0.7917023900459759,
        "pearson": 0.8018748482734416,
        "spearman": 0.7911939193726168
      },
      {
        "cosine_pearson": 0.28387291433553663,
        "cosine_spearman": 0.3047126474803184,
        "euclidean_pearson": 0.32830838508195626,
        "euclidean_spearman": 0.3047126474803184,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.3047126474803184,
        "manhattan_pearson": 0.32769778748260453,
        "manhattan_spearman": 0.3035002788612318,
        "pearson": 0.28387291433553663,
        "spearman": 0.3047126474803184
      },
      {
        "cosine_pearson": 0.49109930892470066,
        "cosine_spearman": 0.48197005298053547,
        "euclidean_pearson": 0.487862594029926,
        "euclidean_spearman": 0.48197005298053547,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.48197005298053547,
        "manhattan_pearson": 0.48737907044175516,
        "manhattan_spearman": 0.4811670968580258,
        "pearson": 0.49109930892470066,
        "spearman": 0.48197005298053547
      },
      {
        "cosine_pearson": 0.3519174928371895,
        "cosine_spearman": 0.3011785801942464,
        "euclidean_pearson": 0.37150999009242314,
        "euclidean_spearman": 0.3011785801942464,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.3011785801942464,
        "manhattan_pearson": 0.37152425195426586,
        "manhattan_spearman": 0.3009377650452016,
        "pearson": 0.3519174928371895,
        "spearman": 0.3011785801942464
      },
      {
        "cosine_pearson": 0.2664347714200381,
        "cosine_spearman": 0.22555743387321803,
        "euclidean_pearson": 0.24967229147131415,
        "euclidean_spearman": 0.22555743387321803,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.22555743387321803,
        "manhattan_pearson": 0.25148690840184224,
        "manhattan_spearman": 0.22715822015586318,
        "pearson": 0.2664347714200381,
        "spearman": 0.22555743387321803
      },
      {
        "cosine_pearson": 0.8455521685431799,
        "cosine_spearman": 0.8374012122363811,
        "euclidean_pearson": 0.8390862811904497,
        "euclidean_spearman": 0.8374012122363811,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8374012122363811,
        "manhattan_pearson": 0.8384189979834754,
        "manhattan_spearman": 0.8365095229679411,
        "pearson": 0.8455521685431799,
        "spearman": 0.8374012122363811
      },
      {
        "cosine_pearson": 0.4033934413418754,
        "cosine_spearman": 0.3822731909252489,
        "euclidean_pearson": 0.4179226001027374,
        "euclidean_spearman": 0.3822731909252489,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.3822731909252489,
        "manhattan_pearson": 0.41702593939240273,
        "manhattan_spearman": 0.3805760991160262,
        "pearson": 0.4033934413418754,
        "spearman": 0.3822731909252489
      },
      {
        "cosine_pearson": 0.7253628279789203,
        "cosine_spearman": 0.7230449338358368,
        "euclidean_pearson": 0.7055830165634849,
        "euclidean_spearman": 0.7230449338358368,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7230449338358368,
        "manhattan_pearson": 0.7048689187749463,
        "manhattan_spearman": 0.7210784562966122,
        "pearson": 0.7253628279789203,
        "spearman": 0.7230449338358368
      },
      {
        "cosine_pearson": 0.4655624791460177,
        "cosine_spearman": 0.46931390683370766,
        "euclidean_pearson": 0.4858092638382527,
        "euclidean_spearman": 0.46931390683370766,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.46931390683370766,
        "manhattan_pearson": 0.485342500126372,
        "manhattan_spearman": 0.46920380619989493,
        "pearson": 0.4655624791460177,
        "spearman": 0.46931390683370766
      },
      {
        "cosine_pearson": 0.41891325769921633,
        "cosine_spearman": 0.40984896955454836,
        "euclidean_pearson": 0.4241737864325551,
        "euclidean_spearman": 0.40984896955454836,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.40984896955454836,
        "manhattan_pearson": 0.4261140144131523,
        "manhattan_spearman": 0.4112066995671058,
        "pearson": 0.41891325769921633,
        "spearman": 0.40984896955454836
      },
      {
        "cosine_pearson": 0.7049854820983619,
        "cosine_spearman": 0.6772316286588644,
        "euclidean_pearson": 0.7080396261797658,
        "euclidean_spearman": 0.6772316286588644,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.6772316286588644,
        "manhattan_pearson": 0.7071192380217203,
        "manhattan_spearman": 0.6782447921372184,
        "pearson": 0.7049854820983619,
        "spearman": 0.6772316286588644
      },
      {
        "cosine_pearson": 0.6900566914071702,
        "cosine_spearman": 0.6590242516040933,
        "euclidean_pearson": 0.7124541956685612,
        "euclidean_spearman": 0.6590242516040933,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.6590242516040933,
        "manhattan_pearson": 0.7119422914114946,
        "manhattan_spearman": 0.6585851041520863,
        "pearson": 0.6900566914071702,
        "spearman": 0.6590242516040933
      }
    ]
  },
  "task_name": "SemRel24STS"
}