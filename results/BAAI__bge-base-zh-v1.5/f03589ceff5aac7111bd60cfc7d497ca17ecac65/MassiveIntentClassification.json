{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "task_name": "MassiveIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.378603,
        "f1": 0.341618,
        "f1_weighted": 0.367905,
        "scores_per_experiment": [
          {
            "accuracy": 0.37088,
            "f1": 0.332157,
            "f1_weighted": 0.352501
          },
          {
            "accuracy": 0.352189,
            "f1": 0.32212,
            "f1_weighted": 0.351503
          },
          {
            "accuracy": 0.370389,
            "f1": 0.333187,
            "f1_weighted": 0.357904
          },
          {
            "accuracy": 0.393015,
            "f1": 0.351046,
            "f1_weighted": 0.386566
          },
          {
            "accuracy": 0.40728,
            "f1": 0.357365,
            "f1_weighted": 0.399848
          },
          {
            "accuracy": 0.403837,
            "f1": 0.357984,
            "f1_weighted": 0.396121
          },
          {
            "accuracy": 0.351697,
            "f1": 0.325764,
            "f1_weighted": 0.339877
          },
          {
            "accuracy": 0.379242,
            "f1": 0.337429,
            "f1_weighted": 0.356307
          },
          {
            "accuracy": 0.384161,
            "f1": 0.357257,
            "f1_weighted": 0.369737
          },
          {
            "accuracy": 0.37334,
            "f1": 0.341876,
            "f1_weighted": 0.368688
          }
        ],
        "main_score": 0.378603,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.396873,
        "f1": 0.358566,
        "f1_weighted": 0.378532,
        "scores_per_experiment": [
          {
            "accuracy": 0.406859,
            "f1": 0.355571,
            "f1_weighted": 0.397438
          },
          {
            "accuracy": 0.393073,
            "f1": 0.343589,
            "f1_weighted": 0.365828
          },
          {
            "accuracy": 0.405851,
            "f1": 0.362655,
            "f1_weighted": 0.388836
          },
          {
            "accuracy": 0.398453,
            "f1": 0.361538,
            "f1_weighted": 0.381668
          },
          {
            "accuracy": 0.410894,
            "f1": 0.355522,
            "f1_weighted": 0.388423
          },
          {
            "accuracy": 0.402824,
            "f1": 0.367059,
            "f1_weighted": 0.389222
          },
          {
            "accuracy": 0.407196,
            "f1": 0.379077,
            "f1_weighted": 0.392616
          },
          {
            "accuracy": 0.35844,
            "f1": 0.320815,
            "f1_weighted": 0.33278
          },
          {
            "accuracy": 0.406187,
            "f1": 0.367932,
            "f1_weighted": 0.387846
          },
          {
            "accuracy": 0.378951,
            "f1": 0.371902,
            "f1_weighted": 0.360659
          }
        ],
        "main_score": 0.396873,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 22.193466901779175,
  "kg_co2_emissions": null
}