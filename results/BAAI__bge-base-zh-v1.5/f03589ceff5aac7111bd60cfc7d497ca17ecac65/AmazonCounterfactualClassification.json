{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.599356,
        "f1": 0.576608,
        "f1_weighted": 0.614994,
        "ap": 0.746008,
        "ap_weighted": 0.746008,
        "scores_per_experiment": [
          {
            "accuracy": 0.592275,
            "f1": 0.567279,
            "f1_weighted": 0.608344,
            "ap": 0.738836,
            "ap_weighted": 0.738836
          },
          {
            "accuracy": 0.566524,
            "f1": 0.541919,
            "f1_weighted": 0.583838,
            "ap": 0.72579,
            "ap_weighted": 0.72579
          },
          {
            "accuracy": 0.618026,
            "f1": 0.595486,
            "f1_weighted": 0.633189,
            "ap": 0.755841,
            "ap_weighted": 0.755841
          },
          {
            "accuracy": 0.594421,
            "f1": 0.576834,
            "f1_weighted": 0.610897,
            "ap": 0.749339,
            "ap_weighted": 0.749339
          },
          {
            "accuracy": 0.611588,
            "f1": 0.592443,
            "f1_weighted": 0.627321,
            "ap": 0.756866,
            "ap_weighted": 0.756866
          },
          {
            "accuracy": 0.620172,
            "f1": 0.59554,
            "f1_weighted": 0.634951,
            "ap": 0.754381,
            "ap_weighted": 0.754381
          },
          {
            "accuracy": 0.562232,
            "f1": 0.548938,
            "f1_weighted": 0.579514,
            "ap": 0.737587,
            "ap_weighted": 0.737587
          },
          {
            "accuracy": 0.598712,
            "f1": 0.578101,
            "f1_weighted": 0.614922,
            "ap": 0.747591,
            "ap_weighted": 0.747591
          },
          {
            "accuracy": 0.60515,
            "f1": 0.565976,
            "f1_weighted": 0.617462,
            "ap": 0.732136,
            "ap_weighted": 0.732136
          },
          {
            "accuracy": 0.624464,
            "f1": 0.603562,
            "f1_weighted": 0.639505,
            "ap": 0.761714,
            "ap_weighted": 0.761714
          }
        ],
        "main_score": 0.599356,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.59454,
        "f1": 0.577626,
        "f1_weighted": 0.610537,
        "ap": 0.749455,
        "ap_weighted": 0.749455,
        "scores_per_experiment": [
          {
            "accuracy": 0.576017,
            "f1": 0.556486,
            "f1_weighted": 0.592957,
            "ap": 0.734693,
            "ap_weighted": 0.734693
          },
          {
            "accuracy": 0.547109,
            "f1": 0.528197,
            "f1_weighted": 0.565213,
            "ap": 0.720117,
            "ap_weighted": 0.720117
          },
          {
            "accuracy": 0.630621,
            "f1": 0.615196,
            "f1_weighted": 0.645386,
            "ap": 0.772247,
            "ap_weighted": 0.772247
          },
          {
            "accuracy": 0.627409,
            "f1": 0.610245,
            "f1_weighted": 0.642296,
            "ap": 0.767305,
            "ap_weighted": 0.767305
          },
          {
            "accuracy": 0.601713,
            "f1": 0.580507,
            "f1_weighted": 0.617467,
            "ap": 0.746673,
            "ap_weighted": 0.746673
          },
          {
            "accuracy": 0.59743,
            "f1": 0.583299,
            "f1_weighted": 0.613369,
            "ap": 0.754616,
            "ap_weighted": 0.754616
          },
          {
            "accuracy": 0.568522,
            "f1": 0.55875,
            "f1_weighted": 0.584482,
            "ap": 0.745424,
            "ap_weighted": 0.745424
          },
          {
            "accuracy": 0.572805,
            "f1": 0.558345,
            "f1_weighted": 0.589661,
            "ap": 0.739856,
            "ap_weighted": 0.739856
          },
          {
            "accuracy": 0.576017,
            "f1": 0.552526,
            "f1_weighted": 0.592702,
            "ap": 0.730112,
            "ap_weighted": 0.730112
          },
          {
            "accuracy": 0.647752,
            "f1": 0.632712,
            "f1_weighted": 0.661836,
            "ap": 0.783511,
            "ap_weighted": 0.783511
          }
        ],
        "main_score": 0.59454,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 12.401063919067383,
  "kg_co2_emissions": null
}