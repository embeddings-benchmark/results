{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "task_name": "MTOPIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.42843,
        "f1": 0.266427,
        "f1_weighted": 0.47173,
        "scores_per_experiment": [
          {
            "accuracy": 0.419835,
            "f1": 0.264927,
            "f1_weighted": 0.469774
          },
          {
            "accuracy": 0.430854,
            "f1": 0.288082,
            "f1_weighted": 0.469271
          },
          {
            "accuracy": 0.442975,
            "f1": 0.258891,
            "f1_weighted": 0.49558
          },
          {
            "accuracy": 0.391736,
            "f1": 0.251263,
            "f1_weighted": 0.427944
          },
          {
            "accuracy": 0.433058,
            "f1": 0.270572,
            "f1_weighted": 0.469339
          },
          {
            "accuracy": 0.39449,
            "f1": 0.244939,
            "f1_weighted": 0.444623
          },
          {
            "accuracy": 0.450138,
            "f1": 0.278967,
            "f1_weighted": 0.493743
          },
          {
            "accuracy": 0.433058,
            "f1": 0.266676,
            "f1_weighted": 0.478422
          },
          {
            "accuracy": 0.441322,
            "f1": 0.266534,
            "f1_weighted": 0.480844
          },
          {
            "accuracy": 0.446832,
            "f1": 0.273419,
            "f1_weighted": 0.487763
          }
        ],
        "main_score": 0.42843,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.44421,
        "f1": 0.267085,
        "f1_weighted": 0.488673,
        "scores_per_experiment": [
          {
            "accuracy": 0.418991,
            "f1": 0.255772,
            "f1_weighted": 0.459972
          },
          {
            "accuracy": 0.442942,
            "f1": 0.284957,
            "f1_weighted": 0.48312
          },
          {
            "accuracy": 0.460975,
            "f1": 0.25143,
            "f1_weighted": 0.512398
          },
          {
            "accuracy": 0.408848,
            "f1": 0.261908,
            "f1_weighted": 0.446981
          },
          {
            "accuracy": 0.443505,
            "f1": 0.267515,
            "f1_weighted": 0.489518
          },
          {
            "accuracy": 0.407439,
            "f1": 0.256414,
            "f1_weighted": 0.455877
          },
          {
            "accuracy": 0.478163,
            "f1": 0.275662,
            "f1_weighted": 0.524426
          },
          {
            "accuracy": 0.451395,
            "f1": 0.267761,
            "f1_weighted": 0.505756
          },
          {
            "accuracy": 0.468583,
            "f1": 0.276589,
            "f1_weighted": 0.507181
          },
          {
            "accuracy": 0.461257,
            "f1": 0.272843,
            "f1_weighted": 0.501498
          }
        ],
        "main_score": 0.44421,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 31.173824787139893,
  "kg_co2_emissions": null
}