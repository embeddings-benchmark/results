{
    "dataset_revision": "e6b647fcb6299a2f686f742f4d4c023e553ea67e",
    "task_name": "FloresBitextMining",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "devtest": [
            {
                "hf_subset": "ace_Arab-rus_Cyrl",
                "languages": [
                    "ace-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.06225296442687747,
                "f1": 0.055190958860075,
                "main_score": 0.055190958860075,
                "precision": 0.053752643758000006,
                "recall": 0.06225296442687747
            },
            {
                "hf_subset": "bam_Latn-rus_Cyrl",
                "languages": [
                    "bam-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6837944664031622,
                "f1": 0.6454819836666252,
                "main_score": 0.6454819836666252,
                "precision": 0.6307479233454916,
                "recall": 0.6837944664031622
            },
            {
                "hf_subset": "dzo_Tibt-rus_Cyrl",
                "languages": [
                    "dzo-Tibt",
                    "rus-Cyrl"
                ],
                "accuracy": 0.0009881422924901185,
                "f1": 1.9509225912934225e-06,
                "main_score": 1.9509225912934225e-06,
                "precision": 9.76425190207627e-07,
                "recall": 0.0009881422924901185
            },
            {
                "hf_subset": "hin_Deva-rus_Cyrl",
                "languages": [
                    "hin-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9960474308300395,
                "f1": 0.9947299077733861,
                "main_score": 0.9947299077733861,
                "precision": 0.9940711462450593,
                "recall": 0.9960474308300395
            },
            {
                "hf_subset": "khm_Khmr-rus_Cyrl",
                "languages": [
                    "khm-Khmr",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8883399209486166,
                "f1": 0.8771151056318254,
                "main_score": 0.8771151056318254,
                "precision": 0.8732012500709193,
                "recall": 0.8883399209486166
            },
            {
                "hf_subset": "mag_Deva-rus_Cyrl",
                "languages": [
                    "mag-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9802371541501976,
                "f1": 0.9772397891963109,
                "main_score": 0.9772397891963109,
                "precision": 0.9761904761904762,
                "recall": 0.9802371541501976
            },
            {
                "hf_subset": "pap_Latn-rus_Cyrl",
                "languages": [
                    "pap-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.940711462450593,
                "f1": 0.9368187806922984,
                "main_score": 0.9368187806922984,
                "precision": 0.9358925452707051,
                "recall": 0.940711462450593
            },
            {
                "hf_subset": "sot_Latn-rus_Cyrl",
                "languages": [
                    "sot-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9090909090909091,
                "f1": 0.8923171936758892,
                "main_score": 0.8923171936758892,
                "precision": 0.8851790014083867,
                "recall": 0.9090909090909091
            },
            {
                "hf_subset": "tur_Latn-rus_Cyrl",
                "languages": [
                    "tur-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.989459815546772,
                "main_score": 0.989459815546772,
                "precision": 0.9881422924901186,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "ace_Latn-rus_Cyrl",
                "languages": [
                    "ace-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6610671936758892,
                "f1": 0.6381888256297873,
                "main_score": 0.6381888256297873,
                "precision": 0.6301614067933451,
                "recall": 0.6610671936758892
            },
            {
                "hf_subset": "ban_Latn-rus_Cyrl",
                "languages": [
                    "ban-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7944664031620553,
                "f1": 0.776311962082713,
                "main_score": 0.776311962082713,
                "precision": 0.7693977931929739,
                "recall": 0.7944664031620553
            },
            {
                "hf_subset": "ell_Grek-rus_Cyrl",
                "languages": [
                    "ell-Grek",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9940711462450593,
                "f1": 0.9920948616600791,
                "main_score": 0.9920948616600791,
                "precision": 0.9911067193675891,
                "recall": 0.9940711462450593
            },
            {
                "hf_subset": "hne_Deva-rus_Cyrl",
                "languages": [
                    "hne-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.968379446640316,
                "f1": 0.9625352907961603,
                "main_score": 0.9625352907961603,
                "precision": 0.9602155091285526,
                "recall": 0.968379446640316
            },
            {
                "hf_subset": "kik_Latn-rus_Cyrl",
                "languages": [
                    "kik-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7628458498023716,
                "f1": 0.735596919895859,
                "main_score": 0.735596919895859,
                "precision": 0.7240900759055247,
                "recall": 0.7628458498023716
            },
            {
                "hf_subset": "mai_Deva-rus_Cyrl",
                "languages": [
                    "mai-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9772727272727273,
                "f1": 0.9737812911725956,
                "main_score": 0.9737812911725956,
                "precision": 0.9726002258610953,
                "recall": 0.9772727272727273
            },
            {
                "hf_subset": "pbt_Arab-rus_Cyrl",
                "languages": [
                    "pbt-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.940711462450593,
                "f1": 0.9334700387331967,
                "main_score": 0.9334700387331967,
                "precision": 0.9306920556920556,
                "recall": 0.940711462450593
            },
            {
                "hf_subset": "spa_Latn-rus_Cyrl",
                "languages": [
                    "spa-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.989459815546772,
                "main_score": 0.989459815546772,
                "precision": 0.9881422924901186,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "twi_Latn-rus_Cyrl",
                "languages": [
                    "twi-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8073122529644269,
                "f1": 0.777743436324672,
                "main_score": 0.777743436324672,
                "precision": 0.7654444287596462,
                "recall": 0.8073122529644269
            },
            {
                "hf_subset": "acm_Arab-rus_Cyrl",
                "languages": [
                    "acm-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9456521739130435,
                "f1": 0.9292490118577075,
                "main_score": 0.9292490118577075,
                "precision": 0.9216897233201581,
                "recall": 0.9456521739130435
            },
            {
                "hf_subset": "bel_Cyrl-rus_Cyrl",
                "languages": [
                    "bel-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.9898550724637681,
                "main_score": 0.9898550724637681,
                "precision": 0.9888833992094862,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "eng_Latn-rus_Cyrl",
                "languages": [
                    "eng-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9960474308300395,
                "f1": 0.994729907773386,
                "main_score": 0.994729907773386,
                "precision": 0.9940711462450593,
                "recall": 0.9960474308300395
            },
            {
                "hf_subset": "hrv_Latn-rus_Cyrl",
                "languages": [
                    "hrv-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.9905138339920948,
                "main_score": 0.9905138339920948,
                "precision": 0.9900691699604743,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "kin_Latn-rus_Cyrl",
                "languages": [
                    "kin-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8824110671936759,
                "f1": 0.865485246227658,
                "main_score": 0.865485246227658,
                "precision": 0.8590652101521666,
                "recall": 0.8824110671936759
            },
            {
                "hf_subset": "mal_Mlym-rus_Cyrl",
                "languages": [
                    "mal-Mlym",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9851778656126481,
                "f1": 0.9807971014492753,
                "main_score": 0.9807971014492753,
                "precision": 0.9788372859025033,
                "recall": 0.9851778656126481
            },
            {
                "hf_subset": "pes_Arab-rus_Cyrl",
                "languages": [
                    "pes-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9851778656126481,
                "f1": 0.980566534914361,
                "main_score": 0.980566534914361,
                "precision": 0.9782608695652173,
                "recall": 0.9851778656126481
            },
            {
                "hf_subset": "srd_Latn-rus_Cyrl",
                "languages": [
                    "srd-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.826086956521739,
                "f1": 0.8091734709798211,
                "main_score": 0.8091734709798211,
                "precision": 0.8024468672882626,
                "recall": 0.826086956521739
            },
            {
                "hf_subset": "tzm_Tfng-rus_Cyrl",
                "languages": [
                    "tzm-Tfng",
                    "rus-Cyrl"
                ],
                "accuracy": 0.0741106719367589,
                "f1": 0.06363562740945329,
                "main_score": 0.06363562740945329,
                "precision": 0.06090373175353411,
                "recall": 0.0741106719367589
            },
            {
                "hf_subset": "acq_Arab-rus_Cyrl",
                "languages": [
                    "acq-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9525691699604744,
                "f1": 0.9381422924901187,
                "main_score": 0.9381422924901187,
                "precision": 0.9314064558629775,
                "recall": 0.9525691699604744
            },
            {
                "hf_subset": "bem_Latn-rus_Cyrl",
                "languages": [
                    "bem-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6808300395256918,
                "f1": 0.6501368772860867,
                "main_score": 0.6501368772860867,
                "precision": 0.6391052337510628,
                "recall": 0.6808300395256918
            },
            {
                "hf_subset": "epo_Latn-rus_Cyrl",
                "languages": [
                    "epo-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9841897233201581,
                "f1": 0.9817193675889329,
                "main_score": 0.9817193675889329,
                "precision": 0.9808210564139418,
                "recall": 0.9841897233201581
            },
            {
                "hf_subset": "hun_Latn-rus_Cyrl",
                "languages": [
                    "hun-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9930830039525692,
                "f1": 0.9911067193675891,
                "main_score": 0.9911067193675891,
                "precision": 0.9901185770750988,
                "recall": 0.9930830039525692
            },
            {
                "hf_subset": "kir_Cyrl-rus_Cyrl",
                "languages": [
                    "kir-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9752964426877471,
                "f1": 0.9707549806364035,
                "main_score": 0.9707549806364035,
                "precision": 0.9690958498023715,
                "recall": 0.9752964426877471
            },
            {
                "hf_subset": "mar_Deva-rus_Cyrl",
                "languages": [
                    "mar-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9782608695652173,
                "f1": 0.9744400527009222,
                "main_score": 0.9744400527009222,
                "precision": 0.9728966685488425,
                "recall": 0.9782608695652173
            },
            {
                "hf_subset": "plt_Latn-rus_Cyrl",
                "languages": [
                    "plt-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.799407114624506,
                "f1": 0.783154177760691,
                "main_score": 0.783154177760691,
                "precision": 0.7769877344877344,
                "recall": 0.799407114624506
            },
            {
                "hf_subset": "srp_Cyrl-rus_Cyrl",
                "languages": [
                    "srp-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9970355731225297,
                "f1": 0.9960474308300395,
                "main_score": 0.9960474308300395,
                "precision": 0.9955533596837944,
                "recall": 0.9970355731225297
            },
            {
                "hf_subset": "uig_Arab-rus_Cyrl",
                "languages": [
                    "uig-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8320158102766798,
                "f1": 0.8144381923034585,
                "main_score": 0.8144381923034585,
                "precision": 0.8078813411582477,
                "recall": 0.8320158102766798
            },
            {
                "hf_subset": "aeb_Arab-rus_Cyrl",
                "languages": [
                    "aeb-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9120553359683794,
                "f1": 0.8875352907961603,
                "main_score": 0.8875352907961603,
                "precision": 0.8764328063241106,
                "recall": 0.9120553359683794
            },
            {
                "hf_subset": "ben_Beng-rus_Cyrl",
                "languages": [
                    "ben-Beng",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.9860671936758894,
                "main_score": 0.9860671936758894,
                "precision": 0.9847661396574441,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "est_Latn-rus_Cyrl",
                "languages": [
                    "est-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9624505928853755,
                "f1": 0.9527417027417028,
                "main_score": 0.9527417027417028,
                "precision": 0.9484107378129117,
                "recall": 0.9624505928853755
            },
            {
                "hf_subset": "hye_Armn-rus_Cyrl",
                "languages": [
                    "hye-Armn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9802371541501976,
                "f1": 0.9767786561264822,
                "main_score": 0.9767786561264822,
                "precision": 0.9755839022637441,
                "recall": 0.9802371541501976
            },
            {
                "hf_subset": "kmb_Latn-rus_Cyrl",
                "languages": [
                    "kmb-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.46047430830039526,
                "f1": 0.42944648048044715,
                "main_score": 0.42944648048044715,
                "precision": 0.419851895607238,
                "recall": 0.46047430830039526
            },
            {
                "hf_subset": "min_Arab-rus_Cyrl",
                "languages": [
                    "min-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.039525691699604744,
                "f1": 0.03402665192725756,
                "main_score": 0.03402665192725756,
                "precision": 0.03303787557740127,
                "recall": 0.039525691699604744
            },
            {
                "hf_subset": "pol_Latn-rus_Cyrl",
                "languages": [
                    "pol-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9960474308300395,
                "f1": 0.994729907773386,
                "main_score": 0.994729907773386,
                "precision": 0.9940711462450593,
                "recall": 0.9960474308300395
            },
            {
                "hf_subset": "ssw_Latn-rus_Cyrl",
                "languages": [
                    "ssw-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7322134387351779,
                "f1": 0.7043086049508974,
                "main_score": 0.7043086049508974,
                "precision": 0.6935312022355656,
                "recall": 0.7322134387351779
            },
            {
                "hf_subset": "ukr_Cyrl-rus_Cyrl",
                "languages": [
                    "ukr-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9990118577075099,
                "f1": 0.9986824769433464,
                "main_score": 0.9986824769433464,
                "precision": 0.9985177865612649,
                "recall": 0.9990118577075099
            },
            {
                "hf_subset": "afr_Latn-rus_Cyrl",
                "languages": [
                    "afr-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.989459815546772,
                "main_score": 0.989459815546772,
                "precision": 0.9881422924901186,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "bho_Deva-rus_Cyrl",
                "languages": [
                    "bho-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.940711462450593,
                "f1": 0.9312182382834557,
                "main_score": 0.9312182382834557,
                "precision": 0.927523453232338,
                "recall": 0.940711462450593
            },
            {
                "hf_subset": "eus_Latn-rus_Cyrl",
                "languages": [
                    "eus-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9219367588932806,
                "f1": 0.9123604975587072,
                "main_score": 0.9123604975587072,
                "precision": 0.9086697443588663,
                "recall": 0.9219367588932806
            },
            {
                "hf_subset": "ibo_Latn-rus_Cyrl",
                "languages": [
                    "ibo-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8221343873517788,
                "f1": 0.8017901604858126,
                "main_score": 0.8017901604858126,
                "precision": 0.7937922847800281,
                "recall": 0.8221343873517788
            },
            {
                "hf_subset": "kmr_Latn-rus_Cyrl",
                "languages": [
                    "kmr-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6867588932806324,
                "f1": 0.6672311714750278,
                "main_score": 0.6672311714750278,
                "precision": 0.6600178401554004,
                "recall": 0.6867588932806324
            },
            {
                "hf_subset": "min_Latn-rus_Cyrl",
                "languages": [
                    "min-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7865612648221344,
                "f1": 0.7626592719972166,
                "main_score": 0.7626592719972166,
                "precision": 0.7539980459997484,
                "recall": 0.7865612648221344
            },
            {
                "hf_subset": "por_Latn-rus_Cyrl",
                "languages": [
                    "por-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.968379446640316,
                "f1": 0.959669678147939,
                "main_score": 0.959669678147939,
                "precision": 0.9559453227931488,
                "recall": 0.968379446640316
            },
            {
                "hf_subset": "sun_Latn-rus_Cyrl",
                "languages": [
                    "sun-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.924901185770751,
                "f1": 0.9166553983773662,
                "main_score": 0.9166553983773662,
                "precision": 0.9134530928009188,
                "recall": 0.924901185770751
            },
            {
                "hf_subset": "umb_Latn-rus_Cyrl",
                "languages": [
                    "umb-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.41007905138339923,
                "f1": 0.3821319326004483,
                "main_score": 0.3821319326004483,
                "precision": 0.3720065546767555,
                "recall": 0.41007905138339923
            },
            {
                "hf_subset": "ajp_Arab-rus_Cyrl",
                "languages": [
                    "ajp-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9535573122529645,
                "f1": 0.9397233201581028,
                "main_score": 0.9397233201581028,
                "precision": 0.9333333333333332,
                "recall": 0.9535573122529645
            },
            {
                "hf_subset": "bjn_Arab-rus_Cyrl",
                "languages": [
                    "bjn-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.036561264822134384,
                "f1": 0.031071978056336484,
                "main_score": 0.031071978056336484,
                "precision": 0.030039741229718215,
                "recall": 0.036561264822134384
            },
            {
                "hf_subset": "ewe_Latn-rus_Cyrl",
                "languages": [
                    "ewe-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6284584980237155,
                "f1": 0.5982201175670472,
                "main_score": 0.5982201175670472,
                "precision": 0.5872629236362004,
                "recall": 0.6284584980237155
            },
            {
                "hf_subset": "ilo_Latn-rus_Cyrl",
                "languages": [
                    "ilo-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8310276679841897,
                "f1": 0.8075065288987582,
                "main_score": 0.8075065288987582,
                "precision": 0.7980726451662179,
                "recall": 0.8310276679841897
            },
            {
                "hf_subset": "knc_Arab-rus_Cyrl",
                "languages": [
                    "knc-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.1007905138339921,
                "f1": 0.08759282456080922,
                "main_score": 0.08759282456080922,
                "precision": 0.08474735138956141,
                "recall": 0.1007905138339921
            },
            {
                "hf_subset": "mkd_Cyrl-rus_Cyrl",
                "languages": [
                    "mkd-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.9855072463768115,
                "main_score": 0.9855072463768115,
                "precision": 0.9836956521739131,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "prs_Arab-rus_Cyrl",
                "languages": [
                    "prs-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9901185770750988,
                "f1": 0.9868247694334652,
                "main_score": 0.9868247694334652,
                "precision": 0.9851778656126481,
                "recall": 0.9901185770750988
            },
            {
                "hf_subset": "swe_Latn-rus_Cyrl",
                "languages": [
                    "swe-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9940711462450593,
                "f1": 0.9922595520421607,
                "main_score": 0.9922595520421607,
                "precision": 0.9914361001317523,
                "recall": 0.9940711462450593
            },
            {
                "hf_subset": "urd_Arab-rus_Cyrl",
                "languages": [
                    "urd-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9782608695652173,
                "f1": 0.9725625823451911,
                "main_score": 0.9725625823451911,
                "precision": 0.9703063241106719,
                "recall": 0.9782608695652173
            },
            {
                "hf_subset": "aka_Latn-rus_Cyrl",
                "languages": [
                    "aka-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8122529644268774,
                "f1": 0.7794307687941228,
                "main_score": 0.7794307687941228,
                "precision": 0.7658782793293665,
                "recall": 0.8122529644268774
            },
            {
                "hf_subset": "bjn_Latn-rus_Cyrl",
                "languages": [
                    "bjn-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8527667984189723,
                "f1": 0.8368691928299221,
                "main_score": 0.8368691928299221,
                "precision": 0.8308670670691656,
                "recall": 0.8527667984189723
            },
            {
                "hf_subset": "fao_Latn-rus_Cyrl",
                "languages": [
                    "fao-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.809288537549407,
                "f1": 0.7929806087454745,
                "main_score": 0.7929806087454745,
                "precision": 0.7871445871526987,
                "recall": 0.809288537549407
            },
            {
                "hf_subset": "ind_Latn-rus_Cyrl",
                "languages": [
                    "ind-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9812252964426879,
                "f1": 0.9752964426877471,
                "main_score": 0.9752964426877471,
                "precision": 0.9723320158102767,
                "recall": 0.9812252964426879
            },
            {
                "hf_subset": "knc_Latn-rus_Cyrl",
                "languages": [
                    "knc-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.3349802371541502,
                "f1": 0.3202378215033989,
                "main_score": 0.3202378215033989,
                "precision": 0.31511356103747407,
                "recall": 0.3349802371541502
            },
            {
                "hf_subset": "mlt_Latn-rus_Cyrl",
                "languages": [
                    "mlt-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9140316205533597,
                "f1": 0.9035317684386005,
                "main_score": 0.9035317684386005,
                "precision": 0.8994845939633488,
                "recall": 0.9140316205533597
            },
            {
                "hf_subset": "quy_Latn-rus_Cyrl",
                "languages": [
                    "quy-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.4061264822134387,
                "f1": 0.3874337544712602,
                "main_score": 0.3874337544712602,
                "precision": 0.38133716022178576,
                "recall": 0.4061264822134387
            },
            {
                "hf_subset": "swh_Latn-rus_Cyrl",
                "languages": [
                    "swh-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9713438735177866,
                "f1": 0.9647435897435898,
                "main_score": 0.9647435897435898,
                "precision": 0.9618741765480895,
                "recall": 0.9713438735177866
            },
            {
                "hf_subset": "uzn_Latn-rus_Cyrl",
                "languages": [
                    "uzn-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.968379446640316,
                "f1": 0.9626355528529441,
                "main_score": 0.9626355528529441,
                "precision": 0.960501756697409,
                "recall": 0.968379446640316
            },
            {
                "hf_subset": "als_Latn-rus_Cyrl",
                "languages": [
                    "als-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.986907114624506,
                "main_score": 0.986907114624506,
                "precision": 0.986142480707698,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "bod_Tibt-rus_Cyrl",
                "languages": [
                    "bod-Tibt",
                    "rus-Cyrl"
                ],
                "accuracy": 0.010869565217391304,
                "f1": 0.009224649610442628,
                "main_score": 0.009224649610442628,
                "precision": 0.008894275740459898,
                "recall": 0.010869565217391304
            },
            {
                "hf_subset": "fij_Latn-rus_Cyrl",
                "languages": [
                    "fij-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6324110671936759,
                "f1": 0.6037318906818953,
                "main_score": 0.6037318906818953,
                "precision": 0.5932326368115546,
                "recall": 0.6324110671936759
            },
            {
                "hf_subset": "isl_Latn-rus_Cyrl",
                "languages": [
                    "isl-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8903162055335969,
                "f1": 0.873102634715907,
                "main_score": 0.873102634715907,
                "precision": 0.8665991814698712,
                "recall": 0.8903162055335969
            },
            {
                "hf_subset": "kon_Latn-rus_Cyrl",
                "languages": [
                    "kon-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7391304347826086,
                "f1": 0.7151823552357299,
                "main_score": 0.7151823552357299,
                "precision": 0.7058714102449801,
                "recall": 0.7391304347826086
            },
            {
                "hf_subset": "mni_Beng-rus_Cyrl",
                "languages": [
                    "mni-Beng",
                    "rus-Cyrl"
                ],
                "accuracy": 0.29545454545454547,
                "f1": 0.2759513619889114,
                "main_score": 0.2759513619889114,
                "precision": 0.26983849851025343,
                "recall": 0.29545454545454547
            },
            {
                "hf_subset": "ron_Latn-rus_Cyrl",
                "languages": [
                    "ron-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9940711462450593,
                "f1": 0.9920948616600791,
                "main_score": 0.9920948616600791,
                "precision": 0.9911067193675891,
                "recall": 0.9940711462450593
            },
            {
                "hf_subset": "szl_Latn-rus_Cyrl",
                "languages": [
                    "szl-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8626482213438735,
                "f1": 0.8518912031587511,
                "main_score": 0.8518912031587511,
                "precision": 0.8477199409959775,
                "recall": 0.8626482213438735
            },
            {
                "hf_subset": "vec_Latn-rus_Cyrl",
                "languages": [
                    "vec-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8567193675889329,
                "f1": 0.8462529734716582,
                "main_score": 0.8462529734716582,
                "precision": 0.842611422440705,
                "recall": 0.8567193675889329
            },
            {
                "hf_subset": "amh_Ethi-rus_Cyrl",
                "languages": [
                    "amh-Ethi",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9476284584980238,
                "f1": 0.9391735076517684,
                "main_score": 0.9391735076517684,
                "precision": 0.9357553798858147,
                "recall": 0.9476284584980238
            },
            {
                "hf_subset": "bos_Latn-rus_Cyrl",
                "languages": [
                    "bos-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.9905655938264634,
                "main_score": 0.9905655938264634,
                "precision": 0.9901185770750988,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "fin_Latn-rus_Cyrl",
                "languages": [
                    "fin-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9802371541501976,
                "f1": 0.9743741765480896,
                "main_score": 0.9743741765480896,
                "precision": 0.9715909090909091,
                "recall": 0.9802371541501976
            },
            {
                "hf_subset": "ita_Latn-rus_Cyrl",
                "languages": [
                    "ita-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9970355731225297,
                "f1": 0.9960474308300395,
                "main_score": 0.9960474308300395,
                "precision": 0.9955533596837944,
                "recall": 0.9970355731225297
            },
            {
                "hf_subset": "kor_Hang-rus_Cyrl",
                "languages": [
                    "kor-Hang",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9733201581027668,
                "f1": 0.9649868247694334,
                "main_score": 0.9649868247694334,
                "precision": 0.9610507246376812,
                "recall": 0.9733201581027668
            },
            {
                "hf_subset": "mos_Latn-rus_Cyrl",
                "languages": [
                    "mos-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.3468379446640316,
                "f1": 0.32766819308009076,
                "main_score": 0.32766819308009076,
                "precision": 0.321637493670237,
                "recall": 0.3468379446640316
            },
            {
                "hf_subset": "run_Latn-rus_Cyrl",
                "languages": [
                    "run-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.83399209486166,
                "f1": 0.8110578750604326,
                "main_score": 0.8110578750604326,
                "precision": 0.8016763162673528,
                "recall": 0.83399209486166
            },
            {
                "hf_subset": "tam_Taml-rus_Cyrl",
                "languages": [
                    "tam-Taml",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9841897233201581,
                "f1": 0.9801548089591567,
                "main_score": 0.9801548089591567,
                "precision": 0.9784020327498588,
                "recall": 0.9841897233201581
            },
            {
                "hf_subset": "vie_Latn-rus_Cyrl",
                "languages": [
                    "vie-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9911067193675891,
                "f1": 0.9881422924901186,
                "main_score": 0.9881422924901186,
                "precision": 0.9866600790513834,
                "recall": 0.9911067193675891
            },
            {
                "hf_subset": "apc_Arab-rus_Cyrl",
                "languages": [
                    "apc-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9387351778656127,
                "f1": 0.9210803689064558,
                "main_score": 0.9210803689064558,
                "precision": 0.9130434782608695,
                "recall": 0.9387351778656127
            },
            {
                "hf_subset": "bug_Latn-rus_Cyrl",
                "languages": [
                    "bug-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.5760869565217391,
                "f1": 0.5495878654927162,
                "main_score": 0.5495878654927162,
                "precision": 0.5406798742780565,
                "recall": 0.5760869565217391
            },
            {
                "hf_subset": "fon_Latn-rus_Cyrl",
                "languages": [
                    "fon-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6195652173913043,
                "f1": 0.5806537275812945,
                "main_score": 0.5806537275812945,
                "precision": 0.5655405759695921,
                "recall": 0.6195652173913043
            },
            {
                "hf_subset": "jav_Latn-rus_Cyrl",
                "languages": [
                    "jav-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9347826086956522,
                "f1": 0.924784405318002,
                "main_score": 0.924784405318002,
                "precision": 0.9209168143201127,
                "recall": 0.9347826086956522
            },
            {
                "hf_subset": "lao_Laoo-rus_Cyrl",
                "languages": [
                    "lao-Laoo",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9110671936758892,
                "f1": 0.8976104922745239,
                "main_score": 0.8976104922745239,
                "precision": 0.8924754593232855,
                "recall": 0.9110671936758892
            },
            {
                "hf_subset": "mri_Latn-rus_Cyrl",
                "languages": [
                    "mri-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7114624505928853,
                "f1": 0.6826947125119063,
                "main_score": 0.6826947125119063,
                "precision": 0.6715942311051006,
                "recall": 0.7114624505928853
            },
            {
                "hf_subset": "rus_Cyrl-ace_Arab",
                "languages": [
                    "rus-Cyrl",
                    "ace-Arab"
                ],
                "accuracy": 0.1956521739130435,
                "f1": 0.16321465000323804,
                "main_score": 0.16321465000323804,
                "precision": 0.1547852740934751,
                "recall": 0.1956521739130435
            },
            {
                "hf_subset": "rus_Cyrl-bam_Latn",
                "languages": [
                    "rus-Cyrl",
                    "bam-Latn"
                ],
                "accuracy": 0.7341897233201581,
                "f1": 0.6877366228182745,
                "main_score": 0.6877366228182745,
                "precision": 0.6696012924273795,
                "recall": 0.7341897233201581
            },
            {
                "hf_subset": "rus_Cyrl-dzo_Tibt",
                "languages": [
                    "rus-Cyrl",
                    "dzo-Tibt"
                ],
                "accuracy": 0.00592885375494071,
                "f1": 0.0002458062426370458,
                "main_score": 0.0002458062426370458,
                "precision": 0.00012824114724683877,
                "recall": 0.00592885375494071
            },
            {
                "hf_subset": "rus_Cyrl-hin_Deva",
                "languages": [
                    "rus-Cyrl",
                    "hin-Deva"
                ],
                "accuracy": 0.9990118577075099,
                "f1": 0.9986824769433464,
                "main_score": 0.9986824769433464,
                "precision": 0.9985177865612649,
                "recall": 0.9990118577075099
            },
            {
                "hf_subset": "rus_Cyrl-khm_Khmr",
                "languages": [
                    "rus-Cyrl",
                    "khm-Khmr"
                ],
                "accuracy": 0.9713438735177866,
                "f1": 0.9624505928853755,
                "main_score": 0.9624505928853755,
                "precision": 0.9581686429512516,
                "recall": 0.9713438735177866
            },
            {
                "hf_subset": "rus_Cyrl-mag_Deva",
                "languages": [
                    "rus-Cyrl",
                    "mag-Deva"
                ],
                "accuracy": 0.9950592885375493,
                "f1": 0.9935770750988142,
                "main_score": 0.9935770750988142,
                "precision": 0.9929183135704875,
                "recall": 0.9950592885375493
            },
            {
                "hf_subset": "rus_Cyrl-pap_Latn",
                "languages": [
                    "rus-Cyrl",
                    "pap-Latn"
                ],
                "accuracy": 0.9693675889328063,
                "f1": 0.9605072463768116,
                "main_score": 0.9605072463768116,
                "precision": 0.9566040843214758,
                "recall": 0.9693675889328063
            },
            {
                "hf_subset": "rus_Cyrl-sot_Latn",
                "languages": [
                    "rus-Cyrl",
                    "sot-Latn"
                ],
                "accuracy": 0.9367588932806324,
                "f1": 0.917786561264822,
                "main_score": 0.917786561264822,
                "precision": 0.9091238471673254,
                "recall": 0.9367588932806324
            },
            {
                "hf_subset": "rus_Cyrl-tur_Latn",
                "languages": [
                    "rus-Cyrl",
                    "tur-Latn"
                ],
                "accuracy": 0.9901185770750988,
                "f1": 0.9868247694334652,
                "main_score": 0.9868247694334652,
                "precision": 0.9851778656126481,
                "recall": 0.9901185770750988
            },
            {
                "hf_subset": "rus_Cyrl-ace_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ace-Latn"
                ],
                "accuracy": 0.7411067193675891,
                "f1": 0.7021737923911836,
                "main_score": 0.7021737923911836,
                "precision": 0.687068791410511,
                "recall": 0.7411067193675891
            },
            {
                "hf_subset": "rus_Cyrl-ban_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ban-Latn"
                ],
                "accuracy": 0.817193675889328,
                "f1": 0.7876470334510617,
                "main_score": 0.7876470334510617,
                "precision": 0.7776208475761421,
                "recall": 0.817193675889328
            },
            {
                "hf_subset": "rus_Cyrl-ell_Grek",
                "languages": [
                    "rus-Cyrl",
                    "ell-Grek"
                ],
                "accuracy": 0.983201581027668,
                "f1": 0.9776021080368907,
                "main_score": 0.9776021080368907,
                "precision": 0.9748023715415018,
                "recall": 0.983201581027668
            },
            {
                "hf_subset": "rus_Cyrl-hne_Deva",
                "languages": [
                    "rus-Cyrl",
                    "hne-Deva"
                ],
                "accuracy": 0.9851778656126481,
                "f1": 0.980566534914361,
                "main_score": 0.980566534914361,
                "precision": 0.9782608695652173,
                "recall": 0.9851778656126481
            },
            {
                "hf_subset": "rus_Cyrl-kik_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kik-Latn"
                ],
                "accuracy": 0.8073122529644269,
                "f1": 0.7642689244220864,
                "main_score": 0.7642689244220864,
                "precision": 0.7463877909530083,
                "recall": 0.8073122529644269
            },
            {
                "hf_subset": "rus_Cyrl-mai_Deva",
                "languages": [
                    "rus-Cyrl",
                    "mai-Deva"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.9856719367588933,
                "main_score": 0.9856719367588933,
                "precision": 0.9840250329380763,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "rus_Cyrl-pbt_Arab",
                "languages": [
                    "rus-Cyrl",
                    "pbt-Arab"
                ],
                "accuracy": 0.9752964426877471,
                "f1": 0.967391304347826,
                "main_score": 0.967391304347826,
                "precision": 0.9636034255599474,
                "recall": 0.9752964426877471
            },
            {
                "hf_subset": "rus_Cyrl-spa_Latn",
                "languages": [
                    "rus-Cyrl",
                    "spa-Latn"
                ],
                "accuracy": 0.9940711462450593,
                "f1": 0.9920948616600789,
                "main_score": 0.9920948616600789,
                "precision": 0.9911067193675891,
                "recall": 0.9940711462450593
            },
            {
                "hf_subset": "rus_Cyrl-twi_Latn",
                "languages": [
                    "rus-Cyrl",
                    "twi-Latn"
                ],
                "accuracy": 0.8201581027667985,
                "f1": 0.78064787822953,
                "main_score": 0.78064787822953,
                "precision": 0.7643272186750448,
                "recall": 0.8201581027667985
            },
            {
                "hf_subset": "rus_Cyrl-acm_Arab",
                "languages": [
                    "rus-Cyrl",
                    "acm-Arab"
                ],
                "accuracy": 0.983201581027668,
                "f1": 0.9776021080368907,
                "main_score": 0.9776021080368907,
                "precision": 0.9748023715415018,
                "recall": 0.983201581027668
            },
            {
                "hf_subset": "rus_Cyrl-bel_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "bel-Cyrl"
                ],
                "accuracy": 0.9822134387351779,
                "f1": 0.9767786561264822,
                "main_score": 0.9767786561264822,
                "precision": 0.9743083003952571,
                "recall": 0.9822134387351779
            },
            {
                "hf_subset": "rus_Cyrl-eng_Latn",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 0.9970355731225297,
                "f1": 0.9960474308300395,
                "main_score": 0.9960474308300395,
                "precision": 0.9955533596837944,
                "recall": 0.9970355731225297
            },
            {
                "hf_subset": "rus_Cyrl-hrv_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hrv-Latn"
                ],
                "accuracy": 0.9911067193675891,
                "f1": 0.9883069828722002,
                "main_score": 0.9883069828722002,
                "precision": 0.9869894598155465,
                "recall": 0.9911067193675891
            },
            {
                "hf_subset": "rus_Cyrl-kin_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kin-Latn"
                ],
                "accuracy": 0.9337944664031622,
                "f1": 0.9153162055335968,
                "main_score": 0.9153162055335968,
                "precision": 0.9071475625823452,
                "recall": 0.9337944664031622
            },
            {
                "hf_subset": "rus_Cyrl-mal_Mlym",
                "languages": [
                    "rus-Cyrl",
                    "mal-Mlym"
                ],
                "accuracy": 0.9930830039525692,
                "f1": 0.9907773386034254,
                "main_score": 0.9907773386034254,
                "precision": 0.9896245059288538,
                "recall": 0.9930830039525692
            },
            {
                "hf_subset": "rus_Cyrl-pes_Arab",
                "languages": [
                    "rus-Cyrl",
                    "pes-Arab"
                ],
                "accuracy": 0.9871541501976284,
                "f1": 0.9830368906455863,
                "main_score": 0.9830368906455863,
                "precision": 0.9810606060606061,
                "recall": 0.9871541501976284
            },
            {
                "hf_subset": "rus_Cyrl-srd_Latn",
                "languages": [
                    "rus-Cyrl",
                    "srd-Latn"
                ],
                "accuracy": 0.8903162055335969,
                "f1": 0.8611048371917938,
                "main_score": 0.8611048371917938,
                "precision": 0.8486001317523056,
                "recall": 0.8903162055335969
            },
            {
                "hf_subset": "rus_Cyrl-tzm_Tfng",
                "languages": [
                    "rus-Cyrl",
                    "tzm-Tfng"
                ],
                "accuracy": 0.12351778656126483,
                "f1": 0.10112177999067715,
                "main_score": 0.10112177999067715,
                "precision": 0.0953495885438645,
                "recall": 0.12351778656126483
            },
            {
                "hf_subset": "rus_Cyrl-acq_Arab",
                "languages": [
                    "rus-Cyrl",
                    "acq-Arab"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.9855072463768115,
                "main_score": 0.9855072463768115,
                "precision": 0.9836956521739131,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "rus_Cyrl-bem_Latn",
                "languages": [
                    "rus-Cyrl",
                    "bem-Latn"
                ],
                "accuracy": 0.7322134387351779,
                "f1": 0.6830479412989295,
                "main_score": 0.6830479412989295,
                "precision": 0.6640073447632736,
                "recall": 0.7322134387351779
            },
            {
                "hf_subset": "rus_Cyrl-epo_Latn",
                "languages": [
                    "rus-Cyrl",
                    "epo-Latn"
                ],
                "accuracy": 0.9911067193675891,
                "f1": 0.9881422924901186,
                "main_score": 0.9881422924901186,
                "precision": 0.9866600790513834,
                "recall": 0.9911067193675891
            },
            {
                "hf_subset": "rus_Cyrl-hun_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hun-Latn"
                ],
                "accuracy": 0.968379446640316,
                "f1": 0.9588274044795785,
                "main_score": 0.9588274044795785,
                "precision": 0.9545454545454546,
                "recall": 0.968379446640316
            },
            {
                "hf_subset": "rus_Cyrl-kir_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "kir-Cyrl"
                ],
                "accuracy": 0.9634387351778656,
                "f1": 0.9549280429715212,
                "main_score": 0.9549280429715212,
                "precision": 0.9514163372859027,
                "recall": 0.9634387351778656
            },
            {
                "hf_subset": "rus_Cyrl-mar_Deva",
                "languages": [
                    "rus-Cyrl",
                    "mar-Deva"
                ],
                "accuracy": 0.9871541501976284,
                "f1": 0.9828722002635046,
                "main_score": 0.9828722002635046,
                "precision": 0.9807312252964426,
                "recall": 0.9871541501976284
            },
            {
                "hf_subset": "rus_Cyrl-plt_Latn",
                "languages": [
                    "rus-Cyrl",
                    "plt-Latn"
                ],
                "accuracy": 0.8804347826086957,
                "f1": 0.8514328063241107,
                "main_score": 0.8514328063241107,
                "precision": 0.8396339168078297,
                "recall": 0.8804347826086957
            },
            {
                "hf_subset": "rus_Cyrl-srp_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "srp-Cyrl"
                ],
                "accuracy": 0.9940711462450593,
                "f1": 0.9920948616600791,
                "main_score": 0.9920948616600791,
                "precision": 0.9911067193675891,
                "recall": 0.9940711462450593
            },
            {
                "hf_subset": "rus_Cyrl-uig_Arab",
                "languages": [
                    "rus-Cyrl",
                    "uig-Arab"
                ],
                "accuracy": 0.9219367588932806,
                "f1": 0.8998541313758706,
                "main_score": 0.8998541313758706,
                "precision": 0.8901021080368906,
                "recall": 0.9219367588932806
            },
            {
                "hf_subset": "rus_Cyrl-aeb_Arab",
                "languages": [
                    "rus-Cyrl",
                    "aeb-Arab"
                ],
                "accuracy": 0.958498023715415,
                "f1": 0.9463109354413703,
                "main_score": 0.9463109354413703,
                "precision": 0.9405467720685111,
                "recall": 0.958498023715415
            },
            {
                "hf_subset": "rus_Cyrl-ben_Beng",
                "languages": [
                    "rus-Cyrl",
                    "ben-Beng"
                ],
                "accuracy": 0.9940711462450593,
                "f1": 0.9920948616600791,
                "main_score": 0.9920948616600791,
                "precision": 0.9911067193675891,
                "recall": 0.9940711462450593
            },
            {
                "hf_subset": "rus_Cyrl-est_Latn",
                "languages": [
                    "rus-Cyrl",
                    "est-Latn"
                ],
                "accuracy": 0.9555335968379447,
                "f1": 0.942588932806324,
                "main_score": 0.942588932806324,
                "precision": 0.9365118577075099,
                "recall": 0.9555335968379447
            },
            {
                "hf_subset": "rus_Cyrl-hye_Armn",
                "languages": [
                    "rus-Cyrl",
                    "hye-Armn"
                ],
                "accuracy": 0.9871541501976284,
                "f1": 0.9828722002635045,
                "main_score": 0.9828722002635045,
                "precision": 0.9807312252964426,
                "recall": 0.9871541501976284
            },
            {
                "hf_subset": "rus_Cyrl-kmb_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kmb-Latn"
                ],
                "accuracy": 0.5424901185770751,
                "f1": 0.49461466741169136,
                "main_score": 0.49461466741169136,
                "precision": 0.47810337993144325,
                "recall": 0.5424901185770751
            },
            {
                "hf_subset": "rus_Cyrl-min_Arab",
                "languages": [
                    "rus-Cyrl",
                    "min-Arab"
                ],
                "accuracy": 0.15810276679841898,
                "f1": 0.13271207641419333,
                "main_score": 0.13271207641419333,
                "precision": 0.12510673148766033,
                "recall": 0.15810276679841898
            },
            {
                "hf_subset": "rus_Cyrl-pol_Latn",
                "languages": [
                    "rus-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.9871541501976284,
                "f1": 0.9832674571805007,
                "main_score": 0.9832674571805007,
                "precision": 0.9814723320158103,
                "recall": 0.9871541501976284
            },
            {
                "hf_subset": "rus_Cyrl-ssw_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ssw-Latn"
                ],
                "accuracy": 0.808300395256917,
                "f1": 0.7651717847370023,
                "main_score": 0.7651717847370023,
                "precision": 0.7474143610013175,
                "recall": 0.808300395256917
            },
            {
                "hf_subset": "rus_Cyrl-ukr_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "ukr-Cyrl"
                ],
                "accuracy": 0.9960474308300395,
                "f1": 0.994729907773386,
                "main_score": 0.994729907773386,
                "precision": 0.9940711462450593,
                "recall": 0.9960474308300395
            },
            {
                "hf_subset": "rus_Cyrl-afr_Latn",
                "languages": [
                    "rus-Cyrl",
                    "afr-Latn"
                ],
                "accuracy": 0.9911067193675891,
                "f1": 0.9881422924901186,
                "main_score": 0.9881422924901186,
                "precision": 0.9866600790513834,
                "recall": 0.9911067193675891
            },
            {
                "hf_subset": "rus_Cyrl-bho_Deva",
                "languages": [
                    "rus-Cyrl",
                    "bho-Deva"
                ],
                "accuracy": 0.9664031620553359,
                "f1": 0.9556982872200266,
                "main_score": 0.9556982872200266,
                "precision": 0.950592885375494,
                "recall": 0.9664031620553359
            },
            {
                "hf_subset": "rus_Cyrl-eus_Latn",
                "languages": [
                    "rus-Cyrl",
                    "eus-Latn"
                ],
                "accuracy": 0.9762845849802372,
                "f1": 0.969038208168643,
                "main_score": 0.969038208168643,
                "precision": 0.9655797101449275,
                "recall": 0.9762845849802372
            },
            {
                "hf_subset": "rus_Cyrl-ibo_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ibo-Latn"
                ],
                "accuracy": 0.892292490118577,
                "f1": 0.8635234330886505,
                "main_score": 0.8635234330886505,
                "precision": 0.8509881422924902,
                "recall": 0.892292490118577
            },
            {
                "hf_subset": "rus_Cyrl-kmr_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kmr-Latn"
                ],
                "accuracy": 0.8349802371541502,
                "f1": 0.7923630717108978,
                "main_score": 0.7923630717108978,
                "precision": 0.7748188405797102,
                "recall": 0.8349802371541502
            },
            {
                "hf_subset": "rus_Cyrl-min_Latn",
                "languages": [
                    "rus-Cyrl",
                    "min-Latn"
                ],
                "accuracy": 0.7934782608695652,
                "f1": 0.7531689928429058,
                "main_score": 0.7531689928429058,
                "precision": 0.7391519410541149,
                "recall": 0.7934782608695652
            },
            {
                "hf_subset": "rus_Cyrl-por_Latn",
                "languages": [
                    "rus-Cyrl",
                    "por-Latn"
                ],
                "accuracy": 0.9654150197628458,
                "f1": 0.9553218520609825,
                "main_score": 0.9553218520609825,
                "precision": 0.9507575757575757,
                "recall": 0.9654150197628458
            },
            {
                "hf_subset": "rus_Cyrl-sun_Latn",
                "languages": [
                    "rus-Cyrl",
                    "sun-Latn"
                ],
                "accuracy": 0.932806324110672,
                "f1": 0.9156973461321287,
                "main_score": 0.9156973461321287,
                "precision": 0.9084396334890406,
                "recall": 0.932806324110672
            },
            {
                "hf_subset": "rus_Cyrl-umb_Latn",
                "languages": [
                    "rus-Cyrl",
                    "umb-Latn"
                ],
                "accuracy": 0.5187747035573123,
                "f1": 0.46365917788842687,
                "main_score": 0.46365917788842687,
                "precision": 0.44577303912342275,
                "recall": 0.5187747035573123
            },
            {
                "hf_subset": "rus_Cyrl-ajp_Arab",
                "languages": [
                    "rus-Cyrl",
                    "ajp-Arab"
                ],
                "accuracy": 0.9871541501976284,
                "f1": 0.9830368906455863,
                "main_score": 0.9830368906455863,
                "precision": 0.9810606060606061,
                "recall": 0.9871541501976284
            },
            {
                "hf_subset": "rus_Cyrl-bjn_Arab",
                "languages": [
                    "rus-Cyrl",
                    "bjn-Arab"
                ],
                "accuracy": 0.1482213438735178,
                "f1": 0.12365434276616856,
                "main_score": 0.12365434276616856,
                "precision": 0.11802079517180589,
                "recall": 0.1482213438735178
            },
            {
                "hf_subset": "rus_Cyrl-ewe_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ewe-Latn"
                ],
                "accuracy": 0.7144268774703558,
                "f1": 0.6674603174603174,
                "main_score": 0.6674603174603174,
                "precision": 0.6499933339607253,
                "recall": 0.7144268774703558
            },
            {
                "hf_subset": "rus_Cyrl-ilo_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ilo-Latn"
                ],
                "accuracy": 0.8586956521739131,
                "f1": 0.8300139015960917,
                "main_score": 0.8300139015960917,
                "precision": 0.819141139657444,
                "recall": 0.8586956521739131
            },
            {
                "hf_subset": "rus_Cyrl-knc_Arab",
                "languages": [
                    "rus-Cyrl",
                    "knc-Arab"
                ],
                "accuracy": 0.14525691699604742,
                "f1": 0.12618283715726805,
                "main_score": 0.12618283715726805,
                "precision": 0.12048458493742352,
                "recall": 0.14525691699604742
            },
            {
                "hf_subset": "rus_Cyrl-mkd_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "mkd-Cyrl"
                ],
                "accuracy": 0.9940711462450593,
                "f1": 0.9922595520421607,
                "main_score": 0.9922595520421607,
                "precision": 0.9914361001317523,
                "recall": 0.9940711462450593
            },
            {
                "hf_subset": "rus_Cyrl-prs_Arab",
                "languages": [
                    "rus-Cyrl",
                    "prs-Arab"
                ],
                "accuracy": 0.9930830039525692,
                "f1": 0.9907773386034254,
                "main_score": 0.9907773386034254,
                "precision": 0.9896245059288538,
                "recall": 0.9930830039525692
            },
            {
                "hf_subset": "rus_Cyrl-swe_Latn",
                "languages": [
                    "rus-Cyrl",
                    "swe-Latn"
                ],
                "accuracy": 0.9930830039525692,
                "f1": 0.9907773386034257,
                "main_score": 0.9907773386034257,
                "precision": 0.9896245059288538,
                "recall": 0.9930830039525692
            },
            {
                "hf_subset": "rus_Cyrl-urd_Arab",
                "languages": [
                    "rus-Cyrl",
                    "urd-Arab"
                ],
                "accuracy": 0.9861660079051383,
                "f1": 0.9815546772068511,
                "main_score": 0.9815546772068511,
                "precision": 0.9792490118577075,
                "recall": 0.9861660079051383
            },
            {
                "hf_subset": "rus_Cyrl-aka_Latn",
                "languages": [
                    "rus-Cyrl",
                    "aka-Latn"
                ],
                "accuracy": 0.8102766798418972,
                "f1": 0.7673277809147375,
                "main_score": 0.7673277809147375,
                "precision": 0.7497404165882426,
                "recall": 0.8102766798418972
            },
            {
                "hf_subset": "rus_Cyrl-bjn_Latn",
                "languages": [
                    "rus-Cyrl",
                    "bjn-Latn"
                ],
                "accuracy": 0.8675889328063241,
                "f1": 0.8392064566965753,
                "main_score": 0.8392064566965753,
                "precision": 0.8283734079929732,
                "recall": 0.8675889328063241
            },
            {
                "hf_subset": "rus_Cyrl-fao_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fao-Latn"
                ],
                "accuracy": 0.8843873517786561,
                "f1": 0.8548136645962733,
                "main_score": 0.8548136645962733,
                "precision": 0.8423418972332015,
                "recall": 0.8843873517786561
            },
            {
                "hf_subset": "rus_Cyrl-ind_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ind-Latn"
                ],
                "accuracy": 0.9901185770750988,
                "f1": 0.9868247694334652,
                "main_score": 0.9868247694334652,
                "precision": 0.9851778656126481,
                "recall": 0.9901185770750988
            },
            {
                "hf_subset": "rus_Cyrl-knc_Latn",
                "languages": [
                    "rus-Cyrl",
                    "knc-Latn"
                ],
                "accuracy": 0.458498023715415,
                "f1": 0.4011203086548937,
                "main_score": 0.4011203086548937,
                "precision": 0.3828262440050776,
                "recall": 0.458498023715415
            },
            {
                "hf_subset": "rus_Cyrl-mlt_Latn",
                "languages": [
                    "rus-Cyrl",
                    "mlt-Latn"
                ],
                "accuracy": 0.9318181818181818,
                "f1": 0.9130787690570298,
                "main_score": 0.9130787690570298,
                "precision": 0.904983060417843,
                "recall": 0.9318181818181818
            },
            {
                "hf_subset": "rus_Cyrl-quy_Latn",
                "languages": [
                    "rus-Cyrl",
                    "quy-Latn"
                ],
                "accuracy": 0.6245059288537549,
                "f1": 0.5728742975628178,
                "main_score": 0.5728742975628178,
                "precision": 0.5556854987623269,
                "recall": 0.6245059288537549
            },
            {
                "hf_subset": "rus_Cyrl-swh_Latn",
                "languages": [
                    "rus-Cyrl",
                    "swh-Latn"
                ],
                "accuracy": 0.983201581027668,
                "f1": 0.9777667984189723,
                "main_score": 0.9777667984189723,
                "precision": 0.9751317523056655,
                "recall": 0.983201581027668
            },
            {
                "hf_subset": "rus_Cyrl-uzn_Latn",
                "languages": [
                    "rus-Cyrl",
                    "uzn-Latn"
                ],
                "accuracy": 0.9812252964426879,
                "f1": 0.9759081498211932,
                "main_score": 0.9759081498211932,
                "precision": 0.9734848484848484,
                "recall": 0.9812252964426879
            },
            {
                "hf_subset": "rus_Cyrl-als_Latn",
                "languages": [
                    "rus-Cyrl",
                    "als-Latn"
                ],
                "accuracy": 0.9930830039525692,
                "f1": 0.9909420289855073,
                "main_score": 0.9909420289855073,
                "precision": 0.9899538866930172,
                "recall": 0.9930830039525692
            },
            {
                "hf_subset": "rus_Cyrl-bod_Tibt",
                "languages": [
                    "rus-Cyrl",
                    "bod-Tibt"
                ],
                "accuracy": 0.11561264822134387,
                "f1": 0.08121312045385637,
                "main_score": 0.08121312045385637,
                "precision": 0.07350577020893972,
                "recall": 0.11561264822134387
            },
            {
                "hf_subset": "rus_Cyrl-fij_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fij-Latn"
                ],
                "accuracy": 0.7223320158102767,
                "f1": 0.6721000233846083,
                "main_score": 0.6721000233846083,
                "precision": 0.653869439739005,
                "recall": 0.7223320158102767
            },
            {
                "hf_subset": "rus_Cyrl-isl_Latn",
                "languages": [
                    "rus-Cyrl",
                    "isl-Latn"
                ],
                "accuracy": 0.9199604743083004,
                "f1": 0.8975955204216074,
                "main_score": 0.8975955204216074,
                "precision": 0.887598814229249,
                "recall": 0.9199604743083004
            },
            {
                "hf_subset": "rus_Cyrl-kon_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kon-Latn"
                ],
                "accuracy": 0.8181818181818182,
                "f1": 0.7777800098452272,
                "main_score": 0.7777800098452272,
                "precision": 0.761521268586486,
                "recall": 0.8181818181818182
            },
            {
                "hf_subset": "rus_Cyrl-mni_Beng",
                "languages": [
                    "rus-Cyrl",
                    "mni-Beng"
                ],
                "accuracy": 0.5474308300395256,
                "f1": 0.4897285299254615,
                "main_score": 0.4897285299254615,
                "precision": 0.4695125742968299,
                "recall": 0.5474308300395256
            },
            {
                "hf_subset": "rus_Cyrl-ron_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ron-Latn"
                ],
                "accuracy": 0.9822134387351779,
                "f1": 0.9764492753623188,
                "main_score": 0.9764492753623188,
                "precision": 0.9736495388669302,
                "recall": 0.9822134387351779
            },
            {
                "hf_subset": "rus_Cyrl-szl_Latn",
                "languages": [
                    "rus-Cyrl",
                    "szl-Latn"
                ],
                "accuracy": 0.9209486166007905,
                "f1": 0.9010375494071147,
                "main_score": 0.9010375494071147,
                "precision": 0.8929606625258798,
                "recall": 0.9209486166007905
            },
            {
                "hf_subset": "rus_Cyrl-vec_Latn",
                "languages": [
                    "rus-Cyrl",
                    "vec-Latn"
                ],
                "accuracy": 0.924901185770751,
                "f1": 0.9051430453604365,
                "main_score": 0.9051430453604365,
                "precision": 0.8969367588932807,
                "recall": 0.924901185770751
            },
            {
                "hf_subset": "rus_Cyrl-amh_Ethi",
                "languages": [
                    "rus-Cyrl",
                    "amh-Ethi"
                ],
                "accuracy": 0.9782608695652173,
                "f1": 0.9711791831357048,
                "main_score": 0.9711791831357048,
                "precision": 0.9677206851119894,
                "recall": 0.9782608695652173
            },
            {
                "hf_subset": "rus_Cyrl-bos_Latn",
                "languages": [
                    "rus-Cyrl",
                    "bos-Latn"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.9855072463768115,
                "main_score": 0.9855072463768115,
                "precision": 0.9836956521739131,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "rus_Cyrl-fin_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fin-Latn"
                ],
                "accuracy": 0.9565217391304348,
                "f1": 0.944235836627141,
                "main_score": 0.944235836627141,
                "precision": 0.9384881422924901,
                "recall": 0.9565217391304348
            },
            {
                "hf_subset": "rus_Cyrl-ita_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ita-Latn"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.9855072463768118,
                "main_score": 0.9855072463768118,
                "precision": 0.9836956521739131,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "rus_Cyrl-kor_Hang",
                "languages": [
                    "rus-Cyrl",
                    "kor-Hang"
                ],
                "accuracy": 0.9555335968379447,
                "f1": 0.9415349143610012,
                "main_score": 0.9415349143610012,
                "precision": 0.9349472990777339,
                "recall": 0.9555335968379447
            },
            {
                "hf_subset": "rus_Cyrl-mos_Latn",
                "languages": [
                    "rus-Cyrl",
                    "mos-Latn"
                ],
                "accuracy": 0.43675889328063244,
                "f1": 0.38848497211900823,
                "main_score": 0.38848497211900823,
                "precision": 0.3743294462099682,
                "recall": 0.43675889328063244
            },
            {
                "hf_subset": "rus_Cyrl-run_Latn",
                "languages": [
                    "rus-Cyrl",
                    "run-Latn"
                ],
                "accuracy": 0.9021739130434783,
                "f1": 0.8737483530961793,
                "main_score": 0.8737483530961793,
                "precision": 0.8607872200263507,
                "recall": 0.9021739130434783
            },
            {
                "hf_subset": "rus_Cyrl-tam_Taml",
                "languages": [
                    "rus-Cyrl",
                    "tam-Taml"
                ],
                "accuracy": 0.9940711462450593,
                "f1": 0.9920948616600791,
                "main_score": 0.9920948616600791,
                "precision": 0.9911067193675891,
                "recall": 0.9940711462450593
            },
            {
                "hf_subset": "rus_Cyrl-vie_Latn",
                "languages": [
                    "rus-Cyrl",
                    "vie-Latn"
                ],
                "accuracy": 0.9703557312252964,
                "f1": 0.9613636363636364,
                "main_score": 0.9613636363636364,
                "precision": 0.9570981554677206,
                "recall": 0.9703557312252964
            },
            {
                "hf_subset": "rus_Cyrl-apc_Arab",
                "languages": [
                    "rus-Cyrl",
                    "apc-Arab"
                ],
                "accuracy": 0.9812252964426879,
                "f1": 0.9749670619235836,
                "main_score": 0.9749670619235836,
                "precision": 0.9718379446640316,
                "recall": 0.9812252964426879
            },
            {
                "hf_subset": "rus_Cyrl-bug_Latn",
                "languages": [
                    "rus-Cyrl",
                    "bug-Latn"
                ],
                "accuracy": 0.6729249011857708,
                "f1": 0.6209268717667927,
                "main_score": 0.6209268717667927,
                "precision": 0.6028554009748714,
                "recall": 0.6729249011857708
            },
            {
                "hf_subset": "rus_Cyrl-fon_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fon-Latn"
                ],
                "accuracy": 0.6343873517786561,
                "f1": 0.5766660107569199,
                "main_score": 0.5766660107569199,
                "precision": 0.5566676396919363,
                "recall": 0.6343873517786561
            },
            {
                "hf_subset": "rus_Cyrl-jav_Latn",
                "languages": [
                    "rus-Cyrl",
                    "jav-Latn"
                ],
                "accuracy": 0.9446640316205532,
                "f1": 0.9289384528514963,
                "main_score": 0.9289384528514963,
                "precision": 0.9219367588932806,
                "recall": 0.9446640316205532
            },
            {
                "hf_subset": "rus_Cyrl-lao_Laoo",
                "languages": [
                    "rus-Cyrl",
                    "lao-Laoo"
                ],
                "accuracy": 0.9723320158102767,
                "f1": 0.9640974967061922,
                "main_score": 0.9640974967061922,
                "precision": 0.96034255599473,
                "recall": 0.9723320158102767
            },
            {
                "hf_subset": "rus_Cyrl-mri_Latn",
                "languages": [
                    "rus-Cyrl",
                    "mri-Latn"
                ],
                "accuracy": 0.7677865612648221,
                "f1": 0.7311286539547409,
                "main_score": 0.7311286539547409,
                "precision": 0.7178177214337046,
                "recall": 0.7677865612648221
            },
            {
                "hf_subset": "rus_Cyrl-taq_Latn",
                "languages": [
                    "rus-Cyrl",
                    "taq-Latn"
                ],
                "accuracy": 0.4199604743083004,
                "f1": 0.3725127063318763,
                "main_score": 0.3725127063318763,
                "precision": 0.35718929186985726,
                "recall": 0.4199604743083004
            },
            {
                "hf_subset": "rus_Cyrl-war_Latn",
                "languages": [
                    "rus-Cyrl",
                    "war-Latn"
                ],
                "accuracy": 0.9555335968379447,
                "f1": 0.941699604743083,
                "main_score": 0.941699604743083,
                "precision": 0.9352766798418972,
                "recall": 0.9555335968379447
            },
            {
                "hf_subset": "rus_Cyrl-arb_Arab",
                "languages": [
                    "rus-Cyrl",
                    "arb-Arab"
                ],
                "accuracy": 0.9960474308300395,
                "f1": 0.994729907773386,
                "main_score": 0.994729907773386,
                "precision": 0.9940711462450593,
                "recall": 0.9960474308300395
            },
            {
                "hf_subset": "rus_Cyrl-bul_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "bul-Cyrl"
                ],
                "accuracy": 0.9970355731225297,
                "f1": 0.9960474308300395,
                "main_score": 0.9960474308300395,
                "precision": 0.9955533596837944,
                "recall": 0.9970355731225297
            },
            {
                "hf_subset": "rus_Cyrl-fra_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fra-Latn"
                ],
                "accuracy": 0.9960474308300395,
                "f1": 0.9947299077733861,
                "main_score": 0.9947299077733861,
                "precision": 0.9940711462450593,
                "recall": 0.9960474308300395
            },
            {
                "hf_subset": "rus_Cyrl-jpn_Jpan",
                "languages": [
                    "rus-Cyrl",
                    "jpn-Jpan"
                ],
                "accuracy": 0.9644268774703558,
                "f1": 0.9530632411067194,
                "main_score": 0.9530632411067194,
                "precision": 0.9476284584980238,
                "recall": 0.9644268774703558
            },
            {
                "hf_subset": "rus_Cyrl-lij_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lij-Latn"
                ],
                "accuracy": 0.9021739130434783,
                "f1": 0.874703557312253,
                "main_score": 0.874703557312253,
                "precision": 0.8629611330698288,
                "recall": 0.9021739130434783
            },
            {
                "hf_subset": "rus_Cyrl-mya_Mymr",
                "languages": [
                    "rus-Cyrl",
                    "mya-Mymr"
                ],
                "accuracy": 0.9802371541501976,
                "f1": 0.9736495388669301,
                "main_score": 0.9736495388669301,
                "precision": 0.9703557312252964,
                "recall": 0.9802371541501976
            },
            {
                "hf_subset": "rus_Cyrl-sag_Latn",
                "languages": [
                    "rus-Cyrl",
                    "sag-Latn"
                ],
                "accuracy": 0.5484189723320159,
                "f1": 0.49618820375033496,
                "main_score": 0.49618820375033496,
                "precision": 0.478319687558818,
                "recall": 0.5484189723320159
            },
            {
                "hf_subset": "rus_Cyrl-taq_Tfng",
                "languages": [
                    "rus-Cyrl",
                    "taq-Tfng"
                ],
                "accuracy": 0.15316205533596838,
                "f1": 0.11614836360389717,
                "main_score": 0.11614836360389717,
                "precision": 0.10741446193235223,
                "recall": 0.15316205533596838
            },
            {
                "hf_subset": "rus_Cyrl-wol_Latn",
                "languages": [
                    "rus-Cyrl",
                    "wol-Latn"
                ],
                "accuracy": 0.6788537549407114,
                "f1": 0.622536417249856,
                "main_score": 0.622536417249856,
                "precision": 0.6027629128666678,
                "recall": 0.6788537549407114
            },
            {
                "hf_subset": "rus_Cyrl-arb_Latn",
                "languages": [
                    "rus-Cyrl",
                    "arb-Latn"
                ],
                "accuracy": 0.2776679841897233,
                "f1": 0.23396748896240768,
                "main_score": 0.23396748896240768,
                "precision": 0.2228521155585345,
                "recall": 0.2776679841897233
            },
            {
                "hf_subset": "rus_Cyrl-cat_Latn",
                "languages": [
                    "rus-Cyrl",
                    "cat-Latn"
                ],
                "accuracy": 0.9723320158102767,
                "f1": 0.9642151326933935,
                "main_score": 0.9642151326933935,
                "precision": 0.9604743083003953,
                "recall": 0.9723320158102767
            },
            {
                "hf_subset": "rus_Cyrl-fur_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fur-Latn"
                ],
                "accuracy": 0.8863636363636364,
                "f1": 0.8580792396009788,
                "main_score": 0.8580792396009788,
                "precision": 0.8461508901726293,
                "recall": 0.8863636363636364
            },
            {
                "hf_subset": "rus_Cyrl-kab_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kab-Latn"
                ],
                "accuracy": 0.48122529644268774,
                "f1": 0.43053875829710664,
                "main_score": 0.43053875829710664,
                "precision": 0.4144165117538212,
                "recall": 0.48122529644268774
            },
            {
                "hf_subset": "rus_Cyrl-lim_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lim-Latn"
                ],
                "accuracy": 0.8181818181818182,
                "f1": 0.7781676163099087,
                "main_score": 0.7781676163099087,
                "precision": 0.7619565217391304,
                "recall": 0.8181818181818182
            },
            {
                "hf_subset": "rus_Cyrl-nld_Latn",
                "languages": [
                    "rus-Cyrl",
                    "nld-Latn"
                ],
                "accuracy": 0.9733201581027668,
                "f1": 0.964756258234519,
                "main_score": 0.964756258234519,
                "precision": 0.9606389986824769,
                "recall": 0.9733201581027668
            },
            {
                "hf_subset": "rus_Cyrl-san_Deva",
                "languages": [
                    "rus-Cyrl",
                    "san-Deva"
                ],
                "accuracy": 0.9347826086956522,
                "f1": 0.9170289855072462,
                "main_score": 0.9170289855072462,
                "precision": 0.909370882740448,
                "recall": 0.9347826086956522
            },
            {
                "hf_subset": "rus_Cyrl-tat_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "tat-Cyrl"
                ],
                "accuracy": 0.9772727272727273,
                "f1": 0.9700263504611332,
                "main_score": 0.9700263504611332,
                "precision": 0.9665678524374176,
                "recall": 0.9772727272727273
            },
            {
                "hf_subset": "rus_Cyrl-xho_Latn",
                "languages": [
                    "rus-Cyrl",
                    "xho-Latn"
                ],
                "accuracy": 0.9308300395256918,
                "f1": 0.9112977602108036,
                "main_score": 0.9112977602108036,
                "precision": 0.9022562582345192,
                "recall": 0.9308300395256918
            },
            {
                "hf_subset": "rus_Cyrl-ars_Arab",
                "languages": [
                    "rus-Cyrl",
                    "ars-Arab"
                ],
                "accuracy": 0.9940711462450593,
                "f1": 0.9920948616600791,
                "main_score": 0.9920948616600791,
                "precision": 0.9911067193675891,
                "recall": 0.9940711462450593
            },
            {
                "hf_subset": "rus_Cyrl-ceb_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ceb-Latn"
                ],
                "accuracy": 0.9565217391304348,
                "f1": 0.9435441370223979,
                "main_score": 0.9435441370223979,
                "precision": 0.9376646903820817,
                "recall": 0.9565217391304348
            },
            {
                "hf_subset": "rus_Cyrl-fuv_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fuv-Latn"
                ],
                "accuracy": 0.5118577075098815,
                "f1": 0.445990252610806,
                "main_score": 0.445990252610806,
                "precision": 0.42343315994501773,
                "recall": 0.5118577075098815
            },
            {
                "hf_subset": "rus_Cyrl-kac_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kac-Latn"
                ],
                "accuracy": 0.46936758893280633,
                "f1": 0.41790040187017874,
                "main_score": 0.41790040187017874,
                "precision": 0.4024335566239262,
                "recall": 0.46936758893280633
            },
            {
                "hf_subset": "rus_Cyrl-lin_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lin-Latn"
                ],
                "accuracy": 0.9150197628458498,
                "f1": 0.891205533596838,
                "main_score": 0.891205533596838,
                "precision": 0.8807147562582345,
                "recall": 0.9150197628458498
            },
            {
                "hf_subset": "rus_Cyrl-nno_Latn",
                "languages": [
                    "rus-Cyrl",
                    "nno-Latn"
                ],
                "accuracy": 0.9881422924901186,
                "f1": 0.9841897233201581,
                "main_score": 0.9841897233201581,
                "precision": 0.9822134387351779,
                "recall": 0.9881422924901186
            },
            {
                "hf_subset": "rus_Cyrl-sat_Olck",
                "languages": [
                    "rus-Cyrl",
                    "sat-Olck"
                ],
                "accuracy": 0.02371541501976284,
                "f1": 0.010726274943087382,
                "main_score": 0.010726274943087382,
                "precision": 0.00875279634748803,
                "recall": 0.02371541501976284
            },
            {
                "hf_subset": "rus_Cyrl-tel_Telu",
                "languages": [
                    "rus-Cyrl",
                    "tel-Telu"
                ],
                "accuracy": 0.9901185770750988,
                "f1": 0.9868247694334652,
                "main_score": 0.9868247694334652,
                "precision": 0.9851778656126481,
                "recall": 0.9901185770750988
            },
            {
                "hf_subset": "rus_Cyrl-ydd_Hebr",
                "languages": [
                    "rus-Cyrl",
                    "ydd-Hebr"
                ],
                "accuracy": 0.8942687747035574,
                "f1": 0.8647609636740072,
                "main_score": 0.8647609636740072,
                "precision": 0.8513669301712781,
                "recall": 0.8942687747035574
            },
            {
                "hf_subset": "rus_Cyrl-ary_Arab",
                "languages": [
                    "rus-Cyrl",
                    "ary-Arab"
                ],
                "accuracy": 0.8982213438735178,
                "f1": 0.8704545454545456,
                "main_score": 0.8704545454545456,
                "precision": 0.8576910408432148,
                "recall": 0.8982213438735178
            },
            {
                "hf_subset": "rus_Cyrl-ces_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ces-Latn"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.989459815546772,
                "main_score": 0.989459815546772,
                "precision": 0.9881422924901186,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "rus_Cyrl-gaz_Latn",
                "languages": [
                    "rus-Cyrl",
                    "gaz-Latn"
                ],
                "accuracy": 0.6492094861660079,
                "f1": 0.5869745811939487,
                "main_score": 0.5869745811939487,
                "precision": 0.5643402189597841,
                "recall": 0.6492094861660079
            },
            {
                "hf_subset": "rus_Cyrl-kam_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kam-Latn"
                ],
                "accuracy": 0.591897233201581,
                "f1": 0.5319031511966295,
                "main_score": 0.5319031511966295,
                "precision": 0.5108128357343655,
                "recall": 0.591897233201581
            },
            {
                "hf_subset": "rus_Cyrl-lit_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lit-Latn"
                ],
                "accuracy": 0.9654150197628458,
                "f1": 0.9553689064558629,
                "main_score": 0.9553689064558629,
                "precision": 0.950592885375494,
                "recall": 0.9654150197628458
            },
            {
                "hf_subset": "rus_Cyrl-nob_Latn",
                "languages": [
                    "rus-Cyrl",
                    "nob-Latn"
                ],
                "accuracy": 0.9812252964426879,
                "f1": 0.9751317523056655,
                "main_score": 0.9751317523056655,
                "precision": 0.972167325428195,
                "recall": 0.9812252964426879
            },
            {
                "hf_subset": "rus_Cyrl-scn_Latn",
                "languages": [
                    "rus-Cyrl",
                    "scn-Latn"
                ],
                "accuracy": 0.8409090909090909,
                "f1": 0.8037000439174352,
                "main_score": 0.8037000439174352,
                "precision": 0.7883994628559846,
                "recall": 0.8409090909090909
            },
            {
                "hf_subset": "rus_Cyrl-tgk_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "tgk-Cyrl"
                ],
                "accuracy": 0.9268774703557312,
                "f1": 0.9086344814605684,
                "main_score": 0.9086344814605684,
                "precision": 0.9012516469038208,
                "recall": 0.9268774703557312
            },
            {
                "hf_subset": "rus_Cyrl-yor_Latn",
                "languages": [
                    "rus-Cyrl",
                    "yor-Latn"
                ],
                "accuracy": 0.7213438735177866,
                "f1": 0.6678759646150951,
                "main_score": 0.6678759646150951,
                "precision": 0.6485080192096002,
                "recall": 0.7213438735177866
            },
            {
                "hf_subset": "rus_Cyrl-arz_Arab",
                "languages": [
                    "rus-Cyrl",
                    "arz-Arab"
                ],
                "accuracy": 0.9802371541501976,
                "f1": 0.9736495388669301,
                "main_score": 0.9736495388669301,
                "precision": 0.9703557312252964,
                "recall": 0.9802371541501976
            },
            {
                "hf_subset": "rus_Cyrl-cjk_Latn",
                "languages": [
                    "rus-Cyrl",
                    "cjk-Latn"
                ],
                "accuracy": 0.5197628458498024,
                "f1": 0.4646876235314971,
                "main_score": 0.4646876235314971,
                "precision": 0.4464073366247278,
                "recall": 0.5197628458498024
            },
            {
                "hf_subset": "rus_Cyrl-gla_Latn",
                "languages": [
                    "rus-Cyrl",
                    "gla-Latn"
                ],
                "accuracy": 0.7974308300395256,
                "f1": 0.7555611165294959,
                "main_score": 0.7555611165294959,
                "precision": 0.7395033408620365,
                "recall": 0.7974308300395256
            },
            {
                "hf_subset": "rus_Cyrl-kan_Knda",
                "languages": [
                    "rus-Cyrl",
                    "kan-Knda"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.9896245059288538,
                "main_score": 0.9896245059288538,
                "precision": 0.9884716732542819,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "rus_Cyrl-lmo_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lmo-Latn"
                ],
                "accuracy": 0.8241106719367589,
                "f1": 0.7856413514022209,
                "main_score": 0.7856413514022209,
                "precision": 0.7715313068573938,
                "recall": 0.8241106719367589
            },
            {
                "hf_subset": "rus_Cyrl-npi_Deva",
                "languages": [
                    "rus-Cyrl",
                    "npi-Deva"
                ],
                "accuracy": 0.9871541501976284,
                "f1": 0.983201581027668,
                "main_score": 0.983201581027668,
                "precision": 0.9812252964426879,
                "recall": 0.9871541501976284
            },
            {
                "hf_subset": "rus_Cyrl-shn_Mymr",
                "languages": [
                    "rus-Cyrl",
                    "shn-Mymr"
                ],
                "accuracy": 0.5711462450592886,
                "f1": 0.5151361369197337,
                "main_score": 0.5151361369197337,
                "precision": 0.49718600436495725,
                "recall": 0.5711462450592886
            },
            {
                "hf_subset": "rus_Cyrl-tgl_Latn",
                "languages": [
                    "rus-Cyrl",
                    "tgl-Latn"
                ],
                "accuracy": 0.9782608695652173,
                "f1": 0.9718379446640316,
                "main_score": 0.9718379446640316,
                "precision": 0.9688735177865613,
                "recall": 0.9782608695652173
            },
            {
                "hf_subset": "rus_Cyrl-yue_Hant",
                "languages": [
                    "rus-Cyrl",
                    "yue-Hant"
                ],
                "accuracy": 0.9930830039525692,
                "f1": 0.9909420289855072,
                "main_score": 0.9909420289855072,
                "precision": 0.9899538866930171,
                "recall": 0.9930830039525692
            },
            {
                "hf_subset": "rus_Cyrl-asm_Beng",
                "languages": [
                    "rus-Cyrl",
                    "asm-Beng"
                ],
                "accuracy": 0.9555335968379447,
                "f1": 0.9416007905138339,
                "main_score": 0.9416007905138339,
                "precision": 0.9350296442687747,
                "recall": 0.9555335968379447
            },
            {
                "hf_subset": "rus_Cyrl-ckb_Arab",
                "languages": [
                    "rus-Cyrl",
                    "ckb-Arab"
                ],
                "accuracy": 0.9288537549407114,
                "f1": 0.9076745718050065,
                "main_score": 0.9076745718050065,
                "precision": 0.8980072463768116,
                "recall": 0.9288537549407114
            },
            {
                "hf_subset": "rus_Cyrl-gle_Latn",
                "languages": [
                    "rus-Cyrl",
                    "gle-Latn"
                ],
                "accuracy": 0.91699604743083,
                "f1": 0.8940899680030115,
                "main_score": 0.8940899680030115,
                "precision": 0.8840085638998683,
                "recall": 0.91699604743083
            },
            {
                "hf_subset": "rus_Cyrl-kas_Arab",
                "languages": [
                    "rus-Cyrl",
                    "kas-Arab"
                ],
                "accuracy": 0.8833992094861659,
                "f1": 0.8514351590438548,
                "main_score": 0.8514351590438548,
                "precision": 0.8372364953886692,
                "recall": 0.8833992094861659
            },
            {
                "hf_subset": "rus_Cyrl-ltg_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ltg-Latn"
                ],
                "accuracy": 0.83399209486166,
                "f1": 0.7988408934061106,
                "main_score": 0.7988408934061106,
                "precision": 0.7853794509179884,
                "recall": 0.83399209486166
            },
            {
                "hf_subset": "rus_Cyrl-nso_Latn",
                "languages": [
                    "rus-Cyrl",
                    "nso-Latn"
                ],
                "accuracy": 0.9120553359683794,
                "f1": 0.8895406635525213,
                "main_score": 0.8895406635525213,
                "precision": 0.8801548089591568,
                "recall": 0.9120553359683794
            },
            {
                "hf_subset": "rus_Cyrl-sin_Sinh",
                "languages": [
                    "rus-Cyrl",
                    "sin-Sinh"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.9856719367588933,
                "main_score": 0.9856719367588933,
                "precision": 0.9840250329380763,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "rus_Cyrl-tha_Thai",
                "languages": [
                    "rus-Cyrl",
                    "tha-Thai"
                ],
                "accuracy": 0.9594861660079052,
                "f1": 0.9466403162055336,
                "main_score": 0.9466403162055336,
                "precision": 0.9403820816864296,
                "recall": 0.9594861660079052
            },
            {
                "hf_subset": "rus_Cyrl-zho_Hans",
                "languages": [
                    "rus-Cyrl",
                    "zho-Hans"
                ],
                "accuracy": 0.9743083003952571,
                "f1": 0.9659090909090909,
                "main_score": 0.9659090909090909,
                "precision": 0.9617918313570487,
                "recall": 0.9743083003952571
            },
            {
                "hf_subset": "rus_Cyrl-ast_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ast-Latn"
                ],
                "accuracy": 0.9446640316205532,
                "f1": 0.9286890645586297,
                "main_score": 0.9286890645586297,
                "precision": 0.9214756258234519,
                "recall": 0.9446640316205532
            },
            {
                "hf_subset": "rus_Cyrl-crh_Latn",
                "languages": [
                    "rus-Cyrl",
                    "crh-Latn"
                ],
                "accuracy": 0.9466403162055336,
                "f1": 0.932663592446201,
                "main_score": 0.932663592446201,
                "precision": 0.9266716073781293,
                "recall": 0.9466403162055336
            },
            {
                "hf_subset": "rus_Cyrl-glg_Latn",
                "languages": [
                    "rus-Cyrl",
                    "glg-Latn"
                ],
                "accuracy": 0.9881422924901186,
                "f1": 0.9846837944664031,
                "main_score": 0.9846837944664031,
                "precision": 0.983201581027668,
                "recall": 0.9881422924901186
            },
            {
                "hf_subset": "rus_Cyrl-kas_Deva",
                "languages": [
                    "rus-Cyrl",
                    "kas-Deva"
                ],
                "accuracy": 0.691699604743083,
                "f1": 0.6305505292906477,
                "main_score": 0.6305505292906477,
                "precision": 0.6062594108789761,
                "recall": 0.691699604743083
            },
            {
                "hf_subset": "rus_Cyrl-ltz_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ltz-Latn"
                ],
                "accuracy": 0.9140316205533597,
                "f1": 0.8926571616789009,
                "main_score": 0.8926571616789009,
                "precision": 0.8840179747788443,
                "recall": 0.9140316205533597
            },
            {
                "hf_subset": "rus_Cyrl-nus_Latn",
                "languages": [
                    "rus-Cyrl",
                    "nus-Latn"
                ],
                "accuracy": 0.3893280632411067,
                "f1": 0.3398513032905371,
                "main_score": 0.3398513032905371,
                "precision": 0.32562578848023077,
                "recall": 0.3893280632411067
            },
            {
                "hf_subset": "rus_Cyrl-slk_Latn",
                "languages": [
                    "rus-Cyrl",
                    "slk-Latn"
                ],
                "accuracy": 0.9802371541501976,
                "f1": 0.9742094861660078,
                "main_score": 0.9742094861660078,
                "precision": 0.9714262187088274,
                "recall": 0.9802371541501976
            },
            {
                "hf_subset": "rus_Cyrl-tir_Ethi",
                "languages": [
                    "rus-Cyrl",
                    "tir-Ethi"
                ],
                "accuracy": 0.9130434782608695,
                "f1": 0.8878129117259551,
                "main_score": 0.8878129117259551,
                "precision": 0.8761528326745718,
                "recall": 0.9130434782608695
            },
            {
                "hf_subset": "rus_Cyrl-zho_Hant",
                "languages": [
                    "rus-Cyrl",
                    "zho-Hant"
                ],
                "accuracy": 0.9911067193675891,
                "f1": 0.9881422924901186,
                "main_score": 0.9881422924901186,
                "precision": 0.9866600790513834,
                "recall": 0.9911067193675891
            },
            {
                "hf_subset": "rus_Cyrl-awa_Deva",
                "languages": [
                    "rus-Cyrl",
                    "awa-Deva"
                ],
                "accuracy": 0.9812252964426879,
                "f1": 0.9770092226613966,
                "main_score": 0.9770092226613966,
                "precision": 0.9750494071146245,
                "recall": 0.9812252964426879
            },
            {
                "hf_subset": "rus_Cyrl-cym_Latn",
                "languages": [
                    "rus-Cyrl",
                    "cym-Latn"
                ],
                "accuracy": 0.9594861660079052,
                "f1": 0.9474308300395257,
                "main_score": 0.9474308300395257,
                "precision": 0.9420289855072465,
                "recall": 0.9594861660079052
            },
            {
                "hf_subset": "rus_Cyrl-grn_Latn",
                "languages": [
                    "rus-Cyrl",
                    "grn-Latn"
                ],
                "accuracy": 0.7796442687747036,
                "f1": 0.7364286789187975,
                "main_score": 0.7364286789187975,
                "precision": 0.7199324893260821,
                "recall": 0.7796442687747036
            },
            {
                "hf_subset": "rus_Cyrl-kat_Geor",
                "languages": [
                    "rus-Cyrl",
                    "kat-Geor"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.9856719367588933,
                "main_score": 0.9856719367588933,
                "precision": 0.9840250329380764,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "rus_Cyrl-lua_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lua-Latn"
                ],
                "accuracy": 0.7203557312252964,
                "f1": 0.6723928163404449,
                "main_score": 0.6723928163404449,
                "precision": 0.6530797101449275,
                "recall": 0.7203557312252964
            },
            {
                "hf_subset": "rus_Cyrl-nya_Latn",
                "languages": [
                    "rus-Cyrl",
                    "nya-Latn"
                ],
                "accuracy": 0.9229249011857708,
                "f1": 0.900494071146245,
                "main_score": 0.900494071146245,
                "precision": 0.8904808959156786,
                "recall": 0.9229249011857708
            },
            {
                "hf_subset": "rus_Cyrl-slv_Latn",
                "languages": [
                    "rus-Cyrl",
                    "slv-Latn"
                ],
                "accuracy": 0.9871541501976284,
                "f1": 0.9830368906455863,
                "main_score": 0.9830368906455863,
                "precision": 0.9810606060606061,
                "recall": 0.9871541501976284
            },
            {
                "hf_subset": "rus_Cyrl-tpi_Latn",
                "languages": [
                    "rus-Cyrl",
                    "tpi-Latn"
                ],
                "accuracy": 0.8053359683794468,
                "f1": 0.76594818225253,
                "main_score": 0.76594818225253,
                "precision": 0.7512913223140497,
                "recall": 0.8053359683794468
            },
            {
                "hf_subset": "rus_Cyrl-zsm_Latn",
                "languages": [
                    "rus-Cyrl",
                    "zsm-Latn"
                ],
                "accuracy": 0.9733201581027668,
                "f1": 0.9658620365142104,
                "main_score": 0.9658620365142104,
                "precision": 0.9626152832674572,
                "recall": 0.9733201581027668
            },
            {
                "hf_subset": "rus_Cyrl-ayr_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ayr-Latn"
                ],
                "accuracy": 0.4555335968379446,
                "f1": 0.4013076578531388,
                "main_score": 0.4013076578531388,
                "precision": 0.38398064362362355,
                "recall": 0.4555335968379446
            },
            {
                "hf_subset": "rus_Cyrl-dan_Latn",
                "languages": [
                    "rus-Cyrl",
                    "dan-Latn"
                ],
                "accuracy": 0.9901185770750988,
                "f1": 0.9868247694334652,
                "main_score": 0.9868247694334652,
                "precision": 0.9851778656126481,
                "recall": 0.9901185770750988
            },
            {
                "hf_subset": "rus_Cyrl-guj_Gujr",
                "languages": [
                    "rus-Cyrl",
                    "guj-Gujr"
                ],
                "accuracy": 0.9901185770750988,
                "f1": 0.9868247694334652,
                "main_score": 0.9868247694334652,
                "precision": 0.9851778656126481,
                "recall": 0.9901185770750988
            },
            {
                "hf_subset": "rus_Cyrl-kaz_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "kaz-Cyrl"
                ],
                "accuracy": 0.9881422924901186,
                "f1": 0.9843544137022399,
                "main_score": 0.9843544137022399,
                "precision": 0.9825428194993413,
                "recall": 0.9881422924901186
            },
            {
                "hf_subset": "rus_Cyrl-lug_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lug-Latn"
                ],
                "accuracy": 0.8221343873517788,
                "f1": 0.7797485726833554,
                "main_score": 0.7797485726833554,
                "precision": 0.7622376717485415,
                "recall": 0.8221343873517788
            },
            {
                "hf_subset": "rus_Cyrl-oci_Latn",
                "languages": [
                    "rus-Cyrl",
                    "oci-Latn"
                ],
                "accuracy": 0.9387351778656127,
                "f1": 0.9225319969885187,
                "main_score": 0.9225319969885187,
                "precision": 0.9156385281385281,
                "recall": 0.9387351778656127
            },
            {
                "hf_subset": "rus_Cyrl-smo_Latn",
                "languages": [
                    "rus-Cyrl",
                    "smo-Latn"
                ],
                "accuracy": 0.8488142292490118,
                "f1": 0.8124364765669114,
                "main_score": 0.8124364765669114,
                "precision": 0.7969991416137661,
                "recall": 0.8488142292490118
            },
            {
                "hf_subset": "rus_Cyrl-tsn_Latn",
                "languages": [
                    "rus-Cyrl",
                    "tsn-Latn"
                ],
                "accuracy": 0.8705533596837944,
                "f1": 0.8390645586297761,
                "main_score": 0.8390645586297761,
                "precision": 0.8256752305665348,
                "recall": 0.8705533596837944
            },
            {
                "hf_subset": "rus_Cyrl-zul_Latn",
                "languages": [
                    "rus-Cyrl",
                    "zul-Latn"
                ],
                "accuracy": 0.951581027667984,
                "f1": 0.9377140974967062,
                "main_score": 0.9377140974967062,
                "precision": 0.9316534914361001,
                "recall": 0.951581027667984
            },
            {
                "hf_subset": "rus_Cyrl-azb_Arab",
                "languages": [
                    "rus-Cyrl",
                    "azb-Arab"
                ],
                "accuracy": 0.8191699604743082,
                "f1": 0.7718050065876152,
                "main_score": 0.7718050065876152,
                "precision": 0.7521519543258672,
                "recall": 0.8191699604743082
            },
            {
                "hf_subset": "rus_Cyrl-deu_Latn",
                "languages": [
                    "rus-Cyrl",
                    "deu-Latn"
                ],
                "accuracy": 0.9950592885375493,
                "f1": 0.9934123847167325,
                "main_score": 0.9934123847167325,
                "precision": 0.9925889328063241,
                "recall": 0.9950592885375493
            },
            {
                "hf_subset": "rus_Cyrl-hat_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hat-Latn"
                ],
                "accuracy": 0.9100790513833992,
                "f1": 0.8869126043039085,
                "main_score": 0.8869126043039085,
                "precision": 0.8775774044795784,
                "recall": 0.9100790513833992
            },
            {
                "hf_subset": "rus_Cyrl-kbp_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kbp-Latn"
                ],
                "accuracy": 0.4723320158102766,
                "f1": 0.4301118618096943,
                "main_score": 0.4301118618096943,
                "precision": 0.41739069205043555,
                "recall": 0.4723320158102766
            },
            {
                "hf_subset": "rus_Cyrl-luo_Latn",
                "languages": [
                    "rus-Cyrl",
                    "luo-Latn"
                ],
                "accuracy": 0.6047430830039525,
                "f1": 0.5483210565429816,
                "main_score": 0.5483210565429816,
                "precision": 0.5281630744284779,
                "recall": 0.6047430830039525
            },
            {
                "hf_subset": "rus_Cyrl-ory_Orya",
                "languages": [
                    "rus-Cyrl",
                    "ory-Orya"
                ],
                "accuracy": 0.9911067193675891,
                "f1": 0.9883069828722003,
                "main_score": 0.9883069828722003,
                "precision": 0.9869894598155468,
                "recall": 0.9911067193675891
            },
            {
                "hf_subset": "rus_Cyrl-sna_Latn",
                "languages": [
                    "rus-Cyrl",
                    "sna-Latn"
                ],
                "accuracy": 0.8972332015810277,
                "f1": 0.8730013645774514,
                "main_score": 0.8730013645774514,
                "precision": 0.8625329380764163,
                "recall": 0.8972332015810277
            },
            {
                "hf_subset": "rus_Cyrl-tso_Latn",
                "languages": [
                    "rus-Cyrl",
                    "tso-Latn"
                ],
                "accuracy": 0.8438735177865613,
                "f1": 0.8070424744337789,
                "main_score": 0.8070424744337789,
                "precision": 0.7918560606060606,
                "recall": 0.8438735177865613
            },
            {
                "hf_subset": "rus_Cyrl-azj_Latn",
                "languages": [
                    "rus-Cyrl",
                    "azj-Latn"
                ],
                "accuracy": 0.9733201581027668,
                "f1": 0.9656455862977602,
                "main_score": 0.9656455862977602,
                "precision": 0.9623682476943345,
                "recall": 0.9733201581027668
            },
            {
                "hf_subset": "rus_Cyrl-dik_Latn",
                "languages": [
                    "rus-Cyrl",
                    "dik-Latn"
                ],
                "accuracy": 0.46047430830039526,
                "f1": 0.4005513069495283,
                "main_score": 0.4005513069495283,
                "precision": 0.38072590197096123,
                "recall": 0.46047430830039526
            },
            {
                "hf_subset": "rus_Cyrl-hau_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hau-Latn"
                ],
                "accuracy": 0.8794466403162056,
                "f1": 0.8476943346508563,
                "main_score": 0.8476943346508563,
                "precision": 0.8334486166007905,
                "recall": 0.8794466403162056
            },
            {
                "hf_subset": "rus_Cyrl-kea_Latn",
                "languages": [
                    "rus-Cyrl",
                    "kea-Latn"
                ],
                "accuracy": 0.8942687747035574,
                "f1": 0.8683803021747685,
                "main_score": 0.8683803021747685,
                "precision": 0.8578416149068323,
                "recall": 0.8942687747035574
            },
            {
                "hf_subset": "rus_Cyrl-lus_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lus-Latn"
                ],
                "accuracy": 0.6897233201581028,
                "f1": 0.6405480726292745,
                "main_score": 0.6405480726292745,
                "precision": 0.6242670749487857,
                "recall": 0.6897233201581028
            },
            {
                "hf_subset": "rus_Cyrl-pag_Latn",
                "languages": [
                    "rus-Cyrl",
                    "pag-Latn"
                ],
                "accuracy": 0.7875494071146245,
                "f1": 0.7458573558401933,
                "main_score": 0.7458573558401933,
                "precision": 0.7305532028358115,
                "recall": 0.7875494071146245
            },
            {
                "hf_subset": "rus_Cyrl-snd_Arab",
                "languages": [
                    "rus-Cyrl",
                    "snd-Arab"
                ],
                "accuracy": 0.958498023715415,
                "f1": 0.9456521739130435,
                "main_score": 0.9456521739130435,
                "precision": 0.9397233201581028,
                "recall": 0.958498023715415
            },
            {
                "hf_subset": "rus_Cyrl-tuk_Latn",
                "languages": [
                    "rus-Cyrl",
                    "tuk-Latn"
                ],
                "accuracy": 0.6808300395256918,
                "f1": 0.6293565240205556,
                "main_score": 0.6293565240205556,
                "precision": 0.6119159025704394,
                "recall": 0.6808300395256918
            },
            {
                "hf_subset": "rus_Cyrl-bak_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "bak-Cyrl"
                ],
                "accuracy": 0.9604743083003953,
                "f1": 0.9486824769433464,
                "main_score": 0.9486824769433464,
                "precision": 0.9434288537549407,
                "recall": 0.9604743083003953
            },
            {
                "hf_subset": "rus_Cyrl-dyu_Latn",
                "languages": [
                    "rus-Cyrl",
                    "dyu-Latn"
                ],
                "accuracy": 0.37450592885375494,
                "f1": 0.3167048231280081,
                "main_score": 0.3167048231280081,
                "precision": 0.2999928568357422,
                "recall": 0.37450592885375494
            },
            {
                "hf_subset": "rus_Cyrl-heb_Hebr",
                "languages": [
                    "rus-Cyrl",
                    "heb-Hebr"
                ],
                "accuracy": 0.9723320158102767,
                "f1": 0.9638998682476942,
                "main_score": 0.9638998682476942,
                "precision": 0.9599802371541502,
                "recall": 0.9723320158102767
            },
            {
                "hf_subset": "rus_Cyrl-khk_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "khk-Cyrl"
                ],
                "accuracy": 0.9841897233201581,
                "f1": 0.9800724637681157,
                "main_score": 0.9800724637681157,
                "precision": 0.9782938076416337,
                "recall": 0.9841897233201581
            },
            {
                "hf_subset": "rus_Cyrl-lvs_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lvs-Latn"
                ],
                "accuracy": 0.9743083003952571,
                "f1": 0.9661396574440053,
                "main_score": 0.9661396574440053,
                "precision": 0.9622035573122529,
                "recall": 0.9743083003952571
            },
            {
                "hf_subset": "rus_Cyrl-pan_Guru",
                "languages": [
                    "rus-Cyrl",
                    "pan-Guru"
                ],
                "accuracy": 0.9930830039525692,
                "f1": 0.9907773386034257,
                "main_score": 0.9907773386034257,
                "precision": 0.9896245059288538,
                "recall": 0.9930830039525692
            },
            {
                "hf_subset": "rus_Cyrl-som_Latn",
                "languages": [
                    "rus-Cyrl",
                    "som-Latn"
                ],
                "accuracy": 0.8774703557312253,
                "f1": 0.8452898550724638,
                "main_score": 0.8452898550724638,
                "precision": 0.830928853754941,
                "recall": 0.8774703557312253
            },
            {
                "hf_subset": "rus_Cyrl-tum_Latn",
                "languages": [
                    "rus-Cyrl",
                    "tum-Latn"
                ],
                "accuracy": 0.8715415019762845,
                "f1": 0.8385069640504424,
                "main_score": 0.8385069640504424,
                "precision": 0.8243671183888576,
                "recall": 0.8715415019762845
            },
            {
                "hf_subset": "taq_Latn-rus_Cyrl",
                "languages": [
                    "taq-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.2855731225296443,
                "f1": 0.2681072636004957,
                "main_score": 0.2681072636004957,
                "precision": 0.2626034285826558,
                "recall": 0.2855731225296443
            },
            {
                "hf_subset": "war_Latn-rus_Cyrl",
                "languages": [
                    "war-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9486166007905138,
                "f1": 0.9403147083483051,
                "main_score": 0.9403147083483051,
                "precision": 0.9370653606003322,
                "recall": 0.9486166007905138
            },
            {
                "hf_subset": "arb_Arab-rus_Cyrl",
                "languages": [
                    "arb-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9634387351778656,
                "f1": 0.9523056653491436,
                "main_score": 0.9523056653491436,
                "precision": 0.9470520421607378,
                "recall": 0.9634387351778656
            },
            {
                "hf_subset": "bul_Cyrl-rus_Cyrl",
                "languages": [
                    "bul-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9990118577075099,
                "f1": 0.9986824769433464,
                "main_score": 0.9986824769433464,
                "precision": 0.9985177865612649,
                "recall": 0.9990118577075099
            },
            {
                "hf_subset": "fra_Latn-rus_Cyrl",
                "languages": [
                    "fra-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.989459815546772,
                "main_score": 0.989459815546772,
                "precision": 0.9881422924901186,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "jpn_Jpan-rus_Cyrl",
                "languages": [
                    "jpn-Jpan",
                    "rus-Cyrl"
                ],
                "accuracy": 0.983201581027668,
                "f1": 0.9776021080368905,
                "main_score": 0.9776021080368905,
                "precision": 0.9748023715415018,
                "recall": 0.983201581027668
            },
            {
                "hf_subset": "lij_Latn-rus_Cyrl",
                "languages": [
                    "lij-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8349802371541502,
                "f1": 0.8164800059239635,
                "main_score": 0.8164800059239635,
                "precision": 0.809443055878478,
                "recall": 0.8349802371541502
            },
            {
                "hf_subset": "mya_Mymr-rus_Cyrl",
                "languages": [
                    "mya-Mymr",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9021739130434783,
                "f1": 0.8876776366313682,
                "main_score": 0.8876776366313682,
                "precision": 0.8818370446119436,
                "recall": 0.9021739130434783
            },
            {
                "hf_subset": "sag_Latn-rus_Cyrl",
                "languages": [
                    "sag-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.41699604743083,
                "f1": 0.3953066322643847,
                "main_score": 0.3953066322643847,
                "precision": 0.38822876239229276,
                "recall": 0.41699604743083
            },
            {
                "hf_subset": "taq_Tfng-rus_Cyrl",
                "languages": [
                    "taq-Tfng",
                    "rus-Cyrl"
                ],
                "accuracy": 0.1067193675889328,
                "f1": 0.09205744965817951,
                "main_score": 0.09205744965817951,
                "precision": 0.08851952190738172,
                "recall": 0.1067193675889328
            },
            {
                "hf_subset": "wol_Latn-rus_Cyrl",
                "languages": [
                    "wol-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6353754940711462,
                "f1": 0.6065190727391827,
                "main_score": 0.6065190727391827,
                "precision": 0.5961144833427442,
                "recall": 0.6353754940711462
            },
            {
                "hf_subset": "arb_Latn-rus_Cyrl",
                "languages": [
                    "arb-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.13142292490118576,
                "f1": 0.12372910318176764,
                "main_score": 0.12372910318176764,
                "precision": 0.12197580895919188,
                "recall": 0.13142292490118576
            },
            {
                "hf_subset": "cat_Latn-rus_Cyrl",
                "languages": [
                    "cat-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9901185770750988,
                "f1": 0.9880599472990776,
                "main_score": 0.9880599472990776,
                "precision": 0.9872953133822697,
                "recall": 0.9901185770750988
            },
            {
                "hf_subset": "fur_Latn-rus_Cyrl",
                "languages": [
                    "fur-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8102766798418972,
                "f1": 0.7936184294084613,
                "main_score": 0.7936184294084613,
                "precision": 0.7869187826527706,
                "recall": 0.8102766798418972
            },
            {
                "hf_subset": "kab_Latn-rus_Cyrl",
                "languages": [
                    "kab-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.3438735177865613,
                "f1": 0.3202306921576947,
                "main_score": 0.3202306921576947,
                "precision": 0.3124667034713747,
                "recall": 0.3438735177865613
            },
            {
                "hf_subset": "lim_Latn-rus_Cyrl",
                "languages": [
                    "lim-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.782608695652174,
                "f1": 0.7590239449214359,
                "main_score": 0.7590239449214359,
                "precision": 0.7502211430745492,
                "recall": 0.782608695652174
            },
            {
                "hf_subset": "nld_Latn-rus_Cyrl",
                "languages": [
                    "nld-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.989459815546772,
                "main_score": 0.989459815546772,
                "precision": 0.9881422924901186,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "san_Deva-rus_Cyrl",
                "languages": [
                    "san-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8794466403162056,
                "f1": 0.8668928897189767,
                "main_score": 0.8668928897189767,
                "precision": 0.8623822997079216,
                "recall": 0.8794466403162056
            },
            {
                "hf_subset": "tat_Cyrl-rus_Cyrl",
                "languages": [
                    "tat-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9703557312252964,
                "f1": 0.9641673653531361,
                "main_score": 0.9641673653531361,
                "precision": 0.9616847826086957,
                "recall": 0.9703557312252964
            },
            {
                "hf_subset": "xho_Latn-rus_Cyrl",
                "languages": [
                    "xho-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8695652173913043,
                "f1": 0.855506497283435,
                "main_score": 0.855506497283435,
                "precision": 0.8495270479733396,
                "recall": 0.8695652173913043
            },
            {
                "hf_subset": "ars_Arab-rus_Cyrl",
                "languages": [
                    "ars-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9664031620553359,
                "f1": 0.9560935441370223,
                "main_score": 0.9560935441370223,
                "precision": 0.9513339920948617,
                "recall": 0.9664031620553359
            },
            {
                "hf_subset": "ceb_Latn-rus_Cyrl",
                "languages": [
                    "ceb-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.957509881422925,
                "f1": 0.9505209198303827,
                "main_score": 0.9505209198303827,
                "precision": 0.9477662283368805,
                "recall": 0.957509881422925
            },
            {
                "hf_subset": "fuv_Latn-rus_Cyrl",
                "languages": [
                    "fuv-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.4525691699604743,
                "f1": 0.42285666666742366,
                "main_score": 0.42285666666742366,
                "precision": 0.4121979853402283,
                "recall": 0.4525691699604743
            },
            {
                "hf_subset": "kac_Latn-rus_Cyrl",
                "languages": [
                    "kac-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.3468379446640316,
                "f1": 0.33323534622903095,
                "main_score": 0.33323534622903095,
                "precision": 0.3294673924616852,
                "recall": 0.3468379446640316
            },
            {
                "hf_subset": "lin_Latn-rus_Cyrl",
                "languages": [
                    "lin-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8685770750988142,
                "f1": 0.851867110799439,
                "main_score": 0.851867110799439,
                "precision": 0.8453038212173273,
                "recall": 0.8685770750988142
            },
            {
                "hf_subset": "nno_Latn-rus_Cyrl",
                "languages": [
                    "nno-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9743083003952571,
                "f1": 0.9678383210991907,
                "main_score": 0.9678383210991907,
                "precision": 0.9651185770750988,
                "recall": 0.9743083003952571
            },
            {
                "hf_subset": "sat_Olck-rus_Cyrl",
                "languages": [
                    "sat-Olck",
                    "rus-Cyrl"
                ],
                "accuracy": 0.01185770750988142,
                "f1": 0.010279253129117259,
                "main_score": 0.010279253129117259,
                "precision": 0.010129746819135175,
                "recall": 0.01185770750988142
            },
            {
                "hf_subset": "tel_Telu-rus_Cyrl",
                "languages": [
                    "tel-Telu",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9812252964426879,
                "f1": 0.9761198945981555,
                "main_score": 0.9761198945981555,
                "precision": 0.97401185770751,
                "recall": 0.9812252964426879
            },
            {
                "hf_subset": "ydd_Hebr-rus_Cyrl",
                "languages": [
                    "ydd-Hebr",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7588932806324109,
                "f1": 0.7400244008018511,
                "main_score": 0.7400244008018511,
                "precision": 0.7325683020960382,
                "recall": 0.7588932806324109
            },
            {
                "hf_subset": "ary_Arab-rus_Cyrl",
                "languages": [
                    "ary-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8656126482213439,
                "f1": 0.8372796285839764,
                "main_score": 0.8372796285839764,
                "precision": 0.8265014273166448,
                "recall": 0.8656126482213439
            },
            {
                "hf_subset": "ces_Latn-rus_Cyrl",
                "languages": [
                    "ces-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9960474308300395,
                "f1": 0.994729907773386,
                "main_score": 0.994729907773386,
                "precision": 0.9940711462450593,
                "recall": 0.9960474308300395
            },
            {
                "hf_subset": "gaz_Latn-rus_Cyrl",
                "languages": [
                    "gaz-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.4258893280632411,
                "f1": 0.40758328668059784,
                "main_score": 0.40758328668059784,
                "precision": 0.4014285046917723,
                "recall": 0.4258893280632411
            },
            {
                "hf_subset": "kam_Latn-rus_Cyrl",
                "languages": [
                    "kam-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.4525691699604743,
                "f1": 0.426975518029456,
                "main_score": 0.426975518029456,
                "precision": 0.41874727109845966,
                "recall": 0.4525691699604743
            },
            {
                "hf_subset": "lit_Latn-rus_Cyrl",
                "languages": [
                    "lit-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9733201581027668,
                "f1": 0.9662384716732543,
                "main_score": 0.9662384716732543,
                "precision": 0.963175230566535,
                "recall": 0.9733201581027668
            },
            {
                "hf_subset": "nob_Latn-rus_Cyrl",
                "languages": [
                    "nob-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9871541501976284,
                "f1": 0.9830368906455863,
                "main_score": 0.9830368906455863,
                "precision": 0.9810606060606061,
                "recall": 0.9871541501976284
            },
            {
                "hf_subset": "scn_Latn-rus_Cyrl",
                "languages": [
                    "scn-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7045454545454546,
                "f1": 0.6862561022640076,
                "main_score": 0.6862561022640076,
                "precision": 0.6795229103411222,
                "recall": 0.7045454545454546
            },
            {
                "hf_subset": "tgk_Cyrl-rus_Cyrl",
                "languages": [
                    "tgk-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.924901185770751,
                "f1": 0.9158514492753623,
                "main_score": 0.9158514492753623,
                "precision": 0.9124759298672341,
                "recall": 0.924901185770751
            },
            {
                "hf_subset": "yor_Latn-rus_Cyrl",
                "languages": [
                    "yor-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6798418972332015,
                "f1": 0.6472874247330768,
                "main_score": 0.6472874247330768,
                "precision": 0.6345082339993868,
                "recall": 0.6798418972332015
            },
            {
                "hf_subset": "arz_Arab-rus_Cyrl",
                "languages": [
                    "arz-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9456521739130435,
                "f1": 0.9307971014492754,
                "main_score": 0.9307971014492754,
                "precision": 0.9242753623188407,
                "recall": 0.9456521739130435
            },
            {
                "hf_subset": "cjk_Latn-rus_Cyrl",
                "languages": [
                    "cjk-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.38636363636363635,
                "f1": 0.36257471408629377,
                "main_score": 0.36257471408629377,
                "precision": 0.35491013550747236,
                "recall": 0.38636363636363635
            },
            {
                "hf_subset": "gla_Latn-rus_Cyrl",
                "languages": [
                    "gla-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6926877470355731,
                "f1": 0.6611797423328614,
                "main_score": 0.6611797423328614,
                "precision": 0.6489369649409694,
                "recall": 0.6926877470355731
            },
            {
                "hf_subset": "kan_Knda-rus_Cyrl",
                "languages": [
                    "kan-Knda",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9802371541501976,
                "f1": 0.9751505740636176,
                "main_score": 0.9751505740636176,
                "precision": 0.9730731225296442,
                "recall": 0.9802371541501976
            },
            {
                "hf_subset": "lmo_Latn-rus_Cyrl",
                "languages": [
                    "lmo-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.733201581027668,
                "f1": 0.7106371608677273,
                "main_score": 0.7106371608677273,
                "precision": 0.7026320288266222,
                "recall": 0.733201581027668
            },
            {
                "hf_subset": "npi_Deva-rus_Cyrl",
                "languages": [
                    "npi-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9782608695652173,
                "f1": 0.9736645107198466,
                "main_score": 0.9736645107198466,
                "precision": 0.971772068511199,
                "recall": 0.9782608695652173
            },
            {
                "hf_subset": "shn_Mymr-rus_Cyrl",
                "languages": [
                    "shn-Mymr",
                    "rus-Cyrl"
                ],
                "accuracy": 0.39426877470355737,
                "f1": 0.3716728785513024,
                "main_score": 0.3716728785513024,
                "precision": 0.3656918548278505,
                "recall": 0.39426877470355737
            },
            {
                "hf_subset": "tgl_Latn-rus_Cyrl",
                "languages": [
                    "tgl-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9792490118577075,
                "f1": 0.976378693769998,
                "main_score": 0.976378693769998,
                "precision": 0.9755371440154047,
                "recall": 0.9792490118577075
            },
            {
                "hf_subset": "yue_Hant-rus_Cyrl",
                "languages": [
                    "yue-Hant",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9792490118577075,
                "f1": 0.973833051006964,
                "main_score": 0.973833051006964,
                "precision": 0.9715909090909091,
                "recall": 0.9792490118577075
            },
            {
                "hf_subset": "asm_Beng-rus_Cyrl",
                "languages": [
                    "asm-Beng",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9278656126482212,
                "f1": 0.9176917395296842,
                "main_score": 0.9176917395296842,
                "precision": 0.9138292866553737,
                "recall": 0.9278656126482212
            },
            {
                "hf_subset": "ckb_Arab-rus_Cyrl",
                "languages": [
                    "ckb-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.808300395256917,
                "f1": 0.7917664345468799,
                "main_score": 0.7917664345468799,
                "precision": 0.7856221716834589,
                "recall": 0.808300395256917
            },
            {
                "hf_subset": "gle_Latn-rus_Cyrl",
                "languages": [
                    "gle-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8586956521739131,
                "f1": 0.8445408265372493,
                "main_score": 0.8445408265372493,
                "precision": 0.838774340026703,
                "recall": 0.8586956521739131
            },
            {
                "hf_subset": "kas_Arab-rus_Cyrl",
                "languages": [
                    "kas-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7628458498023716,
                "f1": 0.7411216313578266,
                "main_score": 0.7411216313578266,
                "precision": 0.732491277759584,
                "recall": 0.7628458498023716
            },
            {
                "hf_subset": "ltg_Latn-rus_Cyrl",
                "languages": [
                    "ltg-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7114624505928853,
                "f1": 0.6869245357723618,
                "main_score": 0.6869245357723618,
                "precision": 0.678135329666459,
                "recall": 0.7114624505928853
            },
            {
                "hf_subset": "nso_Latn-rus_Cyrl",
                "languages": [
                    "nso-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8764822134387351,
                "f1": 0.8598419219986725,
                "main_score": 0.8598419219986725,
                "precision": 0.8532513873917036,
                "recall": 0.8764822134387351
            },
            {
                "hf_subset": "sin_Sinh-rus_Cyrl",
                "languages": [
                    "sin-Sinh",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9762845849802372,
                "f1": 0.9710144927536232,
                "main_score": 0.9710144927536232,
                "precision": 0.9687986585219788,
                "recall": 0.9762845849802372
            },
            {
                "hf_subset": "tha_Thai-rus_Cyrl",
                "languages": [
                    "tha-Thai",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9871541501976284,
                "f1": 0.9828722002635045,
                "main_score": 0.9828722002635045,
                "precision": 0.9807312252964426,
                "recall": 0.9871541501976284
            },
            {
                "hf_subset": "zho_Hans-rus_Cyrl",
                "languages": [
                    "zho-Hans",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9901185770750988,
                "f1": 0.9868247694334652,
                "main_score": 0.9868247694334652,
                "precision": 0.9851778656126481,
                "recall": 0.9901185770750988
            },
            {
                "hf_subset": "ast_Latn-rus_Cyrl",
                "languages": [
                    "ast-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9565217391304348,
                "f1": 0.9490649683857505,
                "main_score": 0.9490649683857505,
                "precision": 0.9461352657004831,
                "recall": 0.9565217391304348
            },
            {
                "hf_subset": "crh_Latn-rus_Cyrl",
                "languages": [
                    "crh-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9308300395256918,
                "f1": 0.9220988998886428,
                "main_score": 0.9220988998886428,
                "precision": 0.9185631013694254,
                "recall": 0.9308300395256918
            },
            {
                "hf_subset": "glg_Latn-rus_Cyrl",
                "languages": [
                    "glg-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9555335968379447,
                "f1": 0.9518006148440931,
                "main_score": 0.9518006148440931,
                "precision": 0.9506540560888387,
                "recall": 0.9555335968379447
            },
            {
                "hf_subset": "kas_Deva-rus_Cyrl",
                "languages": [
                    "kas-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.5503952569169961,
                "f1": 0.5219871938895554,
                "main_score": 0.5219871938895554,
                "precision": 0.5117660971469558,
                "recall": 0.5503952569169961
            },
            {
                "hf_subset": "ltz_Latn-rus_Cyrl",
                "languages": [
                    "ltz-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8764822134387351,
                "f1": 0.8664179841897234,
                "main_score": 0.8664179841897234,
                "precision": 0.8630023235431586,
                "recall": 0.8764822134387351
            },
            {
                "hf_subset": "nus_Latn-rus_Cyrl",
                "languages": [
                    "nus-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.274703557312253,
                "f1": 0.2570301427785809,
                "main_score": 0.2570301427785809,
                "precision": 0.25194105476917317,
                "recall": 0.274703557312253
            },
            {
                "hf_subset": "slk_Latn-rus_Cyrl",
                "languages": [
                    "slk-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9930830039525692,
                "f1": 0.9911067193675891,
                "main_score": 0.9911067193675891,
                "precision": 0.9902832674571804,
                "recall": 0.9930830039525692
            },
            {
                "hf_subset": "tir_Ethi-rus_Cyrl",
                "languages": [
                    "tir-Ethi",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8073122529644269,
                "f1": 0.7866903754775607,
                "main_score": 0.7866903754775607,
                "precision": 0.7786431694163611,
                "recall": 0.8073122529644269
            },
            {
                "hf_subset": "zho_Hant-rus_Cyrl",
                "languages": [
                    "zho-Hant",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9822134387351779,
                "f1": 0.9766798418972332,
                "main_score": 0.9766798418972332,
                "precision": 0.9740612648221344,
                "recall": 0.9822134387351779
            },
            {
                "hf_subset": "awa_Deva-rus_Cyrl",
                "languages": [
                    "awa-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9752964426877471,
                "f1": 0.9694224857268335,
                "main_score": 0.9694224857268335,
                "precision": 0.9668560606060607,
                "recall": 0.9752964426877471
            },
            {
                "hf_subset": "cym_Latn-rus_Cyrl",
                "languages": [
                    "cym-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9268774703557312,
                "f1": 0.9169854302097962,
                "main_score": 0.9169854302097962,
                "precision": 0.9131236846157794,
                "recall": 0.9268774703557312
            },
            {
                "hf_subset": "grn_Latn-rus_Cyrl",
                "languages": [
                    "grn-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6413043478260869,
                "f1": 0.6185058611874,
                "main_score": 0.6185058611874,
                "precision": 0.610049495186209,
                "recall": 0.6413043478260869
            },
            {
                "hf_subset": "kat_Geor-rus_Cyrl",
                "languages": [
                    "kat-Geor",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9802371541501976,
                "f1": 0.9759881422924902,
                "main_score": 0.9759881422924902,
                "precision": 0.9742534036012296,
                "recall": 0.9802371541501976
            },
            {
                "hf_subset": "lua_Latn-rus_Cyrl",
                "languages": [
                    "lua-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6363636363636364,
                "f1": 0.609709122526128,
                "main_score": 0.609709122526128,
                "precision": 0.6003915902282226,
                "recall": 0.6363636363636364
            },
            {
                "hf_subset": "nya_Latn-rus_Cyrl",
                "languages": [
                    "nya-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.892292490118577,
                "f1": 0.8759723824473149,
                "main_score": 0.8759723824473149,
                "precision": 0.8690172707867349,
                "recall": 0.892292490118577
            },
            {
                "hf_subset": "slv_Latn-rus_Cyrl",
                "languages": [
                    "slv-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9901185770750988,
                "f1": 0.9874835309617918,
                "main_score": 0.9874835309617918,
                "precision": 0.9863636363636364,
                "recall": 0.9901185770750988
            },
            {
                "hf_subset": "tpi_Latn-rus_Cyrl",
                "languages": [
                    "tpi-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7737154150197628,
                "f1": 0.7544251611276084,
                "main_score": 0.7544251611276084,
                "precision": 0.7478103665109594,
                "recall": 0.7737154150197628
            },
            {
                "hf_subset": "zsm_Latn-rus_Cyrl",
                "languages": [
                    "zsm-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9920948616600791,
                "f1": 0.9896245059288538,
                "main_score": 0.9896245059288538,
                "precision": 0.988471673254282,
                "recall": 0.9920948616600791
            },
            {
                "hf_subset": "ayr_Latn-rus_Cyrl",
                "languages": [
                    "ayr-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.2776679841897233,
                "f1": 0.2643910319528131,
                "main_score": 0.2643910319528131,
                "precision": 0.26052655604573965,
                "recall": 0.2776679841897233
            },
            {
                "hf_subset": "dan_Latn-rus_Cyrl",
                "languages": [
                    "dan-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9930830039525692,
                "f1": 0.9907773386034254,
                "main_score": 0.9907773386034254,
                "precision": 0.9896245059288538,
                "recall": 0.9930830039525692
            },
            {
                "hf_subset": "guj_Gujr-rus_Cyrl",
                "languages": [
                    "guj-Gujr",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9782608695652173,
                "f1": 0.9726449275362318,
                "main_score": 0.9726449275362318,
                "precision": 0.9702498588368154,
                "recall": 0.9782608695652173
            },
            {
                "hf_subset": "kaz_Cyrl-rus_Cyrl",
                "languages": [
                    "kaz-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9752964426877471,
                "f1": 0.9703557312252964,
                "main_score": 0.9703557312252964,
                "precision": 0.9685022158342317,
                "recall": 0.9752964426877471
            },
            {
                "hf_subset": "lug_Latn-rus_Cyrl",
                "languages": [
                    "lug-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6857707509881423,
                "f1": 0.6593361605820395,
                "main_score": 0.6593361605820395,
                "precision": 0.6490348248593789,
                "recall": 0.6857707509881423
            },
            {
                "hf_subset": "oci_Latn-rus_Cyrl",
                "languages": [
                    "oci-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8626482213438735,
                "f1": 0.8533176417155623,
                "main_score": 0.8533176417155623,
                "precision": 0.8500208833384637,
                "recall": 0.8626482213438735
            },
            {
                "hf_subset": "smo_Latn-rus_Cyrl",
                "languages": [
                    "smo-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7796442687747036,
                "f1": 0.7570960450188885,
                "main_score": 0.7570960450188885,
                "precision": 0.7483126327367771,
                "recall": 0.7796442687747036
            },
            {
                "hf_subset": "tsn_Latn-rus_Cyrl",
                "languages": [
                    "tsn-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8438735177865613,
                "f1": 0.8213656376349224,
                "main_score": 0.8213656376349224,
                "precision": 0.8116794543904519,
                "recall": 0.8438735177865613
            },
            {
                "hf_subset": "zul_Latn-rus_Cyrl",
                "languages": [
                    "zul-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9021739130434783,
                "f1": 0.8877570602050753,
                "main_score": 0.8877570602050753,
                "precision": 0.8815978104021582,
                "recall": 0.9021739130434783
            },
            {
                "hf_subset": "azb_Arab-rus_Cyrl",
                "languages": [
                    "azb-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.657114624505929,
                "f1": 0.6418825390221271,
                "main_score": 0.6418825390221271,
                "precision": 0.6366811154793568,
                "recall": 0.657114624505929
            },
            {
                "hf_subset": "deu_Latn-rus_Cyrl",
                "languages": [
                    "deu-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9970355731225297,
                "f1": 0.9960474308300395,
                "main_score": 0.9960474308300395,
                "precision": 0.9955533596837944,
                "recall": 0.9970355731225297
            },
            {
                "hf_subset": "hat_Latn-rus_Cyrl",
                "languages": [
                    "hat-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8675889328063241,
                "f1": 0.8586738623695146,
                "main_score": 0.8586738623695146,
                "precision": 0.8555235467420822,
                "recall": 0.8675889328063241
            },
            {
                "hf_subset": "kbp_Latn-rus_Cyrl",
                "languages": [
                    "kbp-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.3488142292490119,
                "f1": 0.3216511669463015,
                "main_score": 0.3216511669463015,
                "precision": 0.31432098549546317,
                "recall": 0.3488142292490119
            },
            {
                "hf_subset": "luo_Latn-rus_Cyrl",
                "languages": [
                    "luo-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.5227272727272727,
                "f1": 0.49604896268369747,
                "main_score": 0.49604896268369747,
                "precision": 0.4869639631803339,
                "recall": 0.5227272727272727
            },
            {
                "hf_subset": "ory_Orya-rus_Cyrl",
                "languages": [
                    "ory-Orya",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9782608695652173,
                "f1": 0.9727437417654808,
                "main_score": 0.9727437417654808,
                "precision": 0.9704968944099377,
                "recall": 0.9782608695652173
            },
            {
                "hf_subset": "sna_Latn-rus_Cyrl",
                "languages": [
                    "sna-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8537549407114624,
                "f1": 0.8309911316305176,
                "main_score": 0.8309911316305176,
                "precision": 0.8212849509588639,
                "recall": 0.8537549407114624
            },
            {
                "hf_subset": "tso_Latn-rus_Cyrl",
                "languages": [
                    "tso-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8290513833992095,
                "f1": 0.8028290385503825,
                "main_score": 0.8028290385503825,
                "precision": 0.7923672543237761,
                "recall": 0.8290513833992095
            },
            {
                "hf_subset": "azj_Latn-rus_Cyrl",
                "languages": [
                    "azj-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9802371541501976,
                "f1": 0.9749200075287031,
                "main_score": 0.9749200075287031,
                "precision": 0.97266139657444,
                "recall": 0.9802371541501976
            },
            {
                "hf_subset": "dik_Latn-rus_Cyrl",
                "languages": [
                    "dik-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.3843873517786561,
                "f1": 0.35781524429552225,
                "main_score": 0.35781524429552225,
                "precision": 0.34824243250782366,
                "recall": 0.3843873517786561
            },
            {
                "hf_subset": "hau_Latn-rus_Cyrl",
                "languages": [
                    "hau-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8142292490118577,
                "f1": 0.7924612283124592,
                "main_score": 0.7924612283124592,
                "precision": 0.7834736070751448,
                "recall": 0.8142292490118577
            },
            {
                "hf_subset": "kea_Latn-rus_Cyrl",
                "languages": [
                    "kea-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8162055335968378,
                "f1": 0.8047015182884748,
                "main_score": 0.8047015182884748,
                "precision": 0.8002671028885863,
                "recall": 0.8162055335968378
            },
            {
                "hf_subset": "lus_Latn-rus_Cyrl",
                "languages": [
                    "lus-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6274703557312253,
                "f1": 0.6053900079111122,
                "main_score": 0.6053900079111122,
                "precision": 0.5980024202850289,
                "recall": 0.6274703557312253
            },
            {
                "hf_subset": "pag_Latn-rus_Cyrl",
                "languages": [
                    "pag-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7401185770750988,
                "f1": 0.7257280648279528,
                "main_score": 0.7257280648279528,
                "precision": 0.7199952968456789,
                "recall": 0.7401185770750988
            },
            {
                "hf_subset": "snd_Arab-rus_Cyrl",
                "languages": [
                    "snd-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9130434782608695,
                "f1": 0.9024653499445359,
                "main_score": 0.9024653499445359,
                "precision": 0.8983134068200233,
                "recall": 0.9130434782608695
            },
            {
                "hf_subset": "tuk_Latn-rus_Cyrl",
                "languages": [
                    "tuk-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.4762845849802372,
                "f1": 0.4581292883664425,
                "main_score": 0.4581292883664425,
                "precision": 0.45237138331703547,
                "recall": 0.4762845849802372
            },
            {
                "hf_subset": "bak_Cyrl-rus_Cyrl",
                "languages": [
                    "bak-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.958498023715415,
                "f1": 0.9518904459615922,
                "main_score": 0.9518904459615922,
                "precision": 0.9492812441182007,
                "recall": 0.958498023715415
            },
            {
                "hf_subset": "dyu_Latn-rus_Cyrl",
                "languages": [
                    "dyu-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.2964426877470356,
                "f1": 0.27287335193938167,
                "main_score": 0.27287335193938167,
                "precision": 0.2658399602658749,
                "recall": 0.2964426877470356
            },
            {
                "hf_subset": "heb_Hebr-rus_Cyrl",
                "languages": [
                    "heb-Hebr",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9891304347826086,
                "f1": 0.9855072463768115,
                "main_score": 0.9855072463768115,
                "precision": 0.9836956521739131,
                "recall": 0.9891304347826086
            },
            {
                "hf_subset": "khk_Cyrl-rus_Cyrl",
                "languages": [
                    "khk-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.951581027667984,
                "f1": 0.9444009547764487,
                "main_score": 0.9444009547764487,
                "precision": 0.9416579797014579,
                "recall": 0.951581027667984
            },
            {
                "hf_subset": "lvs_Latn-rus_Cyrl",
                "languages": [
                    "lvs-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9792490118577075,
                "f1": 0.9751467241585817,
                "main_score": 0.9751467241585817,
                "precision": 0.9736166007905137,
                "recall": 0.9792490118577075
            },
            {
                "hf_subset": "pan_Guru-rus_Cyrl",
                "languages": [
                    "pan-Guru",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9792490118577075,
                "f1": 0.9742918313570486,
                "main_score": 0.9742918313570486,
                "precision": 0.9722261434217956,
                "recall": 0.9792490118577075
            },
            {
                "hf_subset": "som_Latn-rus_Cyrl",
                "languages": [
                    "som-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.7569169960474308,
                "f1": 0.737211667065916,
                "main_score": 0.737211667065916,
                "precision": 0.7295842401892384,
                "recall": 0.7569169960474308
            },
            {
                "hf_subset": "tum_Latn-rus_Cyrl",
                "languages": [
                    "tum-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8567193675889329,
                "f1": 0.829296066252588,
                "main_score": 0.829296066252588,
                "precision": 0.8177330225447936,
                "recall": 0.8567193675889329
            }
        ]
    }
}