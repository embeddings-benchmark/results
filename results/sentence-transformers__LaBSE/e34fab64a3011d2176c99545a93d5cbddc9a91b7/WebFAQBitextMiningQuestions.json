{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQuestions",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.995621,
        "recall": 0.996716,
        "f1": 0.995895,
        "accuracy": 0.996716,
        "main_score": 0.995895,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.951431,
        "recall": 0.965235,
        "f1": 0.955862,
        "accuracy": 0.965235,
        "main_score": 0.955862,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.980757,
        "recall": 0.986515,
        "f1": 0.982621,
        "accuracy": 0.986515,
        "main_score": 0.982621,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.979474,
        "recall": 0.985251,
        "f1": 0.981318,
        "accuracy": 0.985251,
        "main_score": 0.981318,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.988715,
        "recall": 0.992477,
        "f1": 0.989969,
        "accuracy": 0.992477,
        "main_score": 0.989969,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.987494,
        "recall": 0.991342,
        "f1": 0.988696,
        "accuracy": 0.991342,
        "main_score": 0.988696,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.98896,
        "recall": 0.99264,
        "f1": 0.990187,
        "accuracy": 0.99264,
        "main_score": 0.990187,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.986584,
        "recall": 0.990712,
        "f1": 0.987874,
        "accuracy": 0.990712,
        "main_score": 0.987874,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.820147,
        "recall": 0.857143,
        "f1": 0.831502,
        "accuracy": 0.857143,
        "main_score": 0.831502,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.996032,
        "recall": 0.997354,
        "f1": 0.996473,
        "accuracy": 0.997354,
        "main_score": 0.996473,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.959327,
        "recall": 0.972178,
        "f1": 0.963434,
        "accuracy": 0.972178,
        "main_score": 0.963434,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.988215,
        "recall": 0.991919,
        "f1": 0.98945,
        "accuracy": 0.991919,
        "main_score": 0.98945,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.995775,
        "recall": 0.997183,
        "f1": 0.996244,
        "accuracy": 0.997183,
        "main_score": 0.996244,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.994396,
        "recall": 0.996264,
        "f1": 0.995019,
        "accuracy": 0.996264,
        "main_score": 0.995019,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.987156,
        "recall": 0.991437,
        "f1": 0.988583,
        "accuracy": 0.991437,
        "main_score": 0.988583,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.954776,
        "recall": 0.968157,
        "f1": 0.959169,
        "accuracy": 0.968157,
        "main_score": 0.959169,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.987868,
        "recall": 0.991334,
        "f1": 0.989024,
        "accuracy": 0.991334,
        "main_score": 0.989024,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.9755,
        "recall": 0.982592,
        "f1": 0.977756,
        "accuracy": 0.982592,
        "main_score": 0.977756,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.970721,
        "recall": 0.97973,
        "f1": 0.973536,
        "accuracy": 0.97973,
        "main_score": 0.973536,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.973309,
        "recall": 0.981378,
        "f1": 0.975947,
        "accuracy": 0.981378,
        "main_score": 0.975947,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.996571,
        "recall": 0.997714,
        "f1": 0.996952,
        "accuracy": 0.997714,
        "main_score": 0.996952,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.994012,
        "recall": 0.996008,
        "f1": 0.994677,
        "accuracy": 0.996008,
        "main_score": 0.994677,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.991387,
        "recall": 0.99406,
        "f1": 0.992278,
        "accuracy": 0.99406,
        "main_score": 0.992278,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.988029,
        "recall": 0.991604,
        "f1": 0.989195,
        "accuracy": 0.991604,
        "main_score": 0.989195,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.994708,
        "recall": 0.996472,
        "f1": 0.995296,
        "accuracy": 0.996472,
        "main_score": 0.995296,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.984672,
        "recall": 0.989781,
        "f1": 0.986375,
        "accuracy": 0.989781,
        "main_score": 0.986375,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.987569,
        "recall": 0.991713,
        "f1": 0.98895,
        "accuracy": 0.991713,
        "main_score": 0.98895,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.980934,
        "recall": 0.985992,
        "f1": 0.98262,
        "accuracy": 0.985992,
        "main_score": 0.98262,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.985623,
        "recall": 0.990415,
        "f1": 0.98722,
        "accuracy": 0.990415,
        "main_score": 0.98722,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.987747,
        "recall": 0.991517,
        "f1": 0.989004,
        "accuracy": 0.991517,
        "main_score": 0.989004,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.992114,
        "recall": 0.994742,
        "f1": 0.99299,
        "accuracy": 0.994742,
        "main_score": 0.99299,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.990439,
        "recall": 0.993626,
        "f1": 0.991501,
        "accuracy": 0.993626,
        "main_score": 0.991501,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.996198,
        "recall": 0.997465,
        "f1": 0.99662,
        "accuracy": 0.997465,
        "main_score": 0.99662,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.997104,
        "recall": 0.998069,
        "f1": 0.997426,
        "accuracy": 0.998069,
        "main_score": 0.997426,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.989637,
        "recall": 0.993092,
        "f1": 0.990789,
        "accuracy": 0.993092,
        "main_score": 0.990789,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.997076,
        "recall": 0.998051,
        "f1": 0.997401,
        "accuracy": 0.998051,
        "main_score": 0.997401,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.996878,
        "recall": 0.997919,
        "f1": 0.997225,
        "accuracy": 0.997919,
        "main_score": 0.997225,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.989523,
        "recall": 0.993015,
        "f1": 0.990687,
        "accuracy": 0.993015,
        "main_score": 0.990687,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.987644,
        "recall": 0.991763,
        "f1": 0.989017,
        "accuracy": 0.991763,
        "main_score": 0.989017,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.985915,
        "recall": 0.99061,
        "f1": 0.98748,
        "accuracy": 0.99061,
        "main_score": 0.98748,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.967292,
        "recall": 0.976665,
        "f1": 0.97031,
        "accuracy": 0.976665,
        "main_score": 0.97031,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.990615,
        "recall": 0.993222,
        "f1": 0.991484,
        "accuracy": 0.993222,
        "main_score": 0.991484,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.956669,
        "recall": 0.968162,
        "f1": 0.960251,
        "accuracy": 0.968162,
        "main_score": 0.960251,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.984756,
        "recall": 0.989837,
        "f1": 0.98645,
        "accuracy": 0.989837,
        "main_score": 0.98645,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.974121,
        "recall": 0.981857,
        "f1": 0.976653,
        "accuracy": 0.981857,
        "main_score": 0.976653,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.987728,
        "recall": 0.991291,
        "f1": 0.988915,
        "accuracy": 0.991291,
        "main_score": 0.988915,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.959778,
        "recall": 0.969891,
        "f1": 0.962956,
        "accuracy": 0.969891,
        "main_score": 0.962956,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.967033,
        "recall": 0.978022,
        "f1": 0.970696,
        "accuracy": 0.978022,
        "main_score": 0.970696,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.985957,
        "recall": 0.990099,
        "f1": 0.987301,
        "accuracy": 0.990099,
        "main_score": 0.987301,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.985438,
        "recall": 0.989674,
        "f1": 0.986762,
        "accuracy": 0.989674,
        "main_score": 0.986762,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.989305,
        "recall": 0.99287,
        "f1": 0.990493,
        "accuracy": 0.99287,
        "main_score": 0.990493,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.992055,
        "recall": 0.994703,
        "f1": 0.992938,
        "accuracy": 0.994703,
        "main_score": 0.992938,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.996994,
        "recall": 0.997996,
        "f1": 0.997328,
        "accuracy": 0.997996,
        "main_score": 0.997328,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.945998,
        "recall": 0.960437,
        "f1": 0.950296,
        "accuracy": 0.960437,
        "main_score": 0.950296,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.985099,
        "recall": 0.990066,
        "f1": 0.986755,
        "accuracy": 0.990066,
        "main_score": 0.986755,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.98495,
        "recall": 0.989967,
        "f1": 0.986622,
        "accuracy": 0.989967,
        "main_score": 0.986622,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.996411,
        "recall": 0.997608,
        "f1": 0.99681,
        "accuracy": 0.997608,
        "main_score": 0.99681,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.996224,
        "recall": 0.997356,
        "f1": 0.996601,
        "accuracy": 0.997356,
        "main_score": 0.996601,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.984628,
        "recall": 0.989394,
        "f1": 0.986204,
        "accuracy": 0.989394,
        "main_score": 0.986204,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.971835,
        "recall": 0.979484,
        "f1": 0.974285,
        "accuracy": 0.979484,
        "main_score": 0.974285,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.969247,
        "recall": 0.976427,
        "f1": 0.971512,
        "accuracy": 0.976427,
        "main_score": 0.971512,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.98028,
        "recall": 0.985118,
        "f1": 0.981817,
        "accuracy": 0.985118,
        "main_score": 0.981817,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.983417,
        "recall": 0.987706,
        "f1": 0.984761,
        "accuracy": 0.987706,
        "main_score": 0.984761,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.964447,
        "recall": 0.972863,
        "f1": 0.967118,
        "accuracy": 0.972863,
        "main_score": 0.967118,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.961745,
        "recall": 0.970273,
        "f1": 0.964289,
        "accuracy": 0.970273,
        "main_score": 0.964289,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.967096,
        "recall": 0.975637,
        "f1": 0.969794,
        "accuracy": 0.975637,
        "main_score": 0.969794,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.972645,
        "recall": 0.97985,
        "f1": 0.974945,
        "accuracy": 0.97985,
        "main_score": 0.974945,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.970355,
        "recall": 0.979262,
        "f1": 0.973233,
        "accuracy": 0.979262,
        "main_score": 0.973233,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.984694,
        "recall": 0.989796,
        "f1": 0.986395,
        "accuracy": 0.989796,
        "main_score": 0.986395,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.972858,
        "recall": 0.981104,
        "f1": 0.975554,
        "accuracy": 0.981104,
        "main_score": 0.975554,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.978807,
        "recall": 0.985434,
        "f1": 0.980974,
        "accuracy": 0.985434,
        "main_score": 0.980974,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.988573,
        "recall": 0.991736,
        "f1": 0.98958,
        "accuracy": 0.991736,
        "main_score": 0.98958,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.982596,
        "recall": 0.988073,
        "f1": 0.984407,
        "accuracy": 0.988073,
        "main_score": 0.984407,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.986103,
        "recall": 0.990272,
        "f1": 0.987447,
        "accuracy": 0.990272,
        "main_score": 0.987447,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.975822,
        "recall": 0.983282,
        "f1": 0.978244,
        "accuracy": 0.983282,
        "main_score": 0.978244,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.984436,
        "recall": 0.989432,
        "f1": 0.986082,
        "accuracy": 0.989432,
        "main_score": 0.986082,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.969953,
        "recall": 0.979152,
        "f1": 0.972942,
        "accuracy": 0.979152,
        "main_score": 0.972942,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.971097,
        "recall": 0.979774,
        "f1": 0.973933,
        "accuracy": 0.979774,
        "main_score": 0.973933,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.974036,
        "recall": 0.981626,
        "f1": 0.97644,
        "accuracy": 0.981626,
        "main_score": 0.97644,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.977818,
        "recall": 0.984244,
        "f1": 0.979915,
        "accuracy": 0.984244,
        "main_score": 0.979915,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.968986,
        "recall": 0.976024,
        "f1": 0.971133,
        "accuracy": 0.976024,
        "main_score": 0.971133,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.970046,
        "recall": 0.979023,
        "f1": 0.97299,
        "accuracy": 0.979023,
        "main_score": 0.97299,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.971208,
        "recall": 0.979425,
        "f1": 0.973865,
        "accuracy": 0.979425,
        "main_score": 0.973865,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.992874,
        "recall": 0.995249,
        "f1": 0.993666,
        "accuracy": 0.995249,
        "main_score": 0.993666,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.985531,
        "recall": 0.990354,
        "f1": 0.987138,
        "accuracy": 0.990354,
        "main_score": 0.987138,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.986804,
        "recall": 0.991202,
        "f1": 0.98827,
        "accuracy": 0.991202,
        "main_score": 0.98827,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.979885,
        "recall": 0.985917,
        "f1": 0.981849,
        "accuracy": 0.985917,
        "main_score": 0.981849,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.973006,
        "recall": 0.97973,
        "f1": 0.975185,
        "accuracy": 0.97973,
        "main_score": 0.975185,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.978453,
        "recall": 0.984529,
        "f1": 0.980431,
        "accuracy": 0.984529,
        "main_score": 0.980431,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.971389,
        "recall": 0.978274,
        "f1": 0.973562,
        "accuracy": 0.978274,
        "main_score": 0.973562,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.972533,
        "recall": 0.980404,
        "f1": 0.97508,
        "accuracy": 0.980404,
        "main_score": 0.97508,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.973555,
        "recall": 0.981017,
        "f1": 0.975966,
        "accuracy": 0.981017,
        "main_score": 0.975966,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.983046,
        "recall": 0.987613,
        "f1": 0.984547,
        "accuracy": 0.987613,
        "main_score": 0.984547,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.976753,
        "recall": 0.982766,
        "f1": 0.978662,
        "accuracy": 0.982766,
        "main_score": 0.978662,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.970833,
        "recall": 0.977839,
        "f1": 0.972928,
        "accuracy": 0.977839,
        "main_score": 0.972928,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.975231,
        "recall": 0.982418,
        "f1": 0.977582,
        "accuracy": 0.982418,
        "main_score": 0.977582,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.981565,
        "recall": 0.986396,
        "f1": 0.98311,
        "accuracy": 0.986396,
        "main_score": 0.98311,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.966035,
        "recall": 0.975191,
        "f1": 0.968869,
        "accuracy": 0.975191,
        "main_score": 0.968869,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.951782,
        "recall": 0.962465,
        "f1": 0.954878,
        "accuracy": 0.962465,
        "main_score": 0.954878,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.968854,
        "recall": 0.976181,
        "f1": 0.971117,
        "accuracy": 0.976181,
        "main_score": 0.971117,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.974829,
        "recall": 0.981675,
        "f1": 0.977041,
        "accuracy": 0.981675,
        "main_score": 0.977041,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.966725,
        "recall": 0.974223,
        "f1": 0.969074,
        "accuracy": 0.974223,
        "main_score": 0.969074,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.979897,
        "recall": 0.985762,
        "f1": 0.981814,
        "accuracy": 0.985762,
        "main_score": 0.981814,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.973475,
        "recall": 0.979929,
        "f1": 0.97551,
        "accuracy": 0.979929,
        "main_score": 0.97551,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.969457,
        "recall": 0.977185,
        "f1": 0.971862,
        "accuracy": 0.977185,
        "main_score": 0.971862,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.95537,
        "recall": 0.967038,
        "f1": 0.958953,
        "accuracy": 0.967038,
        "main_score": 0.958953,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.972854,
        "recall": 0.980753,
        "f1": 0.97541,
        "accuracy": 0.980753,
        "main_score": 0.97541,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.992334,
        "recall": 0.994889,
        "f1": 0.993186,
        "accuracy": 0.994889,
        "main_score": 0.993186,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.99735,
        "recall": 0.998233,
        "f1": 0.997644,
        "accuracy": 0.998233,
        "main_score": 0.997644,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.997561,
        "recall": 0.998374,
        "f1": 0.997832,
        "accuracy": 0.998374,
        "main_score": 0.997832,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.994495,
        "recall": 0.99633,
        "f1": 0.995107,
        "accuracy": 0.99633,
        "main_score": 0.995107,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.977778,
        "recall": 0.985185,
        "f1": 0.980247,
        "accuracy": 0.985185,
        "main_score": 0.980247,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.989078,
        "recall": 0.992718,
        "f1": 0.990291,
        "accuracy": 0.992718,
        "main_score": 0.990291,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.996134,
        "recall": 0.997423,
        "f1": 0.996564,
        "accuracy": 0.997423,
        "main_score": 0.996564,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.995588,
        "recall": 0.997059,
        "f1": 0.996078,
        "accuracy": 0.997059,
        "main_score": 0.996078,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.993038,
        "recall": 0.994937,
        "f1": 0.993671,
        "accuracy": 0.994937,
        "main_score": 0.993671,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.988872,
        "recall": 0.992582,
        "f1": 0.990109,
        "accuracy": 0.992582,
        "main_score": 0.990109,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.992434,
        "recall": 0.994812,
        "f1": 0.993191,
        "accuracy": 0.994812,
        "main_score": 0.993191,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.979326,
        "recall": 0.984731,
        "f1": 0.980987,
        "accuracy": 0.984731,
        "main_score": 0.980987,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995025,
        "recall": 0.996683,
        "f1": 0.995578,
        "accuracy": 0.996683,
        "main_score": 0.995578,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998903,
        "recall": 0.999268,
        "f1": 0.999025,
        "accuracy": 0.999268,
        "main_score": 0.999025,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.993124,
        "recall": 0.995312,
        "f1": 0.993827,
        "accuracy": 0.995312,
        "main_score": 0.993827,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.992188,
        "recall": 0.994792,
        "f1": 0.993056,
        "accuracy": 0.994792,
        "main_score": 0.993056,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.99404,
        "recall": 0.996026,
        "f1": 0.994702,
        "accuracy": 0.996026,
        "main_score": 0.994702,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.977217,
        "recall": 0.982934,
        "f1": 0.978997,
        "accuracy": 0.982934,
        "main_score": 0.978997,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978018,
        "recall": 0.984845,
        "f1": 0.980237,
        "accuracy": 0.984845,
        "main_score": 0.980237,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989427,
        "recall": 0.992832,
        "f1": 0.990562,
        "accuracy": 0.992832,
        "main_score": 0.990562,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.996026,
        "recall": 0.997351,
        "f1": 0.996468,
        "accuracy": 0.997351,
        "main_score": 0.996468,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.994604,
        "recall": 0.996403,
        "f1": 0.995204,
        "accuracy": 0.996403,
        "main_score": 0.995204,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.987269,
        "recall": 0.991287,
        "f1": 0.988576,
        "accuracy": 0.991287,
        "main_score": 0.988576,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.977757,
        "recall": 0.984358,
        "f1": 0.979898,
        "accuracy": 0.984358,
        "main_score": 0.979898,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.967215,
        "recall": 0.977324,
        "f1": 0.970408,
        "accuracy": 0.977324,
        "main_score": 0.970408,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.993916,
        "recall": 0.995944,
        "f1": 0.994592,
        "accuracy": 0.995944,
        "main_score": 0.994592,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991071,
        "recall": 0.994048,
        "f1": 0.992063,
        "accuracy": 0.994048,
        "main_score": 0.992063,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.995881,
        "recall": 0.997254,
        "f1": 0.996339,
        "accuracy": 0.997254,
        "main_score": 0.996339,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.970937,
        "recall": 0.977417,
        "f1": 0.972839,
        "accuracy": 0.977417,
        "main_score": 0.972839,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.99581,
        "recall": 0.997207,
        "f1": 0.996276,
        "accuracy": 0.997207,
        "main_score": 0.996276,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.979333,
        "recall": 0.985148,
        "f1": 0.98118,
        "accuracy": 0.985148,
        "main_score": 0.98118,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.989975,
        "recall": 0.992908,
        "f1": 0.990938,
        "accuracy": 0.992908,
        "main_score": 0.990938,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.991329,
        "recall": 0.99422,
        "f1": 0.992293,
        "accuracy": 0.99422,
        "main_score": 0.992293,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.995309,
        "recall": 0.996873,
        "f1": 0.99583,
        "accuracy": 0.996873,
        "main_score": 0.99583,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.994439,
        "recall": 0.996293,
        "f1": 0.995057,
        "accuracy": 0.996293,
        "main_score": 0.995057,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.994093,
        "recall": 0.995781,
        "f1": 0.994655,
        "accuracy": 0.995781,
        "main_score": 0.994655,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.892751,
        "recall": 0.916844,
        "f1": 0.899716,
        "accuracy": 0.916844,
        "main_score": 0.899716,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.979585,
        "recall": 0.985589,
        "f1": 0.981492,
        "accuracy": 0.985589,
        "main_score": 0.981492,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.98409,
        "recall": 0.988747,
        "f1": 0.985521,
        "accuracy": 0.988747,
        "main_score": 0.985521,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.983115,
        "recall": 0.987333,
        "f1": 0.98443,
        "accuracy": 0.987333,
        "main_score": 0.98443,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.987018,
        "recall": 0.990408,
        "f1": 0.988044,
        "accuracy": 0.990408,
        "main_score": 0.988044,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.985851,
        "recall": 0.988812,
        "f1": 0.986783,
        "accuracy": 0.988812,
        "main_score": 0.986783,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.982139,
        "recall": 0.986966,
        "f1": 0.983656,
        "accuracy": 0.986966,
        "main_score": 0.983656,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.995886,
        "recall": 0.997257,
        "f1": 0.996343,
        "accuracy": 0.997257,
        "main_score": 0.996343,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.962575,
        "recall": 0.972414,
        "f1": 0.965494,
        "accuracy": 0.972414,
        "main_score": 0.965494,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.981049,
        "recall": 0.986599,
        "f1": 0.982838,
        "accuracy": 0.986599,
        "main_score": 0.982838,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990099,
        "recall": 0.993399,
        "f1": 0.991199,
        "accuracy": 0.993399,
        "main_score": 0.991199,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.985753,
        "recall": 0.989675,
        "f1": 0.987016,
        "accuracy": 0.989675,
        "main_score": 0.987016,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.997278,
        "recall": 0.998185,
        "f1": 0.99758,
        "accuracy": 0.998185,
        "main_score": 0.99758,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.990786,
        "recall": 0.993857,
        "f1": 0.99181,
        "accuracy": 0.993857,
        "main_score": 0.99181,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.990628,
        "recall": 0.993704,
        "f1": 0.991641,
        "accuracy": 0.993704,
        "main_score": 0.991641,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.977159,
        "recall": 0.983325,
        "f1": 0.979078,
        "accuracy": 0.983325,
        "main_score": 0.979078,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.998813,
        "recall": 0.999209,
        "f1": 0.998945,
        "accuracy": 0.999209,
        "main_score": 0.998945,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.989816,
        "recall": 0.992942,
        "f1": 0.990858,
        "accuracy": 0.992942,
        "main_score": 0.990858,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 3847.2108421325684,
  "kg_co2_emissions": null
}