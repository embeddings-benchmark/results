{
  "dataset_revision": "e60893b7a8d01c9b8c12fadfe8f0a06e9d548a63",
  "task_name": "SynPerChatbotConvSAHappiness",
  "mteb_version": "1.25.8",
  "scores": {
    "test": [
      {
        "accuracy": 0.690678,
        "f1": 0.66667,
        "f1_weighted": 0.697824,
        "ap": 0.774711,
        "ap_weighted": 0.774711,
        "scores_per_experiment": [
          {
            "accuracy": 0.728814,
            "f1": 0.697436,
            "f1_weighted": 0.732116,
            "ap": 0.784779,
            "ap_weighted": 0.784779
          },
          {
            "accuracy": 0.694915,
            "f1": 0.685892,
            "f1_weighted": 0.704841,
            "ap": 0.806323,
            "ap_weighted": 0.806323
          },
          {
            "accuracy": 0.652542,
            "f1": 0.636213,
            "f1_weighted": 0.663646,
            "ap": 0.761834,
            "ap_weighted": 0.761834
          },
          {
            "accuracy": 0.661017,
            "f1": 0.630326,
            "f1_weighted": 0.668238,
            "ap": 0.747834,
            "ap_weighted": 0.747834
          },
          {
            "accuracy": 0.70339,
            "f1": 0.667016,
            "f1_weighted": 0.706188,
            "ap": 0.765075,
            "ap_weighted": 0.765075
          },
          {
            "accuracy": 0.720339,
            "f1": 0.702362,
            "f1_weighted": 0.728398,
            "ap": 0.801072,
            "ap_weighted": 0.801072
          },
          {
            "accuracy": 0.584746,
            "f1": 0.568346,
            "f1_weighted": 0.598293,
            "ap": 0.721742,
            "ap_weighted": 0.721742
          },
          {
            "accuracy": 0.711864,
            "f1": 0.685777,
            "f1_weighted": 0.718003,
            "ap": 0.782306,
            "ap_weighted": 0.782306
          },
          {
            "accuracy": 0.728814,
            "f1": 0.707287,
            "f1_weighted": 0.735541,
            "ap": 0.799573,
            "ap_weighted": 0.799573
          },
          {
            "accuracy": 0.720339,
            "f1": 0.686044,
            "f1_weighted": 0.722977,
            "ap": 0.776568,
            "ap_weighted": 0.776568
          }
        ],
        "main_score": 0.690678,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 2.8432953357696533,
  "kg_co2_emissions": null
}