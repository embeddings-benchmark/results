{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQAs",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.964894,
        "recall": 0.97546,
        "f1": 0.968303,
        "accuracy": 0.97546,
        "main_score": 0.968303,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.998444,
        "recall": 0.998963,
        "f1": 0.998617,
        "accuracy": 0.998963,
        "main_score": 0.998617,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.993707,
        "recall": 0.994792,
        "f1": 0.993956,
        "accuracy": 0.994792,
        "main_score": 0.993956,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.998557,
        "recall": 0.998557,
        "f1": 0.998557,
        "accuracy": 0.998557,
        "main_score": 0.998557,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.99862,
        "recall": 0.99908,
        "f1": 0.998773,
        "accuracy": 0.99908,
        "main_score": 0.998773,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.995356,
        "recall": 0.996904,
        "f1": 0.995872,
        "accuracy": 0.996904,
        "main_score": 0.995872,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.904396,
        "recall": 0.931868,
        "f1": 0.913187,
        "accuracy": 0.931868,
        "main_score": 0.913187,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.985692,
        "recall": 0.990461,
        "f1": 0.987281,
        "accuracy": 0.990461,
        "main_score": 0.987281,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.99899,
        "recall": 0.999327,
        "f1": 0.999102,
        "accuracy": 0.999327,
        "main_score": 0.999102,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.999083,
        "recall": 0.999388,
        "f1": 0.999185,
        "accuracy": 0.999388,
        "main_score": 0.999185,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.982949,
        "recall": 0.987805,
        "f1": 0.98453,
        "accuracy": 0.987805,
        "main_score": 0.98453,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.9987,
        "recall": 0.999133,
        "f1": 0.998845,
        "accuracy": 0.999133,
        "main_score": 0.998845,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.992747,
        "recall": 0.995164,
        "f1": 0.993553,
        "accuracy": 0.995164,
        "main_score": 0.993553,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.986809,
        "recall": 0.990689,
        "f1": 0.988051,
        "accuracy": 0.990689,
        "main_score": 0.988051,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.998286,
        "recall": 0.998857,
        "f1": 0.998476,
        "accuracy": 0.998857,
        "main_score": 0.998476,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.998503,
        "recall": 0.999002,
        "f1": 0.998669,
        "accuracy": 0.999002,
        "main_score": 0.998669,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.999109,
        "recall": 0.999406,
        "f1": 0.999208,
        "accuracy": 0.999406,
        "main_score": 0.999208,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.997201,
        "recall": 0.998134,
        "f1": 0.997512,
        "accuracy": 0.998134,
        "main_score": 0.997512,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.99562,
        "recall": 0.99708,
        "f1": 0.996107,
        "accuracy": 0.99708,
        "main_score": 0.996107,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.995856,
        "recall": 0.997238,
        "f1": 0.996317,
        "accuracy": 0.997238,
        "main_score": 0.996317,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.992996,
        "recall": 0.995331,
        "f1": 0.993774,
        "accuracy": 0.995331,
        "main_score": 0.993774,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.995208,
        "recall": 0.996805,
        "f1": 0.99574,
        "accuracy": 0.996805,
        "main_score": 0.99574,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.995058,
        "recall": 0.996705,
        "f1": 0.995607,
        "accuracy": 0.996705,
        "main_score": 0.995607,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.985607,
        "recall": 0.98943,
        "f1": 0.986837,
        "accuracy": 0.98943,
        "main_score": 0.986837,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.999218,
        "recall": 0.999479,
        "f1": 0.999305,
        "accuracy": 0.999479,
        "main_score": 0.999305,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.967861,
        "recall": 0.976122,
        "f1": 0.970381,
        "accuracy": 0.976122,
        "main_score": 0.970381,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.990854,
        "recall": 0.993902,
        "f1": 0.99187,
        "accuracy": 0.993902,
        "main_score": 0.99187,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.989522,
        "recall": 0.992405,
        "f1": 0.990436,
        "accuracy": 0.992405,
        "main_score": 0.990436,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.996437,
        "recall": 0.997625,
        "f1": 0.996833,
        "accuracy": 0.997625,
        "main_score": 0.996833,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.976125,
        "recall": 0.982664,
        "f1": 0.978254,
        "accuracy": 0.982664,
        "main_score": 0.978254,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.961172,
        "recall": 0.973626,
        "f1": 0.965201,
        "accuracy": 0.973626,
        "main_score": 0.965201,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.99596,
        "recall": 0.996853,
        "f1": 0.996229,
        "accuracy": 0.996853,
        "main_score": 0.996229,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.994043,
        "recall": 0.996029,
        "f1": 0.994705,
        "accuracy": 0.996029,
        "main_score": 0.994705,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.997326,
        "recall": 0.998217,
        "f1": 0.997623,
        "accuracy": 0.998217,
        "main_score": 0.997623,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.998411,
        "recall": 0.998941,
        "f1": 0.998588,
        "accuracy": 0.998941,
        "main_score": 0.998588,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.982037,
        "recall": 0.987722,
        "f1": 0.983856,
        "accuracy": 0.987722,
        "main_score": 0.983856,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.997118,
        "recall": 0.997925,
        "f1": 0.997387,
        "accuracy": 0.997925,
        "main_score": 0.997387,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.983934,
        "recall": 0.988164,
        "f1": 0.985288,
        "accuracy": 0.988164,
        "main_score": 0.985288,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.979614,
        "recall": 0.984023,
        "f1": 0.981002,
        "accuracy": 0.984023,
        "main_score": 0.981002,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.987029,
        "recall": 0.989754,
        "f1": 0.987875,
        "accuracy": 0.989754,
        "main_score": 0.987875,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.984953,
        "recall": 0.988859,
        "f1": 0.98617,
        "accuracy": 0.988859,
        "main_score": 0.98617,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.974078,
        "recall": 0.979414,
        "f1": 0.975717,
        "accuracy": 0.979414,
        "main_score": 0.975717,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.973863,
        "recall": 0.979532,
        "f1": 0.975552,
        "accuracy": 0.979532,
        "main_score": 0.975552,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.976897,
        "recall": 0.982078,
        "f1": 0.978521,
        "accuracy": 0.982078,
        "main_score": 0.978521,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.986235,
        "recall": 0.989456,
        "f1": 0.987246,
        "accuracy": 0.989456,
        "main_score": 0.987246,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.998629,
        "recall": 0.999062,
        "f1": 0.998774,
        "accuracy": 0.999062,
        "main_score": 0.998774,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.997445,
        "recall": 0.99819,
        "f1": 0.997693,
        "accuracy": 0.99819,
        "main_score": 0.997693,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.998323,
        "recall": 0.998804,
        "f1": 0.998475,
        "accuracy": 0.998804,
        "main_score": 0.998475,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.995508,
        "recall": 0.996766,
        "f1": 0.995928,
        "accuracy": 0.996766,
        "main_score": 0.995928,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.997674,
        "recall": 0.99841,
        "f1": 0.997909,
        "accuracy": 0.99841,
        "main_score": 0.997909,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.99648,
        "recall": 0.997499,
        "f1": 0.996804,
        "accuracy": 0.997499,
        "main_score": 0.996804,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.998421,
        "recall": 0.998936,
        "f1": 0.99859,
        "accuracy": 0.998936,
        "main_score": 0.99859,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.99922,
        "recall": 0.99948,
        "f1": 0.999307,
        "accuracy": 0.99948,
        "main_score": 0.999307,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.994251,
        "recall": 0.99585,
        "f1": 0.994765,
        "accuracy": 0.99585,
        "main_score": 0.994765,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.994041,
        "recall": 0.99571,
        "f1": 0.994572,
        "accuracy": 0.99571,
        "main_score": 0.994572,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.986774,
        "recall": 0.990618,
        "f1": 0.988011,
        "accuracy": 0.990618,
        "main_score": 0.988011,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.992304,
        "recall": 0.994346,
        "f1": 0.992956,
        "accuracy": 0.994346,
        "main_score": 0.992956,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.982069,
        "recall": 0.986343,
        "f1": 0.983379,
        "accuracy": 0.986343,
        "main_score": 0.983379,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.995178,
        "recall": 0.996397,
        "f1": 0.99557,
        "accuracy": 0.996397,
        "main_score": 0.99557,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.98902,
        "recall": 0.99201,
        "f1": 0.989945,
        "accuracy": 0.99201,
        "main_score": 0.989945,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.994032,
        "recall": 0.995633,
        "f1": 0.994541,
        "accuracy": 0.995633,
        "main_score": 0.994541,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.984334,
        "recall": 0.987679,
        "f1": 0.985387,
        "accuracy": 0.987679,
        "main_score": 0.985387,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.992298,
        "recall": 0.994233,
        "f1": 0.992906,
        "accuracy": 0.994233,
        "main_score": 0.992906,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.983705,
        "recall": 0.987798,
        "f1": 0.98499,
        "accuracy": 0.987798,
        "main_score": 0.98499,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.993523,
        "recall": 0.995161,
        "f1": 0.994047,
        "accuracy": 0.995161,
        "main_score": 0.994047,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.986879,
        "recall": 0.990086,
        "f1": 0.987883,
        "accuracy": 0.990086,
        "main_score": 0.987883,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.98755,
        "recall": 0.990616,
        "f1": 0.988551,
        "accuracy": 0.990616,
        "main_score": 0.988551,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.988919,
        "recall": 0.991169,
        "f1": 0.989598,
        "accuracy": 0.991169,
        "main_score": 0.989598,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.987708,
        "recall": 0.991343,
        "f1": 0.988862,
        "accuracy": 0.991343,
        "main_score": 0.988862,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.992282,
        "recall": 0.994244,
        "f1": 0.992908,
        "accuracy": 0.994244,
        "main_score": 0.992908,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990323,
        "recall": 0.992508,
        "f1": 0.991009,
        "accuracy": 0.992508,
        "main_score": 0.991009,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.981886,
        "recall": 0.986641,
        "f1": 0.983381,
        "accuracy": 0.986641,
        "main_score": 0.983381,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.979049,
        "recall": 0.985127,
        "f1": 0.980925,
        "accuracy": 0.985127,
        "main_score": 0.980925,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.981688,
        "recall": 0.986554,
        "f1": 0.983212,
        "accuracy": 0.986554,
        "main_score": 0.983212,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.989258,
        "recall": 0.992101,
        "f1": 0.990205,
        "accuracy": 0.992101,
        "main_score": 0.990205,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.978952,
        "recall": 0.983146,
        "f1": 0.980254,
        "accuracy": 0.983146,
        "main_score": 0.980254,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.994373,
        "recall": 0.995897,
        "f1": 0.994871,
        "accuracy": 0.995897,
        "main_score": 0.994871,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.986718,
        "recall": 0.989847,
        "f1": 0.987687,
        "accuracy": 0.989847,
        "main_score": 0.987687,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.983481,
        "recall": 0.987852,
        "f1": 0.984859,
        "accuracy": 0.987852,
        "main_score": 0.984859,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.978234,
        "recall": 0.983287,
        "f1": 0.979759,
        "accuracy": 0.983287,
        "main_score": 0.979759,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.986374,
        "recall": 0.990172,
        "f1": 0.987558,
        "accuracy": 0.990172,
        "main_score": 0.987558,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.998722,
        "recall": 0.999148,
        "f1": 0.998864,
        "accuracy": 0.999148,
        "main_score": 0.998864,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.996359,
        "recall": 0.997573,
        "f1": 0.996764,
        "accuracy": 0.997573,
        "main_score": 0.996764,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.997774,
        "recall": 0.998516,
        "f1": 0.998022,
        "accuracy": 0.998516,
        "main_score": 0.998022,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.998054,
        "recall": 0.998703,
        "f1": 0.998271,
        "accuracy": 0.998703,
        "main_score": 0.998271,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.991196,
        "recall": 0.99298,
        "f1": 0.991716,
        "accuracy": 0.99298,
        "main_score": 0.991716,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995781,
        "recall": 0.997187,
        "f1": 0.996249,
        "accuracy": 0.997187,
        "main_score": 0.996249,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998698,
        "recall": 0.999132,
        "f1": 0.998843,
        "accuracy": 0.999132,
        "main_score": 0.998843,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.999603,
        "recall": 0.999735,
        "f1": 0.999647,
        "accuracy": 0.999735,
        "main_score": 0.999647,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.987343,
        "recall": 0.989583,
        "f1": 0.987981,
        "accuracy": 0.989583,
        "main_score": 0.987981,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.99913,
        "recall": 0.999384,
        "f1": 0.99921,
        "accuracy": 0.999384,
        "main_score": 0.99921,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997969,
        "recall": 0.998566,
        "f1": 0.998148,
        "accuracy": 0.998566,
        "main_score": 0.998148,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.999564,
        "recall": 0.99971,
        "f1": 0.999613,
        "accuracy": 0.99971,
        "main_score": 0.999613,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.996596,
        "recall": 0.997393,
        "f1": 0.996834,
        "accuracy": 0.997393,
        "main_score": 0.996834,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.978269,
        "recall": 0.985261,
        "f1": 0.980537,
        "accuracy": 0.985261,
        "main_score": 0.980537,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.999324,
        "recall": 0.999549,
        "f1": 0.999399,
        "accuracy": 0.999549,
        "main_score": 0.999399,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.97873,
        "recall": 0.983208,
        "f1": 0.980014,
        "accuracy": 0.983208,
        "main_score": 0.980014,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.994048,
        "recall": 0.995422,
        "f1": 0.994433,
        "accuracy": 0.995422,
        "main_score": 0.994433,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.999081,
        "recall": 0.999212,
        "f1": 0.999124,
        "accuracy": 0.999212,
        "main_score": 0.999124,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.995665,
        "recall": 0.99711,
        "f1": 0.996146,
        "accuracy": 0.99711,
        "main_score": 0.996146,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.999414,
        "recall": 0.999609,
        "f1": 0.999479,
        "accuracy": 0.999609,
        "main_score": 0.999479,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.99861,
        "recall": 0.999073,
        "f1": 0.998764,
        "accuracy": 0.999073,
        "main_score": 0.998764,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.883262,
        "recall": 0.906183,
        "f1": 0.890334,
        "accuracy": 0.906183,
        "main_score": 0.890334,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.995426,
        "recall": 0.996605,
        "f1": 0.995772,
        "accuracy": 0.996605,
        "main_score": 0.995772,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.989841,
        "recall": 0.992873,
        "f1": 0.990773,
        "accuracy": 0.992873,
        "main_score": 0.990773,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.99139,
        "recall": 0.993157,
        "f1": 0.991883,
        "accuracy": 0.993157,
        "main_score": 0.991883,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.992131,
        "recall": 0.993874,
        "f1": 0.992614,
        "accuracy": 0.993874,
        "main_score": 0.992614,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.992596,
        "recall": 0.994077,
        "f1": 0.993035,
        "accuracy": 0.994077,
        "main_score": 0.993035,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.992032,
        "recall": 0.993697,
        "f1": 0.992525,
        "accuracy": 0.993697,
        "main_score": 0.992525,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.973437,
        "recall": 0.98,
        "f1": 0.975333,
        "accuracy": 0.98,
        "main_score": 0.975333,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.996195,
        "recall": 0.997122,
        "f1": 0.996473,
        "accuracy": 0.997122,
        "main_score": 0.996473,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.995611,
        "recall": 0.996669,
        "f1": 0.995934,
        "accuracy": 0.996669,
        "main_score": 0.995934,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.997033,
        "recall": 0.997829,
        "f1": 0.997286,
        "accuracy": 0.997829,
        "main_score": 0.997286,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.991023,
        "recall": 0.993383,
        "f1": 0.991724,
        "accuracy": 0.993383,
        "main_score": 0.991724,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.999294,
        "recall": 0.999395,
        "f1": 0.999328,
        "accuracy": 0.999395,
        "main_score": 0.999328,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 5285.618667125702,
  "kg_co2_emissions": null
}