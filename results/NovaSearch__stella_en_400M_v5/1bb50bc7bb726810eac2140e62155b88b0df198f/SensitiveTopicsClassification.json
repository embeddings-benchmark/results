{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "evaluation_time": 47.77882170677185,
  "kg_co2_emissions": null,
  "mteb_version": "1.19.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.179833984375,
        "f1": 0.019114291074852217,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "lrap": 0.261232503255202,
        "main_score": 0.179833984375,
        "scores_per_experiment": [
          {
            "accuracy": 0.18115234375,
            "f1": 0.007582174358512373,
            "lrap": 0.25646972656249367
          },
          {
            "accuracy": 0.1875,
            "f1": 0.03497039561697098,
            "lrap": 0.2713216145833268
          },
          {
            "accuracy": 0.1806640625,
            "f1": 0.02785031533309173,
            "lrap": 0.2587348090277714
          },
          {
            "accuracy": 0.18505859375,
            "f1": 0.01748443255481736,
            "lrap": 0.26171874999999356
          },
          {
            "accuracy": 0.1708984375,
            "f1": 0.011360719001969496,
            "lrap": 0.2570393880208269
          },
          {
            "accuracy": 0.1748046875,
            "f1": 0.021436353935820697,
            "lrap": 0.26424153645832693
          },
          {
            "accuracy": 0.18212890625,
            "f1": 0.021102917152422105,
            "lrap": 0.2633599175347158
          },
          {
            "accuracy": 0.18017578125,
            "f1": 0.014892885463763593,
            "lrap": 0.2591824001736047
          },
          {
            "accuracy": 0.171875,
            "f1": 0.0202603068519639,
            "lrap": 0.26077609592013246
          },
          {
            "accuracy": 0.18408203125,
            "f1": 0.014202410479189936,
            "lrap": 0.25948079427082693
          }
        ]
      }
    ]
  },
  "task_name": "SensitiveTopicsClassification"
}