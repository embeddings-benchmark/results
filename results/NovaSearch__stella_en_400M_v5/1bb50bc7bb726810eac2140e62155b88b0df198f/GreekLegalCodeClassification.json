{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "evaluation_time": 1064.07754445076,
  "kg_co2_emissions": 0.06764765024432373,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.080712890625,
        "f1": 0.06436129882183783,
        "f1_weighted": 0.0707969949354755,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.080712890625,
        "scores_per_experiment": [
          {
            "accuracy": 0.0849609375,
            "f1": 0.06502706412605273,
            "f1_weighted": 0.07060816798365765
          },
          {
            "accuracy": 0.087890625,
            "f1": 0.0766376093789881,
            "f1_weighted": 0.08079889472092697
          },
          {
            "accuracy": 0.07421875,
            "f1": 0.06401106788243635,
            "f1_weighted": 0.06650677597570508
          },
          {
            "accuracy": 0.08056640625,
            "f1": 0.0627291463191706,
            "f1_weighted": 0.07307049290848411
          },
          {
            "accuracy": 0.0693359375,
            "f1": 0.06044511091538306,
            "f1_weighted": 0.06440690705654845
          },
          {
            "accuracy": 0.0810546875,
            "f1": 0.0678754335152723,
            "f1_weighted": 0.07289973142432904
          },
          {
            "accuracy": 0.09423828125,
            "f1": 0.06601243788498078,
            "f1_weighted": 0.0811238535875916
          },
          {
            "accuracy": 0.07568359375,
            "f1": 0.060649221682032135,
            "f1_weighted": 0.06429331920936168
          },
          {
            "accuracy": 0.078125,
            "f1": 0.059582533618485756,
            "f1_weighted": 0.06387266360120361
          },
          {
            "accuracy": 0.0810546875,
            "f1": 0.06064336289557652,
            "f1_weighted": 0.07038914288694689
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.0857421875,
        "f1": 0.0635450458068221,
        "f1_weighted": 0.07795637086443245,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.0857421875,
        "scores_per_experiment": [
          {
            "accuracy": 0.08056640625,
            "f1": 0.05534068473028248,
            "f1_weighted": 0.07115723139460392
          },
          {
            "accuracy": 0.09326171875,
            "f1": 0.07219260712386938,
            "f1_weighted": 0.08557987067256947
          },
          {
            "accuracy": 0.08203125,
            "f1": 0.0649371377263774,
            "f1_weighted": 0.076770050576127
          },
          {
            "accuracy": 0.0810546875,
            "f1": 0.06934815034653585,
            "f1_weighted": 0.069619868589985
          },
          {
            "accuracy": 0.072265625,
            "f1": 0.056500333955239936,
            "f1_weighted": 0.06844534640339689
          },
          {
            "accuracy": 0.0908203125,
            "f1": 0.06896811362699774,
            "f1_weighted": 0.08407558937380084
          },
          {
            "accuracy": 0.0947265625,
            "f1": 0.06123018776124936,
            "f1_weighted": 0.0840822825372301
          },
          {
            "accuracy": 0.0810546875,
            "f1": 0.05414088685928458,
            "f1_weighted": 0.06985755345974935
          },
          {
            "accuracy": 0.08544921875,
            "f1": 0.05962033722587285,
            "f1_weighted": 0.07643902834051317
          },
          {
            "accuracy": 0.09619140625,
            "f1": 0.07317201871251128,
            "f1_weighted": 0.09353688729634882
          }
        ]
      }
    ]
  },
  "task_name": "GreekLegalCodeClassification"
}