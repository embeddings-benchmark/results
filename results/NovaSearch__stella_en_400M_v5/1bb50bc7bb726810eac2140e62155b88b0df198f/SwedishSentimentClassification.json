{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.719629,
        "f1": 0.715087,
        "f1_weighted": 0.71518,
        "ap": 0.651697,
        "ap_weighted": 0.651697,
        "scores_per_experiment": [
          {
            "accuracy": 0.693848,
            "f1": 0.681894,
            "f1_weighted": 0.682075,
            "ap": 0.625006,
            "ap_weighted": 0.625006
          },
          {
            "accuracy": 0.708984,
            "f1": 0.700022,
            "f1_weighted": 0.700174,
            "ap": 0.637981,
            "ap_weighted": 0.637981
          },
          {
            "accuracy": 0.692383,
            "f1": 0.692333,
            "f1_weighted": 0.692345,
            "ap": 0.63372,
            "ap_weighted": 0.63372
          },
          {
            "accuracy": 0.69043,
            "f1": 0.682483,
            "f1_weighted": 0.68263,
            "ap": 0.623846,
            "ap_weighted": 0.623846
          },
          {
            "accuracy": 0.74707,
            "f1": 0.744828,
            "f1_weighted": 0.744898,
            "ap": 0.676134,
            "ap_weighted": 0.676134
          },
          {
            "accuracy": 0.723633,
            "f1": 0.720696,
            "f1_weighted": 0.72078,
            "ap": 0.654504,
            "ap_weighted": 0.654504
          },
          {
            "accuracy": 0.72168,
            "f1": 0.714715,
            "f1_weighted": 0.714845,
            "ap": 0.649341,
            "ap_weighted": 0.649341
          },
          {
            "accuracy": 0.725098,
            "f1": 0.723473,
            "f1_weighted": 0.723535,
            "ap": 0.657734,
            "ap_weighted": 0.657734
          },
          {
            "accuracy": 0.756836,
            "f1": 0.756691,
            "f1_weighted": 0.756708,
            "ap": 0.692702,
            "ap_weighted": 0.692702
          },
          {
            "accuracy": 0.736328,
            "f1": 0.733738,
            "f1_weighted": 0.733815,
            "ap": 0.666001,
            "ap_weighted": 0.666001
          }
        ],
        "main_score": 0.719629,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.71958,
        "f1": 0.715238,
        "f1_weighted": 0.715298,
        "ap": 0.651559,
        "ap_weighted": 0.651559,
        "scores_per_experiment": [
          {
            "accuracy": 0.711426,
            "f1": 0.700854,
            "f1_weighted": 0.700964,
            "ap": 0.638864,
            "ap_weighted": 0.638864
          },
          {
            "accuracy": 0.683105,
            "f1": 0.674178,
            "f1_weighted": 0.674284,
            "ap": 0.617457,
            "ap_weighted": 0.617457
          },
          {
            "accuracy": 0.717285,
            "f1": 0.717285,
            "f1_weighted": 0.717284,
            "ap": 0.656976,
            "ap_weighted": 0.656976
          },
          {
            "accuracy": 0.703125,
            "f1": 0.695978,
            "f1_weighted": 0.696069,
            "ap": 0.63386,
            "ap_weighted": 0.63386
          },
          {
            "accuracy": 0.730957,
            "f1": 0.728287,
            "f1_weighted": 0.72834,
            "ap": 0.660787,
            "ap_weighted": 0.660787
          },
          {
            "accuracy": 0.731934,
            "f1": 0.729167,
            "f1_weighted": 0.72922,
            "ap": 0.661503,
            "ap_weighted": 0.661503
          },
          {
            "accuracy": 0.724609,
            "f1": 0.718237,
            "f1_weighted": 0.718319,
            "ap": 0.651801,
            "ap_weighted": 0.651801
          },
          {
            "accuracy": 0.72998,
            "f1": 0.728085,
            "f1_weighted": 0.728129,
            "ap": 0.661133,
            "ap_weighted": 0.661133
          },
          {
            "accuracy": 0.749023,
            "f1": 0.749021,
            "f1_weighted": 0.749023,
            "ap": 0.687135,
            "ap_weighted": 0.687135
          },
          {
            "accuracy": 0.714355,
            "f1": 0.711291,
            "f1_weighted": 0.711349,
            "ap": 0.646069,
            "ap_weighted": 0.646069
          }
        ],
        "main_score": 0.71958,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.324427366256714,
  "kg_co2_emissions": 0.0014296545194769944
}