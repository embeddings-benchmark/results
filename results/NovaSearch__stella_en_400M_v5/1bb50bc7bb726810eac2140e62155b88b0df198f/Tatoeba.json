{
  "dataset_revision": "69e8f12da6e31d59addadda9a9c8a2e601a0e282",
  "evaluation_time": 557.4967153072357,
  "kg_co2_emissions": 0.02420439417706689,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.202,
        "f1": 0.15999604857479283,
        "hf_subset": "cmn-eng",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.15999604857479283,
        "precision": 0.14932325777901986,
        "recall": 0.202
      },
      {
        "accuracy": 0.095,
        "f1": 0.07969652077733108,
        "hf_subset": "vie-eng",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07969652077733108,
        "precision": 0.07586801897484897,
        "recall": 0.095
      },
      {
        "accuracy": 0.2535211267605634,
        "f1": 0.21384710411042315,
        "hf_subset": "max-eng",
        "languages": [
          "max-Deva",
          "eng-Latn"
        ],
        "main_score": 0.21384710411042315,
        "precision": 0.20401109867762726,
        "recall": 0.2535211267605634
      },
      {
        "accuracy": 0.183,
        "f1": 0.15433960279486592,
        "hf_subset": "eus-eng",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.15433960279486592,
        "precision": 0.1460842162552582,
        "recall": 0.183
      },
      {
        "accuracy": 0.6536964980544747,
        "f1": 0.6090634398027394,
        "hf_subset": "nov-eng",
        "languages": [
          "nov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.6090634398027394,
        "precision": 0.5925032425421529,
        "recall": 0.6536964980544747
      },
      {
        "accuracy": 0.010723860589812333,
        "f1": 0.007778367760513951,
        "hf_subset": "kat-eng",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ],
        "main_score": 0.007778367760513951,
        "precision": 0.007468846192036541,
        "recall": 0.010723860589812333
      },
      {
        "accuracy": 0.10822510822510822,
        "f1": 0.07878585971143567,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07878585971143567,
        "precision": 0.07313182848897133,
        "recall": 0.10822510822510822
      },
      {
        "accuracy": 0.14,
        "f1": 0.11591349096126238,
        "hf_subset": "srp-eng",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.11591349096126238,
        "precision": 0.10954363284076146,
        "recall": 0.14
      },
      {
        "accuracy": 0.1975609756097561,
        "f1": 0.16886417981826873,
        "hf_subset": "kur-eng",
        "languages": [
          "kur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16886417981826873,
        "precision": 0.16240923585756706,
        "recall": 0.1975609756097561
      },
      {
        "accuracy": 0.204,
        "f1": 0.17195754405952765,
        "hf_subset": "sqi-eng",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.17195754405952765,
        "precision": 0.1631727022977023,
        "recall": 0.204
      },
      {
        "accuracy": 0.012,
        "f1": 0.0049808662298024,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0049808662298024,
        "precision": 0.0034829306839792773,
        "recall": 0.012
      },
      {
        "accuracy": 0.161,
        "f1": 0.12330580310294863,
        "hf_subset": "rus-eng",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.12330580310294863,
        "precision": 0.11553111915843918,
        "recall": 0.161
      },
      {
        "accuracy": 0.01282051282051282,
        "f1": 0.0009136472347174688,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.0009136472347174688,
        "precision": 0.0004867026382898051,
        "recall": 0.01282051282051282
      },
      {
        "accuracy": 0.268361581920904,
        "f1": 0.22756703434669537,
        "hf_subset": "bos-eng",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.22756703434669537,
        "precision": 0.21632197563154693,
        "recall": 0.268361581920904
      },
      {
        "accuracy": 0.11267605633802817,
        "f1": 0.0964556570190373,
        "hf_subset": "xho-eng",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0964556570190373,
        "precision": 0.09443842542434092,
        "recall": 0.11267605633802817
      },
      {
        "accuracy": 0.233201581027668,
        "f1": 0.18595925374581498,
        "hf_subset": "csb-eng",
        "languages": [
          "csb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.18595925374581498,
        "precision": 0.17460767123575036,
        "recall": 0.233201581027668
      },
      {
        "accuracy": 0.10833333333333334,
        "f1": 0.09517460317460316,
        "hf_subset": "ceb-eng",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09517460317460316,
        "precision": 0.09151262626262625,
        "recall": 0.10833333333333334
      },
      {
        "accuracy": 0.47398843930635837,
        "f1": 0.4129465589003161,
        "hf_subset": "fry-eng",
        "languages": [
          "fry-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4129465589003161,
        "precision": 0.3928252383454695,
        "recall": 0.47398843930635837
      },
      {
        "accuracy": 0.02,
        "f1": 0.012440178541265497,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ],
        "main_score": 0.012440178541265497,
        "precision": 0.011336923992203377,
        "recall": 0.02
      },
      {
        "accuracy": 0.53,
        "f1": 0.4825538688776759,
        "hf_subset": "lfn-eng",
        "languages": [
          "lfn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4825538688776759,
        "precision": 0.46579876543567444,
        "recall": 0.53
      },
      {
        "accuracy": 0.32,
        "f1": 0.2791653761930078,
        "hf_subset": "nno-eng",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2791653761930078,
        "precision": 0.2672707405818819,
        "recall": 0.32
      },
      {
        "accuracy": 0.13076923076923078,
        "f1": 0.10211427403735095,
        "hf_subset": "swh-eng",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10211427403735095,
        "precision": 0.09458577182715114,
        "recall": 0.13076923076923078
      },
      {
        "accuracy": 0.134,
        "f1": 0.11239675899440629,
        "hf_subset": "tgl-eng",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11239675899440629,
        "precision": 0.10659367297259963,
        "recall": 0.134
      },
      {
        "accuracy": 0.782,
        "f1": 0.7406214285714287,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.7406214285714287,
        "precision": 0.7261555916305916,
        "recall": 0.782
      },
      {
        "accuracy": 0.41964285714285715,
        "f1": 0.36223672161172166,
        "hf_subset": "swg-eng",
        "languages": [
          "swg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.36223672161172166,
        "precision": 0.3488874716553288,
        "recall": 0.41964285714285715
      },
      {
        "accuracy": 0.055,
        "f1": 0.03871382101867591,
        "hf_subset": "mkd-eng",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.03871382101867591,
        "precision": 0.03588889002079792,
        "recall": 0.055
      },
      {
        "accuracy": 0.025,
        "f1": 0.01510954498424713,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.01510954498424713,
        "precision": 0.013281265478014703,
        "recall": 0.025
      },
      {
        "accuracy": 0.009771986970684038,
        "f1": 0.006979990693345742,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.006979990693345742,
        "precision": 0.006765221748935103,
        "recall": 0.009771986970684038
      },
      {
        "accuracy": 0.169,
        "f1": 0.13148380592006764,
        "hf_subset": "wuu-eng",
        "languages": [
          "wuu-Hans",
          "eng-Latn"
        ],
        "main_score": 0.13148380592006764,
        "precision": 0.12262121824254177,
        "recall": 0.169
      },
      {
        "accuracy": 0.143,
        "f1": 0.12135710445657182,
        "hf_subset": "lvs-eng",
        "languages": [
          "lvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12135710445657182,
        "precision": 0.11601518889607124,
        "recall": 0.143
      },
      {
        "accuracy": 0.719,
        "f1": 0.6665525252525253,
        "hf_subset": "ita-eng",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.6665525252525253,
        "precision": 0.6463376373626374,
        "recall": 0.719
      },
      {
        "accuracy": 0.024,
        "f1": 0.01742268089053803,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ],
        "main_score": 0.01742268089053803,
        "precision": 0.01628441642120766,
        "recall": 0.024
      },
      {
        "accuracy": 0.042,
        "f1": 0.029788054187192117,
        "hf_subset": "mhr-eng",
        "languages": [
          "mhr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.029788054187192117,
        "precision": 0.027965691960482646,
        "recall": 0.042
      },
      {
        "accuracy": 0.2153209109730849,
        "f1": 0.18676169413747054,
        "hf_subset": "hsb-eng",
        "languages": [
          "hsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.18676169413747054,
        "precision": 0.17823336809933737,
        "recall": 0.2153209109730849
      },
      {
        "accuracy": 0.633,
        "f1": 0.5814582268608585,
        "hf_subset": "ido-eng",
        "languages": [
          "ido-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5814582268608585,
        "precision": 0.5628487983793475,
        "recall": 0.633
      },
      {
        "accuracy": 0.225,
        "f1": 0.19763898300947172,
        "hf_subset": "pol-eng",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.19763898300947172,
        "precision": 0.18982262233136124,
        "recall": 0.225
      },
      {
        "accuracy": 0.846,
        "f1": 0.8118166666666667,
        "hf_subset": "ina-eng",
        "languages": [
          "ina-Latn",
          "eng-Latn"
        ],
        "main_score": 0.8118166666666667,
        "precision": 0.7975428571428571,
        "recall": 0.846
      },
      {
        "accuracy": 0.374,
        "f1": 0.3235936240292525,
        "hf_subset": "oci-eng",
        "languages": [
          "oci-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3235936240292525,
        "precision": 0.3083845960043541,
        "recall": 0.374
      },
      {
        "accuracy": 0.366,
        "f1": 0.3130539904539904,
        "hf_subset": "swe-eng",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3130539904539904,
        "precision": 0.29717874425196406,
        "recall": 0.366
      },
      {
        "accuracy": 0.1919805589307412,
        "f1": 0.16105358717395027,
        "hf_subset": "slv-eng",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16105358717395027,
        "precision": 0.15286979775131868,
        "recall": 0.1919805589307412
      },
      {
        "accuracy": 0.4533333333333333,
        "f1": 0.40654337840673244,
        "hf_subset": "pms-eng",
        "languages": [
          "pms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.40654337840673244,
        "precision": 0.3928869919897784,
        "recall": 0.4533333333333333
      },
      {
        "accuracy": 0.765,
        "f1": 0.7130897546897548,
        "hf_subset": "por-eng",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.7130897546897548,
        "precision": 0.6917440476190476,
        "recall": 0.765
      },
      {
        "accuracy": 0.402,
        "f1": 0.35362793456543457,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.35362793456543457,
        "precision": 0.34026044898908864,
        "recall": 0.402
      },
      {
        "accuracy": 0.6141732283464567,
        "f1": 0.5436013680108168,
        "hf_subset": "ast-eng",
        "languages": [
          "ast-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5436013680108168,
        "precision": 0.5206692913385826,
        "recall": 0.6141732283464567
      },
      {
        "accuracy": 0.62,
        "f1": 0.5728020238095238,
        "hf_subset": "glg-eng",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5728020238095238,
        "precision": 0.5554527467863206,
        "recall": 0.62
      },
      {
        "accuracy": 0.01078167115902965,
        "f1": 0.008989349323987986,
        "hf_subset": "hye-eng",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ],
        "main_score": 0.008989349323987986,
        "precision": 0.008762423467733718,
        "recall": 0.01078167115902965
      },
      {
        "accuracy": 0.107,
        "f1": 0.09298934879934881,
        "hf_subset": "pam-eng",
        "languages": [
          "pam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09298934879934881,
        "precision": 0.08910172684458399,
        "recall": 0.107
      },
      {
        "accuracy": 0.022,
        "f1": 0.010117347290358616,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.010117347290358616,
        "precision": 0.00898000833079003,
        "recall": 0.022
      },
      {
        "accuracy": 0.219,
        "f1": 0.18114320401820402,
        "hf_subset": "hrv-eng",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.18114320401820402,
        "precision": 0.1703883851883852,
        "recall": 0.219
      },
      {
        "accuracy": 0.039,
        "f1": 0.03205395805965065,
        "hf_subset": "kor-eng",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ],
        "main_score": 0.03205395805965065,
        "precision": 0.030315441176470587,
        "recall": 0.039
      },
      {
        "accuracy": 0.012578616352201259,
        "f1": 0.009049615653389237,
        "hf_subset": "arz-eng",
        "languages": [
          "arz-Arab",
          "eng-Latn"
        ],
        "main_score": 0.009049615653389237,
        "precision": 0.008161126085654388,
        "recall": 0.012578616352201259
      },
      {
        "accuracy": 0.155,
        "f1": 0.11986695335742854,
        "hf_subset": "bel-eng",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.11986695335742854,
        "precision": 0.11191853537588571,
        "recall": 0.155
      },
      {
        "accuracy": 0.22755741127348644,
        "f1": 0.19717551690925178,
        "hf_subset": "dsb-eng",
        "languages": [
          "dsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.19717551690925178,
        "precision": 0.18770408436379207,
        "recall": 0.22755741127348644
      },
      {
        "accuracy": 0.114,
        "f1": 0.09349551159195121,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09349551159195121,
        "precision": 0.088417939005439,
        "recall": 0.114
      },
      {
        "accuracy": 0.34615384615384615,
        "f1": 0.3152777777777778,
        "hf_subset": "tzl-eng",
        "languages": [
          "tzl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3152777777777778,
        "precision": 0.30488782051282054,
        "recall": 0.34615384615384615
      },
      {
        "accuracy": 0.014150943396226415,
        "f1": 0.005907409032409031,
        "hf_subset": "yid-eng",
        "languages": [
          "yid-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.005907409032409031,
        "precision": 0.005064641102850499,
        "recall": 0.014150943396226415
      },
      {
        "accuracy": 0.815,
        "f1": 0.7753722222222222,
        "hf_subset": "fra-eng",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.7753722222222222,
        "precision": 0.7590345238095237,
        "recall": 0.815
      },
      {
        "accuracy": 0.1408695652173913,
        "f1": 0.11960254721124287,
        "hf_subset": "cym-eng",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11960254721124287,
        "precision": 0.11437835424024681,
        "recall": 0.1408695652173913
      },
      {
        "accuracy": 0.151,
        "f1": 0.13015271579486348,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13015271579486348,
        "precision": 0.12378742643124666,
        "recall": 0.151
      },
      {
        "accuracy": 0.3504273504273504,
        "f1": 0.28619312785979456,
        "hf_subset": "gsw-eng",
        "languages": [
          "gsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.28619312785979456,
        "precision": 0.26788168258756495,
        "recall": 0.3504273504273504
      },
      {
        "accuracy": 0.093,
        "f1": 0.07345357323835586,
        "hf_subset": "bre-eng",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07345357323835586,
        "precision": 0.06833709205448335,
        "recall": 0.093
      },
      {
        "accuracy": 0.129,
        "f1": 0.10134838492415801,
        "hf_subset": "ukr-eng",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.10134838492415801,
        "precision": 0.09421037001430835,
        "recall": 0.129
      },
      {
        "accuracy": 0.08863636363636364,
        "f1": 0.07463667285095857,
        "hf_subset": "mon-eng",
        "languages": [
          "mon-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.07463667285095857,
        "precision": 0.0703107870514014,
        "recall": 0.08863636363636364
      },
      {
        "accuracy": 0.05391304347826087,
        "f1": 0.042886858634472634,
        "hf_subset": "kaz-eng",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.042886858634472634,
        "precision": 0.04026618800691398,
        "recall": 0.05391304347826087
      },
      {
        "accuracy": 0.799,
        "f1": 0.7539214285714286,
        "hf_subset": "spa-eng",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.7539214285714286,
        "precision": 0.7359619047619047,
        "recall": 0.799
      },
      {
        "accuracy": 0.368,
        "f1": 0.318988154676607,
        "hf_subset": "ron-eng",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.318988154676607,
        "precision": 0.3051387866772085,
        "recall": 0.368
      },
      {
        "accuracy": 0.106,
        "f1": 0.08970473872532696,
        "hf_subset": "hun-eng",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08970473872532696,
        "precision": 0.08562853535353536,
        "recall": 0.106
      },
      {
        "accuracy": 0.016423357664233577,
        "f1": 0.013997340576019918,
        "hf_subset": "tha-eng",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 0.013997340576019918,
        "precision": 0.013689674721848203,
        "recall": 0.016423357664233577
      },
      {
        "accuracy": 0.03,
        "f1": 0.022184615384615382,
        "hf_subset": "kab-eng",
        "languages": [
          "kab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022184615384615382,
        "precision": 0.021154572120773835,
        "recall": 0.03
      },
      {
        "accuracy": 0.365,
        "f1": 0.30874848950202854,
        "hf_subset": "afr-eng",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.30874848950202854,
        "precision": 0.2913951730050995,
        "recall": 0.365
      },
      {
        "accuracy": 0.193,
        "f1": 0.14844816759087803,
        "hf_subset": "jpn-eng",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.14844816759087803,
        "precision": 0.13675689731415536,
        "recall": 0.193
      },
      {
        "accuracy": 0.069,
        "f1": 0.059318648756036436,
        "hf_subset": "ber-eng",
        "languages": [
          "ber-Tfng",
          "eng-Latn"
        ],
        "main_score": 0.059318648756036436,
        "precision": 0.05765579896898915,
        "recall": 0.069
      },
      {
        "accuracy": 0.091,
        "f1": 0.07869494542196154,
        "hf_subset": "fin-eng",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07869494542196154,
        "precision": 0.07582040386364657,
        "recall": 0.091
      },
      {
        "accuracy": 0.006925207756232687,
        "f1": 0.004217685388556757,
        "hf_subset": "khm-eng",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ],
        "main_score": 0.004217685388556757,
        "precision": 0.004186822422458201,
        "recall": 0.006925207756232687
      },
      {
        "accuracy": 0.061519903498190594,
        "f1": 0.04700073459088212,
        "hf_subset": "gla-eng",
        "languages": [
          "gla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04700073459088212,
        "precision": 0.04460423209849041,
        "recall": 0.061519903498190594
      },
      {
        "accuracy": 0.011904761904761904,
        "f1": 0.006023666951810665,
        "hf_subset": "amh-eng",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ],
        "main_score": 0.006023666951810665,
        "precision": 0.005988238668961561,
        "recall": 0.011904761904761904
      },
      {
        "accuracy": 0.695,
        "f1": 0.6410851073762839,
        "hf_subset": "ile-eng",
        "languages": [
          "ile-Latn",
          "eng-Latn"
        ],
        "main_score": 0.6410851073762839,
        "precision": 0.6206157106782106,
        "recall": 0.695
      },
      {
        "accuracy": 0.061,
        "f1": 0.04863728649569985,
        "hf_subset": "dtp-eng",
        "languages": [
          "dtp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04863728649569985,
        "precision": 0.04632428326059905,
        "recall": 0.061
      },
      {
        "accuracy": 0.10837438423645321,
        "f1": 0.07908118154423573,
        "hf_subset": "tuk-eng",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07908118154423573,
        "precision": 0.07261618360255089,
        "recall": 0.10837438423645321
      },
      {
        "accuracy": 0.14634146341463414,
        "f1": 0.11906715900043097,
        "hf_subset": "jav-eng",
        "languages": [
          "jav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11906715900043097,
        "precision": 0.1142175665346397,
        "recall": 0.14634146341463414
      },
      {
        "accuracy": 0.013,
        "f1": 0.009099839137428806,
        "hf_subset": "heb-eng",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.009099839137428806,
        "precision": 0.008451436781609194,
        "recall": 0.013
      },
      {
        "accuracy": 0.068,
        "f1": 0.05245556139164386,
        "hf_subset": "cor-eng",
        "languages": [
          "cor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05245556139164386,
        "precision": 0.04935074023199023,
        "recall": 0.068
      },
      {
        "accuracy": 0.094,
        "f1": 0.07410655549761856,
        "hf_subset": "kzj-eng",
        "languages": [
          "kzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07410655549761856,
        "precision": 0.06979120738273661,
        "recall": 0.094
      },
      {
        "accuracy": 0.054,
        "f1": 0.03808896312326666,
        "hf_subset": "tat-eng",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.03808896312326666,
        "precision": 0.035016780777433275,
        "recall": 0.054
      },
      {
        "accuracy": 0.017,
        "f1": 0.01035879809845327,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.01035879809845327,
        "precision": 0.009520561821219716,
        "recall": 0.017
      },
      {
        "accuracy": 0.012,
        "f1": 0.007982480711582878,
        "hf_subset": "uig-eng",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ],
        "main_score": 0.007982480711582878,
        "precision": 0.007666484348125215,
        "recall": 0.012
      },
      {
        "accuracy": 0.185,
        "f1": 0.16123597901285402,
        "hf_subset": "ind-eng",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16123597901285402,
        "precision": 0.15558851871919013,
        "recall": 0.185
      },
      {
        "accuracy": 0.159,
        "f1": 0.12488052206205609,
        "hf_subset": "isl-eng",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12488052206205609,
        "precision": 0.11656894353140944,
        "recall": 0.159
      },
      {
        "accuracy": 0.102803738317757,
        "f1": 0.07804361638811588,
        "hf_subset": "uzb-eng",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07804361638811588,
        "precision": 0.07211166711109723,
        "recall": 0.102803738317757
      },
      {
        "accuracy": 0.117,
        "f1": 0.09328817171359584,
        "hf_subset": "tur-eng",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09328817171359584,
        "precision": 0.08626784834229392,
        "recall": 0.117
      },
      {
        "accuracy": 0.021,
        "f1": 0.013018244179180256,
        "hf_subset": "pes-eng",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 0.013018244179180256,
        "precision": 0.012193948412698411,
        "recall": 0.021
      },
      {
        "accuracy": 0.002911208151382824,
        "f1": 0.0001256362715723189,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.0001256362715723189,
        "precision": 6.429580844356419e-05,
        "recall": 0.002911208151382824
      },
      {
        "accuracy": 0.114,
        "f1": 0.09185066137566136,
        "hf_subset": "lit-eng",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09185066137566136,
        "precision": 0.08591355789934674,
        "recall": 0.114
      },
      {
        "accuracy": 0.16,
        "f1": 0.13851445279866334,
        "hf_subset": "slk-eng",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13851445279866334,
        "precision": 0.13308173722412853,
        "recall": 0.16
      },
      {
        "accuracy": 0.03832335329341317,
        "f1": 0.0218179602183174,
        "hf_subset": "orv-eng",
        "languages": [
          "orv-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0218179602183174,
        "precision": 0.019609383109314194,
        "recall": 0.03832335329341317
      },
      {
        "accuracy": 0.34306569343065696,
        "f1": 0.30135557872784147,
        "hf_subset": "cha-eng",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.30135557872784147,
        "precision": 0.2861313868613139,
        "recall": 0.34306569343065696
      },
      {
        "accuracy": 0.3053435114503817,
        "f1": 0.2613287475882896,
        "hf_subset": "fao-eng",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2613287475882896,
        "precision": 0.24920194309507282,
        "recall": 0.3053435114503817
      },
      {
        "accuracy": 0.592,
        "f1": 0.5394882105022349,
        "hf_subset": "cbk-eng",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5394882105022349,
        "precision": 0.5223868797868797,
        "recall": 0.592
      },
      {
        "accuracy": 0.156,
        "f1": 0.12300621427628455,
        "hf_subset": "yue-eng",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ],
        "main_score": 0.12300621427628455,
        "precision": 0.11497169652105484,
        "recall": 0.156
      },
      {
        "accuracy": 0.082,
        "f1": 0.06025340738755372,
        "hf_subset": "gle-eng",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06025340738755372,
        "precision": 0.05586342803726297,
        "recall": 0.082
      },
      {
        "accuracy": 0.466,
        "f1": 0.41420703185703184,
        "hf_subset": "nds-eng",
        "languages": [
          "nds-Latn",
          "eng-Latn"
        ],
        "main_score": 0.41420703185703184,
        "precision": 0.3982165873015873,
        "recall": 0.466
      },
      {
        "accuracy": 0.416,
        "f1": 0.3534613579403053,
        "hf_subset": "lat-eng",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3534613579403053,
        "precision": 0.3345977294240452,
        "recall": 0.416
      },
      {
        "accuracy": 0.234,
        "f1": 0.20627482931138144,
        "hf_subset": "zsm-eng",
        "languages": [
          "zsm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.20627482931138144,
        "precision": 0.19925156077994774,
        "recall": 0.234
      },
      {
        "accuracy": 0.395,
        "f1": 0.3429200207200207,
        "hf_subset": "nob-eng",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3429200207200207,
        "precision": 0.3280779731379731,
        "recall": 0.395
      },
      {
        "accuracy": 0.079,
        "f1": 0.0668594145647854,
        "hf_subset": "est-eng",
        "languages": [
          "est-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0668594145647854,
        "precision": 0.0637051282051282,
        "recall": 0.079
      },
      {
        "accuracy": 0.589,
        "f1": 0.5328444628470945,
        "hf_subset": "nld-eng",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5328444628470945,
        "precision": 0.5123572362278244,
        "recall": 0.589
      },
      {
        "accuracy": 0.61,
        "f1": 0.56542558356676,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.56542558356676,
        "precision": 0.5504633820456083,
        "recall": 0.61
      },
      {
        "accuracy": 0.134,
        "f1": 0.11242902617678159,
        "hf_subset": "war-eng",
        "languages": [
          "war-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11242902617678159,
        "precision": 0.10759029677573365,
        "recall": 0.134
      },
      {
        "accuracy": 0.01646542261251372,
        "f1": 0.007645322838998311,
        "hf_subset": "arq-eng",
        "languages": [
          "arq-Arab",
          "eng-Latn"
        ],
        "main_score": 0.007645322838998311,
        "precision": 0.006564872939495286,
        "recall": 0.01646542261251372
      },
      {
        "accuracy": 0.141,
        "f1": 0.10794334706537147,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.10794334706537147,
        "precision": 0.10200438440819283,
        "recall": 0.141
      },
      {
        "accuracy": 0.5373134328358209,
        "f1": 0.4615336777650211,
        "hf_subset": "ang-eng",
        "languages": [
          "ang-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4615336777650211,
        "precision": 0.43358208955223876,
        "recall": 0.5373134328358209
      },
      {
        "accuracy": 0.454,
        "f1": 0.4054234126984127,
        "hf_subset": "epo-eng",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4054234126984127,
        "precision": 0.3892690836940837,
        "recall": 0.454
      }
    ]
  },
  "task_name": "Tatoeba"
}