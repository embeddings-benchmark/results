{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 14.17385983467102,
  "kg_co2_emissions": 0.00044810163808431153,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5798076923076922,
        "f1": 0.44392663612028277,
        "f1_weighted": 0.6408259462335527,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5798076923076922,
        "scores_per_experiment": [
          {
            "accuracy": 0.6346153846153846,
            "f1": 0.4855732502791327,
            "f1_weighted": 0.6963828027176444
          },
          {
            "accuracy": 0.5865384615384616,
            "f1": 0.46225161269409054,
            "f1_weighted": 0.6389030189234409
          },
          {
            "accuracy": 0.6634615384615384,
            "f1": 0.5145114942528736,
            "f1_weighted": 0.7131907603890362
          },
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.47586872586872586,
            "f1_weighted": 0.6771235521235521
          },
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.42077798861480076,
            "f1_weighted": 0.6472230331338491
          },
          {
            "accuracy": 0.5,
            "f1": 0.4090153452685422,
            "f1_weighted": 0.5716678142829038
          },
          {
            "accuracy": 0.5673076923076923,
            "f1": 0.46120789779326365,
            "f1_weighted": 0.6238497275082641
          },
          {
            "accuracy": 0.5576923076923077,
            "f1": 0.404288240495137,
            "f1_weighted": 0.6208724409984357
          },
          {
            "accuracy": 0.6057692307692307,
            "f1": 0.4481140839836492,
            "f1_weighted": 0.6417760054883801
          },
          {
            "accuracy": 0.49038461538461536,
            "f1": 0.35765772195261203,
            "f1_weighted": 0.5772703067700213
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5752380952380951,
        "f1": 0.4285834734829758,
        "f1_weighted": 0.6311506087299282,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5752380952380951,
        "scores_per_experiment": [
          {
            "accuracy": 0.638095238095238,
            "f1": 0.49353448275862066,
            "f1_weighted": 0.6934811165845649
          },
          {
            "accuracy": 0.580952380952381,
            "f1": 0.4352225672877847,
            "f1_weighted": 0.638344671201814
          },
          {
            "accuracy": 0.5904761904761905,
            "f1": 0.43551567239635997,
            "f1_weighted": 0.6533111849390919
          },
          {
            "accuracy": 0.5714285714285714,
            "f1": 0.4570205633887503,
            "f1_weighted": 0.6571172316444842
          },
          {
            "accuracy": 0.5523809523809524,
            "f1": 0.37092897022332505,
            "f1_weighted": 0.597632340777502
          },
          {
            "accuracy": 0.42857142857142855,
            "f1": 0.3456022489041357,
            "f1_weighted": 0.4834626589343571
          },
          {
            "accuracy": 0.6,
            "f1": 0.46514245014245015,
            "f1_weighted": 0.6522865282865283
          },
          {
            "accuracy": 0.580952380952381,
            "f1": 0.4129659769045958,
            "f1_weighted": 0.626962352793555
          },
          {
            "accuracy": 0.5714285714285714,
            "f1": 0.3891044568948112,
            "f1_weighted": 0.6107619960966417
          },
          {
            "accuracy": 0.638095238095238,
            "f1": 0.48079734592892487,
            "f1_weighted": 0.6981460060407428
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}