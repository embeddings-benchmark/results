{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 100.88558840751648,
  "kg_co2_emissions": 0.005678865925513109,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.2705078125,
        "f1": 0.22224953132294584,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.22224953132294584,
        "precision": 0.2069674973108937,
        "recall": 0.2705078125
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.016264257808472148,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.016264257808472148,
        "precision": 0.014535523171834645,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03015366138275382,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.03015366138275382,
        "precision": 0.027666433002190606,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002415648983693438,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.002415648983693438,
        "precision": 0.0017836660162857253,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.025098543638128565,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.025098543638128565,
        "precision": 0.0232208189216787,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0039781797403230824,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0039781797403230824,
        "precision": 0.003284660218253968,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.035766310114536425,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.035766310114536425,
        "precision": 0.03241647994916961,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0028013069574420674,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0028013069574420674,
        "precision": 0.00247635774979525,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.010662894778068433,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.010662894778068433,
        "precision": 0.008761440544467985,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.03568979848276724,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.03568979848276724,
        "precision": 0.0329337285977911,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003176805449695122,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.003176805449695122,
        "precision": 0.0030706873636859324,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.031644674132214334,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.031644674132214334,
        "precision": 0.028535058820415453,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0043865854149191495,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0043865854149191495,
        "precision": 0.003867767345416816,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.03706397875692654,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.03706397875692654,
        "precision": 0.03413851440034521,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.016560827123499457,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.016560827123499457,
        "precision": 0.013879926976613447,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013932534895184723,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0013932534895184723,
        "precision": 0.001209757217618657,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.03559549805767572,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.03559549805767572,
        "precision": 0.032981599781881116,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019193819867886178,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0019193819867886178,
        "precision": 0.0016287667410714284,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.02335896505714491,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.02335896505714491,
        "precision": 0.02115083362655043,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0061590589020718,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0061590589020718,
        "precision": 0.005338775945152234,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012436565170940172,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0012436565170940172,
        "precision": 0.0011243318256578948,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007961309523809523,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.007961309523809523,
        "precision": 0.007238610998376624,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.28125,
        "f1": 0.2250558401303721,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.2250558401303721,
        "precision": 0.207725521006771,
        "recall": 0.28125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04123873973551481,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.04123873973551481,
        "precision": 0.03801501710399753,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07489638166165485,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.07489638166165485,
        "precision": 0.06950790555637185,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.01497792712380569,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.01497792712380569,
        "precision": 0.01359849544416695,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06435709775697138,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.06435709775697138,
        "precision": 0.05981778742835665,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002824613112673306,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.002824613112673306,
        "precision": 0.0025651958626760566,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.09814737318157851,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.09814737318157851,
        "precision": 0.08989182457137965,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004191806655907668,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.004191806655907668,
        "precision": 0.003492933269951499,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.03210112533307083,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.03210112533307083,
        "precision": 0.02978973297681373,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.1875,
        "f1": 0.1578488463179536,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.1578488463179536,
        "precision": 0.15134909923856776,
        "recall": 0.1875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013697174546632124,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0013697174546632124,
        "precision": 0.0012219697430285344,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.10712302051068254,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.10712302051068254,
        "precision": 0.100830031979868,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0025559344042812623,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0025559344042812623,
        "precision": 0.0019192132142610973,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.12787328555762986,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.12787328555762986,
        "precision": 0.1206440740987093,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.007713185252247752,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.007713185252247752,
        "precision": 0.006336686849961479,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001202408988193671,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.001202408988193671,
        "precision": 0.0011030596940381635,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.1074383399761931,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.1074383399761931,
        "precision": 0.1013009587244334,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002408742192123465,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.002408742192123465,
        "precision": 0.0022092720647408147,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07858968336374145,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.07858968336374145,
        "precision": 0.07230289132413874,
        "recall": 0.109375
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.013164850452062265,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.013164850452062265,
        "precision": 0.011865135731361684,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012183321657446328,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0012183321657446328,
        "precision": 0.0011111264692368883,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04864510334346915,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.04864510334346915,
        "precision": 0.04531604594886586,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.049519550709847676,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.049519550709847676,
        "precision": 0.04373467515557359,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.10804277445416424,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.10804277445416424,
        "precision": 0.10055780893311732,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.400390625,
        "f1": 0.37277697963826784,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.37277697963826784,
        "precision": 0.36424688999151894,
        "recall": 0.400390625
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.10678595545716787,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.10678595545716787,
        "precision": 0.1013741693419439,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.359375,
        "f1": 0.32489647098289065,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.32489647098289065,
        "precision": 0.31378532074332854,
        "recall": 0.359375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.021704785722827614,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.021704785722827614,
        "precision": 0.017302681322465468,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.3798828125,
        "f1": 0.34935424276244587,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.34935424276244587,
        "precision": 0.34056463521711366,
        "recall": 0.3798828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004453967433164381,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.004453967433164381,
        "precision": 0.003954355047713881,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.30078125,
        "f1": 0.275743977915091,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.275743977915091,
        "precision": 0.2676934831604343,
        "recall": 0.30078125
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.14817592075892855,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.14817592075892855,
        "precision": 0.1378334496093947,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.11088140976638941,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11088140976638941,
        "precision": 0.1018452964963516,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.10162238853541214,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.10162238853541214,
        "precision": 0.09333614174626287,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0027533352401253584,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0027533352401253584,
        "precision": 0.002385976526548596,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.1258891393087252,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.1258891393087252,
        "precision": 0.11693021306237932,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.008708854802604802,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.008708854802604802,
        "precision": 0.0072903850403406014,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.18549645598370929,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.18549645598370929,
        "precision": 0.1805156757305195,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.14857743511058863,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.14857743511058863,
        "precision": 0.14077017618962168,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0025836017329043033,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0025836017329043033,
        "precision": 0.002355111153051494,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.4189453125,
        "f1": 0.39081792863531145,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.39081792863531145,
        "precision": 0.3816879643984998,
        "recall": 0.4189453125
      },
      {
        "accuracy": 0.2138671875,
        "f1": 0.1859268335830836,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1859268335830836,
        "precision": 0.17677951388888888,
        "recall": 0.2138671875
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.1604991693606322,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1604991693606322,
        "precision": 0.15098129438178778,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.299683154825915,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.299683154825915,
        "precision": 0.2936818477765268,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.07056234780844156,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.07056234780844156,
        "precision": 0.0618245500752406,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.23046875,
        "f1": 0.1859017989389083,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.1859017989389083,
        "precision": 0.1710154103708791,
        "recall": 0.23046875
      },
      {
        "accuracy": 0.390625,
        "f1": 0.35887041575008627,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.35887041575008627,
        "precision": 0.34911625994912826,
        "recall": 0.390625
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.1186764104010173,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.1186764104010173,
        "precision": 0.11302594105781177,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.521484375,
        "f1": 0.4841119212064354,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4841119212064354,
        "precision": 0.4721305306022103,
        "recall": 0.521484375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026778380208040197,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.026778380208040197,
        "precision": 0.02264667194858721,
        "recall": 0.046875
      },
      {
        "accuracy": 0.69921875,
        "f1": 0.6546903950382236,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6546903950382236,
        "precision": 0.6384806315104167,
        "recall": 0.69921875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003201412493063263,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.003201412493063263,
        "precision": 0.002703356525455927,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.361328125,
        "f1": 0.33151257036472814,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.33151257036472814,
        "precision": 0.32231949438826235,
        "recall": 0.361328125
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.5293011329485787,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5293011329485787,
        "precision": 0.5114230685763889,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.11087032773615099,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11087032773615099,
        "precision": 0.10263220315873517,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.3515625,
        "f1": 0.3029024415254884,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3029024415254884,
        "precision": 0.2869441547333896,
        "recall": 0.3515625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0026608945416858663,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0026608945416858663,
        "precision": 0.0023393253661740847,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.443359375,
        "f1": 0.38783469812522553,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.38783469812522553,
        "precision": 0.3694930995320542,
        "recall": 0.443359375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007696691272451962,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.007696691272451962,
        "precision": 0.0067924561777833285,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.2021484375,
        "f1": 0.1862555695810521,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1862555695810521,
        "precision": 0.18137785395891926,
        "recall": 0.2021484375
      },
      {
        "accuracy": 0.2646484375,
        "f1": 0.23152625965424645,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.23152625965424645,
        "precision": 0.221636078764985,
        "recall": 0.2646484375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003479999185358882,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003479999185358882,
        "precision": 0.003256708754581023,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.6171875,
        "f1": 0.5769378768316038,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5769378768316038,
        "precision": 0.5622448149181547,
        "recall": 0.6171875
      },
      {
        "accuracy": 0.2236328125,
        "f1": 0.19931992920274166,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.19931992920274166,
        "precision": 0.19137320284909717,
        "recall": 0.2236328125
      },
      {
        "accuracy": 0.1884765625,
        "f1": 0.16514136904761903,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.16514136904761903,
        "precision": 0.15592447916666666,
        "recall": 0.1884765625
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.40938797755711903,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.40938797755711903,
        "precision": 0.39999653479263547,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.0294479204225869,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0294479204225869,
        "precision": 0.025806465441539455,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.057968934418917435,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.057968934418917435,
        "precision": 0.05144474922308103,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.17541141944733574,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.17541141944733574,
        "precision": 0.16300842886748543,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.2861328125,
        "f1": 0.2332137101584542,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.2332137101584542,
        "precision": 0.21889947888483044,
        "recall": 0.2861328125
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.2066269008014932,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.2066269008014932,
        "precision": 0.19315878891074204,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.011695437238203963,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.011695437238203963,
        "precision": 0.008898243298299836,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.291015625,
        "f1": 0.24038272468576743,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.24038272468576743,
        "precision": 0.2263898953711109,
        "recall": 0.291015625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.002728218804718117,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.002728218804718117,
        "precision": 0.002088421528673231,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.25,
        "f1": 0.19711960195502243,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.19711960195502243,
        "precision": 0.1829483494628635,
        "recall": 0.25
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.09077023779172216,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.09077023779172216,
        "precision": 0.08407189426925334,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.07486041609576766,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.07486041609576766,
        "precision": 0.0639811470402253,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.05776282100011057,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.05776282100011057,
        "precision": 0.051765210700757576,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0029706458905677654,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0029706458905677654,
        "precision": 0.002533209539203612,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06397407155849766,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.06397407155849766,
        "precision": 0.05998432713918939,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.004717898490833116,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.004717898490833116,
        "precision": 0.003945464553414061,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.12247480555354734,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.12247480555354734,
        "precision": 0.11200166048130003,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.08885920104806369,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.08885920104806369,
        "precision": 0.08353819118107769,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0019960175454101126,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0019960175454101126,
        "precision": 0.0015526849711111417,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.2763671875,
        "f1": 0.2279108619296239,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.2279108619296239,
        "precision": 0.2150476219201805,
        "recall": 0.2763671875
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.10665740742098889,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.10665740742098889,
        "precision": 0.09630530536761622,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.10771157372563259,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.10771157372563259,
        "precision": 0.09681296065268752,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.25390625,
        "f1": 0.2024980353470503,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.2024980353470503,
        "precision": 0.18821518242161925,
        "recall": 0.25390625
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.05739319816468254,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.05739319816468254,
        "precision": 0.05118127761739894,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.18457348315746752,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.18457348315746752,
        "precision": 0.17099070363230517,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.375,
        "f1": 0.33718340398027896,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.33718340398027896,
        "precision": 0.32622135033501376,
        "recall": 0.375
      },
      {
        "accuracy": 0.5234375,
        "f1": 0.48560655381944445,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.48560655381944445,
        "precision": 0.47369258250175067,
        "recall": 0.5234375
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.10881372048722467,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.10881372048722467,
        "precision": 0.10371026761193543,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.026452982639760203,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.026452982639760203,
        "precision": 0.021801698976178143,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5582867111187424,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5582867111187424,
        "precision": 0.5430468872376253,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003706983805668016,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.003706983805668016,
        "precision": 0.0034106450433973147,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.294921875,
        "f1": 0.26746379972543594,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.26746379972543594,
        "precision": 0.2577569506938563,
        "recall": 0.294921875
      },
      {
        "accuracy": 0.4326171875,
        "f1": 0.3763541525748557,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3763541525748557,
        "precision": 0.35670737044817924,
        "recall": 0.4326171875
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.12300121753246751,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.12300121753246751,
        "precision": 0.11437230123753561,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.626953125,
        "f1": 0.5665310329861111,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5665310329861111,
        "precision": 0.5423270089285714,
        "recall": 0.626953125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003775013523942455,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003775013523942455,
        "precision": 0.0031367893304375975,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.3642578125,
        "f1": 0.30903530063686313,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.30903530063686313,
        "precision": 0.28989666693157523,
        "recall": 0.3642578125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.010057826850511379,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.010057826850511379,
        "precision": 0.008243770245351965,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.212890625,
        "f1": 0.1971076588032708,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1971076588032708,
        "precision": 0.19236095175869364,
        "recall": 0.212890625
      },
      {
        "accuracy": 0.283203125,
        "f1": 0.24154176444215505,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.24154176444215505,
        "precision": 0.2277887693903319,
        "recall": 0.283203125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002060134991151887,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002060134991151887,
        "precision": 0.0020088061070419744,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.5029296875,
        "f1": 0.46356194173922594,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.46356194173922594,
        "precision": 0.45027547051472827,
        "recall": 0.5029296875
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.1904994419642857,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1904994419642857,
        "precision": 0.18096788194444444,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.1962890625,
        "f1": 0.1689387529151668,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1689387529151668,
        "precision": 0.15926535404823283,
        "recall": 0.1962890625
      },
      {
        "accuracy": 0.34375,
        "f1": 0.31640216337481963,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.31640216337481963,
        "precision": 0.3072186952461371,
        "recall": 0.34375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0033661597396050617,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.0033661597396050617,
        "precision": 0.0026867706375313283,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0021366042455412777,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0021366042455412777,
        "precision": 0.0013214509257664325,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.02187789351851852,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.02187789351851852,
        "precision": 0.02124168328078635,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.025966314621913577,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.025966314621913577,
        "precision": 0.025533157341884122,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005699822096306471,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.005699822096306471,
        "precision": 0.005459539933795303,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.02556697974744526,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.02556697974744526,
        "precision": 0.02518752331370927,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.02206832138298852,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.02206832138298852,
        "precision": 0.021531070543993842,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.10372274560866013,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.10372274560866013,
        "precision": 0.09447877561891234,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.019243289262820512,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.019243289262820512,
        "precision": 0.01873659620098039,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0018776863280514774,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.0018776863280514774,
        "precision": 0.0015115051731381761,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06898627089056776,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.06898627089056776,
        "precision": 0.06429340516254578,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018513997395833333,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0018513997395833333,
        "precision": 0.0015118467581925242,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.05310519773265489,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.05310519773265489,
        "precision": 0.04644151998455174,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001453053393647282,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.001453053393647282,
        "precision": 0.0012489113256736804,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.012944318495322283,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.012944318495322283,
        "precision": 0.01134918270140427,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.05411972738632895,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.05411972738632895,
        "precision": 0.050400802667002115,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016820520189181436,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0016820520189181436,
        "precision": 0.001369512648809524,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03886143974149489,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.03886143974149489,
        "precision": 0.03432178704723601,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.02510401822068404,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.02510401822068404,
        "precision": 0.024363000408496732,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.03131217567655834,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.03131217567655834,
        "precision": 0.03097055530394525,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08905485169103561,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.08905485169103561,
        "precision": 0.08252611054253223,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.02394219406512605,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.02394219406512605,
        "precision": 0.023283015536723163,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.06953884120386515,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06953884120386515,
        "precision": 0.06267775279134243,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.2919921875,
        "f1": 0.2364680117348827,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2364680117348827,
        "precision": 0.2184950086805556,
        "recall": 0.2919921875
      },
      {
        "accuracy": 0.3671875,
        "f1": 0.3371185464203042,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.3371185464203042,
        "precision": 0.32879146125914094,
        "recall": 0.3671875
      },
      {
        "accuracy": 0.6923828125,
        "f1": 0.6512765978787348,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6512765978787348,
        "precision": 0.6371561100766063,
        "recall": 0.6923828125
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.12342878304400179,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.12342878304400179,
        "precision": 0.11837437147477925,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.5517578125,
        "f1": 0.5134403905960088,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5134403905960088,
        "precision": 0.5009899856146539,
        "recall": 0.5517578125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022556799391572256,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.022556799391572256,
        "precision": 0.01822795355283677,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020713480791037,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0020713480791037,
        "precision": 0.0016346509533791743,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.322265625,
        "f1": 0.29062216565740245,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.29062216565740245,
        "precision": 0.2799891989593686,
        "recall": 0.322265625
      },
      {
        "accuracy": 0.7294921875,
        "f1": 0.6759369861908924,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6759369861908924,
        "precision": 0.6555738044507576,
        "recall": 0.7294921875
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.097345782619809,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.097345782619809,
        "precision": 0.09028566298016373,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.4736328125,
        "f1": 0.41969372858044734,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.41969372858044734,
        "precision": 0.40100897181103806,
        "recall": 0.4736328125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0032411236452330686,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0032411236452330686,
        "precision": 0.0027089335495308333,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.5234894283234126,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5234894283234126,
        "precision": 0.5020067325975529,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003252131753112231,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.003252131753112231,
        "precision": 0.002730591534173977,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.1706768597794721,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1706768597794721,
        "precision": 0.16607830850468397,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.314453125,
        "f1": 0.2753829558028777,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.2753829558028777,
        "precision": 0.2641741208202031,
        "recall": 0.314453125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002129021433016479,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002129021433016479,
        "precision": 0.002046588328510972,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.5986328125,
        "f1": 0.5572970391695977,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5572970391695977,
        "precision": 0.5436411936482816,
        "recall": 0.5986328125
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.1738688656508799,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1738688656508799,
        "precision": 0.16522493348665224,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.15298084077380952,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.15298084077380952,
        "precision": 0.14381510416666665,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.3779296875,
        "f1": 0.3466401313421661,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.3466401313421661,
        "precision": 0.33876510976167185,
        "recall": 0.3779296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016950034273403836,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0016950034273403836,
        "precision": 0.0011241957720588235,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0031993090338237958,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0031993090338237958,
        "precision": 0.00242638352296447,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007698290618060696,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0007698290618060696,
        "precision": 0.0004895478680285344,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013713787553648069,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0013713787553648069,
        "precision": 0.0012228032594086022,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.8109796075239646e-05,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 5.8109796075239646e-05,
        "precision": 2.9761037977632807e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011886327287113565,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0011886327287113565,
        "precision": 0.0010934911435639071,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.0989893353174603,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.0989893353174603,
        "precision": 0.0859179809876253,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014429673499103944,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0014429673499103944,
        "precision": 0.0012407739850067386,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018397539511494252,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0018397539511494252,
        "precision": 0.0015818425422705314,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002333549082996899,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.002333549082996899,
        "precision": 0.0021596356542932828,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.06374705481150793,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.06374705481150793,
        "precision": 0.05493280319940476,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0036825513082837298,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0036825513082837298,
        "precision": 0.0030474354204822955,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.040654111784482874,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.040654111784482874,
        "precision": 0.03440315607028118,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015320279219914802,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0015320279219914802,
        "precision": 0.0010589838197405828,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02135823442700333,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.02135823442700333,
        "precision": 0.019127192750822745,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01663170093802048,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.01663170093802048,
        "precision": 0.014348880828373016,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0012672338030148265,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0012672338030148265,
        "precision": 0.0007839330326082426,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02676007086954848,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.02676007086954848,
        "precision": 0.023105702205828582,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002640865512208068,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.002640865512208068,
        "precision": 0.0023892305703309695,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00021701388888888888,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.00021701388888888888,
        "precision": 0.0001220703125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08161709167568543,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.08161709167568543,
        "precision": 0.07232996405359687,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016382189764492753,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0016382189764492753,
        "precision": 0.0014701801571038251,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.03025556257978133,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.03025556257978133,
        "precision": 0.02813427620556527,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.06610978535761994,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.06610978535761994,
        "precision": 0.059955932831389946,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.275390625,
        "f1": 0.25849220878349377,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.25849220878349377,
        "precision": 0.2527815825667388,
        "recall": 0.275390625
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.3225773372135677,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.3225773372135677,
        "precision": 0.31346746999256947,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.11112979064056779,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.11112979064056779,
        "precision": 0.10590243821838474,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.2900390625,
        "f1": 0.26501972338350865,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.26501972338350865,
        "precision": 0.2580283547785399,
        "recall": 0.2900390625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.017622841167550744,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.017622841167550744,
        "precision": 0.013681938047172422,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.310546875,
        "f1": 0.28315295895000625,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.28315295895000625,
        "precision": 0.2755475088647348,
        "recall": 0.310546875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0014002284456600005,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0014002284456600005,
        "precision": 0.0008502604166666666,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07036163148151889,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.07036163148151889,
        "precision": 0.06365406383167614,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09819025917658729,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.09819025917658729,
        "precision": 0.08997646571441531,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.055043254456278064,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.055043254456278064,
        "precision": 0.05045746634346578,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021729963993557654,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0021729963993557654,
        "precision": 0.0015043712797619046,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06545720749462526,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.06545720749462526,
        "precision": 0.061187865859361736,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0066826746025964775,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0066826746025964775,
        "precision": 0.006037089547866283,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.20753542770756134,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.20753542770756134,
        "precision": 0.2027022319955532,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.0679899465292704,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0679899465292704,
        "precision": 0.06205747972865585,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00038192698813155395,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00038192698813155395,
        "precision": 0.0002116776516477803,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.359375,
        "f1": 0.3281869111568324,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.3281869111568324,
        "precision": 0.3194909621341434,
        "recall": 0.359375
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.16870272197420633,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.16870272197420633,
        "precision": 0.15981226474964985,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.14826329269688643,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.14826329269688643,
        "precision": 0.13978223613664215,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.73046875,
        "f1": 0.6856059123551081,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.6856059123551081,
        "precision": 0.6682778010292659,
        "recall": 0.73046875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09328140563749117,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.09328140563749117,
        "precision": 0.08555338541666666,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.3251953125,
        "f1": 0.26884064281094383,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.26884064281094383,
        "precision": 0.2509979278533966,
        "recall": 0.3251953125
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.09584311767852034,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.09584311767852034,
        "precision": 0.08863144545086755,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.435546875,
        "f1": 0.3654012497929837,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3654012497929837,
        "precision": 0.34371788916944324,
        "recall": 0.435546875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.02251033433418635,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.02251033433418635,
        "precision": 0.0204611261281279,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.25884650710963175,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.25884650710963175,
        "precision": 0.23896632926173939,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00470500010440468,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.00470500010440468,
        "precision": 0.0040809640663156295,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.5712890625,
        "f1": 0.4944313390602453,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4944313390602453,
        "precision": 0.46688255321067823,
        "recall": 0.5712890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003017552149223109,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.003017552149223109,
        "precision": 0.002669886202801162,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.06366589222843864,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.06366589222843864,
        "precision": 0.057996887411308734,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009810115318906606,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0009810115318906606,
        "precision": 0.0009787920947488585,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.4921875,
        "f1": 0.4344892023454353,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4344892023454353,
        "precision": 0.4146172945977633,
        "recall": 0.4921875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.002671500453826789,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002671500453826789,
        "precision": 0.001994521898712812,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.6806640625,
        "f1": 0.6222884889632937,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6222884889632937,
        "precision": 0.5988111091382575,
        "recall": 0.6806640625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007400422927766678,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.007400422927766678,
        "precision": 0.006798837699142158,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013900631360456136,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0013900631360456136,
        "precision": 0.0012177972696945912,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.384765625,
        "f1": 0.3395748015762199,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.3395748015762199,
        "precision": 0.32511017330109127,
        "recall": 0.384765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0021607786744505496,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0021607786744505496,
        "precision": 0.002063105924357228,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.296875,
        "f1": 0.2427723874882316,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2427723874882316,
        "precision": 0.22638575113546508,
        "recall": 0.296875
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.02036772228422619,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.02036772228422619,
        "precision": 0.01800955261136713,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013237847222222223,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0013237847222222223,
        "precision": 0.0011683872767857143,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.08549878434574483,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.08549878434574483,
        "precision": 0.07823476020809778,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010601672242786637,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.0010601672242786637,
        "precision": 0.0006614557881305316,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0010629234218358396,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0010629234218358396,
        "precision": 0.0006251691949884451,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.09026963975694444,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.09026963975694444,
        "precision": 0.0853529207232267,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.09141017982897384,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.09141017982897384,
        "precision": 0.08584181262600807,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.03232781758172383,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.03232781758172383,
        "precision": 0.029038193727174887,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.08652843505289204,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.08652843505289204,
        "precision": 0.08179505801719726,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.05365007884796125,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.05365007884796125,
        "precision": 0.04448442995806277,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.08468898538632685,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.08468898538632685,
        "precision": 0.07865983514185783,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.069311291082588,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.069311291082588,
        "precision": 0.06167086087740384,
        "recall": 0.09375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.08987440751763667,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.08987440751763667,
        "precision": 0.08434851352225672,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00038650395620204605,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.00038650395620204605,
        "precision": 0.00020752901612276612,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015319875208855472,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0015319875208855472,
        "precision": 0.0012843466212606838,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.018369552680648077,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.018369552680648077,
        "precision": 0.015767390043360502,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005601986434108526,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0005601986434108526,
        "precision": 0.0003266034968588322,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006064357121592176,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.006064357121592176,
        "precision": 0.004721352749123556,
        "recall": 0.015625
      },
      {
        "accuracy": 0.171875,
        "f1": 0.15529069635632184,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.15529069635632184,
        "precision": 0.15049173374368688,
        "recall": 0.171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00037677761366790844,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.00037677761366790844,
        "precision": 0.00021265886754928432,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.010540027044819468,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.010540027044819468,
        "precision": 0.008924646922981023,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.09464945608816558,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.09464945608816558,
        "precision": 0.08983891613800124,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.12150607638888887,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.12150607638888887,
        "precision": 0.11734324488146552,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.23046875,
        "f1": 0.20281427556818182,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.20281427556818182,
        "precision": 0.19269039964969242,
        "recall": 0.23046875
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.0937108120987159,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.0937108120987159,
        "precision": 0.08787802024592732,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.06429935217777014,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06429935217777014,
        "precision": 0.057060800794759635,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.25390625,
        "f1": 0.20667455847725288,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.20667455847725288,
        "precision": 0.19198952400425862,
        "recall": 0.25390625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06320750530978406,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.06320750530978406,
        "precision": 0.05585262040433694,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.2607421875,
        "f1": 0.2058824677698033,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2058824677698033,
        "precision": 0.1906238697193287,
        "recall": 0.2607421875
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.01687710512720631,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.01687710512720631,
        "precision": 0.014840359831060527,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.431640625,
        "f1": 0.35757931340939153,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.35757931340939153,
        "precision": 0.3331729387149309,
        "recall": 0.431640625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004893593453833623,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004893593453833623,
        "precision": 0.004571313280152182,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.359375,
        "f1": 0.28709770224397435,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.28709770224397435,
        "precision": 0.2647064605316558,
        "recall": 0.359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0039740608414418396,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0039740608414418396,
        "precision": 0.0034526382844709117,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.050937675318707035,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.050937675318707035,
        "precision": 0.04697711278521825,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.48828125,
        "f1": 0.4313951166404062,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4313951166404062,
        "precision": 0.4114835969694368,
        "recall": 0.48828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017214792854904626,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0017214792854904626,
        "precision": 0.0014441837590299276,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0054645715085946504,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0054645715085946504,
        "precision": 0.00492532467366421,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.4462890625,
        "f1": 0.38715721298986105,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.38715721298986105,
        "precision": 0.3672479538690476,
        "recall": 0.4462890625
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.014704402236990915,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.014704402236990915,
        "precision": 0.012507690876831502,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018806799331534674,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0018806799331534674,
        "precision": 0.001527671175853782,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.3330078125,
        "f1": 0.2896933903769841,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.2896933903769841,
        "precision": 0.2746449140975196,
        "recall": 0.3330078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0020938421250089817,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0020938421250089817,
        "precision": 0.00202679129597183,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.17423948149198903,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.17423948149198903,
        "precision": 0.16162634286995406,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.024366735694860694,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.024366735694860694,
        "precision": 0.021943295547385618,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026078807354020144,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0026078807354020144,
        "precision": 0.002313069395395102,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05557160576691826,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.05557160576691826,
        "precision": 0.051342724378423785,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0035829187686846034,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0035829187686846034,
        "precision": 0.0034190647797418634,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030780111364436197,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0030780111364436197,
        "precision": 0.0026400266739129725,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00032844030269058293,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.00032844030269058293,
        "precision": 0.00019677441991017966,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002090816570881226,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.002090816570881226,
        "precision": 0.0014685997596153846,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005734493463100968,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0005734493463100968,
        "precision": 0.00036928016537074595,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0032940204326923073,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0032940204326923073,
        "precision": 0.0028785741001250446,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.04734241685274051,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.04734241685274051,
        "precision": 0.04180379606427464,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012828944782657071,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0012828944782657071,
        "precision": 0.0011531061305231226,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.030734558551729067,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.030734558551729067,
        "precision": 0.02823552268610013,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0017057291666666666,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0017057291666666666,
        "precision": 0.0015055338541666667,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016054908633033633,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0016054908633033633,
        "precision": 0.0013325606684981685,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.015308743005677854,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.015308743005677854,
        "precision": 0.013844124634719328,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012523569140349105,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0012523569140349105,
        "precision": 0.0011260548603386786,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018466804895576675,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0018466804895576675,
        "precision": 0.0015879463695824523,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.006947457727558575,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.006947457727558575,
        "precision": 0.0064676205722943875,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022082653674450548,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.022082653674450548,
        "precision": 0.018147998448185265,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011743919136597938,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0011743919136597938,
        "precision": 0.0010863295250896057,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.06825927436278999,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.06825927436278999,
        "precision": 0.0602876209077381,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003225082492236025,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.003225082492236025,
        "precision": 0.0030905737058080805,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002029718137254902,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0002029718137254902,
        "precision": 0.00011235167869641294,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.01898041898409169,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.01898041898409169,
        "precision": 0.016683225397756952,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.675513698630137e-05,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 2.675513698630137e-05,
        "precision": 1.3563368055555555e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06725931819899417,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06725931819899417,
        "precision": 0.06083147551537765,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.2822265625,
        "f1": 0.2338612221796616,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2338612221796616,
        "precision": 0.22051919241117612,
        "recall": 0.2822265625
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.07536664795479557,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.07536664795479557,
        "precision": 0.06904668296215426,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.326171875,
        "f1": 0.27105969627798665,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.27105969627798665,
        "precision": 0.2558270798052795,
        "recall": 0.326171875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.013803582446099758,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.013803582446099758,
        "precision": 0.012717522408664118,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.19532363946078754,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.19532363946078754,
        "precision": 0.18238262205331945,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004728016936579192,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004728016936579192,
        "precision": 0.004370113729907237,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.4404296875,
        "f1": 0.36970280601607025,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.36970280601607025,
        "precision": 0.34786754315562907,
        "recall": 0.4404296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005558534894501898,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.005558534894501898,
        "precision": 0.005058013386290085,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.05332905105580574,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.05332905105580574,
        "precision": 0.04872145065568931,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.640625,
        "f1": 0.5828047495039683,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5828047495039683,
        "precision": 0.5616203187003969,
        "recall": 0.640625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001713248840065502,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.001713248840065502,
        "precision": 0.001443729160154215,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.35778753039495226,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.35778753039495226,
        "precision": 0.33928571428571425,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004524775233372351,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004524775233372351,
        "precision": 0.003914631238343344,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.012893695977935108,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.012893695977935108,
        "precision": 0.0121760150038518,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0013433171372211413,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0013433171372211413,
        "precision": 0.0011710582264900368,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.3544921875,
        "f1": 0.31063575909767316,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.31063575909767316,
        "precision": 0.2958457449668387,
        "recall": 0.3544921875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004054740272608217,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004054740272608217,
        "precision": 0.0036910875083729145,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.18340034409627337,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.18340034409627337,
        "precision": 0.17053181464802558,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.017654262225723624,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.017654262225723624,
        "precision": 0.01605878242538792,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002562786846338042,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.002562786846338042,
        "precision": 0.0022901201273994396,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06380946399895468,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.06380946399895468,
        "precision": 0.05796743760739443,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.00522009765385711,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.00522009765385711,
        "precision": 0.003968360984599879,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0038690094751182053,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0038690094751182053,
        "precision": 0.0031337249856190383,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006505782418392292,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0006505782418392292,
        "precision": 0.00041018009768009763,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015081484793340026,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0015081484793340026,
        "precision": 0.0010197242435848334,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00021348096552621906,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.00021348096552621906,
        "precision": 0.00011292504096780412,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002839274137475988,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.002839274137475988,
        "precision": 0.002569990688075159,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.009095118932947222,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.009095118932947222,
        "precision": 0.007229748676986484,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0013785207939459392,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0013785207939459392,
        "precision": 0.0012018055385934914,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.01626724920219744,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.01626724920219744,
        "precision": 0.015065169134059874,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008190377331002331,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0008190377331002331,
        "precision": 0.000578620747324159,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0033222843551276937,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0033222843551276937,
        "precision": 0.0025583814916074923,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004006320224719101,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.004006320224719101,
        "precision": 0.0032588798627776207,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003039914541004036,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.003039914541004036,
        "precision": 0.002375716857230302,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.011834459925662953,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.011834459925662953,
        "precision": 0.010736175312983279,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003567135989010989,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.003567135989010989,
        "precision": 0.003021711580737866,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.0069115777366945165,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.0069115777366945165,
        "precision": 0.005902115712807406,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027867515388764084,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0027867515388764084,
        "precision": 0.0021676861892578276,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.01253462978162992,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.01253462978162992,
        "precision": 0.011102076451277452,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0022333943379719253,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0022333943379719253,
        "precision": 0.0021048989094458494,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002276470278124422,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.002276470278124422,
        "precision": 0.0018555765641626763,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006437384285726849,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.006437384285726849,
        "precision": 0.00532063350530735,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0018830714971170134,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0018830714971170134,
        "precision": 0.0013000562103641592,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020029774912587416,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.0020029774912587416,
        "precision": 0.0016722605548423906,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002191533862818383,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.002191533862818383,
        "precision": 0.0017235023773228804,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.169752201640905,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.169752201640905,
        "precision": 0.16176373810651154,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.203125,
        "f1": 0.18253737833815958,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.18253737833815958,
        "precision": 0.17528333599064627,
        "recall": 0.203125
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.054960920795469465,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.054960920795469465,
        "precision": 0.049653731196699954,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.163715588062254,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.163715588062254,
        "precision": 0.15586187179334007,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.04574887460629648,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.04574887460629648,
        "precision": 0.03881887241390737,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.14468161843039773,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.14468161843039773,
        "precision": 0.135736361265052,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.021185006437228957,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.021185006437228957,
        "precision": 0.017856790561868688,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.1820248271501101,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.1820248271501101,
        "precision": 0.17388324946607026,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003501375930802567,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.003501375930802567,
        "precision": 0.0028928960289665434,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.1547696552579365,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.1547696552579365,
        "precision": 0.14474107977525946,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017652508089433796,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0017652508089433796,
        "precision": 0.0014667507538748804,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.03166614879261363,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.03166614879261363,
        "precision": 0.027993211302365456,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00168419951538769,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.00168419951538769,
        "precision": 0.001383896065528484,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007756541418650794,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.007756541418650794,
        "precision": 0.00684140843837535,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0032411697215824122,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0032411697215824122,
        "precision": 0.0027271314766776356,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.024987620886058385,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.024987620886058385,
        "precision": 0.022161803582702016,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.1734475097952573,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.1734475097952573,
        "precision": 0.16485810598184683,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.1571608348850954,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.1571608348850954,
        "precision": 0.1509451811880003,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.20557621507448606,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.20557621507448606,
        "precision": 0.19597006501143774,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.203125,
        "f1": 0.18017492602285168,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.18017492602285168,
        "precision": 0.17161690848214284,
        "recall": 0.203125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06903491202807609,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06903491202807609,
        "precision": 0.06268199953258546,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.18691997498821145,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.18691997498821145,
        "precision": 0.17452826100849106,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.08175591600460536,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.08175591600460536,
        "precision": 0.07494014215612076,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.15960276221269562,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.15960276221269562,
        "precision": 0.1501902985093185,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.016108182673406912,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.016108182673406912,
        "precision": 0.014928073697754042,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.208984375,
        "f1": 0.15886315302907827,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.15886315302907827,
        "precision": 0.14555870926549425,
        "recall": 0.208984375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003050107610979174,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.003050107610979174,
        "precision": 0.0026877137091541937,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2236328125,
        "f1": 0.17164764546920394,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.17164764546920394,
        "precision": 0.15887780299644777,
        "recall": 0.2236328125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004828041655627087,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.004828041655627087,
        "precision": 0.004547428761803987,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.05743718002737818,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.05743718002737818,
        "precision": 0.05328890294668513,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.34375,
        "f1": 0.2897590663459804,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2897590663459804,
        "precision": 0.2736684484212844,
        "recall": 0.34375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0029970492128056185,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0029970492128056185,
        "precision": 0.0025836532709554863,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.27720347043215837,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.27720347043215837,
        "precision": 0.26161745291383964,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.001798108698624151,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001798108698624151,
        "precision": 0.001435438259677241,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.33203125,
        "f1": 0.28355533833762236,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.28355533833762236,
        "precision": 0.2677654897186147,
        "recall": 0.33203125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010808410147130083,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.010808410147130083,
        "precision": 0.010066589578677367,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014318594476885054,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0014318594476885054,
        "precision": 0.001239270556509809,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012330127159919245,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0012330127159919245,
        "precision": 0.0011126917365678155,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.1384443309608734,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1384443309608734,
        "precision": 0.12772096230615468,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.015398567004535945,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.015398567004535945,
        "precision": 0.013157234060383046,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003447865159207377,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.003447865159207377,
        "precision": 0.0029320500619993877,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.0615041385930296,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0615041385930296,
        "precision": 0.05594278720284005,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009787374721603563,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0009787374721603563,
        "precision": 0.000977651198439242,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0021844417840523075,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0021844417840523075,
        "precision": 0.0017019627675397453,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001630443011143411,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.001630443011143411,
        "precision": 0.0014662652383551674,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019159226190476187,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0019159226190476187,
        "precision": 0.0016322767145135566,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00022850285947712418,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.00022850285947712418,
        "precision": 0.00012784878883136095,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012301431230992723,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0012301431230992723,
        "precision": 0.0011208046386882082,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.024256492460766353,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.024256492460766353,
        "precision": 0.021383108194587185,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001307810972629521,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.001307810972629521,
        "precision": 0.0011747472426470588,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.01916698314525463,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.01916698314525463,
        "precision": 0.017423085269764958,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00011777467634025545,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.00011777467634025545,
        "precision": 6.247977533284023e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003119302677967739,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.003119302677967739,
        "precision": 0.002751416499071782,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008432582173114735,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.008432582173114735,
        "precision": 0.007294127500552608,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0039029709439865686,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0039029709439865686,
        "precision": 0.0036026761038496554,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.054732404097638465,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.054732404097638465,
        "precision": 0.047545805431547614,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00521037421630094,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.00521037421630094,
        "precision": 0.0050791465088912136,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.009603480197035011,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.009603480197035011,
        "precision": 0.008973610110921383,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.017096207503523874,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.017096207503523874,
        "precision": 0.013856174606260773,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003591755699099461,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.003591755699099461,
        "precision": 0.0034235023189876897,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004067047817047817,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.004067047817047817,
        "precision": 0.003992937613224638,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00025692981560122174,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.00025692981560122174,
        "precision": 0.00014592453334489136,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00787121754124706,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.00787121754124706,
        "precision": 0.0066431742815850955,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010226153795416856,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0010226153795416856,
        "precision": 0.0010000839534955533,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.0416471705208907,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0416471705208907,
        "precision": 0.03776432389653622,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.16127029146443994,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.16127029146443994,
        "precision": 0.15024380973843865,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.3896484375,
        "f1": 0.3596900638806659,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.3596900638806659,
        "precision": 0.35044175920953036,
        "recall": 0.3896484375
      },
      {
        "accuracy": 0.59375,
        "f1": 0.5528355189732144,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5528355189732144,
        "precision": 0.5379742707379427,
        "recall": 0.59375
      },
      {
        "accuracy": 0.15625,
        "f1": 0.12853580272212914,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.12853580272212914,
        "precision": 0.1231409519242426,
        "recall": 0.15625
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.4370132905289155,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4370132905289155,
        "precision": 0.42531690585889803,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.022583316588946183,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.022583316588946183,
        "precision": 0.018180886421558566,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.578125,
        "f1": 0.5349612654056013,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5349612654056013,
        "precision": 0.5199876767113095,
        "recall": 0.578125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005497456904319469,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.005497456904319469,
        "precision": 0.004902836870548526,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.3515625,
        "f1": 0.3192413814484127,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3192413814484127,
        "precision": 0.30884174148334304,
        "recall": 0.3515625
      },
      {
        "accuracy": 0.369140625,
        "f1": 0.32257717714029394,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.32257717714029394,
        "precision": 0.3077765336670698,
        "recall": 0.369140625
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.1081243637287103,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1081243637287103,
        "precision": 0.10044391493266452,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.287109375,
        "f1": 0.24483498361007405,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.24483498361007405,
        "precision": 0.23203643406592397,
        "recall": 0.287109375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0031134563586645812,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0031134563586645812,
        "precision": 0.0026082857823459425,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.287109375,
        "f1": 0.24463108528290073,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.24463108528290073,
        "precision": 0.23135457207722832,
        "recall": 0.287109375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007282366071428572,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.007282366071428572,
        "precision": 0.006328092119107744,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.2021484375,
        "f1": 0.18511958916479385,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.18511958916479385,
        "precision": 0.17983987193362194,
        "recall": 0.2021484375
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.2023498419982795,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.2023498419982795,
        "precision": 0.19157474549015074,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003128467857660416,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003128467857660416,
        "precision": 0.003034438732574772,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.2177734375,
        "f1": 0.19016588509032997,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.19016588509032997,
        "precision": 0.18072857398167602,
        "recall": 0.2177734375
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.15294853344298245,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.15294853344298245,
        "precision": 0.14336949253941442,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.421875,
        "f1": 0.38707672684743083,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.38707672684743083,
        "precision": 0.37809292364281455,
        "recall": 0.421875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008026527037651358,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.008026527037651358,
        "precision": 0.006600854134191958,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017699195335914082,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.017699195335914082,
        "precision": 0.015462733734954433,
        "recall": 0.03125
      },
      {
        "accuracy": 0.166015625,
        "f1": 0.14784138231959623,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.14784138231959623,
        "precision": 0.14180551050690585,
        "recall": 0.166015625
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.16871211375175071,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.16871211375175071,
        "precision": 0.16358056006493504,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.04275942121813959,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.04275942121813959,
        "precision": 0.039353303537097255,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.1517183165333441,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.1517183165333441,
        "precision": 0.1458455652103232,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.0299622608284159,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.0299622608284159,
        "precision": 0.024656117521363503,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.14592187135270773,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.14592187135270773,
        "precision": 0.13953474504011612,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005742913572550337,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.005742913572550337,
        "precision": 0.004166290266979001,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.14486042551765654,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.14486042551765654,
        "precision": 0.13937276152340417,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010126098743098791,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.010126098743098791,
        "precision": 0.008975753412813661,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.13453367379148629,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.13453367379148629,
        "precision": 0.1280974050867174,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.010398225677830941,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.010398225677830941,
        "precision": 0.009167716125723938,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003751205064216125,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.003751205064216125,
        "precision": 0.0033810497191748574,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010176374094959622,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.010176374094959622,
        "precision": 0.008696892969928356,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.009667630546536795,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.009667630546536795,
        "precision": 0.007949084877795816,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.16203043619791666,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.16203043619791666,
        "precision": 0.15749677487445451,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01087728707103008,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.01087728707103008,
        "precision": 0.009467618427579365,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003133957215151231,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.003133957215151231,
        "precision": 0.002669241174178201,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.1598086402529762,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.1598086402529762,
        "precision": 0.1535136340324971,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.17363452576754385,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.17363452576754385,
        "precision": 0.1694468048227814,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.1689453125,
        "f1": 0.1496042219675032,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.1496042219675032,
        "precision": 0.14283330761099605,
        "recall": 0.1689453125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002085672405189621,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.002085672405189621,
        "precision": 0.0017310816525351147,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0011241443584210792,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.0011241443584210792,
        "precision": 0.0006404904232052669,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.11852520636792452,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.11852520636792452,
        "precision": 0.11131338685203411,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.1341843712529976,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.1341843712529976,
        "precision": 0.12718333708934293,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03767356515414147,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.03767356515414147,
        "precision": 0.033709016786165225,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.12335892731400544,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.12335892731400544,
        "precision": 0.11741255366399789,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.07188596451291762,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.07188596451291762,
        "precision": 0.061192491319444445,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.11171140500437284,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.11171140500437284,
        "precision": 0.10471411704472443,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.08558802308802307,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.08558802308802307,
        "precision": 0.07705546677714646,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.12925347222222222,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.12925347222222222,
        "precision": 0.12203245698735955,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002091354103072853,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.002091354103072853,
        "precision": 0.0017228517977667212,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.19606204342532466,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.19606204342532466,
        "precision": 0.18414403521825395,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0029261444160997734,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.0029261444160997734,
        "precision": 0.00254221368851817,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.025713479998064163,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.025713479998064163,
        "precision": 0.02264789140938038,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013206735041469196,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.0013206735041469196,
        "precision": 0.0008188357684785065,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.009173133939057124,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.009173133939057124,
        "precision": 0.007919460961638574,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.20270824832789297,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.20270824832789297,
        "precision": 0.19605881314865692,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008310100672353963,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0008310100672353963,
        "precision": 0.00048313555432808884,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021373327821210222,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.021373327821210222,
        "precision": 0.01829024653731685,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.13044329843222435,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.13044329843222435,
        "precision": 0.12297718892244397,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.1471167905083819,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.1471167905083819,
        "precision": 0.14218480885554452,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.12649302909044713,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.12649302909044713,
        "precision": 0.11970930219288635,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.030692679716117215,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.030692679716117215,
        "precision": 0.028417503720238095,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.1006631268606166,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.1006631268606166,
        "precision": 0.0936817283785501,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.30078125,
        "f1": 0.28175029451884914,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.28175029451884914,
        "precision": 0.27486353165064104,
        "recall": 0.30078125
      },
      {
        "accuracy": 0.4169921875,
        "f1": 0.3781431360265653,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.3781431360265653,
        "precision": 0.3679887536073827,
        "recall": 0.4169921875
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.10835537397580905,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.10835537397580905,
        "precision": 0.10211393143631999,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.3076171875,
        "f1": 0.2800674166275886,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.2800674166275886,
        "precision": 0.27296466012286325,
        "recall": 0.3076171875
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.019439166737168178,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.019439166737168178,
        "precision": 0.015544101180528368,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.36328125,
        "f1": 0.33782316806171503,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.33782316806171503,
        "precision": 0.3312261572025092,
        "recall": 0.36328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014167906746031746,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0014167906746031746,
        "precision": 0.0009390024038461539,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.660833594573829,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.660833594573829,
        "precision": 0.6427629743303571,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.0974788137184225,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0974788137184225,
        "precision": 0.09249243712797901,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09838277470235342,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.09838277470235342,
        "precision": 0.08988144158084577,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.07236752389165893,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.07236752389165893,
        "precision": 0.06882098250984121,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011157344504830918,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0011157344504830918,
        "precision": 0.000738833648989899,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.07970033831048358,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.07970033831048358,
        "precision": 0.07301567770942316,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005202744743870369,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.005202744743870369,
        "precision": 0.004019949875896917,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.21484375,
        "f1": 0.1950237434896302,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.1950237434896302,
        "precision": 0.18859410039829963,
        "recall": 0.21484375
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.0768024890935027,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.0768024890935027,
        "precision": 0.07332807197919503,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0009062348091551109,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0009062348091551109,
        "precision": 0.0006250637652879581,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.40625,
        "f1": 0.378175519142316,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.378175519142316,
        "precision": 0.36997404807591894,
        "recall": 0.40625
      },
      {
        "accuracy": 0.197265625,
        "f1": 0.17039559570274038,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.17039559570274038,
        "precision": 0.16124011459460677,
        "recall": 0.197265625
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.14743910845588235,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.14743910845588235,
        "precision": 0.13747657569679053,
        "recall": 0.173828125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}