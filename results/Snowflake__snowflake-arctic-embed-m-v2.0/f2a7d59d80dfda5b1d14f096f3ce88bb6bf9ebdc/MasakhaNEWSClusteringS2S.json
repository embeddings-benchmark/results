{
  "dataset_revision": "8ccc72e69e65f40c70e117d8b3c08306bb788b60",
  "task_name": "MasakhaNEWSClusteringS2S",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "v_measure": 0.428563,
        "v_measure_std": 0.46854,
        "v_measures": [
          1.0,
          0.017608,
          0.125177,
          3.2e-05,
          1.0
        ],
        "main_score": 0.428563,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ]
      },
      {
        "v_measure": 0.500251,
        "v_measure_std": 0.23654,
        "v_measures": [
          0.04921,
          0.611278,
          0.532846,
          0.565427,
          0.742492
        ],
        "main_score": 0.500251,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "v_measure": 0.452733,
        "v_measure_std": 0.313377,
        "v_measures": [
          1.0,
          0.126139,
          0.198391,
          0.370563,
          0.56857
        ],
        "main_score": 0.452733,
        "hf_subset": "fra",
        "languages": [
          "fra-Latn"
        ]
      },
      {
        "v_measure": 0.160705,
        "v_measure_std": 0.107853,
        "v_measures": [
          0.08156,
          0.0411,
          0.169352,
          0.157149,
          0.354365
        ],
        "main_score": 0.160705,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ]
      },
      {
        "v_measure": 0.389657,
        "v_measure_std": 0.342175,
        "v_measures": [
          0.000126,
          0.434865,
          0.147705,
          1.0,
          0.365591
        ],
        "main_score": 0.389657,
        "hf_subset": "ibo",
        "languages": [
          "ibo-Latn"
        ]
      },
      {
        "v_measure": 0.456121,
        "v_measure_std": 0.447182,
        "v_measures": [
          0.036397,
          0.055214,
          1.0,
          1.0,
          0.188996
        ],
        "main_score": 0.456121,
        "hf_subset": "lin",
        "languages": [
          "lin-Latn"
        ]
      },
      {
        "v_measure": 0.447214,
        "v_measure_std": 0.457764,
        "v_measures": [
          0.003235,
          0.014864,
          1.0,
          1.0,
          0.217972
        ],
        "main_score": 0.447214,
        "hf_subset": "lug",
        "languages": [
          "lug-Latn"
        ]
      },
      {
        "v_measure": 0.294037,
        "v_measure_std": 0.368293,
        "v_measures": [
          0.300731,
          0.031275,
          1.0,
          8.2e-05,
          0.1381
        ],
        "main_score": 0.294037,
        "hf_subset": "orm",
        "languages": [
          "orm-Ethi"
        ]
      },
      {
        "v_measure": 0.681969,
        "v_measure_std": 0.319803,
        "v_measures": [
          0.078843,
          0.734466,
          0.88953,
          0.707006,
          1.0
        ],
        "main_score": 0.681969,
        "hf_subset": "pcm",
        "languages": [
          "pcm-Latn"
        ]
      },
      {
        "v_measure": 0.47866,
        "v_measure_std": 0.42999,
        "v_measures": [
          0.193138,
          0.020397,
          1.0,
          0.179766,
          1.0
        ],
        "main_score": 0.47866,
        "hf_subset": "run",
        "languages": [
          "run-Latn"
        ]
      },
      {
        "v_measure": 0.479186,
        "v_measure_std": 0.434692,
        "v_measures": [
          1.0,
          0.295907,
          0.037363,
          0.062659,
          1.0
        ],
        "main_score": 0.479186,
        "hf_subset": "sna",
        "languages": [
          "sna-Latn"
        ]
      },
      {
        "v_measure": 0.264561,
        "v_measure_std": 0.375714,
        "v_measures": [
          0.039376,
          1.0,
          0.0002,
          0.057631,
          0.225596
        ],
        "main_score": 0.264561,
        "hf_subset": "som",
        "languages": [
          "som-Latn"
        ]
      },
      {
        "v_measure": 0.186346,
        "v_measure_std": 0.178667,
        "v_measures": [
          0.071019,
          0.074859,
          0.007175,
          0.487739,
          0.29094
        ],
        "main_score": 0.186346,
        "hf_subset": "swa",
        "languages": [
          "swa-Latn"
        ]
      },
      {
        "v_measure": 0.431062,
        "v_measure_std": 0.46518,
        "v_measures": [
          0.096459,
          1.0,
          0.029028,
          1.0,
          0.029823
        ],
        "main_score": 0.431062,
        "hf_subset": "tir",
        "languages": [
          "tir-Ethi"
        ]
      },
      {
        "v_measure": 0.308989,
        "v_measure_std": 0.35391,
        "v_measures": [
          0.202349,
          0.052734,
          0.050338,
          0.239524,
          1.0
        ],
        "main_score": 0.308989,
        "hf_subset": "xho",
        "languages": [
          "xho-Latn"
        ]
      },
      {
        "v_measure": 0.294197,
        "v_measure_std": 0.35874,
        "v_measures": [
          1.0,
          0.124324,
          0.006423,
          0.207882,
          0.132354
        ],
        "main_score": 0.294197,
        "hf_subset": "yor",
        "languages": [
          "yor-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 4.445993423461914,
  "kg_co2_emissions": 0.0001829835386256158
}