{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.890598,
        "recall": 0.920762,
        "f1": 0.899635,
        "accuracy": 0.920762,
        "main_score": 0.899635,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.835967,
        "recall": 0.882648,
        "f1": 0.850119,
        "accuracy": 0.882648,
        "main_score": 0.850119,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.906847,
        "recall": 0.931795,
        "f1": 0.914178,
        "accuracy": 0.931795,
        "main_score": 0.914178,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.879589,
        "recall": 0.915747,
        "f1": 0.890858,
        "accuracy": 0.915747,
        "main_score": 0.890858,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.982615,
        "recall": 0.987964,
        "f1": 0.984286,
        "accuracy": 0.987964,
        "main_score": 0.984286,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.950685,
        "recall": 0.966901,
        "f1": 0.956035,
        "accuracy": 0.966901,
        "main_score": 0.956035,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.936058,
        "recall": 0.954865,
        "f1": 0.941892,
        "accuracy": 0.954865,
        "main_score": 0.941892,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.906887,
        "recall": 0.933801,
        "f1": 0.915165,
        "accuracy": 0.933801,
        "main_score": 0.915165,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.91675,
        "recall": 0.940822,
        "f1": 0.924039,
        "accuracy": 0.940822,
        "main_score": 0.924039,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.885667,
        "recall": 0.919759,
        "f1": 0.896272,
        "accuracy": 0.919759,
        "main_score": 0.896272,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.945814,
        "recall": 0.960883,
        "f1": 0.950387,
        "accuracy": 0.960883,
        "main_score": 0.950387,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.907138,
        "recall": 0.935807,
        "f1": 0.916148,
        "accuracy": 0.935807,
        "main_score": 0.916148,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.907584,
        "recall": 0.931795,
        "f1": 0.914596,
        "accuracy": 0.931795,
        "main_score": 0.914596,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.894851,
        "recall": 0.925777,
        "f1": 0.904332,
        "accuracy": 0.925777,
        "main_score": 0.904332,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.947777,
        "recall": 0.961886,
        "f1": 0.952038,
        "accuracy": 0.961886,
        "main_score": 0.952038,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.879555,
        "recall": 0.914744,
        "f1": 0.890371,
        "accuracy": 0.914744,
        "main_score": 0.890371,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.893249,
        "recall": 0.920762,
        "f1": 0.901212,
        "accuracy": 0.920762,
        "main_score": 0.901212,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.870896,
        "recall": 0.908726,
        "f1": 0.882347,
        "accuracy": 0.908726,
        "main_score": 0.882347,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.285258,
        "recall": 0.336008,
        "f1": 0.296205,
        "accuracy": 0.336008,
        "main_score": 0.296205,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.341976,
        "recall": 0.440321,
        "f1": 0.364622,
        "accuracy": 0.440321,
        "main_score": 0.364622,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.758233,
        "recall": 0.799398,
        "f1": 0.769456,
        "accuracy": 0.799398,
        "main_score": 0.769456,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.706703,
        "recall": 0.778335,
        "f1": 0.726964,
        "accuracy": 0.778335,
        "main_score": 0.726964,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.947793,
        "recall": 0.960883,
        "f1": 0.951373,
        "accuracy": 0.960883,
        "main_score": 0.951373,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.927616,
        "recall": 0.94985,
        "f1": 0.934804,
        "accuracy": 0.94985,
        "main_score": 0.934804,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.015432,
        "recall": 0.023069,
        "f1": 0.016183,
        "accuracy": 0.023069,
        "main_score": 0.016183,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017996,
        "recall": 0.038114,
        "f1": 0.021408,
        "accuracy": 0.038114,
        "main_score": 0.021408,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.880402,
        "recall": 0.90672,
        "f1": 0.887741,
        "accuracy": 0.90672,
        "main_score": 0.887741,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.883317,
        "recall": 0.918756,
        "f1": 0.894469,
        "accuracy": 0.918756,
        "main_score": 0.894469,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.278558,
        "recall": 0.315948,
        "f1": 0.285934,
        "accuracy": 0.315948,
        "main_score": 0.285934,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.316138,
        "recall": 0.425276,
        "f1": 0.342246,
        "accuracy": 0.425276,
        "main_score": 0.342246,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.485975,
        "recall": 0.53661,
        "f1": 0.497475,
        "accuracy": 0.53661,
        "main_score": 0.497475,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.554628,
        "recall": 0.654965,
        "f1": 0.581688,
        "accuracy": 0.654965,
        "main_score": 0.581688,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.906712,
        "recall": 0.929789,
        "f1": 0.913334,
        "accuracy": 0.929789,
        "main_score": 0.913334,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.835799,
        "recall": 0.883651,
        "f1": 0.850574,
        "accuracy": 0.883651,
        "main_score": 0.850574,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.804228,
        "recall": 0.832497,
        "f1": 0.811649,
        "accuracy": 0.832497,
        "main_score": 0.811649,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.764256,
        "recall": 0.825476,
        "f1": 0.782017,
        "accuracy": 0.825476,
        "main_score": 0.782017,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.014177,
        "recall": 0.018054,
        "f1": 0.014728,
        "accuracy": 0.018054,
        "main_score": 0.014728,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027829,
        "recall": 0.072217,
        "f1": 0.034175,
        "accuracy": 0.072217,
        "main_score": 0.034175,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.046457,
        "recall": 0.061184,
        "f1": 0.048857,
        "accuracy": 0.061184,
        "main_score": 0.048857,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.126529,
        "recall": 0.201605,
        "f1": 0.143355,
        "accuracy": 0.201605,
        "main_score": 0.143355,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.823267,
        "recall": 0.857573,
        "f1": 0.832497,
        "accuracy": 0.857573,
        "main_score": 0.832497,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.771576,
        "recall": 0.828485,
        "f1": 0.787616,
        "accuracy": 0.828485,
        "main_score": 0.787616,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.514706,
        "recall": 0.559679,
        "f1": 0.524379,
        "accuracy": 0.559679,
        "main_score": 0.524379,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.523779,
        "recall": 0.611836,
        "f1": 0.546361,
        "accuracy": 0.611836,
        "main_score": 0.546361,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.815675,
        "recall": 0.843531,
        "f1": 0.822847,
        "accuracy": 0.843531,
        "main_score": 0.822847,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.744358,
        "recall": 0.812437,
        "f1": 0.764349,
        "accuracy": 0.812437,
        "main_score": 0.764349,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.814754,
        "recall": 0.84654,
        "f1": 0.822619,
        "accuracy": 0.84654,
        "main_score": 0.822619,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.741325,
        "recall": 0.809428,
        "f1": 0.760961,
        "accuracy": 0.809428,
        "main_score": 0.760961,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.831786,
        "recall": 0.8666,
        "f1": 0.84135,
        "accuracy": 0.8666,
        "main_score": 0.84135,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.757995,
        "recall": 0.817452,
        "f1": 0.774426,
        "accuracy": 0.817452,
        "main_score": 0.774426,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.033683,
        "recall": 0.044132,
        "f1": 0.034482,
        "accuracy": 0.044132,
        "main_score": 0.034482,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.09674,
        "recall": 0.152457,
        "f1": 0.107735,
        "accuracy": 0.152457,
        "main_score": 0.107735,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.868996,
        "recall": 0.894684,
        "f1": 0.875543,
        "accuracy": 0.894684,
        "main_score": 0.875543,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.764895,
        "recall": 0.830491,
        "f1": 0.784372,
        "accuracy": 0.830491,
        "main_score": 0.784372,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.84569,
        "recall": 0.877633,
        "f1": 0.854194,
        "accuracy": 0.877633,
        "main_score": 0.854194,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.784554,
        "recall": 0.839519,
        "f1": 0.800514,
        "accuracy": 0.839519,
        "main_score": 0.800514,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.007081,
        "recall": 0.009027,
        "f1": 0.007135,
        "accuracy": 0.009027,
        "main_score": 0.007135,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002201,
        "recall": 0.022066,
        "f1": 0.003763,
        "accuracy": 0.022066,
        "main_score": 0.003763,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.874804,
        "recall": 0.907115,
        "f1": 0.884129,
        "accuracy": 0.907115,
        "main_score": 0.884129,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.83946,
        "recall": 0.889328,
        "f1": 0.855402,
        "accuracy": 0.889328,
        "main_score": 0.855402,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.913159,
        "recall": 0.937747,
        "f1": 0.920487,
        "accuracy": 0.937747,
        "main_score": 0.920487,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.895998,
        "recall": 0.927866,
        "f1": 0.906028,
        "accuracy": 0.927866,
        "main_score": 0.906028,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.973238,
        "recall": 0.981225,
        "f1": 0.975692,
        "accuracy": 0.981225,
        "main_score": 0.975692,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.947958,
        "recall": 0.964427,
        "f1": 0.953228,
        "accuracy": 0.964427,
        "main_score": 0.953228,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.939453,
        "recall": 0.955534,
        "f1": 0.944271,
        "accuracy": 0.955534,
        "main_score": 0.944271,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.919549,
        "recall": 0.945652,
        "f1": 0.928096,
        "accuracy": 0.945652,
        "main_score": 0.928096,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.925125,
        "recall": 0.945652,
        "f1": 0.93111,
        "accuracy": 0.945652,
        "main_score": 0.93111,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.90448,
        "recall": 0.934783,
        "f1": 0.914196,
        "accuracy": 0.934783,
        "main_score": 0.914196,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.957708,
        "recall": 0.970356,
        "f1": 0.961627,
        "accuracy": 0.970356,
        "main_score": 0.961627,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.919137,
        "recall": 0.945652,
        "f1": 0.927866,
        "accuracy": 0.945652,
        "main_score": 0.927866,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.908465,
        "recall": 0.934783,
        "f1": 0.916436,
        "accuracy": 0.934783,
        "main_score": 0.916436,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.906868,
        "recall": 0.935771,
        "f1": 0.916074,
        "accuracy": 0.935771,
        "main_score": 0.916074,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.952108,
        "recall": 0.965415,
        "f1": 0.955995,
        "accuracy": 0.965415,
        "main_score": 0.955995,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.907889,
        "recall": 0.934783,
        "f1": 0.916074,
        "accuracy": 0.934783,
        "main_score": 0.916074,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.90308,
        "recall": 0.929842,
        "f1": 0.910874,
        "accuracy": 0.929842,
        "main_score": 0.910874,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.867013,
        "recall": 0.907115,
        "f1": 0.879348,
        "accuracy": 0.907115,
        "main_score": 0.879348,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.309044,
        "recall": 0.36166,
        "f1": 0.319842,
        "accuracy": 0.36166,
        "main_score": 0.319842,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.37193,
        "recall": 0.477273,
        "f1": 0.397509,
        "accuracy": 0.477273,
        "main_score": 0.397509,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.81144,
        "recall": 0.849802,
        "f1": 0.821744,
        "accuracy": 0.849802,
        "main_score": 0.821744,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.738617,
        "recall": 0.799407,
        "f1": 0.755301,
        "accuracy": 0.799407,
        "main_score": 0.755301,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.94753,
        "recall": 0.962451,
        "f1": 0.952075,
        "accuracy": 0.962451,
        "main_score": 0.952075,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.931489,
        "recall": 0.953557,
        "f1": 0.938735,
        "accuracy": 0.953557,
        "main_score": 0.938735,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.013392,
        "recall": 0.018775,
        "f1": 0.014063,
        "accuracy": 0.018775,
        "main_score": 0.014063,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025007,
        "recall": 0.039526,
        "f1": 0.027364,
        "accuracy": 0.039526,
        "main_score": 0.027364,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.857609,
        "recall": 0.895257,
        "f1": 0.86837,
        "accuracy": 0.895257,
        "main_score": 0.86837,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.848238,
        "recall": 0.895257,
        "f1": 0.863373,
        "accuracy": 0.895257,
        "main_score": 0.863373,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.2783,
        "recall": 0.323123,
        "f1": 0.287778,
        "accuracy": 0.323123,
        "main_score": 0.287778,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.29818,
        "recall": 0.401186,
        "f1": 0.322567,
        "accuracy": 0.401186,
        "main_score": 0.322567,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.50239,
        "recall": 0.560277,
        "f1": 0.514563,
        "accuracy": 0.560277,
        "main_score": 0.514563,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.537495,
        "recall": 0.62747,
        "f1": 0.560062,
        "accuracy": 0.62747,
        "main_score": 0.560062,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.906868,
        "recall": 0.933794,
        "f1": 0.915053,
        "accuracy": 0.933794,
        "main_score": 0.915053,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.867852,
        "recall": 0.906126,
        "f1": 0.879956,
        "accuracy": 0.906126,
        "main_score": 0.879956,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.873701,
        "recall": 0.901186,
        "f1": 0.880855,
        "accuracy": 0.901186,
        "main_score": 0.880855,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.796082,
        "recall": 0.851779,
        "f1": 0.812489,
        "accuracy": 0.851779,
        "main_score": 0.812489,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.018941,
        "recall": 0.024704,
        "f1": 0.019837,
        "accuracy": 0.024704,
        "main_score": 0.019837,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026098,
        "recall": 0.059289,
        "f1": 0.031121,
        "accuracy": 0.059289,
        "main_score": 0.031121,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.051533,
        "recall": 0.060277,
        "f1": 0.053035,
        "accuracy": 0.060277,
        "main_score": 0.053035,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.12071,
        "recall": 0.185771,
        "f1": 0.133901,
        "accuracy": 0.185771,
        "main_score": 0.133901,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.840841,
        "recall": 0.874506,
        "f1": 0.849428,
        "accuracy": 0.874506,
        "main_score": 0.849428,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.776219,
        "recall": 0.836957,
        "f1": 0.79393,
        "accuracy": 0.836957,
        "main_score": 0.79393,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.538643,
        "recall": 0.590909,
        "f1": 0.550271,
        "accuracy": 0.590909,
        "main_score": 0.550271,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.52449,
        "recall": 0.614625,
        "f1": 0.54723,
        "accuracy": 0.614625,
        "main_score": 0.54723,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.829818,
        "recall": 0.866601,
        "f1": 0.839766,
        "accuracy": 0.866601,
        "main_score": 0.839766,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.774878,
        "recall": 0.83498,
        "f1": 0.792471,
        "accuracy": 0.83498,
        "main_score": 0.792471,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.830407,
        "recall": 0.864625,
        "f1": 0.838993,
        "accuracy": 0.864625,
        "main_score": 0.838993,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.756679,
        "recall": 0.81917,
        "f1": 0.774406,
        "accuracy": 0.81917,
        "main_score": 0.774406,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.81803,
        "recall": 0.854743,
        "f1": 0.827247,
        "accuracy": 0.854743,
        "main_score": 0.827247,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.784761,
        "recall": 0.842885,
        "f1": 0.801856,
        "accuracy": 0.842885,
        "main_score": 0.801856,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.024213,
        "recall": 0.028656,
        "f1": 0.02487,
        "accuracy": 0.028656,
        "main_score": 0.02487,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.085228,
        "recall": 0.147233,
        "f1": 0.097555,
        "accuracy": 0.147233,
        "main_score": 0.097555,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.88211,
        "recall": 0.909091,
        "f1": 0.889272,
        "accuracy": 0.909091,
        "main_score": 0.889272,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.80896,
        "recall": 0.858696,
        "f1": 0.823388,
        "accuracy": 0.858696,
        "main_score": 0.823388,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.863023,
        "recall": 0.894269,
        "f1": 0.8713,
        "accuracy": 0.894269,
        "main_score": 0.8713,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.794945,
        "recall": 0.850791,
        "f1": 0.811768,
        "accuracy": 0.850791,
        "main_score": 0.811768,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.009091,
        "recall": 0.01087,
        "f1": 0.009552,
        "accuracy": 0.01087,
        "main_score": 0.009552,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002768,
        "recall": 0.024704,
        "f1": 0.004498,
        "accuracy": 0.024704,
        "main_score": 0.004498,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 157.1336965560913,
  "kg_co2_emissions": 0.008387164807468338
}