{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.225098,
        "f1": 0.190631,
        "f1_weighted": 0.223062,
        "scores_per_experiment": [
          {
            "accuracy": 0.225098,
            "f1": 0.192346,
            "f1_weighted": 0.227186
          },
          {
            "accuracy": 0.219727,
            "f1": 0.189746,
            "f1_weighted": 0.216937
          },
          {
            "accuracy": 0.221191,
            "f1": 0.183354,
            "f1_weighted": 0.21905
          },
          {
            "accuracy": 0.220215,
            "f1": 0.176782,
            "f1_weighted": 0.207466
          },
          {
            "accuracy": 0.216797,
            "f1": 0.177688,
            "f1_weighted": 0.216653
          },
          {
            "accuracy": 0.226562,
            "f1": 0.196582,
            "f1_weighted": 0.226833
          },
          {
            "accuracy": 0.242188,
            "f1": 0.188787,
            "f1_weighted": 0.236447
          },
          {
            "accuracy": 0.220703,
            "f1": 0.194449,
            "f1_weighted": 0.215281
          },
          {
            "accuracy": 0.22998,
            "f1": 0.201472,
            "f1_weighted": 0.233189
          },
          {
            "accuracy": 0.228516,
            "f1": 0.205102,
            "f1_weighted": 0.231578
          }
        ],
        "main_score": 0.225098,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.224854,
        "f1": 0.198648,
        "f1_weighted": 0.221194,
        "scores_per_experiment": [
          {
            "accuracy": 0.230957,
            "f1": 0.204465,
            "f1_weighted": 0.231427
          },
          {
            "accuracy": 0.223633,
            "f1": 0.199689,
            "f1_weighted": 0.220315
          },
          {
            "accuracy": 0.219727,
            "f1": 0.192848,
            "f1_weighted": 0.214563
          },
          {
            "accuracy": 0.227051,
            "f1": 0.194764,
            "f1_weighted": 0.211922
          },
          {
            "accuracy": 0.210938,
            "f1": 0.188662,
            "f1_weighted": 0.209799
          },
          {
            "accuracy": 0.223145,
            "f1": 0.204269,
            "f1_weighted": 0.220179
          },
          {
            "accuracy": 0.239258,
            "f1": 0.198586,
            "f1_weighted": 0.239255
          },
          {
            "accuracy": 0.220703,
            "f1": 0.197284,
            "f1_weighted": 0.216527
          },
          {
            "accuracy": 0.225098,
            "f1": 0.203968,
            "f1_weighted": 0.223518
          },
          {
            "accuracy": 0.228027,
            "f1": 0.201944,
            "f1_weighted": 0.224437
          }
        ],
        "main_score": 0.224854,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 969.0551745891571,
  "kg_co2_emissions": 0.07918872083842866
}