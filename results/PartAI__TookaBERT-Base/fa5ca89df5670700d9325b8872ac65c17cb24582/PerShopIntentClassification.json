{
  "dataset_revision": "05027cfce1d20ab7c9f4755b064ea6958cdee96e",
  "task_name": "PerShopIntentClassification",
  "mteb_version": "1.38.38",
  "scores": {
    "test": [
      {
        "accuracy": 0.902135,
        "f1": 0.548148,
        "f1_weighted": 0.918422,
        "scores_per_experiment": [
          {
            "accuracy": 0.901793,
            "f1": 0.549062,
            "f1_weighted": 0.918067
          },
          {
            "accuracy": 0.88386,
            "f1": 0.524979,
            "f1_weighted": 0.901204
          },
          {
            "accuracy": 0.920581,
            "f1": 0.644781,
            "f1_weighted": 0.932353
          },
          {
            "accuracy": 0.909479,
            "f1": 0.502096,
            "f1_weighted": 0.925317
          },
          {
            "accuracy": 0.920581,
            "f1": 0.557676,
            "f1_weighted": 0.934081
          },
          {
            "accuracy": 0.882152,
            "f1": 0.470252,
            "f1_weighted": 0.905465
          },
          {
            "accuracy": 0.898377,
            "f1": 0.493069,
            "f1_weighted": 0.913022
          },
          {
            "accuracy": 0.893254,
            "f1": 0.489198,
            "f1_weighted": 0.914113
          },
          {
            "accuracy": 0.922289,
            "f1": 0.647595,
            "f1_weighted": 0.934724
          },
          {
            "accuracy": 0.888984,
            "f1": 0.602768,
            "f1_weighted": 0.905876
          }
        ],
        "main_score": 0.902135,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 28.112638235092163,
  "kg_co2_emissions": null
}