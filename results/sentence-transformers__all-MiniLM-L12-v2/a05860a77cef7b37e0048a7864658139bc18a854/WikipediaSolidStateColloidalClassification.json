{
  "dataset_revision": "7d8df44e588b6143d4856c781f72f919fa0599a7",
  "task_name": "WikipediaSolidStateColloidalClassification",
  "mteb_version": "1.26.4",
  "scores": {
    "test": [
      {
        "accuracy": 0.782432,
        "f1": 0.778125,
        "f1_weighted": 0.779576,
        "ap": 0.759109,
        "ap_weighted": 0.759109,
        "scores_per_experiment": [
          {
            "accuracy": 0.768018,
            "f1": 0.768007,
            "f1_weighted": 0.767845,
            "ap": 0.765944,
            "ap_weighted": 0.765944
          },
          {
            "accuracy": 0.630631,
            "f1": 0.621759,
            "f1_weighted": 0.615757,
            "ap": 0.663149,
            "ap_weighted": 0.663149
          },
          {
            "accuracy": 0.79955,
            "f1": 0.797991,
            "f1_weighted": 0.799829,
            "ap": 0.773671,
            "ap_weighted": 0.773671
          },
          {
            "accuracy": 0.81982,
            "f1": 0.814381,
            "f1_weighted": 0.817673,
            "ap": 0.774674,
            "ap_weighted": 0.774674
          },
          {
            "accuracy": 0.781532,
            "f1": 0.781397,
            "f1_weighted": 0.781958,
            "ap": 0.771409,
            "ap_weighted": 0.771409
          },
          {
            "accuracy": 0.831081,
            "f1": 0.827382,
            "f1_weighted": 0.83,
            "ap": 0.791093,
            "ap_weighted": 0.791093
          },
          {
            "accuracy": 0.790541,
            "f1": 0.783693,
            "f1_weighted": 0.78768,
            "ap": 0.746249,
            "ap_weighted": 0.746249
          },
          {
            "accuracy": 0.851351,
            "f1": 0.850135,
            "f1_weighted": 0.851534,
            "ap": 0.827063,
            "ap_weighted": 0.827063
          },
          {
            "accuracy": 0.754505,
            "f1": 0.754054,
            "f1_weighted": 0.755145,
            "ap": 0.739729,
            "ap_weighted": 0.739729
          },
          {
            "accuracy": 0.797297,
            "f1": 0.782448,
            "f1_weighted": 0.788336,
            "ap": 0.738104,
            "ap_weighted": 0.738104
          }
        ],
        "main_score": 0.782432,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 0.9074575901031494,
  "kg_co2_emissions": null
}