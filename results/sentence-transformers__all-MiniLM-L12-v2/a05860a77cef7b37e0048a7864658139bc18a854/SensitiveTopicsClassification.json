{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "evaluation_time": 5.378125190734863,
  "kg_co2_emissions": 0.0008177721907070514,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.18046875,
        "f1": 0.01563735323224391,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "lrap": 0.25893554687499354,
        "main_score": 0.18046875,
        "scores_per_experiment": [
          {
            "accuracy": 0.17822265625,
            "f1": 0.004119168552070335,
            "lrap": 0.25390624999999367
          },
          {
            "accuracy": 0.1865234375,
            "f1": 0.030364413954243816,
            "lrap": 0.26493326822916025
          },
          {
            "accuracy": 0.1796875,
            "f1": 0.009422308939744524,
            "lrap": 0.2564832899305492
          },
          {
            "accuracy": 0.1796875,
            "f1": 0.006894790602655771,
            "lrap": 0.25580512152777146
          },
          {
            "accuracy": 0.18115234375,
            "f1": 0.01132140760807162,
            "lrap": 0.256673177083327
          },
          {
            "accuracy": 0.1865234375,
            "f1": 0.035530613355838736,
            "lrap": 0.26742892795138234
          },
          {
            "accuracy": 0.177734375,
            "f1": 0.013693708385635014,
            "lrap": 0.2598470052083269
          },
          {
            "accuracy": 0.17626953125,
            "f1": 0.014328114883569717,
            "lrap": 0.25687662760416025
          },
          {
            "accuracy": 0.1748046875,
            "f1": 0.011081471972881134,
            "lrap": 0.2561170789930492
          },
          {
            "accuracy": 0.18408203125,
            "f1": 0.01961753406772845,
            "lrap": 0.2612847222222158
          }
        ]
      }
    ]
  },
  "task_name": "SensitiveTopicsClassification"
}