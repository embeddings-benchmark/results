{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "task_name": "AmazonReviewsClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.26572,
        "f1": 0.262237,
        "f1_weighted": 0.262237,
        "scores_per_experiment": [
          {
            "accuracy": 0.2802,
            "f1": 0.280486,
            "f1_weighted": 0.280486
          },
          {
            "accuracy": 0.2474,
            "f1": 0.234825,
            "f1_weighted": 0.234825
          },
          {
            "accuracy": 0.2716,
            "f1": 0.271501,
            "f1_weighted": 0.271501
          },
          {
            "accuracy": 0.2622,
            "f1": 0.259305,
            "f1_weighted": 0.259305
          },
          {
            "accuracy": 0.2518,
            "f1": 0.251105,
            "f1_weighted": 0.251105
          },
          {
            "accuracy": 0.27,
            "f1": 0.259337,
            "f1_weighted": 0.259337
          },
          {
            "accuracy": 0.2556,
            "f1": 0.256131,
            "f1_weighted": 0.256131
          },
          {
            "accuracy": 0.2802,
            "f1": 0.279029,
            "f1_weighted": 0.279029
          },
          {
            "accuracy": 0.2784,
            "f1": 0.272464,
            "f1_weighted": 0.272464
          },
          {
            "accuracy": 0.2598,
            "f1": 0.258189,
            "f1_weighted": 0.258189
          }
        ],
        "main_score": 0.26572,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.2593,
        "f1": 0.255644,
        "f1_weighted": 0.255644,
        "scores_per_experiment": [
          {
            "accuracy": 0.2766,
            "f1": 0.276756,
            "f1_weighted": 0.276756
          },
          {
            "accuracy": 0.2426,
            "f1": 0.229718,
            "f1_weighted": 0.229718
          },
          {
            "accuracy": 0.2582,
            "f1": 0.255803,
            "f1_weighted": 0.255803
          },
          {
            "accuracy": 0.2506,
            "f1": 0.247735,
            "f1_weighted": 0.247735
          },
          {
            "accuracy": 0.2566,
            "f1": 0.256462,
            "f1_weighted": 0.256462
          },
          {
            "accuracy": 0.2648,
            "f1": 0.256423,
            "f1_weighted": 0.256423
          },
          {
            "accuracy": 0.2548,
            "f1": 0.254444,
            "f1_weighted": 0.254444
          },
          {
            "accuracy": 0.27,
            "f1": 0.268681,
            "f1_weighted": 0.268681
          },
          {
            "accuracy": 0.259,
            "f1": 0.252022,
            "f1_weighted": 0.252022
          },
          {
            "accuracy": 0.2598,
            "f1": 0.258392,
            "f1_weighted": 0.258392
          }
        ],
        "main_score": 0.2593,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 48.791348934173584,
  "kg_co2_emissions": null
}