{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.583691,
        "f1": 0.56141,
        "f1_weighted": 0.599765,
        "ap": 0.738158,
        "ap_weighted": 0.738158,
        "scores_per_experiment": [
          {
            "accuracy": 0.596567,
            "f1": 0.568926,
            "f1_weighted": 0.612026,
            "ap": 0.738276,
            "ap_weighted": 0.738276
          },
          {
            "accuracy": 0.587983,
            "f1": 0.559754,
            "f1_weighted": 0.603772,
            "ap": 0.733207,
            "ap_weighted": 0.733207
          },
          {
            "accuracy": 0.545064,
            "f1": 0.528241,
            "f1_weighted": 0.563417,
            "ap": 0.723364,
            "ap_weighted": 0.723364
          },
          {
            "accuracy": 0.555794,
            "f1": 0.545837,
            "f1_weighted": 0.572389,
            "ap": 0.739574,
            "ap_weighted": 0.739574
          },
          {
            "accuracy": 0.572961,
            "f1": 0.558264,
            "f1_weighted": 0.590079,
            "ap": 0.741472,
            "ap_weighted": 0.741472
          },
          {
            "accuracy": 0.61588,
            "f1": 0.591882,
            "f1_weighted": 0.630958,
            "ap": 0.752795,
            "ap_weighted": 0.752795
          },
          {
            "accuracy": 0.618026,
            "f1": 0.589919,
            "f1_weighted": 0.63231,
            "ap": 0.749175,
            "ap_weighted": 0.749175
          },
          {
            "accuracy": 0.530043,
            "f1": 0.514646,
            "f1_weighted": 0.548779,
            "ap": 0.717317,
            "ap_weighted": 0.717317
          },
          {
            "accuracy": 0.579399,
            "f1": 0.547349,
            "f1_weighted": 0.594907,
            "ap": 0.725291,
            "ap_weighted": 0.725291
          },
          {
            "accuracy": 0.635193,
            "f1": 0.609284,
            "f1_weighted": 0.649011,
            "ap": 0.761111,
            "ap_weighted": 0.761111
          }
        ],
        "main_score": 0.583691,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.571092,
        "f1": 0.551958,
        "f1_weighted": 0.587266,
        "ap": 0.733938,
        "ap_weighted": 0.733938,
        "scores_per_experiment": [
          {
            "accuracy": 0.610278,
            "f1": 0.578085,
            "f1_weighted": 0.623755,
            "ap": 0.739182,
            "ap_weighted": 0.739182
          },
          {
            "accuracy": 0.550321,
            "f1": 0.521827,
            "f1_weighted": 0.567568,
            "ap": 0.7123,
            "ap_weighted": 0.7123
          },
          {
            "accuracy": 0.550321,
            "f1": 0.541438,
            "f1_weighted": 0.566448,
            "ap": 0.736477,
            "ap_weighted": 0.736477
          },
          {
            "accuracy": 0.555675,
            "f1": 0.547305,
            "f1_weighted": 0.571426,
            "ap": 0.740633,
            "ap_weighted": 0.740633
          },
          {
            "accuracy": 0.561028,
            "f1": 0.549406,
            "f1_weighted": 0.577763,
            "ap": 0.737702,
            "ap_weighted": 0.737702
          },
          {
            "accuracy": 0.585653,
            "f1": 0.568733,
            "f1_weighted": 0.602207,
            "ap": 0.743485,
            "ap_weighted": 0.743485
          },
          {
            "accuracy": 0.567452,
            "f1": 0.54488,
            "f1_weighted": 0.584597,
            "ap": 0.726626,
            "ap_weighted": 0.726626
          },
          {
            "accuracy": 0.525696,
            "f1": 0.512617,
            "f1_weighted": 0.543903,
            "ap": 0.716198,
            "ap_weighted": 0.716198
          },
          {
            "accuracy": 0.557816,
            "f1": 0.534035,
            "f1_weighted": 0.575285,
            "ap": 0.720404,
            "ap_weighted": 0.720404
          },
          {
            "accuracy": 0.646681,
            "f1": 0.621255,
            "f1_weighted": 0.659709,
            "ap": 0.766378,
            "ap_weighted": 0.766378
          }
        ],
        "main_score": 0.571092,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 38.71449899673462,
  "kg_co2_emissions": null
}