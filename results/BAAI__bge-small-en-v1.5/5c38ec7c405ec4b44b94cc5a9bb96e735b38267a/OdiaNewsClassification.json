{
  "dataset_revision": "ffb8a34c9637fb20256e8c7be02504d16af4bd6b",
  "evaluation_time": 9.465399742126465,
  "kg_co2_emissions": 0.0002779241282347221,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.592724609375,
        "f1": 0.5886762084396301,
        "f1_weighted": 0.5815363309946765,
        "hf_subset": "default",
        "languages": [
          "ory-Orya"
        ],
        "main_score": 0.5886762084396301,
        "scores_per_experiment": [
          {
            "accuracy": 0.61181640625,
            "f1": 0.6099275593972856,
            "f1_weighted": 0.6103797606310726
          },
          {
            "accuracy": 0.5986328125,
            "f1": 0.5729631940935819,
            "f1_weighted": 0.5739549764147099
          },
          {
            "accuracy": 0.57421875,
            "f1": 0.5951289292432104,
            "f1_weighted": 0.5757596465555012
          },
          {
            "accuracy": 0.634765625,
            "f1": 0.6134819673728686,
            "f1_weighted": 0.6209740830186771
          },
          {
            "accuracy": 0.62109375,
            "f1": 0.5371818289760301,
            "f1_weighted": 0.5473716298327673
          },
          {
            "accuracy": 0.5693359375,
            "f1": 0.5927974517463,
            "f1_weighted": 0.5724709551693075
          },
          {
            "accuracy": 0.572265625,
            "f1": 0.5871431260216976,
            "f1_weighted": 0.5753402881403241
          },
          {
            "accuracy": 0.5693359375,
            "f1": 0.5941716165549803,
            "f1_weighted": 0.5728582733197174
          },
          {
            "accuracy": 0.60888671875,
            "f1": 0.6010993518424517,
            "f1_weighted": 0.5990667982258349
          },
          {
            "accuracy": 0.56689453125,
            "f1": 0.582867059147894,
            "f1_weighted": 0.5671868986388535
          }
        ]
      }
    ]
  },
  "task_name": "OdiaNewsClassification"
}