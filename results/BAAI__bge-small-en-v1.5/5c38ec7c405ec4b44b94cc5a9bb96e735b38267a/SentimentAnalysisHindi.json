{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 7.777679920196533,
  "kg_co2_emissions": 0.00023893568775905423,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.36376953125,
        "f1": 0.3448993358771788,
        "f1_weighted": 0.3686006689642331,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.3448993358771788,
        "scores_per_experiment": [
          {
            "accuracy": 0.36865234375,
            "f1": 0.355124625085612,
            "f1_weighted": 0.3985666242292131
          },
          {
            "accuracy": 0.3330078125,
            "f1": 0.32604722130711755,
            "f1_weighted": 0.34059102532515684
          },
          {
            "accuracy": 0.31982421875,
            "f1": 0.2906060777375176,
            "f1_weighted": 0.28210467295280106
          },
          {
            "accuracy": 0.42333984375,
            "f1": 0.39924987352629265,
            "f1_weighted": 0.43916572837267304
          },
          {
            "accuracy": 0.32275390625,
            "f1": 0.31384887177312865,
            "f1_weighted": 0.33010980405728263
          },
          {
            "accuracy": 0.26416015625,
            "f1": 0.2636475994421064,
            "f1_weighted": 0.2616573381710173
          },
          {
            "accuracy": 0.47705078125,
            "f1": 0.4235618251197999,
            "f1_weighted": 0.4774190071680152
          },
          {
            "accuracy": 0.40234375,
            "f1": 0.3912749192527836,
            "f1_weighted": 0.42663900493804696
          },
          {
            "accuracy": 0.298828125,
            "f1": 0.29096439593759427,
            "f1_weighted": 0.28592116182930966
          },
          {
            "accuracy": 0.427734375,
            "f1": 0.39466794958983537,
            "f1_weighted": 0.44383232259881555
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}