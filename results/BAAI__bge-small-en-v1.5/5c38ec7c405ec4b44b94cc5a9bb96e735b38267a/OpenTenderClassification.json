{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.14",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.290747,
            "f1": 0.271383,
            "f1_weighted": 0.271379,
            "precision": 0.281166,
            "precision_weighted": 0.281213,
            "recall": 0.290786,
            "recall_weighted": 0.290747,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.276031,
            "f1": 0.263881,
            "f1_weighted": 0.263846,
            "precision": 0.275593,
            "precision_weighted": 0.275624,
            "recall": 0.276118,
            "recall_weighted": 0.276031,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.301672,
            "f1": 0.279526,
            "f1_weighted": 0.279504,
            "precision": 0.292743,
            "precision_weighted": 0.292773,
            "recall": 0.301727,
            "recall_weighted": 0.301672,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.290301,
            "f1": 0.27279,
            "f1_weighted": 0.272781,
            "precision": 0.288547,
            "precision_weighted": 0.288531,
            "recall": 0.290311,
            "recall_weighted": 0.290301,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.262207,
            "f1": 0.241421,
            "f1_weighted": 0.241457,
            "precision": 0.258991,
            "precision_weighted": 0.259026,
            "recall": 0.262115,
            "recall_weighted": 0.262207,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.282051,
            "f1": 0.263241,
            "f1_weighted": 0.263165,
            "precision": 0.275847,
            "precision_weighted": 0.275844,
            "recall": 0.282187,
            "recall_weighted": 0.282051,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.286065,
            "f1": 0.266707,
            "f1_weighted": 0.266672,
            "precision": 0.289403,
            "precision_weighted": 0.289368,
            "recall": 0.286061,
            "recall_weighted": 0.286065,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.262653,
            "f1": 0.240941,
            "f1_weighted": 0.24089,
            "precision": 0.266458,
            "precision_weighted": 0.266386,
            "recall": 0.262683,
            "recall_weighted": 0.262653,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.279599,
            "f1": 0.260134,
            "f1_weighted": 0.260065,
            "precision": 0.270603,
            "precision_weighted": 0.270553,
            "recall": 0.279675,
            "recall_weighted": 0.279599,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.278038,
            "f1": 0.249443,
            "f1_weighted": 0.249461,
            "precision": 0.272586,
            "precision_weighted": 0.272555,
            "recall": 0.277971,
            "recall_weighted": 0.278038,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.280936,
        "f1": 0.260947,
        "f1_weighted": 0.260922,
        "precision": 0.277194,
        "precision_weighted": 0.277187,
        "recall": 0.280964,
        "recall_weighted": 0.280936,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.260947,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 47.50005483627319,
  "kg_co2_emissions": null
}