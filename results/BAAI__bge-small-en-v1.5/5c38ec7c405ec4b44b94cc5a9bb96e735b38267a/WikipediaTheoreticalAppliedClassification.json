{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.26.4",
  "scores": {
    "test": [
      {
        "accuracy": 0.658338,
        "f1": 0.654022,
        "f1_weighted": 0.655132,
        "ap": 0.578625,
        "ap_weighted": 0.578625,
        "scores_per_experiment": [
          {
            "accuracy": 0.677292,
            "f1": 0.677288,
            "f1_weighted": 0.677218,
            "ap": 0.592772,
            "ap_weighted": 0.592772
          },
          {
            "accuracy": 0.655013,
            "f1": 0.654658,
            "f1_weighted": 0.654021,
            "ap": 0.574237,
            "ap_weighted": 0.574237
          },
          {
            "accuracy": 0.716024,
            "f1": 0.714622,
            "f1_weighted": 0.715774,
            "ap": 0.630826,
            "ap_weighted": 0.630826
          },
          {
            "accuracy": 0.665981,
            "f1": 0.654132,
            "f1_weighted": 0.657819,
            "ap": 0.587739,
            "ap_weighted": 0.587739
          },
          {
            "accuracy": 0.652271,
            "f1": 0.652265,
            "f1_weighted": 0.652183,
            "ap": 0.571953,
            "ap_weighted": 0.571953
          },
          {
            "accuracy": 0.678406,
            "f1": 0.676892,
            "f1_weighted": 0.678165,
            "ap": 0.59502,
            "ap_weighted": 0.59502
          },
          {
            "accuracy": 0.661011,
            "f1": 0.659808,
            "f1_weighted": 0.658643,
            "ap": 0.579136,
            "ap_weighted": 0.579136
          },
          {
            "accuracy": 0.617652,
            "f1": 0.617606,
            "f1_weighted": 0.617365,
            "ap": 0.54532,
            "ap_weighted": 0.54532
          },
          {
            "accuracy": 0.632905,
            "f1": 0.631258,
            "f1_weighted": 0.632677,
            "ap": 0.556189,
            "ap_weighted": 0.556189
          },
          {
            "accuracy": 0.626821,
            "f1": 0.601696,
            "f1_weighted": 0.607456,
            "ap": 0.553058,
            "ap_weighted": 0.553058
          }
        ],
        "main_score": 0.658338,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 59.08994126319885,
  "kg_co2_emissions": null
}