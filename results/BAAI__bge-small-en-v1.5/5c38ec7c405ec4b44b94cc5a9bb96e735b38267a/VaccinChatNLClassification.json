{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.14",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.238462,
            "f1": 0.264227,
            "f1_weighted": 0.218215,
            "precision": 0.310958,
            "precision_weighted": 0.377757,
            "recall": 0.414043,
            "recall_weighted": 0.238462,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.266667,
            "f1": 0.319692,
            "f1_weighted": 0.250253,
            "precision": 0.407525,
            "precision_weighted": 0.548947,
            "recall": 0.459293,
            "recall_weighted": 0.266667,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.264103,
            "f1": 0.309622,
            "f1_weighted": 0.237398,
            "precision": 0.378565,
            "precision_weighted": 0.409984,
            "recall": 0.449149,
            "recall_weighted": 0.264103,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.27094,
            "f1": 0.302786,
            "f1_weighted": 0.245059,
            "precision": 0.347313,
            "precision_weighted": 0.396538,
            "recall": 0.446727,
            "recall_weighted": 0.27094,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.266667,
            "f1": 0.303023,
            "f1_weighted": 0.233455,
            "precision": 0.344842,
            "precision_weighted": 0.382009,
            "recall": 0.449753,
            "recall_weighted": 0.266667,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.271795,
            "f1": 0.326857,
            "f1_weighted": 0.253794,
            "precision": 0.371323,
            "precision_weighted": 0.380568,
            "recall": 0.46955,
            "recall_weighted": 0.271795,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.248718,
            "f1": 0.292429,
            "f1_weighted": 0.209711,
            "precision": 0.347385,
            "precision_weighted": 0.388217,
            "recall": 0.431738,
            "recall_weighted": 0.248718,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.251282,
            "f1": 0.275668,
            "f1_weighted": 0.222668,
            "precision": 0.361511,
            "precision_weighted": 0.5066,
            "recall": 0.425707,
            "recall_weighted": 0.251282,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.267521,
            "f1": 0.304427,
            "f1_weighted": 0.233559,
            "precision": 0.356763,
            "precision_weighted": 0.44998,
            "recall": 0.470194,
            "recall_weighted": 0.267521,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.255556,
            "f1": 0.298352,
            "f1_weighted": 0.224474,
            "precision": 0.320464,
            "precision_weighted": 0.357928,
            "recall": 0.441699,
            "recall_weighted": 0.255556,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.260171,
        "f1": 0.299708,
        "f1_weighted": 0.232858,
        "precision": 0.354665,
        "precision_weighted": 0.419853,
        "recall": 0.445785,
        "recall_weighted": 0.260171,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.299708,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 34.608349323272705,
  "kg_co2_emissions": null
}