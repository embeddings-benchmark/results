{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.533417,
        "f1": 0.531241,
        "f1_weighted": 0.531241,
        "ap": 0.518426,
        "ap_weighted": 0.518426,
        "scores_per_experiment": [
          {
            "accuracy": 0.5125,
            "f1": 0.511547,
            "f1_weighted": 0.511547,
            "ap": 0.506421,
            "ap_weighted": 0.506421
          },
          {
            "accuracy": 0.518333,
            "f1": 0.516872,
            "f1_weighted": 0.516872,
            "ap": 0.509469,
            "ap_weighted": 0.509469
          },
          {
            "accuracy": 0.540833,
            "f1": 0.539482,
            "f1_weighted": 0.539482,
            "ap": 0.521921,
            "ap_weighted": 0.521921
          },
          {
            "accuracy": 0.553333,
            "f1": 0.551894,
            "f1_weighted": 0.551894,
            "ap": 0.529222,
            "ap_weighted": 0.529222
          },
          {
            "accuracy": 0.575833,
            "f1": 0.57555,
            "f1_weighted": 0.57555,
            "ap": 0.543981,
            "ap_weighted": 0.543981
          },
          {
            "accuracy": 0.525833,
            "f1": 0.522843,
            "f1_weighted": 0.522843,
            "ap": 0.513493,
            "ap_weighted": 0.513493
          },
          {
            "accuracy": 0.499167,
            "f1": 0.494686,
            "f1_weighted": 0.494686,
            "ap": 0.499584,
            "ap_weighted": 0.499584
          },
          {
            "accuracy": 0.505,
            "f1": 0.504834,
            "f1_weighted": 0.504834,
            "ap": 0.502524,
            "ap_weighted": 0.502524
          },
          {
            "accuracy": 0.585,
            "f1": 0.576501,
            "f1_weighted": 0.576501,
            "ap": 0.54813,
            "ap_weighted": 0.54813
          },
          {
            "accuracy": 0.518333,
            "f1": 0.518199,
            "f1_weighted": 0.518199,
            "ap": 0.509514,
            "ap_weighted": 0.509514
          }
        ],
        "main_score": 0.533417,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.538583,
        "f1": 0.53565,
        "f1_weighted": 0.53565,
        "ap": 0.522626,
        "ap_weighted": 0.522626,
        "scores_per_experiment": [
          {
            "accuracy": 0.525,
            "f1": 0.523645,
            "f1_weighted": 0.523645,
            "ap": 0.5132,
            "ap_weighted": 0.5132
          },
          {
            "accuracy": 0.529167,
            "f1": 0.523833,
            "f1_weighted": 0.523833,
            "ap": 0.515285,
            "ap_weighted": 0.515285
          },
          {
            "accuracy": 0.578333,
            "f1": 0.576257,
            "f1_weighted": 0.576257,
            "ap": 0.544549,
            "ap_weighted": 0.544549
          },
          {
            "accuracy": 0.575833,
            "f1": 0.572173,
            "f1_weighted": 0.572173,
            "ap": 0.54277,
            "ap_weighted": 0.54277
          },
          {
            "accuracy": 0.593333,
            "f1": 0.592314,
            "f1_weighted": 0.592314,
            "ap": 0.556346,
            "ap_weighted": 0.556346
          },
          {
            "accuracy": 0.4825,
            "f1": 0.48231,
            "f1_weighted": 0.48231,
            "ap": 0.491545,
            "ap_weighted": 0.491545
          },
          {
            "accuracy": 0.516667,
            "f1": 0.508995,
            "f1_weighted": 0.508995,
            "ap": 0.508556,
            "ap_weighted": 0.508556
          },
          {
            "accuracy": 0.460833,
            "f1": 0.460725,
            "f1_weighted": 0.460725,
            "ap": 0.481908,
            "ap_weighted": 0.481908
          },
          {
            "accuracy": 0.610833,
            "f1": 0.604572,
            "f1_weighted": 0.604572,
            "ap": 0.565231,
            "ap_weighted": 0.565231
          },
          {
            "accuracy": 0.513333,
            "f1": 0.511672,
            "f1_weighted": 0.511672,
            "ap": 0.506868,
            "ap_weighted": 0.506868
          }
        ],
        "main_score": 0.538583,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.025595903396606,
  "kg_co2_emissions": 0.0005714362770660039
}