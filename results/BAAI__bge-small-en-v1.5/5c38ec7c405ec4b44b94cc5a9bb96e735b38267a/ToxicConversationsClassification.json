{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 10.536282777786255,
  "kg_co2_emissions": 0.00031197255154524024,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.65478515625,
        "ap": 0.11767293930863784,
        "ap_weighted": 0.11767293930863784,
        "f1": 0.5007522783653079,
        "f1_weighted": 0.7293279253325575,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.65478515625,
        "scores_per_experiment": [
          {
            "accuracy": 0.7041015625,
            "ap": 0.13189251375084948,
            "ap_weighted": 0.13189251375084948,
            "f1": 0.5362984218077474,
            "f1_weighted": 0.7711138556985294
          },
          {
            "accuracy": 0.732421875,
            "ap": 0.11134479109931011,
            "ap_weighted": 0.11134479109931011,
            "f1": 0.5310720582951023,
            "f1_weighted": 0.7897360553139128
          },
          {
            "accuracy": 0.70703125,
            "ap": 0.13645893061926606,
            "ap_weighted": 0.13645893061926606,
            "f1": 0.5408895265423243,
            "f1_weighted": 0.7733800551470589
          },
          {
            "accuracy": 0.72314453125,
            "ap": 0.13109339370854065,
            "ap_weighted": 0.13109339370854065,
            "f1": 0.5443021880021898,
            "f1_weighted": 0.7846172306828015
          },
          {
            "accuracy": 0.53515625,
            "ap": 0.10298431920993707,
            "ap_weighted": 0.10298431920993707,
            "f1": 0.4339433762209858,
            "f1_weighted": 0.6354341318734343
          },
          {
            "accuracy": 0.427734375,
            "ap": 0.09523264164025357,
            "ap_weighted": 0.09523264164025357,
            "f1": 0.3691717688219067,
            "f1_weighted": 0.5309697384549721
          },
          {
            "accuracy": 0.72021484375,
            "ap": 0.11227385715212251,
            "ap_weighted": 0.11227385715212251,
            "f1": 0.5269698805597981,
            "f1_weighted": 0.7814804355941053
          },
          {
            "accuracy": 0.61669921875,
            "ap": 0.10445233994366626,
            "ap_weighted": 0.10445233994366626,
            "f1": 0.4746279426119391,
            "f1_weighted": 0.7046099896185278
          },
          {
            "accuracy": 0.705078125,
            "ap": 0.11977964861356065,
            "ap_weighted": 0.11977964861356065,
            "f1": 0.5272825103333578,
            "f1_weighted": 0.7713268094458507
          },
          {
            "accuracy": 0.67626953125,
            "ap": 0.13121695734887187,
            "ap_weighted": 0.13121695734887187,
            "f1": 0.5229651104577282,
            "f1_weighted": 0.7506109514963815
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}