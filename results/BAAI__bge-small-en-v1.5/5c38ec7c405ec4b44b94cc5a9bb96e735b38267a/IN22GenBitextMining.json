{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 42.314836263656616,
  "kg_co2_emissions": 0.0014410316219611394,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.1015625,
        "f1": 0.07853655133928572,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.07853655133928572,
        "precision": 0.07028924851190477,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 7.62939453125e-06,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 7.62939453125e-06,
        "precision": 3.829656862745098e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.632243935309973e-06,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 2.632243935309973e-06,
        "precision": 1.3178981106612685e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.950622775800711e-06,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 6.950622775800711e-06,
        "precision": 3.487723214285714e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0015913472364353868,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0015913472364353868,
        "precision": 0.00136643991064343,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00042712200393661557,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.00042712200393661557,
        "precision": 0.000262686560207048,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.686607418130062e-05,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 7.686607418130062e-05,
        "precision": 3.9215926101406286e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.2929755472112835e-05,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 4.2929755472112835e-05,
        "precision": 2.1762347846441947e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.9097736849752974e-05,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 4.9097736849752974e-05,
        "precision": 2.488706222056632e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00020887586805555557,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.00020887586805555557,
        "precision": 0.00011533605283605283,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00021414771519403215,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.00021414771519403215,
        "precision": 0.00011797795803574912,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000243884996112035,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.000243884996112035,
        "precision": 0.00013181196857468445,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003097428828287123,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.003097428828287123,
        "precision": 0.002690652844826688,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009846950627375361,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0009846950627375361,
        "precision": 0.0006787469609322601,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00031490265376984126,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.00031490265376984126,
        "precision": 0.00018095894979383944,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.912952987267385e-06,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 1.912952987267385e-06,
        "precision": 9.574142156862745e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00039792074179558406,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.00039792074179558406,
        "precision": 0.00021777190443485086,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.1022709258084973e-05,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 1.1022709258084973e-05,
        "precision": 5.527021937201572e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.2440286624203822e-05,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 1.2440286624203822e-05,
        "precision": 6.2600160256410254e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.07108128958714896,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.07108128958714896,
        "precision": 0.066006282129329,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.982461734693877e-06,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 4.982461734693877e-06,
        "precision": 2.4976023017902815e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006184895833333333,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0006184895833333333,
        "precision": 0.0003952752976190476,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009790473918575063,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0009790473918575063,
        "precision": 0.0009778065286624204,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.3821772527326046e-05,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 2.3821772527326046e-05,
        "precision": 1.1991659076341802e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00016725653776063606,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.00016725653776063606,
        "precision": 8.685434458541591e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000995025395934591,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.000995025395934591,
        "precision": 0.0009858616449659545,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006853818003331986,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0006853818003331986,
        "precision": 0.0005055842519209552,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019049142083082482,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.00019049142083082482,
        "precision": 0.00010416666666666667,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009789707922318125,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0009789707922318125,
        "precision": 0.0009777681327160495,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00031300080128205125,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.00031300080128205125,
        "precision": 0.00017015861742424244,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010934098116243847,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0010934098116243847,
        "precision": 0.0010378925120772947,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012046709191635458,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0012046709191635458,
        "precision": 0.0010986328125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012468863224637681,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0012468863224637681,
        "precision": 0.0011233227401129945,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 7.573341836734694e-05,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 7.573341836734694e-05,
        "precision": 3.879008110976349e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00025065104166666665,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.00025065104166666665,
        "precision": 0.00014277502388915431,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009784698486328125,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0009784698486328125,
        "precision": 0.0009775171065493646,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009860415292414393,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0009860415292414393,
        "precision": 0.0009813147048566744,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000987839033018868,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.000987839033018868,
        "precision": 0.0009822186394569442,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010036600989079842,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0010036600989079842,
        "precision": 0.000990212658838212,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.8627157104437473e-05,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 2.8627157104437473e-05,
        "precision": 1.443699110716885e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.488057324840764e-06,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 2.488057324840764e-06,
        "precision": 1.2456154336734693e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014008596550179212,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0014008596550179212,
        "precision": 0.0012099745536406396,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.2255859375,
        "f1": 0.20876746329817847,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.20876746329817847,
        "precision": 0.20355964429450757,
        "recall": 0.2255859375
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.01279189263494412,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.01279189263494412,
        "precision": 0.011831193380586883,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.12021328098399728,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.12021328098399728,
        "precision": 0.11609835134711778,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.009773782382590197,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.009773782382590197,
        "precision": 0.007947022439970378,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.20075024801587305,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.20075024801587305,
        "precision": 0.19424121428085123,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0017497801677489177,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0017497801677489177,
        "precision": 0.0014678120250759877,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.09986208078978395,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.09986208078978395,
        "precision": 0.09577135917467948,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03865954466540404,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.03865954466540404,
        "precision": 0.03419562711039875,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.04696108142161974,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.04696108142161974,
        "precision": 0.04404415822929354,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008080512152777778,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.008080512152777778,
        "precision": 0.006969878309053885,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00039802320075757577,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00039802320075757577,
        "precision": 0.0002478537903992395,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.025828591152005673,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.025828591152005673,
        "precision": 0.02335321335565476,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005863598324184963,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0005863598324184963,
        "precision": 0.0003469773371917314,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.10630498402097201,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.10630498402097201,
        "precision": 0.10383713959867344,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.021819009543989763,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.021819009543989763,
        "precision": 0.019288055332977207,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004921259842519685,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0004921259842519685,
        "precision": 0.00032744699211045364,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.20311911437134347,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.20311911437134347,
        "precision": 0.1964955495788094,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04934456201602822,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.04934456201602822,
        "precision": 0.04430119163219666,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.09117101070226069,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09117101070226069,
        "precision": 0.08795360301707958,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.10002638556556512,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10002638556556512,
        "precision": 0.0955424837642365,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.5869205298013245e-06,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 2.5869205298013245e-06,
        "precision": 1.2951757294429708e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00012405211031951642,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00012405211031951642,
        "precision": 6.409740893092912e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.20842594716575696,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.20842594716575696,
        "precision": 0.20131678285364807,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01809587767398626,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.01809587767398626,
        "precision": 0.017027554617850747,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.1624306869917252,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.1624306869917252,
        "precision": 0.1586912504984051,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012055327641062822,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.012055327641062822,
        "precision": 0.010212807590971386,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.361328125,
        "f1": 0.3191530962527056,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3191530962527056,
        "precision": 0.304133172371762,
        "recall": 0.361328125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016340289199561404,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0016340289199561404,
        "precision": 0.001468066728547855,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.099381806759162,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.099381806759162,
        "precision": 0.09561919848630175,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.12499922495039682,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.12499922495039682,
        "precision": 0.11372029121052558,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.04785403481012658,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.04785403481012658,
        "precision": 0.04449993563846641,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.011306483230311356,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.011306483230311356,
        "precision": 0.009919371104093116,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00018077697880087586,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00018077697880087586,
        "precision": 9.436144028223283e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.08285280257936507,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.08285280257936507,
        "precision": 0.07528641605790043,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.492484078421578e-05,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 8.492484078421578e-05,
        "precision": 4.3501109038413785e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.11126213767192193,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.11126213767192193,
        "precision": 0.10823076776835135,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026210689513982303,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.026210689513982303,
        "precision": 0.022510738538739097,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017543556747507069,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0017543556747507069,
        "precision": 0.0015303214651639346,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.2783203125,
        "f1": 0.24389727377146955,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.24389727377146955,
        "precision": 0.23255657509807898,
        "recall": 0.2783203125
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.05543437916529725,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.05543437916529725,
        "precision": 0.04984258695148637,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.09387540446551426,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09387540446551426,
        "precision": 0.0895945041569617,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.10800255224409439,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10800255224409439,
        "precision": 0.1029507760589701,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.6393581081081083e-05,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 2.6393581081081083e-05,
        "precision": 1.3377568493150684e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026616115196078432,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0026616115196078432,
        "precision": 0.002470999053030303,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.055576882533968225,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.055576882533968225,
        "precision": 0.0487068298105709,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.06817947061565835,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.06817947061565835,
        "precision": 0.05751209326598336,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.06154278161903966,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.06154278161903966,
        "precision": 0.052054133715905546,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.008734184145149794,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.008734184145149794,
        "precision": 0.0062178062966891665,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.053532791582568684,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.053532791582568684,
        "precision": 0.045379905906253834,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0018428912246204786,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.0018428912246204786,
        "precision": 0.0012071397569444443,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.06458219875785884,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.06458219875785884,
        "precision": 0.05656430947460933,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011031539351851853,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.0011031539351851853,
        "precision": 0.0006804637419871795,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.06281408401530059,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.06281408401530059,
        "precision": 0.052904090877113334,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003865559895833333,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0003865559895833333,
        "precision": 0.0002110171815702087,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004066010283486287,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0004066010283486287,
        "precision": 0.00021636801421957673,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.765625e-05,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 9.765625e-05,
        "precision": 5.139802631578947e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018684895833333333,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0018684895833333333,
        "precision": 0.0014915829613095237,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.07992706331449492,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.07992706331449492,
        "precision": 0.06802946969219584,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.1097301136363637e-05,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 1.1097301136363637e-05,
        "precision": 5.580357142857143e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009264269866698242,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0009264269866698242,
        "precision": 0.0005582153035502518,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.09375,
        "f1": 0.055540322316697796,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.055540322316697796,
        "precision": 0.048378313199023,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.029770213510447886,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.029770213510447886,
        "precision": 0.02500015127973538,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.07911923185997077,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.07911923185997077,
        "precision": 0.06629707040340957,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.05649302939727487,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.05649302939727487,
        "precision": 0.04919232156833041,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00013950892857142856,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00013950892857142856,
        "precision": 7.512019230769231e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001743127153154057,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.001743127153154057,
        "precision": 0.0014530739289940254,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.18306216378596893,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.18306216378596893,
        "precision": 0.17500333955196662,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.240234375,
        "f1": 0.20598617190148694,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.20598617190148694,
        "precision": 0.19571750546580435,
        "recall": 0.240234375
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.016794373454959738,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.016794373454959738,
        "precision": 0.015192136170098139,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.019655608633978645,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.019655608633978645,
        "precision": 0.017629973981508992,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.240234375,
        "f1": 0.2052455563171843,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2052455563171843,
        "precision": 0.1948740509165314,
        "recall": 0.240234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002940598812849162,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.002940598812849162,
        "precision": 0.002935173806179775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.11148462069057664,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.11148462069057664,
        "precision": 0.10493631771120246,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.044942059388617846,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.044942059388617846,
        "precision": 0.03819919309780294,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.06666993823283082,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.06666993823283082,
        "precision": 0.06289226352768457,
        "recall": 0.078125
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.1837247333829365,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.1837247333829365,
        "precision": 0.16786683097718255,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002723106971153846,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0002723106971153846,
        "precision": 0.000146484375,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.03396463291482823,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.03396463291482823,
        "precision": 0.029381446589052288,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007543231635602959,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0007543231635602959,
        "precision": 0.0004425355867439662,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.11563756433311533,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.11563756433311533,
        "precision": 0.11110411562524705,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.054987127130681816,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.054987127130681816,
        "precision": 0.049106308188339436,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001597297054597701,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001597297054597701,
        "precision": 0.0010656932043650793,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.2314453125,
        "f1": 0.20504356660097148,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.20504356660097148,
        "precision": 0.19657681727994225,
        "recall": 0.2314453125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05816235766712005,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.05816235766712005,
        "precision": 0.0523839665447063,
        "recall": 0.078125
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.10419161435659703,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.10419161435659703,
        "precision": 0.0991198171977124,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.10673971211080585,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10673971211080585,
        "precision": 0.10127418154761905,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 6.454167247305834e-05,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 6.454167247305834e-05,
        "precision": 3.2856641048980194e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0014716968201754386,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0014716968201754386,
        "precision": 0.001305521933685446,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.018803534450301206,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.018803534450301206,
        "precision": 0.018078065691856448,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.019719543249368133,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.019719543249368133,
        "precision": 0.019381320858812518,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005042868658205829,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.005042868658205829,
        "precision": 0.004968285105400698,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.018588956628579602,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.018588956628579602,
        "precision": 0.018257286354126427,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.019759472298534798,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.019759472298534798,
        "precision": 0.0194017909473572,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.10841548859126984,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.10841548859126984,
        "precision": 0.09965239025297618,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.018237964527027025,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.018237964527027025,
        "precision": 0.017745304251508293,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.82593515395328e-05,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 3.82593515395328e-05,
        "precision": 1.9332890345211664e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.07353593129960317,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.07353593129960317,
        "precision": 0.06782689153294622,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.786717646961407e-05,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 6.786717646961407e-05,
        "precision": 3.4378803583990645e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.025968036954365076,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.025968036954365076,
        "precision": 0.021254018100295674,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9629396984924625e-06,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 1.9629396984924625e-06,
        "precision": 9.824572434607647e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.020404326554479803,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.020404326554479803,
        "precision": 0.018126523424210873,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04599752287957681,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.04599752287957681,
        "precision": 0.043542797573805664,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006729796289987671,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0006729796289987671,
        "precision": 0.0004993361666732292,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02444976412177382,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.02444976412177382,
        "precision": 0.02160322026558663,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018152580875594453,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.018152580875594453,
        "precision": 0.01709564946841796,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013994510185530091,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.013994510185530091,
        "precision": 0.013553123942580294,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.09008644691633758,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.09008644691633758,
        "precision": 0.08331489609565781,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.013023178021208483,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.013023178021208483,
        "precision": 0.012696486253004808,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006628096100646693,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0006628096100646693,
        "precision": 0.0004941866157035029,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002470163554948391,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.002470163554948391,
        "precision": 0.0022931383136917598,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.1785830587258092,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1785830587258092,
        "precision": 0.1707265404408959,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.3057663202682734,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3057663202682734,
        "precision": 0.29395649110004574,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.014301852328627419,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.014301852328627419,
        "precision": 0.013585329576649994,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.14318021930326616,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.14318021930326616,
        "precision": 0.1400721467223039,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.011731794663580914,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011731794663580914,
        "precision": 0.010095319981691641,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.08084639259239741,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.08084639259239741,
        "precision": 0.07727331998572233,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.2138671875,
        "f1": 0.16718970591040902,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.16718970591040902,
        "precision": 0.15159014067274637,
        "recall": 0.2138671875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.035972380003476356,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.035972380003476356,
        "precision": 0.03326939451571201,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.020225061152143387,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.020225061152143387,
        "precision": 0.0184158081447552,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00010320490056818182,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00010320490056818182,
        "precision": 5.418025566051882e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.09222845839056776,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09222845839056776,
        "precision": 0.0832807004193723,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003994228603603604,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0003994228603603604,
        "precision": 0.00024855945984162894,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.08316566964457442,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.08316566964457442,
        "precision": 0.08088703821927352,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.028406069110556757,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.028406069110556757,
        "precision": 0.025697705614697804,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.907349246231156e-06,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 4.907349246231156e-06,
        "precision": 2.4598551637279596e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.287109375,
        "f1": 0.2522822545623157,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2522822545623157,
        "precision": 0.2406934157422439,
        "recall": 0.287109375
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.04241621009199134,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.04241621009199134,
        "precision": 0.03722563244047619,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.07261797501055313,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.07261797501055313,
        "precision": 0.06871739974974217,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.10327649238782052,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10327649238782052,
        "precision": 0.10000984572582022,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00031614006055008206,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.00031614006055008206,
        "precision": 0.00017680168738317472,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020005339159531177,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0020005339159531177,
        "precision": 0.00197719972537856,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001252405889271031,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.001252405889271031,
        "precision": 0.000848680149311159,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00011373852926587302,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.00011373852926587302,
        "precision": 5.9473230957104507e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001305154284591195,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.001305154284591195,
        "precision": 0.0011734128937007874,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0005518323780431692,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0005518323780431692,
        "precision": 0.0003276206553965164,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.10358847966269841,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.10358847966269841,
        "precision": 0.09131673177083333,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00016362158289241622,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.00016362158289241622,
        "precision": 8.732722355769231e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019585654596100278,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0019585654596100278,
        "precision": 0.0019558528282122905,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005226383314826375,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.0005226383314826375,
        "precision": 0.0003014244511279315,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.06253262254238817,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.06253262254238817,
        "precision": 0.05576249379960317,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0013065923575227211,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0013065923575227211,
        "precision": 0.001154019971619229,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.027217654843199268,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.027217654843199268,
        "precision": 0.021997209288536768,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006529812148295266,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0006529812148295266,
        "precision": 0.0004892519880715705,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029392185953225312,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.029392185953225312,
        "precision": 0.025730866842826407,
        "recall": 0.046875
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.013773869337107645,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.013773869337107645,
        "precision": 0.011458545702415134,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016032898336665515,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0016032898336665515,
        "precision": 0.001345823883084957,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025780343236932537,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.025780343236932537,
        "precision": 0.02176062911267271,
        "recall": 0.046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004315878648768679,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0004315878648768679,
        "precision": 0.0002499966148397508,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00035729013929618767,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.00035729013929618767,
        "precision": 0.00021138153318759937,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.08380732671238786,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.08380732671238786,
        "precision": 0.07328147926292457,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.2950940070505287e-06,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 2.2950940070505287e-06,
        "precision": 1.1488970588235293e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010009765625,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0010009765625,
        "precision": 0.0009889240506329115,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002894503430037704,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0002894503430037704,
        "precision": 0.00015242156169678248,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.11962193080357142,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.11962193080357142,
        "precision": 0.11583962912087914,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.1278077816965783,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.1278077816965783,
        "precision": 0.1222980519258017,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.01711247785154335,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.01711247785154335,
        "precision": 0.016133051471428964,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.11039026800745551,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.11039026800745551,
        "precision": 0.10544836360818818,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.015934745136533788,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.015934745136533788,
        "precision": 0.013184958801478127,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.11387814915123162,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.11387814915123162,
        "precision": 0.10872269401746729,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008871336996336996,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0008871336996336996,
        "precision": 0.0006141193312615102,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014173719618055555,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0014173719618055555,
        "precision": 0.0009673744119623655,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.07839670914580621,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.07839670914580621,
        "precision": 0.07214192072134994,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00029221464768339764,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.00029221464768339764,
        "precision": 0.00016940369897959184,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004485961130453705,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0004485961130453705,
        "precision": 0.00025390625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017076490267639902,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0017076490267639902,
        "precision": 0.001423514714765656,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007509653026918476,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0007509653026918476,
        "precision": 0.0005393533740724108,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.13260982452876985,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.13260982452876985,
        "precision": 0.12766450532563814,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006730693922305763,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0006730693922305763,
        "precision": 0.0004993645922670097,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.3005005889281506e-06,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 2.3005005889281506e-06,
        "precision": 1.1516067216981132e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.10900459674873737,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.10900459674873737,
        "precision": 0.1034299820188492,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06705856094882998,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.06705856094882998,
        "precision": 0.059808058965773805,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.10186524756733367,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.10186524756733367,
        "precision": 0.09649013519060774,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.2451171875,
        "f1": 0.21629433194766873,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.21629433194766873,
        "precision": 0.20844800929060192,
        "recall": 0.2451171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.278894150829314e-05,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 1.278894150829314e-05,
        "precision": 6.4230647866380796e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00017757242088555454,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00017757242088555454,
        "precision": 9.516896960193331e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.025346997062873508,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.025346997062873508,
        "precision": 0.02210901880091333,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.09482211836876359,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.09482211836876359,
        "precision": 0.08339570721162518,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006052421382789595,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0006052421382789595,
        "precision": 0.0003875926801353503,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.015111038191880581,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.015111038191880581,
        "precision": 0.014338463138989635,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.187155197444832e-05,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 3.187155197444832e-05,
        "precision": 1.6051497547265953e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.16806828515812888,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.16806828515812888,
        "precision": 0.15078051193343012,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0011541193181818182,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0011541193181818182,
        "precision": 0.00107421875,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.9064360119047617e-06,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 2.9064360119047617e-06,
        "precision": 1.4553837555886736e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1629291251384274e-06,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 2.1629291251384274e-06,
        "precision": 1.0826635254988914e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.018480231814071425,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.018480231814071425,
        "precision": 0.016920847606775133,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00016283556576247274,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00016283556576247274,
        "precision": 8.628100457200618e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.15107034350198412,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.15107034350198412,
        "precision": 0.13963836185515874,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00022150053967090257,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00022150053967090257,
        "precision": 0.00012167050429876665,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005108840315830897,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0005108840315830897,
        "precision": 0.0003063704706624123,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04465176934425408,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.04465176934425408,
        "precision": 0.039984949945887444,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.90625e-06,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 3.90625e-06,
        "precision": 1.9570390781563125e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.05779934583645521,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.05779934583645521,
        "precision": 0.051266790520294654,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009864769656058535,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0009864769656058535,
        "precision": 0.0009815325682609056,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000732421875,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.000732421875,
        "precision": 0.0004650297619047619,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.5464471968709256e-06,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 2.5464471968709256e-06,
        "precision": 1.274885770234987e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019670478367629102,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0019670478367629102,
        "precision": 0.00196011867489217,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.0642409324082128,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.0642409324082128,
        "precision": 0.05915850240590946,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.08056380654058887,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.08056380654058887,
        "precision": 0.07643742507083792,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.025706639592893894,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.025706639592893894,
        "precision": 0.02449433527447039,
        "recall": 0.03125
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.07175174756874222,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.07175174756874222,
        "precision": 0.06742618306934123,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.05302347608988234,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.05302347608988234,
        "precision": 0.044153152205484464,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.06786440811090529,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.06786440811090529,
        "precision": 0.06189990024692163,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.0659743484278181,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.0659743484278181,
        "precision": 0.06070169239904492,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.07241019325625297,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.07241019325625297,
        "precision": 0.0683711211909454,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001954872634449439,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.001954872634449439,
        "precision": 0.0016435947910925148,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0005662151994001138,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0005662151994001138,
        "precision": 0.00032385233947733954,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.014364571605310012,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.014364571605310012,
        "precision": 0.01167975786634555,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.030275467775468e-06,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 2.030275467775468e-06,
        "precision": 1.01619406867846e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.012409728523895948,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.012409728523895948,
        "precision": 0.011272559905372405,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.15766863467525832,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.15766863467525832,
        "precision": 0.15148884117323896,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006687973484848485,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0006687973484848485,
        "precision": 0.0004972405389908256,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.01181245978120978,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.01181245978120978,
        "precision": 0.009824141245039683,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.06299645582977688,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.06299645582977688,
        "precision": 0.05910385187728938,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.05114226470122466,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.05114226470122466,
        "precision": 0.04918846203794838,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.19599963466289294,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.19599963466289294,
        "precision": 0.18731957739526098,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.06107811976260758,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.06107811976260758,
        "precision": 0.05748249857636181,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.2950940070505287e-06,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 2.2950940070505287e-06,
        "precision": 1.1488970588235293e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010085265756387743,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0010085265756387743,
        "precision": 0.0009926327120398006,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012069579509587102,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.012069579509587102,
        "precision": 0.0086462778107969,
        "recall": 0.03125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.028570234647023296,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.028570234647023296,
        "precision": 0.023455134589232037,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.9368249877270495e-05,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 1.9368249877270495e-05,
        "precision": 9.732457173314823e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2158203125,
        "f1": 0.15810061329219188,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.15810061329219188,
        "precision": 0.1401963302188773,
        "recall": 0.2158203125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.994120654396728e-06,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 3.994120654396728e-06,
        "precision": 2.0011526639344263e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.02785555761398689,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.02785555761398689,
        "precision": 0.02236952688727735,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010245115589198038,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0010245115589198038,
        "precision": 0.0010009330436720142,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.160556801634647e-05,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 2.160556801634647e-05,
        "precision": 1.0876978543269688e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.05863612874252751,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05863612874252751,
        "precision": 0.05027205410634687,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005008776432738797,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0005008776432738797,
        "precision": 0.0003318430663144531,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.982461734693877e-06,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 4.982461734693877e-06,
        "precision": 2.4976023017902815e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.053311224674663135,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.053311224674663135,
        "precision": 0.04659310726995125,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002072948619631902,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0002072948619631902,
        "precision": 0.00011453510802469135,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00010516826923076924,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.00010516826923076924,
        "precision": 5.43212890625e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.04811270543692418,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.04811270543692418,
        "precision": 0.04225086118874332,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005552696893251982,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0005552696893251982,
        "precision": 0.0003594333900963087,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024387333043319345,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.024387333043319345,
        "precision": 0.021110804089894162,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009801727125693161,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0009801727125693161,
        "precision": 0.000978370949074074,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.5210348462301587e-05,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 1.5210348462301587e-05,
        "precision": 7.64036000399935e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003992668329106472,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0003992668329106472,
        "precision": 0.0002484718405421818,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0023467273246951218,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0023467273246951218,
        "precision": 0.002198756560114504,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.220143312101911e-06,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 6.220143312101911e-06,
        "precision": 3.120007987220447e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.0294270433163876e-05,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 5.0294270433163876e-05,
        "precision": 2.535091683071306e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.275457753682488e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 4.275457753682488e-05,
        "precision": 2.1752450980392158e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.201844262295082e-05,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 3.201844262295082e-05,
        "precision": 1.6276041666666666e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.03540034832955946,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.03540034832955946,
        "precision": 0.032417423755855865,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019822326751117736,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.00019822326751117736,
        "precision": 0.0001099645004145937,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.0315365745907738,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0315365745907738,
        "precision": 0.02801038077625779,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1001344086021505e-06,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 2.1001344086021505e-06,
        "precision": 1.0511975242195909e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 6.977713760418843e-05,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 6.977713760418843e-05,
        "precision": 3.545525745963305e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01496190983495671,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.01496190983495671,
        "precision": 0.013495221722752629,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.6919106236355505e-05,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 2.6919106236355505e-05,
        "precision": 1.3595200154683166e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.030275467775468e-06,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 2.030275467775468e-06,
        "precision": 1.01619406867846e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.048450437366452985,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.048450437366452985,
        "precision": 0.042812047207863406,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.036641652960526315,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.036641652960526315,
        "precision": 0.031785812974518095,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001182935554029304,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.001182935554029304,
        "precision": 0.0010906167868314242,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.06671855651243949,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.06671855651243949,
        "precision": 0.059451651086119495,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00021900687358276642,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.00021900687358276642,
        "precision": 0.0001230678227145046,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003379182642090251,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0003379182642090251,
        "precision": 0.00020153100868238054,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.0163906162343352,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0163906162343352,
        "precision": 0.014982589949811423,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 5.059909326424871e-06,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 5.059909326424871e-06,
        "precision": 2.536525974025974e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001201896774334734,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.001201896774334734,
        "precision": 0.0010952236416103603,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.01658862593059514,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.01658862593059514,
        "precision": 0.013804989769345239,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07050788295905483,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.07050788295905483,
        "precision": 0.06385214449179294,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00016841017308068937,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00016841017308068937,
        "precision": 8.790532949840016e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009954871864003612,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.009954871864003612,
        "precision": 0.009277371933621935,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.164445628997868e-06,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 4.164445628997868e-06,
        "precision": 2.0866720085470088e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.09407403726508373,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.09407403726508373,
        "precision": 0.08401492984012515,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006558881306865178,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0006558881306865178,
        "precision": 0.0004907105099502488,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.6251680107526884e-06,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 2.6251680107526884e-06,
        "precision": 1.314350605652759e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.15971602182539682,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.15971602182539682,
        "precision": 0.14530129334385997,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.146291208791209e-06,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 2.146291208791209e-06,
        "precision": 1.0743261826182618e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.017773726062782914,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.017773726062782914,
        "precision": 0.017063197774892104,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.9390756302521004e-05,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 3.9390756302521004e-05,
        "precision": 1.9931556041505875e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.623938268284757e-05,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 1.623938268284757e-05,
        "precision": 8.165607344632769e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014145122155287818,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0014145122155287818,
        "precision": 0.0012448626417596487,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03824059948815052,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.03824059948815052,
        "precision": 0.03448603066651484,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019565041089965396,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0019565041089965396,
        "precision": 0.0019548174826689775,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.032175859577825025,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.032175859577825025,
        "precision": 0.026681646261724385,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.950622775800711e-06,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 6.950622775800711e-06,
        "precision": 3.487723214285714e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0006510416666666666,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.00048828125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.368885869565217e-05,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 6.368885869565217e-05,
        "precision": 3.283067259161729e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009791357872200263,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0009791357872200263,
        "precision": 0.0009778508410290237,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0001414853827198047,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0001414853827198047,
        "precision": 7.487763554216866e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00023192908616073883,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.00023192908616073883,
        "precision": 0.00012382303786980583,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009896836528270352,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0009896836528270352,
        "precision": 0.0009831513631476131,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001743861607142857,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0001743861607142857,
        "precision": 9.462608873162766e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.01252878094315767,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.01252878094315767,
        "precision": 0.010607728744598262,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.8807153392330383e-06,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 2.8807153392330383e-06,
        "precision": 1.4424852289512556e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.02441479691829186,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.02441479691829186,
        "precision": 0.022553828164159715,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0451570680628274e-06,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 2.0451570680628274e-06,
        "precision": 1.0236504192872118e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0001210445603918208,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0001210445603918208,
        "precision": 6.285938169923793e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.008356704797117337,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.008356704797117337,
        "precision": 0.007398688407563637,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00032975264283394303,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.00032975264283394303,
        "precision": 0.000177740895514333,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.04499038387174728,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.04499038387174728,
        "precision": 0.0397065609278385,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.941476143141153e-06,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 1.941476143141153e-06,
        "precision": 9.717039800995024e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.009959252665610752,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.009959252665610752,
        "precision": 0.008517672132200355,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001572681980738066,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.001572681980738066,
        "precision": 0.001334316011005803,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.0266791138132808,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0266791138132808,
        "precision": 0.022993512834821428,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00022384791249373907,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.00022384791249373907,
        "precision": 0.00011709887953953374,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00040290157723918933,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.00040290157723918933,
        "precision": 0.0002502993257039606,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009560494724571968,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.009560494724571968,
        "precision": 0.008968001851009566,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 4.5943076605890993e-05,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 4.5943076605890993e-05,
        "precision": 2.329026237387188e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 8.861757863965744e-05,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 8.861757863965744e-05,
        "precision": 4.6242264317750564e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011749801271860095,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0011749801271860095,
        "precision": 0.0010866244802724698,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.11076220444775131,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.11076220444775131,
        "precision": 0.10371166979194718,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.15625,
        "f1": 0.13658121206206295,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.13658121206206295,
        "precision": 0.13065177977574577,
        "recall": 0.15625
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.025944774141596377,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.025944774141596377,
        "precision": 0.024614115594660195,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.11212036661255409,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.11212036661255409,
        "precision": 0.10594829776422764,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.03893977026707102,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.03893977026707102,
        "precision": 0.03276483197980097,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.12274473979796245,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.12274473979796245,
        "precision": 0.11510103047269507,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.011795251802469871,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.011795251802469871,
        "precision": 0.01013494404354763,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.10910924772869673,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.10910924772869673,
        "precision": 0.1029909808686558,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002417311325571895,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.002417311325571895,
        "precision": 0.0019269413552201855,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.14568555323897875,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.14568555323897875,
        "precision": 0.1349626470561329,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00012251797432928006,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.00012251797432928006,
        "precision": 6.311294880319149e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04388337899080086,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.04388337899080086,
        "precision": 0.039450799851190474,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019553072625698325,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0019553072625698325,
        "precision": 0.001954217351789709,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.027515691773504273,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.027515691773504273,
        "precision": 0.025253401131465517,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013734676446945336,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0013734676446945336,
        "precision": 0.0012238533266129032,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.0268889177173593,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0268889177173593,
        "precision": 0.02392213499391234,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.10566347274503203,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.10566347274503203,
        "precision": 0.09978966829552766,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.05061169299450549,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.05061169299450549,
        "precision": 0.04842481426164215,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.2216796875,
        "f1": 0.19925103569440394,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.19925103569440394,
        "precision": 0.19146212849216634,
        "recall": 0.2216796875
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.0918185494327192,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.0918185494327192,
        "precision": 0.0860403537686877,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.444664902998236e-06,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 3.444664902998236e-06,
        "precision": 1.725375441696113e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001074793683647002,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.001074793683647002,
        "precision": 0.0010271782445495682,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.029083743947025197,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.029083743947025197,
        "precision": 0.024245493454542077,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.03149397260725385,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.03149397260725385,
        "precision": 0.0275700997136544,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.786985655378137e-05,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 3.786985655378137e-05,
        "precision": 1.913286701556629e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.02504048494397759,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.02504048494397759,
        "precision": 0.023520753244874338,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000992808745709382,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.000992808745709382,
        "precision": 0.000984731129721716,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.046953041533119654,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.046953041533119654,
        "precision": 0.03987668960813492,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002936894603321033,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.002936894603321033,
        "precision": 0.002933304398148148,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.188336588958627e-05,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 1.188336588958627e-05,
        "precision": 5.9640286707428835e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.06340448288690476,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.06340448288690476,
        "precision": 0.05464565816128316,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009890073680132855,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0009890073680132855,
        "precision": 0.0009828111341783215,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03062783912907268,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.03062783912907268,
        "precision": 0.028482297867063494,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009975376186313687,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009975376186313687,
        "precision": 0.00098710882713885,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.046208338102869354,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.046208338102869354,
        "precision": 0.040840463789682535,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010033058001999754,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0010033058001999754,
        "precision": 0.00099000262482148,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001053342677883119,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.001053342677883119,
        "precision": 0.0010155078376351786,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001957786396181384,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001957786396181384,
        "precision": 0.001955461273923445,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.03132757541937229,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.03132757541937229,
        "precision": 0.02730654761904762,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010291757509689923,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0010291757509689923,
        "precision": 0.0010034988019666418,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000999378566969859,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.000999378566969859,
        "precision": 0.0009880462875939849,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003928699712643678,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0003928699712643678,
        "precision": 0.0002452644023302647,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0022808703492786637,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0022808703492786637,
        "precision": 0.0021495510262257694,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00017252189821632098,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.00017252189821632098,
        "precision": 9.367138722758855e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.000831188222631253,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.000831188222631253,
        "precision": 0.0005827616285235204,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002061214951839952,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.002061214951839952,
        "precision": 0.002008864266128286,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011118245814307458,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0011118245814307458,
        "precision": 0.001047570720996732,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.0277453592797113,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0277453592797113,
        "precision": 0.024375060256746604,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000498340404424181,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.000498340404424181,
        "precision": 0.00028598642443293884,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.02736780982622212,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.02736780982622212,
        "precision": 0.024552277562341532,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0537592008412197e-06,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 2.0537592008412197e-06,
        "precision": 1.0279605263157895e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009809124443207126,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0009809124443207126,
        "precision": 0.0009787423270089285,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008203004200083318,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.008203004200083318,
        "precision": 0.007001500019078144,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00012098618095936577,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.00012098618095936577,
        "precision": 6.297278025793651e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.05237780340319402,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.05237780340319402,
        "precision": 0.04462658110119048,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009784848671259842,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0009784848671259842,
        "precision": 0.000977524630541872,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.024580978916006017,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.024580978916006017,
        "precision": 0.021754247299137122,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.017611660258144632,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.017611660258144632,
        "precision": 0.014740673055983651,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001982374026987514,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.001982374026987514,
        "precision": 0.001967932381816723,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002443377112764884,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.002443377112764884,
        "precision": 0.00227963226010101,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006330832002516453,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0006330832002516453,
        "precision": 0.0004032947280866778,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.013778066031108755,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.013778066031108755,
        "precision": 0.012512884467856632,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00011945308205057724,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.00011945308205057724,
        "precision": 6.332218786592506e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.0985876403108425e-05,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 1.0985876403108425e-05,
        "precision": 5.511861234641411e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006806344696969696,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0006806344696969696,
        "precision": 0.0005033052884615384,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.20794646434294872,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.20794646434294872,
        "precision": 0.2011668724071068,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.296875,
        "f1": 0.2681663876488095,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2681663876488095,
        "precision": 0.2572684151785714,
        "recall": 0.296875
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.017336569708377977,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.017336569708377977,
        "precision": 0.016319017959930182,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.17470238095238094,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.17470238095238094,
        "precision": 0.170947265625,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.01229719742468304,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01229719742468304,
        "precision": 0.010613345660741983,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.341796875,
        "f1": 0.30503523340694394,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.30503523340694394,
        "precision": 0.29078776041666665,
        "recall": 0.341796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006999530450767263,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0006999530450767263,
        "precision": 0.0005131489071038252,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.08803570553122626,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.08803570553122626,
        "precision": 0.08363991919465069,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.08379371279761905,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08379371279761905,
        "precision": 0.0753759342870671,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.052606713113863536,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.052606713113863536,
        "precision": 0.04907354051077023,
        "recall": 0.0625
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.03186797334784346,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.03186797334784346,
        "precision": 0.030174070335845626,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.0160995770857366e-05,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 5.0160995770857366e-05,
        "precision": 2.5585444286616164e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04867699032738095,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04867699032738095,
        "precision": 0.0434543538059163,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004223038530799801,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0004223038530799801,
        "precision": 0.0002458342519106408,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.11219183206565164,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.11219183206565164,
        "precision": 0.1086486138073823,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.03434832420183982,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.03434832420183982,
        "precision": 0.03067898975404556,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.04425783985469188,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.04425783985469188,
        "precision": 0.03926501693835678,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.08779028031673433,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.08779028031673433,
        "precision": 0.08396794123734924,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.10497846507727022,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10497846507727022,
        "precision": 0.0999683869190705,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010546875,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0010546875,
        "precision": 0.0010172526041666667,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.07036238473947826,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.07036238473947826,
        "precision": 0.06746384824184304,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.09209438643129247,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.09209438643129247,
        "precision": 0.08916668417412628,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.017148860254329004,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.017148860254329004,
        "precision": 0.016146027755277598,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.07533293991546545,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.07533293991546545,
        "precision": 0.07228205393918734,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.02291758082773708,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.02291758082773708,
        "precision": 0.0199320597129076,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.07156958402280635,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.07156958402280635,
        "precision": 0.06831407210061444,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021973532370196938,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.0021973532370196938,
        "precision": 0.0015937041246917873,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.07577967102172321,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.07577967102172321,
        "precision": 0.07353627440965359,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001669404634075015,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.001669404634075015,
        "precision": 0.0011854075422190655,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.10455225915280496,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.10455225915280496,
        "precision": 0.0993208858944954,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00015908787393162393,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.00015908787393162393,
        "precision": 8.203299075311943e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0020824830923507464,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0020824830923507464,
        "precision": 0.00202188670411985,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007496120777370777,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.0007496120777370777,
        "precision": 0.0005398995535714285,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018825954861111111,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.0018825954861111111,
        "precision": 0.001559978359741784,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.11296670177902621,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.11296670177902621,
        "precision": 0.11037187620377503,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001577537187676454,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.001577537187676454,
        "precision": 0.0013139925913625862,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008958225500345066,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0008958225500345066,
        "precision": 0.0006185228180057069,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.07081873294230676,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.07081873294230676,
        "precision": 0.06685193362083912,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.1245736000468516,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.1245736000468516,
        "precision": 0.12040076791329739,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.05590218158577533,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.05590218158577533,
        "precision": 0.053351446873821644,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00022625801752839796,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.00022625801752839796,
        "precision": 0.00012418962249705927,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002451947351800816,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.002451947351800816,
        "precision": 0.002283931683628078,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.08587085828553756,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.08587085828553756,
        "precision": 0.08047045361545536,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.11216845080753347,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.11216845080753347,
        "precision": 0.10702733276984878,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.03785024677720579,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.03785024677720579,
        "precision": 0.036475039185953406,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.0865125791191132,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.0865125791191132,
        "precision": 0.0808437727838644,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.07747514435481487,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.07747514435481487,
        "precision": 0.06646030293491231,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.09403978837404214,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.09403978837404214,
        "precision": 0.08826894038865546,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.08971586681547619,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.08971586681547619,
        "precision": 0.08053475562810351,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.09152297819563873,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.09152297819563873,
        "precision": 0.08689954255756578,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005259687339414183,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.0005259687339414183,
        "precision": 0.000344683665727884,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2255859375,
        "f1": 0.19608522445436505,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.19608522445436505,
        "precision": 0.18396926153273807,
        "recall": 0.2255859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00028218681280088305,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.00028218681280088305,
        "precision": 0.0001551462161590046,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01627204236830391,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.01627204236830391,
        "precision": 0.014372908249755227,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000978576030927835,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.000978576030927835,
        "precision": 0.0009775703044375644,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0110953635123557,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.0110953635123557,
        "precision": 0.008485538178220703,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.2177734375,
        "f1": 0.19888849775409786,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.19888849775409786,
        "precision": 0.19297906412164226,
        "recall": 0.2177734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006998531708534406,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0006998531708534406,
        "precision": 0.0005130263202129127,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.019544815135423152,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.019544815135423152,
        "precision": 0.01652528871895648,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.08931119236761169,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.08931119236761169,
        "precision": 0.08480862775777434,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.048839803548376116,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.048839803548376116,
        "precision": 0.04631983227086736,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07824715817409247,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.07824715817409247,
        "precision": 0.07341562751144552,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010679740646258504,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0010679740646258504,
        "precision": 0.001023941388413242,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 8.004610655737705e-06,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 8.004610655737705e-06,
        "precision": 4.018775720164609e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.09016758962231407,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.09016758962231407,
        "precision": 0.08645222981770834,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.10231748210263834,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.10231748210263834,
        "precision": 0.09713823241118617,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.007452951334815661,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.007452951334815661,
        "precision": 0.0070049596624001086,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.08821372995309465,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.08821372995309465,
        "precision": 0.08293351399489568,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.013789425841638002,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.013789425841638002,
        "precision": 0.011897398094032138,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.1062184597032109,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.1062184597032109,
        "precision": 0.10007356916155133,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.313131313131313e-05,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 6.313131313131313e-05,
        "precision": 3.24944252909919e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.15135977968263986,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.15135977968263986,
        "precision": 0.1445938090805086,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008242201690355098,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0008242201690355098,
        "precision": 0.000504232523917968,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.05918110871911033,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.05918110871911033,
        "precision": 0.053009526227949216,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.921937751004016e-06,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 3.921937751004016e-06,
        "precision": 1.9649144869215293e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0003255208333333333,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0003255208333333333,
        "precision": 0.0001953125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.588572322719637e-05,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 8.588572322719637e-05,
        "precision": 4.3679006840996234e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.125,
        "f1": 0.1073158186515405,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.1073158186515405,
        "precision": 0.10098592735814489,
        "recall": 0.125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.488057324840764e-06,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 2.488057324840764e-06,
        "precision": 1.2456154336734693e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1046605603448276e-06,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 2.1046605603448276e-06,
        "precision": 1.0534654800431499e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.09660888182852681,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.09660888182852681,
        "precision": 0.09179135387449816,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.04551788363853848,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.04551788363853848,
        "precision": 0.039777935503561575,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.08453022076251965,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.08453022076251965,
        "precision": 0.07886905024783375,
        "recall": 0.107421875
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}