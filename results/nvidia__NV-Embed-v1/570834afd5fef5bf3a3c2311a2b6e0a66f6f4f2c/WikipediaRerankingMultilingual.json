{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.910597,
        "mrr": 0.910597,
        "nAUC_map_max": 0.489175,
        "nAUC_map_std": 0.403076,
        "nAUC_map_diff1": 0.817992,
        "nAUC_mrr_max": 0.489175,
        "nAUC_mrr_std": 0.403076,
        "nAUC_mrr_diff1": 0.817992,
        "main_score": 0.910597,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.766477,
        "mrr": 0.766477,
        "nAUC_map_max": 0.427923,
        "nAUC_map_std": 0.294606,
        "nAUC_map_diff1": 0.65533,
        "nAUC_mrr_max": 0.427923,
        "nAUC_mrr_std": 0.294606,
        "nAUC_mrr_diff1": 0.65533,
        "main_score": 0.766477,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.920038,
        "mrr": 0.920038,
        "nAUC_map_max": 0.519886,
        "nAUC_map_std": 0.364072,
        "nAUC_map_diff1": 0.863186,
        "nAUC_mrr_max": 0.519886,
        "nAUC_mrr_std": 0.364072,
        "nAUC_mrr_diff1": 0.863186,
        "main_score": 0.920038,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.928628,
        "mrr": 0.929072,
        "nAUC_map_max": 0.503613,
        "nAUC_map_std": 0.388854,
        "nAUC_map_diff1": 0.877639,
        "nAUC_mrr_max": 0.513821,
        "nAUC_mrr_std": 0.402142,
        "nAUC_mrr_diff1": 0.876314,
        "main_score": 0.928628,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.923275,
        "mrr": 0.923275,
        "nAUC_map_max": 0.466038,
        "nAUC_map_std": 0.286329,
        "nAUC_map_diff1": 0.820402,
        "nAUC_mrr_max": 0.466038,
        "nAUC_mrr_std": 0.286329,
        "nAUC_mrr_diff1": 0.820402,
        "main_score": 0.923275,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.943578,
        "mrr": 0.943578,
        "nAUC_map_max": 0.611954,
        "nAUC_map_std": 0.45742,
        "nAUC_map_diff1": 0.886132,
        "nAUC_mrr_max": 0.611954,
        "nAUC_mrr_std": 0.45742,
        "nAUC_mrr_diff1": 0.886132,
        "main_score": 0.943578,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.845101,
        "mrr": 0.845101,
        "nAUC_map_max": 0.441677,
        "nAUC_map_std": 0.356249,
        "nAUC_map_diff1": 0.768712,
        "nAUC_mrr_max": 0.441677,
        "nAUC_mrr_std": 0.356249,
        "nAUC_mrr_diff1": 0.768712,
        "main_score": 0.845101,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.916065,
        "mrr": 0.916065,
        "nAUC_map_max": 0.387447,
        "nAUC_map_std": 0.187465,
        "nAUC_map_diff1": 0.789486,
        "nAUC_mrr_max": 0.387447,
        "nAUC_mrr_std": 0.187465,
        "nAUC_mrr_diff1": 0.789486,
        "main_score": 0.916065,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.803316,
        "mrr": 0.804002,
        "nAUC_map_max": 0.455017,
        "nAUC_map_std": 0.319822,
        "nAUC_map_diff1": 0.697143,
        "nAUC_mrr_max": 0.45933,
        "nAUC_mrr_std": 0.327321,
        "nAUC_mrr_diff1": 0.695234,
        "main_score": 0.803316,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.929408,
        "mrr": 0.929408,
        "nAUC_map_max": 0.541966,
        "nAUC_map_std": 0.40872,
        "nAUC_map_diff1": 0.849387,
        "nAUC_mrr_max": 0.541966,
        "nAUC_mrr_std": 0.40872,
        "nAUC_mrr_diff1": 0.849387,
        "main_score": 0.929408,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.926188,
        "mrr": 0.926521,
        "nAUC_map_max": 0.354251,
        "nAUC_map_std": 0.301766,
        "nAUC_map_diff1": 0.763168,
        "nAUC_mrr_max": 0.356452,
        "nAUC_mrr_std": 0.310964,
        "nAUC_mrr_diff1": 0.761622,
        "main_score": 0.926188,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.909186,
        "mrr": 0.909186,
        "nAUC_map_max": 0.452079,
        "nAUC_map_std": 0.344275,
        "nAUC_map_diff1": 0.822517,
        "nAUC_mrr_max": 0.452079,
        "nAUC_mrr_std": 0.344275,
        "nAUC_mrr_diff1": 0.822517,
        "main_score": 0.909186,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.916881,
        "mrr": 0.917214,
        "nAUC_map_max": 0.468555,
        "nAUC_map_std": 0.353079,
        "nAUC_map_diff1": 0.844149,
        "nAUC_mrr_max": 0.466105,
        "nAUC_mrr_std": 0.35384,
        "nAUC_mrr_diff1": 0.843049,
        "main_score": 0.916881,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.910251,
        "mrr": 0.910584,
        "nAUC_map_max": 0.415356,
        "nAUC_map_std": 0.314421,
        "nAUC_map_diff1": 0.844362,
        "nAUC_mrr_max": 0.423436,
        "nAUC_mrr_std": 0.322164,
        "nAUC_mrr_diff1": 0.843339,
        "main_score": 0.910251,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.907841,
        "mrr": 0.907841,
        "nAUC_map_max": 0.46534,
        "nAUC_map_std": 0.305826,
        "nAUC_map_diff1": 0.806506,
        "nAUC_mrr_max": 0.46534,
        "nAUC_mrr_std": 0.305826,
        "nAUC_mrr_diff1": 0.806506,
        "main_score": 0.907841,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.932961,
        "mrr": 0.932961,
        "nAUC_map_max": 0.367211,
        "nAUC_map_std": 0.219359,
        "nAUC_map_diff1": 0.832128,
        "nAUC_mrr_max": 0.367211,
        "nAUC_mrr_std": 0.219359,
        "nAUC_mrr_diff1": 0.832128,
        "main_score": 0.932961,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 3784.4068009853363,
  "kg_co2_emissions": 0.33402959994743237
}