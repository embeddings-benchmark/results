{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.677546,
        "f1": 0.676511,
        "f1_weighted": 0.676333,
        "scores_per_experiment": [
          {
            "accuracy": 0.67624,
            "f1": 0.67767,
            "f1_weighted": 0.679186
          },
          {
            "accuracy": 0.681462,
            "f1": 0.684756,
            "f1_weighted": 0.68285
          },
          {
            "accuracy": 0.710183,
            "f1": 0.706098,
            "f1_weighted": 0.708057
          },
          {
            "accuracy": 0.678851,
            "f1": 0.679512,
            "f1_weighted": 0.678905
          },
          {
            "accuracy": 0.697128,
            "f1": 0.694778,
            "f1_weighted": 0.690911
          },
          {
            "accuracy": 0.660574,
            "f1": 0.663051,
            "f1_weighted": 0.659973
          },
          {
            "accuracy": 0.73107,
            "f1": 0.730199,
            "f1_weighted": 0.731334
          },
          {
            "accuracy": 0.639687,
            "f1": 0.643186,
            "f1_weighted": 0.639992
          },
          {
            "accuracy": 0.657963,
            "f1": 0.650278,
            "f1_weighted": 0.653594
          },
          {
            "accuracy": 0.642298,
            "f1": 0.635578,
            "f1_weighted": 0.63853
          }
        ],
        "main_score": 0.677546,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.660417,
        "f1": 0.666296,
        "f1_weighted": 0.655718,
        "scores_per_experiment": [
          {
            "accuracy": 0.625,
            "f1": 0.632031,
            "f1_weighted": 0.626282
          },
          {
            "accuracy": 0.65625,
            "f1": 0.669012,
            "f1_weighted": 0.650502
          },
          {
            "accuracy": 0.65625,
            "f1": 0.669708,
            "f1_weighted": 0.660395
          },
          {
            "accuracy": 0.666667,
            "f1": 0.677042,
            "f1_weighted": 0.663171
          },
          {
            "accuracy": 0.729167,
            "f1": 0.735953,
            "f1_weighted": 0.718947
          },
          {
            "accuracy": 0.614583,
            "f1": 0.631556,
            "f1_weighted": 0.614563
          },
          {
            "accuracy": 0.6875,
            "f1": 0.695038,
            "f1_weighted": 0.682868
          },
          {
            "accuracy": 0.697917,
            "f1": 0.706569,
            "f1_weighted": 0.695563
          },
          {
            "accuracy": 0.71875,
            "f1": 0.71506,
            "f1_weighted": 0.713722
          },
          {
            "accuracy": 0.552083,
            "f1": 0.53099,
            "f1_weighted": 0.531167
          }
        ],
        "main_score": 0.660417,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 12.585789203643799,
  "kg_co2_emissions": 0.00034749578425846423
}