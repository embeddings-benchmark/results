{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.064209,
        "f1": 0.046076,
        "f1_weighted": 0.067671,
        "scores_per_experiment": [
          {
            "accuracy": 0.060059,
            "f1": 0.043037,
            "f1_weighted": 0.06455
          },
          {
            "accuracy": 0.068359,
            "f1": 0.049181,
            "f1_weighted": 0.07246
          },
          {
            "accuracy": 0.057129,
            "f1": 0.040541,
            "f1_weighted": 0.058985
          },
          {
            "accuracy": 0.067871,
            "f1": 0.047775,
            "f1_weighted": 0.070624
          },
          {
            "accuracy": 0.058594,
            "f1": 0.041145,
            "f1_weighted": 0.063081
          },
          {
            "accuracy": 0.066895,
            "f1": 0.044253,
            "f1_weighted": 0.0702
          },
          {
            "accuracy": 0.072754,
            "f1": 0.054754,
            "f1_weighted": 0.077342
          },
          {
            "accuracy": 0.061523,
            "f1": 0.050649,
            "f1_weighted": 0.064289
          },
          {
            "accuracy": 0.066406,
            "f1": 0.048717,
            "f1_weighted": 0.070073
          },
          {
            "accuracy": 0.0625,
            "f1": 0.040707,
            "f1_weighted": 0.065107
          }
        ],
        "main_score": 0.064209,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.058496,
        "f1": 0.046702,
        "f1_weighted": 0.057939,
        "scores_per_experiment": [
          {
            "accuracy": 0.067871,
            "f1": 0.053713,
            "f1_weighted": 0.063748
          },
          {
            "accuracy": 0.05957,
            "f1": 0.05002,
            "f1_weighted": 0.059374
          },
          {
            "accuracy": 0.051758,
            "f1": 0.044986,
            "f1_weighted": 0.048217
          },
          {
            "accuracy": 0.055176,
            "f1": 0.042633,
            "f1_weighted": 0.056818
          },
          {
            "accuracy": 0.059082,
            "f1": 0.046263,
            "f1_weighted": 0.05821
          },
          {
            "accuracy": 0.054688,
            "f1": 0.045833,
            "f1_weighted": 0.056418
          },
          {
            "accuracy": 0.052734,
            "f1": 0.042481,
            "f1_weighted": 0.054016
          },
          {
            "accuracy": 0.066895,
            "f1": 0.050677,
            "f1_weighted": 0.066215
          },
          {
            "accuracy": 0.056641,
            "f1": 0.043245,
            "f1_weighted": 0.05454
          },
          {
            "accuracy": 0.060547,
            "f1": 0.047172,
            "f1_weighted": 0.061835
          }
        ],
        "main_score": 0.058496,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 1421.7970790863037,
  "kg_co2_emissions": 0.06590716996871963
}