{
  "dataset_revision": "d09e1c9f0f04f7f52f5cbfb74fa6c793c4eb84da",
  "task_name": "PAC",
  "mteb_version": "2.3.3",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.492615,
            "f1": 0.480326,
            "f1_weighted": 0.508399,
            "precision": 0.500297,
            "precision_weighted": 0.562003,
            "recall": 0.500338,
            "recall_weighted": 0.492615,
            "ap": 0.675792,
            "ap_weighted": 0.675792
          },
          {
            "accuracy": 0.455256,
            "f1": 0.453423,
            "f1_weighted": 0.464544,
            "precision": 0.496412,
            "precision_weighted": 0.557818,
            "recall": 0.496134,
            "recall_weighted": 0.455256,
            "ap": 0.673961,
            "ap_weighted": 0.673961
          },
          {
            "accuracy": 0.527078,
            "f1": 0.499539,
            "f1_weighted": 0.540779,
            "precision": 0.506465,
            "precision_weighted": 0.567899,
            "recall": 0.507272,
            "recall_weighted": 0.527078,
            "ap": 0.678859,
            "ap_weighted": 0.678859
          },
          {
            "accuracy": 0.50391,
            "f1": 0.482521,
            "f1_weighted": 0.519479,
            "precision": 0.494176,
            "precision_weighted": 0.555991,
            "recall": 0.493377,
            "recall_weighted": 0.50391,
            "ap": 0.672765,
            "ap_weighted": 0.672765
          },
          {
            "accuracy": 0.52563,
            "f1": 0.5026,
            "f1_weighted": 0.540198,
            "precision": 0.511817,
            "precision_weighted": 0.573191,
            "recall": 0.513396,
            "recall_weighted": 0.52563,
            "ap": 0.681611,
            "ap_weighted": 0.681611
          },
          {
            "accuracy": 0.524182,
            "f1": 0.499419,
            "f1_weighted": 0.53853,
            "precision": 0.50782,
            "precision_weighted": 0.569265,
            "recall": 0.508843,
            "recall_weighted": 0.524182,
            "ap": 0.679561,
            "ap_weighted": 0.679561
          },
          {
            "accuracy": 0.514625,
            "f1": 0.49159,
            "f1_weighted": 0.529606,
            "precision": 0.501561,
            "precision_weighted": 0.563222,
            "recall": 0.501771,
            "recall_weighted": 0.514625,
            "ap": 0.676422,
            "ap_weighted": 0.676422
          },
          {
            "accuracy": 0.560382,
            "f1": 0.511231,
            "f1_weighted": 0.565679,
            "precision": 0.511615,
            "precision_weighted": 0.572162,
            "recall": 0.512189,
            "recall_weighted": 0.560382,
            "ap": 0.681053,
            "ap_weighted": 0.681053
          },
          {
            "accuracy": 0.514335,
            "f1": 0.484095,
            "f1_weighted": 0.527973,
            "precision": 0.490825,
            "precision_weighted": 0.552956,
            "recall": 0.489719,
            "recall_weighted": 0.514335,
            "ap": 0.671191,
            "ap_weighted": 0.671191
          },
          {
            "accuracy": 0.516073,
            "f1": 0.498633,
            "f1_weighted": 0.531481,
            "precision": 0.512264,
            "precision_weighted": 0.573872,
            "recall": 0.513984,
            "recall_weighted": 0.516073,
            "ap": 0.681882,
            "ap_weighted": 0.681882
          }
        ],
        "accuracy": 0.513409,
        "f1": 0.490338,
        "f1_weighted": 0.526667,
        "precision": 0.503325,
        "precision_weighted": 0.564838,
        "recall": 0.503702,
        "recall_weighted": 0.513409,
        "ap": 0.67731,
        "ap_weighted": 0.67731,
        "main_score": 0.513409,
        "hf_subset": "default",
        "languages": [
          "pol-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 43.00941181182861,
  "kg_co2_emissions": null
}