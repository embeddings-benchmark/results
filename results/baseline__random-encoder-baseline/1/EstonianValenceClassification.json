{
  "dataset_revision": "9157397f05a127b3ac93b93dd88abf1bdf710c22",
  "task_name": "EstonianValenceClassification",
  "mteb_version": "2.3.3",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.226161,
            "f1": 0.215683,
            "f1_weighted": 0.239852,
            "precision": 0.23873,
            "precision_weighted": 0.313229,
            "recall": 0.234704,
            "recall_weighted": 0.226161,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.243276,
            "f1": 0.217771,
            "f1_weighted": 0.260047,
            "precision": 0.228392,
            "precision_weighted": 0.299484,
            "recall": 0.226281,
            "recall_weighted": 0.243276,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.259169,
            "f1": 0.230015,
            "f1_weighted": 0.277363,
            "precision": 0.248477,
            "precision_weighted": 0.331434,
            "recall": 0.245183,
            "recall_weighted": 0.259169,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.234719,
            "f1": 0.227558,
            "f1_weighted": 0.248556,
            "precision": 0.255754,
            "precision_weighted": 0.333579,
            "recall": 0.254479,
            "recall_weighted": 0.234719,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.226161,
            "f1": 0.21932,
            "f1_weighted": 0.235293,
            "precision": 0.243188,
            "precision_weighted": 0.313555,
            "recall": 0.244883,
            "recall_weighted": 0.226161,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.239609,
            "f1": 0.233777,
            "f1_weighted": 0.251022,
            "precision": 0.255775,
            "precision_weighted": 0.32461,
            "recall": 0.260146,
            "recall_weighted": 0.239609,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.270171,
            "f1": 0.241481,
            "f1_weighted": 0.290853,
            "precision": 0.256151,
            "precision_weighted": 0.341124,
            "recall": 0.250305,
            "recall_weighted": 0.270171,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.251834,
            "f1": 0.228745,
            "f1_weighted": 0.267384,
            "precision": 0.237684,
            "precision_weighted": 0.306691,
            "recall": 0.238871,
            "recall_weighted": 0.251834,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.213936,
            "f1": 0.197639,
            "f1_weighted": 0.231033,
            "precision": 0.218165,
            "precision_weighted": 0.294763,
            "recall": 0.209717,
            "recall_weighted": 0.213936,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.268949,
            "f1": 0.25604,
            "f1_weighted": 0.285414,
            "precision": 0.284168,
            "precision_weighted": 0.373858,
            "recall": 0.282369,
            "recall_weighted": 0.268949,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.243399,
        "f1": 0.226803,
        "f1_weighted": 0.258682,
        "precision": 0.246648,
        "precision_weighted": 0.323233,
        "recall": 0.244694,
        "recall_weighted": 0.243399,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.243399,
        "hf_subset": "default",
        "languages": [
          "est-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.010214567184448,
  "kg_co2_emissions": null
}