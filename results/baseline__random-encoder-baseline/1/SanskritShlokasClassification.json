{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "2.3.3",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.34375,
            "f1": 0.343725,
            "f1_weighted": 0.346587,
            "precision": 0.362409,
            "precision_weighted": 0.362013,
            "recall": 0.338796,
            "recall_weighted": 0.34375,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.333333,
            "f1": 0.317054,
            "f1_weighted": 0.327308,
            "precision": 0.320152,
            "precision_weighted": 0.329063,
            "recall": 0.322713,
            "recall_weighted": 0.333333,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.395833,
            "f1": 0.383338,
            "f1_weighted": 0.382091,
            "precision": 0.388819,
            "precision_weighted": 0.394896,
            "recall": 0.405857,
            "recall_weighted": 0.395833,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.354167,
            "f1": 0.354723,
            "f1_weighted": 0.352742,
            "precision": 0.354095,
            "precision_weighted": 0.357118,
            "recall": 0.360774,
            "recall_weighted": 0.354167,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.385417,
            "f1": 0.38434,
            "f1_weighted": 0.386211,
            "precision": 0.387173,
            "precision_weighted": 0.395504,
            "recall": 0.389363,
            "recall_weighted": 0.385417,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.302083,
            "f1": 0.303367,
            "f1_weighted": 0.305172,
            "precision": 0.30836,
            "precision_weighted": 0.311415,
            "recall": 0.301661,
            "recall_weighted": 0.302083,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.40625,
            "f1": 0.401963,
            "f1_weighted": 0.399063,
            "precision": 0.415711,
            "precision_weighted": 0.415733,
            "recall": 0.413656,
            "recall_weighted": 0.40625,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.291667,
            "f1": 0.290909,
            "f1_weighted": 0.287311,
            "precision": 0.304082,
            "precision_weighted": 0.311694,
            "recall": 0.303598,
            "recall_weighted": 0.291667,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.322917,
            "f1": 0.325725,
            "f1_weighted": 0.320014,
            "precision": 0.331252,
            "precision_weighted": 0.332304,
            "recall": 0.334312,
            "recall_weighted": 0.322917,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.354167,
            "f1": 0.344385,
            "f1_weighted": 0.336679,
            "precision": 0.366204,
            "precision_weighted": 0.374479,
            "recall": 0.374205,
            "recall_weighted": 0.354167,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.348958,
        "f1": 0.344953,
        "f1_weighted": 0.344318,
        "precision": 0.353826,
        "precision_weighted": 0.358422,
        "recall": 0.354493,
        "recall_weighted": 0.348958,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.348958,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 1.642836332321167,
  "kg_co2_emissions": null
}