{
  "dataset_revision": "d096f402fdc76886458c0cfb5dedc829bea2b935",
  "task_name": "FilipinoShopeeReviewsClassification",
  "mteb_version": "2.3.3",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.194824,
            "f1": 0.191836,
            "f1_weighted": 0.19186,
            "precision": 0.194409,
            "precision_weighted": 0.194411,
            "recall": 0.19478,
            "recall_weighted": 0.194824,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.207031,
            "f1": 0.203811,
            "f1_weighted": 0.203808,
            "precision": 0.207113,
            "precision_weighted": 0.207112,
            "recall": 0.207031,
            "recall_weighted": 0.207031,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.207031,
            "f1": 0.205537,
            "f1_weighted": 0.20552,
            "precision": 0.20746,
            "precision_weighted": 0.207455,
            "recall": 0.207059,
            "recall_weighted": 0.207031,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.193848,
            "f1": 0.192431,
            "f1_weighted": 0.192434,
            "precision": 0.194389,
            "precision_weighted": 0.194385,
            "recall": 0.193839,
            "recall_weighted": 0.193848,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.200684,
            "f1": 0.199669,
            "f1_weighted": 0.199673,
            "precision": 0.20065,
            "precision_weighted": 0.20064,
            "recall": 0.200668,
            "recall_weighted": 0.200684,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.195801,
            "f1": 0.194564,
            "f1_weighted": 0.194573,
            "precision": 0.196387,
            "precision_weighted": 0.1964,
            "recall": 0.195792,
            "recall_weighted": 0.195801,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.20166,
            "f1": 0.199207,
            "f1_weighted": 0.199176,
            "precision": 0.201132,
            "precision_weighted": 0.201116,
            "recall": 0.20171,
            "recall_weighted": 0.20166,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.208008,
            "f1": 0.205748,
            "f1_weighted": 0.205741,
            "precision": 0.206192,
            "precision_weighted": 0.206185,
            "recall": 0.208011,
            "recall_weighted": 0.208008,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.178711,
            "f1": 0.177692,
            "f1_weighted": 0.177666,
            "precision": 0.177386,
            "precision_weighted": 0.177365,
            "recall": 0.178743,
            "recall_weighted": 0.178711,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.197754,
            "f1": 0.196944,
            "f1_weighted": 0.196946,
            "precision": 0.198757,
            "precision_weighted": 0.19875,
            "recall": 0.197746,
            "recall_weighted": 0.197754,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.198535,
        "f1": 0.196744,
        "f1_weighted": 0.19674,
        "precision": 0.198388,
        "precision_weighted": 0.198382,
        "recall": 0.198538,
        "recall_weighted": 0.198535,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.198535,
        "hf_subset": "default",
        "languages": [
          "fil-Latn"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.209473,
            "f1": 0.20591,
            "f1_weighted": 0.205933,
            "precision": 0.210073,
            "precision_weighted": 0.210068,
            "recall": 0.209423,
            "recall_weighted": 0.209473,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.20459,
            "f1": 0.202619,
            "f1_weighted": 0.202597,
            "precision": 0.205841,
            "precision_weighted": 0.205826,
            "recall": 0.204614,
            "recall_weighted": 0.20459,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.185547,
            "f1": 0.18443,
            "f1_weighted": 0.184417,
            "precision": 0.18705,
            "precision_weighted": 0.187049,
            "recall": 0.185569,
            "recall_weighted": 0.185547,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.197754,
            "f1": 0.19697,
            "f1_weighted": 0.196973,
            "precision": 0.199539,
            "precision_weighted": 0.19954,
            "recall": 0.197749,
            "recall_weighted": 0.197754,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.196777,
            "f1": 0.194855,
            "f1_weighted": 0.194873,
            "precision": 0.19508,
            "precision_weighted": 0.195084,
            "recall": 0.196748,
            "recall_weighted": 0.196777,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.197266,
            "f1": 0.196351,
            "f1_weighted": 0.19637,
            "precision": 0.198098,
            "precision_weighted": 0.198113,
            "recall": 0.197243,
            "recall_weighted": 0.197266,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.218262,
            "f1": 0.215278,
            "f1_weighted": 0.215264,
            "precision": 0.216343,
            "precision_weighted": 0.216342,
            "recall": 0.218293,
            "recall_weighted": 0.218262,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.205566,
            "f1": 0.205478,
            "f1_weighted": 0.20548,
            "precision": 0.207553,
            "precision_weighted": 0.207555,
            "recall": 0.205563,
            "recall_weighted": 0.205566,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.205566,
            "f1": 0.205584,
            "f1_weighted": 0.20559,
            "precision": 0.206196,
            "precision_weighted": 0.20621,
            "recall": 0.205567,
            "recall_weighted": 0.205566,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.222168,
            "f1": 0.220833,
            "f1_weighted": 0.220838,
            "precision": 0.222398,
            "precision_weighted": 0.222393,
            "recall": 0.222156,
            "recall_weighted": 0.222168,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.204297,
        "f1": 0.202831,
        "f1_weighted": 0.202834,
        "precision": 0.204817,
        "precision_weighted": 0.204818,
        "recall": 0.204293,
        "recall_weighted": 0.204297,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.204297,
        "hf_subset": "default",
        "languages": [
          "fil-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 171.68152403831482,
  "kg_co2_emissions": null
}