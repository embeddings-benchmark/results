{
  "dataset_revision": "b07c6ce548f6a7ac8d546e1bbe197a0086409190",
  "task_name": "SweRecClassification",
  "mteb_version": "2.3.3",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.315918,
            "f1": 0.299093,
            "f1_weighted": 0.335155,
            "precision": 0.322774,
            "precision_weighted": 0.385632,
            "recall": 0.328155,
            "recall_weighted": 0.315918,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.334961,
            "f1": 0.313278,
            "f1_weighted": 0.352735,
            "precision": 0.329655,
            "precision_weighted": 0.393691,
            "recall": 0.334059,
            "recall_weighted": 0.334961,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.34082,
            "f1": 0.310546,
            "f1_weighted": 0.353966,
            "precision": 0.32623,
            "precision_weighted": 0.392337,
            "recall": 0.324838,
            "recall_weighted": 0.34082,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.310547,
            "f1": 0.301508,
            "f1_weighted": 0.335871,
            "precision": 0.345796,
            "precision_weighted": 0.415919,
            "recall": 0.341654,
            "recall_weighted": 0.310547,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.348633,
            "f1": 0.326522,
            "f1_weighted": 0.36458,
            "precision": 0.347195,
            "precision_weighted": 0.414441,
            "recall": 0.35203,
            "recall_weighted": 0.348633,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.324219,
            "f1": 0.301397,
            "f1_weighted": 0.332567,
            "precision": 0.330843,
            "precision_weighted": 0.395587,
            "recall": 0.335567,
            "recall_weighted": 0.324219,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.312988,
            "f1": 0.303028,
            "f1_weighted": 0.334537,
            "precision": 0.33713,
            "precision_weighted": 0.403262,
            "recall": 0.342798,
            "recall_weighted": 0.312988,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.327148,
            "f1": 0.318098,
            "f1_weighted": 0.348084,
            "precision": 0.353865,
            "precision_weighted": 0.421085,
            "recall": 0.363835,
            "recall_weighted": 0.327148,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.322266,
            "f1": 0.296398,
            "f1_weighted": 0.336306,
            "precision": 0.311278,
            "precision_weighted": 0.373403,
            "recall": 0.312204,
            "recall_weighted": 0.322266,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.344238,
            "f1": 0.31776,
            "f1_weighted": 0.362569,
            "precision": 0.332284,
            "precision_weighted": 0.398733,
            "recall": 0.332998,
            "recall_weighted": 0.344238,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.328174,
        "f1": 0.308763,
        "f1_weighted": 0.345637,
        "precision": 0.333705,
        "precision_weighted": 0.399409,
        "recall": 0.336814,
        "recall_weighted": 0.328174,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.328174,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.54872155189514,
  "kg_co2_emissions": null
}