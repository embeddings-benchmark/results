{
  "dataset_revision": "d94f96ca5a6798e20f5a77e566f7a288dc6138d7",
  "evaluation_time": 8.913821697235107,
  "kg_co2_emissions": 0.00048399160663341415,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_accuracy": 0.8482328482328483,
        "cosine_accuracy_threshold": 0.4930848479270935,
        "cosine_ap": 0.8602689620627615,
        "cosine_f1": 0.9178852643419573,
        "cosine_f1_threshold": 0.4930848479270935,
        "cosine_precision": 0.85,
        "cosine_recall": 0.9975550122249389,
        "dot_accuracy": 0.8482328482328483,
        "dot_accuracy_threshold": 145.73086547851562,
        "dot_ap": 0.8626302946977221,
        "dot_f1": 0.9178852643419573,
        "dot_f1_threshold": 145.73086547851562,
        "dot_precision": 0.85,
        "dot_recall": 0.9975550122249389,
        "euclidean_accuracy": 0.8482328482328483,
        "euclidean_accuracy_threshold": 17.63856315612793,
        "euclidean_ap": 0.8575640666561387,
        "euclidean_f1": 0.9178852643419573,
        "euclidean_f1_threshold": 17.63856315612793,
        "euclidean_precision": 0.85,
        "euclidean_recall": 0.9975550122249389,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ],
        "main_score": 0.8626302946977221,
        "manhattan_accuracy": 0.8482328482328483,
        "manhattan_accuracy_threshold": 454.5926513671875,
        "manhattan_ap": 0.8573582343434804,
        "manhattan_f1": 0.9178852643419573,
        "manhattan_f1_threshold": 454.5926513671875,
        "manhattan_precision": 0.85,
        "manhattan_recall": 0.9975550122249389,
        "max_accuracy": 0.8482328482328483,
        "max_ap": 0.8626302946977221,
        "max_f1": 0.9178852643419573,
        "max_precision": 0.85,
        "max_recall": 0.9975550122249389,
        "similarity_accuracy": 0.8482328482328483,
        "similarity_accuracy_threshold": 0.4930848479270935,
        "similarity_ap": 0.8602689620627615,
        "similarity_f1": 0.9178852643419573,
        "similarity_f1_threshold": 0.4930848479270935,
        "similarity_precision": 0.85,
        "similarity_recall": 0.9975550122249389
      },
      {
        "cosine_accuracy": 0.8485477178423236,
        "cosine_accuracy_threshold": 0.5479285717010498,
        "cosine_ap": 0.9007820995243088,
        "cosine_f1": 0.9180695847362514,
        "cosine_f1_threshold": 0.5251922607421875,
        "cosine_precision": 0.8503118503118503,
        "cosine_recall": 0.9975609756097561,
        "dot_accuracy": 0.8526970954356846,
        "dot_accuracy_threshold": 171.8280792236328,
        "dot_ap": 0.892654729509188,
        "dot_f1": 0.920314253647587,
        "dot_f1_threshold": 160.98397827148438,
        "dot_precision": 0.8523908523908524,
        "dot_recall": 1.0,
        "euclidean_accuracy": 0.8485477178423236,
        "euclidean_accuracy_threshold": 18.181285858154297,
        "euclidean_ap": 0.90094311625264,
        "euclidean_f1": 0.9180695847362514,
        "euclidean_f1_threshold": 18.181285858154297,
        "euclidean_precision": 0.8503118503118503,
        "euclidean_recall": 0.9975609756097561,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.9020416830661132,
        "manhattan_accuracy": 0.8485477178423236,
        "manhattan_accuracy_threshold": 464.3507995605469,
        "manhattan_ap": 0.9020416830661132,
        "manhattan_f1": 0.9180695847362514,
        "manhattan_f1_threshold": 464.3507995605469,
        "manhattan_precision": 0.8503118503118503,
        "manhattan_recall": 0.9975609756097561,
        "max_accuracy": 0.8526970954356846,
        "max_ap": 0.9020416830661132,
        "max_f1": 0.920314253647587,
        "max_precision": 0.8523908523908524,
        "max_recall": 1.0,
        "similarity_accuracy": 0.8485477178423236,
        "similarity_accuracy_threshold": 0.5479285717010498,
        "similarity_ap": 0.9007820995243088,
        "similarity_f1": 0.9180695847362514,
        "similarity_f1_threshold": 0.5251922607421875,
        "similarity_precision": 0.8503118503118503,
        "similarity_recall": 0.9975609756097561
      },
      {
        "cosine_accuracy": 0.8506224066390041,
        "cosine_accuracy_threshold": 0.5220932960510254,
        "cosine_ap": 0.8673608262417611,
        "cosine_f1": 0.9189189189189189,
        "cosine_f1_threshold": 0.5220932960510254,
        "cosine_precision": 0.8517745302713987,
        "cosine_recall": 0.9975550122249389,
        "dot_accuracy": 0.8506224066390041,
        "dot_accuracy_threshold": 154.95477294921875,
        "dot_ap": 0.8599443642353927,
        "dot_f1": 0.9191011235955057,
        "dot_f1_threshold": 152.1903076171875,
        "dot_precision": 0.8503118503118503,
        "dot_recall": 1.0,
        "euclidean_accuracy": 0.8506224066390041,
        "euclidean_accuracy_threshold": 16.73706817626953,
        "euclidean_ap": 0.86768270133104,
        "euclidean_f1": 0.9189189189189189,
        "euclidean_f1_threshold": 16.73706817626953,
        "euclidean_precision": 0.8517745302713987,
        "euclidean_recall": 0.9975550122249389,
        "hf_subset": "fr",
        "languages": [
          "fra-Latn"
        ],
        "main_score": 0.86768270133104,
        "manhattan_accuracy": 0.8506224066390041,
        "manhattan_accuracy_threshold": 427.4642333984375,
        "manhattan_ap": 0.8666441066703533,
        "manhattan_f1": 0.9189189189189189,
        "manhattan_f1_threshold": 427.4642333984375,
        "manhattan_precision": 0.8517745302713987,
        "manhattan_recall": 0.9975550122249389,
        "max_accuracy": 0.8506224066390041,
        "max_ap": 0.86768270133104,
        "max_f1": 0.9191011235955057,
        "max_precision": 0.8517745302713987,
        "max_recall": 1.0,
        "similarity_accuracy": 0.8506224066390041,
        "similarity_accuracy_threshold": 0.5220932960510254,
        "similarity_ap": 0.8673608262417611,
        "similarity_f1": 0.9189189189189189,
        "similarity_f1_threshold": 0.5220932960510254,
        "similarity_precision": 0.8517745302713987,
        "similarity_recall": 0.9975550122249389
      },
      {
        "cosine_accuracy": 0.8472803347280334,
        "cosine_accuracy_threshold": 0.5270267724990845,
        "cosine_ap": 0.8676484557393447,
        "cosine_f1": 0.9173272933182333,
        "cosine_f1_threshold": 0.5270267724990845,
        "cosine_precision": 0.8490566037735849,
        "cosine_recall": 0.9975369458128078,
        "dot_accuracy": 0.8472803347280334,
        "dot_accuracy_threshold": 170.13580322265625,
        "dot_ap": 0.8603394822193298,
        "dot_f1": 0.9173272933182333,
        "dot_f1_threshold": 170.13580322265625,
        "dot_precision": 0.8490566037735849,
        "dot_recall": 0.9975369458128078,
        "euclidean_accuracy": 0.8472803347280334,
        "euclidean_accuracy_threshold": 17.506263732910156,
        "euclidean_ap": 0.8672779612091359,
        "euclidean_f1": 0.9173272933182333,
        "euclidean_f1_threshold": 17.506263732910156,
        "euclidean_precision": 0.8490566037735849,
        "euclidean_recall": 0.9975369458128078,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ],
        "main_score": 0.8676484557393447,
        "manhattan_accuracy": 0.8472803347280334,
        "manhattan_accuracy_threshold": 447.9229736328125,
        "manhattan_ap": 0.8668176327666388,
        "manhattan_f1": 0.9173272933182333,
        "manhattan_f1_threshold": 447.9229736328125,
        "manhattan_precision": 0.8490566037735849,
        "manhattan_recall": 0.9975369458128078,
        "max_accuracy": 0.8472803347280334,
        "max_ap": 0.8676484557393447,
        "max_f1": 0.9173272933182333,
        "max_precision": 0.8490566037735849,
        "max_recall": 0.9975369458128078,
        "similarity_accuracy": 0.8472803347280334,
        "similarity_accuracy_threshold": 0.5270267724990845,
        "similarity_ap": 0.8676484557393447,
        "similarity_f1": 0.9173272933182333,
        "similarity_f1_threshold": 0.5270267724990845,
        "similarity_precision": 0.8490566037735849,
        "similarity_recall": 0.9975369458128078
      }
    ]
  },
  "task_name": "RTE3"
}