{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 14.133396625518799,
  "kg_co2_emissions": 0.0004302508900841779,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5365384615384615,
        "f1": 0.41647081511606066,
        "f1_weighted": 0.5794247871758086,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5365384615384615,
        "scores_per_experiment": [
          {
            "accuracy": 0.5288461538461539,
            "f1": 0.4128023968161695,
            "f1_weighted": 0.5645055878700738
          },
          {
            "accuracy": 0.5769230769230769,
            "f1": 0.4640702434820082,
            "f1_weighted": 0.6225428041038902
          },
          {
            "accuracy": 0.6346153846153846,
            "f1": 0.4991596638655462,
            "f1_weighted": 0.7054621848739496
          },
          {
            "accuracy": 0.5673076923076923,
            "f1": 0.45246931602528834,
            "f1_weighted": 0.6348061741970425
          },
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.43068181818181817,
            "f1_weighted": 0.6486451048951049
          },
          {
            "accuracy": 0.47115384615384615,
            "f1": 0.37312653806461854,
            "f1_weighted": 0.49301947655424677
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.39276878092667566,
            "f1_weighted": 0.5158357555624762
          },
          {
            "accuracy": 0.5769230769230769,
            "f1": 0.38454869551126236,
            "f1_weighted": 0.6142359423108086
          },
          {
            "accuracy": 0.46153846153846156,
            "f1": 0.3740530303030303,
            "f1_weighted": 0.4981060606060606
          },
          {
            "accuracy": 0.47115384615384615,
            "f1": 0.38102766798418974,
            "f1_weighted": 0.49708878078443297
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5266666666666667,
        "f1": 0.40117222651654777,
        "f1_weighted": 0.5753159186436453,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5266666666666667,
        "scores_per_experiment": [
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.42691688343862255,
            "f1_weighted": 0.5990621294969121
          },
          {
            "accuracy": 0.5238095238095238,
            "f1": 0.4206086059534335,
            "f1_weighted": 0.5909126633264565
          },
          {
            "accuracy": 0.580952380952381,
            "f1": 0.42843137254901964,
            "f1_weighted": 0.6447058823529411
          },
          {
            "accuracy": 0.5047619047619047,
            "f1": 0.3885780885780886,
            "f1_weighted": 0.5769608169608169
          },
          {
            "accuracy": 0.5714285714285714,
            "f1": 0.3901458019105078,
            "f1_weighted": 0.6100600924130336
          },
          {
            "accuracy": 0.4380952380952381,
            "f1": 0.3458452030697863,
            "f1_weighted": 0.4554374697465343
          },
          {
            "accuracy": 0.5142857142857142,
            "f1": 0.415625,
            "f1_weighted": 0.5589935064935065
          },
          {
            "accuracy": 0.6,
            "f1": 0.4201319472211116,
            "f1_weighted": 0.6332666933226709
          },
          {
            "accuracy": 0.44761904761904764,
            "f1": 0.35502824238553354,
            "f1_weighted": 0.4944991265437555
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.4204111200593743,
            "f1_weighted": 0.5892608057798261
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}