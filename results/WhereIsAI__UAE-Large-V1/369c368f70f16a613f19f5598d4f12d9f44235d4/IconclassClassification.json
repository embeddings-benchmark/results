{
  "dataset_revision": "1cd02f1579dab39fedc95de8cc15fd620557a9f2",
  "task_name": "IconclassClassification",
  "mteb_version": "2.1.8",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.470297,
            "f1": 0.462863,
            "f1_weighted": 0.46472,
            "precision": 0.4624,
            "precision_weighted": 0.464131,
            "recall": 0.468379,
            "recall_weighted": 0.470297,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.524752,
            "f1": 0.520326,
            "f1_weighted": 0.522551,
            "precision": 0.52899,
            "precision_weighted": 0.531285,
            "recall": 0.522398,
            "recall_weighted": 0.524752,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.514851,
            "f1": 0.5101,
            "f1_weighted": 0.512978,
            "precision": 0.516381,
            "precision_weighted": 0.519623,
            "recall": 0.512297,
            "recall_weighted": 0.514851,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.49505,
            "f1": 0.493428,
            "f1_weighted": 0.4954,
            "precision": 0.496306,
            "precision_weighted": 0.498407,
            "recall": 0.493193,
            "recall_weighted": 0.49505,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.534653,
            "f1": 0.533197,
            "f1_weighted": 0.535543,
            "precision": 0.536728,
            "precision_weighted": 0.539505,
            "recall": 0.532718,
            "recall_weighted": 0.534653,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.49505,
            "f1": 0.487931,
            "f1_weighted": 0.490023,
            "precision": 0.491925,
            "precision_weighted": 0.49414,
            "recall": 0.492973,
            "recall_weighted": 0.49505,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.524752,
            "f1": 0.520664,
            "f1_weighted": 0.522645,
            "precision": 0.521186,
            "precision_weighted": 0.523204,
            "recall": 0.522837,
            "recall_weighted": 0.524752,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.514851,
            "f1": 0.501067,
            "f1_weighted": 0.503711,
            "precision": 0.499843,
            "precision_weighted": 0.502216,
            "recall": 0.512077,
            "recall_weighted": 0.514851,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.50495,
            "f1": 0.496061,
            "f1_weighted": 0.498663,
            "precision": 0.49609,
            "precision_weighted": 0.498356,
            "recall": 0.501976,
            "recall_weighted": 0.50495,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.529703,
            "f1": 0.525942,
            "f1_weighted": 0.528626,
            "precision": 0.53405,
            "precision_weighted": 0.537236,
            "recall": 0.527448,
            "recall_weighted": 0.529703,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.510891,
        "f1": 0.505158,
        "f1_weighted": 0.507486,
        "precision": 0.50839,
        "precision_weighted": 0.51081,
        "recall": 0.50863,
        "recall_weighted": 0.510891,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.505158,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.783786058425903,
  "kg_co2_emissions": null
}