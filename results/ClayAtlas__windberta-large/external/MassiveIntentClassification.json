{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.28813046402151987,
                "f1": 0.2666771458648628,
                "main_score": 0.28813046402151987
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.03036314727639543,
                "f1": 0.02128263295887802,
                "main_score": 0.03036314727639543
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.06745124411566913,
                "f1": 0.0464897627862169,
                "main_score": 0.06745124411566913
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.2700403496973773,
                "f1": 0.2450373453583708,
                "main_score": 0.2700403496973773
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.0324142568930733,
                "f1": 0.014440829714459097,
                "main_score": 0.0324142568930733
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.311768661735037,
                "f1": 0.27449943893371537,
                "main_score": 0.311768661735037
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.35527908540685943,
                "f1": 0.3228409587721973,
                "main_score": 0.35527908540685943
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.3064895763281775,
                "f1": 0.2727309813767002,
                "main_score": 0.3064895763281775
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.18167451244115668,
                "f1": 0.14717271932824832,
                "main_score": 0.18167451244115668
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.5476126429051782,
                "f1": 0.5043678929170828,
                "main_score": 0.5476126429051782
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.3253194351042367,
                "f1": 0.3092286461509156,
                "main_score": 0.3253194351042367
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.08715534633490249,
                "f1": 0.05943557212598054,
                "main_score": 0.08715534633490249
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.31785474108944184,
                "f1": 0.28416607289904294,
                "main_score": 0.31785474108944184
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.3316072629455279,
                "f1": 0.3178249030156056,
                "main_score": 0.3316072629455279
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.030262273032952258,
                "f1": 0.010249360076972785,
                "main_score": 0.030262273032952258
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.03611297915265635,
                "f1": 0.018805751299306374,
                "main_score": 0.03611297915265635
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.3047074646940148,
                "f1": 0.27326274554457025,
                "main_score": 0.3047074646940148
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.05346334902488231,
                "f1": 0.020115115171706197,
                "main_score": 0.05346334902488231
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.32454606590450574,
                "f1": 0.318382002228813,
                "main_score": 0.32454606590450574
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.3011768661735037,
                "f1": 0.2793469768600366,
                "main_score": 0.3011768661735037
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.36321452589105585,
                "f1": 0.34476157222424125,
                "main_score": 0.36321452589105585
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.4108944182918628,
                "f1": 0.3927783199703022,
                "main_score": 0.4108944182918628
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.30423671822461335,
                "f1": 0.2809995717285775,
                "main_score": 0.30423671822461335
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.03789509078681909,
                "f1": 0.02369761705240627,
                "main_score": 0.03789509078681909
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.06785474108944183,
                "f1": 0.02899091377235745,
                "main_score": 0.06785474108944183
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.038567585743106925,
                "f1": 0.020161963929375477,
                "main_score": 0.038567585743106925
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.08823133826496302,
                "f1": 0.07858046825547553,
                "main_score": 0.08823133826496302
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.302320107599193,
                "f1": 0.28881628667244785,
                "main_score": 0.302320107599193
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.029287155346334904,
                "f1": 0.012010642206520263,
                "main_score": 0.029287155346334904
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.1260928043039677,
                "f1": 0.11505263544077053,
                "main_score": 0.1260928043039677
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.3065568258238063,
                "f1": 0.2759065107222783,
                "main_score": 0.3065568258238063
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.058473436449226625,
                "f1": 0.033114858432654826,
                "main_score": 0.058473436449226625
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.3107262945527909,
                "f1": 0.2931785883589503,
                "main_score": 0.3107262945527909
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.34095494283792876,
                "f1": 0.3031949299509232,
                "main_score": 0.34095494283792876
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.33170813718897113,
                "f1": 0.28978304060463583,
                "main_score": 0.33170813718897113
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.3691661062542031,
                "f1": 0.34591929627017803,
                "main_score": 0.3691661062542031
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.33006052454606594,
                "f1": 0.3091144759622849,
                "main_score": 0.33006052454606594
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.10403496973772697,
                "f1": 0.10071257139055659,
                "main_score": 0.10403496973772697
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.307296570275723,
                "f1": 0.28973650264516443,
                "main_score": 0.307296570275723
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.3698386012104909,
                "f1": 0.33553081407485086,
                "main_score": 0.3698386012104909
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.3301613987895091,
                "f1": 0.3076482715530935,
                "main_score": 0.3301613987895091
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.3162071284465367,
                "f1": 0.2979828395194018,
                "main_score": 0.3162071284465367
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.03194351042367182,
                "f1": 0.012345975087085737,
                "main_score": 0.03194351042367182
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.025924680564895764,
                "f1": 0.01376573193199978,
                "main_score": 0.025924680564895764
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.04613315400134499,
                "f1": 0.03315370311126649,
                "main_score": 0.04613315400134499
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.32548755884330866,
                "f1": 0.2872005484752792,
                "main_score": 0.32548755884330866
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.2686617350369872,
                "f1": 0.2504984155580145,
                "main_score": 0.2686617350369872
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.04229993275050437,
                "f1": 0.026738110863892467,
                "main_score": 0.04229993275050437
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.2924344317417619,
                "f1": 0.2663298392811213,
                "main_score": 0.2924344317417619
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.7091123066576999,
                "f1": 0.6865382422288536,
                "main_score": 0.7091123066576999
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6549092131809011,
                "f1": 0.6463433166397587,
                "main_score": 0.6549092131809011
            }
        ]
    }
}