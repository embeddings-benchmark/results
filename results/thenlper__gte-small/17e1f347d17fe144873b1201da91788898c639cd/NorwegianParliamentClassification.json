{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.536333,
        "f1": 0.533671,
        "f1_weighted": 0.533671,
        "ap": 0.520252,
        "ap_weighted": 0.520252,
        "scores_per_experiment": [
          {
            "accuracy": 0.51,
            "f1": 0.509864,
            "f1_weighted": 0.509864,
            "ap": 0.505103,
            "ap_weighted": 0.505103
          },
          {
            "accuracy": 0.525833,
            "f1": 0.525714,
            "f1_weighted": 0.525714,
            "ap": 0.513564,
            "ap_weighted": 0.513564
          },
          {
            "accuracy": 0.573333,
            "f1": 0.567274,
            "f1_weighted": 0.567274,
            "ap": 0.541015,
            "ap_weighted": 0.541015
          },
          {
            "accuracy": 0.539167,
            "f1": 0.538397,
            "f1_weighted": 0.538397,
            "ap": 0.521254,
            "ap_weighted": 0.521254
          },
          {
            "accuracy": 0.5725,
            "f1": 0.569917,
            "f1_weighted": 0.569917,
            "ap": 0.54247,
            "ap_weighted": 0.54247
          },
          {
            "accuracy": 0.544167,
            "f1": 0.540233,
            "f1_weighted": 0.540233,
            "ap": 0.523729,
            "ap_weighted": 0.523729
          },
          {
            "accuracy": 0.481667,
            "f1": 0.472522,
            "f1_weighted": 0.472522,
            "ap": 0.491099,
            "ap_weighted": 0.491099
          },
          {
            "accuracy": 0.530833,
            "f1": 0.53069,
            "f1_weighted": 0.53069,
            "ap": 0.516335,
            "ap_weighted": 0.516335
          },
          {
            "accuracy": 0.576667,
            "f1": 0.572947,
            "f1_weighted": 0.572947,
            "ap": 0.543287,
            "ap_weighted": 0.543287
          },
          {
            "accuracy": 0.509167,
            "f1": 0.50915,
            "f1_weighted": 0.50915,
            "ap": 0.504666,
            "ap_weighted": 0.504666
          }
        ],
        "main_score": 0.536333,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.536167,
        "f1": 0.533106,
        "f1_weighted": 0.533106,
        "ap": 0.521378,
        "ap_weighted": 0.521378,
        "scores_per_experiment": [
          {
            "accuracy": 0.480833,
            "f1": 0.480824,
            "f1_weighted": 0.480824,
            "ap": 0.490781,
            "ap_weighted": 0.490781
          },
          {
            "accuracy": 0.526667,
            "f1": 0.52633,
            "f1_weighted": 0.52633,
            "ap": 0.514008,
            "ap_weighted": 0.514008
          },
          {
            "accuracy": 0.585833,
            "f1": 0.578432,
            "f1_weighted": 0.578432,
            "ap": 0.548741,
            "ap_weighted": 0.548741
          },
          {
            "accuracy": 0.544167,
            "f1": 0.543685,
            "f1_weighted": 0.543685,
            "ap": 0.52417,
            "ap_weighted": 0.52417
          },
          {
            "accuracy": 0.596667,
            "f1": 0.592993,
            "f1_weighted": 0.592993,
            "ap": 0.55987,
            "ap_weighted": 0.55987
          },
          {
            "accuracy": 0.495833,
            "f1": 0.493639,
            "f1_weighted": 0.493639,
            "ap": 0.497932,
            "ap_weighted": 0.497932
          },
          {
            "accuracy": 0.5,
            "f1": 0.486864,
            "f1_weighted": 0.486864,
            "ap": 0.5,
            "ap_weighted": 0.5
          },
          {
            "accuracy": 0.4975,
            "f1": 0.49712,
            "f1_weighted": 0.49712,
            "ap": 0.498756,
            "ap_weighted": 0.498756
          },
          {
            "accuracy": 0.62,
            "f1": 0.617012,
            "f1_weighted": 0.617012,
            "ap": 0.572238,
            "ap_weighted": 0.572238
          },
          {
            "accuracy": 0.514167,
            "f1": 0.514164,
            "f1_weighted": 0.514164,
            "ap": 0.507283,
            "ap_weighted": 0.507283
          }
        ],
        "main_score": 0.536167,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 24.027511596679688,
  "kg_co2_emissions": 0.0007857058776702861
}