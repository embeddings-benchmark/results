{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.502167,
        "f1": 0.496277,
        "f1_weighted": 0.496277,
        "ap": 0.501315,
        "ap_weighted": 0.501315,
        "scores_per_experiment": [
          {
            "accuracy": 0.514167,
            "f1": 0.51411,
            "f1_weighted": 0.51411,
            "ap": 0.50728,
            "ap_weighted": 0.50728
          },
          {
            "accuracy": 0.4725,
            "f1": 0.471998,
            "f1_weighted": 0.471998,
            "ap": 0.486962,
            "ap_weighted": 0.486962
          },
          {
            "accuracy": 0.491667,
            "f1": 0.48544,
            "f1_weighted": 0.48544,
            "ap": 0.495922,
            "ap_weighted": 0.495922
          },
          {
            "accuracy": 0.504167,
            "f1": 0.503045,
            "f1_weighted": 0.503045,
            "ap": 0.502099,
            "ap_weighted": 0.502099
          },
          {
            "accuracy": 0.521667,
            "f1": 0.520126,
            "f1_weighted": 0.520126,
            "ap": 0.511363,
            "ap_weighted": 0.511363
          },
          {
            "accuracy": 0.495833,
            "f1": 0.49116,
            "f1_weighted": 0.49116,
            "ap": 0.497938,
            "ap_weighted": 0.497938
          },
          {
            "accuracy": 0.514167,
            "f1": 0.505706,
            "f1_weighted": 0.505706,
            "ap": 0.507242,
            "ap_weighted": 0.507242
          },
          {
            "accuracy": 0.513333,
            "f1": 0.499713,
            "f1_weighted": 0.499713,
            "ap": 0.5068,
            "ap_weighted": 0.5068
          },
          {
            "accuracy": 0.509167,
            "f1": 0.509068,
            "f1_weighted": 0.509068,
            "ap": 0.504665,
            "ap_weighted": 0.504665
          },
          {
            "accuracy": 0.485,
            "f1": 0.462408,
            "f1_weighted": 0.462408,
            "ap": 0.492881,
            "ap_weighted": 0.492881
          }
        ],
        "main_score": 0.502167,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.506167,
        "f1": 0.499405,
        "f1_weighted": 0.499405,
        "ap": 0.503401,
        "ap_weighted": 0.503401,
        "scores_per_experiment": [
          {
            "accuracy": 0.518333,
            "f1": 0.517946,
            "f1_weighted": 0.517946,
            "ap": 0.509523,
            "ap_weighted": 0.509523
          },
          {
            "accuracy": 0.4825,
            "f1": 0.480131,
            "f1_weighted": 0.480131,
            "ap": 0.49152,
            "ap_weighted": 0.49152
          },
          {
            "accuracy": 0.53,
            "f1": 0.52192,
            "f1_weighted": 0.52192,
            "ap": 0.516216,
            "ap_weighted": 0.516216
          },
          {
            "accuracy": 0.504167,
            "f1": 0.502425,
            "f1_weighted": 0.502425,
            "ap": 0.502099,
            "ap_weighted": 0.502099
          },
          {
            "accuracy": 0.520833,
            "f1": 0.519672,
            "f1_weighted": 0.519672,
            "ap": 0.510898,
            "ap_weighted": 0.510898
          },
          {
            "accuracy": 0.514167,
            "f1": 0.510418,
            "f1_weighted": 0.510418,
            "ap": 0.507327,
            "ap_weighted": 0.507327
          },
          {
            "accuracy": 0.4825,
            "f1": 0.477184,
            "f1_weighted": 0.477184,
            "ap": 0.491505,
            "ap_weighted": 0.491505
          },
          {
            "accuracy": 0.4975,
            "f1": 0.482394,
            "f1_weighted": 0.482394,
            "ap": 0.498755,
            "ap_weighted": 0.498755
          },
          {
            "accuracy": 0.516667,
            "f1": 0.516473,
            "f1_weighted": 0.516473,
            "ap": 0.508623,
            "ap_weighted": 0.508623
          },
          {
            "accuracy": 0.495,
            "f1": 0.465481,
            "f1_weighted": 0.465481,
            "ap": 0.497547,
            "ap_weighted": 0.497547
          }
        ],
        "main_score": 0.506167,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 42.232741355895996,
  "kg_co2_emissions": 0.0024663616948049074
}