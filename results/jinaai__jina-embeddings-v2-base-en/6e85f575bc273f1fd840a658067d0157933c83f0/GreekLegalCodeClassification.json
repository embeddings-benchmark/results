{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.006689,
        "f1": 0.002493,
        "f1_weighted": 0.004236,
        "scores_per_experiment": [
          {
            "accuracy": 0.009277,
            "f1": 0.003904,
            "f1_weighted": 0.006706
          },
          {
            "accuracy": 0.005371,
            "f1": 0.001967,
            "f1_weighted": 0.003925
          },
          {
            "accuracy": 0.008301,
            "f1": 0.002862,
            "f1_weighted": 0.004628
          },
          {
            "accuracy": 0.005371,
            "f1": 0.003403,
            "f1_weighted": 0.004109
          },
          {
            "accuracy": 0.002441,
            "f1": 0.000726,
            "f1_weighted": 0.001378
          },
          {
            "accuracy": 0.006836,
            "f1": 0.001921,
            "f1_weighted": 0.003154
          },
          {
            "accuracy": 0.006836,
            "f1": 0.002422,
            "f1_weighted": 0.005762
          },
          {
            "accuracy": 0.008301,
            "f1": 0.003364,
            "f1_weighted": 0.005414
          },
          {
            "accuracy": 0.006836,
            "f1": 0.00224,
            "f1_weighted": 0.004337
          },
          {
            "accuracy": 0.007324,
            "f1": 0.002117,
            "f1_weighted": 0.002943
          }
        ],
        "main_score": 0.006689,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.006592,
        "f1": 0.003003,
        "f1_weighted": 0.004169,
        "scores_per_experiment": [
          {
            "accuracy": 0.008789,
            "f1": 0.003597,
            "f1_weighted": 0.004173
          },
          {
            "accuracy": 0.005371,
            "f1": 0.002463,
            "f1_weighted": 0.002825
          },
          {
            "accuracy": 0.003906,
            "f1": 0.001527,
            "f1_weighted": 0.002754
          },
          {
            "accuracy": 0.005371,
            "f1": 0.002899,
            "f1_weighted": 0.003753
          },
          {
            "accuracy": 0.006348,
            "f1": 0.004212,
            "f1_weighted": 0.003948
          },
          {
            "accuracy": 0.009766,
            "f1": 0.003222,
            "f1_weighted": 0.005289
          },
          {
            "accuracy": 0.007324,
            "f1": 0.002367,
            "f1_weighted": 0.004278
          },
          {
            "accuracy": 0.007324,
            "f1": 0.003499,
            "f1_weighted": 0.006918
          },
          {
            "accuracy": 0.005371,
            "f1": 0.003524,
            "f1_weighted": 0.00397
          },
          {
            "accuracy": 0.006348,
            "f1": 0.002719,
            "f1_weighted": 0.003781
          }
        ],
        "main_score": 0.006592,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 2316.566837310791,
  "kg_co2_emissions": 0.1916387680792112
}