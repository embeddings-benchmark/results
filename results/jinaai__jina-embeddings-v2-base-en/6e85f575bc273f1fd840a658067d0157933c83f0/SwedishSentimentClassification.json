{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.717432,
        "f1": 0.716336,
        "f1_weighted": 0.716338,
        "ap": 0.657999,
        "ap_weighted": 0.657999,
        "scores_per_experiment": [
          {
            "accuracy": 0.71875,
            "f1": 0.717313,
            "f1_weighted": 0.717372,
            "ap": 0.652525,
            "ap_weighted": 0.652525
          },
          {
            "accuracy": 0.721191,
            "f1": 0.7211,
            "f1_weighted": 0.721115,
            "ap": 0.65923,
            "ap_weighted": 0.65923
          },
          {
            "accuracy": 0.720215,
            "f1": 0.720103,
            "f1_weighted": 0.720119,
            "ap": 0.658145,
            "ap_weighted": 0.658145
          },
          {
            "accuracy": 0.739258,
            "f1": 0.739177,
            "f1_weighted": 0.739164,
            "ap": 0.680486,
            "ap_weighted": 0.680486
          },
          {
            "accuracy": 0.692383,
            "f1": 0.691427,
            "f1_weighted": 0.691376,
            "ap": 0.639476,
            "ap_weighted": 0.639476
          },
          {
            "accuracy": 0.701172,
            "f1": 0.69841,
            "f1_weighted": 0.698494,
            "ap": 0.635772,
            "ap_weighted": 0.635772
          },
          {
            "accuracy": 0.736816,
            "f1": 0.73518,
            "f1_weighted": 0.735241,
            "ap": 0.668111,
            "ap_weighted": 0.668111
          },
          {
            "accuracy": 0.745117,
            "f1": 0.744021,
            "f1_weighted": 0.743972,
            "ap": 0.693392,
            "ap_weighted": 0.693392
          },
          {
            "accuracy": 0.684082,
            "f1": 0.681426,
            "f1_weighted": 0.681341,
            "ap": 0.635249,
            "ap_weighted": 0.635249
          },
          {
            "accuracy": 0.715332,
            "f1": 0.715206,
            "f1_weighted": 0.715189,
            "ap": 0.6576,
            "ap_weighted": 0.6576
          }
        ],
        "main_score": 0.717432,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.711035,
        "f1": 0.710078,
        "f1_weighted": 0.710076,
        "ap": 0.652,
        "ap_weighted": 0.652,
        "scores_per_experiment": [
          {
            "accuracy": 0.728516,
            "f1": 0.727814,
            "f1_weighted": 0.727841,
            "ap": 0.662542,
            "ap_weighted": 0.662542
          },
          {
            "accuracy": 0.736328,
            "f1": 0.736171,
            "f1_weighted": 0.736183,
            "ap": 0.672343,
            "ap_weighted": 0.672343
          },
          {
            "accuracy": 0.705566,
            "f1": 0.705437,
            "f1_weighted": 0.705449,
            "ap": 0.644276,
            "ap_weighted": 0.644276
          },
          {
            "accuracy": 0.726562,
            "f1": 0.726312,
            "f1_weighted": 0.726295,
            "ap": 0.668964,
            "ap_weighted": 0.668964
          },
          {
            "accuracy": 0.687988,
            "f1": 0.686667,
            "f1_weighted": 0.686627,
            "ap": 0.635718,
            "ap_weighted": 0.635718
          },
          {
            "accuracy": 0.696289,
            "f1": 0.693708,
            "f1_weighted": 0.693763,
            "ap": 0.631517,
            "ap_weighted": 0.631517
          },
          {
            "accuracy": 0.714355,
            "f1": 0.71342,
            "f1_weighted": 0.713452,
            "ap": 0.649286,
            "ap_weighted": 0.649286
          },
          {
            "accuracy": 0.750977,
            "f1": 0.750357,
            "f1_weighted": 0.750333,
            "ap": 0.696543,
            "ap_weighted": 0.696543
          },
          {
            "accuracy": 0.669922,
            "f1": 0.667236,
            "f1_weighted": 0.667177,
            "ap": 0.621313,
            "ap_weighted": 0.621313
          },
          {
            "accuracy": 0.693848,
            "f1": 0.693658,
            "f1_weighted": 0.693643,
            "ap": 0.637497,
            "ap_weighted": 0.637497
          }
        ],
        "main_score": 0.711035,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 23.394161462783813,
  "kg_co2_emissions": 0.001032434920562544
}