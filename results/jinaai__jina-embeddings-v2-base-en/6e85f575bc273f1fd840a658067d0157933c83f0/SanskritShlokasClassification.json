{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.592167,
        "f1": 0.592705,
        "f1_weighted": 0.591642,
        "scores_per_experiment": [
          {
            "accuracy": 0.524804,
            "f1": 0.509874,
            "f1_weighted": 0.514779
          },
          {
            "accuracy": 0.626632,
            "f1": 0.625282,
            "f1_weighted": 0.6226
          },
          {
            "accuracy": 0.582245,
            "f1": 0.591257,
            "f1_weighted": 0.591204
          },
          {
            "accuracy": 0.543081,
            "f1": 0.553357,
            "f1_weighted": 0.549991
          },
          {
            "accuracy": 0.587467,
            "f1": 0.589505,
            "f1_weighted": 0.586894
          },
          {
            "accuracy": 0.605744,
            "f1": 0.615738,
            "f1_weighted": 0.614115
          },
          {
            "accuracy": 0.639687,
            "f1": 0.63728,
            "f1_weighted": 0.636685
          },
          {
            "accuracy": 0.608355,
            "f1": 0.589786,
            "f1_weighted": 0.582907
          },
          {
            "accuracy": 0.592689,
            "f1": 0.599062,
            "f1_weighted": 0.599772
          },
          {
            "accuracy": 0.610966,
            "f1": 0.615915,
            "f1_weighted": 0.617472
          }
        ],
        "main_score": 0.592167,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.586458,
        "f1": 0.591273,
        "f1_weighted": 0.582354,
        "scores_per_experiment": [
          {
            "accuracy": 0.645833,
            "f1": 0.632138,
            "f1_weighted": 0.632924
          },
          {
            "accuracy": 0.604167,
            "f1": 0.607527,
            "f1_weighted": 0.598286
          },
          {
            "accuracy": 0.635417,
            "f1": 0.650994,
            "f1_weighted": 0.64123
          },
          {
            "accuracy": 0.520833,
            "f1": 0.536984,
            "f1_weighted": 0.526879
          },
          {
            "accuracy": 0.572917,
            "f1": 0.573425,
            "f1_weighted": 0.568246
          },
          {
            "accuracy": 0.53125,
            "f1": 0.549016,
            "f1_weighted": 0.527883
          },
          {
            "accuracy": 0.614583,
            "f1": 0.610764,
            "f1_weighted": 0.614909
          },
          {
            "accuracy": 0.53125,
            "f1": 0.525865,
            "f1_weighted": 0.498911
          },
          {
            "accuracy": 0.65625,
            "f1": 0.671676,
            "f1_weighted": 0.661943
          },
          {
            "accuracy": 0.552083,
            "f1": 0.554344,
            "f1_weighted": 0.552334
          }
        ],
        "main_score": 0.586458,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 23.40827512741089,
  "kg_co2_emissions": 0.000701319059675011
}