{
  "dataset_revision": "b7c64bd89eb87f8ded463478346f76731f07bf8b",
  "task_name": "JDReview",
  "mteb_version": "2.1.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.896811,
            "f1": 0.850794,
            "f1_weighted": 0.902874,
            "precision": 0.819584,
            "precision_weighted": 0.920249,
            "recall": 0.905448,
            "recall_weighted": 0.896811,
            "ap": 0.621143,
            "ap_weighted": 0.621143
          },
          {
            "accuracy": 0.878049,
            "f1": 0.827761,
            "f1_weighted": 0.886255,
            "precision": 0.796591,
            "precision_weighted": 0.909821,
            "recall": 0.890029,
            "recall_weighted": 0.878049,
            "ap": 0.577284,
            "ap_weighted": 0.577284
          },
          {
            "accuracy": 0.879925,
            "f1": 0.832784,
            "f1_weighted": 0.888587,
            "precision": 0.800094,
            "precision_weighted": 0.915866,
            "recall": 0.902877,
            "recall_weighted": 0.879925,
            "ap": 0.589824,
            "ap_weighted": 0.589824
          },
          {
            "accuracy": 0.889306,
            "f1": 0.842756,
            "f1_weighted": 0.896529,
            "precision": 0.810447,
            "precision_weighted": 0.918274,
            "recall": 0.904739,
            "recall_weighted": 0.889306,
            "ap": 0.606848,
            "ap_weighted": 0.606848
          },
          {
            "accuracy": 0.881801,
            "f1": 0.834008,
            "f1_weighted": 0.889989,
            "precision": 0.80172,
            "precision_weighted": 0.914915,
            "recall": 0.90013,
            "recall_weighted": 0.881801,
            "ap": 0.590802,
            "ap_weighted": 0.590802
          },
          {
            "accuracy": 0.889306,
            "f1": 0.842756,
            "f1_weighted": 0.896529,
            "precision": 0.810447,
            "precision_weighted": 0.918274,
            "recall": 0.904739,
            "recall_weighted": 0.889306,
            "ap": 0.606848,
            "ap_weighted": 0.606848
          },
          {
            "accuracy": 0.879925,
            "f1": 0.831848,
            "f1_weighted": 0.88836,
            "precision": 0.79961,
            "precision_weighted": 0.914101,
            "recall": 0.898978,
            "recall_weighted": 0.879925,
            "ap": 0.586925,
            "ap_weighted": 0.586925
          },
          {
            "accuracy": 0.889306,
            "f1": 0.842756,
            "f1_weighted": 0.896529,
            "precision": 0.810447,
            "precision_weighted": 0.918274,
            "recall": 0.904739,
            "recall_weighted": 0.889306,
            "ap": 0.606848,
            "ap_weighted": 0.606848
          },
          {
            "accuracy": 0.883677,
            "f1": 0.836179,
            "f1_weighted": 0.891621,
            "precision": 0.803858,
            "precision_weighted": 0.915739,
            "recall": 0.901282,
            "recall_weighted": 0.883677,
            "ap": 0.594732,
            "ap_weighted": 0.594732
          },
          {
            "accuracy": 0.870544,
            "f1": 0.822166,
            "f1_weighted": 0.880463,
            "precision": 0.790119,
            "precision_weighted": 0.91203,
            "recall": 0.897116,
            "recall_weighted": 0.870544,
            "ap": 0.57128,
            "ap_weighted": 0.57128
          }
        ],
        "accuracy": 0.883865,
        "f1": 0.836381,
        "f1_weighted": 0.891774,
        "precision": 0.804292,
        "precision_weighted": 0.915754,
        "recall": 0.901008,
        "recall_weighted": 0.883865,
        "ap": 0.595253,
        "ap_weighted": 0.595253,
        "main_score": 0.883865,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 56.864190101623535,
  "kg_co2_emissions": null
}