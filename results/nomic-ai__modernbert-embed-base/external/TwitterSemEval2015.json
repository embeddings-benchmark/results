{
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
    "task_name": "TwitterSemEval2015",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "cos_sim_accuracy": 0.8575430649102939,
                "cos_sim_ap": 0.736284265647765,
                "cos_sim_f1": 0.6776023680315738,
                "cos_sim_precision": 0.6361741547012506,
                "cos_sim_recall": 0.724802110817942,
                "dot_accuracy": 0.857423854085951,
                "dot_ap": 0.7359147637253723,
                "dot_f1": 0.6769498693867396,
                "dot_precision": 0.6403859731701577,
                "dot_recall": 0.7179419525065963,
                "euclidean_accuracy": 0.857423854085951,
                "euclidean_ap": 0.7362889904096539,
                "euclidean_f1": 0.6780415430267064,
                "euclidean_precision": 0.6379711493718009,
                "euclidean_recall": 0.7234828496042216,
                "manhattan_accuracy": 0.8569470107885796,
                "manhattan_ap": 0.7349219614602531,
                "manhattan_f1": 0.6760809797550613,
                "manhattan_precision": 0.6422127255460589,
                "manhattan_recall": 0.7137203166226914,
                "max_accuracy": 0.8575430649102939,
                "max_ap": 0.7362889904096539,
                "max_f1": 0.6780415430267064,
                "main_score": 0.7362889904096539
            }
        ]
    }
}