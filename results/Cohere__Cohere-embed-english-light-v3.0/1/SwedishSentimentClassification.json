{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.711768,
        "f1": 0.710898,
        "f1_weighted": 0.710903,
        "ap": 0.652289,
        "ap_weighted": 0.652289,
        "scores_per_experiment": [
          {
            "accuracy": 0.73291,
            "f1": 0.732334,
            "f1_weighted": 0.732371,
            "ap": 0.667428,
            "ap_weighted": 0.667428
          },
          {
            "accuracy": 0.733887,
            "f1": 0.733666,
            "f1_weighted": 0.733643,
            "ap": 0.676555,
            "ap_weighted": 0.676555
          },
          {
            "accuracy": 0.667969,
            "f1": 0.667953,
            "f1_weighted": 0.66796,
            "ap": 0.613268,
            "ap_weighted": 0.613268
          },
          {
            "accuracy": 0.712402,
            "f1": 0.711929,
            "f1_weighted": 0.711895,
            "ap": 0.656892,
            "ap_weighted": 0.656892
          },
          {
            "accuracy": 0.700684,
            "f1": 0.700418,
            "f1_weighted": 0.700392,
            "ap": 0.644725,
            "ap_weighted": 0.644725
          },
          {
            "accuracy": 0.708008,
            "f1": 0.705473,
            "f1_weighted": 0.705553,
            "ap": 0.64172,
            "ap_weighted": 0.64172
          },
          {
            "accuracy": 0.740234,
            "f1": 0.737474,
            "f1_weighted": 0.737553,
            "ap": 0.669184,
            "ap_weighted": 0.669184
          },
          {
            "accuracy": 0.716797,
            "f1": 0.71679,
            "f1_weighted": 0.716794,
            "ap": 0.656399,
            "ap_weighted": 0.656399
          },
          {
            "accuracy": 0.692383,
            "f1": 0.692372,
            "f1_weighted": 0.692367,
            "ap": 0.635127,
            "ap_weighted": 0.635127
          },
          {
            "accuracy": 0.712402,
            "f1": 0.710569,
            "f1_weighted": 0.710501,
            "ap": 0.661591,
            "ap_weighted": 0.661591
          }
        ],
        "main_score": 0.711768,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.715625,
        "f1": 0.714857,
        "f1_weighted": 0.714859,
        "ap": 0.655769,
        "ap_weighted": 0.655769,
        "scores_per_experiment": [
          {
            "accuracy": 0.727539,
            "f1": 0.727102,
            "f1_weighted": 0.727123,
            "ap": 0.662604,
            "ap_weighted": 0.662604
          },
          {
            "accuracy": 0.742188,
            "f1": 0.742034,
            "f1_weighted": 0.742021,
            "ap": 0.683793,
            "ap_weighted": 0.683793
          },
          {
            "accuracy": 0.666504,
            "f1": 0.666502,
            "f1_weighted": 0.6665,
            "ap": 0.612094,
            "ap_weighted": 0.612094
          },
          {
            "accuracy": 0.718262,
            "f1": 0.717307,
            "f1_weighted": 0.717275,
            "ap": 0.664138,
            "ap_weighted": 0.664138
          },
          {
            "accuracy": 0.717285,
            "f1": 0.717066,
            "f1_weighted": 0.717051,
            "ap": 0.659675,
            "ap_weighted": 0.659675
          },
          {
            "accuracy": 0.708008,
            "f1": 0.706475,
            "f1_weighted": 0.706516,
            "ap": 0.642655,
            "ap_weighted": 0.642655
          },
          {
            "accuracy": 0.737793,
            "f1": 0.735191,
            "f1_weighted": 0.735242,
            "ap": 0.666876,
            "ap_weighted": 0.666876
          },
          {
            "accuracy": 0.739258,
            "f1": 0.739209,
            "f1_weighted": 0.739216,
            "ap": 0.6763,
            "ap_weighted": 0.6763
          },
          {
            "accuracy": 0.691895,
            "f1": 0.691894,
            "f1_weighted": 0.691894,
            "ap": 0.633786,
            "ap_weighted": 0.633786
          },
          {
            "accuracy": 0.70752,
            "f1": 0.705791,
            "f1_weighted": 0.705746,
            "ap": 0.655767,
            "ap_weighted": 0.655767
          }
        ],
        "main_score": 0.715625,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 37.733126163482666,
  "kg_co2_emissions": null
}