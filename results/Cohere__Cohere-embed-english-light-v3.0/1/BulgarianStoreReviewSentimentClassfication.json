{
  "dataset_revision": "701984d6c6efea0e14a1c7850ef70e464c5577c0",
  "task_name": "BulgarianStoreReviewSentimentClassfication",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.347802,
        "f1": 0.247511,
        "f1_weighted": 0.407521,
        "scores_per_experiment": [
          {
            "accuracy": 0.357143,
            "f1": 0.252556,
            "f1_weighted": 0.427901
          },
          {
            "accuracy": 0.417582,
            "f1": 0.282052,
            "f1_weighted": 0.467264
          },
          {
            "accuracy": 0.384615,
            "f1": 0.252772,
            "f1_weighted": 0.444616
          },
          {
            "accuracy": 0.401099,
            "f1": 0.244937,
            "f1_weighted": 0.466549
          },
          {
            "accuracy": 0.39011,
            "f1": 0.267413,
            "f1_weighted": 0.455175
          },
          {
            "accuracy": 0.291209,
            "f1": 0.214772,
            "f1_weighted": 0.342481
          },
          {
            "accuracy": 0.252747,
            "f1": 0.213923,
            "f1_weighted": 0.304608
          },
          {
            "accuracy": 0.335165,
            "f1": 0.254716,
            "f1_weighted": 0.390134
          },
          {
            "accuracy": 0.318681,
            "f1": 0.245625,
            "f1_weighted": 0.3825
          },
          {
            "accuracy": 0.32967,
            "f1": 0.246347,
            "f1_weighted": 0.393981
          }
        ],
        "main_score": 0.347802,
        "hf_subset": "default",
        "languages": [
          "bul-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 10.164794445037842,
  "kg_co2_emissions": null
}