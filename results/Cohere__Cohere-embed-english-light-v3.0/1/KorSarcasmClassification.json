{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "task_name": "KorSarcasmClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.546045,
        "f1": 0.541166,
        "f1_weighted": 0.541147,
        "ap": 0.526058,
        "ap_weighted": 0.526058,
        "scores_per_experiment": [
          {
            "accuracy": 0.600098,
            "f1": 0.595557,
            "f1_weighted": 0.595641,
            "ap": 0.561625,
            "ap_weighted": 0.561625
          },
          {
            "accuracy": 0.563477,
            "f1": 0.562906,
            "f1_weighted": 0.562937,
            "ap": 0.53506,
            "ap_weighted": 0.53506
          },
          {
            "accuracy": 0.628906,
            "f1": 0.603123,
            "f1_weighted": 0.602925,
            "ap": 0.574825,
            "ap_weighted": 0.574825
          },
          {
            "accuracy": 0.533691,
            "f1": 0.533402,
            "f1_weighted": 0.533379,
            "ap": 0.516979,
            "ap_weighted": 0.516979
          },
          {
            "accuracy": 0.493164,
            "f1": 0.488382,
            "f1_weighted": 0.488479,
            "ap": 0.495573,
            "ap_weighted": 0.495573
          },
          {
            "accuracy": 0.55127,
            "f1": 0.551251,
            "f1_weighted": 0.551246,
            "ap": 0.527262,
            "ap_weighted": 0.527262
          },
          {
            "accuracy": 0.58252,
            "f1": 0.581765,
            "f1_weighted": 0.58173,
            "ap": 0.546616,
            "ap_weighted": 0.546616
          },
          {
            "accuracy": 0.539062,
            "f1": 0.533681,
            "f1_weighted": 0.533584,
            "ap": 0.519931,
            "ap_weighted": 0.519931
          },
          {
            "accuracy": 0.483887,
            "f1": 0.478766,
            "f1_weighted": 0.478665,
            "ap": 0.491276,
            "ap_weighted": 0.491276
          },
          {
            "accuracy": 0.484375,
            "f1": 0.482828,
            "f1_weighted": 0.482884,
            "ap": 0.491436,
            "ap_weighted": 0.491436
          }
        ],
        "main_score": 0.546045,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 272.65786623954773,
  "kg_co2_emissions": null
}