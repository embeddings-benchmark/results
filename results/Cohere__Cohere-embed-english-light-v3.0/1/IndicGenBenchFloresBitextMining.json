{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.02257,
        "recall": 0.052156,
        "f1": 0.026451,
        "accuracy": 0.052156,
        "main_score": 0.026451,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.009174,
        "recall": 0.018054,
        "f1": 0.010586,
        "accuracy": 0.018054,
        "main_score": 0.010586,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021052,
        "recall": 0.055165,
        "f1": 0.025624,
        "accuracy": 0.055165,
        "main_score": 0.025624,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.015662,
        "recall": 0.021063,
        "f1": 0.016597,
        "accuracy": 0.021063,
        "main_score": 0.016597,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.070779,
        "recall": 0.116349,
        "f1": 0.078763,
        "accuracy": 0.116349,
        "main_score": 0.078763,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.014893,
        "recall": 0.023069,
        "f1": 0.016201,
        "accuracy": 0.023069,
        "main_score": 0.016201,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024071,
        "recall": 0.058175,
        "f1": 0.028072,
        "accuracy": 0.058175,
        "main_score": 0.028072,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.010168,
        "recall": 0.02006,
        "f1": 0.011685,
        "accuracy": 0.02006,
        "main_score": 0.011685,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024785,
        "recall": 0.059178,
        "f1": 0.028776,
        "accuracy": 0.059178,
        "main_score": 0.028776,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.014843,
        "recall": 0.018054,
        "f1": 0.015282,
        "accuracy": 0.018054,
        "main_score": 0.015282,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054746,
        "recall": 0.09328,
        "f1": 0.061478,
        "accuracy": 0.09328,
        "main_score": 0.061478,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.011114,
        "recall": 0.014042,
        "f1": 0.011188,
        "accuracy": 0.014042,
        "main_score": 0.011188,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.05397,
        "recall": 0.102307,
        "f1": 0.061284,
        "accuracy": 0.102307,
        "main_score": 0.061284,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.042955,
        "recall": 0.051153,
        "f1": 0.044611,
        "accuracy": 0.051153,
        "main_score": 0.044611,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.038669,
        "recall": 0.104313,
        "f1": 0.047635,
        "accuracy": 0.104313,
        "main_score": 0.047635,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001455,
        "recall": 0.004012,
        "f1": 0.001741,
        "accuracy": 0.004012,
        "main_score": 0.001741,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.048031,
        "recall": 0.089268,
        "f1": 0.054628,
        "accuracy": 0.089268,
        "main_score": 0.054628,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023896,
        "recall": 0.049147,
        "f1": 0.027627,
        "accuracy": 0.049147,
        "main_score": 0.027627,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.030718,
        "recall": 0.038114,
        "f1": 0.031664,
        "accuracy": 0.038114,
        "main_score": 0.031664,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.08009,
        "recall": 0.130391,
        "f1": 0.089086,
        "accuracy": 0.130391,
        "main_score": 0.089086,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.021801,
        "recall": 0.026078,
        "f1": 0.02247,
        "accuracy": 0.026078,
        "main_score": 0.02247,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.063155,
        "recall": 0.119358,
        "f1": 0.072943,
        "accuracy": 0.119358,
        "main_score": 0.072943,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.007688,
        "recall": 0.013039,
        "f1": 0.008575,
        "accuracy": 0.013039,
        "main_score": 0.008575,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.02939,
        "recall": 0.080241,
        "f1": 0.036293,
        "accuracy": 0.080241,
        "main_score": 0.036293,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010327,
        "recall": 0.016048,
        "f1": 0.011427,
        "accuracy": 0.016048,
        "main_score": 0.011427,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028058,
        "recall": 0.068205,
        "f1": 0.033288,
        "accuracy": 0.068205,
        "main_score": 0.033288,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.043202,
        "recall": 0.045135,
        "f1": 0.043265,
        "accuracy": 0.045135,
        "main_score": 0.043265,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.09685,
        "recall": 0.177533,
        "f1": 0.111915,
        "accuracy": 0.177533,
        "main_score": 0.111915,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.016356,
        "recall": 0.021063,
        "f1": 0.017227,
        "accuracy": 0.021063,
        "main_score": 0.017227,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054445,
        "recall": 0.100301,
        "f1": 0.061267,
        "accuracy": 0.100301,
        "main_score": 0.061267,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006894,
        "recall": 0.01003,
        "f1": 0.007267,
        "accuracy": 0.01003,
        "main_score": 0.007267,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.064015,
        "recall": 0.105316,
        "f1": 0.071729,
        "accuracy": 0.105316,
        "main_score": 0.071729,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.010272,
        "recall": 0.014042,
        "f1": 0.010446,
        "accuracy": 0.014042,
        "main_score": 0.010446,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.066753,
        "recall": 0.112337,
        "f1": 0.075668,
        "accuracy": 0.112337,
        "main_score": 0.075668,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022764,
        "recall": 0.048144,
        "f1": 0.026376,
        "accuracy": 0.048144,
        "main_score": 0.026376,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.003947,
        "recall": 0.008024,
        "f1": 0.004373,
        "accuracy": 0.008024,
        "main_score": 0.004373,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.067551,
        "recall": 0.106319,
        "f1": 0.074841,
        "accuracy": 0.106319,
        "main_score": 0.074841,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.007567,
        "recall": 0.011033,
        "f1": 0.007776,
        "accuracy": 0.011033,
        "main_score": 0.007776,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.064736,
        "recall": 0.105316,
        "f1": 0.072279,
        "accuracy": 0.105316,
        "main_score": 0.072279,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.020862,
        "recall": 0.027081,
        "f1": 0.021599,
        "accuracy": 0.027081,
        "main_score": 0.021599,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.073829,
        "recall": 0.125376,
        "f1": 0.083281,
        "accuracy": 0.125376,
        "main_score": 0.083281,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.002174,
        "recall": 0.005015,
        "f1": 0.002306,
        "accuracy": 0.005015,
        "main_score": 0.002306,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.063114,
        "recall": 0.099298,
        "f1": 0.070092,
        "accuracy": 0.099298,
        "main_score": 0.070092,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.009565,
        "recall": 0.012036,
        "f1": 0.009765,
        "accuracy": 0.012036,
        "main_score": 0.009765,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.079797,
        "recall": 0.131394,
        "f1": 0.089074,
        "accuracy": 0.131394,
        "main_score": 0.089074,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.008265,
        "recall": 0.013039,
        "f1": 0.008771,
        "accuracy": 0.013039,
        "main_score": 0.008771,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.08257,
        "recall": 0.1334,
        "f1": 0.09257,
        "accuracy": 0.1334,
        "main_score": 0.09257,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.002006,
        "f1": 0.000671,
        "accuracy": 0.002006,
        "main_score": 0.000671,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032859,
        "recall": 0.075226,
        "f1": 0.039836,
        "accuracy": 0.075226,
        "main_score": 0.039836,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.006202,
        "recall": 0.01003,
        "f1": 0.006348,
        "accuracy": 0.01003,
        "main_score": 0.006348,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.061154,
        "recall": 0.106319,
        "f1": 0.069869,
        "accuracy": 0.106319,
        "main_score": 0.069869,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.004218,
        "recall": 0.008024,
        "f1": 0.004707,
        "accuracy": 0.008024,
        "main_score": 0.004707,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.063891,
        "recall": 0.108325,
        "f1": 0.073037,
        "accuracy": 0.108325,
        "main_score": 0.073037,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.00301,
        "recall": 0.004012,
        "f1": 0.003011,
        "accuracy": 0.004012,
        "main_score": 0.003011,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002509,
        "recall": 0.017051,
        "f1": 0.003568,
        "accuracy": 0.017051,
        "main_score": 0.003568,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.000696,
        "recall": 0.003953,
        "f1": 0.000997,
        "accuracy": 0.003953,
        "main_score": 0.000997,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032195,
        "recall": 0.064229,
        "f1": 0.036771,
        "accuracy": 0.064229,
        "main_score": 0.036771,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.011671,
        "recall": 0.018775,
        "f1": 0.012636,
        "accuracy": 0.018775,
        "main_score": 0.012636,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017504,
        "recall": 0.05336,
        "f1": 0.022291,
        "accuracy": 0.05336,
        "main_score": 0.022291,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.01589,
        "recall": 0.021739,
        "f1": 0.016748,
        "accuracy": 0.021739,
        "main_score": 0.016748,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045946,
        "recall": 0.085968,
        "f1": 0.053224,
        "accuracy": 0.085968,
        "main_score": 0.053224,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.017201,
        "recall": 0.025692,
        "f1": 0.018621,
        "accuracy": 0.025692,
        "main_score": 0.018621,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027736,
        "recall": 0.072134,
        "f1": 0.033628,
        "accuracy": 0.072134,
        "main_score": 0.033628,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.015125,
        "recall": 0.019763,
        "f1": 0.015687,
        "accuracy": 0.019763,
        "main_score": 0.015687,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018429,
        "recall": 0.052372,
        "f1": 0.02263,
        "accuracy": 0.052372,
        "main_score": 0.02263,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.011919,
        "recall": 0.017787,
        "f1": 0.012752,
        "accuracy": 0.017787,
        "main_score": 0.012752,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.044026,
        "recall": 0.089921,
        "f1": 0.051941,
        "accuracy": 0.089921,
        "main_score": 0.051941,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.013722,
        "recall": 0.018775,
        "f1": 0.014194,
        "accuracy": 0.018775,
        "main_score": 0.014194,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.043751,
        "recall": 0.088933,
        "f1": 0.051076,
        "accuracy": 0.088933,
        "main_score": 0.051076,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.048731,
        "recall": 0.060277,
        "f1": 0.050647,
        "accuracy": 0.060277,
        "main_score": 0.050647,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040235,
        "recall": 0.104743,
        "f1": 0.049951,
        "accuracy": 0.104743,
        "main_score": 0.049951,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003987,
        "recall": 0.006917,
        "f1": 0.00445,
        "accuracy": 0.006917,
        "main_score": 0.00445,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030534,
        "recall": 0.064229,
        "f1": 0.035762,
        "accuracy": 0.064229,
        "main_score": 0.035762,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002966,
        "recall": 0.003953,
        "f1": 0.002967,
        "accuracy": 0.003953,
        "main_score": 0.002967,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021507,
        "recall": 0.050395,
        "f1": 0.025818,
        "accuracy": 0.050395,
        "main_score": 0.025818,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023634,
        "recall": 0.031621,
        "f1": 0.024833,
        "accuracy": 0.031621,
        "main_score": 0.024833,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.058137,
        "recall": 0.110672,
        "f1": 0.067352,
        "accuracy": 0.110672,
        "main_score": 0.067352,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.02547,
        "recall": 0.031621,
        "f1": 0.026297,
        "accuracy": 0.031621,
        "main_score": 0.026297,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060984,
        "recall": 0.115613,
        "f1": 0.070656,
        "accuracy": 0.115613,
        "main_score": 0.070656,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.009685,
        "recall": 0.017787,
        "f1": 0.010532,
        "accuracy": 0.017787,
        "main_score": 0.010532,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037321,
        "recall": 0.081028,
        "f1": 0.043402,
        "accuracy": 0.081028,
        "main_score": 0.043402,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.013136,
        "recall": 0.017787,
        "f1": 0.013741,
        "accuracy": 0.017787,
        "main_score": 0.013741,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031379,
        "recall": 0.068182,
        "f1": 0.036174,
        "accuracy": 0.068182,
        "main_score": 0.036174,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.039156,
        "recall": 0.041502,
        "f1": 0.039418,
        "accuracy": 0.041502,
        "main_score": 0.039418,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.071678,
        "recall": 0.146245,
        "f1": 0.084238,
        "accuracy": 0.146245,
        "main_score": 0.084238,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.023348,
        "recall": 0.027668,
        "f1": 0.024031,
        "accuracy": 0.027668,
        "main_score": 0.024031,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042287,
        "recall": 0.090909,
        "f1": 0.050335,
        "accuracy": 0.090909,
        "main_score": 0.050335,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005635,
        "recall": 0.008893,
        "f1": 0.005959,
        "accuracy": 0.008893,
        "main_score": 0.005959,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.053234,
        "recall": 0.08498,
        "f1": 0.058316,
        "accuracy": 0.08498,
        "main_score": 0.058316,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.002681,
        "recall": 0.006917,
        "f1": 0.003335,
        "accuracy": 0.006917,
        "main_score": 0.003335,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040011,
        "recall": 0.06917,
        "f1": 0.045914,
        "accuracy": 0.06917,
        "main_score": 0.045914,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.002911,
        "recall": 0.005929,
        "f1": 0.00333,
        "accuracy": 0.005929,
        "main_score": 0.00333,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020385,
        "recall": 0.044466,
        "f1": 0.024147,
        "accuracy": 0.044466,
        "main_score": 0.024147,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.006074,
        "recall": 0.009881,
        "f1": 0.006526,
        "accuracy": 0.009881,
        "main_score": 0.006526,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.049816,
        "recall": 0.090909,
        "f1": 0.056828,
        "accuracy": 0.090909,
        "main_score": 0.056828,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.006536,
        "recall": 0.009881,
        "f1": 0.006801,
        "accuracy": 0.009881,
        "main_score": 0.006801,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039263,
        "recall": 0.079051,
        "f1": 0.045824,
        "accuracy": 0.079051,
        "main_score": 0.045824,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.02567,
        "recall": 0.036561,
        "f1": 0.027625,
        "accuracy": 0.036561,
        "main_score": 0.027625,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.081931,
        "recall": 0.140316,
        "f1": 0.09157,
        "accuracy": 0.140316,
        "main_score": 0.09157,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001625,
        "recall": 0.004941,
        "f1": 0.002014,
        "accuracy": 0.004941,
        "main_score": 0.002014,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042054,
        "recall": 0.070158,
        "f1": 0.046917,
        "accuracy": 0.070158,
        "main_score": 0.046917,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.011955,
        "recall": 0.017787,
        "f1": 0.012827,
        "accuracy": 0.017787,
        "main_score": 0.012827,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.062908,
        "recall": 0.115613,
        "f1": 0.071435,
        "accuracy": 0.115613,
        "main_score": 0.071435,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.007534,
        "recall": 0.012846,
        "f1": 0.008253,
        "accuracy": 0.012846,
        "main_score": 0.008253,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.062045,
        "recall": 0.105731,
        "f1": 0.069404,
        "accuracy": 0.105731,
        "main_score": 0.069404,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.004122,
        "recall": 0.007905,
        "f1": 0.004573,
        "accuracy": 0.007905,
        "main_score": 0.004573,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030979,
        "recall": 0.068182,
        "f1": 0.036141,
        "accuracy": 0.068182,
        "main_score": 0.036141,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.005475,
        "recall": 0.007905,
        "f1": 0.005678,
        "accuracy": 0.007905,
        "main_score": 0.005678,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042272,
        "recall": 0.077075,
        "f1": 0.048365,
        "accuracy": 0.077075,
        "main_score": 0.048365,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.008011,
        "recall": 0.012846,
        "f1": 0.008765,
        "accuracy": 0.012846,
        "main_score": 0.008765,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.051846,
        "recall": 0.097826,
        "f1": 0.059549,
        "accuracy": 0.097826,
        "main_score": 0.059549,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.000991,
        "accuracy": 0.001976,
        "main_score": 0.000991,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005641,
        "recall": 0.020751,
        "f1": 0.007077,
        "accuracy": 0.020751,
        "main_score": 0.007077,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 4382.177046775818,
  "kg_co2_emissions": null
}