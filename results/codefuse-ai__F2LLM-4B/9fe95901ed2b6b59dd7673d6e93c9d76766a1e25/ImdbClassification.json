{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_version": "1.38.54",
  "scores": {
    "test": [
      {
        "accuracy": 0.968752,
        "f1": 0.968748,
        "f1_weighted": 0.968748,
        "ap": 0.950066,
        "ap_weighted": 0.950066,
        "scores_per_experiment": [
          {
            "accuracy": 0.96964,
            "f1": 0.96964,
            "f1_weighted": 0.96964,
            "ap": 0.954871,
            "ap_weighted": 0.954871
          },
          {
            "accuracy": 0.96976,
            "f1": 0.96976,
            "f1_weighted": 0.96976,
            "ap": 0.954012,
            "ap_weighted": 0.954012
          },
          {
            "accuracy": 0.96924,
            "f1": 0.969236,
            "f1_weighted": 0.969236,
            "ap": 0.950134,
            "ap_weighted": 0.950134
          },
          {
            "accuracy": 0.96956,
            "f1": 0.969559,
            "f1_weighted": 0.969559,
            "ap": 0.953187,
            "ap_weighted": 0.953187
          },
          {
            "accuracy": 0.96924,
            "f1": 0.969238,
            "f1_weighted": 0.969238,
            "ap": 0.951766,
            "ap_weighted": 0.951766
          },
          {
            "accuracy": 0.96992,
            "f1": 0.969917,
            "f1_weighted": 0.969917,
            "ap": 0.951591,
            "ap_weighted": 0.951591
          },
          {
            "accuracy": 0.966,
            "f1": 0.965987,
            "f1_weighted": 0.965987,
            "ap": 0.941965,
            "ap_weighted": 0.941965
          },
          {
            "accuracy": 0.9678,
            "f1": 0.967793,
            "f1_weighted": 0.967793,
            "ap": 0.946264,
            "ap_weighted": 0.946264
          },
          {
            "accuracy": 0.96676,
            "f1": 0.96675,
            "f1_weighted": 0.96675,
            "ap": 0.943853,
            "ap_weighted": 0.943853
          },
          {
            "accuracy": 0.9696,
            "f1": 0.969599,
            "f1_weighted": 0.969599,
            "ap": 0.95302,
            "ap_weighted": 0.95302
          }
        ],
        "main_score": 0.968752,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 958.1978635787964,
  "kg_co2_emissions": null
}