{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.01709,
        "f1": 0.006929,
        "f1_weighted": 0.009613,
        "scores_per_experiment": [
          {
            "accuracy": 0.016113,
            "f1": 0.005237,
            "f1_weighted": 0.006737
          },
          {
            "accuracy": 0.015137,
            "f1": 0.00813,
            "f1_weighted": 0.010398
          },
          {
            "accuracy": 0.018555,
            "f1": 0.008749,
            "f1_weighted": 0.009892
          },
          {
            "accuracy": 0.012207,
            "f1": 0.004022,
            "f1_weighted": 0.005951
          },
          {
            "accuracy": 0.015625,
            "f1": 0.007567,
            "f1_weighted": 0.008439
          },
          {
            "accuracy": 0.019531,
            "f1": 0.004537,
            "f1_weighted": 0.010594
          },
          {
            "accuracy": 0.016113,
            "f1": 0.005725,
            "f1_weighted": 0.008022
          },
          {
            "accuracy": 0.022949,
            "f1": 0.010314,
            "f1_weighted": 0.01548
          },
          {
            "accuracy": 0.016113,
            "f1": 0.007857,
            "f1_weighted": 0.009949
          },
          {
            "accuracy": 0.018555,
            "f1": 0.007149,
            "f1_weighted": 0.010671
          }
        ],
        "main_score": 0.01709,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.015576,
        "f1": 0.005162,
        "f1_weighted": 0.006982,
        "scores_per_experiment": [
          {
            "accuracy": 0.021484,
            "f1": 0.005965,
            "f1_weighted": 0.006718
          },
          {
            "accuracy": 0.018066,
            "f1": 0.009225,
            "f1_weighted": 0.010017
          },
          {
            "accuracy": 0.012695,
            "f1": 0.004603,
            "f1_weighted": 0.006468
          },
          {
            "accuracy": 0.013184,
            "f1": 0.004255,
            "f1_weighted": 0.005375
          },
          {
            "accuracy": 0.01416,
            "f1": 0.005682,
            "f1_weighted": 0.007484
          },
          {
            "accuracy": 0.016113,
            "f1": 0.003055,
            "f1_weighted": 0.005473
          },
          {
            "accuracy": 0.016113,
            "f1": 0.002803,
            "f1_weighted": 0.007713
          },
          {
            "accuracy": 0.013672,
            "f1": 0.005593,
            "f1_weighted": 0.00706
          },
          {
            "accuracy": 0.013672,
            "f1": 0.003905,
            "f1_weighted": 0.004866
          },
          {
            "accuracy": 0.016602,
            "f1": 0.006534,
            "f1_weighted": 0.008649
          }
        ],
        "main_score": 0.015576,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 469.5772488117218,
  "kg_co2_emissions": 0.03260418478478232
}