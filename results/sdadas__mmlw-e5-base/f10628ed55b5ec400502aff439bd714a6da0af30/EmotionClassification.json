{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.52925,
        "f1": 0.488843,
        "f1_weighted": 0.545265,
        "scores_per_experiment": [
          {
            "accuracy": 0.554,
            "f1": 0.510318,
            "f1_weighted": 0.569707
          },
          {
            "accuracy": 0.5375,
            "f1": 0.487765,
            "f1_weighted": 0.549436
          },
          {
            "accuracy": 0.5355,
            "f1": 0.483784,
            "f1_weighted": 0.551446
          },
          {
            "accuracy": 0.5195,
            "f1": 0.482027,
            "f1_weighted": 0.543912
          },
          {
            "accuracy": 0.5635,
            "f1": 0.52559,
            "f1_weighted": 0.581471
          },
          {
            "accuracy": 0.5175,
            "f1": 0.482668,
            "f1_weighted": 0.532111
          },
          {
            "accuracy": 0.5495,
            "f1": 0.495654,
            "f1_weighted": 0.563747
          },
          {
            "accuracy": 0.5,
            "f1": 0.468835,
            "f1_weighted": 0.511941
          },
          {
            "accuracy": 0.531,
            "f1": 0.493795,
            "f1_weighted": 0.546456
          },
          {
            "accuracy": 0.4845,
            "f1": 0.457995,
            "f1_weighted": 0.502421
          }
        ],
        "main_score": 0.52925,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.53035,
        "f1": 0.482199,
        "f1_weighted": 0.549608,
        "scores_per_experiment": [
          {
            "accuracy": 0.5575,
            "f1": 0.506265,
            "f1_weighted": 0.578181
          },
          {
            "accuracy": 0.53,
            "f1": 0.480506,
            "f1_weighted": 0.543028
          },
          {
            "accuracy": 0.527,
            "f1": 0.476162,
            "f1_weighted": 0.545036
          },
          {
            "accuracy": 0.5105,
            "f1": 0.464491,
            "f1_weighted": 0.538835
          },
          {
            "accuracy": 0.564,
            "f1": 0.51574,
            "f1_weighted": 0.583724
          },
          {
            "accuracy": 0.527,
            "f1": 0.472325,
            "f1_weighted": 0.546514
          },
          {
            "accuracy": 0.5375,
            "f1": 0.48409,
            "f1_weighted": 0.552293
          },
          {
            "accuracy": 0.5085,
            "f1": 0.465097,
            "f1_weighted": 0.524695
          },
          {
            "accuracy": 0.539,
            "f1": 0.491127,
            "f1_weighted": 0.55804
          },
          {
            "accuracy": 0.5025,
            "f1": 0.466185,
            "f1_weighted": 0.52573
          }
        ],
        "main_score": 0.53035,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.794157981872559,
  "kg_co2_emissions": 0.0005071249515944763
}