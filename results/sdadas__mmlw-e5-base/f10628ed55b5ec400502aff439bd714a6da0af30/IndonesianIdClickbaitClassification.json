{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.586865,
        "f1": 0.578081,
        "f1_weighted": 0.583935,
        "ap": 0.472595,
        "ap_weighted": 0.472595,
        "scores_per_experiment": [
          {
            "accuracy": 0.653809,
            "f1": 0.635331,
            "f1_weighted": 0.648558,
            "ap": 0.513258,
            "ap_weighted": 0.513258
          },
          {
            "accuracy": 0.56543,
            "f1": 0.563389,
            "f1_weighted": 0.55858,
            "ap": 0.471492,
            "ap_weighted": 0.471492
          },
          {
            "accuracy": 0.587402,
            "f1": 0.567909,
            "f1_weighted": 0.582697,
            "ap": 0.459599,
            "ap_weighted": 0.459599
          },
          {
            "accuracy": 0.57959,
            "f1": 0.579368,
            "f1_weighted": 0.577813,
            "ap": 0.476721,
            "ap_weighted": 0.476721
          },
          {
            "accuracy": 0.589844,
            "f1": 0.586651,
            "f1_weighted": 0.592505,
            "ap": 0.473276,
            "ap_weighted": 0.473276
          },
          {
            "accuracy": 0.549316,
            "f1": 0.53172,
            "f1_weighted": 0.546347,
            "ap": 0.436452,
            "ap_weighted": 0.436452
          },
          {
            "accuracy": 0.600098,
            "f1": 0.599643,
            "f1_weighted": 0.601817,
            "ap": 0.48589,
            "ap_weighted": 0.48589
          },
          {
            "accuracy": 0.603516,
            "f1": 0.603128,
            "f1_weighted": 0.605126,
            "ap": 0.488645,
            "ap_weighted": 0.488645
          },
          {
            "accuracy": 0.605469,
            "f1": 0.580886,
            "f1_weighted": 0.597241,
            "ap": 0.470259,
            "ap_weighted": 0.470259
          },
          {
            "accuracy": 0.53418,
            "f1": 0.532782,
            "f1_weighted": 0.528665,
            "ap": 0.45036,
            "ap_weighted": 0.45036
          }
        ],
        "main_score": 0.578081,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.858134031295776,
  "kg_co2_emissions": 0.0002363954056247476
}