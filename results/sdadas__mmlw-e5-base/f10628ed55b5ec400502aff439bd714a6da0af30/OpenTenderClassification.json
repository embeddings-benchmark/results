{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.315942,
            "f1": 0.311916,
            "f1_weighted": 0.311871,
            "precision": 0.318371,
            "precision_weighted": 0.318318,
            "recall": 0.315984,
            "recall_weighted": 0.315942,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.303679,
            "f1": 0.304317,
            "f1_weighted": 0.304233,
            "precision": 0.31417,
            "precision_weighted": 0.314073,
            "recall": 0.303753,
            "recall_weighted": 0.303679,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.315719,
            "f1": 0.316226,
            "f1_weighted": 0.3162,
            "precision": 0.325045,
            "precision_weighted": 0.325023,
            "recall": 0.315746,
            "recall_weighted": 0.315719,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.301226,
            "f1": 0.302127,
            "f1_weighted": 0.302086,
            "precision": 0.312704,
            "precision_weighted": 0.312711,
            "recall": 0.301312,
            "recall_weighted": 0.301226,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.278484,
            "f1": 0.276181,
            "f1_weighted": 0.27617,
            "precision": 0.282796,
            "precision_weighted": 0.28277,
            "recall": 0.278494,
            "recall_weighted": 0.278484,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.298105,
            "f1": 0.301249,
            "f1_weighted": 0.301137,
            "precision": 0.320442,
            "precision_weighted": 0.320255,
            "recall": 0.298168,
            "recall_weighted": 0.298105,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.296544,
            "f1": 0.293308,
            "f1_weighted": 0.293268,
            "precision": 0.30339,
            "precision_weighted": 0.303286,
            "recall": 0.296525,
            "recall_weighted": 0.296544,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.287179,
            "f1": 0.286857,
            "f1_weighted": 0.286694,
            "precision": 0.296958,
            "precision_weighted": 0.296799,
            "recall": 0.287354,
            "recall_weighted": 0.287179,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.276923,
            "f1": 0.276377,
            "f1_weighted": 0.276305,
            "precision": 0.294823,
            "precision_weighted": 0.294666,
            "recall": 0.276932,
            "recall_weighted": 0.276923,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.296544,
            "f1": 0.297906,
            "f1_weighted": 0.297857,
            "precision": 0.306617,
            "precision_weighted": 0.306503,
            "recall": 0.296536,
            "recall_weighted": 0.296544,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.297035,
        "f1": 0.296646,
        "f1_weighted": 0.296582,
        "precision": 0.307532,
        "precision_weighted": 0.30744,
        "recall": 0.29708,
        "recall_weighted": 0.297035,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.296646,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 63.72091770172119,
  "kg_co2_emissions": null
}