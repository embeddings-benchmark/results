{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.702979,
        "f1": 0.701188,
        "f1_weighted": 0.701216,
        "ap": 0.642891,
        "ap_weighted": 0.642891,
        "scores_per_experiment": [
          {
            "accuracy": 0.693848,
            "f1": 0.682511,
            "f1_weighted": 0.682687,
            "ap": 0.625209,
            "ap_weighted": 0.625209
          },
          {
            "accuracy": 0.704102,
            "f1": 0.704067,
            "f1_weighted": 0.704077,
            "ap": 0.64427,
            "ap_weighted": 0.64427
          },
          {
            "accuracy": 0.673828,
            "f1": 0.67308,
            "f1_weighted": 0.673125,
            "ap": 0.615838,
            "ap_weighted": 0.615838
          },
          {
            "accuracy": 0.70459,
            "f1": 0.704574,
            "f1_weighted": 0.704568,
            "ap": 0.646265,
            "ap_weighted": 0.646265
          },
          {
            "accuracy": 0.738281,
            "f1": 0.738209,
            "f1_weighted": 0.738222,
            "ap": 0.675511,
            "ap_weighted": 0.675511
          },
          {
            "accuracy": 0.687012,
            "f1": 0.686365,
            "f1_weighted": 0.686407,
            "ap": 0.626916,
            "ap_weighted": 0.626916
          },
          {
            "accuracy": 0.716797,
            "f1": 0.712986,
            "f1_weighted": 0.713083,
            "ap": 0.647756,
            "ap_weighted": 0.647756
          },
          {
            "accuracy": 0.706543,
            "f1": 0.706315,
            "f1_weighted": 0.706292,
            "ap": 0.65,
            "ap_weighted": 0.65
          },
          {
            "accuracy": 0.674316,
            "f1": 0.674027,
            "f1_weighted": 0.673999,
            "ap": 0.62102,
            "ap_weighted": 0.62102
          },
          {
            "accuracy": 0.730469,
            "f1": 0.729745,
            "f1_weighted": 0.729704,
            "ap": 0.676127,
            "ap_weighted": 0.676127
          }
        ],
        "main_score": 0.702979,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.708203,
        "f1": 0.706509,
        "f1_weighted": 0.706525,
        "ap": 0.647066,
        "ap_weighted": 0.647066,
        "scores_per_experiment": [
          {
            "accuracy": 0.710449,
            "f1": 0.699727,
            "f1_weighted": 0.699838,
            "ap": 0.63803,
            "ap_weighted": 0.63803
          },
          {
            "accuracy": 0.702148,
            "f1": 0.702144,
            "f1_weighted": 0.702142,
            "ap": 0.643246,
            "ap_weighted": 0.643246
          },
          {
            "accuracy": 0.687012,
            "f1": 0.686569,
            "f1_weighted": 0.686592,
            "ap": 0.626945,
            "ap_weighted": 0.626945
          },
          {
            "accuracy": 0.709961,
            "f1": 0.709961,
            "f1_weighted": 0.70996,
            "ap": 0.650131,
            "ap_weighted": 0.650131
          },
          {
            "accuracy": 0.737793,
            "f1": 0.737754,
            "f1_weighted": 0.73776,
            "ap": 0.675047,
            "ap_weighted": 0.675047
          },
          {
            "accuracy": 0.6875,
            "f1": 0.686973,
            "f1_weighted": 0.686998,
            "ap": 0.627147,
            "ap_weighted": 0.627147
          },
          {
            "accuracy": 0.71875,
            "f1": 0.714965,
            "f1_weighted": 0.715029,
            "ap": 0.649035,
            "ap_weighted": 0.649035
          },
          {
            "accuracy": 0.731445,
            "f1": 0.731321,
            "f1_weighted": 0.73131,
            "ap": 0.672719,
            "ap_weighted": 0.672719
          },
          {
            "accuracy": 0.681641,
            "f1": 0.68131,
            "f1_weighted": 0.68129,
            "ap": 0.627126,
            "ap_weighted": 0.627126
          },
          {
            "accuracy": 0.715332,
            "f1": 0.714368,
            "f1_weighted": 0.714335,
            "ap": 0.661235,
            "ap_weighted": 0.661235
          }
        ],
        "main_score": 0.708203,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.716292142868042,
  "kg_co2_emissions": 0.0006014759066558498
}