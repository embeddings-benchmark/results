{
  "dataset_revision": "23a20c659d868740ef9c54854de631fe19cd5c17",
  "task_name": "CSFDSKMovieReviewSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.187109,
        "f1": 0.185367,
        "f1_weighted": 0.18561,
        "scores_per_experiment": [
          {
            "accuracy": 0.17334,
            "f1": 0.173259,
            "f1_weighted": 0.174019
          },
          {
            "accuracy": 0.204102,
            "f1": 0.201891,
            "f1_weighted": 0.202302
          },
          {
            "accuracy": 0.174805,
            "f1": 0.173186,
            "f1_weighted": 0.172977
          },
          {
            "accuracy": 0.187012,
            "f1": 0.182529,
            "f1_weighted": 0.182366
          },
          {
            "accuracy": 0.177734,
            "f1": 0.173003,
            "f1_weighted": 0.173663
          },
          {
            "accuracy": 0.180176,
            "f1": 0.17972,
            "f1_weighted": 0.180195
          },
          {
            "accuracy": 0.186035,
            "f1": 0.185273,
            "f1_weighted": 0.185259
          },
          {
            "accuracy": 0.189453,
            "f1": 0.189184,
            "f1_weighted": 0.189099
          },
          {
            "accuracy": 0.195801,
            "f1": 0.194495,
            "f1_weighted": 0.194596
          },
          {
            "accuracy": 0.202637,
            "f1": 0.201132,
            "f1_weighted": 0.201624
          }
        ],
        "main_score": 0.187109,
        "hf_subset": "default",
        "languages": [
          "slk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 38.63259291648865,
  "kg_co2_emissions": 0.0019178531396315732
}