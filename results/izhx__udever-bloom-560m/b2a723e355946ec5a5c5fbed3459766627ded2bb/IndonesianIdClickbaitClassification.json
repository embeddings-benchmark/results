{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.562646,
        "f1": 0.558457,
        "f1_weighted": 0.562692,
        "ap": 0.458185,
        "ap_weighted": 0.458185,
        "scores_per_experiment": [
          {
            "accuracy": 0.611328,
            "f1": 0.605159,
            "f1_weighted": 0.613111,
            "ap": 0.485715,
            "ap_weighted": 0.485715
          },
          {
            "accuracy": 0.548828,
            "f1": 0.546946,
            "f1_weighted": 0.551651,
            "ap": 0.4482,
            "ap_weighted": 0.4482
          },
          {
            "accuracy": 0.522949,
            "f1": 0.516802,
            "f1_weighted": 0.525584,
            "ap": 0.428714,
            "ap_weighted": 0.428714
          },
          {
            "accuracy": 0.556152,
            "f1": 0.555588,
            "f1_weighted": 0.55814,
            "ap": 0.455524,
            "ap_weighted": 0.455524
          },
          {
            "accuracy": 0.557129,
            "f1": 0.549931,
            "f1_weighted": 0.540759,
            "ap": 0.471581,
            "ap_weighted": 0.471581
          },
          {
            "accuracy": 0.5625,
            "f1": 0.559017,
            "f1_weighted": 0.565332,
            "ap": 0.45455,
            "ap_weighted": 0.45455
          },
          {
            "accuracy": 0.584473,
            "f1": 0.576384,
            "f1_weighted": 0.585816,
            "ap": 0.464645,
            "ap_weighted": 0.464645
          },
          {
            "accuracy": 0.548828,
            "f1": 0.547221,
            "f1_weighted": 0.551567,
            "ap": 0.448658,
            "ap_weighted": 0.448658
          },
          {
            "accuracy": 0.606934,
            "f1": 0.60024,
            "f1_weighted": 0.608575,
            "ap": 0.481932,
            "ap_weighted": 0.481932
          },
          {
            "accuracy": 0.527344,
            "f1": 0.527279,
            "f1_weighted": 0.526386,
            "ap": 0.442334,
            "ap_weighted": 0.442334
          }
        ],
        "main_score": 0.558457,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.642752647399902,
  "kg_co2_emissions": 0.00029136385000735356
}