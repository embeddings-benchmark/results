{
  "dataset_revision": "e254179d18ab0165fdb6dbef91178266222bee2a",
  "task_name": "NordicLangClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.490833,
        "f1": 0.487881,
        "f1_weighted": 0.489937,
        "scores_per_experiment": [
          {
            "accuracy": 0.505667,
            "f1": 0.509095,
            "f1_weighted": 0.511574
          },
          {
            "accuracy": 0.511333,
            "f1": 0.510754,
            "f1_weighted": 0.513454
          },
          {
            "accuracy": 0.501,
            "f1": 0.502211,
            "f1_weighted": 0.503439
          },
          {
            "accuracy": 0.498667,
            "f1": 0.492865,
            "f1_weighted": 0.494781
          },
          {
            "accuracy": 0.495333,
            "f1": 0.490033,
            "f1_weighted": 0.492915
          },
          {
            "accuracy": 0.522667,
            "f1": 0.512741,
            "f1_weighted": 0.515418
          },
          {
            "accuracy": 0.477333,
            "f1": 0.474337,
            "f1_weighted": 0.47651
          },
          {
            "accuracy": 0.464333,
            "f1": 0.454555,
            "f1_weighted": 0.457357
          },
          {
            "accuracy": 0.463333,
            "f1": 0.468619,
            "f1_weighted": 0.469535
          },
          {
            "accuracy": 0.468667,
            "f1": 0.463599,
            "f1_weighted": 0.464391
          }
        ],
        "main_score": 0.490833,
        "hf_subset": "default",
        "languages": [
          "nob-Latn",
          "nno-Latn",
          "dan-Latn",
          "swe-Latn",
          "isl-Latn",
          "fao-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.531627893447876,
  "kg_co2_emissions": 0.0006371703101324576
}