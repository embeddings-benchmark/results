{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.4329186281102892,
                "f1": 0.4183461350696014,
                "main_score": 0.4329186281102892
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.23214525891055815,
                "f1": 0.22364131190189962,
                "main_score": 0.23214525891055815
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.5338264963012778,
                "f1": 0.5074546702709091,
                "main_score": 0.5338264963012778
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3955951580363147,
                "f1": 0.3907769075741216,
                "main_score": 0.3955951580363147
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.5673839946200403,
                "f1": 0.5436728741542025,
                "main_score": 0.5673839946200403
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.39996637525218565,
                "f1": 0.387098179536526,
                "main_score": 0.39996637525218565
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.46933422999327506,
                "f1": 0.45320226798957625,
                "main_score": 0.46933422999327506
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.45820443846671155,
                "f1": 0.42853155158197886,
                "main_score": 0.45820443846671155
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.37874915938130466,
                "f1": 0.359849010888881,
                "main_score": 0.37874915938130466
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6608944182918628,
                "f1": 0.645039080809391,
                "main_score": 0.6608944182918628
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.6117350369872225,
                "f1": 0.600792530132073,
                "main_score": 0.6117350369872225
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.4565232010759919,
                "f1": 0.44281825542876246,
                "main_score": 0.4565232010759919
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.4028244788164088,
                "f1": 0.38799275248868365,
                "main_score": 0.4028244788164088
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.6260591795561533,
                "f1": 0.6101451309609411,
                "main_score": 0.6260591795561533
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.3222595830531272,
                "f1": 0.30903299940417905,
                "main_score": 0.3222595830531272
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.5946200403496974,
                "f1": 0.5734556231956784,
                "main_score": 0.5946200403496974
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.40907868190988567,
                "f1": 0.3974702259997524,
                "main_score": 0.40907868190988567
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.29939475453934095,
                "f1": 0.28462353413371355,
                "main_score": 0.29939475453934095
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.5914256893073302,
                "f1": 0.5724600767871435,
                "main_score": 0.5914256893073302
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.3962004034969738,
                "f1": 0.38414866180464735,
                "main_score": 0.3962004034969738
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.5177202420981842,
                "f1": 0.5105050942366993,
                "main_score": 0.5177202420981842
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.5374915938130463,
                "f1": 0.5204563008527909,
                "main_score": 0.5374915938130463
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.4629455279085406,
                "f1": 0.4384047527739209,
                "main_score": 0.4629455279085406
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.25107599193006047,
                "f1": 0.2458731463875415,
                "main_score": 0.25107599193006047
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.2721923335574984,
                "f1": 0.25964338481976795,
                "main_score": 0.2721923335574984
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.4796906523201077,
                "f1": 0.45322394084355777,
                "main_score": 0.4796906523201077
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.4053799596503026,
                "f1": 0.3915655510771227,
                "main_score": 0.4053799596503026
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.43140551445864156,
                "f1": 0.42122327330951626,
                "main_score": 0.43140551445864156
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.5369199731002017,
                "f1": 0.5067085509122796,
                "main_score": 0.5369199731002017
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.3337256220578346,
                "f1": 0.3339335560955231,
                "main_score": 0.3337256220578346
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.5194014794889038,
                "f1": 0.506207021226521,
                "main_score": 0.5194014794889038
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.2532279757901816,
                "f1": 0.2394164121951907,
                "main_score": 0.2532279757901816
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.4411903160726294,
                "f1": 0.43016752983579537,
                "main_score": 0.4411903160726294
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.4403496973772697,
                "f1": 0.42322828283176755,
                "main_score": 0.4403496973772697
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.4163080026899798,
                "f1": 0.39588246449781656,
                "main_score": 0.4163080026899798
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.617350369872226,
                "f1": 0.5995675220607939,
                "main_score": 0.617350369872226
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.45726294552790864,
                "f1": 0.44731249269647827,
                "main_score": 0.45726294552790864
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.4761264290517822,
                "f1": 0.455280995218491,
                "main_score": 0.4761264290517822
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.42827841291190316,
                "f1": 0.4137165985220223,
                "main_score": 0.42827841291190316
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.4361466039004707,
                "f1": 0.43164498227815534,
                "main_score": 0.4361466039004707
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.4464021519838602,
                "f1": 0.4304775030948548,
                "main_score": 0.4464021519838602
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.45548083389374583,
                "f1": 0.4401167763377998,
                "main_score": 0.45548083389374583
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.512441156691325,
                "f1": 0.48735929324038113,
                "main_score": 0.512441156691325
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.47434431741761945,
                "f1": 0.45086865988914565,
                "main_score": 0.47434431741761945
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.3687962340282448,
                "f1": 0.36505408647569676,
                "main_score": 0.3687962340282448
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.45928043039677197,
                "f1": 0.4457216865343283,
                "main_score": 0.45928043039677197
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.38591123066577,
                "f1": 0.37886312373767445,
                "main_score": 0.38591123066577
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.5185272360457296,
                "f1": 0.4943461566216979,
                "main_score": 0.5185272360457296
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.5872225958305313,
                "f1": 0.5695500715299434,
                "main_score": 0.5872225958305313
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.6374915938130464,
                "f1": 0.6235543158488615,
                "main_score": 0.6374915938130464
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.5995292535305985,
                "f1": 0.5973499569346673,
                "main_score": 0.5995292535305985
            }
        ]
    }
}