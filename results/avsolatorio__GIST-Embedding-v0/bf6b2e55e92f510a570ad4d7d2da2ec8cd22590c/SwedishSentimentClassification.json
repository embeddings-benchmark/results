{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.665479,
        "f1": 0.662426,
        "f1_weighted": 0.662417,
        "ap": 0.612427,
        "ap_weighted": 0.612427,
        "scores_per_experiment": [
          {
            "accuracy": 0.722656,
            "f1": 0.72064,
            "f1_weighted": 0.720709,
            "ap": 0.654935,
            "ap_weighted": 0.654935
          },
          {
            "accuracy": 0.666504,
            "f1": 0.665981,
            "f1_weighted": 0.66602,
            "ap": 0.610313,
            "ap_weighted": 0.610313
          },
          {
            "accuracy": 0.59668,
            "f1": 0.584688,
            "f1_weighted": 0.584481,
            "ap": 0.564384,
            "ap_weighted": 0.564384
          },
          {
            "accuracy": 0.653809,
            "f1": 0.652896,
            "f1_weighted": 0.652844,
            "ap": 0.604868,
            "ap_weighted": 0.604868
          },
          {
            "accuracy": 0.683105,
            "f1": 0.680266,
            "f1_weighted": 0.680178,
            "ap": 0.634627,
            "ap_weighted": 0.634627
          },
          {
            "accuracy": 0.662109,
            "f1": 0.662109,
            "f1_weighted": 0.662109,
            "ap": 0.608803,
            "ap_weighted": 0.608803
          },
          {
            "accuracy": 0.714844,
            "f1": 0.711328,
            "f1_weighted": 0.711422,
            "ap": 0.646408,
            "ap_weighted": 0.646408
          },
          {
            "accuracy": 0.662598,
            "f1": 0.655547,
            "f1_weighted": 0.655692,
            "ap": 0.602994,
            "ap_weighted": 0.602994
          },
          {
            "accuracy": 0.625977,
            "f1": 0.6246,
            "f1_weighted": 0.624534,
            "ap": 0.58266,
            "ap_weighted": 0.58266
          },
          {
            "accuracy": 0.666504,
            "f1": 0.666208,
            "f1_weighted": 0.666179,
            "ap": 0.61428,
            "ap_weighted": 0.61428
          }
        ],
        "main_score": 0.665479,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.66084,
        "f1": 0.657574,
        "f1_weighted": 0.657568,
        "ap": 0.607744,
        "ap_weighted": 0.607744,
        "scores_per_experiment": [
          {
            "accuracy": 0.700684,
            "f1": 0.698167,
            "f1_weighted": 0.698221,
            "ap": 0.635215,
            "ap_weighted": 0.635215
          },
          {
            "accuracy": 0.675781,
            "f1": 0.674975,
            "f1_weighted": 0.675007,
            "ap": 0.616884,
            "ap_weighted": 0.616884
          },
          {
            "accuracy": 0.588379,
            "f1": 0.575479,
            "f1_weighted": 0.575335,
            "ap": 0.557434,
            "ap_weighted": 0.557434
          },
          {
            "accuracy": 0.660645,
            "f1": 0.659645,
            "f1_weighted": 0.659609,
            "ap": 0.610343,
            "ap_weighted": 0.610343
          },
          {
            "accuracy": 0.663574,
            "f1": 0.660496,
            "f1_weighted": 0.660433,
            "ap": 0.615999,
            "ap_weighted": 0.615999
          },
          {
            "accuracy": 0.662109,
            "f1": 0.662108,
            "f1_weighted": 0.662109,
            "ap": 0.608207,
            "ap_weighted": 0.608207
          },
          {
            "accuracy": 0.70752,
            "f1": 0.704675,
            "f1_weighted": 0.704731,
            "ap": 0.640563,
            "ap_weighted": 0.640563
          },
          {
            "accuracy": 0.678711,
            "f1": 0.670773,
            "f1_weighted": 0.670873,
            "ap": 0.614458,
            "ap_weighted": 0.614458
          },
          {
            "accuracy": 0.614258,
            "f1": 0.612929,
            "f1_weighted": 0.612885,
            "ap": 0.572985,
            "ap_weighted": 0.572985
          },
          {
            "accuracy": 0.656738,
            "f1": 0.656491,
            "f1_weighted": 0.656473,
            "ap": 0.605355,
            "ap_weighted": 0.605355
          }
        ],
        "main_score": 0.66084,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 18.49037766456604,
  "kg_co2_emissions": 0.000755730847880817
}