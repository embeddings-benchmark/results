{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.041992,
        "f1": 0.024576,
        "f1_weighted": 0.036594,
        "scores_per_experiment": [
          {
            "accuracy": 0.047363,
            "f1": 0.027239,
            "f1_weighted": 0.042931
          },
          {
            "accuracy": 0.041992,
            "f1": 0.023481,
            "f1_weighted": 0.037031
          },
          {
            "accuracy": 0.043945,
            "f1": 0.027909,
            "f1_weighted": 0.039893
          },
          {
            "accuracy": 0.033691,
            "f1": 0.018588,
            "f1_weighted": 0.027605
          },
          {
            "accuracy": 0.033691,
            "f1": 0.021037,
            "f1_weighted": 0.026851
          },
          {
            "accuracy": 0.042969,
            "f1": 0.026887,
            "f1_weighted": 0.040714
          },
          {
            "accuracy": 0.040527,
            "f1": 0.022202,
            "f1_weighted": 0.038813
          },
          {
            "accuracy": 0.041504,
            "f1": 0.022555,
            "f1_weighted": 0.032891
          },
          {
            "accuracy": 0.04541,
            "f1": 0.025698,
            "f1_weighted": 0.039178
          },
          {
            "accuracy": 0.048828,
            "f1": 0.030164,
            "f1_weighted": 0.04003
          }
        ],
        "main_score": 0.041992,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.037354,
        "f1": 0.021971,
        "f1_weighted": 0.02948,
        "scores_per_experiment": [
          {
            "accuracy": 0.040039,
            "f1": 0.022817,
            "f1_weighted": 0.033576
          },
          {
            "accuracy": 0.03125,
            "f1": 0.019638,
            "f1_weighted": 0.022195
          },
          {
            "accuracy": 0.034668,
            "f1": 0.026055,
            "f1_weighted": 0.026316
          },
          {
            "accuracy": 0.038574,
            "f1": 0.022097,
            "f1_weighted": 0.030853
          },
          {
            "accuracy": 0.032227,
            "f1": 0.016087,
            "f1_weighted": 0.024614
          },
          {
            "accuracy": 0.037109,
            "f1": 0.019368,
            "f1_weighted": 0.029701
          },
          {
            "accuracy": 0.036621,
            "f1": 0.019309,
            "f1_weighted": 0.028635
          },
          {
            "accuracy": 0.040527,
            "f1": 0.028636,
            "f1_weighted": 0.034811
          },
          {
            "accuracy": 0.038086,
            "f1": 0.018035,
            "f1_weighted": 0.025741
          },
          {
            "accuracy": 0.044434,
            "f1": 0.027668,
            "f1_weighted": 0.038358
          }
        ],
        "main_score": 0.037354,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 3152.225318670273,
  "kg_co2_emissions": 0.11443688263530173
}