{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.51975,
        "f1": 0.514043,
        "f1_weighted": 0.514043,
        "ap": 0.511631,
        "ap_weighted": 0.511631,
        "scores_per_experiment": [
          {
            "accuracy": 0.54,
            "f1": 0.533467,
            "f1_weighted": 0.533467,
            "ap": 0.521294,
            "ap_weighted": 0.521294
          },
          {
            "accuracy": 0.464167,
            "f1": 0.439651,
            "f1_weighted": 0.439651,
            "ap": 0.484291,
            "ap_weighted": 0.484291
          },
          {
            "accuracy": 0.533333,
            "f1": 0.530327,
            "f1_weighted": 0.530327,
            "ap": 0.517625,
            "ap_weighted": 0.517625
          },
          {
            "accuracy": 0.491667,
            "f1": 0.491667,
            "f1_weighted": 0.491667,
            "ap": 0.495903,
            "ap_weighted": 0.495903
          },
          {
            "accuracy": 0.593333,
            "f1": 0.588653,
            "f1_weighted": 0.588653,
            "ap": 0.55774,
            "ap_weighted": 0.55774
          },
          {
            "accuracy": 0.505833,
            "f1": 0.504716,
            "f1_weighted": 0.504716,
            "ap": 0.502948,
            "ap_weighted": 0.502948
          },
          {
            "accuracy": 0.528333,
            "f1": 0.520225,
            "f1_weighted": 0.520225,
            "ap": 0.514804,
            "ap_weighted": 0.514804
          },
          {
            "accuracy": 0.52,
            "f1": 0.519839,
            "f1_weighted": 0.519839,
            "ap": 0.510386,
            "ap_weighted": 0.510386
          },
          {
            "accuracy": 0.531667,
            "f1": 0.522973,
            "f1_weighted": 0.522973,
            "ap": 0.516623,
            "ap_weighted": 0.516623
          },
          {
            "accuracy": 0.489167,
            "f1": 0.488908,
            "f1_weighted": 0.488908,
            "ap": 0.494696,
            "ap_weighted": 0.494696
          }
        ],
        "main_score": 0.51975,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.52975,
        "f1": 0.5232,
        "f1_weighted": 0.5232,
        "ap": 0.517174,
        "ap_weighted": 0.517174,
        "scores_per_experiment": [
          {
            "accuracy": 0.53,
            "f1": 0.523515,
            "f1_weighted": 0.523515,
            "ap": 0.51573,
            "ap_weighted": 0.51573
          },
          {
            "accuracy": 0.461667,
            "f1": 0.433848,
            "f1_weighted": 0.433848,
            "ap": 0.483473,
            "ap_weighted": 0.483473
          },
          {
            "accuracy": 0.5625,
            "f1": 0.558445,
            "f1_weighted": 0.558445,
            "ap": 0.534528,
            "ap_weighted": 0.534528
          },
          {
            "accuracy": 0.5175,
            "f1": 0.517443,
            "f1_weighted": 0.517443,
            "ap": 0.509063,
            "ap_weighted": 0.509063
          },
          {
            "accuracy": 0.59,
            "f1": 0.584823,
            "f1_weighted": 0.584823,
            "ap": 0.555429,
            "ap_weighted": 0.555429
          },
          {
            "accuracy": 0.515,
            "f1": 0.514405,
            "f1_weighted": 0.514405,
            "ap": 0.50771,
            "ap_weighted": 0.50771
          },
          {
            "accuracy": 0.541667,
            "f1": 0.530876,
            "f1_weighted": 0.530876,
            "ap": 0.522165,
            "ap_weighted": 0.522165
          },
          {
            "accuracy": 0.524167,
            "f1": 0.524127,
            "f1_weighted": 0.524127,
            "ap": 0.512657,
            "ap_weighted": 0.512657
          },
          {
            "accuracy": 0.565833,
            "f1": 0.557048,
            "f1_weighted": 0.557048,
            "ap": 0.536298,
            "ap_weighted": 0.536298
          },
          {
            "accuracy": 0.489167,
            "f1": 0.487472,
            "f1_weighted": 0.487472,
            "ap": 0.494689,
            "ap_weighted": 0.494689
          }
        ],
        "main_score": 0.52975,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 32.57289242744446,
  "kg_co2_emissions": 0.0021700005550786914
}