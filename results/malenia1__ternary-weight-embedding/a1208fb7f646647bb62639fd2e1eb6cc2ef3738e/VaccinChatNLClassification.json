{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.294017,
            "f1": 0.305869,
            "f1_weighted": 0.288793,
            "precision": 0.295007,
            "precision_weighted": 0.416644,
            "recall": 0.435443,
            "recall_weighted": 0.294017,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.275214,
            "f1": 0.2939,
            "f1_weighted": 0.262903,
            "precision": 0.294331,
            "precision_weighted": 0.397842,
            "recall": 0.427532,
            "recall_weighted": 0.275214,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.294872,
            "f1": 0.299533,
            "f1_weighted": 0.285296,
            "precision": 0.281716,
            "precision_weighted": 0.389931,
            "recall": 0.438253,
            "recall_weighted": 0.294872,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.288889,
            "f1": 0.284929,
            "f1_weighted": 0.285772,
            "precision": 0.273889,
            "precision_weighted": 0.402215,
            "recall": 0.404908,
            "recall_weighted": 0.288889,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.295726,
            "f1": 0.304927,
            "f1_weighted": 0.295137,
            "precision": 0.298278,
            "precision_weighted": 0.444849,
            "recall": 0.437715,
            "recall_weighted": 0.295726,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.306838,
            "f1": 0.313222,
            "f1_weighted": 0.299139,
            "precision": 0.29888,
            "precision_weighted": 0.429023,
            "recall": 0.445972,
            "recall_weighted": 0.306838,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.283761,
            "f1": 0.289451,
            "f1_weighted": 0.268621,
            "precision": 0.273182,
            "precision_weighted": 0.35564,
            "recall": 0.419502,
            "recall_weighted": 0.283761,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.308547,
            "f1": 0.317831,
            "f1_weighted": 0.301135,
            "precision": 0.309105,
            "precision_weighted": 0.43225,
            "recall": 0.454718,
            "recall_weighted": 0.308547,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.286325,
            "f1": 0.299269,
            "f1_weighted": 0.271158,
            "precision": 0.286802,
            "precision_weighted": 0.352489,
            "recall": 0.440162,
            "recall_weighted": 0.286325,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.305128,
            "f1": 0.309867,
            "f1_weighted": 0.300616,
            "precision": 0.301427,
            "precision_weighted": 0.420049,
            "recall": 0.436483,
            "recall_weighted": 0.305128,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.293932,
        "f1": 0.30188,
        "f1_weighted": 0.285857,
        "precision": 0.291262,
        "precision_weighted": 0.404093,
        "recall": 0.434069,
        "recall_weighted": 0.293932,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.30188,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 100.4315574169159,
  "kg_co2_emissions": null
}