{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.657812,
        "f1": 0.655992,
        "f1_weighted": 0.656015,
        "ap": 0.605096,
        "ap_weighted": 0.605096,
        "scores_per_experiment": [
          {
            "accuracy": 0.651855,
            "f1": 0.651007,
            "f1_weighted": 0.651057,
            "ap": 0.598268,
            "ap_weighted": 0.598268
          },
          {
            "accuracy": 0.664551,
            "f1": 0.664484,
            "f1_weighted": 0.664497,
            "ap": 0.610039,
            "ap_weighted": 0.610039
          },
          {
            "accuracy": 0.663086,
            "f1": 0.654105,
            "f1_weighted": 0.654268,
            "ap": 0.602759,
            "ap_weighted": 0.602759
          },
          {
            "accuracy": 0.68457,
            "f1": 0.683132,
            "f1_weighted": 0.683194,
            "ap": 0.623601,
            "ap_weighted": 0.623601
          },
          {
            "accuracy": 0.609863,
            "f1": 0.606654,
            "f1_weighted": 0.60655,
            "ap": 0.571344,
            "ap_weighted": 0.571344
          },
          {
            "accuracy": 0.625,
            "f1": 0.624776,
            "f1_weighted": 0.624803,
            "ap": 0.578811,
            "ap_weighted": 0.578811
          },
          {
            "accuracy": 0.664062,
            "f1": 0.663647,
            "f1_weighted": 0.663612,
            "ap": 0.612547,
            "ap_weighted": 0.612547
          },
          {
            "accuracy": 0.665527,
            "f1": 0.665418,
            "f1_weighted": 0.6654,
            "ap": 0.612707,
            "ap_weighted": 0.612707
          },
          {
            "accuracy": 0.637695,
            "f1": 0.634938,
            "f1_weighted": 0.635031,
            "ap": 0.586274,
            "ap_weighted": 0.586274
          },
          {
            "accuracy": 0.711914,
            "f1": 0.711756,
            "f1_weighted": 0.711736,
            "ap": 0.654614,
            "ap_weighted": 0.654614
          }
        ],
        "main_score": 0.657812,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.6729,
        "f1": 0.670627,
        "f1_weighted": 0.670646,
        "ap": 0.616255,
        "ap_weighted": 0.616255,
        "scores_per_experiment": [
          {
            "accuracy": 0.663574,
            "f1": 0.662106,
            "f1_weighted": 0.66215,
            "ap": 0.606298,
            "ap_weighted": 0.606298
          },
          {
            "accuracy": 0.696777,
            "f1": 0.696254,
            "f1_weighted": 0.696279,
            "ap": 0.635045,
            "ap_weighted": 0.635045
          },
          {
            "accuracy": 0.674316,
            "f1": 0.66503,
            "f1_weighted": 0.665139,
            "ap": 0.610673,
            "ap_weighted": 0.610673
          },
          {
            "accuracy": 0.692871,
            "f1": 0.691237,
            "f1_weighted": 0.691281,
            "ap": 0.629761,
            "ap_weighted": 0.629761
          },
          {
            "accuracy": 0.624512,
            "f1": 0.619327,
            "f1_weighted": 0.619241,
            "ap": 0.583657,
            "ap_weighted": 0.583657
          },
          {
            "accuracy": 0.662598,
            "f1": 0.662336,
            "f1_weighted": 0.662354,
            "ap": 0.607274,
            "ap_weighted": 0.607274
          },
          {
            "accuracy": 0.668945,
            "f1": 0.668536,
            "f1_weighted": 0.668513,
            "ap": 0.616216,
            "ap_weighted": 0.616216
          },
          {
            "accuracy": 0.686523,
            "f1": 0.686509,
            "f1_weighted": 0.686513,
            "ap": 0.628549,
            "ap_weighted": 0.628549
          },
          {
            "accuracy": 0.655273,
            "f1": 0.65154,
            "f1_weighted": 0.65161,
            "ap": 0.59843,
            "ap_weighted": 0.59843
          },
          {
            "accuracy": 0.703613,
            "f1": 0.703399,
            "f1_weighted": 0.703384,
            "ap": 0.64665,
            "ap_weighted": 0.64665
          }
        ],
        "main_score": 0.6729,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.272281169891357,
  "kg_co2_emissions": 0.001472942860003195
}