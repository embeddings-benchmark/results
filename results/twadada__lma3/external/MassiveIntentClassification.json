{
    "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.05420309347679893,
                "f1": 0.04315786223132473,
                "f1_weighted": 0.04974594656897622,
                "main_score": 0.05420309347679893
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.2608271687962341,
                "f1": 0.24352547380922793,
                "f1_weighted": 0.25232718928536524,
                "main_score": 0.2608271687962341
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.33180901143241426,
                "f1": 0.31519620659167924,
                "f1_weighted": 0.32384622002888785,
                "main_score": 0.33180901143241426
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.3188298587760592,
                "f1": 0.30942949969741945,
                "f1_weighted": 0.31233095007244976,
                "main_score": 0.3188298587760592
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.02494956287827841,
                "f1": 0.01510175111983324,
                "f1_weighted": 0.01640918892084934,
                "main_score": 0.02494956287827841
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.019670477471418965,
                "f1": 0.006159324585969681,
                "f1_weighted": 0.005819638031791462,
                "main_score": 0.019670477471418965
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.3990248823133827,
                "f1": 0.39287107747032424,
                "f1_weighted": 0.387009325747578,
                "main_score": 0.3990248823133827
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.39266980497646276,
                "f1": 0.37261415787816377,
                "f1_weighted": 0.38933490856264436,
                "main_score": 0.39266980497646276
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.38328850033624756,
                "f1": 0.36439775105490585,
                "f1_weighted": 0.37407641389061763,
                "main_score": 0.38328850033624756
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.04246805648957633,
                "f1": 0.023731445299477297,
                "f1_weighted": 0.02360572588055181,
                "main_score": 0.04246805648957633
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.39108944182918637,
                "f1": 0.3795343741232742,
                "f1_weighted": 0.38194573318930913,
                "main_score": 0.39108944182918637
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.36123066577000673,
                "f1": 0.3466522711901937,
                "f1_weighted": 0.3649423547734652,
                "main_score": 0.36123066577000673
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.017417619367854742,
                "f1": 0.019480195212180508,
                "f1_weighted": 0.012139915329721394,
                "main_score": 0.017417619367854742
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.04152656355077337,
                "f1": 0.0306986734197953,
                "f1_weighted": 0.029192302037256534,
                "main_score": 0.04152656355077337
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.37286482851378616,
                "f1": 0.33437419132021107,
                "f1_weighted": 0.37357621666027346,
                "main_score": 0.37286482851378616
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.0265635507733692,
                "f1": 0.003481671491617231,
                "f1_weighted": 0.0039717054573769235,
                "main_score": 0.0265635507733692
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.014996637525218565,
                "f1": 0.0056189966898433875,
                "f1_weighted": 0.002905955658500835,
                "main_score": 0.014996637525218565
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6147612642905178,
                "f1": 0.6006479567610217,
                "f1_weighted": 0.6083975160734074,
                "main_score": 0.6147612642905178
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.3454606590450572,
                "f1": 0.33676876749763934,
                "f1_weighted": 0.3431704349593066,
                "main_score": 0.3454606590450572
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.016308002689979822,
                "f1": 0.011405209503916072,
                "f1_weighted": 0.007742160479746835,
                "main_score": 0.016308002689979822
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.3889374579690652,
                "f1": 0.362764450733474,
                "f1_weighted": 0.3864418063983438,
                "main_score": 0.3889374579690652
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.03130464021519839,
                "f1": 0.030631307694518002,
                "f1_weighted": 0.024929901519563934,
                "main_score": 0.03130464021519839
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.019502353732347006,
                "f1": 0.0036769465571218534,
                "f1_weighted": 0.0023289064484011877,
                "main_score": 0.019502353732347006
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.015770006724949565,
                "f1": 0.015948300177607292,
                "f1_weighted": 0.012140719337727968,
                "main_score": 0.015770006724949565
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.41590450571620713,
                "f1": 0.3872772290482752,
                "f1_weighted": 0.40529923800339046,
                "main_score": 0.41590450571620713
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.3803631472763954,
                "f1": 0.3693255573737422,
                "f1_weighted": 0.37534936041982564,
                "main_score": 0.3803631472763954
            },
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.3648285137861466,
                "f1": 0.3425594364586224,
                "f1_weighted": 0.35547712962359573,
                "main_score": 0.3648285137861466
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.057296570275722936,
                "f1": 0.033193365093063115,
                "f1_weighted": 0.03960957835377585,
                "main_score": 0.057296570275722936
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.30400134498991255,
                "f1": 0.2982323888109969,
                "f1_weighted": 0.2933334359136608,
                "main_score": 0.30400134498991255
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.03675184936112979,
                "f1": 0.024538503523226365,
                "f1_weighted": 0.02349349563560097,
                "main_score": 0.03675184936112979
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.020208473436449225,
                "f1": 0.003119628541869343,
                "f1_weighted": 0.0030416573008938907,
                "main_score": 0.020208473436449225
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.3597511768661735,
                "f1": 0.3485580589960041,
                "f1_weighted": 0.3523470836629608,
                "main_score": 0.3597511768661735
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.3417283120376597,
                "f1": 0.33401800892953587,
                "f1_weighted": 0.3386971429814368,
                "main_score": 0.3417283120376597
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.37367182246133157,
                "f1": 0.3659417109728048,
                "f1_weighted": 0.3642429431258725,
                "main_score": 0.37367182246133157
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.0144586415601883,
                "f1": 0.019358114043109824,
                "f1_weighted": 0.013118948648488232,
                "main_score": 0.0144586415601883
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.2853396099529254,
                "f1": 0.27187618650859746,
                "f1_weighted": 0.28306754637304077,
                "main_score": 0.2853396099529254
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.3650302622730329,
                "f1": 0.34755765428172813,
                "f1_weighted": 0.36167188300992714,
                "main_score": 0.3650302622730329
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.33997982515131137,
                "f1": 0.3194156494224548,
                "f1_weighted": 0.3420676321754517,
                "main_score": 0.33997982515131137
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.02410894418291863,
                "f1": 0.014788866943655008,
                "f1_weighted": 0.014091387199287393,
                "main_score": 0.02410894418291863
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.01778749159381305,
                "f1": 0.01203177752210266,
                "f1_weighted": 0.012822708886000447,
                "main_score": 0.01778749159381305
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.02340282447881641,
                "f1": 0.018036015686169513,
                "f1_weighted": 0.016221938088400313,
                "main_score": 0.02340282447881641
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.4161062542030935,
                "f1": 0.4018270967869114,
                "f1_weighted": 0.4106080669293675,
                "main_score": 0.4161062542030935
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3606590450571621,
                "f1": 0.34271393604440226,
                "f1_weighted": 0.3664527157457028,
                "main_score": 0.3606590450571621
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.3990248823133827,
                "f1": 0.40196389168951896,
                "f1_weighted": 0.39628253331046787,
                "main_score": 0.3990248823133827
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.02874915938130464,
                "f1": 0.00427443225815916,
                "f1_weighted": 0.006824559991630663,
                "main_score": 0.02874915938130464
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.35252185608607933,
                "f1": 0.3474178305421003,
                "f1_weighted": 0.3500723432214029,
                "main_score": 0.35252185608607933
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.023503698722259582,
                "f1": 0.012412757651054158,
                "f1_weighted": 0.009749592741906576,
                "main_score": 0.023503698722259582
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.11260928043039678,
                "f1": 0.07506881509551466,
                "f1_weighted": 0.100689161190946,
                "main_score": 0.11260928043039678
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.3198386012104909,
                "f1": 0.3093821006895835,
                "f1_weighted": 0.3102780337147849,
                "main_score": 0.3198386012104909
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.37989240080699394,
                "f1": 0.36481409887769606,
                "f1_weighted": 0.3667046029215524,
                "main_score": 0.37989240080699394
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.022696704774714183,
                "f1": 0.014237810211064905,
                "f1_weighted": 0.014245380816139085,
                "main_score": 0.022696704774714183
            }
        ]
    }
}