{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.38.9",
  "scores": {
    "train": [
      {
        "accuracy": 0.553955,
        "f1": 0.545987,
        "f1_weighted": 0.553213,
        "ap": 0.449452,
        "ap_weighted": 0.449452,
        "scores_per_experiment": [
          {
            "accuracy": 0.607422,
            "f1": 0.596024,
            "f1_weighted": 0.606958,
            "ap": 0.478688,
            "ap_weighted": 0.478688
          },
          {
            "accuracy": 0.505371,
            "f1": 0.503695,
            "f1_weighted": 0.508342,
            "ap": 0.424021,
            "ap_weighted": 0.424021
          },
          {
            "accuracy": 0.539062,
            "f1": 0.511796,
            "f1_weighted": 0.530387,
            "ap": 0.426753,
            "ap_weighted": 0.426753
          },
          {
            "accuracy": 0.532227,
            "f1": 0.529771,
            "f1_weighted": 0.524295,
            "ap": 0.450811,
            "ap_weighted": 0.450811
          },
          {
            "accuracy": 0.561523,
            "f1": 0.561522,
            "f1_weighted": 0.561384,
            "ap": 0.462572,
            "ap_weighted": 0.462572
          },
          {
            "accuracy": 0.510742,
            "f1": 0.508575,
            "f1_weighted": 0.513833,
            "ap": 0.426142,
            "ap_weighted": 0.426142
          },
          {
            "accuracy": 0.601562,
            "f1": 0.591592,
            "f1_weighted": 0.601874,
            "ap": 0.475336,
            "ap_weighted": 0.475336
          },
          {
            "accuracy": 0.595703,
            "f1": 0.583965,
            "f1_weighted": 0.595225,
            "ap": 0.469867,
            "ap_weighted": 0.469867
          },
          {
            "accuracy": 0.555176,
            "f1": 0.545086,
            "f1_weighted": 0.556003,
            "ap": 0.444207,
            "ap_weighted": 0.444207
          },
          {
            "accuracy": 0.530762,
            "f1": 0.527844,
            "f1_weighted": 0.533825,
            "ap": 0.436119,
            "ap_weighted": 0.436119
          }
        ],
        "main_score": 0.545987,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 0.3912818431854248,
  "kg_co2_emissions": null
}