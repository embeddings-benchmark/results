{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.38.9",
  "scores": {
    "validation": [
      {
        "precision": 0.696879,
        "recall": 0.748245,
        "f1": 0.709259,
        "accuracy": 0.748245,
        "main_score": 0.709259,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.687573,
        "recall": 0.760281,
        "f1": 0.707694,
        "accuracy": 0.760281,
        "main_score": 0.707694,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.552238,
        "recall": 0.611836,
        "f1": 0.565469,
        "accuracy": 0.611836,
        "main_score": 0.565469,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.542494,
        "recall": 0.635908,
        "f1": 0.56669,
        "accuracy": 0.635908,
        "main_score": 0.56669,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.812403,
        "recall": 0.854564,
        "f1": 0.823733,
        "accuracy": 0.854564,
        "main_score": 0.823733,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.795018,
        "recall": 0.851555,
        "f1": 0.811788,
        "accuracy": 0.851555,
        "main_score": 0.811788,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.596081,
        "recall": 0.64995,
        "f1": 0.608613,
        "accuracy": 0.64995,
        "main_score": 0.608613,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.578423,
        "recall": 0.671013,
        "f1": 0.602987,
        "accuracy": 0.671013,
        "main_score": 0.602987,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.497745,
        "recall": 0.558676,
        "f1": 0.511313,
        "accuracy": 0.558676,
        "main_score": 0.511313,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.549687,
        "recall": 0.635908,
        "f1": 0.571014,
        "accuracy": 0.635908,
        "main_score": 0.571014,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.529149,
        "recall": 0.589769,
        "f1": 0.542811,
        "accuracy": 0.589769,
        "main_score": 0.542811,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.562662,
        "recall": 0.653962,
        "f1": 0.586299,
        "accuracy": 0.653962,
        "main_score": 0.586299,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.541425,
        "recall": 0.608826,
        "f1": 0.557841,
        "accuracy": 0.608826,
        "main_score": 0.557841,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.549904,
        "recall": 0.645938,
        "f1": 0.574663,
        "accuracy": 0.645938,
        "main_score": 0.574663,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.553738,
        "recall": 0.613842,
        "f1": 0.566822,
        "accuracy": 0.613842,
        "main_score": 0.566822,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.543105,
        "recall": 0.631896,
        "f1": 0.564609,
        "accuracy": 0.631896,
        "main_score": 0.564609,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.737209,
        "recall": 0.79338,
        "f1": 0.752164,
        "accuracy": 0.79338,
        "main_score": 0.752164,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.755192,
        "recall": 0.815446,
        "f1": 0.771973,
        "accuracy": 0.815446,
        "main_score": 0.771973,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.060883,
        "recall": 0.079238,
        "f1": 0.063235,
        "accuracy": 0.079238,
        "main_score": 0.063235,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.161536,
        "recall": 0.23671,
        "f1": 0.176278,
        "accuracy": 0.23671,
        "main_score": 0.176278,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.437638,
        "recall": 0.490471,
        "f1": 0.449456,
        "accuracy": 0.490471,
        "main_score": 0.449456,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.497659,
        "recall": 0.591775,
        "f1": 0.520597,
        "accuracy": 0.591775,
        "main_score": 0.520597,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.744259,
        "recall": 0.79338,
        "f1": 0.756179,
        "accuracy": 0.79338,
        "main_score": 0.756179,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.730768,
        "recall": 0.795386,
        "f1": 0.748753,
        "accuracy": 0.795386,
        "main_score": 0.748753,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.119509,
        "recall": 0.14343,
        "f1": 0.122045,
        "accuracy": 0.14343,
        "main_score": 0.122045,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.270677,
        "recall": 0.352056,
        "f1": 0.288107,
        "accuracy": 0.352056,
        "main_score": 0.288107,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.517347,
        "recall": 0.572718,
        "f1": 0.529707,
        "accuracy": 0.572718,
        "main_score": 0.529707,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.527523,
        "recall": 0.617854,
        "f1": 0.549881,
        "accuracy": 0.617854,
        "main_score": 0.549881,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.446668,
        "recall": 0.510532,
        "f1": 0.461204,
        "accuracy": 0.510532,
        "main_score": 0.461204,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.508515,
        "recall": 0.60682,
        "f1": 0.534081,
        "accuracy": 0.60682,
        "main_score": 0.534081,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.226983,
        "recall": 0.264794,
        "f1": 0.233966,
        "accuracy": 0.264794,
        "main_score": 0.233966,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.292357,
        "recall": 0.387161,
        "f1": 0.313514,
        "accuracy": 0.387161,
        "main_score": 0.313514,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.644723,
        "recall": 0.698094,
        "f1": 0.657137,
        "accuracy": 0.698094,
        "main_score": 0.657137,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.676811,
        "recall": 0.751254,
        "f1": 0.69714,
        "accuracy": 0.751254,
        "main_score": 0.69714,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.522662,
        "recall": 0.567703,
        "f1": 0.532909,
        "accuracy": 0.567703,
        "main_score": 0.532909,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.582983,
        "recall": 0.668004,
        "f1": 0.605255,
        "accuracy": 0.668004,
        "main_score": 0.605255,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.010031,
        "recall": 0.011033,
        "f1": 0.010032,
        "accuracy": 0.011033,
        "main_score": 0.010032,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017922,
        "recall": 0.05015,
        "f1": 0.021106,
        "accuracy": 0.05015,
        "main_score": 0.021106,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.008374,
        "recall": 0.015045,
        "f1": 0.00864,
        "accuracy": 0.015045,
        "main_score": 0.00864,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.061373,
        "recall": 0.104313,
        "f1": 0.068795,
        "accuracy": 0.104313,
        "main_score": 0.068795,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.541622,
        "recall": 0.587763,
        "f1": 0.552094,
        "accuracy": 0.587763,
        "main_score": 0.552094,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.595966,
        "recall": 0.681043,
        "f1": 0.617762,
        "accuracy": 0.681043,
        "main_score": 0.617762,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.146696,
        "recall": 0.172518,
        "f1": 0.151585,
        "accuracy": 0.172518,
        "main_score": 0.151585,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.275051,
        "recall": 0.368104,
        "f1": 0.295326,
        "accuracy": 0.368104,
        "main_score": 0.295326,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.565993,
        "recall": 0.608826,
        "f1": 0.575429,
        "accuracy": 0.608826,
        "main_score": 0.575429,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.540776,
        "recall": 0.637914,
        "f1": 0.565887,
        "accuracy": 0.637914,
        "main_score": 0.565887,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.426102,
        "recall": 0.457372,
        "f1": 0.432677,
        "accuracy": 0.457372,
        "main_score": 0.432677,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.561188,
        "recall": 0.645938,
        "f1": 0.582224,
        "accuracy": 0.645938,
        "main_score": 0.582224,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.457998,
        "recall": 0.498495,
        "f1": 0.466476,
        "accuracy": 0.498495,
        "main_score": 0.466476,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.564186,
        "recall": 0.653962,
        "f1": 0.586395,
        "accuracy": 0.653962,
        "main_score": 0.586395,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.005092,
        "recall": 0.011033,
        "f1": 0.005602,
        "accuracy": 0.011033,
        "main_score": 0.005602,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.05939,
        "recall": 0.115346,
        "f1": 0.068682,
        "accuracy": 0.115346,
        "main_score": 0.068682,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.582541,
        "recall": 0.627884,
        "f1": 0.593426,
        "accuracy": 0.627884,
        "main_score": 0.593426,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.605355,
        "recall": 0.687061,
        "f1": 0.625467,
        "accuracy": 0.687061,
        "main_score": 0.625467,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.533272,
        "recall": 0.572718,
        "f1": 0.54135,
        "accuracy": 0.572718,
        "main_score": 0.54135,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.578104,
        "recall": 0.663992,
        "f1": 0.600053,
        "accuracy": 0.663992,
        "main_score": 0.600053,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000398,
        "recall": 0.014042,
        "f1": 0.000754,
        "accuracy": 0.014042,
        "main_score": 0.000754,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.673989,
        "recall": 0.725296,
        "f1": 0.686919,
        "accuracy": 0.725296,
        "main_score": 0.686919,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.646464,
        "recall": 0.726285,
        "f1": 0.668154,
        "accuracy": 0.726285,
        "main_score": 0.668154,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.554518,
        "recall": 0.607708,
        "f1": 0.566847,
        "accuracy": 0.607708,
        "main_score": 0.566847,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.538274,
        "recall": 0.632411,
        "f1": 0.562701,
        "accuracy": 0.632411,
        "main_score": 0.562701,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.794195,
        "recall": 0.839921,
        "f1": 0.80688,
        "accuracy": 0.839921,
        "main_score": 0.80688,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.776468,
        "recall": 0.831028,
        "f1": 0.791927,
        "accuracy": 0.831028,
        "main_score": 0.791927,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.577631,
        "recall": 0.631423,
        "f1": 0.590776,
        "accuracy": 0.631423,
        "main_score": 0.590776,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.539207,
        "recall": 0.634387,
        "f1": 0.564554,
        "accuracy": 0.634387,
        "main_score": 0.564554,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.488238,
        "recall": 0.538538,
        "f1": 0.499234,
        "accuracy": 0.538538,
        "main_score": 0.499234,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.522218,
        "recall": 0.608696,
        "f1": 0.542616,
        "accuracy": 0.608696,
        "main_score": 0.542616,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.523995,
        "recall": 0.583992,
        "f1": 0.539055,
        "accuracy": 0.583992,
        "main_score": 0.539055,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.571649,
        "recall": 0.658103,
        "f1": 0.594512,
        "accuracy": 0.658103,
        "main_score": 0.594512,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.507543,
        "recall": 0.566206,
        "f1": 0.521415,
        "accuracy": 0.566206,
        "main_score": 0.521415,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.502821,
        "recall": 0.606719,
        "f1": 0.52978,
        "accuracy": 0.606719,
        "main_score": 0.52978,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.560398,
        "recall": 0.61166,
        "f1": 0.572831,
        "accuracy": 0.61166,
        "main_score": 0.572831,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.540298,
        "recall": 0.632411,
        "f1": 0.563781,
        "accuracy": 0.632411,
        "main_score": 0.563781,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.659545,
        "recall": 0.725296,
        "f1": 0.67669,
        "accuracy": 0.725296,
        "main_score": 0.67669,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.702237,
        "recall": 0.768775,
        "f1": 0.720601,
        "accuracy": 0.768775,
        "main_score": 0.720601,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.076428,
        "recall": 0.098814,
        "f1": 0.079148,
        "accuracy": 0.098814,
        "main_score": 0.079148,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.170019,
        "recall": 0.25,
        "f1": 0.185671,
        "accuracy": 0.25,
        "main_score": 0.185671,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.500889,
        "recall": 0.552372,
        "f1": 0.512572,
        "accuracy": 0.552372,
        "main_score": 0.512572,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.51639,
        "recall": 0.608696,
        "f1": 0.539643,
        "accuracy": 0.608696,
        "main_score": 0.539643,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.727242,
        "recall": 0.773715,
        "f1": 0.73948,
        "accuracy": 0.773715,
        "main_score": 0.73948,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.699025,
        "recall": 0.771739,
        "f1": 0.719444,
        "accuracy": 0.771739,
        "main_score": 0.719444,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.133499,
        "recall": 0.159091,
        "f1": 0.137404,
        "accuracy": 0.159091,
        "main_score": 0.137404,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.244019,
        "recall": 0.324111,
        "f1": 0.261541,
        "accuracy": 0.324111,
        "main_score": 0.261541,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.495442,
        "recall": 0.552372,
        "f1": 0.50875,
        "accuracy": 0.552372,
        "main_score": 0.50875,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.497253,
        "recall": 0.592885,
        "f1": 0.520955,
        "accuracy": 0.592885,
        "main_score": 0.520955,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.484146,
        "recall": 0.548419,
        "f1": 0.499216,
        "accuracy": 0.548419,
        "main_score": 0.499216,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.515,
        "recall": 0.609684,
        "f1": 0.539445,
        "accuracy": 0.609684,
        "main_score": 0.539445,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.240077,
        "recall": 0.279644,
        "f1": 0.248165,
        "accuracy": 0.279644,
        "main_score": 0.248165,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.299999,
        "recall": 0.409091,
        "f1": 0.324008,
        "accuracy": 0.409091,
        "main_score": 0.324008,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.662367,
        "recall": 0.709486,
        "f1": 0.674118,
        "accuracy": 0.709486,
        "main_score": 0.674118,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.661569,
        "recall": 0.731225,
        "f1": 0.679915,
        "accuracy": 0.731225,
        "main_score": 0.679915,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.604536,
        "recall": 0.644269,
        "f1": 0.614059,
        "accuracy": 0.644269,
        "main_score": 0.614059,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.622531,
        "recall": 0.705534,
        "f1": 0.645009,
        "accuracy": 0.705534,
        "main_score": 0.645009,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.011859,
        "recall": 0.012846,
        "f1": 0.01186,
        "accuracy": 0.012846,
        "main_score": 0.01186,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016571,
        "recall": 0.052372,
        "f1": 0.020517,
        "accuracy": 0.052372,
        "main_score": 0.020517,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.014696,
        "recall": 0.021739,
        "f1": 0.015525,
        "accuracy": 0.021739,
        "main_score": 0.015525,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.064269,
        "recall": 0.12253,
        "f1": 0.074035,
        "accuracy": 0.12253,
        "main_score": 0.074035,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.535877,
        "recall": 0.581028,
        "f1": 0.545937,
        "accuracy": 0.581028,
        "main_score": 0.545937,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.530414,
        "recall": 0.617589,
        "f1": 0.551981,
        "accuracy": 0.617589,
        "main_score": 0.551981,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.156233,
        "recall": 0.189723,
        "f1": 0.162136,
        "accuracy": 0.189723,
        "main_score": 0.162136,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.265562,
        "recall": 0.367589,
        "f1": 0.287614,
        "accuracy": 0.367589,
        "main_score": 0.287614,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.576708,
        "recall": 0.625494,
        "f1": 0.5884,
        "accuracy": 0.625494,
        "main_score": 0.5884,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.569353,
        "recall": 0.663043,
        "f1": 0.593536,
        "accuracy": 0.663043,
        "main_score": 0.593536,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.462055,
        "recall": 0.500988,
        "f1": 0.470792,
        "accuracy": 0.500988,
        "main_score": 0.470792,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.52372,
        "recall": 0.620553,
        "f1": 0.547648,
        "accuracy": 0.620553,
        "main_score": 0.547648,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.465643,
        "recall": 0.512846,
        "f1": 0.47586,
        "accuracy": 0.512846,
        "main_score": 0.47586,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.53093,
        "recall": 0.614625,
        "f1": 0.551743,
        "accuracy": 0.614625,
        "main_score": 0.551743,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.016158,
        "recall": 0.020751,
        "f1": 0.016735,
        "accuracy": 0.020751,
        "main_score": 0.016735,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.061744,
        "recall": 0.112648,
        "f1": 0.069448,
        "accuracy": 0.112648,
        "main_score": 0.069448,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.602907,
        "recall": 0.651186,
        "f1": 0.614402,
        "accuracy": 0.651186,
        "main_score": 0.614402,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.568958,
        "recall": 0.649209,
        "f1": 0.589199,
        "accuracy": 0.649209,
        "main_score": 0.589199,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.545759,
        "recall": 0.593874,
        "f1": 0.556694,
        "accuracy": 0.593874,
        "main_score": 0.556694,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.562139,
        "recall": 0.653162,
        "f1": 0.58545,
        "accuracy": 0.653162,
        "main_score": 0.58545,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0022,
        "recall": 0.019763,
        "f1": 0.003119,
        "accuracy": 0.019763,
        "main_score": 0.003119,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 21.706188917160034,
  "kg_co2_emissions": null
}