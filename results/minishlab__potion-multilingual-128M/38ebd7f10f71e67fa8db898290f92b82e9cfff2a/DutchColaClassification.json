{
  "dataset_revision": "2269ed7d95d8abaab829f1592b4b2047372e9f81",
  "task_name": "DutchColaClassification",
  "mteb_version": "2.1.0",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.527917,
            "f1": 0.52757,
            "f1_weighted": 0.52757,
            "precision": 0.527999,
            "precision_weighted": 0.527999,
            "recall": 0.527917,
            "recall_weighted": 0.527917,
            "ap": 0.514698,
            "ap_weighted": 0.514698
          },
          {
            "accuracy": 0.54125,
            "f1": 0.541221,
            "f1_weighted": 0.541221,
            "precision": 0.54126,
            "precision_weighted": 0.54126,
            "recall": 0.54125,
            "recall_weighted": 0.54125,
            "ap": 0.5223,
            "ap_weighted": 0.5223
          },
          {
            "accuracy": 0.525833,
            "f1": 0.525821,
            "f1_weighted": 0.525821,
            "precision": 0.525836,
            "precision_weighted": 0.525836,
            "recall": 0.525833,
            "recall_weighted": 0.525833,
            "ap": 0.513577,
            "ap_weighted": 0.513577
          },
          {
            "accuracy": 0.533333,
            "f1": 0.532585,
            "f1_weighted": 0.532585,
            "precision": 0.533548,
            "precision_weighted": 0.533548,
            "recall": 0.533333,
            "recall_weighted": 0.533333,
            "ap": 0.517874,
            "ap_weighted": 0.517874
          },
          {
            "accuracy": 0.54375,
            "f1": 0.543003,
            "f1_weighted": 0.543003,
            "precision": 0.544038,
            "precision_weighted": 0.544038,
            "recall": 0.54375,
            "recall_weighted": 0.54375,
            "ap": 0.523957,
            "ap_weighted": 0.523957
          },
          {
            "accuracy": 0.53375,
            "f1": 0.5336,
            "f1_weighted": 0.5336,
            "precision": 0.533793,
            "precision_weighted": 0.533793,
            "recall": 0.53375,
            "recall_weighted": 0.53375,
            "ap": 0.517975,
            "ap_weighted": 0.517975
          },
          {
            "accuracy": 0.558333,
            "f1": 0.558314,
            "f1_weighted": 0.558314,
            "precision": 0.558344,
            "precision_weighted": 0.558344,
            "recall": 0.558333,
            "recall_weighted": 0.558333,
            "ap": 0.532525,
            "ap_weighted": 0.532525
          },
          {
            "accuracy": 0.5425,
            "f1": 0.542194,
            "f1_weighted": 0.542194,
            "precision": 0.542614,
            "precision_weighted": 0.542614,
            "recall": 0.5425,
            "recall_weighted": 0.5425,
            "ap": 0.523155,
            "ap_weighted": 0.523155
          },
          {
            "accuracy": 0.54,
            "f1": 0.537099,
            "f1_weighted": 0.537099,
            "precision": 0.541029,
            "precision_weighted": 0.541029,
            "recall": 0.54,
            "recall_weighted": 0.54,
            "ap": 0.521381,
            "ap_weighted": 0.521381
          },
          {
            "accuracy": 0.5625,
            "f1": 0.561938,
            "f1_weighted": 0.561938,
            "precision": 0.562823,
            "precision_weighted": 0.562823,
            "recall": 0.5625,
            "recall_weighted": 0.5625,
            "ap": 0.535458,
            "ap_weighted": 0.535458
          }
        ],
        "accuracy": 0.540917,
        "f1": 0.540335,
        "f1_weighted": 0.540335,
        "precision": 0.541128,
        "precision_weighted": 0.541128,
        "recall": 0.540917,
        "recall_weighted": 0.540917,
        "ap": 0.52229,
        "ap_weighted": 0.52229,
        "main_score": 0.540335,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 14.12687349319458,
  "kg_co2_emissions": null
}