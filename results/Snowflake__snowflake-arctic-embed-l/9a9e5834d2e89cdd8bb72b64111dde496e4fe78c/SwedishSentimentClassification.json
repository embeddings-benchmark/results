{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.69043,
        "f1": 0.685098,
        "f1_weighted": 0.685207,
        "ap": 0.626302,
        "ap_weighted": 0.626302,
        "scores_per_experiment": [
          {
            "accuracy": 0.716797,
            "f1": 0.713671,
            "f1_weighted": 0.713758,
            "ap": 0.648461,
            "ap_weighted": 0.648461
          },
          {
            "accuracy": 0.677246,
            "f1": 0.666417,
            "f1_weighted": 0.666593,
            "ap": 0.612766,
            "ap_weighted": 0.612766
          },
          {
            "accuracy": 0.671387,
            "f1": 0.666926,
            "f1_weighted": 0.667039,
            "ap": 0.610738,
            "ap_weighted": 0.610738
          },
          {
            "accuracy": 0.671387,
            "f1": 0.661789,
            "f1_weighted": 0.661956,
            "ap": 0.608743,
            "ap_weighted": 0.608743
          },
          {
            "accuracy": 0.696777,
            "f1": 0.696574,
            "f1_weighted": 0.696597,
            "ap": 0.636602,
            "ap_weighted": 0.636602
          },
          {
            "accuracy": 0.664551,
            "f1": 0.664272,
            "f1_weighted": 0.6643,
            "ap": 0.609273,
            "ap_weighted": 0.609273
          },
          {
            "accuracy": 0.710449,
            "f1": 0.702093,
            "f1_weighted": 0.702239,
            "ap": 0.639445,
            "ap_weighted": 0.639445
          },
          {
            "accuracy": 0.688477,
            "f1": 0.683213,
            "f1_weighted": 0.683332,
            "ap": 0.62363,
            "ap_weighted": 0.62363
          },
          {
            "accuracy": 0.688477,
            "f1": 0.679324,
            "f1_weighted": 0.679482,
            "ap": 0.621852,
            "ap_weighted": 0.621852
          },
          {
            "accuracy": 0.71875,
            "f1": 0.716705,
            "f1_weighted": 0.716776,
            "ap": 0.651511,
            "ap_weighted": 0.651511
          }
        ],
        "main_score": 0.69043,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.695557,
        "f1": 0.690492,
        "f1_weighted": 0.690562,
        "ap": 0.629832,
        "ap_weighted": 0.629832,
        "scores_per_experiment": [
          {
            "accuracy": 0.709473,
            "f1": 0.705794,
            "f1_weighted": 0.705858,
            "ap": 0.641377,
            "ap_weighted": 0.641377
          },
          {
            "accuracy": 0.688477,
            "f1": 0.675733,
            "f1_weighted": 0.675858,
            "ap": 0.620342,
            "ap_weighted": 0.620342
          },
          {
            "accuracy": 0.671387,
            "f1": 0.667995,
            "f1_weighted": 0.66806,
            "ap": 0.610943,
            "ap_weighted": 0.610943
          },
          {
            "accuracy": 0.695312,
            "f1": 0.687882,
            "f1_weighted": 0.687976,
            "ap": 0.627532,
            "ap_weighted": 0.627532
          },
          {
            "accuracy": 0.699219,
            "f1": 0.698804,
            "f1_weighted": 0.698826,
            "ap": 0.637466,
            "ap_weighted": 0.637466
          },
          {
            "accuracy": 0.66748,
            "f1": 0.667204,
            "f1_weighted": 0.667223,
            "ap": 0.611191,
            "ap_weighted": 0.611191
          },
          {
            "accuracy": 0.726074,
            "f1": 0.719263,
            "f1_weighted": 0.719348,
            "ap": 0.65271,
            "ap_weighted": 0.65271
          },
          {
            "accuracy": 0.711914,
            "f1": 0.707268,
            "f1_weighted": 0.70734,
            "ap": 0.642585,
            "ap_weighted": 0.642585
          },
          {
            "accuracy": 0.690918,
            "f1": 0.682421,
            "f1_weighted": 0.682522,
            "ap": 0.623637,
            "ap_weighted": 0.623637
          },
          {
            "accuracy": 0.695312,
            "f1": 0.692554,
            "f1_weighted": 0.692611,
            "ap": 0.630542,
            "ap_weighted": 0.630542
          }
        ],
        "main_score": 0.695557,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 26.3230037689209,
  "kg_co2_emissions": 0.0014472348447108721
}