{
  "dataset_revision": "f334d90a9f68cc3af78cc2a2ece6a3b69408124c",
  "task_name": "KurdishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.600302,
        "f1": 0.592068,
        "f1_weighted": 0.593273,
        "ap": 0.600544,
        "ap_weighted": 0.600544,
        "scores_per_experiment": [
          {
            "accuracy": 0.627579,
            "f1": 0.627568,
            "f1_weighted": 0.627716,
            "ap": 0.617598,
            "ap_weighted": 0.617598
          },
          {
            "accuracy": 0.620533,
            "f1": 0.615953,
            "f1_weighted": 0.612935,
            "ap": 0.624029,
            "ap_weighted": 0.624029
          },
          {
            "accuracy": 0.454454,
            "f1": 0.410424,
            "f1_weighted": 0.42202,
            "ap": 0.507153,
            "ap_weighted": 0.507153
          },
          {
            "accuracy": 0.559134,
            "f1": 0.551394,
            "f1_weighted": 0.547153,
            "ap": 0.578676,
            "ap_weighted": 0.578676
          },
          {
            "accuracy": 0.587318,
            "f1": 0.586206,
            "f1_weighted": 0.584662,
            "ap": 0.592725,
            "ap_weighted": 0.592725
          },
          {
            "accuracy": 0.679919,
            "f1": 0.67801,
            "f1_weighted": 0.679795,
            "ap": 0.651468,
            "ap_weighted": 0.651468
          },
          {
            "accuracy": 0.665828,
            "f1": 0.663989,
            "f1_weighted": 0.665778,
            "ap": 0.640592,
            "ap_weighted": 0.640592
          },
          {
            "accuracy": 0.667338,
            "f1": 0.647622,
            "f1_weighted": 0.653621,
            "ap": 0.628002,
            "ap_weighted": 0.628002
          },
          {
            "accuracy": 0.62305,
            "f1": 0.622014,
            "f1_weighted": 0.620591,
            "ap": 0.61966,
            "ap_weighted": 0.61966
          },
          {
            "accuracy": 0.517866,
            "f1": 0.517496,
            "f1_weighted": 0.518458,
            "ap": 0.545539,
            "ap_weighted": 0.545539
          }
        ],
        "main_score": 0.600302,
        "hf_subset": "default",
        "languages": [
          "kur-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 10.779006481170654,
  "kg_co2_emissions": 0.00043240996857284224
}