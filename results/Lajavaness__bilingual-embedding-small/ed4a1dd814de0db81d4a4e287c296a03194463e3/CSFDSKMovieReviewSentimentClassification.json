{
  "dataset_revision": "23a20c659d868740ef9c54854de631fe19cd5c17",
  "task_name": "CSFDSKMovieReviewSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.270703,
        "f1": 0.268817,
        "f1_weighted": 0.27002,
        "scores_per_experiment": [
          {
            "accuracy": 0.259277,
            "f1": 0.259643,
            "f1_weighted": 0.261587
          },
          {
            "accuracy": 0.265625,
            "f1": 0.259542,
            "f1_weighted": 0.261883
          },
          {
            "accuracy": 0.287109,
            "f1": 0.282875,
            "f1_weighted": 0.28441
          },
          {
            "accuracy": 0.274414,
            "f1": 0.274437,
            "f1_weighted": 0.275358
          },
          {
            "accuracy": 0.271973,
            "f1": 0.270614,
            "f1_weighted": 0.271608
          },
          {
            "accuracy": 0.25293,
            "f1": 0.248819,
            "f1_weighted": 0.249735
          },
          {
            "accuracy": 0.266113,
            "f1": 0.264175,
            "f1_weighted": 0.265055
          },
          {
            "accuracy": 0.268066,
            "f1": 0.268828,
            "f1_weighted": 0.269837
          },
          {
            "accuracy": 0.289062,
            "f1": 0.287219,
            "f1_weighted": 0.287993
          },
          {
            "accuracy": 0.272461,
            "f1": 0.272021,
            "f1_weighted": 0.272729
          }
        ],
        "main_score": 0.270703,
        "hf_subset": "default",
        "languages": [
          "slk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 9.723169326782227,
  "kg_co2_emissions": 0.00032547346193861345
}