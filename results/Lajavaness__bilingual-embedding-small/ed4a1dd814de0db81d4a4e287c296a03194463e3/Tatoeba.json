{
  "dataset_revision": "69e8f12da6e31d59addadda9a9c8a2e601a0e282",
  "task_name": "Tatoeba",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.094782,
        "recall": 0.127,
        "f1": 0.101668,
        "accuracy": 0.127,
        "main_score": 0.101668,
        "hf_subset": "bre-eng",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.178135,
        "recall": 0.245,
        "f1": 0.191712,
        "accuracy": 0.245,
        "main_score": 0.191712,
        "hf_subset": "ber-eng",
        "languages": [
          "ber-Tfng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.455897,
        "recall": 0.546341,
        "f1": 0.480538,
        "accuracy": 0.546341,
        "main_score": 0.480538,
        "hf_subset": "kur-eng",
        "languages": [
          "kur-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.648961,
        "recall": 0.733913,
        "f1": 0.674087,
        "accuracy": 0.733913,
        "main_score": 0.674087,
        "hf_subset": "cym-eng",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.917083,
        "recall": 0.942,
        "f1": 0.925233,
        "accuracy": 0.942,
        "main_score": 0.925233,
        "hf_subset": "zsm-eng",
        "languages": [
          "zsm-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.875117,
        "recall": 0.908,
        "f1": 0.885367,
        "accuracy": 0.908,
        "main_score": 0.885367,
        "hf_subset": "tur-eng",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.91095,
        "recall": 0.937,
        "f1": 0.919233,
        "accuracy": 0.937,
        "main_score": 0.919233,
        "hf_subset": "fra-eng",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.84175,
        "recall": 0.885,
        "f1": 0.855319,
        "accuracy": 0.885,
        "main_score": 0.855319,
        "hf_subset": "jpn-eng",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.906022,
        "recall": 0.932482,
        "f1": 0.914477,
        "accuracy": 0.932482,
        "main_score": 0.914477,
        "hf_subset": "tha-eng",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.618794,
        "recall": 0.692,
        "f1": 0.640508,
        "accuracy": 0.692,
        "main_score": 0.640508,
        "hf_subset": "lvs-eng",
        "languages": [
          "lvs-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.67206,
        "recall": 0.739,
        "f1": 0.691669,
        "accuracy": 0.739,
        "main_score": 0.691669,
        "hf_subset": "tat-eng",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.590172,
        "recall": 0.667939,
        "f1": 0.611281,
        "accuracy": 0.667939,
        "main_score": 0.611281,
        "hf_subset": "fao-eng",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.6815,
        "recall": 0.744,
        "f1": 0.700187,
        "accuracy": 0.744,
        "main_score": 0.700187,
        "hf_subset": "fin-eng",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.191139,
        "recall": 0.252,
        "f1": 0.206325,
        "accuracy": 0.252,
        "main_score": 0.206325,
        "hf_subset": "kab-eng",
        "languages": [
          "kab-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.540773,
        "recall": 0.622,
        "f1": 0.562745,
        "accuracy": 0.622,
        "main_score": 0.562745,
        "hf_subset": "lfn-eng",
        "languages": [
          "lfn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.365705,
        "recall": 0.451923,
        "f1": 0.389103,
        "accuracy": 0.451923,
        "main_score": 0.389103,
        "hf_subset": "tzl-eng",
        "languages": [
          "tzl-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.401156,
        "recall": 0.496,
        "f1": 0.424867,
        "accuracy": 0.496,
        "main_score": 0.424867,
        "hf_subset": "lat-eng",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.724528,
        "recall": 0.792453,
        "f1": 0.744716,
        "accuracy": 0.792453,
        "main_score": 0.744716,
        "hf_subset": "yid-eng",
        "languages": [
          "yid-Hebr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.477108,
        "recall": 0.571429,
        "f1": 0.500496,
        "accuracy": 0.571429,
        "main_score": 0.500496,
        "hf_subset": "swg-eng",
        "languages": [
          "swg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.853917,
        "recall": 0.894,
        "f1": 0.866519,
        "accuracy": 0.894,
        "main_score": 0.866519,
        "hf_subset": "pes-eng",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.403187,
        "recall": 0.476,
        "f1": 0.42269,
        "accuracy": 0.476,
        "main_score": 0.42269,
        "hf_subset": "war-eng",
        "languages": [
          "war-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.831228,
        "recall": 0.871,
        "f1": 0.8434,
        "accuracy": 0.871,
        "main_score": 0.8434,
        "hf_subset": "ron-eng",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.784658,
        "recall": 0.84,
        "f1": 0.801089,
        "accuracy": 0.84,
        "main_score": 0.801089,
        "hf_subset": "wuu-eng",
        "languages": [
          "wuu-Hans",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.563437,
        "recall": 0.641509,
        "f1": 0.586308,
        "accuracy": 0.641509,
        "main_score": 0.586308,
        "hf_subset": "arz-eng",
        "languages": [
          "arz-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.441565,
        "recall": 0.515,
        "f1": 0.461597,
        "accuracy": 0.515,
        "main_score": 0.461597,
        "hf_subset": "ceb-eng",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.705011,
        "recall": 0.772,
        "f1": 0.724286,
        "accuracy": 0.772,
        "main_score": 0.724286,
        "hf_subset": "nno-eng",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.832783,
        "recall": 0.88,
        "f1": 0.847567,
        "accuracy": 0.88,
        "main_score": 0.847567,
        "hf_subset": "srp-eng",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.8522,
        "recall": 0.893,
        "f1": 0.865133,
        "accuracy": 0.893,
        "main_score": 0.865133,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.401435,
        "recall": 0.495726,
        "f1": 0.425689,
        "accuracy": 0.495726,
        "main_score": 0.425689,
        "hf_subset": "gsw-eng",
        "languages": [
          "gsw-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.65746,
        "recall": 0.735,
        "f1": 0.679836,
        "accuracy": 0.735,
        "main_score": 0.679836,
        "hf_subset": "uig-eng",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.17339,
        "recall": 0.237126,
        "f1": 0.18698,
        "accuracy": 0.237126,
        "main_score": 0.18698,
        "hf_subset": "orv-eng",
        "languages": [
          "orv-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.794117,
        "recall": 0.845,
        "f1": 0.809833,
        "accuracy": 0.845,
        "main_score": 0.809833,
        "hf_subset": "slk-eng",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.696363,
        "recall": 0.771,
        "f1": 0.718548,
        "accuracy": 0.771,
        "main_score": 0.718548,
        "hf_subset": "ido-eng",
        "languages": [
          "ido-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.79715,
        "recall": 0.847,
        "f1": 0.812152,
        "accuracy": 0.847,
        "main_score": 0.812152,
        "hf_subset": "tgl-eng",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.883,
        "recall": 0.917,
        "f1": 0.8938,
        "accuracy": 0.917,
        "main_score": 0.8938,
        "hf_subset": "sqi-eng",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.771176,
        "recall": 0.831,
        "f1": 0.789669,
        "accuracy": 0.831,
        "main_score": 0.789669,
        "hf_subset": "yue-eng",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.831778,
        "recall": 0.876,
        "f1": 0.845333,
        "accuracy": 0.876,
        "main_score": 0.845333,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.839454,
        "recall": 0.887006,
        "f1": 0.85452,
        "accuracy": 0.887006,
        "main_score": 0.85452,
        "hf_subset": "bos-eng",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.284566,
        "recall": 0.379447,
        "f1": 0.308837,
        "accuracy": 0.379447,
        "main_score": 0.308837,
        "hf_subset": "csb-eng",
        "languages": [
          "csb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.580552,
        "recall": 0.665888,
        "f1": 0.60588,
        "accuracy": 0.665888,
        "main_score": 0.60588,
        "hf_subset": "uzb-eng",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.764493,
        "recall": 0.829565,
        "f1": 0.785043,
        "accuracy": 0.829565,
        "main_score": 0.785043,
        "hf_subset": "kaz-eng",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.691239,
        "recall": 0.769231,
        "f1": 0.714579,
        "accuracy": 0.769231,
        "main_score": 0.714579,
        "hf_subset": "swh-eng",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.31367,
        "recall": 0.415449,
        "f1": 0.340132,
        "accuracy": 0.415449,
        "main_score": 0.340132,
        "hf_subset": "dsb-eng",
        "languages": [
          "dsb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.783126,
        "recall": 0.84,
        "f1": 0.80045,
        "accuracy": 0.84,
        "main_score": 0.80045,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.670233,
        "recall": 0.747082,
        "f1": 0.691903,
        "accuracy": 0.747082,
        "main_score": 0.691903,
        "hf_subset": "nov-eng",
        "languages": [
          "nov-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.842833,
        "recall": 0.883,
        "f1": 0.8555,
        "accuracy": 0.883,
        "main_score": 0.8555,
        "hf_subset": "ita-eng",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.926667,
        "recall": 0.949,
        "f1": 0.934,
        "accuracy": 0.949,
        "main_score": 0.934,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.846167,
        "recall": 0.892,
        "f1": 0.860633,
        "accuracy": 0.892,
        "main_score": 0.860633,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.86875,
        "recall": 0.907,
        "f1": 0.881233,
        "accuracy": 0.907,
        "main_score": 0.881233,
        "hf_subset": "pol-eng",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.080193,
        "recall": 0.109,
        "f1": 0.086841,
        "accuracy": 0.109,
        "main_score": 0.086841,
        "hf_subset": "pam-eng",
        "languages": [
          "pam-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.516149,
        "recall": 0.602113,
        "f1": 0.538847,
        "accuracy": 0.602113,
        "main_score": 0.538847,
        "hf_subset": "max-eng",
        "languages": [
          "max-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.953906,
        "recall": 0.967977,
        "f1": 0.958515,
        "accuracy": 0.967977,
        "main_score": 0.958515,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.8615,
        "recall": 0.899,
        "f1": 0.873133,
        "accuracy": 0.899,
        "main_score": 0.873133,
        "hf_subset": "hrv-eng",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.453218,
        "recall": 0.547648,
        "f1": 0.479483,
        "accuracy": 0.547648,
        "main_score": 0.479483,
        "hf_subset": "gla-eng",
        "languages": [
          "gla-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.233495,
        "recall": 0.307355,
        "f1": 0.251389,
        "accuracy": 0.307355,
        "main_score": 0.251389,
        "hf_subset": "arq-eng",
        "languages": [
          "arq-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.506744,
        "recall": 0.572254,
        "f1": 0.524663,
        "accuracy": 0.572254,
        "main_score": 0.524663,
        "hf_subset": "fry-eng",
        "languages": [
          "fry-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.705643,
        "recall": 0.779528,
        "f1": 0.727559,
        "accuracy": 0.779528,
        "main_score": 0.727559,
        "hf_subset": "ast-eng",
        "languages": [
          "ast-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.724387,
        "recall": 0.800866,
        "f1": 0.74733,
        "accuracy": 0.800866,
        "main_score": 0.74733,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.787483,
        "recall": 0.842,
        "f1": 0.804367,
        "accuracy": 0.842,
        "main_score": 0.804367,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.533031,
        "recall": 0.612,
        "f1": 0.55369,
        "accuracy": 0.612,
        "main_score": 0.55369,
        "hf_subset": "nds-eng",
        "languages": [
          "nds-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060898,
        "recall": 0.085,
        "f1": 0.066403,
        "accuracy": 0.085,
        "main_score": 0.066403,
        "hf_subset": "cor-eng",
        "languages": [
          "cor-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.884833,
        "recall": 0.919,
        "f1": 0.895833,
        "accuracy": 0.919,
        "main_score": 0.895833,
        "hf_subset": "vie-eng",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.559292,
        "recall": 0.637,
        "f1": 0.581246,
        "accuracy": 0.637,
        "main_score": 0.581246,
        "hf_subset": "est-eng",
        "languages": [
          "est-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.362608,
        "recall": 0.459627,
        "f1": 0.387446,
        "accuracy": 0.459627,
        "main_score": 0.387446,
        "hf_subset": "hsb-eng",
        "languages": [
          "hsb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.8537,
        "recall": 0.894,
        "f1": 0.866633,
        "accuracy": 0.894,
        "main_score": 0.866633,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.080801,
        "recall": 0.103,
        "f1": 0.086323,
        "accuracy": 0.103,
        "main_score": 0.086323,
        "hf_subset": "dtp-eng",
        "languages": [
          "dtp-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.7995,
        "recall": 0.858,
        "f1": 0.8178,
        "accuracy": 0.858,
        "main_score": 0.8178,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.624417,
        "recall": 0.706,
        "f1": 0.648768,
        "accuracy": 0.706,
        "main_score": 0.648768,
        "hf_subset": "mkd-eng",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.884667,
        "recall": 0.92,
        "f1": 0.896167,
        "accuracy": 0.92,
        "main_score": 0.896167,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.8217,
        "recall": 0.869,
        "f1": 0.836667,
        "accuracy": 0.869,
        "main_score": 0.836667,
        "hf_subset": "ukr-eng",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.842583,
        "recall": 0.888,
        "f1": 0.857033,
        "accuracy": 0.888,
        "main_score": 0.857033,
        "hf_subset": "afr-eng",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.7368,
        "recall": 0.803,
        "f1": 0.7562,
        "accuracy": 0.803,
        "main_score": 0.7562,
        "hf_subset": "ile-eng",
        "languages": [
          "ile-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.360113,
        "recall": 0.455224,
        "f1": 0.383893,
        "accuracy": 0.455224,
        "main_score": 0.383893,
        "hf_subset": "ang-eng",
        "languages": [
          "ang-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.863667,
        "recall": 0.902,
        "f1": 0.875267,
        "accuracy": 0.902,
        "main_score": 0.875267,
        "hf_subset": "bel-eng",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.827723,
        "recall": 0.872964,
        "f1": 0.841585,
        "accuracy": 0.872964,
        "main_score": 0.841585,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.854667,
        "recall": 0.894,
        "f1": 0.866752,
        "accuracy": 0.894,
        "main_score": 0.866752,
        "hf_subset": "swe-eng",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.91495,
        "recall": 0.936,
        "f1": 0.921567,
        "accuracy": 0.936,
        "main_score": 0.921567,
        "hf_subset": "por-eng",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.752583,
        "recall": 0.81,
        "f1": 0.770119,
        "accuracy": 0.81,
        "main_score": 0.770119,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.435531,
        "recall": 0.512381,
        "f1": 0.45769,
        "accuracy": 0.512381,
        "main_score": 0.45769,
        "hf_subset": "pms-eng",
        "languages": [
          "pms-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.763817,
        "recall": 0.821,
        "f1": 0.7819,
        "accuracy": 0.821,
        "main_score": 0.7819,
        "hf_subset": "kor-eng",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.535285,
        "recall": 0.619512,
        "f1": 0.558591,
        "accuracy": 0.619512,
        "main_score": 0.558591,
        "hf_subset": "jav-eng",
        "languages": [
          "jav-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.829356,
        "recall": 0.872727,
        "f1": 0.8425,
        "accuracy": 0.872727,
        "main_score": 0.8425,
        "hf_subset": "mon-eng",
        "languages": [
          "mon-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.813114,
        "recall": 0.86193,
        "f1": 0.827952,
        "accuracy": 0.86193,
        "main_score": 0.827952,
        "hf_subset": "kat-eng",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.730826,
        "recall": 0.787,
        "f1": 0.747383,
        "accuracy": 0.787,
        "main_score": 0.747383,
        "hf_subset": "hun-eng",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.701583,
        "recall": 0.773,
        "f1": 0.723215,
        "accuracy": 0.773,
        "main_score": 0.723215,
        "hf_subset": "heb-eng",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.91225,
        "recall": 0.939,
        "f1": 0.9209,
        "accuracy": 0.939,
        "main_score": 0.9209,
        "hf_subset": "cmn-eng",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.513149,
        "recall": 0.599723,
        "f1": 0.53712,
        "accuracy": 0.599723,
        "main_score": 0.53712,
        "hf_subset": "khm-eng",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.642658,
        "recall": 0.718,
        "f1": 0.664995,
        "accuracy": 0.718,
        "main_score": 0.664995,
        "hf_subset": "gle-eng",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.904558,
        "recall": 0.931624,
        "f1": 0.913105,
        "accuracy": 0.931624,
        "main_score": 0.913105,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.447158,
        "recall": 0.522,
        "f1": 0.467087,
        "accuracy": 0.522,
        "main_score": 0.467087,
        "hf_subset": "oci-eng",
        "languages": [
          "oci-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.909833,
        "recall": 0.936,
        "f1": 0.918333,
        "accuracy": 0.936,
        "main_score": 0.918333,
        "hf_subset": "nld-eng",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.648474,
        "recall": 0.732394,
        "f1": 0.674178,
        "accuracy": 0.732394,
        "main_score": 0.674178,
        "hf_subset": "xho-eng",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.601032,
        "recall": 0.678,
        "f1": 0.623272,
        "accuracy": 0.678,
        "main_score": 0.623272,
        "hf_subset": "cbk-eng",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.080645,
        "recall": 0.107,
        "f1": 0.085515,
        "accuracy": 0.107,
        "main_score": 0.085515,
        "hf_subset": "kzj-eng",
        "languages": [
          "kzj-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.913167,
        "recall": 0.937,
        "f1": 0.920667,
        "accuracy": 0.937,
        "main_score": 0.920667,
        "hf_subset": "spa-eng",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.865367,
        "recall": 0.903,
        "f1": 0.877133,
        "accuracy": 0.903,
        "main_score": 0.877133,
        "hf_subset": "ina-eng",
        "languages": [
          "ina-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.645442,
        "recall": 0.724,
        "f1": 0.668541,
        "accuracy": 0.724,
        "main_score": 0.668541,
        "hf_subset": "isl-eng",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.191785,
        "recall": 0.246305,
        "f1": 0.203953,
        "accuracy": 0.246305,
        "main_score": 0.203953,
        "hf_subset": "tuk-eng",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.299832,
        "recall": 0.364964,
        "f1": 0.316649,
        "accuracy": 0.364964,
        "main_score": 0.316649,
        "hf_subset": "cha-eng",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.769345,
        "recall": 0.833333,
        "f1": 0.789087,
        "accuracy": 0.833333,
        "main_score": 0.789087,
        "hf_subset": "amh-eng",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.88825,
        "recall": 0.922,
        "f1": 0.899067,
        "accuracy": 0.922,
        "main_score": 0.899067,
        "hf_subset": "nob-eng",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.89125,
        "recall": 0.923,
        "f1": 0.901567,
        "accuracy": 0.923,
        "main_score": 0.901567,
        "hf_subset": "rus-eng",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.845732,
        "recall": 0.889488,
        "f1": 0.859614,
        "accuracy": 0.889488,
        "main_score": 0.859614,
        "hf_subset": "hye-eng",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.852867,
        "recall": 0.893,
        "f1": 0.865667,
        "accuracy": 0.893,
        "main_score": 0.865667,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.538096,
        "recall": 0.611,
        "f1": 0.558643,
        "accuracy": 0.611,
        "main_score": 0.558643,
        "hf_subset": "eus-eng",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.969333,
        "recall": 0.979,
        "f1": 0.9725,
        "accuracy": 0.979,
        "main_score": 0.9725,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.89395,
        "recall": 0.921,
        "f1": 0.902233,
        "accuracy": 0.921,
        "main_score": 0.902233,
        "hf_subset": "ind-eng",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.830267,
        "recall": 0.87,
        "f1": 0.842467,
        "accuracy": 0.87,
        "main_score": 0.842467,
        "hf_subset": "glg-eng",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.92375,
        "recall": 0.947,
        "f1": 0.9314,
        "accuracy": 0.947,
        "main_score": 0.9314,
        "hf_subset": "epo-eng",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.091725,
        "recall": 0.127,
        "f1": 0.0998,
        "accuracy": 0.127,
        "main_score": 0.0998,
        "hf_subset": "mhr-eng",
        "languages": [
          "mhr-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.598426,
        "recall": 0.666,
        "f1": 0.617681,
        "accuracy": 0.666,
        "main_score": 0.617681,
        "hf_subset": "lit-eng",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.742949,
        "recall": 0.797084,
        "f1": 0.758485,
        "accuracy": 0.797084,
        "main_score": 0.758485,
        "hf_subset": "slv-eng",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 33.14188003540039,
  "kg_co2_emissions": 0.0012070111554429684
}