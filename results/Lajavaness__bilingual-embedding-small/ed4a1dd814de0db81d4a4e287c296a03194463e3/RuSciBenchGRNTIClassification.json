{
  "dataset_revision": "673a610d6d3dd91a547a0d57ae1b56f37ebbf6a1",
  "task_name": "RuSciBenchGRNTIClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.560938,
        "f1": 0.557549,
        "f1_weighted": 0.55766,
        "scores_per_experiment": [
          {
            "accuracy": 0.578125,
            "f1": 0.570707,
            "f1_weighted": 0.570836
          },
          {
            "accuracy": 0.55957,
            "f1": 0.555843,
            "f1_weighted": 0.55591
          },
          {
            "accuracy": 0.53418,
            "f1": 0.530778,
            "f1_weighted": 0.530896
          },
          {
            "accuracy": 0.584473,
            "f1": 0.5811,
            "f1_weighted": 0.581194
          },
          {
            "accuracy": 0.559082,
            "f1": 0.558497,
            "f1_weighted": 0.558567
          },
          {
            "accuracy": 0.555176,
            "f1": 0.550214,
            "f1_weighted": 0.550332
          },
          {
            "accuracy": 0.567871,
            "f1": 0.565133,
            "f1_weighted": 0.565301
          },
          {
            "accuracy": 0.546875,
            "f1": 0.543695,
            "f1_weighted": 0.543815
          },
          {
            "accuracy": 0.55957,
            "f1": 0.556629,
            "f1_weighted": 0.556743
          },
          {
            "accuracy": 0.564453,
            "f1": 0.562893,
            "f1_weighted": 0.563008
          }
        ],
        "main_score": 0.560938,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 14.478756189346313,
  "kg_co2_emissions": 0.0005766326975558528
}