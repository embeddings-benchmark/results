{
  "dataset_revision": "b89853e6de927b0e3bfa8ecc0e56fe4e02ceafc6",
  "task_name": "AllegroReviews",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.331809,
        "f1": 0.302039,
        "f1_weighted": 0.353989,
        "scores_per_experiment": [
          {
            "accuracy": 0.306163,
            "f1": 0.286252,
            "f1_weighted": 0.333226
          },
          {
            "accuracy": 0.378728,
            "f1": 0.342889,
            "f1_weighted": 0.401812
          },
          {
            "accuracy": 0.347913,
            "f1": 0.325193,
            "f1_weighted": 0.376213
          },
          {
            "accuracy": 0.337972,
            "f1": 0.304673,
            "f1_weighted": 0.359726
          },
          {
            "accuracy": 0.289264,
            "f1": 0.278764,
            "f1_weighted": 0.309835
          },
          {
            "accuracy": 0.382704,
            "f1": 0.325374,
            "f1_weighted": 0.400039
          },
          {
            "accuracy": 0.324056,
            "f1": 0.30135,
            "f1_weighted": 0.336156
          },
          {
            "accuracy": 0.306163,
            "f1": 0.284222,
            "f1_weighted": 0.335379
          },
          {
            "accuracy": 0.343936,
            "f1": 0.290921,
            "f1_weighted": 0.360288
          },
          {
            "accuracy": 0.301193,
            "f1": 0.280748,
            "f1_weighted": 0.327216
          }
        ],
        "main_score": 0.331809,
        "hf_subset": "default",
        "languages": [
          "pol-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.217167615890503,
  "kg_co2_emissions": 0.00026186966878867035
}