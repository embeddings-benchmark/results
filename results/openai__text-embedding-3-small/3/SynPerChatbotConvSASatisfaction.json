{
  "dataset_revision": "50fd9d5d09edd53af89af765636be5db6f983f0e",
  "task_name": "SynPerChatbotConvSASatisfaction",
  "mteb_version": "1.38.49",
  "scores": {
    "test": [
      {
        "accuracy": 0.866434,
        "f1": 0.854529,
        "f1_weighted": 0.865856,
        "ap": 0.863159,
        "ap_weighted": 0.863159,
        "scores_per_experiment": [
          {
            "accuracy": 0.878788,
            "f1": 0.865023,
            "f1_weighted": 0.876778,
            "ap": 0.863022,
            "ap_weighted": 0.863022
          },
          {
            "accuracy": 0.862471,
            "f1": 0.851214,
            "f1_weighted": 0.862375,
            "ap": 0.863514,
            "ap_weighted": 0.863514
          },
          {
            "accuracy": 0.895105,
            "f1": 0.883764,
            "f1_weighted": 0.893666,
            "ap": 0.879937,
            "ap_weighted": 0.879937
          },
          {
            "accuracy": 0.83683,
            "f1": 0.821692,
            "f1_weighted": 0.835861,
            "ap": 0.835678,
            "ap_weighted": 0.835678
          },
          {
            "accuracy": 0.876457,
            "f1": 0.865586,
            "f1_weighted": 0.876011,
            "ap": 0.872886,
            "ap_weighted": 0.872886
          },
          {
            "accuracy": 0.83683,
            "f1": 0.823228,
            "f1_weighted": 0.836601,
            "ap": 0.840107,
            "ap_weighted": 0.840107
          },
          {
            "accuracy": 0.881119,
            "f1": 0.869501,
            "f1_weighted": 0.880121,
            "ap": 0.872202,
            "ap_weighted": 0.872202
          },
          {
            "accuracy": 0.885781,
            "f1": 0.876085,
            "f1_weighted": 0.885538,
            "ap": 0.883098,
            "ap_weighted": 0.883098
          },
          {
            "accuracy": 0.834499,
            "f1": 0.822852,
            "f1_weighted": 0.83524,
            "ap": 0.844937,
            "ap_weighted": 0.844937
          },
          {
            "accuracy": 0.876457,
            "f1": 0.866345,
            "f1_weighted": 0.876371,
            "ap": 0.876213,
            "ap_weighted": 0.876213
          }
        ],
        "main_score": 0.866434,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 112.34343838691711,
  "kg_co2_emissions": null
}