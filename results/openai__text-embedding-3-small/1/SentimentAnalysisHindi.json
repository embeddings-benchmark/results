{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 36.14345026016235,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.4654296875,
        "f1": 0.4434969561728394,
        "f1_weighted": 0.47398315578261413,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.4434969561728394,
        "scores_per_experiment": [
          {
            "accuracy": 0.4609375,
            "f1": 0.43402415781037434,
            "f1_weighted": 0.46439382345232183
          },
          {
            "accuracy": 0.46533203125,
            "f1": 0.4345785488238856,
            "f1_weighted": 0.47754110433741437
          },
          {
            "accuracy": 0.509765625,
            "f1": 0.4775228289928209,
            "f1_weighted": 0.5251050308501171
          },
          {
            "accuracy": 0.453125,
            "f1": 0.43635042232520965,
            "f1_weighted": 0.4507365143869986
          },
          {
            "accuracy": 0.50537109375,
            "f1": 0.47707781278570915,
            "f1_weighted": 0.513902253660642
          },
          {
            "accuracy": 0.4287109375,
            "f1": 0.4131818814200125,
            "f1_weighted": 0.43796025460442
          },
          {
            "accuracy": 0.47119140625,
            "f1": 0.4538474395863304,
            "f1_weighted": 0.48260484380381274
          },
          {
            "accuracy": 0.44970703125,
            "f1": 0.4314316980390657,
            "f1_weighted": 0.46386667132176174
          },
          {
            "accuracy": 0.39892578125,
            "f1": 0.39673840502723423,
            "f1_weighted": 0.41131172823672724
          },
          {
            "accuracy": 0.51123046875,
            "f1": 0.48021636691775144,
            "f1_weighted": 0.5124093331719259
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}