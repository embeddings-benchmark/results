{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 496.86677956581116,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.4",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8266514387913289,
        "cosine_spearman": 0.8111488594895316,
        "euclidean_pearson": 0.8101059349603454,
        "euclidean_spearman": 0.8111488594895316,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.8111488594895316,
        "manhattan_pearson": 0.8100185492287415,
        "manhattan_spearman": 0.8125172320787998,
        "pearson": 0.8266514387913289,
        "spearman": 0.8111488594895316
      },
      {
        "cosine_pearson": 0.6833060852806844,
        "cosine_spearman": 0.6574302908165865,
        "euclidean_pearson": 0.6707798280590631,
        "euclidean_spearman": 0.6574302908165865,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.6574302908165865,
        "manhattan_pearson": 0.6722321067250545,
        "manhattan_spearman": 0.6588287160059291,
        "pearson": 0.6833060852806844,
        "spearman": 0.6574302908165865
      },
      {
        "cosine_pearson": 0.5801359518746086,
        "cosine_spearman": 0.5862392053407633,
        "euclidean_pearson": 0.5684854628386473,
        "euclidean_spearman": 0.5862392053407633,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.5862392053407633,
        "manhattan_pearson": 0.5633900045148502,
        "manhattan_spearman": 0.5817931136272056,
        "pearson": 0.5801359518746086,
        "spearman": 0.5862392053407633
      },
      {
        "cosine_pearson": 0.5250337437340491,
        "cosine_spearman": 0.4832845605030491,
        "euclidean_pearson": 0.5278131370699864,
        "euclidean_spearman": 0.4832845605030491,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.4832845605030491,
        "manhattan_pearson": 0.5307088466265655,
        "manhattan_spearman": 0.48420631065613584,
        "pearson": 0.5250337437340491,
        "spearman": 0.4832845605030491
      },
      {
        "cosine_pearson": 0.454048740060092,
        "cosine_spearman": 0.44043558265798044,
        "euclidean_pearson": 0.4552456526243396,
        "euclidean_spearman": 0.44043558265798044,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.44043558265798044,
        "manhattan_pearson": 0.45496706036516754,
        "manhattan_spearman": 0.4399854585756902,
        "pearson": 0.454048740060092,
        "spearman": 0.44043558265798044
      },
      {
        "cosine_pearson": 0.8402386159396578,
        "cosine_spearman": 0.8296149295249461,
        "euclidean_pearson": 0.8321462589815403,
        "euclidean_spearman": 0.8296155910077538,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8296149295249461,
        "manhattan_pearson": 0.8315181510109222,
        "manhattan_spearman": 0.8289666582739846,
        "pearson": 0.8402386159396578,
        "spearman": 0.8296149295249461
      },
      {
        "cosine_pearson": 0.43845640135599223,
        "cosine_spearman": 0.4135705211654271,
        "euclidean_pearson": 0.44603745960837293,
        "euclidean_spearman": 0.4135705211654271,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.4135705211654271,
        "manhattan_pearson": 0.4475765717680603,
        "manhattan_spearman": 0.4146247502567597,
        "pearson": 0.43845640135599223,
        "spearman": 0.4135705211654271
      },
      {
        "cosine_pearson": 0.6733772782456429,
        "cosine_spearman": 0.6674662107165373,
        "euclidean_pearson": 0.6533225374975853,
        "euclidean_spearman": 0.6674662107165373,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.6674662107165373,
        "manhattan_pearson": 0.6530670903787255,
        "manhattan_spearman": 0.6656970663409563,
        "pearson": 0.6733772782456429,
        "spearman": 0.6674662107165373
      },
      {
        "cosine_pearson": 0.5332070710030166,
        "cosine_spearman": 0.5351887642569362,
        "euclidean_pearson": 0.5424553153281457,
        "euclidean_spearman": 0.5351887642569362,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.5351887642569362,
        "manhattan_pearson": 0.5412267215114623,
        "manhattan_spearman": 0.5348005771120923,
        "pearson": 0.5332070710030166,
        "spearman": 0.5351887642569362
      },
      {
        "cosine_pearson": 0.45671197630348204,
        "cosine_spearman": 0.442825783913707,
        "euclidean_pearson": 0.46218323714468007,
        "euclidean_spearman": 0.442825783913707,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.442825783913707,
        "manhattan_pearson": 0.46278462305439727,
        "manhattan_spearman": 0.4427582815727433,
        "pearson": 0.45671197630348204,
        "spearman": 0.442825783913707
      },
      {
        "cosine_pearson": 0.7282947900301493,
        "cosine_spearman": 0.7099338784460871,
        "euclidean_pearson": 0.713564409835925,
        "euclidean_spearman": 0.7099338784460871,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7099338784460871,
        "manhattan_pearson": 0.7144474770228613,
        "manhattan_spearman": 0.7107039008344938,
        "pearson": 0.7282947900301493,
        "spearman": 0.7099338784460871
      },
      {
        "cosine_pearson": 0.7655312820422988,
        "cosine_spearman": 0.7306036827172419,
        "euclidean_pearson": 0.7460873010274297,
        "euclidean_spearman": 0.7306036827172419,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7306036827172419,
        "manhattan_pearson": 0.7464874037451465,
        "manhattan_spearman": 0.7297400489696851,
        "pearson": 0.7655312820422988,
        "spearman": 0.7306036827172419
      }
    ]
  },
  "task_name": "SemRel24STS"
}