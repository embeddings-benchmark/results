{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 349.28663063049316,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.7216796875,
        "f1": 0.6620035807291667,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.6620035807291667,
        "precision": 0.6382095931412338,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.06327194045105733,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.06327194045105733,
        "precision": 0.05529608285955942,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.1436545748190418,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.1436545748190418,
        "precision": 0.13058519442796784,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.03577895979378056,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.03577895979378056,
        "precision": 0.03037657117414597,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.09456120051823177,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.09456120051823177,
        "precision": 0.08488426482573154,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.13028547584211647,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.13028547584211647,
        "precision": 0.11686857250822094,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.3115234375,
        "f1": 0.25007579297644056,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.25007579297644056,
        "precision": 0.2321019985496463,
        "recall": 0.3115234375
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.08852920715713683,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.08852920715713683,
        "precision": 0.08052633981502136,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.027380273746084934,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.027380273746084934,
        "precision": 0.024336367214308808,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.275390625,
        "f1": 0.22148843834484938,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.22148843834484938,
        "precision": 0.20554405126066821,
        "recall": 0.275390625
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07076432499351698,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.07076432499351698,
        "precision": 0.06388662466671821,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.2216796875,
        "f1": 0.17343457400822065,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.17343457400822065,
        "precision": 0.16086002156734122,
        "recall": 0.2216796875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002565198066907051,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.002565198066907051,
        "precision": 0.002010478670634921,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.22586219218496184,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.22586219218496184,
        "precision": 0.21139947571532733,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.057560452585543015,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.057560452585543015,
        "precision": 0.051193708677903786,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.08539036552687199,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.08539036552687199,
        "precision": 0.07717752258337048,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.16271329753032054,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.16271329753032054,
        "precision": 0.14828155371415092,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0029669641486047738,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0029669641486047738,
        "precision": 0.002582116362458267,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.09059442790168529,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.09059442790168529,
        "precision": 0.08348355583218864,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0195068782985107,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0195068782985107,
        "precision": 0.01692661830357143,
        "recall": 0.03125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07256396646238791,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.07256396646238791,
        "precision": 0.06521179958331186,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.0406289729127305,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0406289729127305,
        "precision": 0.036633519817007416,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.7373046875,
        "f1": 0.682155257936508,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.682155257936508,
        "precision": 0.6603201729910714,
        "recall": 0.7373046875
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.07121952175961792,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.07121952175961792,
        "precision": 0.06190266181046282,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.2919921875,
        "f1": 0.23472069380272506,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.23472069380272506,
        "precision": 0.21784665529782715,
        "recall": 0.2919921875
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.11165212896683907,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.11165212896683907,
        "precision": 0.09772819248893468,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.1432342555958135,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.1432342555958135,
        "precision": 0.12909757251984208,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.15157632794608533,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.15157632794608533,
        "precision": 0.1359561364200036,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.498046875,
        "f1": 0.42268105158730157,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.42268105158730157,
        "precision": 0.39608874740710676,
        "recall": 0.498046875
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.10757351903184341,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.10757351903184341,
        "precision": 0.09463756593883546,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.04437483530860139,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.04437483530860139,
        "precision": 0.03985145650869498,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.3417846304416447,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.3417846304416447,
        "precision": 0.31841828220686835,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.10644760492788621,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.10644760492788621,
        "precision": 0.09293595256427681,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.2919921875,
        "f1": 0.22978165712899745,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.22978165712899745,
        "precision": 0.21071299310533498,
        "recall": 0.2919921875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004250647888922518,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.004250647888922518,
        "precision": 0.0033108330471611717,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.41015625,
        "f1": 0.3426845804533921,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.3426845804533921,
        "precision": 0.31977074032738095,
        "recall": 0.41015625
      },
      {
        "accuracy": 0.125,
        "f1": 0.08976184756573083,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.08976184756573083,
        "precision": 0.0794471076532485,
        "recall": 0.125
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.10731315667839103,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.10731315667839103,
        "precision": 0.09576903944579726,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.310546875,
        "f1": 0.2375357931998557,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.2375357931998557,
        "precision": 0.2135168759192197,
        "recall": 0.310546875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012576341163436982,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0012576341163436982,
        "precision": 0.0011403508771929824,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.15474154200823967,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.15474154200823967,
        "precision": 0.14098863229722605,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.045765763456321634,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.045765763456321634,
        "precision": 0.03975751493550132,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.10333505040367917,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.10333505040367917,
        "precision": 0.09349956094818526,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.09324882499802076,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.09324882499802076,
        "precision": 0.08363732215050575,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05394426971973589,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.05394426971973589,
        "precision": 0.04871186265025522,
        "recall": 0.078125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07144525816657807,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.07144525816657807,
        "precision": 0.06618334911361107,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.15458196994307172,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.15458196994307172,
        "precision": 0.14489025265222083,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.038620254196268564,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.038620254196268564,
        "precision": 0.03379586885440016,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.12991541849093077,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.12991541849093077,
        "precision": 0.12043794634649825,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04166931502765113,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.04166931502765113,
        "precision": 0.03726311137962071,
        "recall": 0.0625
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.1550983167685467,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.1550983167685467,
        "precision": 0.14442545182691885,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.014655080014789998,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.014655080014789998,
        "precision": 0.012671409392397746,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.05481195237054612,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.05481195237054612,
        "precision": 0.05003692996236954,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.12070311693374422,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.12070311693374422,
        "precision": 0.11211535717748317,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.0494475855270603,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0494475855270603,
        "precision": 0.04560864994611378,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09549948247373719,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09549948247373719,
        "precision": 0.08859643882096999,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017513055571766823,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0017513055571766823,
        "precision": 0.0012191040107989836,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1669921875,
        "f1": 0.12513389006444733,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.12513389006444733,
        "precision": 0.11562723263355701,
        "recall": 0.1669921875
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.012446353088336784,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.012446353088336784,
        "precision": 0.011180099194534034,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.05778912927350427,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.05778912927350427,
        "precision": 0.05263651017218325,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.09344664975640042,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.09344664975640042,
        "precision": 0.08478533988831687,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0012942983856132103,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0012942983856132103,
        "precision": 0.0011436344486270812,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1669921875,
        "f1": 0.1377825085755801,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1377825085755801,
        "precision": 0.1301494795825975,
        "recall": 0.1669921875
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.04077611208397144,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.04077611208397144,
        "precision": 0.03771380560974043,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.041194714512081294,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.041194714512081294,
        "precision": 0.03770191021475764,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.05097542532423503,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.05097542532423503,
        "precision": 0.04748130897422889,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.14784862740801027,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.14784862740801027,
        "precision": 0.13325719580544143,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.2890625,
        "f1": 0.22823660714285712,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.22823660714285712,
        "precision": 0.2078748318738553,
        "recall": 0.2890625
      },
      {
        "accuracy": 0.2607421875,
        "f1": 0.19707270810786437,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.19707270810786437,
        "precision": 0.17873052240728024,
        "recall": 0.2607421875
      },
      {
        "accuracy": 0.265625,
        "f1": 0.20017002123404976,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.20017002123404976,
        "precision": 0.18389662237362797,
        "recall": 0.265625
      },
      {
        "accuracy": 0.5029296875,
        "f1": 0.43675845989437434,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.43675845989437434,
        "precision": 0.41283495557177197,
        "recall": 0.5029296875
      },
      {
        "accuracy": 0.2216796875,
        "f1": 0.16909565229809248,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.16909565229809248,
        "precision": 0.1530351736907555,
        "recall": 0.2216796875
      },
      {
        "accuracy": 0.8408203125,
        "f1": 0.7967029389880953,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7967029389880953,
        "precision": 0.7775065104166667,
        "recall": 0.8408203125
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.062464150268919716,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.062464150268919716,
        "precision": 0.05506705615348194,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.1208680913270757,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1208680913270757,
        "precision": 0.10801327307674964,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.7763671875,
        "f1": 0.7264308120265152,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7264308120265152,
        "precision": 0.7054454985119047,
        "recall": 0.7763671875
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.11827384531255286,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11827384531255286,
        "precision": 0.10720356332718466,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.5380859375,
        "f1": 0.46470114087301584,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.46470114087301584,
        "precision": 0.4376953125,
        "recall": 0.5380859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0031291088754082175,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0031291088754082175,
        "precision": 0.0021246609783026112,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.5804812212527056,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5804812212527056,
        "precision": 0.5563135540674604,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.026312497723630535,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.026312497723630535,
        "precision": 0.023469770247113997,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.3681640625,
        "f1": 0.30200196396485457,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.30200196396485457,
        "precision": 0.27954672660239066,
        "recall": 0.3681640625
      },
      {
        "accuracy": 0.4482421875,
        "f1": 0.371512685990225,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.371512685990225,
        "precision": 0.34543805803571426,
        "recall": 0.4482421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010489107557863783,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0010489107557863783,
        "precision": 0.0006885092684938928,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.638671875,
        "f1": 0.5773452513198607,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5773452513198607,
        "precision": 0.5539643787202382,
        "recall": 0.638671875
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.07483156436152184,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.07483156436152184,
        "precision": 0.06499230833794753,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.11872707732082732,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11872707732082732,
        "precision": 0.10405736570287352,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.24609375,
        "f1": 0.19702386272467481,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.19702386272467481,
        "precision": 0.1809193817250458,
        "recall": 0.24609375
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.05862935350240038,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.05862935350240038,
        "precision": 0.05001743375682626,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.1341952660826016,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.1341952660826016,
        "precision": 0.11774868481957176,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.05317568424873898,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.05317568424873898,
        "precision": 0.04282808160551152,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.2380812384230353,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.2380812384230353,
        "precision": 0.21048534973885386,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.2119140625,
        "f1": 0.1445907742059686,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.1445907742059686,
        "precision": 0.12484990188847611,
        "recall": 0.2119140625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03373483070748695,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.03373483070748695,
        "precision": 0.028302184610566064,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.578125,
        "f1": 0.5001449342757937,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.5001449342757937,
        "precision": 0.4698172433035714,
        "recall": 0.578125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017787269154456654,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.017787269154456654,
        "precision": 0.014583552369090752,
        "recall": 0.03125
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.16468530555701608,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.16468530555701608,
        "precision": 0.14564755215303057,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.302734375,
        "f1": 0.22073652259199136,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.22073652259199136,
        "precision": 0.19410655804698773,
        "recall": 0.302734375
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.06074264725122401,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.06074264725122401,
        "precision": 0.0508347726378154,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.16049494667658729,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.16049494667658729,
        "precision": 0.14045006999237056,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003024881827731092,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.003024881827731092,
        "precision": 0.0022565225239504086,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.27734375,
        "f1": 0.20020848834325394,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.20020848834325394,
        "precision": 0.17593158156692162,
        "recall": 0.27734375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0032558037337845273,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0032558037337845273,
        "precision": 0.0023497918639520205,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.07263060270268087,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.07263060270268087,
        "precision": 0.06324957567389208,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.15395346378371422,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.15395346378371422,
        "precision": 0.13482200985863094,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001243161948728355,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.001243161948728355,
        "precision": 0.0007629886881575171,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2412109375,
        "f1": 0.172585922734977,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.172585922734977,
        "precision": 0.1512654093952922,
        "recall": 0.2412109375
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.06167830469588281,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.06167830469588281,
        "precision": 0.05102197144792503,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.03929929110850164,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.03929929110850164,
        "precision": 0.03276955488725939,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.4912109375,
        "f1": 0.40721571180555555,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.40721571180555555,
        "precision": 0.37714889548385644,
        "recall": 0.4912109375
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.11746649346747003,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.11746649346747003,
        "precision": 0.10611375851738722,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.203125,
        "f1": 0.148169790821158,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.148169790821158,
        "precision": 0.1320211462990645,
        "recall": 0.203125
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.14737850018611737,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.14737850018611737,
        "precision": 0.1307656292275433,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.432059807596917,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.432059807596917,
        "precision": 0.4085316864125458,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.11531530344145234,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11531530344145234,
        "precision": 0.1065458935700654,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.12389201781291623,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.12389201781291623,
        "precision": 0.11137822138798702,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.5869140625,
        "f1": 0.5190946819878769,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5190946819878769,
        "precision": 0.4935802641369047,
        "recall": 0.5869140625
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.052134739430810206,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.052134739430810206,
        "precision": 0.04369010302848193,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09279994349502621,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.09279994349502621,
        "precision": 0.08074730309837731,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.513671875,
        "f1": 0.4456433269421551,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4456433269421551,
        "precision": 0.4203590029761905,
        "recall": 0.513671875
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.0943268798030825,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0943268798030825,
        "precision": 0.08373233546521446,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6837239583333334,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6837239583333334,
        "precision": 0.6594424293154761,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009202670031715113,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009202670031715113,
        "precision": 0.0005905877976190476,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.3777167312237395,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.3777167312237395,
        "precision": 0.35433388361855156,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.02454039558531746,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.02454039558531746,
        "precision": 0.021334190621299993,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.1322346064410656,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1322346064410656,
        "precision": 0.12031919959081866,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.3935546875,
        "f1": 0.3227162675649004,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.3227162675649004,
        "precision": 0.2976159826501623,
        "recall": 0.3935546875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015873313969017092,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0015873313969017092,
        "precision": 0.0013291873975168817,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.34804623353566366,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.34804623353566366,
        "precision": 0.32597640396712657,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.06487667958126941,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.06487667958126941,
        "precision": 0.054586056619511755,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09635038355741479,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09635038355741479,
        "precision": 0.0876073795995671,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10970698738391753,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10970698738391753,
        "precision": 0.10000379753582303,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.1401740763120286,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.1401740763120286,
        "precision": 0.1276074859008368,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.1579826196795255,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.1579826196795255,
        "precision": 0.14242837326461916,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.04415817643613697,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.04415817643613697,
        "precision": 0.03941545758928571,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.16173765853773261,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.16173765853773261,
        "precision": 0.1494095494121193,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.014424214873160786,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.014424214873160786,
        "precision": 0.010939035615675914,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.1328955007665945,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.1328955007665945,
        "precision": 0.12092521194083694,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.2802734375,
        "f1": 0.22660001277093503,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.22660001277093503,
        "precision": 0.20978855942234848,
        "recall": 0.2802734375
      },
      {
        "accuracy": 0.27734375,
        "f1": 0.21329604640151514,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.21329604640151514,
        "precision": 0.19438582065663684,
        "recall": 0.27734375
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.03405285612581092,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.03405285612581092,
        "precision": 0.029771093178910815,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.2373046875,
        "f1": 0.18250056889100646,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.18250056889100646,
        "precision": 0.16744043039209056,
        "recall": 0.2373046875
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.148110633111782,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.148110633111782,
        "precision": 0.1343255575634367,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.1673172151199495,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.1673172151199495,
        "precision": 0.15203312759034265,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001345486111111111,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.001345486111111111,
        "precision": 0.0011741837883478751,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.21484375,
        "f1": 0.1653223963308256,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.1653223963308256,
        "precision": 0.1503455740930265,
        "recall": 0.21484375
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.08037562480921856,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.08037562480921856,
        "precision": 0.06969172049738456,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.31640625,
        "f1": 0.26025003063670943,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.26025003063670943,
        "precision": 0.24241250236251777,
        "recall": 0.31640625
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.13127969884818672,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.13127969884818672,
        "precision": 0.11744529211058319,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002620143673447069,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.002620143673447069,
        "precision": 0.002094519962590299,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.13137841460748467,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.13137841460748467,
        "precision": 0.12191525356437041,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.048170597391917286,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.048170597391917286,
        "precision": 0.04165386198775264,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.22922458400974025,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.22922458400974025,
        "precision": 0.21431024568756096,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.050995621674332615,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.050995621674332615,
        "precision": 0.04449969200202726,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.3466796875,
        "f1": 0.27482168981192423,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.27482168981192423,
        "precision": 0.25095304989893685,
        "recall": 0.3466796875
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.4353788301542208,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.4353788301542208,
        "precision": 0.4042085193452381,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.2666015625,
        "f1": 0.19637902281456968,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.19637902281456968,
        "precision": 0.17555455341099874,
        "recall": 0.2666015625
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8312034970238096,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8312034970238096,
        "precision": 0.815869140625,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.56640625,
        "f1": 0.49048304668421855,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.49048304668421855,
        "precision": 0.4631111266121032,
        "recall": 0.56640625
      },
      {
        "accuracy": 0.6240234375,
        "f1": 0.556543814258658,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.556543814258658,
        "precision": 0.5302183493589744,
        "recall": 0.6240234375
      },
      {
        "accuracy": 0.296875,
        "f1": 0.22956095011759076,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.22956095011759076,
        "precision": 0.2078263912736569,
        "recall": 0.296875
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.10294462481962481,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.10294462481962481,
        "precision": 0.08896135602678572,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.1943359375,
        "f1": 0.14275167649191084,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.14275167649191084,
        "precision": 0.12669758464192057,
        "recall": 0.1943359375
      },
      {
        "accuracy": 0.9326171875,
        "f1": 0.9122721354166666,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9122721354166666,
        "precision": 0.9025065104166667,
        "recall": 0.9326171875
      },
      {
        "accuracy": 0.2158203125,
        "f1": 0.1666045434600122,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1666045434600122,
        "precision": 0.1513255890867134,
        "recall": 0.2158203125
      },
      {
        "accuracy": 0.744140625,
        "f1": 0.6800967261904762,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6800967261904762,
        "precision": 0.6525716145833333,
        "recall": 0.744140625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009194473061660562,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009194473061660562,
        "precision": 0.0005901565882034633,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8053385416666667,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8053385416666667,
        "precision": 0.7867024739583333,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.041856659508026695,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.041856659508026695,
        "precision": 0.03534622833508404,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.3251953125,
        "f1": 0.25169815536026474,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.25169815536026474,
        "precision": 0.22568905432674966,
        "recall": 0.3251953125
      },
      {
        "accuracy": 0.630859375,
        "f1": 0.5601640004960318,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.5601640004960318,
        "precision": 0.5303978329613095,
        "recall": 0.630859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015623708250661374,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0015623708250661374,
        "precision": 0.0013045393680029959,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.646484375,
        "f1": 0.5798591734871031,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5798591734871031,
        "precision": 0.5546103229452839,
        "recall": 0.646484375
      },
      {
        "accuracy": 0.125,
        "f1": 0.0873997801243895,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0873997801243895,
        "precision": 0.0770217005294193,
        "recall": 0.125
      },
      {
        "accuracy": 0.20703125,
        "f1": 0.154200064258658,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.154200064258658,
        "precision": 0.13756866234893578,
        "recall": 0.20703125
      },
      {
        "accuracy": 0.3984375,
        "f1": 0.3281924293154762,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.3281924293154762,
        "precision": 0.3026971726190476,
        "recall": 0.3984375
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.07246529891549422,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.07246529891549422,
        "precision": 0.06449398118622449,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.09546001224827051,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.09546001224827051,
        "precision": 0.08477974526558511,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.022081043956043957,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.022081043956043957,
        "precision": 0.01871746588800454,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.04960288905858396,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.04960288905858396,
        "precision": 0.045017981150793654,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007279146634615384,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.007279146634615384,
        "precision": 0.005146889329146731,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.050957612537202365,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.050957612537202365,
        "precision": 0.04517769425704783,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.2763671875,
        "f1": 0.2271744437652879,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.2271744437652879,
        "precision": 0.21194936743510112,
        "recall": 0.2763671875
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.08158122837334905,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.08158122837334905,
        "precision": 0.07325351383677367,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.010006510416666666,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.010006510416666666,
        "precision": 0.00836514559659091,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.07978362783050283,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.07978362783050283,
        "precision": 0.07179175262671356,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.2431640625,
        "f1": 0.18779995112655232,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.18779995112655232,
        "precision": 0.17221947742757143,
        "recall": 0.2431640625
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.0818853143061504,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0818853143061504,
        "precision": 0.07283038342714804,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001329985119047619,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.001329985119047619,
        "precision": 0.0008897569444444444,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06888286229106541,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.06888286229106541,
        "precision": 0.06112709623020974,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.0639307632471695,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.0639307632471695,
        "precision": 0.0572696093160822,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.09796305040445664,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.09796305040445664,
        "precision": 0.08724740338509869,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09746745938409179,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.09746745938409179,
        "precision": 0.08839914052607853,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002824457610924683,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.002824457610924683,
        "precision": 0.002193094034488795,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03795185391865079,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.03795185391865079,
        "precision": 0.03447666067294973,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08215489050281614,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.08215489050281614,
        "precision": 0.07419026979393961,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.44921875,
        "f1": 0.3902636433205409,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.3902636433205409,
        "precision": 0.37049308169829454,
        "recall": 0.44921875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.01672546289374003,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.01672546289374003,
        "precision": 0.014259236004735325,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.020149882198115893,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.020149882198115893,
        "precision": 0.016411927998195807,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03883648239373979,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.03883648239373979,
        "precision": 0.03372998476391653,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.048776693055653964,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.048776693055653964,
        "precision": 0.043762374371505236,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.1153576604283176,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.1153576604283176,
        "precision": 0.1054458344760822,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.171875,
        "f1": 0.13633630729475954,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.13633630729475954,
        "precision": 0.1278029531328302,
        "recall": 0.171875
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08478407339482943,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.08478407339482943,
        "precision": 0.07866477773273499,
        "recall": 0.109375
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03201536325050251,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.03201536325050251,
        "precision": 0.02660651555531221,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.1224317192424717,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.1224317192424717,
        "precision": 0.11216133984207882,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.010516599286130536,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.010516599286130536,
        "precision": 0.008775356359649121,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06188780252177868,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.06188780252177868,
        "precision": 0.05488248095471329,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.04951635549780081,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.04951635549780081,
        "precision": 0.04398523839441808,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.041899882015281956,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.041899882015281956,
        "precision": 0.035015484835375206,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0013621116849517586,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0013621116849517586,
        "precision": 0.0008932117428667517,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.0577534967585519,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0577534967585519,
        "precision": 0.051576819953990743,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0058521943933823525,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0058521943933823525,
        "precision": 0.004866969331781915,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06937103694916194,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.06937103694916194,
        "precision": 0.06298426317892943,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.03651572029249196,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.03651572029249196,
        "precision": 0.031703472622726325,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0027502719103243986,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0027502719103243986,
        "precision": 0.0020896143781619493,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09541096652913059,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.09541096652913059,
        "precision": 0.08740878889933165,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.05050107133581997,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.05050107133581997,
        "precision": 0.044929420099476675,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.04519287295884262,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.04519287295884262,
        "precision": 0.03963296807104252,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.734375,
        "f1": 0.6883719840044367,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.6883719840044367,
        "precision": 0.6716227213541668,
        "recall": 0.734375
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.21984540635239036,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.21984540635239036,
        "precision": 0.2003629169766865,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.4228515625,
        "f1": 0.3504293287008131,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.3504293287008131,
        "precision": 0.32599635782798697,
        "recall": 0.4228515625
      },
      {
        "accuracy": 0.212890625,
        "f1": 0.15436011467240238,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.15436011467240238,
        "precision": 0.13875502086313324,
        "recall": 0.212890625
      },
      {
        "accuracy": 0.779296875,
        "f1": 0.7252766927083333,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7252766927083333,
        "precision": 0.702060081845238,
        "recall": 0.779296875
      },
      {
        "accuracy": 0.2431640625,
        "f1": 0.17752906358991885,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.17752906358991885,
        "precision": 0.16000105609049772,
        "recall": 0.2431640625
      },
      {
        "accuracy": 0.5068359375,
        "f1": 0.43975081450667386,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.43975081450667386,
        "precision": 0.4152134486607143,
        "recall": 0.5068359375
      },
      {
        "accuracy": 0.248046875,
        "f1": 0.18854817057942058,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.18854817057942058,
        "precision": 0.1709236934047366,
        "recall": 0.248046875
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.8990559895833333,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8990559895833333,
        "precision": 0.8880208333333334,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.08260695594576078,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.08260695594576078,
        "precision": 0.07213051496255739,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.06766702911952223,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.06766702911952223,
        "precision": 0.05754240605314824,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.07740397469170084,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.07740397469170084,
        "precision": 0.06849294991641826,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.677734375,
        "f1": 0.6152064732142858,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6152064732142858,
        "precision": 0.5896647135416667,
        "recall": 0.677734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007164506097100574,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0007164506097100574,
        "precision": 0.0004488191336317136,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.7994977678571429,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7994977678571429,
        "precision": 0.7820963541666667,
        "recall": 0.83984375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04590441547844678,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.04590441547844678,
        "precision": 0.039001887598079,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.14448457087617242,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.14448457087617242,
        "precision": 0.1289784207954015,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.5673828125,
        "f1": 0.4944134424603175,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.4944134424603175,
        "precision": 0.4668672617415936,
        "recall": 0.5673828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008357823828060635,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008357823828060635,
        "precision": 0.00048221837739207047,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.5078125,
        "f1": 0.4435723944024725,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4435723944024725,
        "precision": 0.4213068290216728,
        "recall": 0.5078125
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.03366189651324672,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.03366189651324672,
        "precision": 0.02799713144927989,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.125,
        "f1": 0.08995379732516047,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.08995379732516047,
        "precision": 0.07959977662254594,
        "recall": 0.125
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.13679703000992063,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.13679703000992063,
        "precision": 0.1229794456845238,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07044071109012515,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.07044071109012515,
        "precision": 0.06337341423767204,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08857201593637469,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.08857201593637469,
        "precision": 0.08045558770656426,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.0640303859881815,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.0640303859881815,
        "precision": 0.05937429355526601,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.10315562163275857,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.10315562163275857,
        "precision": 0.09354279075958763,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.05099073276544004,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.05099073276544004,
        "precision": 0.04570503144419502,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.09023580586080586,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.09023580586080586,
        "precision": 0.08480528930322129,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.1513651959036863,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.1513651959036863,
        "precision": 0.14307676029843996,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.14605107732380765,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.14605107732380765,
        "precision": 0.13529913058335125,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.2255859375,
        "f1": 0.18825185366776942,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.18825185366776942,
        "precision": 0.17793110770743045,
        "recall": 0.2255859375
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.04685816534145709,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.04685816534145709,
        "precision": 0.04321605358046559,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06626362915007761,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.06626362915007761,
        "precision": 0.059042653262766545,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06878981695387945,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.06878981695387945,
        "precision": 0.06199200818039102,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004636701771875512,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.004636701771875512,
        "precision": 0.0036420285443722945,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06151867589149049,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.06151867589149049,
        "precision": 0.056188439509326456,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.02849082341269841,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.02849082341269841,
        "precision": 0.025957573784722222,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.1153050252064162,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.1153050252064162,
        "precision": 0.10637392934756215,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.09398295883776425,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.09398295883776425,
        "precision": 0.08485216768908174,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003817012392241379,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.003817012392241379,
        "precision": 0.0029176390016233764,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.0768421032092907,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.0768421032092907,
        "precision": 0.0716693990284788,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.15171440904370675,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.15171440904370675,
        "precision": 0.1406639570824141,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.2744140625,
        "f1": 0.2295725501169837,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.2295725501169837,
        "precision": 0.216213783404063,
        "recall": 0.2744140625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.06598052464751683,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.06598052464751683,
        "precision": 0.062237198565323566,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.2412109375,
        "f1": 0.18440161292700352,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.18440161292700352,
        "precision": 0.16701670802535756,
        "recall": 0.2412109375
      },
      {
        "accuracy": 0.3056640625,
        "f1": 0.24327305723790096,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.24327305723790096,
        "precision": 0.22325229837436872,
        "recall": 0.3056640625
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.11990942542700354,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.11990942542700354,
        "precision": 0.10576824219318157,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.5498046875,
        "f1": 0.48711649136453816,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.48711649136453816,
        "precision": 0.46415589347718256,
        "recall": 0.5498046875
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.12746121290300128,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.12746121290300128,
        "precision": 0.11473800483426243,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.728515625,
        "f1": 0.6719098772321428,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6719098772321428,
        "precision": 0.6487506200396825,
        "recall": 0.728515625
      },
      {
        "accuracy": 0.2333984375,
        "f1": 0.18170303817276473,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.18170303817276473,
        "precision": 0.1670403633208091,
        "recall": 0.2333984375
      },
      {
        "accuracy": 0.7353515625,
        "f1": 0.6800618489583332,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6800618489583332,
        "precision": 0.6567964099702381,
        "recall": 0.7353515625
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.10090130852106592,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.10090130852106592,
        "precision": 0.08859821603878043,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.049558057215456114,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.049558057215456114,
        "precision": 0.04218803901176948,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.6865234375,
        "f1": 0.6267957899305556,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6267957899305556,
        "precision": 0.6026541573660714,
        "recall": 0.6865234375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.0736817968602955,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0736817968602955,
        "precision": 0.06422606979247604,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0033618871716485504,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0033618871716485504,
        "precision": 0.002706557936307114,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.5544549851190477,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5544549851190477,
        "precision": 0.5281684027777778,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02572541370764813,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.02572541370764813,
        "precision": 0.021588516591532447,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.10031073639303703,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.10031073639303703,
        "precision": 0.09158412388392856,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.537109375,
        "f1": 0.4692971850198413,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.4692971850198413,
        "precision": 0.44320475260416664,
        "recall": 0.537109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00031253288089225586,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00031253288089225586,
        "precision": 0.00017483031456898626,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.3465595764912171,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3465595764912171,
        "precision": 0.32455428685897436,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.028947186710858584,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.028947186710858584,
        "precision": 0.02300182318970532,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.07561449509691696,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.07561449509691696,
        "precision": 0.06624307766885892,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.08284338908565853,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.08284338908565853,
        "precision": 0.07326795789930556,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.944620253164557e-06,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 4.944620253164557e-06,
        "precision": 2.4785850253807105e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.930035428329056e-05,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 3.930035428329056e-05,
        "precision": 1.980861896998334e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.8911015458980574e-05,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 1.8911015458980574e-05,
        "precision": 9.518296852333172e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.146291208791209e-06,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 2.146291208791209e-06,
        "precision": 1.0743261826182618e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012668700970272502,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0012668700970272502,
        "precision": 0.0011450006056201551,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.65106098995566e-05,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 2.65106098995566e-05,
        "precision": 1.3392601192523793e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.3462641378574477e-05,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 1.3462641378574477e-05,
        "precision": 6.756983615363953e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.245923913043478e-05,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 4.245923913043478e-05,
        "precision": 2.170138888888889e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019717261904761904,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0019717261904761904,
        "precision": 0.0019625150240384615,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016299073801100627,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0016299073801100627,
        "precision": 0.00146599671635183,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0025252115993337756,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0025252115993337756,
        "precision": 0.002292209201388889,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009858226781436293,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0009858226781436293,
        "precision": 0.0009812036865343707,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006777550200555637,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0006777550200555637,
        "precision": 0.0005017903645833333,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002028486704080899,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.002028486704080899,
        "precision": 0.001991481663348289,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014071025545634918,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0014071025545634918,
        "precision": 0.0012193029682423964,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.2235988394132916e-05,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 3.2235988394132916e-05,
        "precision": 1.6330089243358635e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002450826248345889,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.002450826248345889,
        "precision": 0.0022833672408991766,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016949277935606058,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.0016949277935606058,
        "precision": 0.0014996293115707503,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011775936406484325,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0011775936406484325,
        "precision": 0.0010860674474445823,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004996256824187329,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0004996256824187329,
        "precision": 0.0003312098163540778,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.8722426470588235e-05,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 2.8722426470588235e-05,
        "precision": 1.4575559701492537e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001706023556609494,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.001706023556609494,
        "precision": 0.0015055586400169205,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.2628863035113035,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.2628863035113035,
        "precision": 0.24054329363957122,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.41796875,
        "f1": 0.3424200148809524,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.3424200148809524,
        "precision": 0.31660004763032107,
        "recall": 0.41796875
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.16218328654852093,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.16218328654852093,
        "precision": 0.1446656487929103,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.6767578125,
        "f1": 0.6096617683531746,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6096617683531746,
        "precision": 0.5816650390625,
        "recall": 0.6767578125
      },
      {
        "accuracy": 0.20703125,
        "f1": 0.14984435765942755,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.14984435765942755,
        "precision": 0.13481116737378226,
        "recall": 0.20703125
      },
      {
        "accuracy": 0.4462890625,
        "f1": 0.37373046875000004,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.37373046875000004,
        "precision": 0.34836709966104495,
        "recall": 0.4462890625
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.16021758089886173,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.16021758089886173,
        "precision": 0.14466325318504597,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8060453869047619,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8060453869047619,
        "precision": 0.7881998697916666,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.06860469987911394,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.06860469987911394,
        "precision": 0.05692411429716117,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.062354361133658005,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.062354361133658005,
        "precision": 0.052803012959262964,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.84375,
        "f1": 0.8026227678571428,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8026227678571428,
        "precision": 0.7843749999999999,
        "recall": 0.84375
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.07899950877604829,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.07899950877604829,
        "precision": 0.07032525896051287,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.551811290922619,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.551811290922619,
        "precision": 0.5248763795882936,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016681505818619581,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0016681505818619581,
        "precision": 0.0014853310751748252,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.043979632276679614,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.043979632276679614,
        "precision": 0.038630342495663036,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.11150803869500386,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.11150803869500386,
        "precision": 0.0981753747012536,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.564453125,
        "f1": 0.4877999441964286,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4877999441964286,
        "precision": 0.45808686755952377,
        "recall": 0.564453125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001429371902481416,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001429371902481416,
        "precision": 0.0008622259386329121,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.4111328125,
        "f1": 0.3453876310321623,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3453876310321623,
        "precision": 0.32285091386223047,
        "recall": 0.4111328125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.034057568262606426,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.034057568262606426,
        "precision": 0.02824465523568628,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.0713511369273088,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0713511369273088,
        "precision": 0.06088173165809885,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.10446236976998696,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10446236976998696,
        "precision": 0.09193438668536325,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.022605591488124972,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.022605591488124972,
        "precision": 0.019893278196978517,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.026685303446303772,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.026685303446303772,
        "precision": 0.02331354062574534,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005071394148522574,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.005071394148522574,
        "precision": 0.004564177035978209,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007763480654128624,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.007763480654128624,
        "precision": 0.0064608816160815485,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019084862863686751,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0019084862863686751,
        "precision": 0.0016105124856264238,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00983474097948676,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.00983474097948676,
        "precision": 0.008009236229322578,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.021220478669161266,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.021220478669161266,
        "precision": 0.019742421857994276,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.017260257781498017,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.017260257781498017,
        "precision": 0.015243983139490953,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018329120208885816,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.018329120208885816,
        "precision": 0.016193576571218674,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003379189311594203,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.003379189311594203,
        "precision": 0.0028338160361333527,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.01760057251225393,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.01760057251225393,
        "precision": 0.015738723204966797,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.011177635750969452,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.011177635750969452,
        "precision": 0.009685771150763994,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.00916091742293436,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.00916091742293436,
        "precision": 0.007818741902058102,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002728174603174603,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.002728174603174603,
        "precision": 0.002010091145833333,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.017612583108003864,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.017612583108003864,
        "precision": 0.01598861849235241,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.014166173306578031,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.014166173306578031,
        "precision": 0.01279813362973263,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.011314026085233301,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.011314026085233301,
        "precision": 0.010032968072632337,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021998355263157894,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0021998355263157894,
        "precision": 0.0017735952798977413,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.009909936753114669,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.009909936753114669,
        "precision": 0.008928395280934342,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0028202491362956,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.0028202491362956,
        "precision": 0.002169687012562479,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.013262615687745895,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.013262615687745895,
        "precision": 0.012137902257687369,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0026041666666666665,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.00244140625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.06604865851426653,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.06604865851426653,
        "precision": 0.05659618498363615,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.09794380333164289,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.09794380333164289,
        "precision": 0.08756220360224266,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.06394007533668064,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.06394007533668064,
        "precision": 0.0565037978093398,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.302734375,
        "f1": 0.2503791527254726,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.2503791527254726,
        "precision": 0.23603726802930436,
        "recall": 0.302734375
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.047952725824040233,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.047952725824040233,
        "precision": 0.04336113813432998,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10796600748490684,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.10796600748490684,
        "precision": 0.09844614620049555,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.3046875,
        "f1": 0.2443712724962725,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.2443712724962725,
        "precision": 0.22644848554235025,
        "recall": 0.3046875
      },
      {
        "accuracy": 0.2314453125,
        "f1": 0.18410589484928974,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.18410589484928974,
        "precision": 0.1715148299993592,
        "recall": 0.2314453125
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.08790486773340475,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.08790486773340475,
        "precision": 0.07864773725953243,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06589311838335275,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.06589311838335275,
        "precision": 0.05999004422112975,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.10981711398943723,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.10981711398943723,
        "precision": 0.10076130351980536,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.10138015959952501,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.10138015959952501,
        "precision": 0.09304204382175621,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.09065358676943791,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.09065358676943791,
        "precision": 0.0818206270555765,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001469983552631579,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.001469983552631579,
        "precision": 0.0009819878472222222,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09047110589910967,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.09047110589910967,
        "precision": 0.0820749124629899,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.030447704422313794,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.030447704422313794,
        "precision": 0.026229085042561606,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.07405386955825986,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.07405386955825986,
        "precision": 0.064974117947815,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002008598372781065,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.002008598372781065,
        "precision": 0.001629050925925926,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.2138671875,
        "f1": 0.17215745680101147,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.17215745680101147,
        "precision": 0.1604175638708269,
        "recall": 0.2138671875
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.06449753859421828,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.06449753859421828,
        "precision": 0.05752984303922771,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.1962890625,
        "f1": 0.15235869353660025,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.15235869353660025,
        "precision": 0.14083398358911053,
        "recall": 0.1962890625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08514548049284629,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.08514548049284629,
        "precision": 0.0784420932542585,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.15099872165301853,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.15099872165301853,
        "precision": 0.137639632036704,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.267578125,
        "f1": 0.21092937079983265,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.21092937079983265,
        "precision": 0.19490873071985204,
        "recall": 0.267578125
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.10708452517614231,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.10708452517614231,
        "precision": 0.09549398935873384,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.3984375,
        "f1": 0.33765116624958674,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.33765116624958674,
        "precision": 0.31945179200607743,
        "recall": 0.3984375
      },
      {
        "accuracy": 0.125,
        "f1": 0.09036506915648321,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09036506915648321,
        "precision": 0.08175319018444499,
        "recall": 0.125
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.26805937469138297,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.26805937469138297,
        "precision": 0.24967973823001122,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.1160533759686693,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.1160533759686693,
        "precision": 0.10713586599640254,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.541015625,
        "f1": 0.47776934066253557,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.47776934066253557,
        "precision": 0.4554480684132205,
        "recall": 0.541015625
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09546824793070516,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.09546824793070516,
        "precision": 0.08520090024473942,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.0400775002481284,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0400775002481284,
        "precision": 0.03363260810258668,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.4990234375,
        "f1": 0.4365332111765535,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4365332111765535,
        "precision": 0.41514234694872015,
        "recall": 0.4990234375
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.09058428088328134,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.09058428088328134,
        "precision": 0.08145437055349165,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.466796875,
        "f1": 0.40043518764221886,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.40043518764221886,
        "precision": 0.37765264972736867,
        "recall": 0.466796875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016628671586965949,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0016628671586965949,
        "precision": 0.0014826361930641821,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.505859375,
        "f1": 0.4489221385168651,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4489221385168651,
        "precision": 0.42935665903672865,
        "recall": 0.505859375
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.024900993245507513,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.024900993245507513,
        "precision": 0.02152741188514215,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07142046538195314,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.07142046538195314,
        "precision": 0.0643922765602453,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017697671202125454,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0017697671202125454,
        "precision": 0.0014700406456241866,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.29296875,
        "f1": 0.2432682524341855,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2432682524341855,
        "precision": 0.22785023305334295,
        "recall": 0.29296875
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.031208082670064037,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.031208082670064037,
        "precision": 0.026331490663263412,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.125,
        "f1": 0.09196356916801539,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09196356916801539,
        "precision": 0.08342897445436508,
        "recall": 0.125
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.056922002970374655,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.056922002970374655,
        "precision": 0.0504990869590479,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0028921298053868286,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0028921298053868286,
        "precision": 0.002553707917826221,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003284566734010107,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.003284566734010107,
        "precision": 0.0028661151739659716,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003076613758484163,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0003076613758484163,
        "precision": 0.00016636396832718327,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009805812757201647,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0009805812757201647,
        "precision": 0.000978576030927835,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008496312220357943,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0008496312220357943,
        "precision": 0.0005984294759570495,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00296727614712183,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.00296727614712183,
        "precision": 0.0029487811443140986,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0020611433119898676,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0020611433119898676,
        "precision": 0.002009996602249032,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.340277777777778e-06,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 4.340277777777778e-06,
        "precision": 2.1749721603563473e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0036475377665449657,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0036475377665449657,
        "precision": 0.003452006770728125,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 9.007450928132446e-05,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 9.007450928132446e-05,
        "precision": 4.639227200868444e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00021462912087912088,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.00021462912087912088,
        "precision": 0.00011418269230769232,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00021269050250997373,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.00021269050250997373,
        "precision": 0.00011537036889257746,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001767113095238095,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.001767113095238095,
        "precision": 0.0015399639423076923,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002638308357734079,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.002638308357734079,
        "precision": 0.0024585938568653055,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.003011067708333333,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.003011067708333333,
        "precision": 0.002972146739130435,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019557256990679096,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0019557256990679096,
        "precision": 0.001954427083333333,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010749151939150351,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0010749151939150351,
        "precision": 0.0010270415836530005,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016150841346153845,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0016150841346153845,
        "precision": 0.0013534813596491227,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00048828125,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.00048828125,
        "precision": 0.0003255208333333333,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003583382869112319,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.003583382869112319,
        "precision": 0.003419297406462585,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0021995293474227134,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0021995293474227134,
        "precision": 0.002087427448699636,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009792941433566433,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0009792941433566433,
        "precision": 0.0009779302345938375,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.08782905298310006,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.08782905298310006,
        "precision": 0.07772331675768751,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.14523437080544757,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.14523437080544757,
        "precision": 0.13005716343118687,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.2431640625,
        "f1": 0.19443532008426162,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.19443532008426162,
        "precision": 0.17867398938433243,
        "recall": 0.2431640625
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.5812624007936508,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5812624007936508,
        "precision": 0.5563092912946428,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.12491628360164302,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.12491628360164302,
        "precision": 0.11062506322773077,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.4013671875,
        "f1": 0.3375096881200397,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3375096881200397,
        "precision": 0.31748072434236085,
        "recall": 0.4013671875
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.1242897906986106,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.1242897906986106,
        "precision": 0.11070071183212565,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.6103515625,
        "f1": 0.5422995966478696,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5422995966478696,
        "precision": 0.5182495979383829,
        "recall": 0.6103515625
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.04150629542834276,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.04150629542834276,
        "precision": 0.03619067537280428,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.09984139789294341,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.09984139789294341,
        "precision": 0.08828327976277195,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.417409763088474,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.417409763088474,
        "precision": 0.3925271920890239,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.07631270286654368,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.07631270286654368,
        "precision": 0.0671796095757321,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.38671875,
        "f1": 0.3142161711985931,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3142161711985931,
        "precision": 0.28979960740214644,
        "recall": 0.38671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002213604660538623,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002213604660538623,
        "precision": 0.002097178537608225,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.4150390625,
        "f1": 0.34387944860091596,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.34387944860091596,
        "precision": 0.3194756334160631,
        "recall": 0.4150390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022056269555797023,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.022056269555797023,
        "precision": 0.019087509712509713,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.1874671308509199,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1874671308509199,
        "precision": 0.1729879820700133,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.298828125,
        "f1": 0.22946721003074402,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.22946721003074402,
        "precision": 0.2088676867459986,
        "recall": 0.298828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00048426974613717695,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00048426974613717695,
        "precision": 0.00026391759840971817,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.05416567653152768,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.05416567653152768,
        "precision": 0.04706669720713476,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.07539391198454484,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.07539391198454484,
        "precision": 0.06680745595238174,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.1378171162934665,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.1378171162934665,
        "precision": 0.12192597712617245,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.01715375167849126,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.01715375167849126,
        "precision": 0.01501096695188492,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.03281849667825381,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.03281849667825381,
        "precision": 0.029056472653042897,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.032839949556338024,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.032839949556338024,
        "precision": 0.02948075642125346,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06741109041272758,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.06741109041272758,
        "precision": 0.06032747590858155,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.040549513693557096,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.040549513693557096,
        "precision": 0.036720567133103246,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05310823554025722,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.05310823554025722,
        "precision": 0.04918858060493689,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.03998258469842883,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.03998258469842883,
        "precision": 0.03646400228553413,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06806964736652237,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.06806964736652237,
        "precision": 0.06373959598195582,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.0568163056681599,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.0568163056681599,
        "precision": 0.05160533205943363,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04356786685026575,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.04356786685026575,
        "precision": 0.040220072743199164,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.02883178883413348,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.02883178883413348,
        "precision": 0.026577358776833582,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.11869850002961181,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.11869850002961181,
        "precision": 0.10844377101481043,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02778363762250481,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.02778363762250481,
        "precision": 0.024474456836061656,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017474415920777648,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0017474415920777648,
        "precision": 0.0012147474806808688,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028508623250983082,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.028508623250983082,
        "precision": 0.02482307212124398,
        "recall": 0.046875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009220377604166666,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.009220377604166666,
        "precision": 0.007553112648221344,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06869553144224197,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.06869553144224197,
        "precision": 0.062758676870005,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025409409038814466,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.025409409038814466,
        "precision": 0.022614978608630952,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004756172999723145,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.004756172999723145,
        "precision": 0.0035010391267450754,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.052972175858615585,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.052972175858615585,
        "precision": 0.0479161206089917,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.08857481519705784,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.08857481519705784,
        "precision": 0.08325602849697292,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.052083768521613186,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.052083768521613186,
        "precision": 0.04689500851738722,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.08705144852862781,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.08705144852862781,
        "precision": 0.07851484995039681,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.11649736746429284,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.11649736746429284,
        "precision": 0.10330692843177833,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.0468760333994709,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.0468760333994709,
        "precision": 0.041361873873974754,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.142578125,
        "f1": 0.11230415670845359,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.11230415670845359,
        "precision": 0.10364845657814407,
        "recall": 0.142578125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03753263047091958,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.03753263047091958,
        "precision": 0.03311112622700308,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.09967513497786935,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.09967513497786935,
        "precision": 0.092162286498224,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.291015625,
        "f1": 0.23387741992212951,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.23387741992212951,
        "precision": 0.2150740914901071,
        "recall": 0.291015625
      },
      {
        "accuracy": 0.1875,
        "f1": 0.14209444526827336,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.14209444526827336,
        "precision": 0.12848966083829366,
        "recall": 0.1875
      },
      {
        "accuracy": 0.4677734375,
        "f1": 0.39979899828789633,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.39979899828789633,
        "precision": 0.3753154804180195,
        "recall": 0.4677734375
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.05352604465081486,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.05352604465081486,
        "precision": 0.048595204979482325,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.07703334885090399,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.07703334885090399,
        "precision": 0.06882880167792277,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.328125,
        "f1": 0.2681272476438492,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.2681272476438492,
        "precision": 0.24796907369718718,
        "recall": 0.328125
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.08084760462947141,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.08084760462947141,
        "precision": 0.07339171245421246,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0029143688725490197,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0029143688725490197,
        "precision": 0.0026109483506944445,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07779931828040382,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.07779931828040382,
        "precision": 0.06895242116253629,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.04810887896825397,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.04810887896825397,
        "precision": 0.04154972535889356,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.203125,
        "f1": 0.1626708984375,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.1626708984375,
        "precision": 0.14981212093028498,
        "recall": 0.203125
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.09507768963720856,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.09507768963720856,
        "precision": 0.08540386865279836,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003747040719696969,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.003747040719696969,
        "precision": 0.002964018385701275,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.09225059785097148,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.09225059785097148,
        "precision": 0.08390153683122434,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.11966838500041624,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.11966838500041624,
        "precision": 0.10765785321449384,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.05274297100468975,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.05274297100468975,
        "precision": 0.04828830295138889,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.035456155306073066,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.035456155306073066,
        "precision": 0.030030032824257345,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.09118431929445855,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.09118431929445855,
        "precision": 0.08042920706623422,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.055812242661852036,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.055812242661852036,
        "precision": 0.04781380125975121,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.2333984375,
        "f1": 0.17979200273953777,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.17979200273953777,
        "precision": 0.16361449693969224,
        "recall": 0.2333984375
      },
      {
        "accuracy": 0.4169921875,
        "f1": 0.35986733656439907,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.35986733656439907,
        "precision": 0.3421201589366294,
        "recall": 0.4169921875
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.10733820738098868,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.10733820738098868,
        "precision": 0.09444535363724815,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.04044018192164298,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.04044018192164298,
        "precision": 0.0353612415508318,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.3818359375,
        "f1": 0.31406968682359304,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.31406968682359304,
        "precision": 0.29019104268127704,
        "recall": 0.3818359375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01626447904883107,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.01626447904883107,
        "precision": 0.014108253199943925,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.767578125,
        "f1": 0.7103050595238095,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.7103050595238095,
        "precision": 0.6848415798611112,
        "recall": 0.767578125
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.13281690369092713,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.13281690369092713,
        "precision": 0.11589391782262876,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06507996515089443,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.06507996515089443,
        "precision": 0.057397031137265506,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.142578125,
        "f1": 0.0939650075731937,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0939650075731937,
        "precision": 0.0792991467465847,
        "recall": 0.142578125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001643344092521979,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.001643344092521979,
        "precision": 0.001170850735274241,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.154296875,
        "f1": 0.11156786952197109,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.11156786952197109,
        "precision": 0.09944384229052197,
        "recall": 0.154296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007856290302579364,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.007856290302579364,
        "precision": 0.0064588162488553105,
        "recall": 0.015625
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.09326644493834714,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.09326644493834714,
        "precision": 0.08384552865754039,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.07136317467140862,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.07136317467140862,
        "precision": 0.06143567068162492,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003557670359136896,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0003557670359136896,
        "precision": 0.00020188195129959,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.1442694655987395,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.1442694655987395,
        "precision": 0.12895249959458943,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.0509547765602453,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.0509547765602453,
        "precision": 0.042226287709686144,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.04331432804324815,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.04331432804324815,
        "precision": 0.036525914406773774,
        "recall": 0.0712890625
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}