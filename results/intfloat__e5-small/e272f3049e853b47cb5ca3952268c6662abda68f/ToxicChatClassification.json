{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.728007,
        "f1": 0.614658,
        "f1_weighted": 0.767097,
        "ap": 0.244802,
        "ap_weighted": 0.244802,
        "scores_per_experiment": [
          {
            "accuracy": 0.475945,
            "f1": 0.4331,
            "f1_weighted": 0.549853,
            "ap": 0.159241,
            "ap_weighted": 0.159241
          },
          {
            "accuracy": 0.820447,
            "f1": 0.683922,
            "f1_weighted": 0.839542,
            "ap": 0.288143,
            "ap_weighted": 0.288143
          },
          {
            "accuracy": 0.769759,
            "f1": 0.663548,
            "f1_weighted": 0.805163,
            "ap": 0.296974,
            "ap_weighted": 0.296974
          },
          {
            "accuracy": 0.785223,
            "f1": 0.661344,
            "f1_weighted": 0.814785,
            "ap": 0.275713,
            "ap_weighted": 0.275713
          },
          {
            "accuracy": 0.714777,
            "f1": 0.584372,
            "f1_weighted": 0.758778,
            "ap": 0.199693,
            "ap_weighted": 0.199693
          },
          {
            "accuracy": 0.768041,
            "f1": 0.646786,
            "f1_weighted": 0.801822,
            "ap": 0.263409,
            "ap_weighted": 0.263409
          },
          {
            "accuracy": 0.802405,
            "f1": 0.652853,
            "f1_weighted": 0.823546,
            "ap": 0.247233,
            "ap_weighted": 0.247233
          },
          {
            "accuracy": 0.628866,
            "f1": 0.547334,
            "f1_weighted": 0.691252,
            "ap": 0.208297,
            "ap_weighted": 0.208297
          },
          {
            "accuracy": 0.781787,
            "f1": 0.647765,
            "f1_weighted": 0.810533,
            "ap": 0.253366,
            "ap_weighted": 0.253366
          },
          {
            "accuracy": 0.732818,
            "f1": 0.625552,
            "f1_weighted": 0.77569,
            "ap": 0.255954,
            "ap_weighted": 0.255954
          }
        ],
        "main_score": 0.728007,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.428498983383179,
  "kg_co2_emissions": 0.00022985179576505928
}