{
  "dataset_revision": "1f7e6a9d6fa6e64c53d146e428565640410c0df1",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.729614,
            "f1": 0.583515,
            "f1_weighted": 0.781489,
            "precision": 0.589372,
            "precision_weighted": 0.884037,
            "recall": 0.714493,
            "recall_weighted": 0.729614,
            "ap": 0.184632,
            "ap_weighted": 0.184632
          },
          {
            "accuracy": 0.783262,
            "f1": 0.624514,
            "f1_weighted": 0.82046,
            "precision": 0.610989,
            "precision_weighted": 0.888705,
            "recall": 0.734576,
            "recall_weighted": 0.783262,
            "ap": 0.210747,
            "ap_weighted": 0.210747
          },
          {
            "accuracy": 0.682403,
            "f1": 0.551142,
            "f1_weighted": 0.745951,
            "precision": 0.576402,
            "precision_weighted": 0.88136,
            "recall": 0.697981,
            "recall_weighted": 0.682403,
            "ap": 0.168813,
            "ap_weighted": 0.168813
          },
          {
            "accuracy": 0.759657,
            "f1": 0.600734,
            "f1_weighted": 0.802901,
            "precision": 0.595518,
            "precision_weighted": 0.882377,
            "recall": 0.711801,
            "recall_weighted": 0.759657,
            "ap": 0.189614,
            "ap_weighted": 0.189614
          },
          {
            "accuracy": 0.701717,
            "f1": 0.568389,
            "f1_weighted": 0.760916,
            "precision": 0.585918,
            "precision_weighted": 0.886673,
            "recall": 0.718375,
            "recall_weighted": 0.701717,
            "ap": 0.181841,
            "ap_weighted": 0.181841
          },
          {
            "accuracy": 0.753219,
            "f1": 0.615332,
            "f1_weighted": 0.80017,
            "precision": 0.612275,
            "precision_weighted": 0.898759,
            "recall": 0.766304,
            "recall_weighted": 0.753219,
            "ap": 0.221274,
            "ap_weighted": 0.221274
          },
          {
            "accuracy": 0.725322,
            "f1": 0.555569,
            "f1_weighted": 0.776012,
            "precision": 0.56326,
            "precision_weighted": 0.863315,
            "recall": 0.644358,
            "recall_weighted": 0.725322,
            "ap": 0.147996,
            "ap_weighted": 0.147996
          },
          {
            "accuracy": 0.776824,
            "f1": 0.5955,
            "f1_weighted": 0.812856,
            "precision": 0.586411,
            "precision_weighted": 0.871269,
            "recall": 0.67293,
            "recall_weighted": 0.776824,
            "ap": 0.17087,
            "ap_weighted": 0.17087
          },
          {
            "accuracy": 0.695279,
            "f1": 0.560588,
            "f1_weighted": 0.755838,
            "precision": 0.58047,
            "precision_weighted": 0.882854,
            "recall": 0.705124,
            "recall_weighted": 0.695279,
            "ap": 0.174032,
            "ap_weighted": 0.174032
          },
          {
            "accuracy": 0.740343,
            "f1": 0.581666,
            "f1_weighted": 0.788444,
            "precision": 0.583497,
            "precision_weighted": 0.8768,
            "recall": 0.691408,
            "recall_weighted": 0.740343,
            "ap": 0.173944,
            "ap_weighted": 0.173944
          }
        ],
        "accuracy": 0.734764,
        "f1": 0.583695,
        "f1_weighted": 0.784504,
        "precision": 0.588411,
        "precision_weighted": 0.881615,
        "recall": 0.705735,
        "recall_weighted": 0.734764,
        "ap": 0.182376,
        "ap_weighted": 0.182376,
        "main_score": 0.734764,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.737687,
            "f1": 0.61101,
            "f1_weighted": 0.78736,
            "precision": 0.61356,
            "precision_weighted": 0.897826,
            "recall": 0.770808,
            "recall_weighted": 0.737687,
            "ap": 0.227059,
            "ap_weighted": 0.227059
          },
          {
            "accuracy": 0.747323,
            "f1": 0.611692,
            "f1_weighted": 0.794008,
            "precision": 0.609875,
            "precision_weighted": 0.891606,
            "recall": 0.75312,
            "recall_weighted": 0.747323,
            "ap": 0.218718,
            "ap_weighted": 0.218718
          },
          {
            "accuracy": 0.667024,
            "f1": 0.553471,
            "f1_weighted": 0.732359,
            "precision": 0.585906,
            "precision_weighted": 0.886853,
            "recall": 0.722206,
            "recall_weighted": 0.667024,
            "ap": 0.185355,
            "ap_weighted": 0.185355
          },
          {
            "accuracy": 0.769807,
            "f1": 0.630882,
            "f1_weighted": 0.810782,
            "precision": 0.620546,
            "precision_weighted": 0.894684,
            "recall": 0.76565,
            "recall_weighted": 0.769807,
            "ap": 0.234099,
            "ap_weighted": 0.234099
          },
          {
            "accuracy": 0.705567,
            "f1": 0.589268,
            "f1_weighted": 0.762898,
            "precision": 0.606121,
            "precision_weighted": 0.898936,
            "recall": 0.766744,
            "recall_weighted": 0.705567,
            "ap": 0.216482,
            "ap_weighted": 0.216482
          },
          {
            "accuracy": 0.722698,
            "f1": 0.59173,
            "f1_weighted": 0.775432,
            "precision": 0.599723,
            "precision_weighted": 0.888481,
            "recall": 0.739397,
            "recall_weighted": 0.722698,
            "ap": 0.204271,
            "ap_weighted": 0.204271
          },
          {
            "accuracy": 0.761242,
            "f1": 0.62649,
            "f1_weighted": 0.804718,
            "precision": 0.619397,
            "precision_weighted": 0.896368,
            "recall": 0.7701,
            "recall_weighted": 0.761242,
            "ap": 0.234014,
            "ap_weighted": 0.234014
          },
          {
            "accuracy": 0.749465,
            "f1": 0.608853,
            "f1_weighted": 0.795164,
            "precision": 0.606082,
            "precision_weighted": 0.887537,
            "recall": 0.740478,
            "recall_weighted": 0.749465,
            "ap": 0.21144,
            "ap_weighted": 0.21144
          },
          {
            "accuracy": 0.630621,
            "f1": 0.524647,
            "f1_weighted": 0.702953,
            "precision": 0.572715,
            "precision_weighted": 0.879617,
            "recall": 0.692696,
            "recall_weighted": 0.630621,
            "ap": 0.167236,
            "ap_weighted": 0.167236
          },
          {
            "accuracy": 0.726981,
            "f1": 0.579611,
            "f1_weighted": 0.777348,
            "precision": 0.585103,
            "precision_weighted": 0.874316,
            "recall": 0.695667,
            "recall_weighted": 0.726981,
            "ap": 0.180398,
            "ap_weighted": 0.180398
          }
        ],
        "accuracy": 0.721842,
        "f1": 0.592765,
        "f1_weighted": 0.774302,
        "precision": 0.601903,
        "precision_weighted": 0.889622,
        "recall": 0.741687,
        "recall_weighted": 0.721842,
        "ap": 0.207907,
        "ap_weighted": 0.207907,
        "main_score": 0.721842,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 4.128319978713989,
  "kg_co2_emissions": null
}