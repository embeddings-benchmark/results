{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "task_name": "MassiveIntentClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.676832,
            "f1": 0.664871,
            "f1_weighted": 0.672039,
            "precision": 0.65043,
            "precision_weighted": 0.700353,
            "recall": 0.725528,
            "recall_weighted": 0.676832,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.696016,
            "f1": 0.676978,
            "f1_weighted": 0.694424,
            "precision": 0.659788,
            "precision_weighted": 0.725762,
            "recall": 0.758509,
            "recall_weighted": 0.696016,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.671913,
            "f1": 0.65339,
            "f1_weighted": 0.669692,
            "precision": 0.632015,
            "precision_weighted": 0.695409,
            "recall": 0.720897,
            "recall_weighted": 0.671913,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.67634,
            "f1": 0.645735,
            "f1_weighted": 0.674166,
            "precision": 0.630831,
            "precision_weighted": 0.70481,
            "recall": 0.715813,
            "recall_weighted": 0.67634,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.682735,
            "f1": 0.673015,
            "f1_weighted": 0.678264,
            "precision": 0.655792,
            "precision_weighted": 0.701941,
            "recall": 0.735804,
            "recall_weighted": 0.682735,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.666011,
            "f1": 0.656265,
            "f1_weighted": 0.660711,
            "precision": 0.634037,
            "precision_weighted": 0.686676,
            "recall": 0.723322,
            "recall_weighted": 0.666011,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.671422,
            "f1": 0.655411,
            "f1_weighted": 0.666359,
            "precision": 0.633599,
            "precision_weighted": 0.692041,
            "recall": 0.724326,
            "recall_weighted": 0.671422,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.658141,
            "f1": 0.658664,
            "f1_weighted": 0.651763,
            "precision": 0.636486,
            "precision_weighted": 0.675237,
            "recall": 0.722255,
            "recall_weighted": 0.658141,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.656173,
            "f1": 0.649174,
            "f1_weighted": 0.655637,
            "precision": 0.639761,
            "precision_weighted": 0.687985,
            "recall": 0.710242,
            "recall_weighted": 0.656173,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.698475,
            "f1": 0.682449,
            "f1_weighted": 0.696738,
            "precision": 0.663815,
            "precision_weighted": 0.723088,
            "recall": 0.750055,
            "recall_weighted": 0.698475,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.675406,
        "f1": 0.661595,
        "f1_weighted": 0.671979,
        "precision": 0.643655,
        "precision_weighted": 0.69933,
        "recall": 0.728675,
        "recall_weighted": 0.675406,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.675406,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.67653,
            "f1": 0.657023,
            "f1_weighted": 0.674275,
            "precision": 0.641982,
            "precision_weighted": 0.708539,
            "recall": 0.723612,
            "recall_weighted": 0.67653,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.68191,
            "f1": 0.668705,
            "f1_weighted": 0.683684,
            "precision": 0.652829,
            "precision_weighted": 0.716477,
            "recall": 0.744697,
            "recall_weighted": 0.68191,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.672831,
            "f1": 0.651157,
            "f1_weighted": 0.671526,
            "precision": 0.628159,
            "precision_weighted": 0.707889,
            "recall": 0.720111,
            "recall_weighted": 0.672831,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.673504,
            "f1": 0.652732,
            "f1_weighted": 0.675631,
            "precision": 0.639388,
            "precision_weighted": 0.710801,
            "recall": 0.722534,
            "recall_weighted": 0.673504,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.666443,
            "f1": 0.65442,
            "f1_weighted": 0.663011,
            "precision": 0.636942,
            "precision_weighted": 0.691987,
            "recall": 0.725874,
            "recall_weighted": 0.666443,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.660054,
            "f1": 0.657254,
            "f1_weighted": 0.659281,
            "precision": 0.638494,
            "precision_weighted": 0.69739,
            "recall": 0.728196,
            "recall_weighted": 0.660054,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.656019,
            "f1": 0.637038,
            "f1_weighted": 0.65714,
            "precision": 0.62624,
            "precision_weighted": 0.700529,
            "recall": 0.703902,
            "recall_weighted": 0.656019,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.647276,
            "f1": 0.639532,
            "f1_weighted": 0.647131,
            "precision": 0.626865,
            "precision_weighted": 0.685034,
            "recall": 0.704917,
            "recall_weighted": 0.647276,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.659381,
            "f1": 0.648951,
            "f1_weighted": 0.661001,
            "precision": 0.635541,
            "precision_weighted": 0.702144,
            "recall": 0.71197,
            "recall_weighted": 0.659381,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.69267,
            "f1": 0.679255,
            "f1_weighted": 0.695683,
            "precision": 0.664887,
            "precision_weighted": 0.723062,
            "recall": 0.734417,
            "recall_weighted": 0.69267,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.668662,
        "f1": 0.654607,
        "f1_weighted": 0.668836,
        "precision": 0.639133,
        "precision_weighted": 0.704385,
        "recall": 0.722023,
        "recall_weighted": 0.668662,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.668662,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 12.579124689102173,
  "kg_co2_emissions": null
}