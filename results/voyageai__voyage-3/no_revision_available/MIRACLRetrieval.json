{
  "dataset_revision": "main",
  "evaluation_time": 3600,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.12",
  "scores": {
    "dev": [
      {
        "hf_subset": "ru",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.68426,
        "map_at_1": 0.34295,
        "map_at_10": 0.57322,
        "map_at_100": 0.60019,
        "map_at_1000": 0.60114,
        "map_at_3": 0.4955,
        "map_at_5": 0.54518,
        "mrr_at_1": 0.6445,
        "mrr_at_10": 0.7592,
        "mrr_at_100": 0.76175,
        "mrr_at_1000": 0.76183,
        "mrr_at_3": 0.74718,
        "mrr_at_5": 0.75136,
        "ndcg_at_1": 0.6655,
        "ndcg_at_10": 0.68426,
        "ndcg_at_100": 0.74688,
        "ndcg_at_1000": 0.75717,
        "ndcg_at_3": 0.64003,
        "ndcg_at_5": 0.66579,
        "precision_at_1": 0.6655,
        "precision_at_10": 0.20387,
        "precision_at_100": 0.02732,
        "precision_at_1000": 0.00282,
        "precision_at_3": 0.46913,
        "precision_at_5": 0.34371,
        "recall_at_1": 0.34295,
        "recall_at_10": 0.76233,
        "recall_at_100": 0.95458,
        "recall_at_1000": 0.9926,
        "recall_at_3": 0.56624,
        "recall_at_5": 0.6714
      }
    ]
  },
  "task_name": "MIRACLRetrieval"
}