{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.867833,
        "mrr": 0.867833,
        "nAUC_map_max": 0.565905,
        "nAUC_map_std": 0.227772,
        "nAUC_map_diff1": 0.800948,
        "nAUC_mrr_max": 0.565905,
        "nAUC_mrr_std": 0.227772,
        "nAUC_mrr_diff1": 0.800948,
        "main_score": 0.867833,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.870183,
        "mrr": 0.870183,
        "nAUC_map_max": 0.446587,
        "nAUC_map_std": 0.25038,
        "nAUC_map_diff1": 0.739936,
        "nAUC_mrr_max": 0.446587,
        "nAUC_mrr_std": 0.25038,
        "nAUC_mrr_diff1": 0.739936,
        "main_score": 0.870183,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.870179,
        "mrr": 0.870179,
        "nAUC_map_max": 0.504443,
        "nAUC_map_std": 0.241952,
        "nAUC_map_diff1": 0.796806,
        "nAUC_mrr_max": 0.504443,
        "nAUC_mrr_std": 0.241952,
        "nAUC_mrr_diff1": 0.796806,
        "main_score": 0.870179,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.882362,
        "mrr": 0.882806,
        "nAUC_map_max": 0.506968,
        "nAUC_map_std": 0.237283,
        "nAUC_map_diff1": 0.808653,
        "nAUC_mrr_max": 0.508299,
        "nAUC_mrr_std": 0.234157,
        "nAUC_mrr_diff1": 0.807577,
        "main_score": 0.882362,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.869202,
        "mrr": 0.869202,
        "nAUC_map_max": 0.545548,
        "nAUC_map_std": 0.263525,
        "nAUC_map_diff1": 0.80292,
        "nAUC_mrr_max": 0.545548,
        "nAUC_mrr_std": 0.263525,
        "nAUC_mrr_diff1": 0.80292,
        "main_score": 0.869202,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.921642,
        "mrr": 0.921642,
        "nAUC_map_max": 0.583424,
        "nAUC_map_std": 0.452758,
        "nAUC_map_diff1": 0.869135,
        "nAUC_mrr_max": 0.583424,
        "nAUC_mrr_std": 0.452758,
        "nAUC_mrr_diff1": 0.869135,
        "main_score": 0.921642,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.884743,
        "mrr": 0.884743,
        "nAUC_map_max": 0.615363,
        "nAUC_map_std": 0.336907,
        "nAUC_map_diff1": 0.826274,
        "nAUC_mrr_max": 0.615363,
        "nAUC_mrr_std": 0.336907,
        "nAUC_mrr_diff1": 0.826274,
        "main_score": 0.884743,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.913197,
        "mrr": 0.913197,
        "nAUC_map_max": 0.457908,
        "nAUC_map_std": 0.239028,
        "nAUC_map_diff1": 0.794694,
        "nAUC_mrr_max": 0.457908,
        "nAUC_mrr_std": 0.239028,
        "nAUC_mrr_diff1": 0.794694,
        "main_score": 0.913197,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.873271,
        "mrr": 0.874281,
        "nAUC_map_max": 0.428786,
        "nAUC_map_std": 0.268274,
        "nAUC_map_diff1": 0.819515,
        "nAUC_mrr_max": 0.429593,
        "nAUC_mrr_std": 0.270958,
        "nAUC_mrr_diff1": 0.817114,
        "main_score": 0.873271,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.873265,
        "mrr": 0.873265,
        "nAUC_map_max": 0.512843,
        "nAUC_map_std": 0.275535,
        "nAUC_map_diff1": 0.772175,
        "nAUC_mrr_max": 0.512843,
        "nAUC_mrr_std": 0.275535,
        "nAUC_mrr_diff1": 0.772175,
        "main_score": 0.873265,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.883749,
        "mrr": 0.884083,
        "nAUC_map_max": 0.418805,
        "nAUC_map_std": 0.195855,
        "nAUC_map_diff1": 0.779542,
        "nAUC_mrr_max": 0.418233,
        "nAUC_mrr_std": 0.2016,
        "nAUC_mrr_diff1": 0.778572,
        "main_score": 0.883749,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.872109,
        "mrr": 0.872109,
        "nAUC_map_max": 0.51636,
        "nAUC_map_std": 0.201073,
        "nAUC_map_diff1": 0.807335,
        "nAUC_mrr_max": 0.51636,
        "nAUC_mrr_std": 0.201073,
        "nAUC_mrr_diff1": 0.807335,
        "main_score": 0.872109,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.881492,
        "mrr": 0.881825,
        "nAUC_map_max": 0.516286,
        "nAUC_map_std": 0.294141,
        "nAUC_map_diff1": 0.809229,
        "nAUC_mrr_max": 0.514657,
        "nAUC_mrr_std": 0.29194,
        "nAUC_mrr_diff1": 0.808353,
        "main_score": 0.881492,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.887834,
        "mrr": 0.888167,
        "nAUC_map_max": 0.521068,
        "nAUC_map_std": 0.206301,
        "nAUC_map_diff1": 0.812381,
        "nAUC_mrr_max": 0.523008,
        "nAUC_mrr_std": 0.212265,
        "nAUC_mrr_diff1": 0.811468,
        "main_score": 0.887834,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.864048,
        "mrr": 0.864048,
        "nAUC_map_max": 0.422005,
        "nAUC_map_std": 0.211095,
        "nAUC_map_diff1": 0.773561,
        "nAUC_mrr_max": 0.422005,
        "nAUC_mrr_std": 0.211095,
        "nAUC_mrr_diff1": 0.773561,
        "main_score": 0.864048,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.89202,
        "mrr": 0.89202,
        "nAUC_map_max": 0.455424,
        "nAUC_map_std": 0.230321,
        "nAUC_map_diff1": 0.834729,
        "nAUC_mrr_max": 0.455424,
        "nAUC_mrr_std": 0.230321,
        "nAUC_mrr_diff1": 0.834729,
        "main_score": 0.89202,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5353.586947441101,
  "kg_co2_emissions": null
}