{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.1.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.635258,
            "f1": 0.556005,
            "f1_weighted": 0.696836,
            "precision": 0.600783,
            "precision_weighted": 0.875474,
            "recall": 0.728913,
            "recall_weighted": 0.635258,
            "ap": 0.930532,
            "ap_weighted": 0.930532
          },
          {
            "accuracy": 0.653495,
            "f1": 0.561025,
            "f1_weighted": 0.712284,
            "precision": 0.593351,
            "precision_weighted": 0.863455,
            "recall": 0.707952,
            "recall_weighted": 0.653495,
            "ap": 0.92478,
            "ap_weighted": 0.92478
          },
          {
            "accuracy": 0.738602,
            "f1": 0.58293,
            "f1_weighted": 0.774228,
            "precision": 0.579367,
            "precision_weighted": 0.833115,
            "recall": 0.641514,
            "recall_weighted": 0.738602,
            "ap": 0.907736,
            "ap_weighted": 0.907736
          },
          {
            "accuracy": 0.665653,
            "f1": 0.53373,
            "f1_weighted": 0.719931,
            "precision": 0.553364,
            "precision_weighted": 0.822641,
            "recall": 0.610307,
            "recall_weighted": 0.665653,
            "ap": 0.900454,
            "ap_weighted": 0.900454
          },
          {
            "accuracy": 0.674772,
            "f1": 0.544386,
            "f1_weighted": 0.727371,
            "precision": 0.561204,
            "precision_weighted": 0.828359,
            "recall": 0.625974,
            "recall_weighted": 0.674772,
            "ap": 0.904173,
            "ap_weighted": 0.904173
          },
          {
            "accuracy": 0.674772,
            "f1": 0.526746,
            "f1_weighted": 0.725455,
            "precision": 0.542457,
            "precision_weighted": 0.812554,
            "recall": 0.584138,
            "recall_weighted": 0.674772,
            "ap": 0.8943,
            "ap_weighted": 0.8943
          },
          {
            "accuracy": 0.449848,
            "f1": 0.422174,
            "f1_weighted": 0.517111,
            "precision": 0.574689,
            "precision_weighted": 0.874064,
            "recall": 0.654387,
            "recall_weighted": 0.449848,
            "ap": 0.912838,
            "ap_weighted": 0.912838
          },
          {
            "accuracy": 0.620061,
            "f1": 0.513458,
            "f1_weighted": 0.684438,
            "precision": 0.552258,
            "precision_weighted": 0.826804,
            "recall": 0.615642,
            "recall_weighted": 0.620061,
            "ap": 0.901838,
            "ap_weighted": 0.901838
          },
          {
            "accuracy": 0.617021,
            "f1": 0.518201,
            "f1_weighted": 0.682017,
            "precision": 0.56028,
            "precision_weighted": 0.835085,
            "recall": 0.634824,
            "recall_weighted": 0.617021,
            "ap": 0.906507,
            "ap_weighted": 0.906507
          },
          {
            "accuracy": 0.604863,
            "f1": 0.502906,
            "f1_weighted": 0.671923,
            "precision": 0.547823,
            "precision_weighted": 0.824077,
            "recall": 0.606961,
            "recall_weighted": 0.604863,
            "ap": 0.899794,
            "ap_weighted": 0.899794
          }
        ],
        "accuracy": 0.633435,
        "f1": 0.526156,
        "f1_weighted": 0.691159,
        "precision": 0.566558,
        "precision_weighted": 0.839563,
        "recall": 0.641061,
        "recall_weighted": 0.633435,
        "ap": 0.908295,
        "ap_weighted": 0.908295,
        "main_score": 0.633435,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 21.417738914489746,
  "kg_co2_emissions": null
}