{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.957539,
        "recall": 0.970913,
        "f1": 0.961886,
        "accuracy": 0.970913,
        "main_score": 0.961886,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.904045,
        "recall": 0.934804,
        "f1": 0.914076,
        "accuracy": 0.934804,
        "main_score": 0.914076,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.954697,
        "recall": 0.967904,
        "f1": 0.958877,
        "accuracy": 0.967904,
        "main_score": 0.958877,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.88992,
        "recall": 0.924774,
        "f1": 0.901103,
        "accuracy": 0.924774,
        "main_score": 0.901103,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.984119,
        "recall": 0.988967,
        "f1": 0.985624,
        "accuracy": 0.988967,
        "main_score": 0.985624,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.931712,
        "recall": 0.952859,
        "f1": 0.938382,
        "accuracy": 0.952859,
        "main_score": 0.938382,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.936593,
        "recall": 0.954865,
        "f1": 0.942227,
        "accuracy": 0.954865,
        "main_score": 0.942227,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.868639,
        "recall": 0.907723,
        "f1": 0.880895,
        "accuracy": 0.907723,
        "main_score": 0.880895,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.928452,
        "recall": 0.948847,
        "f1": 0.934771,
        "accuracy": 0.948847,
        "main_score": 0.934771,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.874992,
        "recall": 0.913741,
        "f1": 0.887329,
        "accuracy": 0.913741,
        "main_score": 0.887329,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.96339,
        "recall": 0.974925,
        "f1": 0.967068,
        "accuracy": 0.974925,
        "main_score": 0.967068,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.911401,
        "recall": 0.939819,
        "f1": 0.920595,
        "accuracy": 0.939819,
        "main_score": 0.920595,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.90835,
        "recall": 0.933801,
        "f1": 0.916056,
        "accuracy": 0.933801,
        "main_score": 0.916056,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.858024,
        "recall": 0.900702,
        "f1": 0.871314,
        "accuracy": 0.900702,
        "main_score": 0.871314,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.952441,
        "recall": 0.966901,
        "f1": 0.956937,
        "accuracy": 0.966901,
        "main_score": 0.956937,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.870562,
        "recall": 0.909729,
        "f1": 0.882882,
        "accuracy": 0.909729,
        "main_score": 0.882882,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.971414,
        "recall": 0.980943,
        "f1": 0.97459,
        "accuracy": 0.980943,
        "main_score": 0.97459,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.915079,
        "recall": 0.941825,
        "f1": 0.923771,
        "accuracy": 0.941825,
        "main_score": 0.923771,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.894837,
        "recall": 0.922768,
        "f1": 0.903176,
        "accuracy": 0.922768,
        "main_score": 0.903176,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.826229,
        "recall": 0.878636,
        "f1": 0.842762,
        "accuracy": 0.878636,
        "main_score": 0.842762,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.925067,
        "recall": 0.945838,
        "f1": 0.931316,
        "accuracy": 0.945838,
        "main_score": 0.931316,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.844784,
        "recall": 0.892678,
        "f1": 0.85998,
        "accuracy": 0.892678,
        "main_score": 0.85998,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.960214,
        "recall": 0.972919,
        "f1": 0.964393,
        "accuracy": 0.972919,
        "main_score": 0.964393,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.901705,
        "recall": 0.932798,
        "f1": 0.911735,
        "accuracy": 0.932798,
        "main_score": 0.911735,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.947844,
        "recall": 0.963892,
        "f1": 0.952992,
        "accuracy": 0.963892,
        "main_score": 0.952992,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881428,
        "recall": 0.918756,
        "f1": 0.893414,
        "accuracy": 0.918756,
        "main_score": 0.893414,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.963256,
        "recall": 0.973922,
        "f1": 0.966566,
        "accuracy": 0.973922,
        "main_score": 0.966566,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.865513,
        "recall": 0.907723,
        "f1": 0.879037,
        "accuracy": 0.907723,
        "main_score": 0.879037,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.903293,
        "recall": 0.932798,
        "f1": 0.912638,
        "accuracy": 0.932798,
        "main_score": 0.912638,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.799833,
        "recall": 0.85657,
        "f1": 0.81675,
        "accuracy": 0.85657,
        "main_score": 0.81675,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.80506,
        "recall": 0.853561,
        "f1": 0.818876,
        "accuracy": 0.853561,
        "main_score": 0.818876,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.675176,
        "recall": 0.76329,
        "f1": 0.700955,
        "accuracy": 0.76329,
        "main_score": 0.700955,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.953394,
        "recall": 0.965898,
        "f1": 0.957172,
        "accuracy": 0.965898,
        "main_score": 0.957172,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.903878,
        "recall": 0.933801,
        "f1": 0.913574,
        "accuracy": 0.933801,
        "main_score": 0.913574,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.953169,
        "recall": 0.965898,
        "f1": 0.956921,
        "accuracy": 0.965898,
        "main_score": 0.956921,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.869692,
        "recall": 0.909729,
        "f1": 0.882347,
        "accuracy": 0.909729,
        "main_score": 0.882347,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.025115,
        "recall": 0.032096,
        "f1": 0.026712,
        "accuracy": 0.032096,
        "main_score": 0.026712,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015314,
        "recall": 0.035105,
        "f1": 0.018361,
        "accuracy": 0.035105,
        "main_score": 0.018361,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.305457,
        "recall": 0.351053,
        "f1": 0.317212,
        "accuracy": 0.351053,
        "main_score": 0.317212,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.211642,
        "recall": 0.325978,
        "f1": 0.238656,
        "accuracy": 0.325978,
        "main_score": 0.238656,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.924134,
        "recall": 0.944835,
        "f1": 0.930358,
        "accuracy": 0.944835,
        "main_score": 0.930358,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.830408,
        "recall": 0.880642,
        "f1": 0.846024,
        "accuracy": 0.880642,
        "main_score": 0.846024,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.783306,
        "recall": 0.824473,
        "f1": 0.794147,
        "accuracy": 0.824473,
        "main_score": 0.794147,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.674551,
        "recall": 0.759278,
        "f1": 0.699202,
        "accuracy": 0.759278,
        "main_score": 0.699202,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.912474,
        "recall": 0.934804,
        "f1": 0.918946,
        "accuracy": 0.934804,
        "main_score": 0.918946,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.804697,
        "recall": 0.862588,
        "f1": 0.822635,
        "accuracy": 0.862588,
        "main_score": 0.822635,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.926758,
        "recall": 0.945838,
        "f1": 0.932297,
        "accuracy": 0.945838,
        "main_score": 0.932297,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.800869,
        "recall": 0.858576,
        "f1": 0.818575,
        "accuracy": 0.858576,
        "main_score": 0.818575,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.944918,
        "recall": 0.961886,
        "f1": 0.950251,
        "accuracy": 0.961886,
        "main_score": 0.950251,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.898445,
        "recall": 0.930792,
        "f1": 0.908927,
        "accuracy": 0.930792,
        "main_score": 0.908927,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.325066,
        "recall": 0.368104,
        "f1": 0.336111,
        "accuracy": 0.368104,
        "main_score": 0.336111,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.223777,
        "recall": 0.347041,
        "f1": 0.252678,
        "accuracy": 0.347041,
        "main_score": 0.252678,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.91558,
        "recall": 0.939819,
        "f1": 0.923021,
        "accuracy": 0.939819,
        "main_score": 0.923021,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.821698,
        "recall": 0.873621,
        "f1": 0.837732,
        "accuracy": 0.873621,
        "main_score": 0.837732,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.942979,
        "recall": 0.958877,
        "f1": 0.947743,
        "accuracy": 0.958877,
        "main_score": 0.947743,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.851304,
        "recall": 0.897693,
        "f1": 0.865998,
        "accuracy": 0.897693,
        "main_score": 0.865998,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.009638,
        "recall": 0.013039,
        "f1": 0.010314,
        "accuracy": 0.013039,
        "main_score": 0.010314,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003969,
        "recall": 0.01003,
        "f1": 0.004905,
        "accuracy": 0.01003,
        "main_score": 0.004905,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.977767,
        "recall": 0.985178,
        "f1": 0.980237,
        "accuracy": 0.985178,
        "main_score": 0.980237,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.920866,
        "recall": 0.945652,
        "f1": 0.928755,
        "accuracy": 0.945652,
        "main_score": 0.928755,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.972167,
        "recall": 0.981225,
        "f1": 0.975132,
        "accuracy": 0.981225,
        "main_score": 0.975132,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.89496,
        "recall": 0.927866,
        "f1": 0.905468,
        "accuracy": 0.927866,
        "main_score": 0.905468,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.988142,
        "recall": 0.992095,
        "f1": 0.98946,
        "accuracy": 0.992095,
        "main_score": 0.98946,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.935606,
        "recall": 0.955534,
        "f1": 0.941864,
        "accuracy": 0.955534,
        "main_score": 0.941864,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.949193,
        "recall": 0.964427,
        "f1": 0.953953,
        "accuracy": 0.964427,
        "main_score": 0.953953,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.853426,
        "recall": 0.896245,
        "f1": 0.866685,
        "accuracy": 0.896245,
        "main_score": 0.866685,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.960145,
        "recall": 0.972332,
        "f1": 0.96405,
        "accuracy": 0.972332,
        "main_score": 0.96405,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881374,
        "recall": 0.917984,
        "f1": 0.893017,
        "accuracy": 0.917984,
        "main_score": 0.893017,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.957345,
        "recall": 0.971344,
        "f1": 0.961957,
        "accuracy": 0.971344,
        "main_score": 0.961957,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.90415,
        "recall": 0.933794,
        "f1": 0.913505,
        "accuracy": 0.933794,
        "main_score": 0.913505,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.930418,
        "recall": 0.951581,
        "f1": 0.937154,
        "accuracy": 0.951581,
        "main_score": 0.937154,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.852849,
        "recall": 0.896245,
        "f1": 0.866436,
        "accuracy": 0.896245,
        "main_score": 0.866436,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.961133,
        "recall": 0.97332,
        "f1": 0.965086,
        "accuracy": 0.97332,
        "main_score": 0.965086,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.863472,
        "recall": 0.906126,
        "f1": 0.877108,
        "accuracy": 0.906126,
        "main_score": 0.877108,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.979578,
        "recall": 0.986166,
        "f1": 0.981719,
        "accuracy": 0.986166,
        "main_score": 0.981719,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.923666,
        "recall": 0.947628,
        "f1": 0.93139,
        "accuracy": 0.947628,
        "main_score": 0.93139,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.900272,
        "recall": 0.928854,
        "f1": 0.909047,
        "accuracy": 0.928854,
        "main_score": 0.909047,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.810886,
        "recall": 0.867589,
        "f1": 0.828557,
        "accuracy": 0.867589,
        "main_score": 0.828557,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.940794,
        "recall": 0.958498,
        "f1": 0.94633,
        "accuracy": 0.958498,
        "main_score": 0.94633,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.888011,
        "recall": 0.923913,
        "f1": 0.899704,
        "accuracy": 0.923913,
        "main_score": 0.899704,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.959321,
        "recall": 0.972332,
        "f1": 0.963603,
        "accuracy": 0.972332,
        "main_score": 0.963603,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.92309,
        "recall": 0.94664,
        "f1": 0.930501,
        "accuracy": 0.94664,
        "main_score": 0.930501,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.957675,
        "recall": 0.971344,
        "f1": 0.962121,
        "accuracy": 0.971344,
        "main_score": 0.962121,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.879562,
        "recall": 0.91502,
        "f1": 0.890382,
        "accuracy": 0.91502,
        "main_score": 0.890382,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.966568,
        "recall": 0.977273,
        "f1": 0.970026,
        "accuracy": 0.977273,
        "main_score": 0.970026,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.877306,
        "recall": 0.91502,
        "f1": 0.88913,
        "accuracy": 0.91502,
        "main_score": 0.88913,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.944005,
        "recall": 0.960474,
        "f1": 0.949228,
        "accuracy": 0.960474,
        "main_score": 0.949228,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.812665,
        "recall": 0.869565,
        "f1": 0.830764,
        "accuracy": 0.869565,
        "main_score": 0.830764,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.813834,
        "recall": 0.862648,
        "f1": 0.828444,
        "accuracy": 0.862648,
        "main_score": 0.828444,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.698527,
        "recall": 0.780632,
        "f1": 0.722927,
        "accuracy": 0.780632,
        "main_score": 0.722927,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.944335,
        "recall": 0.961462,
        "f1": 0.949934,
        "accuracy": 0.961462,
        "main_score": 0.949934,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.904562,
        "recall": 0.933794,
        "f1": 0.913933,
        "accuracy": 0.933794,
        "main_score": 0.913933,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.957263,
        "recall": 0.970356,
        "f1": 0.961364,
        "accuracy": 0.970356,
        "main_score": 0.961364,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881126,
        "recall": 0.917984,
        "f1": 0.892787,
        "accuracy": 0.917984,
        "main_score": 0.892787,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.028622,
        "recall": 0.043478,
        "f1": 0.03129,
        "accuracy": 0.043478,
        "main_score": 0.03129,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019334,
        "recall": 0.034585,
        "f1": 0.022206,
        "accuracy": 0.034585,
        "main_score": 0.022206,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.264113,
        "recall": 0.322134,
        "f1": 0.277177,
        "accuracy": 0.322134,
        "main_score": 0.277177,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.211466,
        "recall": 0.318182,
        "f1": 0.236017,
        "accuracy": 0.318182,
        "main_score": 0.236017,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.942885,
        "recall": 0.960474,
        "f1": 0.948452,
        "accuracy": 0.960474,
        "main_score": 0.948452,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.867671,
        "recall": 0.908103,
        "f1": 0.880468,
        "accuracy": 0.908103,
        "main_score": 0.880468,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.808971,
        "recall": 0.853755,
        "f1": 0.822023,
        "accuracy": 0.853755,
        "main_score": 0.822023,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.693603,
        "recall": 0.781621,
        "f1": 0.720226,
        "accuracy": 0.781621,
        "main_score": 0.720226,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.920927,
        "recall": 0.942688,
        "f1": 0.927536,
        "accuracy": 0.942688,
        "main_score": 0.927536,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.812368,
        "recall": 0.867589,
        "f1": 0.829282,
        "accuracy": 0.867589,
        "main_score": 0.829282,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.93531,
        "recall": 0.953557,
        "f1": 0.941041,
        "accuracy": 0.953557,
        "main_score": 0.941041,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.85746,
        "recall": 0.902174,
        "f1": 0.871772,
        "accuracy": 0.902174,
        "main_score": 0.871772,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.957675,
        "recall": 0.971344,
        "f1": 0.962121,
        "accuracy": 0.971344,
        "main_score": 0.962121,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.889361,
        "recall": 0.923913,
        "f1": 0.900362,
        "accuracy": 0.923913,
        "main_score": 0.900362,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.336403,
        "recall": 0.391304,
        "f1": 0.349819,
        "accuracy": 0.391304,
        "main_score": 0.349819,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.255057,
        "recall": 0.362648,
        "f1": 0.279942,
        "accuracy": 0.362648,
        "main_score": 0.279942,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.942309,
        "recall": 0.959486,
        "f1": 0.947694,
        "accuracy": 0.959486,
        "main_score": 0.947694,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.830237,
        "recall": 0.879447,
        "f1": 0.845473,
        "accuracy": 0.879447,
        "main_score": 0.845473,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.944252,
        "recall": 0.961462,
        "f1": 0.949835,
        "accuracy": 0.961462,
        "main_score": 0.949835,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.873847,
        "recall": 0.912055,
        "f1": 0.885837,
        "accuracy": 0.912055,
        "main_score": 0.885837,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.009165,
        "recall": 0.01581,
        "f1": 0.010201,
        "accuracy": 0.01581,
        "main_score": 0.010201,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006442,
        "recall": 0.013834,
        "f1": 0.007427,
        "accuracy": 0.013834,
        "main_score": 0.007427,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 3601.0482244491577,
  "kg_co2_emissions": null
}