{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.726893,
        "f1": 0.721133,
        "f1_weighted": 0.721789,
        "scores_per_experiment": [
          {
            "accuracy": 0.751958,
            "f1": 0.743858,
            "f1_weighted": 0.746277
          },
          {
            "accuracy": 0.72846,
            "f1": 0.719397,
            "f1_weighted": 0.720102
          },
          {
            "accuracy": 0.697128,
            "f1": 0.696185,
            "f1_weighted": 0.695812
          },
          {
            "accuracy": 0.67624,
            "f1": 0.66085,
            "f1_weighted": 0.660902
          },
          {
            "accuracy": 0.775457,
            "f1": 0.775214,
            "f1_weighted": 0.775581
          },
          {
            "accuracy": 0.733681,
            "f1": 0.735005,
            "f1_weighted": 0.735072
          },
          {
            "accuracy": 0.75718,
            "f1": 0.75291,
            "f1_weighted": 0.753759
          },
          {
            "accuracy": 0.70235,
            "f1": 0.692488,
            "f1_weighted": 0.692771
          },
          {
            "accuracy": 0.707572,
            "f1": 0.700684,
            "f1_weighted": 0.703156
          },
          {
            "accuracy": 0.738903,
            "f1": 0.734742,
            "f1_weighted": 0.734454
          }
        ],
        "main_score": 0.726893,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.691667,
        "f1": 0.684443,
        "f1_weighted": 0.681108,
        "scores_per_experiment": [
          {
            "accuracy": 0.6875,
            "f1": 0.686021,
            "f1_weighted": 0.679881
          },
          {
            "accuracy": 0.729167,
            "f1": 0.713435,
            "f1_weighted": 0.717772
          },
          {
            "accuracy": 0.666667,
            "f1": 0.663003,
            "f1_weighted": 0.658318
          },
          {
            "accuracy": 0.583333,
            "f1": 0.566407,
            "f1_weighted": 0.557919
          },
          {
            "accuracy": 0.75,
            "f1": 0.748443,
            "f1_weighted": 0.74515
          },
          {
            "accuracy": 0.729167,
            "f1": 0.728864,
            "f1_weighted": 0.726224
          },
          {
            "accuracy": 0.760417,
            "f1": 0.759925,
            "f1_weighted": 0.752801
          },
          {
            "accuracy": 0.6875,
            "f1": 0.671528,
            "f1_weighted": 0.671506
          },
          {
            "accuracy": 0.71875,
            "f1": 0.712985,
            "f1_weighted": 0.709691
          },
          {
            "accuracy": 0.604167,
            "f1": 0.593823,
            "f1_weighted": 0.59182
          }
        ],
        "main_score": 0.691667,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 56.688554525375366,
  "kg_co2_emissions": null
}