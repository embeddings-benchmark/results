{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.416474,
        "recall": 0.504883,
        "f1": 0.438203,
        "accuracy": 0.504883,
        "main_score": 0.438203,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.945394,
        "recall": 0.960938,
        "f1": 0.950098,
        "accuracy": 0.960938,
        "main_score": 0.950098,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.978027,
        "recall": 0.985352,
        "f1": 0.980469,
        "accuracy": 0.985352,
        "main_score": 0.980469,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.8955,
        "recall": 0.923828,
        "f1": 0.904188,
        "accuracy": 0.923828,
        "main_score": 0.904188,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.766418,
        "recall": 0.821289,
        "f1": 0.781857,
        "accuracy": 0.821289,
        "main_score": 0.781857,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.98584,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000327,
        "recall": 0.004883,
        "f1": 0.000598,
        "accuracy": 0.004883,
        "main_score": 0.000598,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.972168,
        "recall": 0.981445,
        "f1": 0.97526,
        "accuracy": 0.981445,
        "main_score": 0.97526,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.956543,
        "recall": 0.969727,
        "f1": 0.960775,
        "accuracy": 0.969727,
        "main_score": 0.960775,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000695,
        "recall": 0.007812,
        "f1": 0.001043,
        "accuracy": 0.007812,
        "main_score": 0.001043,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.837239,
        "recall": 0.878906,
        "f1": 0.849566,
        "accuracy": 0.878906,
        "main_score": 0.849566,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.972982,
        "recall": 0.981445,
        "f1": 0.975749,
        "accuracy": 0.981445,
        "main_score": 0.975749,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.98291,
        "recall": 0.988281,
        "f1": 0.984701,
        "accuracy": 0.988281,
        "main_score": 0.984701,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.424701,
        "recall": 0.512695,
        "f1": 0.446086,
        "accuracy": 0.512695,
        "main_score": 0.446086,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.932568,
        "recall": 0.953125,
        "f1": 0.939193,
        "accuracy": 0.953125,
        "main_score": 0.939193,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.892611,
        "recall": 0.923828,
        "f1": 0.902311,
        "accuracy": 0.923828,
        "main_score": 0.902311,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.984212,
        "recall": 0.989258,
        "f1": 0.98584,
        "accuracy": 0.989258,
        "main_score": 0.98584,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.772926,
        "recall": 0.828125,
        "f1": 0.78866,
        "accuracy": 0.828125,
        "main_score": 0.78866,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.983236,
        "recall": 0.988281,
        "f1": 0.984863,
        "accuracy": 0.988281,
        "main_score": 0.984863,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000448,
        "recall": 0.005859,
        "f1": 0.000799,
        "accuracy": 0.005859,
        "main_score": 0.000799,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.987142,
        "recall": 0.991211,
        "f1": 0.988444,
        "accuracy": 0.991211,
        "main_score": 0.988444,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.972168,
        "recall": 0.981445,
        "f1": 0.97526,
        "accuracy": 0.981445,
        "main_score": 0.97526,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.955218,
        "recall": 0.967773,
        "f1": 0.959066,
        "accuracy": 0.967773,
        "main_score": 0.959066,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001214,
        "recall": 0.006836,
        "f1": 0.001416,
        "accuracy": 0.006836,
        "main_score": 0.001416,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.838913,
        "recall": 0.876953,
        "f1": 0.849975,
        "accuracy": 0.876953,
        "main_score": 0.849975,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.973145,
        "recall": 0.981445,
        "f1": 0.975911,
        "accuracy": 0.981445,
        "main_score": 0.975911,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.982747,
        "recall": 0.988281,
        "f1": 0.984538,
        "accuracy": 0.988281,
        "main_score": 0.984538,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.452615,
        "recall": 0.510742,
        "f1": 0.467412,
        "accuracy": 0.510742,
        "main_score": 0.467412,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.469641,
        "recall": 0.522461,
        "f1": 0.483251,
        "accuracy": 0.522461,
        "main_score": 0.483251,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.474138,
        "recall": 0.526367,
        "f1": 0.486399,
        "accuracy": 0.526367,
        "main_score": 0.486399,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.392382,
        "recall": 0.442383,
        "f1": 0.403198,
        "accuracy": 0.442383,
        "main_score": 0.403198,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.47956,
        "recall": 0.533203,
        "f1": 0.493167,
        "accuracy": 0.533203,
        "main_score": 0.493167,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.466657,
        "recall": 0.506836,
        "f1": 0.476369,
        "accuracy": 0.506836,
        "main_score": 0.476369,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.457314,
        "recall": 0.505859,
        "f1": 0.469877,
        "accuracy": 0.505859,
        "main_score": 0.469877,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.415746,
        "recall": 0.463867,
        "f1": 0.427627,
        "accuracy": 0.463867,
        "main_score": 0.427627,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.382108,
        "recall": 0.421875,
        "f1": 0.39186,
        "accuracy": 0.421875,
        "main_score": 0.39186,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.487651,
        "recall": 0.540039,
        "f1": 0.500797,
        "accuracy": 0.540039,
        "main_score": 0.500797,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.431041,
        "recall": 0.483398,
        "f1": 0.443794,
        "accuracy": 0.483398,
        "main_score": 0.443794,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.45915,
        "recall": 0.505859,
        "f1": 0.47093,
        "accuracy": 0.505859,
        "main_score": 0.47093,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000147,
        "recall": 0.00293,
        "f1": 0.000266,
        "accuracy": 0.00293,
        "main_score": 0.000266,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.477695,
        "recall": 0.53125,
        "f1": 0.490415,
        "accuracy": 0.53125,
        "main_score": 0.490415,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.436703,
        "recall": 0.478516,
        "f1": 0.447215,
        "accuracy": 0.478516,
        "main_score": 0.447215,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.456531,
        "recall": 0.509766,
        "f1": 0.468934,
        "accuracy": 0.509766,
        "main_score": 0.468934,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.433216,
        "recall": 0.504883,
        "f1": 0.449932,
        "accuracy": 0.504883,
        "main_score": 0.449932,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00121,
        "recall": 0.004883,
        "f1": 0.001393,
        "accuracy": 0.004883,
        "main_score": 0.001393,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.508132,
        "recall": 0.548828,
        "f1": 0.517808,
        "accuracy": 0.548828,
        "main_score": 0.517808,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.390263,
        "recall": 0.431641,
        "f1": 0.40007,
        "accuracy": 0.431641,
        "main_score": 0.40007,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.436524,
        "recall": 0.477539,
        "f1": 0.446113,
        "accuracy": 0.477539,
        "main_score": 0.446113,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.435074,
        "recall": 0.476562,
        "f1": 0.445375,
        "accuracy": 0.476562,
        "main_score": 0.445375,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.950846,
        "recall": 0.96582,
        "f1": 0.955534,
        "accuracy": 0.96582,
        "main_score": 0.955534,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.966471,
        "recall": 0.976562,
        "f1": 0.969727,
        "accuracy": 0.976562,
        "main_score": 0.969727,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.463018,
        "recall": 0.536133,
        "f1": 0.481946,
        "accuracy": 0.536133,
        "main_score": 0.481946,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.914365,
        "recall": 0.9375,
        "f1": 0.921064,
        "accuracy": 0.9375,
        "main_score": 0.921064,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.893369,
        "recall": 0.921875,
        "f1": 0.902021,
        "accuracy": 0.921875,
        "main_score": 0.902021,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.965983,
        "recall": 0.975586,
        "f1": 0.969076,
        "accuracy": 0.975586,
        "main_score": 0.969076,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.980469,
        "recall": 0.986328,
        "f1": 0.982259,
        "accuracy": 0.986328,
        "main_score": 0.982259,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.942057,
        "recall": 0.958984,
        "f1": 0.947233,
        "accuracy": 0.958984,
        "main_score": 0.947233,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.774832,
        "recall": 0.823242,
        "f1": 0.787972,
        "accuracy": 0.823242,
        "main_score": 0.787972,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.937695,
        "recall": 0.954102,
        "f1": 0.942499,
        "accuracy": 0.954102,
        "main_score": 0.942499,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.961914,
        "recall": 0.973633,
        "f1": 0.965658,
        "accuracy": 0.973633,
        "main_score": 0.965658,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000364,
        "recall": 0.003906,
        "f1": 0.000636,
        "accuracy": 0.003906,
        "main_score": 0.000636,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.972738,
        "recall": 0.980469,
        "f1": 0.975163,
        "accuracy": 0.980469,
        "main_score": 0.975163,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.952669,
        "recall": 0.966797,
        "f1": 0.957031,
        "accuracy": 0.966797,
        "main_score": 0.957031,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.955729,
        "recall": 0.969727,
        "f1": 0.960286,
        "accuracy": 0.969727,
        "main_score": 0.960286,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.923096,
        "recall": 0.944336,
        "f1": 0.929543,
        "accuracy": 0.944336,
        "main_score": 0.929543,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001026,
        "recall": 0.004883,
        "f1": 0.001074,
        "accuracy": 0.004883,
        "main_score": 0.001074,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.8602,
        "recall": 0.894531,
        "f1": 0.870052,
        "accuracy": 0.894531,
        "main_score": 0.870052,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.917415,
        "recall": 0.939453,
        "f1": 0.924168,
        "accuracy": 0.939453,
        "main_score": 0.924168,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.933708,
        "recall": 0.950195,
        "f1": 0.938314,
        "accuracy": 0.950195,
        "main_score": 0.938314,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.955241,
        "recall": 0.967773,
        "f1": 0.959115,
        "accuracy": 0.967773,
        "main_score": 0.959115,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.9611,
        "recall": 0.973633,
        "f1": 0.965169,
        "accuracy": 0.973633,
        "main_score": 0.965169,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.978027,
        "recall": 0.985352,
        "f1": 0.980469,
        "accuracy": 0.985352,
        "main_score": 0.980469,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.32572,
        "recall": 0.408203,
        "f1": 0.344588,
        "accuracy": 0.408203,
        "main_score": 0.344588,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.881217,
        "recall": 0.916992,
        "f1": 0.892369,
        "accuracy": 0.916992,
        "main_score": 0.892369,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.80774,
        "recall": 0.860352,
        "f1": 0.823356,
        "accuracy": 0.860352,
        "main_score": 0.823356,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.959635,
        "recall": 0.972656,
        "f1": 0.963867,
        "accuracy": 0.972656,
        "main_score": 0.963867,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.9486,
        "recall": 0.963867,
        "f1": 0.953288,
        "accuracy": 0.963867,
        "main_score": 0.953288,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.669109,
        "recall": 0.742188,
        "f1": 0.689475,
        "accuracy": 0.742188,
        "main_score": 0.689475,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.949707,
        "recall": 0.96582,
        "f1": 0.954915,
        "accuracy": 0.96582,
        "main_score": 0.954915,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.963704,
        "recall": 0.974609,
        "f1": 0.967122,
        "accuracy": 0.974609,
        "main_score": 0.967122,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.958171,
        "recall": 0.97168,
        "f1": 0.962565,
        "accuracy": 0.97168,
        "main_score": 0.962565,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 4.7e-05,
        "recall": 0.001953,
        "f1": 9e-05,
        "accuracy": 0.001953,
        "main_score": 9e-05,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.969564,
        "recall": 0.979492,
        "f1": 0.972819,
        "accuracy": 0.979492,
        "main_score": 0.972819,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.948324,
        "recall": 0.964844,
        "f1": 0.953678,
        "accuracy": 0.964844,
        "main_score": 0.953678,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.943197,
        "recall": 0.960938,
        "f1": 0.948893,
        "accuracy": 0.960938,
        "main_score": 0.948893,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.900871,
        "recall": 0.927734,
        "f1": 0.908876,
        "accuracy": 0.927734,
        "main_score": 0.908876,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 3.2e-05,
        "recall": 0.00293,
        "f1": 6.3e-05,
        "accuracy": 0.00293,
        "main_score": 6.3e-05,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.7446,
        "recall": 0.806641,
        "f1": 0.762131,
        "accuracy": 0.806641,
        "main_score": 0.762131,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.945475,
        "recall": 0.961914,
        "f1": 0.950684,
        "accuracy": 0.961914,
        "main_score": 0.950684,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.954183,
        "recall": 0.96875,
        "f1": 0.958887,
        "accuracy": 0.96875,
        "main_score": 0.958887,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.911043,
        "recall": 0.93457,
        "f1": 0.918088,
        "accuracy": 0.93457,
        "main_score": 0.918088,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.923014,
        "recall": 0.944336,
        "f1": 0.929655,
        "accuracy": 0.944336,
        "main_score": 0.929655,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.437554,
        "recall": 0.512695,
        "f1": 0.45673,
        "accuracy": 0.512695,
        "main_score": 0.45673,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.903971,
        "recall": 0.927734,
        "f1": 0.911021,
        "accuracy": 0.927734,
        "main_score": 0.911021,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.845004,
        "recall": 0.881836,
        "f1": 0.855204,
        "accuracy": 0.881836,
        "main_score": 0.855204,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.935368,
        "recall": 0.953125,
        "f1": 0.940658,
        "accuracy": 0.953125,
        "main_score": 0.940658,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.913574,
        "recall": 0.938477,
        "f1": 0.921322,
        "accuracy": 0.938477,
        "main_score": 0.921322,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.903792,
        "recall": 0.926758,
        "f1": 0.910514,
        "accuracy": 0.926758,
        "main_score": 0.910514,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.697192,
        "recall": 0.756836,
        "f1": 0.712489,
        "accuracy": 0.756836,
        "main_score": 0.712489,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.93571,
        "recall": 0.955078,
        "f1": 0.941732,
        "accuracy": 0.955078,
        "main_score": 0.941732,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.877093,
        "recall": 0.907227,
        "f1": 0.886117,
        "accuracy": 0.907227,
        "main_score": 0.886117,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.947591,
        "recall": 0.963867,
        "f1": 0.952799,
        "accuracy": 0.963867,
        "main_score": 0.952799,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 6.6e-05,
        "recall": 0.001953,
        "f1": 0.000125,
        "accuracy": 0.001953,
        "main_score": 0.000125,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.924375,
        "recall": 0.944336,
        "f1": 0.930322,
        "accuracy": 0.944336,
        "main_score": 0.930322,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.886263,
        "recall": 0.916992,
        "f1": 0.895475,
        "accuracy": 0.916992,
        "main_score": 0.895475,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.880494,
        "recall": 0.912109,
        "f1": 0.889632,
        "accuracy": 0.912109,
        "main_score": 0.889632,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.874788,
        "recall": 0.910156,
        "f1": 0.885435,
        "accuracy": 0.910156,
        "main_score": 0.885435,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002117,
        "recall": 0.007812,
        "f1": 0.002694,
        "accuracy": 0.007812,
        "main_score": 0.002694,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.801981,
        "recall": 0.84375,
        "f1": 0.814154,
        "accuracy": 0.84375,
        "main_score": 0.814154,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.87238,
        "recall": 0.904297,
        "f1": 0.882194,
        "accuracy": 0.904297,
        "main_score": 0.882194,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.890765,
        "recall": 0.919922,
        "f1": 0.89943,
        "accuracy": 0.919922,
        "main_score": 0.89943,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.894629,
        "recall": 0.920898,
        "f1": 0.902116,
        "accuracy": 0.920898,
        "main_score": 0.902116,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.424277,
        "recall": 0.510742,
        "f1": 0.445466,
        "accuracy": 0.510742,
        "main_score": 0.445466,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.942139,
        "recall": 0.959961,
        "f1": 0.947819,
        "accuracy": 0.959961,
        "main_score": 0.947819,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.970052,
        "recall": 0.979492,
        "f1": 0.973145,
        "accuracy": 0.979492,
        "main_score": 0.973145,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.918538,
        "recall": 0.943359,
        "f1": 0.926497,
        "accuracy": 0.943359,
        "main_score": 0.926497,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.765852,
        "recall": 0.817383,
        "f1": 0.780273,
        "accuracy": 0.817383,
        "main_score": 0.780273,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.98584,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000226,
        "recall": 0.00293,
        "f1": 0.000399,
        "accuracy": 0.00293,
        "main_score": 0.000399,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.970703,
        "recall": 0.980469,
        "f1": 0.973958,
        "accuracy": 0.980469,
        "main_score": 0.973958,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.948079,
        "recall": 0.963867,
        "f1": 0.953125,
        "accuracy": 0.963867,
        "main_score": 0.953125,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000311,
        "recall": 0.004883,
        "f1": 0.000558,
        "accuracy": 0.004883,
        "main_score": 0.000558,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.854761,
        "recall": 0.891602,
        "f1": 0.865763,
        "accuracy": 0.891602,
        "main_score": 0.865763,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.967611,
        "recall": 0.977539,
        "f1": 0.970866,
        "accuracy": 0.977539,
        "main_score": 0.970866,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.984375,
        "recall": 0.989258,
        "f1": 0.986003,
        "accuracy": 0.989258,
        "main_score": 0.986003,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.422273,
        "recall": 0.511719,
        "f1": 0.444345,
        "accuracy": 0.511719,
        "main_score": 0.444345,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.968424,
        "recall": 0.978516,
        "f1": 0.97168,
        "accuracy": 0.978516,
        "main_score": 0.97168,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.901969,
        "recall": 0.930664,
        "f1": 0.910872,
        "accuracy": 0.930664,
        "main_score": 0.910872,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.987305,
        "recall": 0.991211,
        "f1": 0.988607,
        "accuracy": 0.991211,
        "main_score": 0.988607,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.77527,
        "recall": 0.833008,
        "f1": 0.791915,
        "accuracy": 0.833008,
        "main_score": 0.791915,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.985189,
        "recall": 0.989258,
        "f1": 0.986491,
        "accuracy": 0.989258,
        "main_score": 0.986491,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000744,
        "recall": 0.005859,
        "f1": 0.00125,
        "accuracy": 0.005859,
        "main_score": 0.00125,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991536,
        "recall": 0.994141,
        "f1": 0.99235,
        "accuracy": 0.994141,
        "main_score": 0.99235,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.980632,
        "recall": 0.986328,
        "f1": 0.982422,
        "accuracy": 0.986328,
        "main_score": 0.982422,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.956738,
        "recall": 0.96875,
        "f1": 0.960449,
        "accuracy": 0.96875,
        "main_score": 0.960449,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000363,
        "recall": 0.006836,
        "f1": 0.000641,
        "accuracy": 0.006836,
        "main_score": 0.000641,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.8641,
        "recall": 0.899414,
        "f1": 0.874642,
        "accuracy": 0.899414,
        "main_score": 0.874642,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.978516,
        "recall": 0.985352,
        "f1": 0.980794,
        "accuracy": 0.985352,
        "main_score": 0.980794,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.987142,
        "recall": 0.991211,
        "f1": 0.988444,
        "accuracy": 0.991211,
        "main_score": 0.988444,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.380666,
        "recall": 0.476562,
        "f1": 0.404386,
        "accuracy": 0.476562,
        "main_score": 0.404386,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.927653,
        "recall": 0.950195,
        "f1": 0.934798,
        "accuracy": 0.950195,
        "main_score": 0.934798,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.893636,
        "recall": 0.925781,
        "f1": 0.903678,
        "accuracy": 0.925781,
        "main_score": 0.903678,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.747224,
        "recall": 0.804688,
        "f1": 0.763008,
        "accuracy": 0.804688,
        "main_score": 0.763008,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.984701,
        "recall": 0.989258,
        "f1": 0.986165,
        "accuracy": 0.989258,
        "main_score": 0.986165,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000156,
        "recall": 0.003906,
        "f1": 0.000297,
        "accuracy": 0.003906,
        "main_score": 0.000297,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.965332,
        "recall": 0.975586,
        "f1": 0.96875,
        "accuracy": 0.975586,
        "main_score": 0.96875,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.955892,
        "recall": 0.969727,
        "f1": 0.960449,
        "accuracy": 0.969727,
        "main_score": 0.960449,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002011,
        "recall": 0.008789,
        "f1": 0.002569,
        "accuracy": 0.008789,
        "main_score": 0.002569,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.821851,
        "recall": 0.868164,
        "f1": 0.835746,
        "accuracy": 0.868164,
        "main_score": 0.835746,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.977539,
        "recall": 0.984375,
        "f1": 0.979818,
        "accuracy": 0.984375,
        "main_score": 0.979818,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.801456,
        "recall": 0.84668,
        "f1": 0.814667,
        "accuracy": 0.84668,
        "main_score": 0.814667,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.822545,
        "recall": 0.863281,
        "f1": 0.83459,
        "accuracy": 0.863281,
        "main_score": 0.83459,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.401309,
        "recall": 0.486328,
        "f1": 0.423331,
        "accuracy": 0.486328,
        "main_score": 0.423331,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.820859,
        "recall": 0.865234,
        "f1": 0.834215,
        "accuracy": 0.865234,
        "main_score": 0.834215,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.758371,
        "recall": 0.8125,
        "f1": 0.773027,
        "accuracy": 0.8125,
        "main_score": 0.773027,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.755519,
        "recall": 0.804688,
        "f1": 0.769143,
        "accuracy": 0.804688,
        "main_score": 0.769143,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.813325,
        "recall": 0.848633,
        "f1": 0.823542,
        "accuracy": 0.848633,
        "main_score": 0.823542,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.830282,
        "recall": 0.87207,
        "f1": 0.842541,
        "accuracy": 0.87207,
        "main_score": 0.842541,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.793087,
        "recall": 0.835938,
        "f1": 0.804651,
        "accuracy": 0.835938,
        "main_score": 0.804651,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.840025,
        "recall": 0.879883,
        "f1": 0.851798,
        "accuracy": 0.879883,
        "main_score": 0.851798,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.788081,
        "recall": 0.835938,
        "f1": 0.801908,
        "accuracy": 0.835938,
        "main_score": 0.801908,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.821711,
        "recall": 0.861328,
        "f1": 0.833333,
        "accuracy": 0.861328,
        "main_score": 0.833333,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00132,
        "recall": 0.006836,
        "f1": 0.001612,
        "accuracy": 0.006836,
        "main_score": 0.001612,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.840269,
        "recall": 0.876953,
        "f1": 0.850841,
        "accuracy": 0.876953,
        "main_score": 0.850841,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.783248,
        "recall": 0.824219,
        "f1": 0.794836,
        "accuracy": 0.824219,
        "main_score": 0.794836,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.802239,
        "recall": 0.848633,
        "f1": 0.815252,
        "accuracy": 0.848633,
        "main_score": 0.815252,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.760224,
        "recall": 0.816406,
        "f1": 0.776156,
        "accuracy": 0.816406,
        "main_score": 0.776156,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001958,
        "recall": 0.010742,
        "f1": 0.002936,
        "accuracy": 0.010742,
        "main_score": 0.002936,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.750954,
        "recall": 0.797852,
        "f1": 0.763457,
        "accuracy": 0.797852,
        "main_score": 0.763457,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.750198,
        "recall": 0.803711,
        "f1": 0.765406,
        "accuracy": 0.803711,
        "main_score": 0.765406,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.793636,
        "recall": 0.833984,
        "f1": 0.804822,
        "accuracy": 0.833984,
        "main_score": 0.804822,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.898258,
        "recall": 0.924805,
        "f1": 0.905911,
        "accuracy": 0.924805,
        "main_score": 0.905911,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.980957,
        "recall": 0.987305,
        "f1": 0.983073,
        "accuracy": 0.987305,
        "main_score": 0.983073,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.431285,
        "recall": 0.518555,
        "f1": 0.452317,
        "accuracy": 0.518555,
        "main_score": 0.452317,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.968945,
        "recall": 0.978516,
        "f1": 0.972005,
        "accuracy": 0.978516,
        "main_score": 0.972005,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.970866,
        "recall": 0.979492,
        "f1": 0.973633,
        "accuracy": 0.979492,
        "main_score": 0.973633,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.894938,
        "recall": 0.924805,
        "f1": 0.904153,
        "accuracy": 0.924805,
        "main_score": 0.904153,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.978516,
        "recall": 0.985352,
        "f1": 0.980794,
        "accuracy": 0.985352,
        "main_score": 0.980794,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.975586,
        "recall": 0.983398,
        "f1": 0.97819,
        "accuracy": 0.983398,
        "main_score": 0.97819,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.782139,
        "recall": 0.834961,
        "f1": 0.797089,
        "accuracy": 0.834961,
        "main_score": 0.797089,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.96875,
        "recall": 0.977539,
        "f1": 0.971517,
        "accuracy": 0.977539,
        "main_score": 0.971517,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.98291,
        "recall": 0.988281,
        "f1": 0.984701,
        "accuracy": 0.988281,
        "main_score": 0.984701,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000302,
        "recall": 0.003906,
        "f1": 0.00054,
        "accuracy": 0.003906,
        "main_score": 0.00054,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.973226,
        "recall": 0.981445,
        "f1": 0.975814,
        "accuracy": 0.981445,
        "main_score": 0.975814,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.947103,
        "recall": 0.962891,
        "f1": 0.952311,
        "accuracy": 0.962891,
        "main_score": 0.952311,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000669,
        "recall": 0.005859,
        "f1": 0.000982,
        "accuracy": 0.005859,
        "main_score": 0.000982,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.859864,
        "recall": 0.893555,
        "f1": 0.869459,
        "accuracy": 0.893555,
        "main_score": 0.869459,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.952311,
        "recall": 0.966797,
        "f1": 0.956868,
        "accuracy": 0.966797,
        "main_score": 0.956868,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.977295,
        "recall": 0.984375,
        "f1": 0.979557,
        "accuracy": 0.984375,
        "main_score": 0.979557,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.978353,
        "recall": 0.985352,
        "f1": 0.980632,
        "accuracy": 0.985352,
        "main_score": 0.980632,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.978027,
        "recall": 0.985352,
        "f1": 0.980469,
        "accuracy": 0.985352,
        "main_score": 0.980469,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.987142,
        "recall": 0.991211,
        "f1": 0.988444,
        "accuracy": 0.991211,
        "main_score": 0.988444,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.393806,
        "recall": 0.479492,
        "f1": 0.415127,
        "accuracy": 0.479492,
        "main_score": 0.415127,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.912354,
        "recall": 0.939453,
        "f1": 0.920964,
        "accuracy": 0.939453,
        "main_score": 0.920964,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.871208,
        "recall": 0.910156,
        "f1": 0.883366,
        "accuracy": 0.910156,
        "main_score": 0.883366,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.982747,
        "recall": 0.988281,
        "f1": 0.984538,
        "accuracy": 0.988281,
        "main_score": 0.984538,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.980957,
        "recall": 0.987305,
        "f1": 0.983073,
        "accuracy": 0.987305,
        "main_score": 0.983073,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.72409,
        "recall": 0.787109,
        "f1": 0.741301,
        "accuracy": 0.787109,
        "main_score": 0.741301,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.973633,
        "recall": 0.982422,
        "f1": 0.976562,
        "accuracy": 0.982422,
        "main_score": 0.976562,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.974609,
        "recall": 0.982422,
        "f1": 0.977051,
        "accuracy": 0.982422,
        "main_score": 0.977051,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000281,
        "recall": 0.00293,
        "f1": 0.000493,
        "accuracy": 0.00293,
        "main_score": 0.000493,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.974284,
        "recall": 0.982422,
        "f1": 0.976888,
        "accuracy": 0.982422,
        "main_score": 0.976888,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.958171,
        "recall": 0.970703,
        "f1": 0.962077,
        "accuracy": 0.970703,
        "main_score": 0.962077,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.944499,
        "recall": 0.961914,
        "f1": 0.950033,
        "accuracy": 0.961914,
        "main_score": 0.950033,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00162,
        "recall": 0.006836,
        "f1": 0.001918,
        "accuracy": 0.006836,
        "main_score": 0.001918,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.811412,
        "recall": 0.860352,
        "f1": 0.825756,
        "accuracy": 0.860352,
        "main_score": 0.825756,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.977702,
        "recall": 0.984375,
        "f1": 0.979818,
        "accuracy": 0.984375,
        "main_score": 0.979818,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.978027,
        "recall": 0.985352,
        "f1": 0.980469,
        "accuracy": 0.985352,
        "main_score": 0.980469,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.982747,
        "recall": 0.988281,
        "f1": 0.984538,
        "accuracy": 0.988281,
        "main_score": 0.984538,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.412099,
        "recall": 0.501953,
        "f1": 0.434515,
        "accuracy": 0.501953,
        "main_score": 0.434515,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.952555,
        "recall": 0.966797,
        "f1": 0.956934,
        "accuracy": 0.966797,
        "main_score": 0.956934,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.975749,
        "recall": 0.983398,
        "f1": 0.97819,
        "accuracy": 0.983398,
        "main_score": 0.97819,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.940837,
        "recall": 0.958984,
        "f1": 0.946517,
        "accuracy": 0.958984,
        "main_score": 0.946517,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.737355,
        "recall": 0.796875,
        "f1": 0.753653,
        "accuracy": 0.796875,
        "main_score": 0.753653,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.984375,
        "recall": 0.989258,
        "f1": 0.986003,
        "accuracy": 0.989258,
        "main_score": 0.986003,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000487,
        "recall": 0.003906,
        "f1": 0.000786,
        "accuracy": 0.003906,
        "main_score": 0.000786,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.97334,
        "recall": 0.981445,
        "f1": 0.975911,
        "accuracy": 0.981445,
        "main_score": 0.975911,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.961263,
        "recall": 0.973633,
        "f1": 0.965332,
        "accuracy": 0.973633,
        "main_score": 0.965332,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000574,
        "recall": 0.007812,
        "f1": 0.000944,
        "accuracy": 0.007812,
        "main_score": 0.000944,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.839972,
        "recall": 0.878906,
        "f1": 0.851286,
        "accuracy": 0.878906,
        "main_score": 0.851286,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.972331,
        "recall": 0.980469,
        "f1": 0.974935,
        "accuracy": 0.980469,
        "main_score": 0.974935,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.984538,
        "recall": 0.989258,
        "f1": 0.986003,
        "accuracy": 0.989258,
        "main_score": 0.986003,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002052,
        "recall": 0.004883,
        "f1": 0.002138,
        "accuracy": 0.004883,
        "main_score": 0.002138,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001136,
        "recall": 0.003906,
        "f1": 0.001261,
        "accuracy": 0.003906,
        "main_score": 0.001261,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001122,
        "recall": 0.004883,
        "f1": 0.001244,
        "accuracy": 0.004883,
        "main_score": 0.001244,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.001955,
        "recall": 0.00293,
        "f1": 0.001957,
        "accuracy": 0.00293,
        "main_score": 0.001957,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000491,
        "recall": 0.001953,
        "f1": 0.000657,
        "accuracy": 0.001953,
        "main_score": 0.000657,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001058,
        "recall": 0.001953,
        "f1": 0.001127,
        "accuracy": 0.001953,
        "main_score": 0.001127,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001713,
        "recall": 0.003906,
        "f1": 0.002026,
        "accuracy": 0.003906,
        "main_score": 0.002026,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000244,
        "recall": 0.000977,
        "f1": 0.000391,
        "accuracy": 0.000977,
        "main_score": 0.000391,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000979,
        "recall": 0.001953,
        "f1": 0.000981,
        "accuracy": 0.001953,
        "main_score": 0.000981,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001311,
        "recall": 0.003906,
        "f1": 0.001533,
        "accuracy": 0.003906,
        "main_score": 0.001533,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000885,
        "recall": 0.003906,
        "f1": 0.001276,
        "accuracy": 0.003906,
        "main_score": 0.001276,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.001045,
        "recall": 0.00293,
        "f1": 0.001105,
        "accuracy": 0.00293,
        "main_score": 0.001105,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000983,
        "recall": 0.001953,
        "f1": 0.000989,
        "accuracy": 0.001953,
        "main_score": 0.000989,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00163,
        "recall": 0.003906,
        "f1": 0.001911,
        "accuracy": 0.003906,
        "main_score": 0.001911,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001467,
        "recall": 0.00293,
        "f1": 0.001633,
        "accuracy": 0.00293,
        "main_score": 0.001633,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.003213,
        "recall": 0.004883,
        "f1": 0.003395,
        "accuracy": 0.004883,
        "main_score": 0.003395,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001531,
        "recall": 0.003906,
        "f1": 0.001754,
        "accuracy": 0.003906,
        "main_score": 0.001754,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001175,
        "recall": 0.00293,
        "f1": 0.001309,
        "accuracy": 0.00293,
        "main_score": 0.001309,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.002116,
        "recall": 0.00293,
        "f1": 0.002232,
        "accuracy": 0.00293,
        "main_score": 0.002232,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.000985,
        "recall": 0.00293,
        "f1": 0.000992,
        "accuracy": 0.00293,
        "main_score": 0.000992,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000995,
        "recall": 0.00293,
        "f1": 0.001014,
        "accuracy": 0.00293,
        "main_score": 0.001014,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001505,
        "recall": 0.004883,
        "f1": 0.001706,
        "accuracy": 0.004883,
        "main_score": 0.001706,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.416272,
        "recall": 0.507812,
        "f1": 0.438799,
        "accuracy": 0.507812,
        "main_score": 0.438799,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.953044,
        "recall": 0.967773,
        "f1": 0.957747,
        "accuracy": 0.967773,
        "main_score": 0.957747,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.904297,
        "recall": 0.932617,
        "f1": 0.913216,
        "accuracy": 0.932617,
        "main_score": 0.913216,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.76782,
        "recall": 0.821289,
        "f1": 0.783197,
        "accuracy": 0.821289,
        "main_score": 0.783197,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.980306,
        "recall": 0.986328,
        "f1": 0.982259,
        "accuracy": 0.986328,
        "main_score": 0.982259,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.98877,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000134,
        "recall": 0.00293,
        "f1": 0.000252,
        "accuracy": 0.00293,
        "main_score": 0.000252,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.976237,
        "recall": 0.983398,
        "f1": 0.978516,
        "accuracy": 0.983398,
        "main_score": 0.978516,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.96639,
        "recall": 0.976562,
        "f1": 0.969629,
        "accuracy": 0.976562,
        "main_score": 0.969629,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 6.2e-05,
        "recall": 0.003906,
        "f1": 0.000121,
        "accuracy": 0.003906,
        "main_score": 0.000121,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.858977,
        "recall": 0.895508,
        "f1": 0.869813,
        "accuracy": 0.895508,
        "main_score": 0.869813,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.970052,
        "recall": 0.979492,
        "f1": 0.973145,
        "accuracy": 0.979492,
        "main_score": 0.973145,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.993001,
        "recall": 0.995117,
        "f1": 0.993652,
        "accuracy": 0.995117,
        "main_score": 0.993652,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.411413,
        "recall": 0.505859,
        "f1": 0.434691,
        "accuracy": 0.505859,
        "main_score": 0.434691,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.951497,
        "recall": 0.96582,
        "f1": 0.956008,
        "accuracy": 0.96582,
        "main_score": 0.956008,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.980957,
        "recall": 0.987305,
        "f1": 0.983073,
        "accuracy": 0.987305,
        "main_score": 0.983073,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.903353,
        "recall": 0.931641,
        "f1": 0.91224,
        "accuracy": 0.931641,
        "main_score": 0.91224,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.77763,
        "recall": 0.832031,
        "f1": 0.793167,
        "accuracy": 0.832031,
        "main_score": 0.793167,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.981934,
        "recall": 0.987305,
        "f1": 0.983724,
        "accuracy": 0.987305,
        "main_score": 0.983724,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000132,
        "recall": 0.00293,
        "f1": 0.00025,
        "accuracy": 0.00293,
        "main_score": 0.00025,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.976237,
        "recall": 0.983398,
        "f1": 0.978516,
        "accuracy": 0.983398,
        "main_score": 0.978516,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.949056,
        "recall": 0.963867,
        "f1": 0.953743,
        "accuracy": 0.963867,
        "main_score": 0.953743,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000591,
        "recall": 0.007812,
        "f1": 0.000968,
        "accuracy": 0.007812,
        "main_score": 0.000968,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.846421,
        "recall": 0.885742,
        "f1": 0.858008,
        "accuracy": 0.885742,
        "main_score": 0.858008,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.9764,
        "recall": 0.983398,
        "f1": 0.978678,
        "accuracy": 0.983398,
        "main_score": 0.978678,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.977051,
        "recall": 0.984375,
        "f1": 0.979492,
        "accuracy": 0.984375,
        "main_score": 0.979492,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.987305,
        "recall": 0.991211,
        "f1": 0.988607,
        "accuracy": 0.991211,
        "main_score": 0.988607,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.429638,
        "recall": 0.519531,
        "f1": 0.452493,
        "accuracy": 0.519531,
        "main_score": 0.452493,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.951009,
        "recall": 0.96582,
        "f1": 0.955729,
        "accuracy": 0.96582,
        "main_score": 0.955729,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.968424,
        "recall": 0.978516,
        "f1": 0.97168,
        "accuracy": 0.978516,
        "main_score": 0.97168,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.896494,
        "recall": 0.923828,
        "f1": 0.904639,
        "accuracy": 0.923828,
        "main_score": 0.904639,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.981445,
        "recall": 0.987305,
        "f1": 0.983398,
        "accuracy": 0.987305,
        "main_score": 0.983398,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.982747,
        "recall": 0.988281,
        "f1": 0.984538,
        "accuracy": 0.988281,
        "main_score": 0.984538,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.971029,
        "recall": 0.980469,
        "f1": 0.974121,
        "accuracy": 0.980469,
        "main_score": 0.974121,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.778658,
        "recall": 0.830078,
        "f1": 0.793142,
        "accuracy": 0.830078,
        "main_score": 0.793142,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.975911,
        "recall": 0.983398,
        "f1": 0.978353,
        "accuracy": 0.983398,
        "main_score": 0.978353,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.969564,
        "recall": 0.978516,
        "f1": 0.972331,
        "accuracy": 0.978516,
        "main_score": 0.972331,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.978516,
        "recall": 0.985352,
        "f1": 0.980794,
        "accuracy": 0.985352,
        "main_score": 0.980794,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000546,
        "recall": 0.004883,
        "f1": 0.000889,
        "accuracy": 0.004883,
        "main_score": 0.000889,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.968424,
        "recall": 0.978516,
        "f1": 0.97168,
        "accuracy": 0.978516,
        "main_score": 0.97168,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.945231,
        "recall": 0.961914,
        "f1": 0.950586,
        "accuracy": 0.961914,
        "main_score": 0.950586,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000729,
        "recall": 0.006836,
        "f1": 0.001097,
        "accuracy": 0.006836,
        "main_score": 0.001097,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.86075,
        "recall": 0.893555,
        "f1": 0.870289,
        "accuracy": 0.893555,
        "main_score": 0.870289,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.958008,
        "recall": 0.969727,
        "f1": 0.961751,
        "accuracy": 0.969727,
        "main_score": 0.961751,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.974609,
        "recall": 0.982422,
        "f1": 0.977051,
        "accuracy": 0.982422,
        "main_score": 0.977051,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.984212,
        "recall": 0.989258,
        "f1": 0.98584,
        "accuracy": 0.989258,
        "main_score": 0.98584,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.958008,
        "recall": 0.970703,
        "f1": 0.961914,
        "accuracy": 0.970703,
        "main_score": 0.961914,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.965853,
        "recall": 0.975586,
        "f1": 0.96875,
        "accuracy": 0.975586,
        "main_score": 0.96875,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.417861,
        "recall": 0.495117,
        "f1": 0.437069,
        "accuracy": 0.495117,
        "main_score": 0.437069,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.920199,
        "recall": 0.943359,
        "f1": 0.927637,
        "accuracy": 0.943359,
        "main_score": 0.927637,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.930729,
        "recall": 0.948242,
        "f1": 0.935962,
        "accuracy": 0.948242,
        "main_score": 0.935962,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.873079,
        "recall": 0.907227,
        "f1": 0.883547,
        "accuracy": 0.907227,
        "main_score": 0.883547,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.960075,
        "recall": 0.970703,
        "f1": 0.963281,
        "accuracy": 0.970703,
        "main_score": 0.963281,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.969108,
        "recall": 0.977539,
        "f1": 0.97168,
        "accuracy": 0.977539,
        "main_score": 0.97168,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.957601,
        "recall": 0.969727,
        "f1": 0.961282,
        "accuracy": 0.969727,
        "main_score": 0.961282,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.705648,
        "recall": 0.760742,
        "f1": 0.72028,
        "accuracy": 0.760742,
        "main_score": 0.72028,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.95874,
        "recall": 0.970703,
        "f1": 0.96263,
        "accuracy": 0.970703,
        "main_score": 0.96263,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.942464,
        "recall": 0.958984,
        "f1": 0.947461,
        "accuracy": 0.958984,
        "main_score": 0.947461,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.958659,
        "recall": 0.97168,
        "f1": 0.962891,
        "accuracy": 0.97168,
        "main_score": 0.962891,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001103,
        "recall": 0.00293,
        "f1": 0.001203,
        "accuracy": 0.00293,
        "main_score": 0.001203,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.977376,
        "recall": 0.984375,
        "f1": 0.979655,
        "accuracy": 0.984375,
        "main_score": 0.979655,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.950309,
        "recall": 0.963867,
        "f1": 0.954492,
        "accuracy": 0.963867,
        "main_score": 0.954492,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.939209,
        "recall": 0.955078,
        "f1": 0.944029,
        "accuracy": 0.955078,
        "main_score": 0.944029,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000253,
        "recall": 0.004883,
        "f1": 0.000439,
        "accuracy": 0.004883,
        "main_score": 0.000439,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.830958,
        "recall": 0.874023,
        "f1": 0.843705,
        "accuracy": 0.874023,
        "main_score": 0.843705,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.925618,
        "recall": 0.946289,
        "f1": 0.931934,
        "accuracy": 0.946289,
        "main_score": 0.931934,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.950798,
        "recall": 0.964844,
        "f1": 0.955143,
        "accuracy": 0.964844,
        "main_score": 0.955143,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.938517,
        "recall": 0.954102,
        "f1": 0.943153,
        "accuracy": 0.954102,
        "main_score": 0.943153,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.008437,
        "recall": 0.014648,
        "f1": 0.009247,
        "accuracy": 0.014648,
        "main_score": 0.009247,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002757,
        "recall": 0.007812,
        "f1": 0.003215,
        "accuracy": 0.007812,
        "main_score": 0.003215,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.002734,
        "recall": 0.007812,
        "f1": 0.003462,
        "accuracy": 0.007812,
        "main_score": 0.003462,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.004011,
        "recall": 0.009766,
        "f1": 0.004602,
        "accuracy": 0.009766,
        "main_score": 0.004602,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003284,
        "recall": 0.004883,
        "f1": 0.003474,
        "accuracy": 0.004883,
        "main_score": 0.003474,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00479,
        "recall": 0.009766,
        "f1": 0.005365,
        "accuracy": 0.009766,
        "main_score": 0.005365,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.00368,
        "recall": 0.009766,
        "f1": 0.004069,
        "accuracy": 0.009766,
        "main_score": 0.004069,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002133,
        "recall": 0.011719,
        "f1": 0.002955,
        "accuracy": 0.011719,
        "main_score": 0.002955,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00477,
        "recall": 0.011719,
        "f1": 0.005884,
        "accuracy": 0.011719,
        "main_score": 0.005884,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002423,
        "recall": 0.011719,
        "f1": 0.003302,
        "accuracy": 0.011719,
        "main_score": 0.003302,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.004573,
        "recall": 0.012695,
        "f1": 0.005492,
        "accuracy": 0.012695,
        "main_score": 0.005492,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.003184,
        "recall": 0.007812,
        "f1": 0.003385,
        "accuracy": 0.007812,
        "main_score": 0.003385,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.002715,
        "recall": 0.008789,
        "f1": 0.003206,
        "accuracy": 0.008789,
        "main_score": 0.003206,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000623,
        "recall": 0.004883,
        "f1": 0.00101,
        "accuracy": 0.004883,
        "main_score": 0.00101,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.002949,
        "recall": 0.012695,
        "f1": 0.003977,
        "accuracy": 0.012695,
        "main_score": 0.003977,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.005571,
        "recall": 0.010742,
        "f1": 0.00591,
        "accuracy": 0.010742,
        "main_score": 0.00591,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.003551,
        "recall": 0.009766,
        "f1": 0.003987,
        "accuracy": 0.009766,
        "main_score": 0.003987,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.006929,
        "recall": 0.012695,
        "f1": 0.007542,
        "accuracy": 0.012695,
        "main_score": 0.007542,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004741,
        "recall": 0.008789,
        "f1": 0.00516,
        "accuracy": 0.008789,
        "main_score": 0.00516,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.002366,
        "recall": 0.005859,
        "f1": 0.00261,
        "accuracy": 0.005859,
        "main_score": 0.00261,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.004492,
        "recall": 0.006836,
        "f1": 0.004883,
        "accuracy": 0.006836,
        "main_score": 0.004883,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002551,
        "recall": 0.009766,
        "f1": 0.003259,
        "accuracy": 0.009766,
        "main_score": 0.003259,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.845672,
        "recall": 0.882812,
        "f1": 0.856711,
        "accuracy": 0.882812,
        "main_score": 0.856711,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.878841,
        "recall": 0.907227,
        "f1": 0.887337,
        "accuracy": 0.907227,
        "main_score": 0.887337,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.482505,
        "recall": 0.556641,
        "f1": 0.50117,
        "accuracy": 0.556641,
        "main_score": 0.50117,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.872673,
        "recall": 0.90332,
        "f1": 0.881836,
        "accuracy": 0.90332,
        "main_score": 0.881836,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.797779,
        "recall": 0.838867,
        "f1": 0.808938,
        "accuracy": 0.838867,
        "main_score": 0.808938,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.825814,
        "recall": 0.867188,
        "f1": 0.837551,
        "accuracy": 0.867188,
        "main_score": 0.837551,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.870792,
        "recall": 0.900391,
        "f1": 0.879525,
        "accuracy": 0.900391,
        "main_score": 0.879525,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.887077,
        "recall": 0.916992,
        "f1": 0.895871,
        "accuracy": 0.916992,
        "main_score": 0.895871,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.844026,
        "recall": 0.880859,
        "f1": 0.854988,
        "accuracy": 0.880859,
        "main_score": 0.854988,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.71332,
        "recall": 0.771484,
        "f1": 0.728664,
        "accuracy": 0.771484,
        "main_score": 0.728664,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.89445,
        "recall": 0.920898,
        "f1": 0.902851,
        "accuracy": 0.920898,
        "main_score": 0.902851,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.831634,
        "recall": 0.868164,
        "f1": 0.842274,
        "accuracy": 0.868164,
        "main_score": 0.842274,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.860026,
        "recall": 0.894531,
        "f1": 0.87054,
        "accuracy": 0.894531,
        "main_score": 0.87054,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000304,
        "recall": 0.00293,
        "f1": 0.000504,
        "accuracy": 0.00293,
        "main_score": 0.000504,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.872664,
        "recall": 0.90625,
        "f1": 0.882769,
        "accuracy": 0.90625,
        "main_score": 0.882769,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.854383,
        "recall": 0.883789,
        "f1": 0.862744,
        "accuracy": 0.883789,
        "main_score": 0.862744,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.858496,
        "recall": 0.893555,
        "f1": 0.869094,
        "accuracy": 0.893555,
        "main_score": 0.869094,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.840039,
        "recall": 0.879883,
        "f1": 0.852148,
        "accuracy": 0.879883,
        "main_score": 0.852148,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001886,
        "recall": 0.008789,
        "f1": 0.002467,
        "accuracy": 0.008789,
        "main_score": 0.002467,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.791188,
        "recall": 0.834961,
        "f1": 0.803468,
        "accuracy": 0.834961,
        "main_score": 0.803468,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.837549,
        "recall": 0.874023,
        "f1": 0.847862,
        "accuracy": 0.874023,
        "main_score": 0.847862,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.874228,
        "recall": 0.902344,
        "f1": 0.882068,
        "accuracy": 0.902344,
        "main_score": 0.882068,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.969482,
        "recall": 0.978516,
        "f1": 0.972396,
        "accuracy": 0.978516,
        "main_score": 0.972396,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.978841,
        "recall": 0.985352,
        "f1": 0.980957,
        "accuracy": 0.985352,
        "main_score": 0.980957,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.335293,
        "recall": 0.424805,
        "f1": 0.356725,
        "accuracy": 0.424805,
        "main_score": 0.356725,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.887565,
        "recall": 0.919922,
        "f1": 0.897396,
        "accuracy": 0.919922,
        "main_score": 0.897396,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.969564,
        "recall": 0.979492,
        "f1": 0.972819,
        "accuracy": 0.979492,
        "main_score": 0.972819,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.86071,
        "recall": 0.900391,
        "f1": 0.872852,
        "accuracy": 0.900391,
        "main_score": 0.872852,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.967692,
        "recall": 0.977539,
        "f1": 0.970768,
        "accuracy": 0.977539,
        "main_score": 0.970768,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.978027,
        "recall": 0.985352,
        "f1": 0.980469,
        "accuracy": 0.985352,
        "main_score": 0.980469,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.974284,
        "recall": 0.982422,
        "f1": 0.976888,
        "accuracy": 0.982422,
        "main_score": 0.976888,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.707497,
        "recall": 0.767578,
        "f1": 0.723614,
        "accuracy": 0.767578,
        "main_score": 0.723614,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.959798,
        "recall": 0.972656,
        "f1": 0.96403,
        "accuracy": 0.972656,
        "main_score": 0.96403,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.974284,
        "recall": 0.981445,
        "f1": 0.976516,
        "accuracy": 0.981445,
        "main_score": 0.976516,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.968099,
        "recall": 0.978516,
        "f1": 0.971517,
        "accuracy": 0.978516,
        "main_score": 0.971517,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001122,
        "recall": 0.003906,
        "f1": 0.001248,
        "accuracy": 0.003906,
        "main_score": 0.001248,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.969564,
        "recall": 0.979492,
        "f1": 0.972819,
        "accuracy": 0.979492,
        "main_score": 0.972819,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.9729,
        "recall": 0.981445,
        "f1": 0.975651,
        "accuracy": 0.981445,
        "main_score": 0.975651,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.941081,
        "recall": 0.958984,
        "f1": 0.946777,
        "accuracy": 0.958984,
        "main_score": 0.946777,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.910107,
        "recall": 0.935547,
        "f1": 0.917839,
        "accuracy": 0.935547,
        "main_score": 0.917839,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000226,
        "recall": 0.004883,
        "f1": 0.000403,
        "accuracy": 0.004883,
        "main_score": 0.000403,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.778695,
        "recall": 0.828125,
        "f1": 0.793114,
        "accuracy": 0.828125,
        "main_score": 0.793114,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.964274,
        "recall": 0.974609,
        "f1": 0.96735,
        "accuracy": 0.974609,
        "main_score": 0.96735,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.972982,
        "recall": 0.981445,
        "f1": 0.975749,
        "accuracy": 0.981445,
        "main_score": 0.975749,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.977702,
        "recall": 0.984375,
        "f1": 0.979818,
        "accuracy": 0.984375,
        "main_score": 0.979818,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.415259,
        "recall": 0.508789,
        "f1": 0.438307,
        "accuracy": 0.508789,
        "main_score": 0.438307,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.929362,
        "recall": 0.951172,
        "f1": 0.936198,
        "accuracy": 0.951172,
        "main_score": 0.936198,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.893311,
        "recall": 0.925781,
        "f1": 0.903711,
        "accuracy": 0.925781,
        "main_score": 0.903711,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.985107,
        "recall": 0.989258,
        "f1": 0.986393,
        "accuracy": 0.989258,
        "main_score": 0.986393,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.769658,
        "recall": 0.826172,
        "f1": 0.786184,
        "accuracy": 0.826172,
        "main_score": 0.786184,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.984375,
        "recall": 0.989258,
        "f1": 0.986003,
        "accuracy": 0.989258,
        "main_score": 0.986003,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000689,
        "recall": 0.005859,
        "f1": 0.001034,
        "accuracy": 0.005859,
        "main_score": 0.001034,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.987142,
        "recall": 0.991211,
        "f1": 0.988444,
        "accuracy": 0.991211,
        "main_score": 0.988444,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.968099,
        "recall": 0.978516,
        "f1": 0.971517,
        "accuracy": 0.978516,
        "main_score": 0.971517,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.958577,
        "recall": 0.97168,
        "f1": 0.962793,
        "accuracy": 0.97168,
        "main_score": 0.962793,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000274,
        "recall": 0.005859,
        "f1": 0.000508,
        "accuracy": 0.005859,
        "main_score": 0.000508,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.819615,
        "recall": 0.866211,
        "f1": 0.833352,
        "accuracy": 0.866211,
        "main_score": 0.833352,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.977539,
        "recall": 0.984375,
        "f1": 0.979818,
        "accuracy": 0.984375,
        "main_score": 0.979818,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.984701,
        "recall": 0.989258,
        "f1": 0.986165,
        "accuracy": 0.989258,
        "main_score": 0.986165,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.389708,
        "recall": 0.486328,
        "f1": 0.414194,
        "accuracy": 0.486328,
        "main_score": 0.414194,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.932373,
        "recall": 0.953125,
        "f1": 0.938867,
        "accuracy": 0.953125,
        "main_score": 0.938867,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.884342,
        "recall": 0.918945,
        "f1": 0.89515,
        "accuracy": 0.918945,
        "main_score": 0.89515,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.870312,
        "recall": 0.907227,
        "f1": 0.881594,
        "accuracy": 0.907227,
        "main_score": 0.881594,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.980713,
        "recall": 0.986328,
        "f1": 0.982487,
        "accuracy": 0.986328,
        "main_score": 0.982487,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.983073,
        "recall": 0.988281,
        "f1": 0.984701,
        "accuracy": 0.988281,
        "main_score": 0.984701,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000223,
        "recall": 0.003906,
        "f1": 0.000405,
        "accuracy": 0.003906,
        "main_score": 0.000405,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.993001,
        "recall": 0.995117,
        "f1": 0.993652,
        "accuracy": 0.995117,
        "main_score": 0.993652,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.929281,
        "recall": 0.951172,
        "f1": 0.936263,
        "accuracy": 0.951172,
        "main_score": 0.936263,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000775,
        "recall": 0.006836,
        "f1": 0.001251,
        "accuracy": 0.006836,
        "main_score": 0.001251,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.84381,
        "recall": 0.883789,
        "f1": 0.855618,
        "accuracy": 0.883789,
        "main_score": 0.855618,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.96875,
        "recall": 0.978516,
        "f1": 0.972005,
        "accuracy": 0.978516,
        "main_score": 0.972005,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.982747,
        "recall": 0.988281,
        "f1": 0.984538,
        "accuracy": 0.988281,
        "main_score": 0.984538,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 940.3750541210175,
  "kg_co2_emissions": null
}