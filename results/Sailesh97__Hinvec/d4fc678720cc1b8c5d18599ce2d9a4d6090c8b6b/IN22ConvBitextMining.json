{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.38.30",
  "scores": {
    "test": [
      {
        "precision": 0.000273,
        "recall": 0.003327,
        "f1": 0.000432,
        "accuracy": 0.003327,
        "main_score": 0.000432,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001364,
        "recall": 0.003327,
        "f1": 0.001395,
        "accuracy": 0.003327,
        "main_score": 0.001395,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.056708,
        "recall": 0.072522,
        "f1": 0.058979,
        "accuracy": 0.072522,
        "main_score": 0.058979,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.47817,
        "recall": 0.542249,
        "f1": 0.494831,
        "accuracy": 0.542249,
        "main_score": 0.494831,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.78193,
        "recall": 0.819694,
        "f1": 0.791815,
        "accuracy": 0.819694,
        "main_score": 0.791815,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.147374,
        "recall": 0.192282,
        "f1": 0.15712,
        "accuracy": 0.192282,
        "main_score": 0.15712,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004987,
        "recall": 0.009315,
        "f1": 0.005648,
        "accuracy": 0.009315,
        "main_score": 0.005648,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000672,
        "recall": 0.007319,
        "f1": 0.001115,
        "accuracy": 0.007319,
        "main_score": 0.001115,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.000431,
        "recall": 0.006653,
        "f1": 0.000727,
        "accuracy": 0.006653,
        "main_score": 0.000727,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.048495,
        "recall": 0.089155,
        "f1": 0.055871,
        "accuracy": 0.089155,
        "main_score": 0.055871,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.429653,
        "recall": 0.513639,
        "f1": 0.450629,
        "accuracy": 0.513639,
        "main_score": 0.450629,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.834401,
        "recall": 0.868263,
        "f1": 0.843876,
        "accuracy": 0.868263,
        "main_score": 0.843876,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.160471,
        "recall": 0.23686,
        "f1": 0.176215,
        "accuracy": 0.23686,
        "main_score": 0.176215,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.003016,
        "recall": 0.00998,
        "f1": 0.003665,
        "accuracy": 0.00998,
        "main_score": 0.003665,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000192,
        "recall": 0.004657,
        "f1": 0.000364,
        "accuracy": 0.004657,
        "main_score": 0.000364,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003696,
        "recall": 0.010645,
        "f1": 0.004596,
        "accuracy": 0.010645,
        "main_score": 0.004596,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.473866,
        "recall": 0.547572,
        "f1": 0.492802,
        "accuracy": 0.547572,
        "main_score": 0.492802,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.004552,
        "recall": 0.016633,
        "f1": 0.006015,
        "accuracy": 0.016633,
        "main_score": 0.006015,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.22535,
        "recall": 0.306055,
        "f1": 0.243494,
        "accuracy": 0.306055,
        "main_score": 0.243494,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000777,
        "recall": 0.005988,
        "f1": 0.000879,
        "accuracy": 0.005988,
        "main_score": 0.000879,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.318718,
        "recall": 0.40652,
        "f1": 0.338875,
        "accuracy": 0.40652,
        "main_score": 0.338875,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.003992,
        "f1": 0.000304,
        "accuracy": 0.003992,
        "main_score": 0.000304,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.009254,
        "recall": 0.01996,
        "f1": 0.010997,
        "accuracy": 0.01996,
        "main_score": 0.010997,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.258737,
        "recall": 0.337325,
        "f1": 0.277043,
        "accuracy": 0.337325,
        "main_score": 0.277043,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000254,
        "recall": 0.004657,
        "f1": 0.000457,
        "accuracy": 0.004657,
        "main_score": 0.000457,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.282882,
        "recall": 0.369927,
        "f1": 0.302829,
        "accuracy": 0.369927,
        "main_score": 0.302829,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.004846,
        "recall": 0.017299,
        "f1": 0.006333,
        "accuracy": 0.017299,
        "main_score": 0.006333,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.005907,
        "recall": 0.015968,
        "f1": 0.007448,
        "accuracy": 0.015968,
        "main_score": 0.007448,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002982,
        "recall": 0.008649,
        "f1": 0.003608,
        "accuracy": 0.008649,
        "main_score": 0.003608,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000944,
        "recall": 0.003327,
        "f1": 0.001107,
        "accuracy": 0.003327,
        "main_score": 0.001107,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004162,
        "recall": 0.007319,
        "f1": 0.004549,
        "accuracy": 0.007319,
        "main_score": 0.004549,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.593392,
        "recall": 0.652029,
        "f1": 0.609074,
        "accuracy": 0.652029,
        "main_score": 0.609074,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005523,
        "recall": 0.00998,
        "f1": 0.005986,
        "accuracy": 0.00998,
        "main_score": 0.005986,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.253508,
        "recall": 0.30672,
        "f1": 0.266184,
        "accuracy": 0.30672,
        "main_score": 0.266184,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000715,
        "recall": 0.003327,
        "f1": 0.000763,
        "accuracy": 0.003327,
        "main_score": 0.000763,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.418898,
        "recall": 0.477046,
        "f1": 0.433668,
        "accuracy": 0.477046,
        "main_score": 0.433668,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00092,
        "recall": 0.003327,
        "f1": 0.001062,
        "accuracy": 0.003327,
        "main_score": 0.001062,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003204,
        "recall": 0.008649,
        "f1": 0.003838,
        "accuracy": 0.008649,
        "main_score": 0.003838,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.192772,
        "recall": 0.230206,
        "f1": 0.201531,
        "accuracy": 0.230206,
        "main_score": 0.201531,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001447,
        "recall": 0.005323,
        "f1": 0.001772,
        "accuracy": 0.005323,
        "main_score": 0.001772,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.335716,
        "recall": 0.391883,
        "f1": 0.349394,
        "accuracy": 0.391883,
        "main_score": 0.349394,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004883,
        "recall": 0.00998,
        "f1": 0.005353,
        "accuracy": 0.00998,
        "main_score": 0.005353,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004856,
        "recall": 0.009315,
        "f1": 0.005347,
        "accuracy": 0.009315,
        "main_score": 0.005347,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002548,
        "recall": 0.007319,
        "f1": 0.003047,
        "accuracy": 0.007319,
        "main_score": 0.003047,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 1342.8992455005646,
  "kg_co2_emissions": null
}