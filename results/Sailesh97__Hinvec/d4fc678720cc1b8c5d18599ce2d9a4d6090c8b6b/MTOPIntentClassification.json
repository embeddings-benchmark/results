{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "task_name": "MTOPIntentClassification",
  "mteb_version": "1.38.30",
  "scores": {
    "validation": [
      {
        "accuracy": 0.69334,
        "f1": 0.429968,
        "f1_weighted": 0.730282,
        "scores_per_experiment": [
          {
            "accuracy": 0.685388,
            "f1": 0.433016,
            "f1_weighted": 0.71967
          },
          {
            "accuracy": 0.705765,
            "f1": 0.431352,
            "f1_weighted": 0.741774
          },
          {
            "accuracy": 0.679423,
            "f1": 0.430065,
            "f1_weighted": 0.720771
          },
          {
            "accuracy": 0.699304,
            "f1": 0.432123,
            "f1_weighted": 0.734553
          },
          {
            "accuracy": 0.692843,
            "f1": 0.439862,
            "f1_weighted": 0.733449
          },
          {
            "accuracy": 0.709245,
            "f1": 0.433505,
            "f1_weighted": 0.741758
          },
          {
            "accuracy": 0.687376,
            "f1": 0.423519,
            "f1_weighted": 0.724933
          },
          {
            "accuracy": 0.711233,
            "f1": 0.431096,
            "f1_weighted": 0.750194
          },
          {
            "accuracy": 0.670974,
            "f1": 0.404929,
            "f1_weighted": 0.705261
          },
          {
            "accuracy": 0.691849,
            "f1": 0.440214,
            "f1_weighted": 0.730457
          }
        ],
        "main_score": 0.69334,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.68849,
        "f1": 0.45109,
        "f1_weighted": 0.722504,
        "scores_per_experiment": [
          {
            "accuracy": 0.685909,
            "f1": 0.462259,
            "f1_weighted": 0.719985
          },
          {
            "accuracy": 0.683041,
            "f1": 0.451782,
            "f1_weighted": 0.718594
          },
          {
            "accuracy": 0.681606,
            "f1": 0.447911,
            "f1_weighted": 0.718963
          },
          {
            "accuracy": 0.706705,
            "f1": 0.449041,
            "f1_weighted": 0.742514
          },
          {
            "accuracy": 0.669416,
            "f1": 0.458844,
            "f1_weighted": 0.706249
          },
          {
            "accuracy": 0.713159,
            "f1": 0.45964,
            "f1_weighted": 0.742509
          },
          {
            "accuracy": 0.668698,
            "f1": 0.435953,
            "f1_weighted": 0.706381
          },
          {
            "accuracy": 0.709573,
            "f1": 0.467978,
            "f1_weighted": 0.742277
          },
          {
            "accuracy": 0.691287,
            "f1": 0.445883,
            "f1_weighted": 0.721344
          },
          {
            "accuracy": 0.675511,
            "f1": 0.431606,
            "f1_weighted": 0.70622
          }
        ],
        "main_score": 0.68849,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 280.5332052707672,
  "kg_co2_emissions": null
}