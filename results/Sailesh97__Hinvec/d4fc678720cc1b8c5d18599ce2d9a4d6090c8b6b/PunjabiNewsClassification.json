{
  "dataset_revision": "cec3923e16519efe51d535497e711932b8f1dc44",
  "task_name": "PunjabiNewsClassification",
  "mteb_version": "1.38.30",
  "scores": {
    "test": [
      {
        "accuracy": 0.607006,
        "f1": 0.52947,
        "f1_weighted": 0.655174,
        "ap": 0.213219,
        "ap_weighted": 0.213219,
        "scores_per_experiment": [
          {
            "accuracy": 0.687898,
            "f1": 0.570823,
            "f1_weighted": 0.720736,
            "ap": 0.215456,
            "ap_weighted": 0.215456
          },
          {
            "accuracy": 0.611465,
            "f1": 0.554827,
            "f1_weighted": 0.661023,
            "ap": 0.243345,
            "ap_weighted": 0.243345
          },
          {
            "accuracy": 0.656051,
            "f1": 0.579464,
            "f1_weighted": 0.699488,
            "ap": 0.245667,
            "ap_weighted": 0.245667
          },
          {
            "accuracy": 0.426752,
            "f1": 0.380263,
            "f1_weighted": 0.493781,
            "ap": 0.152109,
            "ap_weighted": 0.152109
          },
          {
            "accuracy": 0.681529,
            "f1": 0.593685,
            "f1_weighted": 0.720035,
            "ap": 0.248969,
            "ap_weighted": 0.248969
          },
          {
            "accuracy": 0.605096,
            "f1": 0.510559,
            "f1_weighted": 0.654419,
            "ap": 0.187641,
            "ap_weighted": 0.187641
          },
          {
            "accuracy": 0.56051,
            "f1": 0.496444,
            "f1_weighted": 0.616567,
            "ap": 0.194976,
            "ap_weighted": 0.194976
          },
          {
            "accuracy": 0.649682,
            "f1": 0.549627,
            "f1_weighted": 0.691596,
            "ap": 0.208687,
            "ap_weighted": 0.208687
          },
          {
            "accuracy": 0.592357,
            "f1": 0.51412,
            "f1_weighted": 0.644515,
            "ap": 0.197326,
            "ap_weighted": 0.197326
          },
          {
            "accuracy": 0.598726,
            "f1": 0.544886,
            "f1_weighted": 0.649575,
            "ap": 0.238017,
            "ap_weighted": 0.238017
          }
        ],
        "main_score": 0.607006,
        "hf_subset": "default",
        "languages": [
          "pan-Guru"
        ]
      }
    ]
  },
  "evaluation_time": 328.4837553501129,
  "kg_co2_emissions": null
}