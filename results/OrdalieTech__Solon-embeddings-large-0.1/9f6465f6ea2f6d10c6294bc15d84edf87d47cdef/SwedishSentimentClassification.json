{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.923877,
        "f1": 0.923813,
        "f1_weighted": 0.923817,
        "ap": 0.888258,
        "ap_weighted": 0.888258,
        "scores_per_experiment": [
          {
            "accuracy": 0.936523,
            "f1": 0.936476,
            "f1_weighted": 0.936481,
            "ap": 0.900272,
            "ap_weighted": 0.900272
          },
          {
            "accuracy": 0.894043,
            "f1": 0.893785,
            "f1_weighted": 0.8938,
            "ap": 0.83961,
            "ap_weighted": 0.83961
          },
          {
            "accuracy": 0.961914,
            "f1": 0.961913,
            "f1_weighted": 0.961913,
            "ap": 0.947925,
            "ap_weighted": 0.947925
          },
          {
            "accuracy": 0.890137,
            "f1": 0.89012,
            "f1_weighted": 0.890116,
            "ap": 0.852614,
            "ap_weighted": 0.852614
          },
          {
            "accuracy": 0.937012,
            "f1": 0.937009,
            "f1_weighted": 0.93701,
            "ap": 0.908531,
            "ap_weighted": 0.908531
          },
          {
            "accuracy": 0.944336,
            "f1": 0.944335,
            "f1_weighted": 0.944335,
            "ap": 0.922254,
            "ap_weighted": 0.922254
          },
          {
            "accuracy": 0.920898,
            "f1": 0.920745,
            "f1_weighted": 0.920756,
            "ap": 0.874561,
            "ap_weighted": 0.874561
          },
          {
            "accuracy": 0.939941,
            "f1": 0.939915,
            "f1_weighted": 0.939919,
            "ap": 0.907087,
            "ap_weighted": 0.907087
          },
          {
            "accuracy": 0.935059,
            "f1": 0.93505,
            "f1_weighted": 0.935053,
            "ap": 0.904063,
            "ap_weighted": 0.904063
          },
          {
            "accuracy": 0.878906,
            "f1": 0.87878,
            "f1_weighted": 0.878792,
            "ap": 0.825663,
            "ap_weighted": 0.825663
          }
        ],
        "main_score": 0.923877,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.918262,
        "f1": 0.918212,
        "f1_weighted": 0.918214,
        "ap": 0.883122,
        "ap_weighted": 0.883122,
        "scores_per_experiment": [
          {
            "accuracy": 0.932617,
            "f1": 0.932594,
            "f1_weighted": 0.932596,
            "ap": 0.897688,
            "ap_weighted": 0.897688
          },
          {
            "accuracy": 0.896973,
            "f1": 0.89675,
            "f1_weighted": 0.89676,
            "ap": 0.843539,
            "ap_weighted": 0.843539
          },
          {
            "accuracy": 0.946289,
            "f1": 0.946279,
            "f1_weighted": 0.946278,
            "ap": 0.928947,
            "ap_weighted": 0.928947
          },
          {
            "accuracy": 0.87793,
            "f1": 0.877892,
            "f1_weighted": 0.877888,
            "ap": 0.838034,
            "ap_weighted": 0.838034
          },
          {
            "accuracy": 0.937988,
            "f1": 0.937986,
            "f1_weighted": 0.937986,
            "ap": 0.91391,
            "ap_weighted": 0.91391
          },
          {
            "accuracy": 0.928223,
            "f1": 0.928202,
            "f1_weighted": 0.928199,
            "ap": 0.905015,
            "ap_weighted": 0.905015
          },
          {
            "accuracy": 0.911133,
            "f1": 0.911035,
            "f1_weighted": 0.911041,
            "ap": 0.864949,
            "ap_weighted": 0.864949
          },
          {
            "accuracy": 0.943848,
            "f1": 0.943835,
            "f1_weighted": 0.943836,
            "ap": 0.914065,
            "ap_weighted": 0.914065
          },
          {
            "accuracy": 0.936035,
            "f1": 0.936032,
            "f1_weighted": 0.936033,
            "ap": 0.906355,
            "ap_weighted": 0.906355
          },
          {
            "accuracy": 0.871582,
            "f1": 0.871514,
            "f1_weighted": 0.87152,
            "ap": 0.818719,
            "ap_weighted": 0.818719
          }
        ],
        "main_score": 0.918262,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 22.495902061462402,
  "kg_co2_emissions": 0.0010559428033739791
}