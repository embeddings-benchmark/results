{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.736031,
        "f1": 0.735309,
        "f1_weighted": 0.735144,
        "scores_per_experiment": [
          {
            "accuracy": 0.772846,
            "f1": 0.773214,
            "f1_weighted": 0.773273
          },
          {
            "accuracy": 0.785901,
            "f1": 0.78498,
            "f1_weighted": 0.786242
          },
          {
            "accuracy": 0.684073,
            "f1": 0.683712,
            "f1_weighted": 0.679991
          },
          {
            "accuracy": 0.697128,
            "f1": 0.687503,
            "f1_weighted": 0.682593
          },
          {
            "accuracy": 0.754569,
            "f1": 0.753836,
            "f1_weighted": 0.755146
          },
          {
            "accuracy": 0.75718,
            "f1": 0.760493,
            "f1_weighted": 0.760425
          },
          {
            "accuracy": 0.751958,
            "f1": 0.754571,
            "f1_weighted": 0.754366
          },
          {
            "accuracy": 0.738903,
            "f1": 0.738135,
            "f1_weighted": 0.739663
          },
          {
            "accuracy": 0.746736,
            "f1": 0.743783,
            "f1_weighted": 0.746001
          },
          {
            "accuracy": 0.671018,
            "f1": 0.672858,
            "f1_weighted": 0.673738
          }
        ],
        "main_score": 0.736031,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.723958,
        "f1": 0.732376,
        "f1_weighted": 0.7243,
        "scores_per_experiment": [
          {
            "accuracy": 0.708333,
            "f1": 0.722569,
            "f1_weighted": 0.71089
          },
          {
            "accuracy": 0.71875,
            "f1": 0.719078,
            "f1_weighted": 0.715998
          },
          {
            "accuracy": 0.729167,
            "f1": 0.741236,
            "f1_weighted": 0.72977
          },
          {
            "accuracy": 0.71875,
            "f1": 0.726618,
            "f1_weighted": 0.710962
          },
          {
            "accuracy": 0.78125,
            "f1": 0.78412,
            "f1_weighted": 0.780646
          },
          {
            "accuracy": 0.760417,
            "f1": 0.77094,
            "f1_weighted": 0.761378
          },
          {
            "accuracy": 0.697917,
            "f1": 0.712101,
            "f1_weighted": 0.702072
          },
          {
            "accuracy": 0.739583,
            "f1": 0.745389,
            "f1_weighted": 0.741776
          },
          {
            "accuracy": 0.739583,
            "f1": 0.743123,
            "f1_weighted": 0.739685
          },
          {
            "accuracy": 0.645833,
            "f1": 0.658589,
            "f1_weighted": 0.649821
          }
        ],
        "main_score": 0.723958,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 16.033677339553833,
  "kg_co2_emissions": 0.0004926633463049966
}