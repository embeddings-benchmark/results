{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "1.34.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.65076,
        "f1": 0.534554,
        "f1_weighted": 0.706865,
        "ap": 0.906717,
        "ap_weighted": 0.906717,
        "scores_per_experiment": [
          {
            "accuracy": 0.677812,
            "f1": 0.572999,
            "f1_weighted": 0.731825,
            "ap": 0.922758,
            "ap_weighted": 0.922758
          },
          {
            "accuracy": 0.720365,
            "f1": 0.582625,
            "f1_weighted": 0.762634,
            "ap": 0.912882,
            "ap_weighted": 0.912882
          },
          {
            "accuracy": 0.68997,
            "f1": 0.546612,
            "f1_weighted": 0.738014,
            "ap": 0.901219,
            "ap_weighted": 0.901219
          },
          {
            "accuracy": 0.632219,
            "f1": 0.525547,
            "f1_weighted": 0.694444,
            "ap": 0.906015,
            "ap_weighted": 0.906015
          },
          {
            "accuracy": 0.671733,
            "f1": 0.568367,
            "f1_weighted": 0.726946,
            "ap": 0.921913,
            "ap_weighted": 0.921913
          },
          {
            "accuracy": 0.641337,
            "f1": 0.495241,
            "f1_weighted": 0.699115,
            "ap": 0.885166,
            "ap_weighted": 0.885166
          },
          {
            "accuracy": 0.519757,
            "f1": 0.465294,
            "f1_weighted": 0.593412,
            "ap": 0.908838,
            "ap_weighted": 0.908838
          },
          {
            "accuracy": 0.574468,
            "f1": 0.491342,
            "f1_weighted": 0.645719,
            "ap": 0.90328,
            "ap_weighted": 0.90328
          },
          {
            "accuracy": 0.677812,
            "f1": 0.528832,
            "f1_weighted": 0.72774,
            "ap": 0.8947,
            "ap_weighted": 0.8947
          },
          {
            "accuracy": 0.702128,
            "f1": 0.56868,
            "f1_weighted": 0.748798,
            "ap": 0.910403,
            "ap_weighted": 0.910403
          }
        ],
        "main_score": 0.65076,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 49.38043189048767,
  "kg_co2_emissions": null
}