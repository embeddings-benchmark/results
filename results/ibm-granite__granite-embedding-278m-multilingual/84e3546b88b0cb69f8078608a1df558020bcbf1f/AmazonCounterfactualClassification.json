{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.24.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.734333,
        "f1": 0.612301,
        "f1_weighted": 0.78409,
        "ap": 0.23347,
        "ap_weighted": 0.23347,
        "scores_per_experiment": [
          {
            "accuracy": 0.793103,
            "f1": 0.663443,
            "f1_weighted": 0.828807,
            "ap": 0.277239,
            "ap_weighted": 0.277239
          },
          {
            "accuracy": 0.685157,
            "f1": 0.571966,
            "f1_weighted": 0.746208,
            "ap": 0.202427,
            "ap_weighted": 0.202427
          },
          {
            "accuracy": 0.705397,
            "f1": 0.590327,
            "f1_weighted": 0.7622,
            "ap": 0.218299,
            "ap_weighted": 0.218299
          },
          {
            "accuracy": 0.681409,
            "f1": 0.559874,
            "f1_weighted": 0.742957,
            "ap": 0.183753,
            "ap_weighted": 0.183753
          },
          {
            "accuracy": 0.730135,
            "f1": 0.610181,
            "f1_weighted": 0.781359,
            "ap": 0.232936,
            "ap_weighted": 0.232936
          },
          {
            "accuracy": 0.775112,
            "f1": 0.64782,
            "f1_weighted": 0.815427,
            "ap": 0.263566,
            "ap_weighted": 0.263566
          },
          {
            "accuracy": 0.726387,
            "f1": 0.603334,
            "f1_weighted": 0.778225,
            "ap": 0.222728,
            "ap_weighted": 0.222728
          },
          {
            "accuracy": 0.764618,
            "f1": 0.63748,
            "f1_weighted": 0.807426,
            "ap": 0.252914,
            "ap_weighted": 0.252914
          },
          {
            "accuracy": 0.701649,
            "f1": 0.590058,
            "f1_weighted": 0.759369,
            "ap": 0.221852,
            "ap_weighted": 0.221852
          },
          {
            "accuracy": 0.78036,
            "f1": 0.648527,
            "f1_weighted": 0.818925,
            "ap": 0.258982,
            "ap_weighted": 0.258982
          }
        ],
        "main_score": 0.734333,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "accuracy": 0.71806,
        "f1": 0.656467,
        "f1_weighted": 0.744815,
        "ap": 0.340457,
        "ap_weighted": 0.340457,
        "scores_per_experiment": [
          {
            "accuracy": 0.71791,
            "f1": 0.658734,
            "f1_weighted": 0.745272,
            "ap": 0.344277,
            "ap_weighted": 0.344277
          },
          {
            "accuracy": 0.735821,
            "f1": 0.678453,
            "f1_weighted": 0.76116,
            "ap": 0.367557,
            "ap_weighted": 0.367557
          },
          {
            "accuracy": 0.677612,
            "f1": 0.626429,
            "f1_weighted": 0.710633,
            "ap": 0.320089,
            "ap_weighted": 0.320089
          },
          {
            "accuracy": 0.713433,
            "f1": 0.654865,
            "f1_weighted": 0.741443,
            "ap": 0.340861,
            "ap_weighted": 0.340861
          },
          {
            "accuracy": 0.732836,
            "f1": 0.666397,
            "f1_weighted": 0.757056,
            "ap": 0.345369,
            "ap_weighted": 0.345369
          },
          {
            "accuracy": 0.691045,
            "f1": 0.634768,
            "f1_weighted": 0.722072,
            "ap": 0.322848,
            "ap_weighted": 0.322848
          },
          {
            "accuracy": 0.774627,
            "f1": 0.701862,
            "f1_weighted": 0.791554,
            "ap": 0.379505,
            "ap_weighted": 0.379505
          },
          {
            "accuracy": 0.71791,
            "f1": 0.652325,
            "f1_weighted": 0.74428,
            "ap": 0.331526,
            "ap_weighted": 0.331526
          },
          {
            "accuracy": 0.726866,
            "f1": 0.663362,
            "f1_weighted": 0.752398,
            "ap": 0.344871,
            "ap_weighted": 0.344871
          },
          {
            "accuracy": 0.692537,
            "f1": 0.627476,
            "f1_weighted": 0.722279,
            "ap": 0.307671,
            "ap_weighted": 0.307671
          }
        ],
        "main_score": 0.71806,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6.094212532043457,
  "kg_co2_emissions": null
}