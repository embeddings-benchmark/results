{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.970244,
        "recall": 0.97994,
        "f1": 0.97342,
        "accuracy": 0.97994,
        "main_score": 0.97342,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.928452,
        "recall": 0.950853,
        "f1": 0.93564,
        "accuracy": 0.950853,
        "main_score": 0.93564,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.996991,
        "recall": 0.997994,
        "f1": 0.997325,
        "accuracy": 0.997994,
        "main_score": 0.997325,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98228,
        "recall": 0.987964,
        "f1": 0.984119,
        "accuracy": 0.987964,
        "main_score": 0.984119,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.992477,
        "recall": 0.994985,
        "f1": 0.993313,
        "accuracy": 0.994985,
        "main_score": 0.993313,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.985456,
        "recall": 0.98997,
        "f1": 0.986961,
        "accuracy": 0.98997,
        "main_score": 0.986961,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.989468,
        "recall": 0.992979,
        "f1": 0.990639,
        "accuracy": 0.992979,
        "main_score": 0.990639,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98345,
        "recall": 0.988967,
        "f1": 0.985289,
        "accuracy": 0.988967,
        "main_score": 0.985289,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.958793,
        "recall": 0.970913,
        "f1": 0.962454,
        "accuracy": 0.970913,
        "main_score": 0.962454,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.954029,
        "recall": 0.968907,
        "f1": 0.958877,
        "accuracy": 0.968907,
        "main_score": 0.958877,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.986459,
        "recall": 0.990973,
        "f1": 0.987964,
        "accuracy": 0.990973,
        "main_score": 0.987964,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.966065,
        "recall": 0.976931,
        "f1": 0.969575,
        "accuracy": 0.976931,
        "main_score": 0.969575,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.992477,
        "recall": 0.994985,
        "f1": 0.993313,
        "accuracy": 0.994985,
        "main_score": 0.993313,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.965764,
        "recall": 0.975928,
        "f1": 0.968907,
        "accuracy": 0.975928,
        "main_score": 0.968907,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.979773,
        "recall": 0.985958,
        "f1": 0.981779,
        "accuracy": 0.985958,
        "main_score": 0.981779,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.947676,
        "recall": 0.963892,
        "f1": 0.952859,
        "accuracy": 0.963892,
        "main_score": 0.952859,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.976596,
        "recall": 0.983952,
        "f1": 0.978937,
        "accuracy": 0.983952,
        "main_score": 0.978937,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.96991,
        "recall": 0.97994,
        "f1": 0.973253,
        "accuracy": 0.97994,
        "main_score": 0.973253,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.295314,
        "recall": 0.364092,
        "f1": 0.309693,
        "accuracy": 0.364092,
        "main_score": 0.309693,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.337288,
        "recall": 0.458375,
        "f1": 0.367633,
        "accuracy": 0.458375,
        "main_score": 0.367633,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.88875,
        "recall": 0.921765,
        "f1": 0.899264,
        "accuracy": 0.921765,
        "main_score": 0.899264,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.846038,
        "recall": 0.892678,
        "f1": 0.860835,
        "accuracy": 0.892678,
        "main_score": 0.860835,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.980943,
        "recall": 0.986961,
        "f1": 0.982949,
        "accuracy": 0.986961,
        "main_score": 0.982949,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.965229,
        "recall": 0.975928,
        "f1": 0.96874,
        "accuracy": 0.975928,
        "main_score": 0.96874,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.969575,
        "recall": 0.978937,
        "f1": 0.972584,
        "accuracy": 0.978937,
        "main_score": 0.972584,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.956703,
        "recall": 0.970913,
        "f1": 0.961384,
        "accuracy": 0.970913,
        "main_score": 0.961384,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.987964,
        "recall": 0.991976,
        "f1": 0.989301,
        "accuracy": 0.991976,
        "main_score": 0.989301,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.975928,
        "recall": 0.983952,
        "f1": 0.978602,
        "accuracy": 0.983952,
        "main_score": 0.978602,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.832765,
        "recall": 0.877633,
        "f1": 0.846174,
        "accuracy": 0.877633,
        "main_score": 0.846174,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.779789,
        "recall": 0.843531,
        "f1": 0.799202,
        "accuracy": 0.843531,
        "main_score": 0.799202,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.81217,
        "recall": 0.865597,
        "f1": 0.828586,
        "accuracy": 0.865597,
        "main_score": 0.828586,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.779957,
        "recall": 0.845537,
        "f1": 0.800635,
        "accuracy": 0.845537,
        "main_score": 0.800635,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.966734,
        "recall": 0.976931,
        "f1": 0.970077,
        "accuracy": 0.976931,
        "main_score": 0.970077,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.932798,
        "recall": 0.953862,
        "f1": 0.939652,
        "accuracy": 0.953862,
        "main_score": 0.939652,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.959295,
        "recall": 0.971916,
        "f1": 0.96329,
        "accuracy": 0.971916,
        "main_score": 0.96329,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.913407,
        "recall": 0.941825,
        "f1": 0.922768,
        "accuracy": 0.941825,
        "main_score": 0.922768,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.074324,
        "recall": 0.091274,
        "f1": 0.07802,
        "accuracy": 0.091274,
        "main_score": 0.07802,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.089719,
        "recall": 0.159478,
        "f1": 0.103132,
        "accuracy": 0.159478,
        "main_score": 0.103132,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.099764,
        "recall": 0.139418,
        "f1": 0.106695,
        "accuracy": 0.139418,
        "main_score": 0.106695,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.117834,
        "recall": 0.212638,
        "f1": 0.13924,
        "accuracy": 0.212638,
        "main_score": 0.13924,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.933801,
        "recall": 0.953862,
        "f1": 0.940154,
        "accuracy": 0.953862,
        "main_score": 0.940154,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.896556,
        "recall": 0.927783,
        "f1": 0.906352,
        "accuracy": 0.927783,
        "main_score": 0.906352,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.640001,
        "recall": 0.717151,
        "f1": 0.66123,
        "accuracy": 0.717151,
        "main_score": 0.66123,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.611862,
        "recall": 0.711133,
        "f1": 0.641279,
        "accuracy": 0.711133,
        "main_score": 0.641279,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.92001,
        "recall": 0.944835,
        "f1": 0.92785,
        "accuracy": 0.944835,
        "main_score": 0.92785,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881344,
        "recall": 0.91675,
        "f1": 0.892511,
        "accuracy": 0.91675,
        "main_score": 0.892511,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.916249,
        "recall": 0.939819,
        "f1": 0.923322,
        "accuracy": 0.939819,
        "main_score": 0.923322,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.884403,
        "recall": 0.919759,
        "f1": 0.895553,
        "accuracy": 0.919759,
        "main_score": 0.895553,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.930993,
        "recall": 0.951856,
        "f1": 0.937479,
        "accuracy": 0.951856,
        "main_score": 0.937479,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.889335,
        "recall": 0.922768,
        "f1": 0.899833,
        "accuracy": 0.922768,
        "main_score": 0.899833,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.083086,
        "recall": 0.107322,
        "f1": 0.086456,
        "accuracy": 0.107322,
        "main_score": 0.086456,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.10065,
        "recall": 0.17653,
        "f1": 0.116348,
        "accuracy": 0.17653,
        "main_score": 0.116348,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.93564,
        "recall": 0.955868,
        "f1": 0.94216,
        "accuracy": 0.955868,
        "main_score": 0.94216,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.885406,
        "recall": 0.920762,
        "f1": 0.89659,
        "accuracy": 0.920762,
        "main_score": 0.89659,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.947593,
        "recall": 0.963892,
        "f1": 0.952758,
        "accuracy": 0.963892,
        "main_score": 0.952758,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.893096,
        "recall": 0.92678,
        "f1": 0.903945,
        "accuracy": 0.92678,
        "main_score": 0.903945,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.013446,
        "recall": 0.018054,
        "f1": 0.014013,
        "accuracy": 0.018054,
        "main_score": 0.014013,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004034,
        "recall": 0.024072,
        "f1": 0.005423,
        "accuracy": 0.024072,
        "main_score": 0.005423,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.947299,
        "recall": 0.964427,
        "f1": 0.952899,
        "accuracy": 0.964427,
        "main_score": 0.952899,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.93997,
        "recall": 0.959486,
        "f1": 0.946377,
        "accuracy": 0.959486,
        "main_score": 0.946377,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.991107,
        "recall": 0.994071,
        "f1": 0.992095,
        "accuracy": 0.994071,
        "main_score": 0.992095,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.979249,
        "recall": 0.986166,
        "f1": 0.981555,
        "accuracy": 0.986166,
        "main_score": 0.981555,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994071,
        "recall": 0.996047,
        "f1": 0.99473,
        "accuracy": 0.996047,
        "main_score": 0.99473,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.979249,
        "recall": 0.986166,
        "f1": 0.981555,
        "accuracy": 0.986166,
        "main_score": 0.981555,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.986989,
        "recall": 0.991107,
        "f1": 0.988307,
        "accuracy": 0.991107,
        "main_score": 0.988307,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.970356,
        "recall": 0.980237,
        "f1": 0.97365,
        "accuracy": 0.980237,
        "main_score": 0.97365,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.96031,
        "recall": 0.972332,
        "f1": 0.964065,
        "accuracy": 0.972332,
        "main_score": 0.964065,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.962945,
        "recall": 0.975296,
        "f1": 0.967062,
        "accuracy": 0.975296,
        "main_score": 0.967062,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.986989,
        "recall": 0.991107,
        "f1": 0.988307,
        "accuracy": 0.991107,
        "main_score": 0.988307,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972497,
        "recall": 0.981225,
        "f1": 0.975296,
        "accuracy": 0.981225,
        "main_score": 0.975296,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.983037,
        "recall": 0.988142,
        "f1": 0.984684,
        "accuracy": 0.988142,
        "main_score": 0.984684,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.970685,
        "recall": 0.980237,
        "f1": 0.973814,
        "accuracy": 0.980237,
        "main_score": 0.973814,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.978096,
        "recall": 0.985178,
        "f1": 0.980402,
        "accuracy": 0.985178,
        "main_score": 0.980402,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.957016,
        "recall": 0.971344,
        "f1": 0.961792,
        "accuracy": 0.971344,
        "main_score": 0.961792,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.985178,
        "f1": 0.980237,
        "accuracy": 0.985178,
        "main_score": 0.980237,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978096,
        "recall": 0.985178,
        "f1": 0.980402,
        "accuracy": 0.985178,
        "main_score": 0.980402,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.295479,
        "recall": 0.364625,
        "f1": 0.311381,
        "accuracy": 0.364625,
        "main_score": 0.311381,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.317556,
        "recall": 0.434783,
        "f1": 0.346704,
        "accuracy": 0.434783,
        "main_score": 0.346704,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.861125,
        "recall": 0.899209,
        "f1": 0.872622,
        "accuracy": 0.899209,
        "main_score": 0.872622,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.86166,
        "recall": 0.903162,
        "f1": 0.874638,
        "accuracy": 0.903162,
        "main_score": 0.874638,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.976779,
        "recall": 0.98419,
        "f1": 0.979249,
        "accuracy": 0.98419,
        "main_score": 0.979249,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972332,
        "recall": 0.981225,
        "f1": 0.975296,
        "accuracy": 0.981225,
        "main_score": 0.975296,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.959898,
        "recall": 0.972332,
        "f1": 0.963834,
        "accuracy": 0.972332,
        "main_score": 0.963834,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.953557,
        "recall": 0.968379,
        "f1": 0.958333,
        "accuracy": 0.968379,
        "main_score": 0.958333,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.970603,
        "recall": 0.979249,
        "f1": 0.973221,
        "accuracy": 0.979249,
        "main_score": 0.973221,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.985178,
        "f1": 0.980237,
        "accuracy": 0.985178,
        "main_score": 0.980237,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.861495,
        "recall": 0.900198,
        "f1": 0.87301,
        "accuracy": 0.900198,
        "main_score": 0.87301,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.800922,
        "recall": 0.857708,
        "f1": 0.818234,
        "accuracy": 0.857708,
        "main_score": 0.818234,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.796476,
        "recall": 0.854743,
        "f1": 0.814248,
        "accuracy": 0.854743,
        "main_score": 0.814248,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.773995,
        "recall": 0.839921,
        "f1": 0.794466,
        "accuracy": 0.839921,
        "main_score": 0.794466,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.960968,
        "recall": 0.97332,
        "f1": 0.965086,
        "accuracy": 0.97332,
        "main_score": 0.965086,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.958169,
        "recall": 0.970356,
        "f1": 0.962121,
        "accuracy": 0.970356,
        "main_score": 0.962121,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.943182,
        "recall": 0.961462,
        "f1": 0.949111,
        "accuracy": 0.961462,
        "main_score": 0.949111,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.932724,
        "recall": 0.953557,
        "f1": 0.93946,
        "accuracy": 0.953557,
        "main_score": 0.93946,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.081419,
        "recall": 0.105731,
        "f1": 0.086932,
        "accuracy": 0.105731,
        "main_score": 0.086932,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.086124,
        "recall": 0.149209,
        "f1": 0.097836,
        "accuracy": 0.149209,
        "main_score": 0.097836,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.10844,
        "recall": 0.134387,
        "f1": 0.113034,
        "accuracy": 0.134387,
        "main_score": 0.113034,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.123371,
        "recall": 0.210474,
        "f1": 0.141759,
        "accuracy": 0.210474,
        "main_score": 0.141759,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.91996,
        "recall": 0.943676,
        "f1": 0.927324,
        "accuracy": 0.943676,
        "main_score": 0.927324,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.919713,
        "recall": 0.944664,
        "f1": 0.927602,
        "accuracy": 0.944664,
        "main_score": 0.927602,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.622947,
        "recall": 0.705534,
        "f1": 0.645587,
        "accuracy": 0.705534,
        "main_score": 0.645587,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.62971,
        "recall": 0.727273,
        "f1": 0.659256,
        "accuracy": 0.727273,
        "main_score": 0.659256,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.924242,
        "recall": 0.947628,
        "f1": 0.931785,
        "accuracy": 0.947628,
        "main_score": 0.931785,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.905797,
        "recall": 0.935771,
        "f1": 0.915514,
        "accuracy": 0.935771,
        "main_score": 0.915514,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.903649,
        "recall": 0.929842,
        "f1": 0.91138,
        "accuracy": 0.929842,
        "main_score": 0.91138,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.901515,
        "recall": 0.932806,
        "f1": 0.911726,
        "accuracy": 0.932806,
        "main_score": 0.911726,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.915926,
        "recall": 0.940711,
        "f1": 0.92357,
        "accuracy": 0.940711,
        "main_score": 0.92357,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.921607,
        "recall": 0.94664,
        "f1": 0.929842,
        "accuracy": 0.94664,
        "main_score": 0.929842,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.079665,
        "recall": 0.114625,
        "f1": 0.085925,
        "accuracy": 0.114625,
        "main_score": 0.085925,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.08834,
        "recall": 0.166996,
        "f1": 0.103463,
        "accuracy": 0.166996,
        "main_score": 0.103463,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.932477,
        "recall": 0.951581,
        "f1": 0.938194,
        "accuracy": 0.951581,
        "main_score": 0.938194,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.910738,
        "recall": 0.938735,
        "f1": 0.919796,
        "accuracy": 0.938735,
        "main_score": 0.919796,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.936924,
        "recall": 0.956522,
        "f1": 0.943149,
        "accuracy": 0.956522,
        "main_score": 0.943149,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.918314,
        "recall": 0.944664,
        "f1": 0.927042,
        "accuracy": 0.944664,
        "main_score": 0.927042,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.014448,
        "recall": 0.021739,
        "f1": 0.015381,
        "accuracy": 0.021739,
        "main_score": 0.015381,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005568,
        "recall": 0.031621,
        "f1": 0.008112,
        "accuracy": 0.031621,
        "main_score": 0.008112,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 83.4014847278595,
  "kg_co2_emissions": 0.005515747463632342
}