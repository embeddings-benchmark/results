{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.603662,
        "f1": 0.596792,
        "f1_weighted": 0.602701,
        "ap": 0.485622,
        "ap_weighted": 0.485622,
        "scores_per_experiment": [
          {
            "accuracy": 0.672852,
            "f1": 0.640078,
            "f1_weighted": 0.657578,
            "ap": 0.528287,
            "ap_weighted": 0.528287
          },
          {
            "accuracy": 0.538574,
            "f1": 0.538019,
            "f1_weighted": 0.535438,
            "ap": 0.451168,
            "ap_weighted": 0.451168
          },
          {
            "accuracy": 0.578125,
            "f1": 0.565877,
            "f1_weighted": 0.577627,
            "ap": 0.457379,
            "ap_weighted": 0.457379
          },
          {
            "accuracy": 0.618652,
            "f1": 0.618055,
            "f1_weighted": 0.620489,
            "ap": 0.499351,
            "ap_weighted": 0.499351
          },
          {
            "accuracy": 0.637207,
            "f1": 0.635224,
            "f1_weighted": 0.639558,
            "ap": 0.511084,
            "ap_weighted": 0.511084
          },
          {
            "accuracy": 0.556152,
            "f1": 0.548242,
            "f1_weighted": 0.557874,
            "ap": 0.44638,
            "ap_weighted": 0.44638
          },
          {
            "accuracy": 0.638672,
            "f1": 0.635122,
            "f1_weighted": 0.640921,
            "ap": 0.510109,
            "ap_weighted": 0.510109
          },
          {
            "accuracy": 0.615234,
            "f1": 0.614858,
            "f1_weighted": 0.612919,
            "ap": 0.503358,
            "ap_weighted": 0.503358
          },
          {
            "accuracy": 0.623047,
            "f1": 0.615334,
            "f1_weighted": 0.624111,
            "ap": 0.493443,
            "ap_weighted": 0.493443
          },
          {
            "accuracy": 0.558105,
            "f1": 0.557112,
            "f1_weighted": 0.560492,
            "ap": 0.455663,
            "ap_weighted": 0.455663
          }
        ],
        "main_score": 0.596792,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.406017303466797,
  "kg_co2_emissions": 0.0004229542814757936
}