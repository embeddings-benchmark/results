{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.546833,
        "f1": 0.544607,
        "f1_weighted": 0.544607,
        "ap": 0.526363,
        "ap_weighted": 0.526363,
        "scores_per_experiment": [
          {
            "accuracy": 0.5425,
            "f1": 0.542016,
            "f1_weighted": 0.542016,
            "ap": 0.522946,
            "ap_weighted": 0.522946
          },
          {
            "accuracy": 0.515833,
            "f1": 0.515712,
            "f1_weighted": 0.515712,
            "ap": 0.508176,
            "ap_weighted": 0.508176
          },
          {
            "accuracy": 0.581667,
            "f1": 0.581103,
            "f1_weighted": 0.581103,
            "ap": 0.547047,
            "ap_weighted": 0.547047
          },
          {
            "accuracy": 0.571667,
            "f1": 0.557048,
            "f1_weighted": 0.557048,
            "ap": 0.539601,
            "ap_weighted": 0.539601
          },
          {
            "accuracy": 0.576667,
            "f1": 0.575675,
            "f1_weighted": 0.575675,
            "ap": 0.543693,
            "ap_weighted": 0.543693
          },
          {
            "accuracy": 0.491667,
            "f1": 0.491665,
            "f1_weighted": 0.491665,
            "ap": 0.495903,
            "ap_weighted": 0.495903
          },
          {
            "accuracy": 0.529167,
            "f1": 0.529093,
            "f1_weighted": 0.529093,
            "ap": 0.515456,
            "ap_weighted": 0.515456
          },
          {
            "accuracy": 0.515833,
            "f1": 0.510522,
            "f1_weighted": 0.510522,
            "ap": 0.508124,
            "ap_weighted": 0.508124
          },
          {
            "accuracy": 0.5925,
            "f1": 0.592452,
            "f1_weighted": 0.592452,
            "ap": 0.554625,
            "ap_weighted": 0.554625
          },
          {
            "accuracy": 0.550833,
            "f1": 0.550781,
            "f1_weighted": 0.550781,
            "ap": 0.528058,
            "ap_weighted": 0.528058
          }
        ],
        "main_score": 0.546833,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.54925,
        "f1": 0.547389,
        "f1_weighted": 0.547389,
        "ap": 0.52872,
        "ap_weighted": 0.52872,
        "scores_per_experiment": [
          {
            "accuracy": 0.514167,
            "f1": 0.513921,
            "f1_weighted": 0.513921,
            "ap": 0.507275,
            "ap_weighted": 0.507275
          },
          {
            "accuracy": 0.5075,
            "f1": 0.507349,
            "f1_weighted": 0.507349,
            "ap": 0.503808,
            "ap_weighted": 0.503808
          },
          {
            "accuracy": 0.580833,
            "f1": 0.580679,
            "f1_weighted": 0.580679,
            "ap": 0.546709,
            "ap_weighted": 0.546709
          },
          {
            "accuracy": 0.611667,
            "f1": 0.600571,
            "f1_weighted": 0.600571,
            "ap": 0.565185,
            "ap_weighted": 0.565185
          },
          {
            "accuracy": 0.601667,
            "f1": 0.601533,
            "f1_weighted": 0.601533,
            "ap": 0.560804,
            "ap_weighted": 0.560804
          },
          {
            "accuracy": 0.503333,
            "f1": 0.503222,
            "f1_weighted": 0.503222,
            "ap": 0.501678,
            "ap_weighted": 0.501678
          },
          {
            "accuracy": 0.5275,
            "f1": 0.527445,
            "f1_weighted": 0.527445,
            "ap": 0.51449,
            "ap_weighted": 0.51449
          },
          {
            "accuracy": 0.486667,
            "f1": 0.480379,
            "f1_weighted": 0.480379,
            "ap": 0.493479,
            "ap_weighted": 0.493479
          },
          {
            "accuracy": 0.610833,
            "f1": 0.610636,
            "f1_weighted": 0.610636,
            "ap": 0.567172,
            "ap_weighted": 0.567172
          },
          {
            "accuracy": 0.548333,
            "f1": 0.548153,
            "f1_weighted": 0.548153,
            "ap": 0.5266,
            "ap_weighted": 0.5266
          }
        ],
        "main_score": 0.54925,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.658306360244751,
  "kg_co2_emissions": 0.0004818324356792048
}