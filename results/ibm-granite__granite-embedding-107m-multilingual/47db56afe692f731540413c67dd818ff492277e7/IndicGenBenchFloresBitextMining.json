{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.908007,
        "recall": 0.935807,
        "f1": 0.916817,
        "accuracy": 0.935807,
        "main_score": 0.916817,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.875878,
        "recall": 0.912738,
        "f1": 0.887348,
        "accuracy": 0.912738,
        "main_score": 0.887348,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.892539,
        "recall": 0.922768,
        "f1": 0.901805,
        "accuracy": 0.922768,
        "main_score": 0.901805,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.891759,
        "recall": 0.925777,
        "f1": 0.902775,
        "accuracy": 0.925777,
        "main_score": 0.902775,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.986459,
        "recall": 0.990973,
        "f1": 0.987964,
        "accuracy": 0.990973,
        "main_score": 0.987964,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976429,
        "recall": 0.983952,
        "f1": 0.978937,
        "accuracy": 0.983952,
        "main_score": 0.978937,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.903019,
        "recall": 0.929789,
        "f1": 0.91127,
        "accuracy": 0.929789,
        "main_score": 0.91127,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.89226,
        "recall": 0.925777,
        "f1": 0.903109,
        "accuracy": 0.925777,
        "main_score": 0.903109,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.899281,
        "recall": 0.925777,
        "f1": 0.907128,
        "accuracy": 0.925777,
        "main_score": 0.907128,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.909562,
        "recall": 0.938816,
        "f1": 0.919091,
        "accuracy": 0.938816,
        "main_score": 0.919091,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.925276,
        "recall": 0.947844,
        "f1": 0.932431,
        "accuracy": 0.947844,
        "main_score": 0.932431,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.907389,
        "recall": 0.935807,
        "f1": 0.916382,
        "accuracy": 0.935807,
        "main_score": 0.916382,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.938733,
        "recall": 0.956871,
        "f1": 0.944366,
        "accuracy": 0.956871,
        "main_score": 0.944366,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.946172,
        "recall": 0.963892,
        "f1": 0.952023,
        "accuracy": 0.963892,
        "main_score": 0.952023,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.923771,
        "recall": 0.946841,
        "f1": 0.931127,
        "accuracy": 0.946841,
        "main_score": 0.931127,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.900284,
        "recall": 0.931795,
        "f1": 0.910465,
        "accuracy": 0.931795,
        "main_score": 0.910465,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.925443,
        "recall": 0.947844,
        "f1": 0.932583,
        "accuracy": 0.947844,
        "main_score": 0.932583,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.913073,
        "recall": 0.939819,
        "f1": 0.921765,
        "accuracy": 0.939819,
        "main_score": 0.921765,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.275346,
        "recall": 0.332999,
        "f1": 0.287527,
        "accuracy": 0.332999,
        "main_score": 0.287527,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.279001,
        "recall": 0.394183,
        "f1": 0.306243,
        "accuracy": 0.394183,
        "main_score": 0.306243,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.83272,
        "recall": 0.872618,
        "f1": 0.844486,
        "accuracy": 0.872618,
        "main_score": 0.844486,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.802383,
        "recall": 0.858576,
        "f1": 0.819843,
        "accuracy": 0.858576,
        "main_score": 0.819843,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.956035,
        "recall": 0.96991,
        "f1": 0.960548,
        "accuracy": 0.96991,
        "main_score": 0.960548,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.936476,
        "recall": 0.955868,
        "f1": 0.942828,
        "accuracy": 0.955868,
        "main_score": 0.942828,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.678493,
        "recall": 0.742227,
        "f1": 0.695161,
        "accuracy": 0.742227,
        "main_score": 0.695161,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.771264,
        "recall": 0.83651,
        "f1": 0.791408,
        "accuracy": 0.83651,
        "main_score": 0.791408,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.751797,
        "recall": 0.80341,
        "f1": 0.766209,
        "accuracy": 0.80341,
        "main_score": 0.766209,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.803494,
        "recall": 0.859579,
        "f1": 0.820796,
        "accuracy": 0.859579,
        "main_score": 0.820796,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.658554,
        "recall": 0.722166,
        "f1": 0.67593,
        "accuracy": 0.722166,
        "main_score": 0.67593,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.622902,
        "recall": 0.722166,
        "f1": 0.651813,
        "accuracy": 0.722166,
        "main_score": 0.651813,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.748508,
        "recall": 0.810431,
        "f1": 0.766476,
        "accuracy": 0.810431,
        "main_score": 0.766476,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.72663,
        "recall": 0.802407,
        "f1": 0.749716,
        "accuracy": 0.802407,
        "main_score": 0.749716,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.947008,
        "recall": 0.962889,
        "f1": 0.952142,
        "accuracy": 0.962889,
        "main_score": 0.952142,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.942996,
        "recall": 0.960883,
        "f1": 0.948847,
        "accuracy": 0.960883,
        "main_score": 0.948847,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.929097,
        "recall": 0.94985,
        "f1": 0.935557,
        "accuracy": 0.94985,
        "main_score": 0.935557,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.896021,
        "recall": 0.928786,
        "f1": 0.906553,
        "accuracy": 0.928786,
        "main_score": 0.906553,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.051226,
        "recall": 0.064193,
        "f1": 0.053978,
        "accuracy": 0.064193,
        "main_score": 0.053978,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.079078,
        "recall": 0.158475,
        "f1": 0.093138,
        "accuracy": 0.158475,
        "main_score": 0.093138,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.096685,
        "recall": 0.1334,
        "f1": 0.102929,
        "accuracy": 0.1334,
        "main_score": 0.102929,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.111001,
        "recall": 0.193581,
        "f1": 0.129399,
        "accuracy": 0.193581,
        "main_score": 0.129399,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.910667,
        "recall": 0.933801,
        "f1": 0.91751,
        "accuracy": 0.933801,
        "main_score": 0.91751,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.895888,
        "recall": 0.927783,
        "f1": 0.906051,
        "accuracy": 0.927783,
        "main_score": 0.906051,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.471732,
        "recall": 0.558676,
        "f1": 0.49467,
        "accuracy": 0.558676,
        "main_score": 0.49467,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.488333,
        "recall": 0.604814,
        "f1": 0.521323,
        "accuracy": 0.604814,
        "main_score": 0.521323,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.900244,
        "recall": 0.927783,
        "f1": 0.908442,
        "accuracy": 0.927783,
        "main_score": 0.908442,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.867603,
        "recall": 0.907723,
        "f1": 0.880274,
        "accuracy": 0.907723,
        "main_score": 0.880274,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.877881,
        "recall": 0.907723,
        "f1": 0.886629,
        "accuracy": 0.907723,
        "main_score": 0.886629,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.841642,
        "recall": 0.887663,
        "f1": 0.855887,
        "accuracy": 0.887663,
        "main_score": 0.855887,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.917467,
        "recall": 0.937813,
        "f1": 0.923487,
        "accuracy": 0.937813,
        "main_score": 0.923487,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.875794,
        "recall": 0.914744,
        "f1": 0.888332,
        "accuracy": 0.914744,
        "main_score": 0.888332,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.066134,
        "recall": 0.088265,
        "f1": 0.068807,
        "accuracy": 0.088265,
        "main_score": 0.068807,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.091223,
        "recall": 0.167503,
        "f1": 0.106421,
        "accuracy": 0.167503,
        "main_score": 0.106421,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.910593,
        "recall": 0.934804,
        "f1": 0.917973,
        "accuracy": 0.934804,
        "main_score": 0.917973,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.871113,
        "recall": 0.911735,
        "f1": 0.88432,
        "accuracy": 0.911735,
        "main_score": 0.88432,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.914928,
        "recall": 0.937813,
        "f1": 0.921847,
        "accuracy": 0.937813,
        "main_score": 0.921847,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.888582,
        "recall": 0.922768,
        "f1": 0.899551,
        "accuracy": 0.922768,
        "main_score": 0.899551,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.011089,
        "recall": 0.013039,
        "f1": 0.011139,
        "accuracy": 0.013039,
        "main_score": 0.011139,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004143,
        "recall": 0.025075,
        "f1": 0.005617,
        "accuracy": 0.025075,
        "main_score": 0.005617,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.918067,
        "recall": 0.943676,
        "f1": 0.926285,
        "accuracy": 0.943676,
        "main_score": 0.926285,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881094,
        "recall": 0.918972,
        "f1": 0.893281,
        "accuracy": 0.918972,
        "main_score": 0.893281,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.873659,
        "recall": 0.910079,
        "f1": 0.884733,
        "accuracy": 0.910079,
        "main_score": 0.884733,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.908926,
        "recall": 0.936759,
        "f1": 0.917787,
        "accuracy": 0.936759,
        "main_score": 0.917787,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.988142,
        "recall": 0.992095,
        "f1": 0.98946,
        "accuracy": 0.992095,
        "main_score": 0.98946,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.969203,
        "recall": 0.979249,
        "f1": 0.972497,
        "accuracy": 0.979249,
        "main_score": 0.972497,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.891996,
        "recall": 0.923913,
        "f1": 0.901812,
        "accuracy": 0.923913,
        "main_score": 0.901812,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.905632,
        "recall": 0.935771,
        "f1": 0.915349,
        "accuracy": 0.935771,
        "main_score": 0.915349,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.876993,
        "recall": 0.912055,
        "f1": 0.887582,
        "accuracy": 0.912055,
        "main_score": 0.887582,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.882658,
        "recall": 0.91996,
        "f1": 0.894829,
        "accuracy": 0.91996,
        "main_score": 0.894829,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.92029,
        "recall": 0.944664,
        "f1": 0.928195,
        "accuracy": 0.944664,
        "main_score": 0.928195,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.905303,
        "recall": 0.935771,
        "f1": 0.915349,
        "accuracy": 0.935771,
        "main_score": 0.915349,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.930995,
        "recall": 0.953557,
        "f1": 0.938406,
        "accuracy": 0.953557,
        "main_score": 0.938406,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.935359,
        "recall": 0.955534,
        "f1": 0.941765,
        "accuracy": 0.955534,
        "main_score": 0.941765,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.931653,
        "recall": 0.953557,
        "f1": 0.938735,
        "accuracy": 0.953557,
        "main_score": 0.938735,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.901927,
        "recall": 0.931818,
        "f1": 0.911298,
        "accuracy": 0.931818,
        "main_score": 0.911298,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.924901,
        "recall": 0.948617,
        "f1": 0.932642,
        "accuracy": 0.948617,
        "main_score": 0.932642,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.893528,
        "recall": 0.924901,
        "f1": 0.903393,
        "accuracy": 0.924901,
        "main_score": 0.903393,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.237174,
        "recall": 0.306324,
        "f1": 0.253729,
        "accuracy": 0.306324,
        "main_score": 0.253729,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.266442,
        "recall": 0.383399,
        "f1": 0.294767,
        "accuracy": 0.383399,
        "main_score": 0.294767,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.839667,
        "recall": 0.882411,
        "f1": 0.852256,
        "accuracy": 0.882411,
        "main_score": 0.852256,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.825511,
        "recall": 0.876482,
        "f1": 0.841436,
        "accuracy": 0.876482,
        "main_score": 0.841436,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.934783,
        "recall": 0.955534,
        "f1": 0.941535,
        "accuracy": 0.955534,
        "main_score": 0.941535,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.916667,
        "recall": 0.943676,
        "f1": 0.92556,
        "accuracy": 0.943676,
        "main_score": 0.92556,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.638679,
        "recall": 0.702569,
        "f1": 0.654693,
        "accuracy": 0.702569,
        "main_score": 0.654693,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.735326,
        "recall": 0.810277,
        "f1": 0.758173,
        "accuracy": 0.810277,
        "main_score": 0.758173,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.690321,
        "recall": 0.755929,
        "f1": 0.70823,
        "accuracy": 0.755929,
        "main_score": 0.70823,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.765053,
        "recall": 0.831028,
        "f1": 0.785112,
        "accuracy": 0.831028,
        "main_score": 0.785112,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.694987,
        "recall": 0.759881,
        "f1": 0.712353,
        "accuracy": 0.759881,
        "main_score": 0.712353,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.680691,
        "recall": 0.767787,
        "f1": 0.706604,
        "accuracy": 0.767787,
        "main_score": 0.706604,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.728937,
        "recall": 0.800395,
        "f1": 0.750156,
        "accuracy": 0.800395,
        "main_score": 0.750156,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.71726,
        "recall": 0.797431,
        "f1": 0.741996,
        "accuracy": 0.797431,
        "main_score": 0.741996,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.945652,
        "recall": 0.961462,
        "f1": 0.950593,
        "accuracy": 0.961462,
        "main_score": 0.950593,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.935441,
        "recall": 0.955534,
        "f1": 0.942029,
        "accuracy": 0.955534,
        "main_score": 0.942029,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.940876,
        "recall": 0.959486,
        "f1": 0.946805,
        "accuracy": 0.959486,
        "main_score": 0.946805,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.914312,
        "recall": 0.940711,
        "f1": 0.922661,
        "accuracy": 0.940711,
        "main_score": 0.922661,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.055888,
        "recall": 0.074111,
        "f1": 0.05985,
        "accuracy": 0.074111,
        "main_score": 0.05985,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.066063,
        "recall": 0.137352,
        "f1": 0.078104,
        "accuracy": 0.137352,
        "main_score": 0.078104,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.08306,
        "recall": 0.106719,
        "f1": 0.087428,
        "accuracy": 0.106719,
        "main_score": 0.087428,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.101161,
        "recall": 0.179842,
        "f1": 0.11709,
        "accuracy": 0.179842,
        "main_score": 0.11709,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.907691,
        "recall": 0.934783,
        "f1": 0.916074,
        "accuracy": 0.934783,
        "main_score": 0.916074,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.899901,
        "recall": 0.93083,
        "f1": 0.909914,
        "accuracy": 0.93083,
        "main_score": 0.909914,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.51215,
        "recall": 0.605731,
        "f1": 0.536898,
        "accuracy": 0.605731,
        "main_score": 0.536898,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.500102,
        "recall": 0.617589,
        "f1": 0.534183,
        "accuracy": 0.617589,
        "main_score": 0.534183,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.909832,
        "recall": 0.937747,
        "f1": 0.918709,
        "accuracy": 0.937747,
        "main_score": 0.918709,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.895669,
        "recall": 0.928854,
        "f1": 0.906357,
        "accuracy": 0.928854,
        "main_score": 0.906357,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.874341,
        "recall": 0.908103,
        "f1": 0.884213,
        "accuracy": 0.908103,
        "main_score": 0.884213,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.859272,
        "recall": 0.902174,
        "f1": 0.87276,
        "accuracy": 0.902174,
        "main_score": 0.87276,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.895275,
        "recall": 0.922925,
        "f1": 0.903647,
        "accuracy": 0.922925,
        "main_score": 0.903647,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881291,
        "recall": 0.917984,
        "f1": 0.892951,
        "accuracy": 0.917984,
        "main_score": 0.892951,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.056513,
        "recall": 0.08498,
        "f1": 0.061611,
        "accuracy": 0.08498,
        "main_score": 0.061611,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.072942,
        "recall": 0.150198,
        "f1": 0.087665,
        "accuracy": 0.150198,
        "main_score": 0.087665,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.908853,
        "recall": 0.934783,
        "f1": 0.916815,
        "accuracy": 0.934783,
        "main_score": 0.916815,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881258,
        "recall": 0.916996,
        "f1": 0.892622,
        "accuracy": 0.916996,
        "main_score": 0.892622,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.930501,
        "recall": 0.951581,
        "f1": 0.937253,
        "accuracy": 0.951581,
        "main_score": 0.937253,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.896657,
        "recall": 0.928854,
        "f1": 0.907016,
        "accuracy": 0.928854,
        "main_score": 0.907016,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.014082,
        "recall": 0.016798,
        "f1": 0.014561,
        "accuracy": 0.016798,
        "main_score": 0.014561,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004594,
        "recall": 0.031621,
        "f1": 0.007059,
        "accuracy": 0.031621,
        "main_score": 0.007059,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 33.88985061645508,
  "kg_co2_emissions": 0.0013825079625936392
}