{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.704639,
        "f1": 0.703623,
        "f1_weighted": 0.703652,
        "ap": 0.646954,
        "ap_weighted": 0.646954,
        "scores_per_experiment": [
          {
            "accuracy": 0.739258,
            "f1": 0.739194,
            "f1_weighted": 0.739206,
            "ap": 0.676559,
            "ap_weighted": 0.676559
          },
          {
            "accuracy": 0.633789,
            "f1": 0.631308,
            "f1_weighted": 0.631397,
            "ap": 0.583558,
            "ap_weighted": 0.583558
          },
          {
            "accuracy": 0.732422,
            "f1": 0.73173,
            "f1_weighted": 0.73169,
            "ap": 0.677979,
            "ap_weighted": 0.677979
          },
          {
            "accuracy": 0.594727,
            "f1": 0.591282,
            "f1_weighted": 0.591392,
            "ap": 0.556231,
            "ap_weighted": 0.556231
          },
          {
            "accuracy": 0.746582,
            "f1": 0.74646,
            "f1_weighted": 0.746443,
            "ap": 0.688432,
            "ap_weighted": 0.688432
          },
          {
            "accuracy": 0.691406,
            "f1": 0.690958,
            "f1_weighted": 0.690992,
            "ap": 0.631113,
            "ap_weighted": 0.631113
          },
          {
            "accuracy": 0.73877,
            "f1": 0.737225,
            "f1_weighted": 0.737284,
            "ap": 0.670061,
            "ap_weighted": 0.670061
          },
          {
            "accuracy": 0.749023,
            "f1": 0.74902,
            "f1_weighted": 0.749017,
            "ap": 0.688495,
            "ap_weighted": 0.688495
          },
          {
            "accuracy": 0.708984,
            "f1": 0.707657,
            "f1_weighted": 0.707715,
            "ap": 0.644264,
            "ap_weighted": 0.644264
          },
          {
            "accuracy": 0.711426,
            "f1": 0.711395,
            "f1_weighted": 0.711387,
            "ap": 0.65285,
            "ap_weighted": 0.65285
          }
        ],
        "main_score": 0.704639,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.697607,
        "f1": 0.696534,
        "f1_weighted": 0.696548,
        "ap": 0.640795,
        "ap_weighted": 0.640795,
        "scores_per_experiment": [
          {
            "accuracy": 0.748535,
            "f1": 0.748528,
            "f1_weighted": 0.748531,
            "ap": 0.686348,
            "ap_weighted": 0.686348
          },
          {
            "accuracy": 0.626465,
            "f1": 0.623842,
            "f1_weighted": 0.623904,
            "ap": 0.577794,
            "ap_weighted": 0.577794
          },
          {
            "accuracy": 0.696289,
            "f1": 0.695504,
            "f1_weighted": 0.695474,
            "ap": 0.64211,
            "ap_weighted": 0.64211
          },
          {
            "accuracy": 0.599121,
            "f1": 0.595529,
            "f1_weighted": 0.595603,
            "ap": 0.55868,
            "ap_weighted": 0.55868
          },
          {
            "accuracy": 0.730957,
            "f1": 0.730135,
            "f1_weighted": 0.730106,
            "ap": 0.676539,
            "ap_weighted": 0.676539
          },
          {
            "accuracy": 0.678223,
            "f1": 0.6782,
            "f1_weighted": 0.678206,
            "ap": 0.621319,
            "ap_weighted": 0.621319
          },
          {
            "accuracy": 0.733887,
            "f1": 0.731974,
            "f1_weighted": 0.732018,
            "ap": 0.664557,
            "ap_weighted": 0.664557
          },
          {
            "accuracy": 0.750488,
            "f1": 0.750478,
            "f1_weighted": 0.750475,
            "ap": 0.689788,
            "ap_weighted": 0.689788
          },
          {
            "accuracy": 0.713867,
            "f1": 0.713099,
            "f1_weighted": 0.713128,
            "ap": 0.649263,
            "ap_weighted": 0.649263
          },
          {
            "accuracy": 0.698242,
            "f1": 0.698048,
            "f1_weighted": 0.698033,
            "ap": 0.641552,
            "ap_weighted": 0.641552
          }
        ],
        "main_score": 0.697607,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 14.690049171447754,
  "kg_co2_emissions": 0.0004314595402782398
}