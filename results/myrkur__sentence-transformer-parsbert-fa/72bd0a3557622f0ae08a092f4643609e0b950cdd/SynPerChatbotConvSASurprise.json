{
  "dataset_revision": "62dad66fc2837b0ac5e5175fe7c265d2d502a386",
  "task_name": "SynPerChatbotConvSASurprise",
  "mteb_version": "1.25.8",
  "scores": {
    "test": [
      {
        "accuracy": 0.56281,
        "f1": 0.556485,
        "f1_weighted": 0.568923,
        "ap": 0.666513,
        "ap_weighted": 0.666513,
        "scores_per_experiment": [
          {
            "accuracy": 0.53719,
            "f1": 0.529967,
            "f1_weighted": 0.544895,
            "ap": 0.648398,
            "ap_weighted": 0.648398
          },
          {
            "accuracy": 0.578512,
            "f1": 0.575614,
            "f1_weighted": 0.584599,
            "ap": 0.680296,
            "ap_weighted": 0.680296
          },
          {
            "accuracy": 0.603306,
            "f1": 0.590986,
            "f1_weighted": 0.609172,
            "ap": 0.68006,
            "ap_weighted": 0.68006
          },
          {
            "accuracy": 0.53719,
            "f1": 0.52549,
            "f1_weighted": 0.544579,
            "ap": 0.643656,
            "ap_weighted": 0.643656
          },
          {
            "accuracy": 0.636364,
            "f1": 0.630688,
            "f1_weighted": 0.642418,
            "ap": 0.711969,
            "ap_weighted": 0.711969
          },
          {
            "accuracy": 0.545455,
            "f1": 0.544957,
            "f1_weighted": 0.548811,
            "ap": 0.66779,
            "ap_weighted": 0.66779
          },
          {
            "accuracy": 0.53719,
            "f1": 0.531786,
            "f1_weighted": 0.544673,
            "ap": 0.65084,
            "ap_weighted": 0.65084
          },
          {
            "accuracy": 0.553719,
            "f1": 0.553445,
            "f1_weighted": 0.556281,
            "ap": 0.674643,
            "ap_weighted": 0.674643
          },
          {
            "accuracy": 0.570248,
            "f1": 0.559384,
            "f1_weighted": 0.57711,
            "ap": 0.662489,
            "ap_weighted": 0.662489
          },
          {
            "accuracy": 0.528926,
            "f1": 0.522534,
            "f1_weighted": 0.536687,
            "ap": 0.644991,
            "ap_weighted": 0.644991
          }
        ],
        "main_score": 0.56281,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 8.882909536361694,
  "kg_co2_emissions": null
}