{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 43.509912729263306,
  "kg_co2_emissions": 0.0019291289622902364,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.2275390625,
        "f1": 0.18059987430104618,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.18059987430104618,
        "precision": 0.16480255313263126,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.011857202286487392,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.011857202286487392,
        "precision": 0.010086551718459779,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.015492226824762105,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.015492226824762105,
        "precision": 0.01419505442942943,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011942582017255374,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0011942582017255374,
        "precision": 0.0010945542098852743,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.013166100702203792,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.013166100702203792,
        "precision": 0.011710974545371382,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007927121161511912,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.007927121161511912,
        "precision": 0.006309132431690482,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011834851616430803,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.011834851616430803,
        "precision": 0.010254917093145518,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.010140947735240916,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.010140947735240916,
        "precision": 0.009098839112490355,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0050190160699696545,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0050190160699696545,
        "precision": 0.004037757438691345,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013615479998383145,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.013615479998383145,
        "precision": 0.011667578696013727,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004975134585084033,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.004975134585084033,
        "precision": 0.00422555009269633,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.011610320157673673,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.011610320157673673,
        "precision": 0.009786033220081768,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007168775221531134,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.007168775221531134,
        "precision": 0.006362153359538257,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.016199298797486352,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.016199298797486352,
        "precision": 0.014000714073956262,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.018203632432722505,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.018203632432722505,
        "precision": 0.015146143532210719,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00379670498006895,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.00379670498006895,
        "precision": 0.0031162247084083406,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.01664324244024345,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.01664324244024345,
        "precision": 0.014685133811765387,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006531418010752688,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0006531418010752688,
        "precision": 0.0004893324475242196,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012808553531209781,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.012808553531209781,
        "precision": 0.011336120248538011,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006629439981619258,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.006629439981619258,
        "precision": 0.005552700109649123,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007627114988110419,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.007627114988110419,
        "precision": 0.006648190230164035,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004199985924767635,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.004199985924767635,
        "precision": 0.00376376259516391,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10790082570487222,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.10790082570487222,
        "precision": 0.09843181602037916,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01088672022553263,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.01088672022553263,
        "precision": 0.009385257633163164,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.016538703241311507,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.016538703241311507,
        "precision": 0.014657448486254809,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013141769344807263,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0013141769344807263,
        "precision": 0.001169113033720064,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.012273550566364443,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.012273550566364443,
        "precision": 0.011048199388357308,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0038033075142450143,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0038033075142450143,
        "precision": 0.003169958296911422,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.02473894347363117,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.02473894347363117,
        "precision": 0.0224339753817394,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003799908496538583,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.003799908496538583,
        "precision": 0.0034794313280742083,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.007156125423219747,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.007156125423219747,
        "precision": 0.006757339521011396,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.037063774967792604,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.037063774967792604,
        "precision": 0.03332806417367794,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017895858253588516,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0017895858253588516,
        "precision": 0.0014519585503472222,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.01993958462051238,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.01993958462051238,
        "precision": 0.018561202842738087,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002717898844034087,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.002717898844034087,
        "precision": 0.002404393088054187,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.03136923511120326,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.03136923511120326,
        "precision": 0.028796090360313706,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007344453828828829,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.007344453828828829,
        "precision": 0.006556751153812974,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00229213650728115,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.00229213650728115,
        "precision": 0.0021552092539377904,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.02192209916819292,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.02192209916819292,
        "precision": 0.019832583619590782,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9054878048780488e-06,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 1.9054878048780488e-06,
        "precision": 9.5367431640625e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.018946390427893187,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.018946390427893187,
        "precision": 0.01667479311295926,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005261550642984466,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.005261550642984466,
        "precision": 0.00475999998042662,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003447561553030303,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.003447561553030303,
        "precision": 0.002668497537236048,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002484643270343959,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.002484643270343959,
        "precision": 0.002242691215295478,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027294853430754135,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.027294853430754135,
        "precision": 0.022920068812081557,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.030063285010859024,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.030063285010859024,
        "precision": 0.027062410901586478,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.365234375,
        "f1": 0.3395144568972694,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3395144568972694,
        "precision": 0.33212604039170845,
        "recall": 0.365234375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06228248176556034,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06228248176556034,
        "precision": 0.056647172232970805,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.32421875,
        "f1": 0.2916426847137615,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2916426847137615,
        "precision": 0.2822380287406724,
        "recall": 0.32421875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.017188275427615186,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.017188275427615186,
        "precision": 0.012398870008265733,
        "recall": 0.046875
      },
      {
        "accuracy": 0.3486328125,
        "f1": 0.3169722452388468,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3169722452388468,
        "precision": 0.3074332629014934,
        "recall": 0.3486328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0035082529562828475,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0035082529562828475,
        "precision": 0.003302287792699724,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.255859375,
        "f1": 0.22736010563626052,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.22736010563626052,
        "precision": 0.21832885267943863,
        "recall": 0.255859375
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.10355102908645472,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10355102908645472,
        "precision": 0.0935707611501711,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.13937214607880144,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.13937214607880144,
        "precision": 0.12974547301701325,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06595646490187931,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06595646490187931,
        "precision": 0.06015597249820431,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003891680237631397,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003891680237631397,
        "precision": 0.0032104934637076617,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.08207985941499268,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.08207985941499268,
        "precision": 0.07435097048134157,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007903175721134047,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.007903175721134047,
        "precision": 0.0071243288573828185,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.2353515625,
        "f1": 0.2170881967995596,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.2170881967995596,
        "precision": 0.21053712174046377,
        "recall": 0.2353515625
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.08119694872443699,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.08119694872443699,
        "precision": 0.07542654645183092,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014214409722222224,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0014214409722222224,
        "precision": 0.0009230840773809524,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.3544921875,
        "f1": 0.32584914606686205,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.32584914606686205,
        "precision": 0.3174038785158972,
        "recall": 0.3544921875
      },
      {
        "accuracy": 0.2080078125,
        "f1": 0.17851328359140858,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.17851328359140858,
        "precision": 0.1675366853412829,
        "recall": 0.2080078125
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.16858313253144752,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.16858313253144752,
        "precision": 0.15678086521354287,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.2685546875,
        "f1": 0.2517092093894009,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2517092093894009,
        "precision": 0.24461263020833335,
        "recall": 0.2685546875
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.02607690823044046,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.02607690823044046,
        "precision": 0.02234807473083416,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03958023226588106,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.03958023226588106,
        "precision": 0.035350749510905756,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.3857421875,
        "f1": 0.34618986643271454,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.34618986643271454,
        "precision": 0.33485605738640295,
        "recall": 0.3857421875
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.09255451576340695,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09255451576340695,
        "precision": 0.08740929420835089,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.4375,
        "f1": 0.39510642666637913,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.39510642666637913,
        "precision": 0.3818768872893788,
        "recall": 0.4375
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.022077679255111286,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.022077679255111286,
        "precision": 0.0166902298373682,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.6787109375,
        "f1": 0.6335542224702382,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6335542224702382,
        "precision": 0.615580047123016,
        "recall": 0.6787109375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002946178399807432,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.002946178399807432,
        "precision": 0.002536320016788767,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2841796875,
        "f1": 0.2611659987148268,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2611659987148268,
        "precision": 0.2536021042188805,
        "recall": 0.2841796875
      },
      {
        "accuracy": 0.5419921875,
        "f1": 0.4744855079816017,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4744855079816017,
        "precision": 0.4502754705147283,
        "recall": 0.5419921875
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.1409683282131565,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1409683282131565,
        "precision": 0.1308991117030403,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.19345388227224164,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.19345388227224164,
        "precision": 0.17993560705532213,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002922749187397625,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002922749187397625,
        "precision": 0.002521273426716701,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.3515625,
        "f1": 0.2839338620746594,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2839338620746594,
        "precision": 0.2613067437853456,
        "recall": 0.3515625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.011642501876876876,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.011642501876876876,
        "precision": 0.010594473701797998,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.22684638413375147,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.22684638413375147,
        "precision": 0.22121036413944128,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.2138671875,
        "f1": 0.16498934008699634,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.16498934008699634,
        "precision": 0.15039918210874093,
        "recall": 0.2138671875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004625624139118457,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004625624139118457,
        "precision": 0.004347319950331126,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.5380859375,
        "f1": 0.48966592377954976,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.48966592377954976,
        "precision": 0.473096125879329,
        "recall": 0.5380859375
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.18184733293758482,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.18184733293758482,
        "precision": 0.1717022343975469,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.16696361144486827,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.16696361144486827,
        "precision": 0.15376789890339695,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.2762949960376411,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2762949960376411,
        "precision": 0.26890438713858417,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004926941548035298,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.004926941548035298,
        "precision": 0.0041120012799700295,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.007994982974159215,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.007994982974159215,
        "precision": 0.005896409899005915,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.2080078125,
        "f1": 0.15828839480321558,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.15828839480321558,
        "precision": 0.14431885428769045,
        "recall": 0.2080078125
      },
      {
        "accuracy": 0.2392578125,
        "f1": 0.17951826580592964,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.17951826580592964,
        "precision": 0.1628522505597701,
        "recall": 0.2392578125
      },
      {
        "accuracy": 0.20703125,
        "f1": 0.15698565565867956,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.15698565565867956,
        "precision": 0.1412744622095208,
        "recall": 0.20703125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012982414767825775,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.012982414767825775,
        "precision": 0.009362963439118842,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.2451171875,
        "f1": 0.19518223204746643,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.19518223204746643,
        "precision": 0.17887752722282824,
        "recall": 0.2451171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017609126984126984,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.0017609126984126984,
        "precision": 0.0011257595486111112,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.12534860838801556,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.12534860838801556,
        "precision": 0.11042370890572867,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.028346685866217115,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.028346685866217115,
        "precision": 0.023729055860532013,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.08194576354847495,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.08194576354847495,
        "precision": 0.07161209112598386,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.02472386725573403,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.02472386725573403,
        "precision": 0.020851051931438443,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004982022813654447,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0004982022813654447,
        "precision": 0.00027283507508116885,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.019079327389661966,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.019079327389661966,
        "precision": 0.015055549918831169,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0011573240289922274,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0011573240289922274,
        "precision": 0.0006531202087842713,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1630859375,
        "f1": 0.11326773044010946,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.11326773044010946,
        "precision": 0.10091706628456215,
        "recall": 0.1630859375
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.02295166385035834,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.02295166385035834,
        "precision": 0.01929835843410062,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0023227434391940604,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0023227434391940604,
        "precision": 0.0013871465590003292,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2177734375,
        "f1": 0.16428229702155484,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.16428229702155484,
        "precision": 0.14877571747302407,
        "recall": 0.2177734375
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.10033820639529527,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.10033820639529527,
        "precision": 0.08633122033916754,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.10048747795972301,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.10048747795972301,
        "precision": 0.08903593404372656,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.12434351889430012,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.12434351889430012,
        "precision": 0.11232142152552309,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.028014892322817897,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.028014892322817897,
        "precision": 0.025338402139892538,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.03780105943062581,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.03780105943062581,
        "precision": 0.0337225333544997,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.3349609375,
        "f1": 0.2960428635011113,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2960428635011113,
        "precision": 0.28464222123716243,
        "recall": 0.3349609375
      },
      {
        "accuracy": 0.4306640625,
        "f1": 0.39665436921296293,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.39665436921296293,
        "precision": 0.3846483160936286,
        "recall": 0.4306640625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.06890892036186907,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06890892036186907,
        "precision": 0.06322640575266347,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.024146303958312968,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.024146303958312968,
        "precision": 0.01939839809059591,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.48046875,
        "f1": 0.4355037232504338,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4355037232504338,
        "precision": 0.4205796640048508,
        "recall": 0.48046875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006773379924886622,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.006773379924886622,
        "precision": 0.0057986958929902065,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.265625,
        "f1": 0.23438787639227093,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.23438787639227093,
        "precision": 0.2246040109746594,
        "recall": 0.265625
      },
      {
        "accuracy": 0.2783203125,
        "f1": 0.2239588932974007,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2239588932974007,
        "precision": 0.2072052085471401,
        "recall": 0.2783203125
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.1312076413422939,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1312076413422939,
        "precision": 0.1191340135444782,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.556640625,
        "f1": 0.4831155443948413,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4831155443948413,
        "precision": 0.45387683334460677,
        "recall": 0.556640625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003282824358053345,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003282824358053345,
        "precision": 0.002529003295604858,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2314453125,
        "f1": 0.18186057106955544,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.18186057106955544,
        "precision": 0.16804400744399595,
        "recall": 0.2314453125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005821777289418048,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.005821777289418048,
        "precision": 0.004550240826307826,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.2099792256896749,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.2099792256896749,
        "precision": 0.20268538083792242,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.14533659699675322,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.14533659699675322,
        "precision": 0.12837269880726915,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004625477539071556,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004625477539071556,
        "precision": 0.0037301404284507482,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.3876953125,
        "f1": 0.34820158469199136,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.34820158469199136,
        "precision": 0.33667077309327104,
        "recall": 0.3876953125
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.16999317956349208,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.16999317956349208,
        "precision": 0.15906146804584304,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.2138671875,
        "f1": 0.1747088341728737,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1747088341728737,
        "precision": 0.16429622568795574,
        "recall": 0.2138671875
      },
      {
        "accuracy": 0.265625,
        "f1": 0.241045448758304,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.241045448758304,
        "precision": 0.23242821631493504,
        "recall": 0.265625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0001739708195193484,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.0001739708195193484,
        "precision": 8.984711163228615e-05,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003126161181123563,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.003126161181123563,
        "precision": 0.0027304178969511043,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.033511581618462266,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.033511581618462266,
        "precision": 0.03274621353338194,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03449719948743386,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.03449719948743386,
        "precision": 0.03386812093419553,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008829079534774435,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.008829079534774435,
        "precision": 0.00832111361387623,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.036092375129399584,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.036092375129399584,
        "precision": 0.03532205266744548,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.030432494136427405,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.030432494136427405,
        "precision": 0.029806818432509367,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.12981770833333334,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.12981770833333334,
        "precision": 0.11989672111742425,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.030933682133052583,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.030933682133052583,
        "precision": 0.030409824153869506,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00125315247448564,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.00125315247448564,
        "precision": 0.0011324211436191313,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.06857258409992785,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.06857258409992785,
        "precision": 0.06302241866206709,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002393457290192085,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.002393457290192085,
        "precision": 0.0018015911750601235,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.05733374435963901,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.05733374435963901,
        "precision": 0.050228146832011815,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000717064439264762,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.000717064439264762,
        "precision": 0.0004246887899896801,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.048584648589317866,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.048584648589317866,
        "precision": 0.04291674959809692,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.05770090885505088,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.05770090885505088,
        "precision": 0.05546421181985725,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002043436205606135,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.002043436205606135,
        "precision": 0.0020000601694480247,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.037898847027912866,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.037898847027912866,
        "precision": 0.032093341400320205,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03722367917566751,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.03722367917566751,
        "precision": 0.03627167121243523,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.03633967318949475,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.03633967318949475,
        "precision": 0.03569136623325453,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.0972971624729437,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.0972971624729437,
        "precision": 0.09055823819135908,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.03036882130101935,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.03036882130101935,
        "precision": 0.029768932589658202,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.039109818643366434,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.039109818643366434,
        "precision": 0.03464327362555599,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.06145420369120819,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.06145420369120819,
        "precision": 0.055153866115674036,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.37890625,
        "f1": 0.342214759746458,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.342214759746458,
        "precision": 0.3305408432904412,
        "recall": 0.37890625
      },
      {
        "accuracy": 0.693359375,
        "f1": 0.6482352825126262,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6482352825126262,
        "precision": 0.6307726606267507,
        "recall": 0.693359375
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.08222869426281865,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08222869426281865,
        "precision": 0.07546749875533716,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.4697265625,
        "f1": 0.4260943808795371,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4260943808795371,
        "precision": 0.4122154792906746,
        "recall": 0.4697265625
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.017989011930093026,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.017989011930093026,
        "precision": 0.013833666202073587,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002476737106492541,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.002476737106492541,
        "precision": 0.002246395424205649,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.2578125,
        "f1": 0.23553653549027728,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.23553653549027728,
        "precision": 0.22668185763888887,
        "recall": 0.2578125
      },
      {
        "accuracy": 0.6884765625,
        "f1": 0.6216866629464286,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6216866629464286,
        "precision": 0.5944754464285714,
        "recall": 0.6884765625
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.1329121010133803,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1329121010133803,
        "precision": 0.12351279704307049,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.3564453125,
        "f1": 0.2927022738546176,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.2927022738546176,
        "precision": 0.2729428864207339,
        "recall": 0.3564453125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005109445826845558,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005109445826845558,
        "precision": 0.004399884677512307,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.5322265625,
        "f1": 0.4681112041170635,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4681112041170635,
        "precision": 0.4430047898065476,
        "recall": 0.5322265625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005376520557808363,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.005376520557808363,
        "precision": 0.004971127542600271,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.2103067737038688,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.2103067737038688,
        "precision": 0.20390018480838792,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.2763671875,
        "f1": 0.22922796604437232,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.22922796604437232,
        "precision": 0.21430822595373378,
        "recall": 0.2763671875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018748109219649397,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0018748109219649397,
        "precision": 0.0016058881542003593,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.5146484375,
        "f1": 0.4726919239614552,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4726919239614552,
        "precision": 0.45978531145814305,
        "recall": 0.5146484375
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.17665380743942077,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.17665380743942077,
        "precision": 0.16666205387144778,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.16187100682409855,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.16187100682409855,
        "precision": 0.15008772991706482,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.2978515625,
        "f1": 0.2707590213749006,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2707590213749006,
        "precision": 0.2614226810515873,
        "recall": 0.2978515625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017136829387371685,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0017136829387371685,
        "precision": 0.0015085267125984497,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001349778975203483,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.001349778975203483,
        "precision": 0.0008956325734653423,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001457224791112924,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.001457224791112924,
        "precision": 0.0012476844038238496,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001976137041942553,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.001976137041942553,
        "precision": 0.0016627893188416055,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003369084336481334,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0003369084336481334,
        "precision": 0.00019248414734363895,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0019905857308201054,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0019905857308201054,
        "precision": 0.001582973494998575,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.11944099195075757,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.11944099195075757,
        "precision": 0.10630037822420635,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00030723219986806616,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.00030723219986806616,
        "precision": 0.0001682543667001893,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002701556096311475,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.002701556096311475,
        "precision": 0.0024262255263675717,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0019798031588935333,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.0019798031588935333,
        "precision": 0.0015484227656859526,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.06633954695478134,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.06633954695478134,
        "precision": 0.056980484250992065,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004782477626685263,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.004782477626685263,
        "precision": 0.004104346329034312,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.050774700873642074,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.050774700873642074,
        "precision": 0.04246893327284672,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0023634157410629257,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0023634157410629257,
        "precision": 0.0018526173985608893,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.061058379254647535,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.061058379254647535,
        "precision": 0.054917124678154086,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.019464092553542284,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.019464092553542284,
        "precision": 0.017163785722004585,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014263762145483192,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0014263762145483192,
        "precision": 0.001237623725833024,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.032602514401830804,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.032602514401830804,
        "precision": 0.027923544054041037,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0052263081209517155,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0052263081209517155,
        "precision": 0.004242658175850239,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002890235516589307,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.002890235516589307,
        "precision": 0.002607704936594203,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.08730972532242064,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.08730972532242064,
        "precision": 0.07651036651639823,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0001175500648320892,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0001175500648320892,
        "precision": 6.165847279667075e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005604688456932279,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.005604688456932279,
        "precision": 0.004967892286941,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01713925316220238,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.01713925316220238,
        "precision": 0.015169383340533794,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.2578125,
        "f1": 0.24018599577250777,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.24018599577250777,
        "precision": 0.235130587728244,
        "recall": 0.2578125
      },
      {
        "accuracy": 0.27734375,
        "f1": 0.26001908419157593,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.26001908419157593,
        "precision": 0.25400074643238707,
        "recall": 0.27734375
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.07162203306384743,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.07162203306384743,
        "precision": 0.06685106142247649,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.2412109375,
        "f1": 0.21670436368040366,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.21670436368040366,
        "precision": 0.20797118965549258,
        "recall": 0.2412109375
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.015036885857198357,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.015036885857198357,
        "precision": 0.01042514720489046,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.2587890625,
        "f1": 0.24033794610223475,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.24033794610223475,
        "precision": 0.2340443817250458,
        "recall": 0.2587890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007920192938859714,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0007920192938859714,
        "precision": 0.0004898313492063492,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027598126157696468,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.027598126157696468,
        "precision": 0.02376587882874504,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.1669921875,
        "f1": 0.13581910490238852,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.13581910490238852,
        "precision": 0.1264707475168701,
        "recall": 0.1669921875
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.01963772515530328,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.01963772515530328,
        "precision": 0.017995031788135236,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001727473819887471,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.001727473819887471,
        "precision": 0.0013875524715824803,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.02192868563262356,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.02192868563262356,
        "precision": 0.018894701617444033,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0013233026861828867,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0013233026861828867,
        "precision": 0.0008811114685034233,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.236328125,
        "f1": 0.21666805746714035,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.21666805746714035,
        "precision": 0.21057503389861273,
        "recall": 0.236328125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013367354002715624,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.013367354002715624,
        "precision": 0.010938275049603175,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0005231584821428571,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0005231584821428571,
        "precision": 0.00030226934523809525,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2724609375,
        "f1": 0.24962329317193382,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.24962329317193382,
        "precision": 0.24234147915701618,
        "recall": 0.2724609375
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.15630882359229611,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.15630882359229611,
        "precision": 0.1460809616815476,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.1718079934388528,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.1718079934388528,
        "precision": 0.16166062127976188,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.6064453125,
        "f1": 0.559295025264392,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.559295025264392,
        "precision": 0.5437564451493316,
        "recall": 0.6064453125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.038027168173098896,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.038027168173098896,
        "precision": 0.034675942529247106,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.06539325306647165,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.06539325306647165,
        "precision": 0.05962141699446387,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08105196622226327,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.08105196622226327,
        "precision": 0.07191313643264771,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.419921875,
        "f1": 0.34897463105470916,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.34897463105470916,
        "precision": 0.3243850333694084,
        "recall": 0.419921875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003790094225021816,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003790094225021816,
        "precision": 0.002528555635489503,
        "recall": 0.015625
      },
      {
        "accuracy": 0.21484375,
        "f1": 0.16257126971197666,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.16257126971197666,
        "precision": 0.14920222057673227,
        "recall": 0.21484375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003220580386150561,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.003220580386150561,
        "precision": 0.002595999287893819,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.533203125,
        "f1": 0.4537898245417777,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4537898245417777,
        "precision": 0.4251864698886183,
        "recall": 0.533203125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00412777457018219,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.00412777457018219,
        "precision": 0.003737612123842593,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015861521562205154,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.015861521562205154,
        "precision": 0.013891073163297836,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.009224242441707484,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.009224242441707484,
        "precision": 0.008748776627951906,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.3662109375,
        "f1": 0.30496026134812904,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.30496026134812904,
        "precision": 0.2870816836209483,
        "recall": 0.3662109375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.008364080352088675,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.008364080352088675,
        "precision": 0.007591068251406819,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.5703125,
        "f1": 0.5004952566964286,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5004952566964286,
        "precision": 0.47513566891008296,
        "recall": 0.5703125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007178263677168022,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.007178263677168022,
        "precision": 0.006196498990938118,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.007018200957779271,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.007018200957779271,
        "precision": 0.006682977587319952,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2900390625,
        "f1": 0.23526961861922802,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.23526961861922802,
        "precision": 0.2182865203373016,
        "recall": 0.2900390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001970063409314487,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001970063409314487,
        "precision": 0.001961642682504864,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.15245255771113447,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.15245255771113447,
        "precision": 0.14017712202590904,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.016841836436090468,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.016841836436090468,
        "precision": 0.01575210998755797,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008249161686185315,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.008249161686185315,
        "precision": 0.006879595377961632,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.01437326976185543,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.01437326976185543,
        "precision": 0.012194612234179851,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0025785276423192253,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.0025785276423192253,
        "precision": 0.002305809345561581,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00031571581664302506,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.00031571581664302506,
        "precision": 0.00017323063853533238,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.142578125,
        "f1": 0.13026815222198318,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.13026815222198318,
        "precision": 0.1261042258522727,
        "recall": 0.142578125
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.13495573244455172,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.13495573244455172,
        "precision": 0.12945738003500634,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.0332651357972697,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.0332651357972697,
        "precision": 0.02995100468642438,
        "recall": 0.046875
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.1304937392213328,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.1304937392213328,
        "precision": 0.12641850051685752,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.06975353422619048,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.06975353422619048,
        "precision": 0.059276956225198414,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.12637368556451967,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.12637368556451967,
        "precision": 0.12262583804743334,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.07853137881573083,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.07853137881573083,
        "precision": 0.06961769330411058,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.13144039821930315,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.13144039821930315,
        "precision": 0.1259354280883045,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004450999149659863,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.004450999149659863,
        "precision": 0.0038861041302447547,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0022705945717839374,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0022705945717839374,
        "precision": 0.0017726089015151515,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.03724617125496031,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.03724617125496031,
        "precision": 0.03394192676367294,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001549252059108527,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.001549252059108527,
        "precision": 0.001312900329968944,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03172933125222752,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.03172933125222752,
        "precision": 0.026949181011442825,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.16782205053946417,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.16782205053946417,
        "precision": 0.16317527039121807,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019629987136239274,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0019629987136239274,
        "precision": 0.0019580747036866907,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016836543447871572,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.016836543447871572,
        "precision": 0.014660450768849207,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.1268010467887336,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.1268010467887336,
        "precision": 0.12274577578536058,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.13139241536458332,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.13139241536458332,
        "precision": 0.1285075994863671,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.20320695009774745,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.20320695009774745,
        "precision": 0.19520096738114318,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.1254298728846634,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.1254298728846634,
        "precision": 0.12058586710088573,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.02953316314943581,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.02953316314943581,
        "precision": 0.026415087367917128,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.047160460422127716,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.047160460422127716,
        "precision": 0.04322827584511513,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.0603714206430931,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.0603714206430931,
        "precision": 0.054506732567676186,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.15292231560876163,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.15292231560876163,
        "precision": 0.1407638402086779,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005279751627141022,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.005279751627141022,
        "precision": 0.003859044511589585,
        "recall": 0.015625
      },
      {
        "accuracy": 0.4013671875,
        "f1": 0.32200678011224887,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.32200678011224887,
        "precision": 0.29597826760912693,
        "recall": 0.4013671875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0052975547349924015,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0052975547349924015,
        "precision": 0.0044320369112318845,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.2900390625,
        "f1": 0.22279624686854207,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.22279624686854207,
        "precision": 0.20477349527642497,
        "recall": 0.2900390625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.009462651064213564,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.009462651064213564,
        "precision": 0.008357747395833334,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.014129224724927851,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.014129224724927851,
        "precision": 0.012866860350825465,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.28105786686673,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.28105786686673,
        "precision": 0.2629465507004569,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.00497602143296317,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.00497602143296317,
        "precision": 0.0035365549214098394,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004700924945258949,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004700924945258949,
        "precision": 0.0035948882818052593,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2958984375,
        "f1": 0.23945881409816236,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.23945881409816236,
        "precision": 0.2228877185639881,
        "recall": 0.2958984375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.008988975857306649,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.008988975857306649,
        "precision": 0.008274927809665534,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005556360718060354,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.005556360718060354,
        "precision": 0.00447097285472919,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.24609375,
        "f1": 0.1889293226678733,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.1889293226678733,
        "precision": 0.1719114904575612,
        "recall": 0.24609375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0048782121884274,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0048782121884274,
        "precision": 0.003893934706090531,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09251891102983992,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.09251891102983992,
        "precision": 0.08376399080280672,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.014173065574220465,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.014173065574220465,
        "precision": 0.012359645562770563,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006390082367352522,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.006390082367352522,
        "precision": 0.005261558374351343,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.015334975284121474,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.015334975284121474,
        "precision": 0.01354741031019643,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0011315724206349205,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0011315724206349205,
        "precision": 0.0006317827659339807,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002625794156025134,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.002625794156025134,
        "precision": 0.0023469119377836486,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015394228763783526,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0015394228763783526,
        "precision": 0.0013000165343915343,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0022258049004170648,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0022258049004170648,
        "precision": 0.0021034128080134407,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 9.875664448305641e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 9.875664448305641e-05,
        "precision": 5.133801619296259e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001285112373860876,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.001285112373860876,
        "precision": 0.0011542016061290696,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06240181566366291,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.06240181566366291,
        "precision": 0.05598645987013838,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009372933201058201,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0009372933201058201,
        "precision": 0.0006491762042557813,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.07460227059668062,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.07460227059668062,
        "precision": 0.06929245522995522,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0032077233768203883,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0032077233768203883,
        "precision": 0.003075649256023284,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0019477308688147295,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0019477308688147295,
        "precision": 0.0015687201433121018,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.028402484461591746,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.028402484461591746,
        "precision": 0.024353902736959324,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00338060067121665,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.00338060067121665,
        "precision": 0.002880121409109896,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002218191964285714,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.002218191964285714,
        "precision": 0.0018438652561802234,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.028583050607104886,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.028583050607104886,
        "precision": 0.026623124931609243,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.027261924384146395,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.027261924384146395,
        "precision": 0.023838558819240678,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010128813789593541,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0010128813789593541,
        "precision": 0.000994879844351144,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.06711219688514611,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.06711219688514611,
        "precision": 0.0609015130814526,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003579788064437187,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.003579788064437187,
        "precision": 0.002967037288711836,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0022764995811478156,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0022764995811478156,
        "precision": 0.0018377549645030129,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.032128140796612484,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.032128140796612484,
        "precision": 0.02835491190451763,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010681684936736473,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0010681684936736473,
        "precision": 0.0010241615417620137,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.029108431353360942,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.029108431353360942,
        "precision": 0.02479348287615476,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.04929139034195271,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.04929139034195271,
        "precision": 0.0444135041479605,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.06879626318811677,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.06879626318811677,
        "precision": 0.060411779079325705,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.2763671875,
        "f1": 0.21428914329304954,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.21428914329304954,
        "precision": 0.1953185179259398,
        "recall": 0.2763671875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.005279143426304691,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.005279143426304691,
        "precision": 0.004033575498494177,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.1287460415139114,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.1287460415139114,
        "precision": 0.11783723817415223,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003563769257703081,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.003563769257703081,
        "precision": 0.0030077829071969695,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.3916015625,
        "f1": 0.31777500194607267,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.31777500194607267,
        "precision": 0.29330466941550926,
        "recall": 0.3916015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0063889791478300186,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0063889791478300186,
        "precision": 0.00556923231640662,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.00954492556055056,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.00954492556055056,
        "precision": 0.008419258150703463,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.5458984375,
        "f1": 0.4816650092528999,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4816650092528999,
        "precision": 0.458093706232493,
        "recall": 0.5458984375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002941435620300752,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.002941435620300752,
        "precision": 0.0019444444444444444,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2880859375,
        "f1": 0.2378561920939385,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.2378561920939385,
        "precision": 0.22372063787863994,
        "recall": 0.2880859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0029086235465329005,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0029086235465329005,
        "precision": 0.0021915600256894176,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.01105315275781365,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.01105315275781365,
        "precision": 0.009875758823468389,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004932916820211141,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.004932916820211141,
        "precision": 0.004289688446364992,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2529296875,
        "f1": 0.2080356274717911,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.2080356274717911,
        "precision": 0.19386159101060296,
        "recall": 0.2529296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0058641271289537715,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0058641271289537715,
        "precision": 0.005047954776422764,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.10510218931777984,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.10510218931777984,
        "precision": 0.09588647282888418,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012892141401397515,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.012892141401397515,
        "precision": 0.011581320456889943,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005192616988464028,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.005192616988464028,
        "precision": 0.0043972391912865325,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.015492516423066755,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.015492516423066755,
        "precision": 0.013945072864697525,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0009303044747570635,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0009303044747570635,
        "precision": 0.0006387614446605088,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005059278024675226,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.005059278024675226,
        "precision": 0.004295342728103528,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018174225280595472,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0018174225280595472,
        "precision": 0.0015110212053571427,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0023783253422638632,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0023783253422638632,
        "precision": 0.0021995634224349758,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.201844262295082e-05,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 3.201844262295082e-05,
        "precision": 1.6276041666666666e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002611142113095238,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.002611142113095238,
        "precision": 0.00208873026071678,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.042219489768624927,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.042219489768624927,
        "precision": 0.03747805317336232,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0008633493812542785,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0008633493812542785,
        "precision": 0.0005013807737017662,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.04501588028454497,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.04501588028454497,
        "precision": 0.04012248618939189,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00012005287789219425,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.00012005287789219425,
        "precision": 6.323581155251925e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0024755356738529986,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0024755356738529986,
        "precision": 0.0022454998099391806,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.009634963666983383,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.009634963666983383,
        "precision": 0.007398158680365262,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006129204990902894,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.006129204990902894,
        "precision": 0.005140004613280324,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03241273833199688,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.03241273833199688,
        "precision": 0.028824506954382205,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003291734179671113,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.003291734179671113,
        "precision": 0.002581297140816055,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.006617653504469316,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.006617653504469316,
        "precision": 0.0056747718452660675,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002310178549691693,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.002310178549691693,
        "precision": 0.002141154714408464,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.01268767536226345,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.01268767536226345,
        "precision": 0.010857902138113596,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003985874640042169,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.003985874640042169,
        "precision": 0.003245322513475087,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0025024531783937915,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.0025024531783937915,
        "precision": 0.0015438768741576818,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.025264888677203643,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.025264888677203643,
        "precision": 0.021324112178084918,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005838140321547718,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0005838140321547718,
        "precision": 0.00033315801414436896,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0028770673091514615,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.0028770673091514615,
        "precision": 0.0021543528414353337,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002915247102130326,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.002915247102130326,
        "precision": 0.0025652203861896896,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.21887746982473544,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.21887746982473544,
        "precision": 0.21203253694282945,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.2392578125,
        "f1": 0.22105854413036777,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.22105854413036777,
        "precision": 0.214151060814951,
        "recall": 0.2392578125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07512886993646106,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.07512886993646106,
        "precision": 0.06944982761421062,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.236328125,
        "f1": 0.21994514873832308,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.21994514873832308,
        "precision": 0.21357656062649877,
        "recall": 0.236328125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04718343028994017,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.04718343028994017,
        "precision": 0.040125263844726256,
        "recall": 0.078125
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.2065898366868205,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.2065898366868205,
        "precision": 0.19979347863615332,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.021085795830936838,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.021085795830936838,
        "precision": 0.01817982432606456,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.2373046875,
        "f1": 0.21576177345938374,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.21576177345938374,
        "precision": 0.20793756964129007,
        "recall": 0.2373046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003357616600975345,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.003357616600975345,
        "precision": 0.0025450368946940364,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.15192537746248683,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.15192537746248683,
        "precision": 0.14107805172258298,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0035522161545429205,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0035522161545429205,
        "precision": 0.0029832440402667985,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.03507083174447241,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.03507083174447241,
        "precision": 0.031841853032102824,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006265684087579062,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.006265684087579062,
        "precision": 0.0057948371556689835,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.026573014120803345,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.026573014120803345,
        "precision": 0.02361655562031885,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003680099422579832,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.003680099422579832,
        "precision": 0.00308221515796546,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.01872426085269457,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.01872426085269457,
        "precision": 0.016253972607188034,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.21148877164502164,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.21148877164502164,
        "precision": 0.20423355524986156,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.1633082798549107,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.1633082798549107,
        "precision": 0.15535090358635617,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.2353515625,
        "f1": 0.20727680532011472,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.20727680532011472,
        "precision": 0.19699992019584944,
        "recall": 0.2353515625
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.20770026276276274,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.20770026276276274,
        "precision": 0.20049466201551186,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.017761961661961232,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.017761961661961232,
        "precision": 0.015967723394345292,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.037947503072014784,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.037947503072014784,
        "precision": 0.03376001417261598,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.05730812054819205,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.05730812054819205,
        "precision": 0.05081381655161489,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.09711001246902769,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.09711001246902769,
        "precision": 0.087665155553233,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0015357282143474175,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0015357282143474175,
        "precision": 0.001031303446859513,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.09877012383663714,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.09877012383663714,
        "precision": 0.09091683088400498,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0043040493697550425,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0043040493697550425,
        "precision": 0.0033939779371987035,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.11833337347817413,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.11833337347817413,
        "precision": 0.10730109367373843,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00456084927140255,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.00456084927140255,
        "precision": 0.004070792465024332,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009610755997474747,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.009610755997474747,
        "precision": 0.008010207636566333,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.23046875,
        "f1": 0.1870955170568167,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1870955170568167,
        "precision": 0.17439528330770107,
        "recall": 0.23046875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0030407779431216933,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0030407779431216933,
        "precision": 0.0019072600428798802,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.212890625,
        "f1": 0.16117267064532687,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.16117267064532687,
        "precision": 0.1477698024911187,
        "recall": 0.212890625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004338165816391939,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004338165816391939,
        "precision": 0.0038542760481466197,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.15554107255336574,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.15554107255336574,
        "precision": 0.14541974845601596,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007445192856638905,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.007445192856638905,
        "precision": 0.006267367797983299,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001972557090361939,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.001972557090361939,
        "precision": 0.0019628980961685586,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.005054532205657492,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005054532205657492,
        "precision": 0.004724552371351766,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.0816794460166733,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.0816794460166733,
        "precision": 0.07364145023812993,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.011367882769980457,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.011367882769980457,
        "precision": 0.010444066949696545,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002684782923959162,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.002684782923959162,
        "precision": 0.0020454582101979545,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.009455048320476427,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.009455048320476427,
        "precision": 0.008793108085840572,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001322875529418498,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.001322875529418498,
        "precision": 0.0011739650051429658,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0044370482568027204,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0044370482568027204,
        "precision": 0.003960362002933507,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001578887606988466,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.001578887606988466,
        "precision": 0.0013221661292581904,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004788334491014305,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.004788334491014305,
        "precision": 0.004461685426048883,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000979393115942029,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.000979393115942029,
        "precision": 0.000977979862119013,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0023004594935585316,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0023004594935585316,
        "precision": 0.002159407073228904,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03817708002779592,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.03817708002779592,
        "precision": 0.03319682559981835,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003838694824249235,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0003838694824249235,
        "precision": 0.0002251938042953668,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03952332837565514,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.03952332837565514,
        "precision": 0.035603873321626775,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016338243099787686,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0016338243099787686,
        "precision": 0.0013939817504114629,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001631036723784417,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.001631036723784417,
        "precision": 0.0013689068001760563,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.011473845949576712,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.011473845949576712,
        "precision": 0.00939315978150082,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030425697244623653,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0030425697244623653,
        "precision": 0.0026294764832162374,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.05443483382936508,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.05443483382936508,
        "precision": 0.04517612649936869,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024540677043402336,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0024540677043402336,
        "precision": 0.0022850010672997227,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.018204299845284495,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.018204299845284495,
        "precision": 0.016772395354186707,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.017460959881111536,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.017460959881111536,
        "precision": 0.015070424780013802,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026078518081761003,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0026078518081761003,
        "precision": 0.0024432523038752365,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0032412678068804855,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0032412678068804855,
        "precision": 0.002792032906176061,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0026390683501261235,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0026390683501261235,
        "precision": 0.002357905521337981,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.0166904611693649,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0166904611693649,
        "precision": 0.013735278464095682,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001177441383906432,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.001177441383906432,
        "precision": 0.0007884626271599776,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.023196878661320298,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.023196878661320298,
        "precision": 0.02054448033995544,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.03318794826097815,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.03318794826097815,
        "precision": 0.02990103382426752,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.37109375,
        "f1": 0.3357155638745313,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.3357155638745313,
        "precision": 0.32506573463173877,
        "recall": 0.37109375
      },
      {
        "accuracy": 0.552734375,
        "f1": 0.5087776191205649,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5087776191205649,
        "precision": 0.4930383107018849,
        "recall": 0.552734375
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.08342641878684978,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08342641878684978,
        "precision": 0.078525656815652,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.423828125,
        "f1": 0.3824112017655479,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3824112017655479,
        "precision": 0.3696205768409297,
        "recall": 0.423828125
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.021868104598612756,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.021868104598612756,
        "precision": 0.016903427493092756,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.5224609375,
        "f1": 0.48203415643601194,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.48203415643601194,
        "precision": 0.46794444844470046,
        "recall": 0.5224609375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0052981668013049685,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0052981668013049685,
        "precision": 0.00511155819235589,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.2705078125,
        "f1": 0.24133482619810742,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.24133482619810742,
        "precision": 0.23225953733766233,
        "recall": 0.2705078125
      },
      {
        "accuracy": 0.28515625,
        "f1": 0.23239818295739348,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.23239818295739348,
        "precision": 0.21655826450748325,
        "recall": 0.28515625
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.13177428216436743,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.13177428216436743,
        "precision": 0.12087202519297949,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.15586096153751622,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.15586096153751622,
        "precision": 0.14316825860771173,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0022607537791509563,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0022607537791509563,
        "precision": 0.001737358154690016,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.18426726810515873,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.18426726810515873,
        "precision": 0.17102736402052807,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.011326788182256933,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.011326788182256933,
        "precision": 0.010629715185492801,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.2431640625,
        "f1": 0.22538293076548577,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.22538293076548577,
        "precision": 0.21953847576860452,
        "recall": 0.2431640625
      },
      {
        "accuracy": 0.1884765625,
        "f1": 0.1351894760727303,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.1351894760727303,
        "precision": 0.1211046379564446,
        "recall": 0.1884765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003234899108552332,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003234899108552332,
        "precision": 0.0022690890495482134,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.16931580915047484,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.16931580915047484,
        "precision": 0.159277746871775,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.2119140625,
        "f1": 0.1692072751812901,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1692072751812901,
        "precision": 0.1572725328387421,
        "recall": 0.2119140625
      },
      {
        "accuracy": 0.294921875,
        "f1": 0.269756549701886,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.269756549701886,
        "precision": 0.2610876994743059,
        "recall": 0.294921875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0023659286763994137,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0023659286763994137,
        "precision": 0.001518563187389075,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009084158815961817,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.009084158815961817,
        "precision": 0.0077685773200240615,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.17329908525910365,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.17329908525910365,
        "precision": 0.16908110119047617,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.18374662578930429,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.18374662578930429,
        "precision": 0.17903303026028633,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04469977273356966,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.04469977273356966,
        "precision": 0.04060599516965357,
        "recall": 0.0625
      },
      {
        "accuracy": 0.1943359375,
        "f1": 0.17634631170742754,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.17634631170742754,
        "precision": 0.17079003438995213,
        "recall": 0.1943359375
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.03144363576454989,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.03144363576454989,
        "precision": 0.02423129837680619,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.16730684244183786,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.16730684244183786,
        "precision": 0.16143469974036379,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012936938958323561,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.012936938958323561,
        "precision": 0.010705892130291658,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.16375830130400212,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.16375830130400212,
        "precision": 0.15775766117562995,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.012862723214285714,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.012862723214285714,
        "precision": 0.010998561751089325,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.15591789514698523,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.15591789514698523,
        "precision": 0.14833356866212172,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.011420867076312848,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.011420867076312848,
        "precision": 0.010429476165624398,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006539609370954465,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.006539609370954465,
        "precision": 0.005611756588319089,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.01282076335189797,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.01282076335189797,
        "precision": 0.011212559896323483,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007374615950124499,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.007374615950124499,
        "precision": 0.006447004705245287,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.18128184015994217,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.18128184015994217,
        "precision": 0.17572877561891231,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.01405226682475158,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.01405226682475158,
        "precision": 0.012083624520193592,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006989009796626984,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.006989009796626984,
        "precision": 0.005536566840277778,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.17187166391692546,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.17187166391692546,
        "precision": 0.1681205707821038,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.18167522391887628,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.18167522391887628,
        "precision": 0.175637550717039,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.15987955729166667,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.15987955729166667,
        "precision": 0.15502232142857142,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014420643336648632,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.0014420643336648632,
        "precision": 0.0012589109381230064,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0017767592234262126,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.0017767592234262126,
        "precision": 0.0014173425238093306,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.17200357465250948,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.17200357465250948,
        "precision": 0.16701481324171186,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.1752735162329664,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.1752735162329664,
        "precision": 0.16937703951493388,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.045787266643343316,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.045787266643343316,
        "precision": 0.041415361593260175,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.17620044111394556,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.17620044111394556,
        "precision": 0.17109875801282054,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.08624456056096681,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.08624456056096681,
        "precision": 0.0739762506565126,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.15195192689700562,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.15195192689700562,
        "precision": 0.14560779784882572,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09663956728524743,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.09663956728524743,
        "precision": 0.08636044323215997,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.17054537606911696,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.17054537606911696,
        "precision": 0.16394186580882353,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005530491643772893,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.005530491643772893,
        "precision": 0.004954147444919377,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.1973059275793651,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.1973059275793651,
        "precision": 0.18580147879464287,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003345959595959596,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.003345959595959596,
        "precision": 0.0027990400518760135,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.0380700276599999,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0380700276599999,
        "precision": 0.03354919487574477,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002820886571223317,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.002820886571223317,
        "precision": 0.00249420940221507,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.042406204057300625,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.042406204057300625,
        "precision": 0.037862085416370796,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.2353515625,
        "f1": 0.22002547978446757,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.22002547978446757,
        "precision": 0.21570304293592438,
        "recall": 0.2353515625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003950882829703145,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.003950882829703145,
        "precision": 0.003928864517008938,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.021268862430971806,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.021268862430971806,
        "precision": 0.017040520557430508,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.15804795984422057,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.15804795984422057,
        "precision": 0.15273948705849028,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.15958997674972114,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.15958997674972114,
        "precision": 0.15491875130337157,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.1651538164409624,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.1651538164409624,
        "precision": 0.1597687865779418,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006551275729519482,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.006551275729519482,
        "precision": 0.005272673290251414,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.017358550989225834,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.017358550989225834,
        "precision": 0.016119900734732996,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.2763671875,
        "f1": 0.2560018739229682,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.2560018739229682,
        "precision": 0.24973469022297146,
        "recall": 0.2763671875
      },
      {
        "accuracy": 0.302734375,
        "f1": 0.2790462021410285,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.2790462021410285,
        "precision": 0.27230808816767915,
        "recall": 0.302734375
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.06713422024222257,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.06713422024222257,
        "precision": 0.06252135653412894,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.251953125,
        "f1": 0.22785850219703194,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.22785850219703194,
        "precision": 0.22033476415800635,
        "recall": 0.251953125
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.016166522344634945,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.016166522344634945,
        "precision": 0.011749586876980743,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.27792305079902735,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.27792305079902735,
        "precision": 0.27085449878366685,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0013521063623934,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0013521063623934,
        "precision": 0.0008854463870292118,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.5849609375,
        "f1": 0.5322742280505952,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.5322742280505952,
        "precision": 0.5128545851934524,
        "recall": 0.5849609375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020838820516281498,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.020838820516281498,
        "precision": 0.01803530048501368,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.1299829807684767,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.1299829807684767,
        "precision": 0.11897183307237585,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.013982869052226154,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.013982869052226154,
        "precision": 0.01219036103576926,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001611063311562022,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.001611063311562022,
        "precision": 0.001148857815805647,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023110836465328653,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.023110836465328653,
        "precision": 0.020019547658954195,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0002692419893931707,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0002692419893931707,
        "precision": 0.00014137319262116986,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.2373046875,
        "f1": 0.2185431497500661,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.2185431497500661,
        "precision": 0.2124361963402946,
        "recall": 0.2373046875
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.017384303233062847,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.017384303233062847,
        "precision": 0.015713140969175164,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00119774893783187,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00119774893783187,
        "precision": 0.0010946217163064489,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.291015625,
        "f1": 0.27171384940088494,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.27171384940088494,
        "precision": 0.26620306753848544,
        "recall": 0.291015625
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.15226113883053222,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.15226113883053222,
        "precision": 0.14070963541666665,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.2021484375,
        "f1": 0.16780447735037576,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.16780447735037576,
        "precision": 0.15593335700757574,
        "recall": 0.2021484375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}