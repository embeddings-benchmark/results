{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.545833,
        "f1": 0.543476,
        "f1_weighted": 0.543476,
        "ap": 0.525603,
        "ap_weighted": 0.525603,
        "scores_per_experiment": [
          {
            "accuracy": 0.555,
            "f1": 0.554876,
            "f1_weighted": 0.554876,
            "ap": 0.530629,
            "ap_weighted": 0.530629
          },
          {
            "accuracy": 0.536667,
            "f1": 0.536151,
            "f1_weighted": 0.536151,
            "ap": 0.519594,
            "ap_weighted": 0.519594
          },
          {
            "accuracy": 0.556667,
            "f1": 0.55393,
            "f1_weighted": 0.55393,
            "ap": 0.53111,
            "ap_weighted": 0.53111
          },
          {
            "accuracy": 0.581667,
            "f1": 0.578741,
            "f1_weighted": 0.578741,
            "ap": 0.54655,
            "ap_weighted": 0.54655
          },
          {
            "accuracy": 0.580833,
            "f1": 0.580434,
            "f1_weighted": 0.580434,
            "ap": 0.54738,
            "ap_weighted": 0.54738
          },
          {
            "accuracy": 0.529167,
            "f1": 0.520536,
            "f1_weighted": 0.520536,
            "ap": 0.515254,
            "ap_weighted": 0.515254
          },
          {
            "accuracy": 0.516667,
            "f1": 0.516323,
            "f1_weighted": 0.516323,
            "ap": 0.508597,
            "ap_weighted": 0.508597
          },
          {
            "accuracy": 0.5225,
            "f1": 0.51743,
            "f1_weighted": 0.51743,
            "ap": 0.511887,
            "ap_weighted": 0.511887
          },
          {
            "accuracy": 0.578333,
            "f1": 0.576635,
            "f1_weighted": 0.576635,
            "ap": 0.544613,
            "ap_weighted": 0.544613
          },
          {
            "accuracy": 0.500833,
            "f1": 0.499705,
            "f1_weighted": 0.499705,
            "ap": 0.500417,
            "ap_weighted": 0.500417
          }
        ],
        "main_score": 0.545833,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.552333,
        "f1": 0.549841,
        "f1_weighted": 0.549841,
        "ap": 0.529801,
        "ap_weighted": 0.529801,
        "scores_per_experiment": [
          {
            "accuracy": 0.551667,
            "f1": 0.551487,
            "f1_weighted": 0.551487,
            "ap": 0.528614,
            "ap_weighted": 0.528614
          },
          {
            "accuracy": 0.538333,
            "f1": 0.53782,
            "f1_weighted": 0.53782,
            "ap": 0.520544,
            "ap_weighted": 0.520544
          },
          {
            "accuracy": 0.5825,
            "f1": 0.580774,
            "f1_weighted": 0.580774,
            "ap": 0.547282,
            "ap_weighted": 0.547282
          },
          {
            "accuracy": 0.599167,
            "f1": 0.595954,
            "f1_weighted": 0.595954,
            "ap": 0.557929,
            "ap_weighted": 0.557929
          },
          {
            "accuracy": 0.585833,
            "f1": 0.583842,
            "f1_weighted": 0.583842,
            "ap": 0.551467,
            "ap_weighted": 0.551467
          },
          {
            "accuracy": 0.525833,
            "f1": 0.519755,
            "f1_weighted": 0.519755,
            "ap": 0.513461,
            "ap_weighted": 0.513461
          },
          {
            "accuracy": 0.521667,
            "f1": 0.518961,
            "f1_weighted": 0.518961,
            "ap": 0.511242,
            "ap_weighted": 0.511242
          },
          {
            "accuracy": 0.523333,
            "f1": 0.518837,
            "f1_weighted": 0.518837,
            "ap": 0.512342,
            "ap_weighted": 0.512342
          },
          {
            "accuracy": 0.5925,
            "f1": 0.590986,
            "f1_weighted": 0.590986,
            "ap": 0.553878,
            "ap_weighted": 0.553878
          },
          {
            "accuracy": 0.5025,
            "f1": 0.499991,
            "f1_weighted": 0.499991,
            "ap": 0.501255,
            "ap_weighted": 0.501255
          }
        ],
        "main_score": 0.552333,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 21.221144676208496,
  "kg_co2_emissions": 0.0009597272396091318
}