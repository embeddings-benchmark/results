{
  "dataset_revision": "264a18480c529d9e922483839b4b9758e690b762",
  "evaluation_time": 1194.0840137004852,
  "kg_co2_emissions": 0.053906739905503015,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.08984375,
        "f1": 0.056727430555555555,
        "hf_subset": "eng_Latn-aai_Latn",
        "languages": [
          "eng-Latn",
          "aai-Latn"
        ],
        "main_score": 0.056727430555555555,
        "precision": 0.04867547392598344,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.0602182145717932,
        "hf_subset": "aai_Latn-eng_Latn",
        "languages": [
          "aai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0602182145717932,
        "precision": 0.056950138078067765,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "eng_Latn-aak_Arab",
        "languages": [
          "eng-Latn",
          "aak-Arab"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0027944711538461535,
        "hf_subset": "aak_Arab-eng_Latn",
        "languages": [
          "aak-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0027944711538461535,
        "precision": 0.001766392118863049,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02329050776830382,
        "hf_subset": "eng_Latn-aau_Latn",
        "languages": [
          "eng-Latn",
          "aau-Latn"
        ],
        "main_score": 0.02329050776830382,
        "precision": 0.02085832417863668,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010295438218390806,
        "hf_subset": "aau_Latn-eng_Latn",
        "languages": [
          "aau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010295438218390806,
        "precision": 0.009388790537766832,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.018275749135124135,
        "hf_subset": "eng_Latn-aaz_Latn",
        "languages": [
          "eng-Latn",
          "aaz-Latn"
        ],
        "main_score": 0.018275749135124135,
        "precision": 0.015479312354312356,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010720486111111111,
        "hf_subset": "aaz_Latn-eng_Latn",
        "languages": [
          "aaz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010720486111111111,
        "precision": 0.0085058170995671,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.017450539911477412,
        "hf_subset": "eng_Latn-abt_Latn",
        "languages": [
          "eng-Latn",
          "abt-Latn"
        ],
        "main_score": 0.017450539911477412,
        "precision": 0.012691084956709956,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014826980744949494,
        "hf_subset": "abt_Latn-eng_Latn",
        "languages": [
          "abt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014826980744949494,
        "precision": 0.013547281711344212,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024054439484126985,
        "hf_subset": "eng_Latn-abx_Latn",
        "languages": [
          "eng-Latn",
          "abx-Latn"
        ],
        "main_score": 0.024054439484126985,
        "precision": 0.019731212797619045,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022873606993851558,
        "hf_subset": "abx_Latn-eng_Latn",
        "languages": [
          "abx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022873606993851558,
        "precision": 0.019215054629806466,
        "recall": 0.046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "eng_Latn-aby_Latn",
        "languages": [
          "eng-Latn",
          "aby-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015024038461538462,
        "hf_subset": "aby_Latn-eng_Latn",
        "languages": [
          "aby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00015024038461538462,
        "precision": 7.659313725490196e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009498530982905984,
        "hf_subset": "eng_Latn-acf_Latn",
        "languages": [
          "eng-Latn",
          "acf-Latn"
        ],
        "main_score": 0.009498530982905984,
        "precision": 0.008707474158141519,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008913055603022708,
        "hf_subset": "acf_Latn-eng_Latn",
        "languages": [
          "acf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008913055603022708,
        "precision": 0.008385038536405723,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023850662852678978,
        "hf_subset": "eng_Latn-acr_Latn",
        "languages": [
          "eng-Latn",
          "acr-Latn"
        ],
        "main_score": 0.023850662852678978,
        "precision": 0.021215928243810786,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017541652077497662,
        "hf_subset": "acr_Latn-eng_Latn",
        "languages": [
          "acr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017541652077497662,
        "precision": 0.01545801648696821,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007161458333333332,
        "hf_subset": "eng_Latn-acu_Latn",
        "languages": [
          "eng-Latn",
          "acu-Latn"
        ],
        "main_score": 0.007161458333333332,
        "precision": 0.005208333333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0033613445378151263,
        "hf_subset": "acu_Latn-eng_Latn",
        "languages": [
          "acu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0033613445378151263,
        "precision": 0.001955211672008547,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.0563058310676451,
        "hf_subset": "eng_Latn-adz_Latn",
        "languages": [
          "eng-Latn",
          "adz-Latn"
        ],
        "main_score": 0.0563058310676451,
        "precision": 0.05101066468253968,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03851356976356977,
        "hf_subset": "adz_Latn-eng_Latn",
        "languages": [
          "adz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03851356976356977,
        "precision": 0.03600248426949049,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029882812499999994,
        "hf_subset": "eng_Latn-aer_Latn",
        "languages": [
          "eng-Latn",
          "aer-Latn"
        ],
        "main_score": 0.029882812499999994,
        "precision": 0.026892138092885376,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014210343228200372,
        "hf_subset": "aer_Latn-eng_Latn",
        "languages": [
          "aer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014210343228200372,
        "precision": 0.013146794819525985,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011868990384615384,
        "hf_subset": "eng_Latn-aey_Latn",
        "languages": [
          "eng-Latn",
          "aey-Latn"
        ],
        "main_score": 0.011868990384615384,
        "precision": 0.009842218137254902,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004906124381570811,
        "hf_subset": "aey_Latn-eng_Latn",
        "languages": [
          "aey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004906124381570811,
        "precision": 0.004444462835451977,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007421875,
        "hf_subset": "eng_Latn-agd_Latn",
        "languages": [
          "eng-Latn",
          "agd-Latn"
        ],
        "main_score": 0.007421875,
        "precision": 0.004949831495098039,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "agd_Latn-eng_Latn",
        "languages": [
          "agd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015885416666666666,
        "hf_subset": "eng_Latn-agg_Latn",
        "languages": [
          "eng-Latn",
          "agg-Latn"
        ],
        "main_score": 0.015885416666666666,
        "precision": 0.013346354166666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004747840447154471,
        "hf_subset": "agg_Latn-eng_Latn",
        "languages": [
          "agg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004747840447154471,
        "precision": 0.0033528645833333336,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010132575757575757,
        "hf_subset": "eng_Latn-agm_Latn",
        "languages": [
          "eng-Latn",
          "agm-Latn"
        ],
        "main_score": 0.010132575757575757,
        "precision": 0.008368598090277778,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0013287388854425143,
        "hf_subset": "agm_Latn-eng_Latn",
        "languages": [
          "agm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013287388854425143,
        "precision": 0.0007389745670995671,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01909722222222222,
        "hf_subset": "eng_Latn-agn_Latn",
        "languages": [
          "eng-Latn",
          "agn-Latn"
        ],
        "main_score": 0.01909722222222222,
        "precision": 0.015736607142857142,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02070532332251082,
        "hf_subset": "agn_Latn-eng_Latn",
        "languages": [
          "agn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02070532332251082,
        "precision": 0.017683716620249014,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015885416666666666,
        "hf_subset": "eng_Latn-agr_Latn",
        "languages": [
          "eng-Latn",
          "agr-Latn"
        ],
        "main_score": 0.015885416666666666,
        "precision": 0.012044270833333332,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00840071386946387,
        "hf_subset": "agr_Latn-eng_Latn",
        "languages": [
          "agr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00840071386946387,
        "precision": 0.007003373660510716,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013372987689393939,
        "hf_subset": "eng_Latn-agt_Latn",
        "languages": [
          "eng-Latn",
          "agt-Latn"
        ],
        "main_score": 0.013372987689393939,
        "precision": 0.011408730158730158,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009521209839357428,
        "hf_subset": "agt_Latn-eng_Latn",
        "languages": [
          "agt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009521209839357428,
        "precision": 0.007726969581485587,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021355142009987515,
        "hf_subset": "eng_Latn-agu_Latn",
        "languages": [
          "eng-Latn",
          "agu-Latn"
        ],
        "main_score": 0.021355142009987515,
        "precision": 0.01980541861631016,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014436141304347824,
        "hf_subset": "agu_Latn-eng_Latn",
        "languages": [
          "agu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014436141304347824,
        "precision": 0.011255361519607841,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01246995192307692,
        "hf_subset": "eng_Latn-aia_Latn",
        "languages": [
          "eng-Latn",
          "aia-Latn"
        ],
        "main_score": 0.01246995192307692,
        "precision": 0.009911823830409358,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00959934163059163,
        "hf_subset": "aia_Latn-eng_Latn",
        "languages": [
          "aia-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00959934163059163,
        "precision": 0.007351872435020519,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013680875576036866,
        "hf_subset": "eng_Latn-aii_Syrc",
        "languages": [
          "eng-Latn",
          "aii-Syrc"
        ],
        "main_score": 0.0013680875576036866,
        "precision": 0.0007812499999999999,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0024135127535862833,
        "hf_subset": "aii_Syrc-eng_Latn",
        "languages": [
          "aii-Syrc",
          "eng-Latn"
        ],
        "main_score": 0.0024135127535862833,
        "precision": 0.0013495710784313724,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02547554347826087,
        "hf_subset": "eng_Latn-aka_Latn",
        "languages": [
          "eng-Latn",
          "aka-Latn"
        ],
        "main_score": 0.02547554347826087,
        "precision": 0.022318830429438982,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013268849206349206,
        "hf_subset": "aka_Latn-eng_Latn",
        "languages": [
          "aka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013268849206349206,
        "precision": 0.011427696078431374,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004603519477317554,
        "hf_subset": "eng_Latn-ake_Latn",
        "languages": [
          "eng-Latn",
          "ake-Latn"
        ],
        "main_score": 0.004603519477317554,
        "precision": 0.003278459821428571,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007571897644927536,
        "hf_subset": "ake_Latn-eng_Latn",
        "languages": [
          "ake-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007571897644927536,
        "precision": 0.006460336538461538,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012214429450757576,
        "hf_subset": "eng_Latn-alp_Latn",
        "languages": [
          "eng-Latn",
          "alp-Latn"
        ],
        "main_score": 0.012214429450757576,
        "precision": 0.009426603302611367,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0024821928524374178,
        "hf_subset": "alp_Latn-eng_Latn",
        "languages": [
          "alp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0024821928524374178,
        "precision": 0.0013516305709769451,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01752888655462185,
        "hf_subset": "eng_Latn-alq_Latn",
        "languages": [
          "eng-Latn",
          "alq-Latn"
        ],
        "main_score": 0.01752888655462185,
        "precision": 0.015523018648018647,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015399128401360544,
        "hf_subset": "alq_Latn-eng_Latn",
        "languages": [
          "alq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015399128401360544,
        "precision": 0.013242900970319636,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023579545454545454,
        "hf_subset": "eng_Latn-als_Latn",
        "languages": [
          "eng-Latn",
          "als-Latn"
        ],
        "main_score": 0.023579545454545454,
        "precision": 0.021157210122053873,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00629308883363472,
        "hf_subset": "als_Latn-eng_Latn",
        "languages": [
          "als-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00629308883363472,
        "precision": 0.003956330128205128,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03093906772575251,
        "hf_subset": "eng_Latn-aly_Latn",
        "languages": [
          "eng-Latn",
          "aly-Latn"
        ],
        "main_score": 0.03093906772575251,
        "precision": 0.02677004419191919,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01645096801346801,
        "hf_subset": "aly_Latn-eng_Latn",
        "languages": [
          "aly-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01645096801346801,
        "precision": 0.013333834134615384,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005034722222222222,
        "hf_subset": "eng_Latn-ame_Latn",
        "languages": [
          "eng-Latn",
          "ame-Latn"
        ],
        "main_score": 0.005034722222222222,
        "precision": 0.00341796875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008101851851851851,
        "hf_subset": "ame_Latn-eng_Latn",
        "languages": [
          "ame-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008101851851851851,
        "precision": 0.007962740384615384,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010026041666666666,
        "hf_subset": "eng_Latn-amf_Latn",
        "languages": [
          "eng-Latn",
          "amf-Latn"
        ],
        "main_score": 0.010026041666666666,
        "precision": 0.008138020833333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00026041666666666666,
        "hf_subset": "amf_Latn-eng_Latn",
        "languages": [
          "amf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00026041666666666666,
        "precision": 0.0001328344863977486,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01550489937217626,
        "hf_subset": "eng_Latn-amk_Latn",
        "languages": [
          "eng-Latn",
          "amk-Latn"
        ],
        "main_score": 0.01550489937217626,
        "precision": 0.013129340277777776,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010011892043142043,
        "hf_subset": "amk_Latn-eng_Latn",
        "languages": [
          "amk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010011892043142043,
        "precision": 0.00911911298643868,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-amm_Latn",
        "languages": [
          "eng-Latn",
          "amm-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003094333172458172,
        "hf_subset": "amm_Latn-eng_Latn",
        "languages": [
          "amm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003094333172458172,
        "precision": 0.00220630787037037,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013825537008281572,
        "hf_subset": "eng_Latn-amn_Latn",
        "languages": [
          "eng-Latn",
          "amn-Latn"
        ],
        "main_score": 0.013825537008281572,
        "precision": 0.011776378090111643,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005838660037878788,
        "hf_subset": "amn_Latn-eng_Latn",
        "languages": [
          "amn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005838660037878788,
        "precision": 0.00502025462962963,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013484515182884748,
        "hf_subset": "eng_Latn-amo_Latn",
        "languages": [
          "eng-Latn",
          "amo-Latn"
        ],
        "main_score": 0.013484515182884748,
        "precision": 0.011497663123167155,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011064593301435405,
        "hf_subset": "amo_Latn-eng_Latn",
        "languages": [
          "amo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011064593301435405,
        "precision": 0.010104709201388888,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015828425785207698,
        "hf_subset": "eng_Latn-amp_Latn",
        "languages": [
          "eng-Latn",
          "amp-Latn"
        ],
        "main_score": 0.015828425785207698,
        "precision": 0.014491302025269418,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0001575164640324215,
        "hf_subset": "amp_Latn-eng_Latn",
        "languages": [
          "amp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001575164640324215,
        "precision": 7.956278432588917e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015950520833333332,
        "hf_subset": "eng_Latn-amr_Latn",
        "languages": [
          "eng-Latn",
          "amr-Latn"
        ],
        "main_score": 0.015950520833333332,
        "precision": 0.013578869047619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01023253367003367,
        "hf_subset": "amr_Latn-eng_Latn",
        "languages": [
          "amr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01023253367003367,
        "precision": 0.008117533508158508,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.017630828373015873,
        "hf_subset": "eng_Latn-amu_Latn",
        "languages": [
          "eng-Latn",
          "amu-Latn"
        ],
        "main_score": 0.017630828373015873,
        "precision": 0.01382820355706385,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019590435606060608,
        "hf_subset": "amu_Latn-eng_Latn",
        "languages": [
          "amu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019590435606060608,
        "precision": 0.017317708333333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.07950804746240601,
        "hf_subset": "eng_Latn-amx_Latn",
        "languages": [
          "eng-Latn",
          "amx-Latn"
        ],
        "main_score": 0.07950804746240601,
        "precision": 0.07237584962194338,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07626402907177363,
        "hf_subset": "amx_Latn-eng_Latn",
        "languages": [
          "amx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07626402907177363,
        "precision": 0.07001015234863966,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.06306306306306306,
        "f1": 0.05268905268905269,
        "hf_subset": "eng_Latn-anh_Latn",
        "languages": [
          "eng-Latn",
          "anh-Latn"
        ],
        "main_score": 0.05268905268905269,
        "precision": 0.05045045045045045,
        "recall": 0.06306306306306306
      },
      {
        "accuracy": 0.04504504504504504,
        "f1": 0.028837661190602368,
        "hf_subset": "anh_Latn-eng_Latn",
        "languages": [
          "anh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028837661190602368,
        "precision": 0.02798178613396005,
        "recall": 0.04504504504504504
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009578518907563024,
        "hf_subset": "eng_Latn-anv_Latn",
        "languages": [
          "eng-Latn",
          "anv-Latn"
        ],
        "main_score": 0.009578518907563024,
        "precision": 0.007508442078754579,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005145465647652065,
        "hf_subset": "anv_Latn-eng_Latn",
        "languages": [
          "anv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005145465647652065,
        "precision": 0.004580823293172691,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004246386054421769,
        "hf_subset": "eng_Latn-aoi_Latn",
        "languages": [
          "eng-Latn",
          "aoi-Latn"
        ],
        "main_score": 0.004246386054421769,
        "precision": 0.002969958118556701,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00451078869047619,
        "hf_subset": "aoi_Latn-eng_Latn",
        "languages": [
          "aoi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00451078869047619,
        "precision": 0.004220762882447665,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022557226015406162,
        "hf_subset": "eng_Latn-aoj_Latn",
        "languages": [
          "eng-Latn",
          "aoj-Latn"
        ],
        "main_score": 0.022557226015406162,
        "precision": 0.01806425461975835,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012363416495747404,
        "hf_subset": "aoj_Latn-eng_Latn",
        "languages": [
          "aoj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012363416495747404,
        "precision": 0.009636640692069886,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.06166397982804232,
        "hf_subset": "eng_Latn-aom_Latn",
        "languages": [
          "eng-Latn",
          "aom-Latn"
        ],
        "main_score": 0.06166397982804232,
        "precision": 0.058148752289377284,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03800590826745718,
        "hf_subset": "aom_Latn-eng_Latn",
        "languages": [
          "aom-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03800590826745718,
        "precision": 0.03593240004079967,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0033082938943207827,
        "hf_subset": "eng_Latn-aon_Latn",
        "languages": [
          "eng-Latn",
          "aon-Latn"
        ],
        "main_score": 0.0033082938943207827,
        "precision": 0.001906105324074074,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005732586772983115,
        "hf_subset": "aon_Latn-eng_Latn",
        "languages": [
          "aon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005732586772983115,
        "precision": 0.00501762699525453,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009926514607279693,
        "hf_subset": "eng_Latn-apb_Latn",
        "languages": [
          "eng-Latn",
          "apb-Latn"
        ],
        "main_score": 0.009926514607279693,
        "precision": 0.008998325892857144,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016369047619047617,
        "hf_subset": "apb_Latn-eng_Latn",
        "languages": [
          "apb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016369047619047617,
        "precision": 0.0009300595238095238,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.01609772605866356,
        "hf_subset": "eng_Latn-ape_Latn",
        "languages": [
          "eng-Latn",
          "ape-Latn"
        ],
        "main_score": 0.01609772605866356,
        "precision": 0.011820991105772453,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012189299529965648,
        "hf_subset": "ape_Latn-eng_Latn",
        "languages": [
          "ape-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012189299529965648,
        "precision": 0.009409204162750626,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0017045454545454547,
        "hf_subset": "eng_Latn-apn_Latn",
        "languages": [
          "eng-Latn",
          "apn-Latn"
        ],
        "main_score": 0.0017045454545454547,
        "precision": 0.0010489004629629629,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.702554744525547e-05,
        "hf_subset": "apn_Latn-eng_Latn",
        "languages": [
          "apn-Latn",
          "eng-Latn"
        ],
        "main_score": 5.702554744525547e-05,
        "precision": 2.8722426470588235e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016942766690009336,
        "hf_subset": "eng_Latn-apr_Latn",
        "languages": [
          "eng-Latn",
          "apr-Latn"
        ],
        "main_score": 0.016942766690009336,
        "precision": 0.014869500155472637,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.139802631578947e-05,
        "hf_subset": "apr_Latn-eng_Latn",
        "languages": [
          "apr-Latn",
          "eng-Latn"
        ],
        "main_score": 5.139802631578947e-05,
        "precision": 2.5869205298013245e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "eng_Latn-apu_Latn",
        "languages": [
          "eng-Latn",
          "apu-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0016724537037037038,
        "hf_subset": "apu_Latn-eng_Latn",
        "languages": [
          "apu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016724537037037038,
        "precision": 0.0009731615360696517,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.06816954746642247,
        "hf_subset": "eng_Latn-apw_Latn",
        "languages": [
          "eng-Latn",
          "apw-Latn"
        ],
        "main_score": 0.06816954746642247,
        "precision": 0.0599619391025641,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.078125,
        "f1": 0.06052066954926625,
        "hf_subset": "apw_Latn-eng_Latn",
        "languages": [
          "apw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06052066954926625,
        "precision": 0.05622746394230769,
        "recall": 0.078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003720238095238095,
        "hf_subset": "eng_Latn-apz_Latn",
        "languages": [
          "eng-Latn",
          "apz-Latn"
        ],
        "main_score": 0.0003720238095238095,
        "precision": 0.0001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00396499060150376,
        "hf_subset": "apz_Latn-eng_Latn",
        "languages": [
          "apz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00396499060150376,
        "precision": 0.003935842803030303,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008696056547619048,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ],
        "main_score": 0.008696056547619048,
        "precision": 0.006808035714285714,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0005499268560458005,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0005499268560458005,
        "precision": 0.0002821180555555556,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07857142857142857,
        "hf_subset": "eng_Latn-are_Latn",
        "languages": [
          "eng-Latn",
          "are-Latn"
        ],
        "main_score": 0.07857142857142857,
        "precision": 0.07454131788439596,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.07142147775423728,
        "hf_subset": "are_Latn-eng_Latn",
        "languages": [
          "are-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07142147775423728,
        "precision": 0.0676826765188834,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006676130330445124,
        "hf_subset": "eng_Latn-arl_Latn",
        "languages": [
          "eng-Latn",
          "arl-Latn"
        ],
        "main_score": 0.006676130330445124,
        "precision": 0.004696524100396383,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013933722527472527,
        "hf_subset": "arl_Latn-eng_Latn",
        "languages": [
          "arl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013933722527472527,
        "precision": 0.012984929204805491,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005947283348457349,
        "hf_subset": "eng_Latn-arn_Latn",
        "languages": [
          "eng-Latn",
          "arn-Latn"
        ],
        "main_score": 0.005947283348457349,
        "precision": 0.005133793780193237,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004005142405063291,
        "hf_subset": "arn_Latn-eng_Latn",
        "languages": [
          "arn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004005142405063291,
        "precision": 0.003956330128205128,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.12903225806451613,
        "f1": 0.0724910394265233,
        "hf_subset": "eng_Latn-arp_Latn",
        "languages": [
          "eng-Latn",
          "arp-Latn"
        ],
        "main_score": 0.0724910394265233,
        "precision": 0.05998075998075997,
        "recall": 0.12903225806451613
      },
      {
        "accuracy": 0.17204301075268819,
        "f1": 0.12630824372759855,
        "hf_subset": "arp_Latn-eng_Latn",
        "languages": [
          "arp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12630824372759855,
        "precision": 0.11987579326289004,
        "recall": 0.17204301075268819
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009765625,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.009765625,
        "precision": 0.007942708333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006081321022727272,
        "hf_subset": "eng_Latn-aso_Latn",
        "languages": [
          "eng-Latn",
          "aso-Latn"
        ],
        "main_score": 0.006081321022727272,
        "precision": 0.00437998670212766,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007102272727272727,
        "hf_subset": "aso_Latn-eng_Latn",
        "languages": [
          "aso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007102272727272727,
        "precision": 0.000390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007626488095238094,
        "hf_subset": "eng_Latn-ata_Latn",
        "languages": [
          "eng-Latn",
          "ata-Latn"
        ],
        "main_score": 0.007626488095238094,
        "precision": 0.005208333333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003255208333333333,
        "hf_subset": "ata_Latn-eng_Latn",
        "languages": [
          "ata-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003255208333333333,
        "precision": 0.0020833333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015488352793040294,
        "hf_subset": "eng_Latn-atb_Latn",
        "languages": [
          "eng-Latn",
          "atb-Latn"
        ],
        "main_score": 0.015488352793040294,
        "precision": 0.012709668803418804,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005837673611111111,
        "hf_subset": "atb_Latn-eng_Latn",
        "languages": [
          "atb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005837673611111111,
        "precision": 0.005017439668174962,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011017628205128204,
        "hf_subset": "eng_Latn-atd_Latn",
        "languages": [
          "eng-Latn",
          "atd-Latn"
        ],
        "main_score": 0.011017628205128204,
        "precision": 0.010091145833333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008463541666666666,
        "hf_subset": "atd_Latn-eng_Latn",
        "languages": [
          "atd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008463541666666666,
        "precision": 0.007161458333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-atg_Latn",
        "languages": [
          "eng-Latn",
          "atg-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.006344696969696969,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00390625,
        "hf_subset": "atg_Latn-eng_Latn",
        "languages": [
          "atg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.002734375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012867254273504273,
        "hf_subset": "eng_Latn-att_Latn",
        "languages": [
          "eng-Latn",
          "att-Latn"
        ],
        "main_score": 0.012867254273504273,
        "precision": 0.009814167580409356,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.25e-05,
        "hf_subset": "att_Latn-eng_Latn",
        "languages": [
          "att-Latn",
          "eng-Latn"
        ],
        "main_score": 6.25e-05,
        "precision": 3.150201612903226e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030153508771929823,
        "hf_subset": "eng_Latn-auc_Latn",
        "languages": [
          "eng-Latn",
          "auc-Latn"
        ],
        "main_score": 0.0030153508771929823,
        "precision": 0.002170138888888889,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00012600806451612903,
        "hf_subset": "auc_Latn-eng_Latn",
        "languages": [
          "auc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00012600806451612903,
        "precision": 6.403688524590164e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07038070436507936,
        "hf_subset": "eng_Latn-aui_Latn",
        "languages": [
          "eng-Latn",
          "aui-Latn"
        ],
        "main_score": 0.07038070436507936,
        "precision": 0.06507876888736264,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.034230661916208785,
        "hf_subset": "aui_Latn-eng_Latn",
        "languages": [
          "aui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.034230661916208785,
        "precision": 0.02963035788136595,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0038039434523809523,
        "hf_subset": "eng_Latn-auy_Latn",
        "languages": [
          "eng-Latn",
          "auy-Latn"
        ],
        "main_score": 0.0038039434523809523,
        "precision": 0.002626050420168067,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0005298466761447201,
        "hf_subset": "auy_Latn-eng_Latn",
        "languages": [
          "auy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005298466761447201,
        "precision": 0.0002717391304347826,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017664930555555555,
        "hf_subset": "eng_Latn-avt_Latn",
        "languages": [
          "eng-Latn",
          "avt-Latn"
        ],
        "main_score": 0.017664930555555555,
        "precision": 0.014290364583333333,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005062692144165358,
        "hf_subset": "avt_Latn-eng_Latn",
        "languages": [
          "avt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005062692144165358,
        "precision": 0.004555286852322934,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-awb_Latn",
        "languages": [
          "eng-Latn",
          "awb-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0015396471088435374,
        "hf_subset": "awb_Latn-eng_Latn",
        "languages": [
          "awb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015396471088435374,
        "precision": 0.000902087279040404,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.06060606060606061,
        "f1": 0.05454545454545455,
        "hf_subset": "eng_Latn-awk_Latn",
        "languages": [
          "eng-Latn",
          "awk-Latn"
        ],
        "main_score": 0.05454545454545455,
        "precision": 0.05303030303030303,
        "recall": 0.06060606060606061
      },
      {
        "accuracy": 0.030303030303030304,
        "f1": 0.023569023569023566,
        "hf_subset": "awk_Latn-eng_Latn",
        "languages": [
          "awk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023569023569023566,
        "precision": 0.022222222222222223,
        "recall": 0.030303030303030304
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.13329903603341103,
        "hf_subset": "eng_Latn-awx_Latn",
        "languages": [
          "eng-Latn",
          "awx-Latn"
        ],
        "main_score": 0.13329903603341103,
        "precision": 0.11910807291666668,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08473524305555555,
        "hf_subset": "awx_Latn-eng_Latn",
        "languages": [
          "awx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08473524305555555,
        "precision": 0.0768107335624928,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.007516275212736611,
        "hf_subset": "eng_Latn-azb_Arab",
        "languages": [
          "eng-Latn",
          "azb-Arab"
        ],
        "main_score": 0.007516275212736611,
        "precision": 0.004615593905472636,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0031804647718370544,
        "hf_subset": "azb_Arab-eng_Latn",
        "languages": [
          "azb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0031804647718370544,
        "precision": 0.0022485977564102562,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009220271915584416,
        "hf_subset": "eng_Latn-azg_Latn",
        "languages": [
          "eng-Latn",
          "azg-Latn"
        ],
        "main_score": 0.009220271915584416,
        "precision": 0.007190168866459627,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011761441256830601,
        "hf_subset": "azg_Latn-eng_Latn",
        "languages": [
          "azg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011761441256830601,
        "precision": 0.011740212912087912,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007260350738396624,
        "hf_subset": "eng_Latn-azz_Latn",
        "languages": [
          "eng-Latn",
          "azz-Latn"
        ],
        "main_score": 0.007260350738396624,
        "precision": 0.006039663461538461,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008370535714285714,
        "hf_subset": "azz_Latn-eng_Latn",
        "languages": [
          "azz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008370535714285714,
        "precision": 0.006941105769230769,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018146851053639845,
        "hf_subset": "eng_Latn-bao_Latn",
        "languages": [
          "eng-Latn",
          "bao-Latn"
        ],
        "main_score": 0.018146851053639845,
        "precision": 0.016278423749882726,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013110632183908046,
        "hf_subset": "bao_Latn-eng_Latn",
        "languages": [
          "bao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013110632183908046,
        "precision": 0.011764171511627907,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003515625,
        "hf_subset": "eng_Latn-bba_Latn",
        "languages": [
          "eng-Latn",
          "bba-Latn"
        ],
        "main_score": 0.003515625,
        "precision": 0.002278645833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0011067708333333333,
        "hf_subset": "bba_Latn-eng_Latn",
        "languages": [
          "bba-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011067708333333333,
        "precision": 0.0006006525262687234,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-bbb_Latn",
        "languages": [
          "eng-Latn",
          "bbb-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004026442307692307,
        "hf_subset": "bbb_Latn-eng_Latn",
        "languages": [
          "bbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004026442307692307,
        "precision": 0.00396728515625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011510131232538147,
        "hf_subset": "eng_Latn-bbr_Latn",
        "languages": [
          "eng-Latn",
          "bbr-Latn"
        ],
        "main_score": 0.011510131232538147,
        "precision": 0.008906533061594203,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004409345975232197,
        "hf_subset": "bbr_Latn-eng_Latn",
        "languages": [
          "bbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004409345975232197,
        "precision": 0.004169766865079365,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02286562220304309,
        "hf_subset": "eng_Latn-bch_Latn",
        "languages": [
          "eng-Latn",
          "bch-Latn"
        ],
        "main_score": 0.02286562220304309,
        "precision": 0.01947437328296703,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009142866750358681,
        "hf_subset": "bch_Latn-eng_Latn",
        "languages": [
          "bch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009142866750358681,
        "precision": 0.0075173367887113865,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024701340326340325,
        "hf_subset": "eng_Latn-bco_Latn",
        "languages": [
          "eng-Latn",
          "bco-Latn"
        ],
        "main_score": 0.024701340326340325,
        "precision": 0.021869736872462166,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00012600806451612903,
        "hf_subset": "bco_Latn-eng_Latn",
        "languages": [
          "bco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00012600806451612903,
        "precision": 6.403688524590164e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010042871315192744,
        "hf_subset": "eng_Latn-bdd_Latn",
        "languages": [
          "eng-Latn",
          "bdd-Latn"
        ],
        "main_score": 0.010042871315192744,
        "precision": 0.007568359375,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008524759306009306,
        "hf_subset": "bdd_Latn-eng_Latn",
        "languages": [
          "bdd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008524759306009306,
        "precision": 0.008188430908893238,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.15333333333333332,
        "f1": 0.09914333814333813,
        "hf_subset": "eng_Latn-bea_Latn",
        "languages": [
          "eng-Latn",
          "bea-Latn"
        ],
        "main_score": 0.09914333814333813,
        "precision": 0.08697416744475568,
        "recall": 0.15333333333333332
      },
      {
        "accuracy": 0.10666666666666667,
        "f1": 0.061611111111111116,
        "hf_subset": "bea_Latn-eng_Latn",
        "languages": [
          "bea-Latn",
          "eng-Latn"
        ],
        "main_score": 0.061611111111111116,
        "precision": 0.05040096618357488,
        "recall": 0.10666666666666667
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-bef_Latn",
        "languages": [
          "eng-Latn",
          "bef-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010850694444444445,
        "hf_subset": "bef_Latn-eng_Latn",
        "languages": [
          "bef-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010850694444444445,
        "precision": 0.0005848930481283422,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.031820436507936506,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ],
        "main_score": 0.031820436507936506,
        "precision": 0.026204427083333336,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.006689190898543949,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.006689190898543949,
        "precision": 0.005439028735184164,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011017628205128204,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.011017628205128204,
        "precision": 0.0087890625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0037571362684483446,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0037571362684483446,
        "precision": 0.0024016203703703704,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008463541666666666,
        "hf_subset": "eng_Latn-beo_Latn",
        "languages": [
          "eng-Latn",
          "beo-Latn"
        ],
        "main_score": 0.008463541666666666,
        "precision": 0.007161458333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002992729543740573,
        "hf_subset": "beo_Latn-eng_Latn",
        "languages": [
          "beo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002992729543740573,
        "precision": 0.0017689732142857142,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03362695890503094,
        "hf_subset": "eng_Latn-beu_Latn",
        "languages": [
          "eng-Latn",
          "beu-Latn"
        ],
        "main_score": 0.03362695890503094,
        "precision": 0.029992014316502464,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.015374432767524874,
        "hf_subset": "beu_Latn-eng_Latn",
        "languages": [
          "beu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015374432767524874,
        "precision": 0.01257719573336581,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015624999999999998,
        "hf_subset": "eng_Latn-bgs_Latn",
        "languages": [
          "eng-Latn",
          "bgs-Latn"
        ],
        "main_score": 0.015624999999999998,
        "precision": 0.0125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014417043172690762,
        "hf_subset": "bgs_Latn-eng_Latn",
        "languages": [
          "bgs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014417043172690762,
        "precision": 0.011766387195121951,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014863568604171654,
        "hf_subset": "eng_Latn-bgt_Latn",
        "languages": [
          "eng-Latn",
          "bgt-Latn"
        ],
        "main_score": 0.014863568604171654,
        "precision": 0.012533608969155844,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017795138888888888,
        "hf_subset": "bgt_Latn-eng_Latn",
        "languages": [
          "bgt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017795138888888888,
        "precision": 0.01689453125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.140625,
        "f1": 0.09533448322510824,
        "hf_subset": "eng_Latn-bhg_Latn",
        "languages": [
          "eng-Latn",
          "bhg-Latn"
        ],
        "main_score": 0.09533448322510824,
        "precision": 0.08583754208754209,
        "recall": 0.140625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07372736855158729,
        "hf_subset": "bhg_Latn-eng_Latn",
        "languages": [
          "bhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07372736855158729,
        "precision": 0.07082572375541125,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02044270833333333,
        "hf_subset": "eng_Latn-bhl_Latn",
        "languages": [
          "eng-Latn",
          "bhl-Latn"
        ],
        "main_score": 0.02044270833333333,
        "precision": 0.016415550595238096,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.5687134502923974e-05,
        "hf_subset": "bhl_Latn-eng_Latn",
        "languages": [
          "bhl-Latn",
          "eng-Latn"
        ],
        "main_score": 4.5687134502923974e-05,
        "precision": 2.2977941176470588e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-big_Latn",
        "languages": [
          "eng-Latn",
          "big-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.002734375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003508839950372209,
        "hf_subset": "big_Latn-eng_Latn",
        "languages": [
          "big-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003508839950372209,
        "precision": 0.00018161525974025975,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007213364042566629,
        "hf_subset": "eng_Latn-bjk_Latn",
        "languages": [
          "eng-Latn",
          "bjk-Latn"
        ],
        "main_score": 0.007213364042566629,
        "precision": 0.004811690301120448,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00621936274509804,
        "hf_subset": "bjk_Latn-eng_Latn",
        "languages": [
          "bjk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00621936274509804,
        "precision": 0.005280201569264069,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006045386904761905,
        "hf_subset": "eng_Latn-bjp_Latn",
        "languages": [
          "eng-Latn",
          "bjp-Latn"
        ],
        "main_score": 0.006045386904761905,
        "precision": 0.005117595818815331,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004309526821862348,
        "hf_subset": "bjp_Latn-eng_Latn",
        "languages": [
          "bjp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004309526821862348,
        "precision": 0.004114583333333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006510416666666666,
        "hf_subset": "eng_Latn-bjr_Latn",
        "languages": [
          "eng-Latn",
          "bjr-Latn"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.0003551136363636364,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.963740458015267e-05,
        "hf_subset": "bjr_Latn-eng_Latn",
        "languages": [
          "bjr-Latn",
          "eng-Latn"
        ],
        "main_score": 5.963740458015267e-05,
        "precision": 3.0048076923076925e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02147850975975976,
        "hf_subset": "eng_Latn-bjv_Latn",
        "languages": [
          "eng-Latn",
          "bjv-Latn"
        ],
        "main_score": 0.02147850975975976,
        "precision": 0.019573608325906117,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006864931533340286,
        "hf_subset": "bjv_Latn-eng_Latn",
        "languages": [
          "bjv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006864931533340286,
        "precision": 0.00554204273421325,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01260361817002442,
        "hf_subset": "eng_Latn-bjz_Latn",
        "languages": [
          "eng-Latn",
          "bjz-Latn"
        ],
        "main_score": 0.01260361817002442,
        "precision": 0.010669327871308705,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00011160714285714285,
        "hf_subset": "bjz_Latn-eng_Latn",
        "languages": [
          "bjz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00011160714285714285,
        "precision": 5.661231884057971e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015120525608375776,
        "hf_subset": "eng_Latn-bkd_Latn",
        "languages": [
          "eng-Latn",
          "bkd-Latn"
        ],
        "main_score": 0.015120525608375776,
        "precision": 0.01297636327413479,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014694940476190476,
        "hf_subset": "bkd_Latn-eng_Latn",
        "languages": [
          "bkd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014694940476190476,
        "precision": 0.012670272435897436,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006649925595238094,
        "hf_subset": "eng_Latn-bki_Latn",
        "languages": [
          "eng-Latn",
          "bki-Latn"
        ],
        "main_score": 0.006649925595238094,
        "precision": 0.004727128623188406,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003364206259426848,
        "hf_subset": "bki_Latn-eng_Latn",
        "languages": [
          "bki-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003364206259426848,
        "precision": 0.002353515625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015628829656862745,
        "hf_subset": "eng_Latn-bkq_Latn",
        "languages": [
          "eng-Latn",
          "bkq-Latn"
        ],
        "main_score": 0.015628829656862745,
        "precision": 0.014371289517773892,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014510680857487922,
        "hf_subset": "bkq_Latn-eng_Latn",
        "languages": [
          "bkq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014510680857487922,
        "precision": 0.0134570055171278,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03475779428904429,
        "hf_subset": "eng_Latn-bkx_Latn",
        "languages": [
          "eng-Latn",
          "bkx-Latn"
        ],
        "main_score": 0.03475779428904429,
        "precision": 0.030230034722222222,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.020818236714975843,
        "hf_subset": "bkx_Latn-eng_Latn",
        "languages": [
          "bkx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020818236714975843,
        "precision": 0.016216458174178765,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007676866319444445,
        "hf_subset": "eng_Latn-blw_Latn",
        "languages": [
          "eng-Latn",
          "blw-Latn"
        ],
        "main_score": 0.007676866319444445,
        "precision": 0.006226014254385965,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "blw_Latn-eng_Latn",
        "languages": [
          "blw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01882280229448198,
        "hf_subset": "eng_Latn-blz_Latn",
        "languages": [
          "eng-Latn",
          "blz-Latn"
        ],
        "main_score": 0.01882280229448198,
        "precision": 0.014112103174603173,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009437411889097743,
        "hf_subset": "blz_Latn-eng_Latn",
        "languages": [
          "blz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009437411889097743,
        "precision": 0.007427918424753868,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017565104166666668,
        "hf_subset": "eng_Latn-bmh_Latn",
        "languages": [
          "eng-Latn",
          "bmh-Latn"
        ],
        "main_score": 0.017565104166666668,
        "precision": 0.01668608651207761,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "bmh_Latn-eng_Latn",
        "languages": [
          "bmh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.00390625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09448818897637795,
        "f1": 0.0658134196640054,
        "hf_subset": "eng_Latn-bmk_Latn",
        "languages": [
          "eng-Latn",
          "bmk-Latn"
        ],
        "main_score": 0.0658134196640054,
        "precision": 0.0585453260650111,
        "recall": 0.09448818897637795
      },
      {
        "accuracy": 0.10236220472440945,
        "f1": 0.056347851623442184,
        "hf_subset": "bmk_Latn-eng_Latn",
        "languages": [
          "bmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.056347851623442184,
        "precision": 0.047937757780277465,
        "recall": 0.10236220472440945
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02280603853383459,
        "hf_subset": "eng_Latn-bmr_Latn",
        "languages": [
          "eng-Latn",
          "bmr-Latn"
        ],
        "main_score": 0.02280603853383459,
        "precision": 0.018898977102102102,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011866465336134453,
        "hf_subset": "bmr_Latn-eng_Latn",
        "languages": [
          "bmr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011866465336134453,
        "precision": 0.01036762147562978,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015392631354821803,
        "hf_subset": "eng_Latn-bmu_Latn",
        "languages": [
          "eng-Latn",
          "bmu-Latn"
        ],
        "main_score": 0.015392631354821803,
        "precision": 0.014237191270739065,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0028483072916666665,
        "hf_subset": "bmu_Latn-eng_Latn",
        "languages": [
          "bmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028483072916666665,
        "precision": 0.002079133064516129,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02005208333333333,
        "hf_subset": "eng_Latn-bnp_Latn",
        "languages": [
          "eng-Latn",
          "bnp-Latn"
        ],
        "main_score": 0.02005208333333333,
        "precision": 0.016110321969696972,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013647475964901236,
        "hf_subset": "bnp_Latn-eng_Latn",
        "languages": [
          "bnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013647475964901236,
        "precision": 0.012796160130718954,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.015625,
        "hf_subset": "eng_Latn-boa_Latn",
        "languages": [
          "eng-Latn",
          "boa-Latn"
        ],
        "main_score": 0.015625,
        "precision": 0.015625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005668967586574778,
        "hf_subset": "boa_Latn-eng_Latn",
        "languages": [
          "boa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005668967586574778,
        "precision": 0.004874318805718635,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02621838515200291,
        "hf_subset": "eng_Latn-boj_Latn",
        "languages": [
          "eng-Latn",
          "boj-Latn"
        ],
        "main_score": 0.02621838515200291,
        "precision": 0.02421469711034519,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012695416833600428,
        "hf_subset": "boj_Latn-eng_Latn",
        "languages": [
          "boj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012695416833600428,
        "precision": 0.010640355180926316,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018640621571209125,
        "hf_subset": "eng_Latn-bon_Latn",
        "languages": [
          "eng-Latn",
          "bon-Latn"
        ],
        "main_score": 0.018640621571209125,
        "precision": 0.016487630208333333,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004596700968523002,
        "hf_subset": "bon_Latn-eng_Latn",
        "languages": [
          "bon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004596700968523002,
        "precision": 0.004274079907161803,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016502808988764046,
        "hf_subset": "eng_Latn-box_Latn",
        "languages": [
          "eng-Latn",
          "box-Latn"
        ],
        "main_score": 0.0016502808988764046,
        "precision": 0.0010209517045454545,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002387152777777778,
        "hf_subset": "box_Latn-eng_Latn",
        "languages": [
          "box-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002387152777777778,
        "precision": 0.001394303319919517,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.007184595657002571,
        "hf_subset": "eng_Latn-bpr_Latn",
        "languages": [
          "eng-Latn",
          "bpr-Latn"
        ],
        "main_score": 0.007184595657002571,
        "precision": 0.004516554550521942,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007309422348484848,
        "hf_subset": "bpr_Latn-eng_Latn",
        "languages": [
          "bpr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007309422348484848,
        "precision": 0.006294899425287356,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.003909632034632035,
        "hf_subset": "eng_Latn-bps_Latn",
        "languages": [
          "eng-Latn",
          "bps-Latn"
        ],
        "main_score": 0.003909632034632035,
        "precision": 0.002387974402010419,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006765808117801576,
        "hf_subset": "bps_Latn-eng_Latn",
        "languages": [
          "bps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006765808117801576,
        "precision": 0.005581958912037037,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020537909010315922,
        "hf_subset": "eng_Latn-bqc_Latn",
        "languages": [
          "eng-Latn",
          "bqc-Latn"
        ],
        "main_score": 0.020537909010315922,
        "precision": 0.015362696256038647,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009570025247573293,
        "hf_subset": "bqc_Latn-eng_Latn",
        "languages": [
          "bqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009570025247573293,
        "precision": 0.00876213535860275,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "eng_Latn-bqp_Latn",
        "languages": [
          "eng-Latn",
          "bqp-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0105615055159326,
        "hf_subset": "bqp_Latn-eng_Latn",
        "languages": [
          "bqp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0105615055159326,
        "precision": 0.009532335069444443,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03917473208403915,
        "hf_subset": "eng_Latn-bre_Latn",
        "languages": [
          "eng-Latn",
          "bre-Latn"
        ],
        "main_score": 0.03917473208403915,
        "precision": 0.03291734307359307,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04423382675438597,
        "hf_subset": "bre_Latn-eng_Latn",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04423382675438597,
        "precision": 0.04022352430555556,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015107548701298702,
        "hf_subset": "eng_Latn-bsj_Latn",
        "languages": [
          "eng-Latn",
          "bsj-Latn"
        ],
        "main_score": 0.015107548701298702,
        "precision": 0.013615185278575845,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018508184523809524,
        "hf_subset": "bsj_Latn-eng_Latn",
        "languages": [
          "bsj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018508184523809524,
        "precision": 0.017720982142857142,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0035677083333333333,
        "hf_subset": "eng_Latn-bsn_Latn",
        "languages": [
          "eng-Latn",
          "bsn-Latn"
        ],
        "main_score": 0.0035677083333333333,
        "precision": 0.002470999053030303,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002027529761904762,
        "hf_subset": "bsn_Latn-eng_Latn",
        "languages": [
          "bsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002027529761904762,
        "precision": 0.0013396434294871795,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.04871335373711339,
        "hf_subset": "eng_Latn-bsp_Latn",
        "languages": [
          "eng-Latn",
          "bsp-Latn"
        ],
        "main_score": 0.04871335373711339,
        "precision": 0.04110043366988381,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020140666625041624,
        "hf_subset": "bsp_Latn-eng_Latn",
        "languages": [
          "bsp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020140666625041624,
        "precision": 0.017604482962213223,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01174220367494824,
        "hf_subset": "eng_Latn-bss_Latn",
        "languages": [
          "eng-Latn",
          "bss-Latn"
        ],
        "main_score": 0.01174220367494824,
        "precision": 0.007878449675324676,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0067620798319327725,
        "hf_subset": "bss_Latn-eng_Latn",
        "languages": [
          "bss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0067620798319327725,
        "precision": 0.0059877532038032245,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005667892156862745,
        "hf_subset": "eng_Latn-buk_Latn",
        "languages": [
          "eng-Latn",
          "buk-Latn"
        ],
        "main_score": 0.005667892156862745,
        "precision": 0.003750887784090909,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009809027777777778,
        "hf_subset": "buk_Latn-eng_Latn",
        "languages": [
          "buk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009809027777777778,
        "precision": 0.009018841911764705,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013485863095238094,
        "hf_subset": "eng_Latn-bus_Latn",
        "languages": [
          "eng-Latn",
          "bus-Latn"
        ],
        "main_score": 0.013485863095238094,
        "precision": 0.011532738095238096,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00759852127039627,
        "hf_subset": "bus_Latn-eng_Latn",
        "languages": [
          "bus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00759852127039627,
        "precision": 0.006443639075887393,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0037075988247863246,
        "hf_subset": "eng_Latn-bvd_Latn",
        "languages": [
          "eng-Latn",
          "bvd-Latn"
        ],
        "main_score": 0.0037075988247863246,
        "precision": 0.002179129464285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004018757200460829,
        "hf_subset": "bvd_Latn-eng_Latn",
        "languages": [
          "bvd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004018757200460829,
        "precision": 0.0026983269850117675,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03655317122113997,
        "hf_subset": "eng_Latn-bvr_Latn",
        "languages": [
          "eng-Latn",
          "bvr-Latn"
        ],
        "main_score": 0.03655317122113997,
        "precision": 0.034256793628426166,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019512518274853802,
        "hf_subset": "bvr_Latn-eng_Latn",
        "languages": [
          "bvr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019512518274853802,
        "precision": 0.016979166666666667,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03008473331766917,
        "hf_subset": "eng_Latn-bxh_Latn",
        "languages": [
          "eng-Latn",
          "bxh-Latn"
        ],
        "main_score": 0.03008473331766917,
        "precision": 0.026323784722222222,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008235563661440185,
        "hf_subset": "bxh_Latn-eng_Latn",
        "languages": [
          "bxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008235563661440185,
        "precision": 0.006815547733516483,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01765252976190476,
        "hf_subset": "eng_Latn-byr_Latn",
        "languages": [
          "eng-Latn",
          "byr-Latn"
        ],
        "main_score": 0.01765252976190476,
        "precision": 0.0146484375,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "byr_Latn-eng_Latn",
        "languages": [
          "byr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017578125,
        "hf_subset": "eng_Latn-byx_Latn",
        "languages": [
          "eng-Latn",
          "byx-Latn"
        ],
        "main_score": 0.017578125,
        "precision": 0.014973958333333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004151086182336183,
        "hf_subset": "byx_Latn-eng_Latn",
        "languages": [
          "byx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004151086182336183,
        "precision": 0.004030683349669198,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025468538708586883,
        "hf_subset": "eng_Latn-bzd_Latn",
        "languages": [
          "eng-Latn",
          "bzd-Latn"
        ],
        "main_score": 0.025468538708586883,
        "precision": 0.022519066220238096,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012639188218390805,
        "hf_subset": "bzd_Latn-eng_Latn",
        "languages": [
          "bzd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012639188218390805,
        "precision": 0.010816592261904762,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01944374145748164,
        "hf_subset": "eng_Latn-bzh_Latn",
        "languages": [
          "eng-Latn",
          "bzh-Latn"
        ],
        "main_score": 0.01944374145748164,
        "precision": 0.017095339556277053,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01456557765151515,
        "hf_subset": "bzh_Latn-eng_Latn",
        "languages": [
          "bzh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01456557765151515,
        "precision": 0.013795543653507915,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.09764981112637364,
        "hf_subset": "eng_Latn-bzj_Latn",
        "languages": [
          "eng-Latn",
          "bzj-Latn"
        ],
        "main_score": 0.09764981112637364,
        "precision": 0.08468175054112555,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.054600694444444445,
        "hf_subset": "bzj_Latn-eng_Latn",
        "languages": [
          "bzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.054600694444444445,
        "precision": 0.05087002840909091,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01078249007936508,
        "hf_subset": "eng_Latn-caa_Latn",
        "languages": [
          "eng-Latn",
          "caa-Latn"
        ],
        "main_score": 0.01078249007936508,
        "precision": 0.009505725033068783,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007506885798874005,
        "hf_subset": "caa_Latn-eng_Latn",
        "languages": [
          "caa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007506885798874005,
        "precision": 0.00638671875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021882166032396566,
        "hf_subset": "eng_Latn-cab_Latn",
        "languages": [
          "eng-Latn",
          "cab-Latn"
        ],
        "main_score": 0.021882166032396566,
        "precision": 0.01863529265873016,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004889027183454026,
        "hf_subset": "cab_Latn-eng_Latn",
        "languages": [
          "cab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004889027183454026,
        "precision": 0.0034256872852233672,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016937099358974358,
        "hf_subset": "eng_Latn-cac_Latn",
        "languages": [
          "eng-Latn",
          "cac-Latn"
        ],
        "main_score": 0.016937099358974358,
        "precision": 0.014072522971567268,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014773882113821137,
        "hf_subset": "cac_Latn-eng_Latn",
        "languages": [
          "cac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014773882113821137,
        "precision": 0.01279296875,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.05868812950879589,
        "hf_subset": "eng_Latn-caf_Latn",
        "languages": [
          "eng-Latn",
          "caf-Latn"
        ],
        "main_score": 0.05868812950879589,
        "precision": 0.053218370681605974,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05096218206157965,
        "hf_subset": "caf_Latn-eng_Latn",
        "languages": [
          "caf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05096218206157965,
        "precision": 0.04526697088765069,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.030922872317633347,
        "hf_subset": "eng_Latn-cak_Latn",
        "languages": [
          "eng-Latn",
          "cak-Latn"
        ],
        "main_score": 0.030922872317633347,
        "precision": 0.02625407832165332,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02740762850682909,
        "hf_subset": "cak_Latn-eng_Latn",
        "languages": [
          "cak-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02740762850682909,
        "precision": 0.024644125574861377,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01372860863095238,
        "hf_subset": "eng_Latn-cao_Latn",
        "languages": [
          "eng-Latn",
          "cao-Latn"
        ],
        "main_score": 0.01372860863095238,
        "precision": 0.011791366185897436,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009819878472222222,
        "hf_subset": "cao_Latn-eng_Latn",
        "languages": [
          "cao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009819878472222222,
        "precision": 0.007850096038829591,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010830082541836273,
        "hf_subset": "eng_Latn-cap_Latn",
        "languages": [
          "eng-Latn",
          "cap-Latn"
        ],
        "main_score": 0.010830082541836273,
        "precision": 0.008678923872180451,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007854192323481116,
        "hf_subset": "cap_Latn-eng_Latn",
        "languages": [
          "cap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007854192323481116,
        "precision": 0.005186719804318488,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025306919642857143,
        "hf_subset": "eng_Latn-car_Latn",
        "languages": [
          "eng-Latn",
          "car-Latn"
        ],
        "main_score": 0.025306919642857143,
        "precision": 0.021691849816849816,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.030944153502747256,
        "hf_subset": "car_Latn-eng_Latn",
        "languages": [
          "car-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030944153502747256,
        "precision": 0.02684127938034188,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.040322580645161e-05,
        "hf_subset": "eng_Latn-cav_Latn",
        "languages": [
          "eng-Latn",
          "cav-Latn"
        ],
        "main_score": 5.040322580645161e-05,
        "precision": 2.5365259740259742e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010366586538461538,
        "hf_subset": "cav_Latn-eng_Latn",
        "languages": [
          "cav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010366586538461538,
        "precision": 0.0005883167220376523,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0194285331320028,
        "hf_subset": "eng_Latn-cax_Latn",
        "languages": [
          "eng-Latn",
          "cax-Latn"
        ],
        "main_score": 0.0194285331320028,
        "precision": 0.01684594177663734,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008818655303030302,
        "hf_subset": "cax_Latn-eng_Latn",
        "languages": [
          "cax-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008818655303030302,
        "precision": 0.007347470238095238,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0071634163533834585,
        "hf_subset": "eng_Latn-cbc_Latn",
        "languages": [
          "eng-Latn",
          "cbc-Latn"
        ],
        "main_score": 0.0071634163533834585,
        "precision": 0.005899677579365079,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005148329493087557,
        "hf_subset": "cbc_Latn-eng_Latn",
        "languages": [
          "cbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005148329493087557,
        "precision": 0.004621328551912569,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.026829769736842105,
        "hf_subset": "eng_Latn-cbi_Latn",
        "languages": [
          "eng-Latn",
          "cbi-Latn"
        ],
        "main_score": 0.026829769736842105,
        "precision": 0.024809337797619048,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0055691370144495145,
        "hf_subset": "cbi_Latn-eng_Latn",
        "languages": [
          "cbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0055691370144495145,
        "precision": 0.004785258850484141,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.25,
        "f1": 0.1933128720238095,
        "hf_subset": "eng_Latn-cbk_Latn",
        "languages": [
          "eng-Latn",
          "cbk-Latn"
        ],
        "main_score": 0.1933128720238095,
        "precision": 0.17395213293650794,
        "recall": 0.25
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.12739109848484848,
        "hf_subset": "cbk_Latn-eng_Latn",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12739109848484848,
        "precision": 0.11936883066061844,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010653409090909092,
        "hf_subset": "eng_Latn-cbr_Latn",
        "languages": [
          "eng-Latn",
          "cbr-Latn"
        ],
        "main_score": 0.010653409090909092,
        "precision": 0.008585611979166666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01729189952806756,
        "hf_subset": "cbr_Latn-eng_Latn",
        "languages": [
          "cbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01729189952806756,
        "precision": 0.015812174479166666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.013020833333333332,
        "hf_subset": "eng_Latn-cbs_Latn",
        "languages": [
          "eng-Latn",
          "cbs-Latn"
        ],
        "main_score": 0.013020833333333332,
        "precision": 0.01171875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013432017543859648,
        "hf_subset": "cbs_Latn-eng_Latn",
        "languages": [
          "cbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013432017543859648,
        "precision": 0.01154513888888889,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00396165780141844,
        "hf_subset": "eng_Latn-cbt_Latn",
        "languages": [
          "eng-Latn",
          "cbt-Latn"
        ],
        "main_score": 0.00396165780141844,
        "precision": 0.003934151785714286,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "cbt_Latn-eng_Latn",
        "languages": [
          "cbt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008386948529411764,
        "hf_subset": "eng_Latn-cbu_Latn",
        "languages": [
          "eng-Latn",
          "cbu-Latn"
        ],
        "main_score": 0.008386948529411764,
        "precision": 0.00811494286380597,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001775568181818182,
        "hf_subset": "cbu_Latn-eng_Latn",
        "languages": [
          "cbu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001775568181818182,
        "precision": 9.084302325581395e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016878574346405228,
        "hf_subset": "eng_Latn-cbv_Latn",
        "languages": [
          "eng-Latn",
          "cbv-Latn"
        ],
        "main_score": 0.016878574346405228,
        "precision": 0.014047152359997029,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0027751068376068375,
        "hf_subset": "cbv_Latn-eng_Latn",
        "languages": [
          "cbv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027751068376068375,
        "precision": 0.002039586731127679,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014504084143738142,
        "hf_subset": "eng_Latn-cco_Latn",
        "languages": [
          "eng-Latn",
          "cco-Latn"
        ],
        "main_score": 0.014504084143738142,
        "precision": 0.01228608630952381,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006059695512820513,
        "hf_subset": "cco_Latn-eng_Latn",
        "languages": [
          "cco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006059695512820513,
        "precision": 0.005311129385964912,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.04816031407828282,
        "hf_subset": "eng_Latn-ceb_Latn",
        "languages": [
          "eng-Latn",
          "ceb-Latn"
        ],
        "main_score": 0.04816031407828282,
        "precision": 0.03951526988636364,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03203869047619048,
        "hf_subset": "ceb_Latn-eng_Latn",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03203869047619048,
        "precision": 0.0305484693877551,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028354458041958044,
        "hf_subset": "eng_Latn-cek_Latn",
        "languages": [
          "eng-Latn",
          "cek-Latn"
        ],
        "main_score": 0.028354458041958044,
        "precision": 0.024632693238778765,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.021935144587239004,
        "hf_subset": "cek_Latn-eng_Latn",
        "languages": [
          "cek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021935144587239004,
        "precision": 0.01956899154589372,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.028511402774374472,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ],
        "main_score": 0.028511402774374472,
        "precision": 0.023727050582519327,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.02827933784965035,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02827933784965035,
        "precision": 0.02156498015873016,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028816626082251082,
        "hf_subset": "eng_Latn-cgc_Latn",
        "languages": [
          "eng-Latn",
          "cgc-Latn"
        ],
        "main_score": 0.028816626082251082,
        "precision": 0.024796195652173912,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017968178910818713,
        "hf_subset": "cgc_Latn-eng_Latn",
        "languages": [
          "cgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017968178910818713,
        "precision": 0.01589443820144297,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.0821040912323807,
        "hf_subset": "eng_Latn-cha_Latn",
        "languages": [
          "eng-Latn",
          "cha-Latn"
        ],
        "main_score": 0.0821040912323807,
        "precision": 0.0706116691468254,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07434382366536971,
        "hf_subset": "cha_Latn-eng_Latn",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07434382366536971,
        "precision": 0.06707606043543543,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012363591269841271,
        "hf_subset": "eng_Latn-chd_Latn",
        "languages": [
          "eng-Latn",
          "chd-Latn"
        ],
        "main_score": 0.012363591269841271,
        "precision": 0.009828629032258064,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017929997519841267,
        "hf_subset": "chd_Latn-eng_Latn",
        "languages": [
          "chd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017929997519841267,
        "precision": 0.016897235999540194,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017578125,
        "hf_subset": "eng_Latn-chf_Latn",
        "languages": [
          "eng-Latn",
          "chf-Latn"
        ],
        "main_score": 0.017578125,
        "precision": 0.015980113636363636,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.0220531496514401,
        "hf_subset": "chf_Latn-eng_Latn",
        "languages": [
          "chf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0220531496514401,
        "precision": 0.019896986693861692,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023920090326340324,
        "hf_subset": "eng_Latn-chk_Latn",
        "languages": [
          "eng-Latn",
          "chk-Latn"
        ],
        "main_score": 0.023920090326340324,
        "precision": 0.021201785032635322,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019173388460497834,
        "hf_subset": "chk_Latn-eng_Latn",
        "languages": [
          "chk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019173388460497834,
        "precision": 0.016557854574487642,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019166459986772487,
        "hf_subset": "eng_Latn-chq_Latn",
        "languages": [
          "eng-Latn",
          "chq-Latn"
        ],
        "main_score": 0.019166459986772487,
        "precision": 0.01654506355696484,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005658595737913486,
        "hf_subset": "chq_Latn-eng_Latn",
        "languages": [
          "chq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005658595737913486,
        "precision": 0.0035642742673992673,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025173611111111112,
        "hf_subset": "eng_Latn-chz_Latn",
        "languages": [
          "eng-Latn",
          "chz-Latn"
        ],
        "main_score": 0.025173611111111112,
        "precision": 0.02294625946969697,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.024609375,
        "hf_subset": "chz_Latn-eng_Latn",
        "languages": [
          "chz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024609375,
        "precision": 0.021614583333333333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020833333333333333,
        "hf_subset": "eng_Latn-cjo_Latn",
        "languages": [
          "eng-Latn",
          "cjo-Latn"
        ],
        "main_score": 0.0020833333333333333,
        "precision": 0.0013682909604519774,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0012428977272727273,
        "hf_subset": "cjo_Latn-eng_Latn",
        "languages": [
          "cjo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0012428977272727273,
        "precision": 0.0006937781628288845,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0099609375,
        "hf_subset": "eng_Latn-cjv_Latn",
        "languages": [
          "eng-Latn",
          "cjv-Latn"
        ],
        "main_score": 0.0099609375,
        "precision": 0.007553774350649351,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00011322463768115942,
        "hf_subset": "cjv_Latn-eng_Latn",
        "languages": [
          "cjv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00011322463768115942,
        "precision": 5.744485294117647e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0005818300836231164,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0005818300836231164,
        "precision": 0.00029878162202380955,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.017284338015814832,
        "hf_subset": "eng_Latn-cle_Latn",
        "languages": [
          "eng-Latn",
          "cle-Latn"
        ],
        "main_score": 0.017284338015814832,
        "precision": 0.01367529766110797,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011182797346627436,
        "hf_subset": "cle_Latn-eng_Latn",
        "languages": [
          "cle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011182797346627436,
        "precision": 0.008747861141834356,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.029825808061202084,
        "hf_subset": "eng_Latn-clu_Latn",
        "languages": [
          "eng-Latn",
          "clu-Latn"
        ],
        "main_score": 0.029825808061202084,
        "precision": 0.026047958245798315,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018905248397435896,
        "hf_subset": "clu_Latn-eng_Latn",
        "languages": [
          "clu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018905248397435896,
        "precision": 0.016769695590614885,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02476829594017094,
        "hf_subset": "eng_Latn-cme_Latn",
        "languages": [
          "eng-Latn",
          "cme-Latn"
        ],
        "main_score": 0.02476829594017094,
        "precision": 0.02139185855263158,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016831341911764705,
        "hf_subset": "cme_Latn-eng_Latn",
        "languages": [
          "cme-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016831341911764705,
        "precision": 0.016277559246309248,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.11767270957752042,
        "hf_subset": "eng_Latn-cmn_Hans",
        "languages": [
          "eng-Latn",
          "cmn-Hans"
        ],
        "main_score": 0.11767270957752042,
        "precision": 0.10468074297664141,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03481131213450292,
        "hf_subset": "cmn_Hans-eng_Latn",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.03481131213450292,
        "precision": 0.02861159852198455,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002734375,
        "hf_subset": "eng_Latn-cni_Latn",
        "languages": [
          "eng-Latn",
          "cni-Latn"
        ],
        "main_score": 0.002734375,
        "precision": 0.001736111111111111,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0037100144128911342,
        "hf_subset": "cni_Latn-eng_Latn",
        "languages": [
          "cni-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0037100144128911342,
        "precision": 0.0023154824921499152,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019402145127118645,
        "hf_subset": "eng_Latn-cnl_Latn",
        "languages": [
          "eng-Latn",
          "cnl-Latn"
        ],
        "main_score": 0.019402145127118645,
        "precision": 0.016735109508547008,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.011593255666992824,
        "hf_subset": "cnl_Latn-eng_Latn",
        "languages": [
          "cnl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011593255666992824,
        "precision": 0.0071805762235449735,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008150629940711463,
        "hf_subset": "eng_Latn-cnt_Latn",
        "languages": [
          "eng-Latn",
          "cnt-Latn"
        ],
        "main_score": 0.008150629940711463,
        "precision": 0.005451790091036414,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015548670977011493,
        "hf_subset": "cnt_Latn-eng_Latn",
        "languages": [
          "cnt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015548670977011493,
        "precision": 0.014101009801826245,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005625725900116143,
        "hf_subset": "eng_Latn-cof_Latn",
        "languages": [
          "eng-Latn",
          "cof-Latn"
        ],
        "main_score": 0.0005625725900116143,
        "precision": 0.00029296875000000004,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026523919753086416,
        "hf_subset": "cof_Latn-eng_Latn",
        "languages": [
          "cof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026523919753086416,
        "precision": 0.0019773874223602485,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012194511217948718,
        "hf_subset": "eng_Latn-con_Latn",
        "languages": [
          "eng-Latn",
          "con-Latn"
        ],
        "main_score": 0.012194511217948718,
        "precision": 0.011965180093776642,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008686755952380953,
        "hf_subset": "con_Latn-eng_Latn",
        "languages": [
          "con-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008686755952380953,
        "precision": 0.007276348039215686,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-cop_Copt",
        "languages": [
          "eng-Latn",
          "cop-Copt"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.201844262295082e-05,
        "hf_subset": "cop_Copt-eng_Latn",
        "languages": [
          "cop-Copt",
          "eng-Latn"
        ],
        "main_score": 3.201844262295082e-05,
        "precision": 1.6075102880658438e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01261780753968254,
        "hf_subset": "eng_Latn-cot_Latn",
        "languages": [
          "eng-Latn",
          "cot-Latn"
        ],
        "main_score": 0.01261780753968254,
        "precision": 0.0107421875,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003966812015503876,
        "hf_subset": "cot_Latn-eng_Latn",
        "languages": [
          "cot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003966812015503876,
        "precision": 0.003936767578125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010131253295315796,
        "hf_subset": "eng_Latn-cpa_Latn",
        "languages": [
          "eng-Latn",
          "cpa-Latn"
        ],
        "main_score": 0.010131253295315796,
        "precision": 0.007494055706521739,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016406249999999997,
        "hf_subset": "cpa_Latn-eng_Latn",
        "languages": [
          "cpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016406249999999997,
        "precision": 0.01351303481258724,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01985105994152047,
        "hf_subset": "eng_Latn-cpb_Latn",
        "languages": [
          "eng-Latn",
          "cpb-Latn"
        ],
        "main_score": 0.01985105994152047,
        "precision": 0.017467447916666667,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011362884004237288,
        "hf_subset": "cpb_Latn-eng_Latn",
        "languages": [
          "cpb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011362884004237288,
        "precision": 0.009079032268630122,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023297076713008937,
        "hf_subset": "eng_Latn-cpc_Latn",
        "languages": [
          "eng-Latn",
          "cpc-Latn"
        ],
        "main_score": 0.023297076713008937,
        "precision": 0.01998397435897436,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013777073935160549,
        "hf_subset": "cpc_Latn-eng_Latn",
        "languages": [
          "cpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013777073935160549,
        "precision": 0.010995987889566395,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017680921052631575,
        "hf_subset": "eng_Latn-cpu_Latn",
        "languages": [
          "eng-Latn",
          "cpu-Latn"
        ],
        "main_score": 0.017680921052631575,
        "precision": 0.015026041666666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.006972675761738262,
        "hf_subset": "cpu_Latn-eng_Latn",
        "languages": [
          "cpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006972675761738262,
        "precision": 0.004850893936890177,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004607371794871794,
        "hf_subset": "eng_Latn-cpy_Latn",
        "languages": [
          "eng-Latn",
          "cpy-Latn"
        ],
        "main_score": 0.004607371794871794,
        "precision": 0.0032804099462365593,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004768474289353714,
        "hf_subset": "cpy_Latn-eng_Latn",
        "languages": [
          "cpy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004768474289353714,
        "precision": 0.0033624235284391533,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021438530323653962,
        "hf_subset": "eng_Latn-crn_Latn",
        "languages": [
          "eng-Latn",
          "crn-Latn"
        ],
        "main_score": 0.021438530323653962,
        "precision": 0.019559319364006865,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007919803882373845,
        "hf_subset": "crn_Latn-eng_Latn",
        "languages": [
          "crn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007919803882373845,
        "precision": 0.0066176997306040255,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.06932499456452876,
        "hf_subset": "eng_Latn-crx_Latn",
        "languages": [
          "eng-Latn",
          "crx-Latn"
        ],
        "main_score": 0.06932499456452876,
        "precision": 0.061987322573260076,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04440855368589743,
        "hf_subset": "crx_Latn-eng_Latn",
        "languages": [
          "crx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04440855368589743,
        "precision": 0.03937670314697609,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01898251488095238,
        "hf_subset": "eng_Latn-cso_Latn",
        "languages": [
          "eng-Latn",
          "cso-Latn"
        ],
        "main_score": 0.01898251488095238,
        "precision": 0.015045978327228326,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013576676479978964,
        "hf_subset": "cso_Latn-eng_Latn",
        "languages": [
          "cso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013576676479978964,
        "precision": 0.010302480345364178,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05334308703449328,
        "hf_subset": "eng_Latn-csy_Latn",
        "languages": [
          "eng-Latn",
          "csy-Latn"
        ],
        "main_score": 0.05334308703449328,
        "precision": 0.04837535511363636,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07068110909822867,
        "hf_subset": "csy_Latn-eng_Latn",
        "languages": [
          "csy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07068110909822867,
        "precision": 0.06488942914724165,
        "recall": 0.09375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0169921875,
        "hf_subset": "eng_Latn-cta_Latn",
        "languages": [
          "eng-Latn",
          "cta-Latn"
        ],
        "main_score": 0.0169921875,
        "precision": 0.014989459325396824,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004938323214653221,
        "hf_subset": "cta_Latn-eng_Latn",
        "languages": [
          "cta-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004938323214653221,
        "precision": 0.004468160962301587,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018045420687654905,
        "hf_subset": "eng_Latn-cth_Latn",
        "languages": [
          "eng-Latn",
          "cth-Latn"
        ],
        "main_score": 0.018045420687654905,
        "precision": 0.015944689310383245,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027260458839406206,
        "hf_subset": "cth_Latn-eng_Latn",
        "languages": [
          "cth-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027260458839406206,
        "precision": 0.02603034559729064,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.027038499694749692,
        "hf_subset": "eng_Latn-ctp_Latn",
        "languages": [
          "eng-Latn",
          "ctp-Latn"
        ],
        "main_score": 0.027038499694749692,
        "precision": 0.024773257902298854,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003526475694444444,
        "hf_subset": "ctp_Latn-eng_Latn",
        "languages": [
          "ctp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003526475694444444,
        "precision": 0.0024433210784313725,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025532670454545454,
        "hf_subset": "eng_Latn-ctu_Latn",
        "languages": [
          "eng-Latn",
          "ctu-Latn"
        ],
        "main_score": 0.025532670454545454,
        "precision": 0.023864951599326598,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.014614335317460318,
        "hf_subset": "ctu_Latn-eng_Latn",
        "languages": [
          "ctu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014614335317460318,
        "precision": 0.011764067606209148,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006151064885762051,
        "hf_subset": "eng_Latn-cub_Latn",
        "languages": [
          "eng-Latn",
          "cub-Latn"
        ],
        "main_score": 0.006151064885762051,
        "precision": 0.005357530381944444,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0062372784961685825,
        "hf_subset": "cub_Latn-eng_Latn",
        "languages": [
          "cub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0062372784961685825,
        "precision": 0.005402859867538565,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010474111519607842,
        "hf_subset": "eng_Latn-cuc_Latn",
        "languages": [
          "eng-Latn",
          "cuc-Latn"
        ],
        "main_score": 0.010474111519607842,
        "precision": 0.008306464947089946,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011339506061912976,
        "hf_subset": "cuc_Latn-eng_Latn",
        "languages": [
          "cuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011339506061912976,
        "precision": 0.009253012085566805,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006583634118541033,
        "hf_subset": "eng_Latn-cui_Latn",
        "languages": [
          "eng-Latn",
          "cui-Latn"
        ],
        "main_score": 0.006583634118541033,
        "precision": 0.005593732580824972,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00548735119047619,
        "hf_subset": "cui_Latn-eng_Latn",
        "languages": [
          "cui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00548735119047619,
        "precision": 0.004761153198653199,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012423878205128205,
        "hf_subset": "eng_Latn-cuk_Latn",
        "languages": [
          "eng-Latn",
          "cuk-Latn"
        ],
        "main_score": 0.012423878205128205,
        "precision": 0.010143932995495495,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009671004132074515,
        "hf_subset": "cuk_Latn-eng_Latn",
        "languages": [
          "cuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009671004132074515,
        "precision": 0.007797784466329005,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017795138888888888,
        "hf_subset": "eng_Latn-cut_Latn",
        "languages": [
          "eng-Latn",
          "cut-Latn"
        ],
        "main_score": 0.017795138888888888,
        "precision": 0.015085565476190475,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004802212967764238,
        "hf_subset": "cut_Latn-eng_Latn",
        "languages": [
          "cut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004802212967764238,
        "precision": 0.0043808082818729945,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02607266865079365,
        "hf_subset": "eng_Latn-cux_Latn",
        "languages": [
          "eng-Latn",
          "cux-Latn"
        ],
        "main_score": 0.02607266865079365,
        "precision": 0.020800781249999997,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022415647644927535,
        "hf_subset": "cux_Latn-eng_Latn",
        "languages": [
          "cux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022415647644927535,
        "precision": 0.020132211538461536,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013216145833333333,
        "hf_subset": "eng_Latn-cwe_Latn",
        "languages": [
          "eng-Latn",
          "cwe-Latn"
        ],
        "main_score": 0.013216145833333333,
        "precision": 0.011383928571428571,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004764766483516484,
        "hf_subset": "cwe_Latn-eng_Latn",
        "languages": [
          "cwe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0004764766483516484,
        "precision": 0.00024899488304093567,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025882685023310023,
        "hf_subset": "eng_Latn-cya_Latn",
        "languages": [
          "eng-Latn",
          "cya-Latn"
        ],
        "main_score": 0.025882685023310023,
        "precision": 0.02293008851875131,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02340741308846175,
        "hf_subset": "cya_Latn-eng_Latn",
        "languages": [
          "cya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02340741308846175,
        "precision": 0.020478686951754387,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005115327380952381,
        "hf_subset": "eng_Latn-daa_Latn",
        "languages": [
          "eng-Latn",
          "daa-Latn"
        ],
        "main_score": 0.005115327380952381,
        "precision": 0.003555689102564102,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.300403225806451e-05,
        "hf_subset": "daa_Latn-eng_Latn",
        "languages": [
          "daa-Latn",
          "eng-Latn"
        ],
        "main_score": 6.300403225806451e-05,
        "precision": 3.1758130081300816e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015749007936507936,
        "hf_subset": "eng_Latn-dad_Latn",
        "languages": [
          "eng-Latn",
          "dad-Latn"
        ],
        "main_score": 0.015749007936507936,
        "precision": 0.014460637019230768,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015572264789259735,
        "hf_subset": "dad_Latn-eng_Latn",
        "languages": [
          "dad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015572264789259735,
        "precision": 0.014369122815349543,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007119487131434283,
        "hf_subset": "eng_Latn-dah_Latn",
        "languages": [
          "eng-Latn",
          "dah-Latn"
        ],
        "main_score": 0.007119487131434283,
        "precision": 0.005880512716450216,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026542467948717945,
        "hf_subset": "dah_Latn-eng_Latn",
        "languages": [
          "dah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026542467948717945,
        "precision": 0.001978326612903226,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.08697558951465201,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ],
        "main_score": 0.08697558951465201,
        "precision": 0.07743481901914806,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.125,
        "f1": 0.09960937499999999,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09960937499999999,
        "precision": 0.09105902777777777,
        "recall": 0.125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011284722222222222,
        "hf_subset": "eng_Latn-ded_Latn",
        "languages": [
          "eng-Latn",
          "ded-Latn"
        ],
        "main_score": 0.011284722222222222,
        "precision": 0.009957978219696968,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00399116847826087,
        "hf_subset": "ded_Latn-eng_Latn",
        "languages": [
          "ded-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00399116847826087,
        "precision": 0.003949175824175824,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.30859375,
        "f1": 0.24597264714452213,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.24597264714452213,
        "precision": 0.22734374999999998,
        "recall": 0.30859375
      },
      {
        "accuracy": 0.3359375,
        "f1": 0.24728422619047616,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.24728422619047616,
        "precision": 0.2204769514339827,
        "recall": 0.3359375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026131854256854256,
        "hf_subset": "eng_Latn-dgc_Latn",
        "languages": [
          "eng-Latn",
          "dgc-Latn"
        ],
        "main_score": 0.026131854256854256,
        "precision": 0.021662159455128206,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0106153612012987,
        "hf_subset": "dgc_Latn-eng_Latn",
        "languages": [
          "dgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0106153612012987,
        "precision": 0.00957623106060606,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04480263398964236,
        "hf_subset": "eng_Latn-dgr_Latn",
        "languages": [
          "eng-Latn",
          "dgr-Latn"
        ],
        "main_score": 0.04480263398964236,
        "precision": 0.04060130251149373,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.0490395634332455,
        "hf_subset": "dgr_Latn-eng_Latn",
        "languages": [
          "dgr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0490395634332455,
        "precision": 0.04615536065523388,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002153445512820513,
        "hf_subset": "eng_Latn-dgz_Latn",
        "languages": [
          "eng-Latn",
          "dgz-Latn"
        ],
        "main_score": 0.002153445512820513,
        "precision": 0.0014048793859649123,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0041583317069997395,
        "hf_subset": "dgz_Latn-eng_Latn",
        "languages": [
          "dgz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0041583317069997395,
        "precision": 0.004034358198924731,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009914687028657616,
        "hf_subset": "eng_Latn-dhg_Latn",
        "languages": [
          "eng-Latn",
          "dhg-Latn"
        ],
        "main_score": 0.009914687028657616,
        "precision": 0.008940197172619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0031939338235294117,
        "hf_subset": "dhg_Latn-eng_Latn",
        "languages": [
          "dhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0031939338235294117,
        "precision": 0.0019615944334464555,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020913874570446737,
        "hf_subset": "eng_Latn-dif_Latn",
        "languages": [
          "eng-Latn",
          "dif-Latn"
        ],
        "main_score": 0.020913874570446737,
        "precision": 0.017772791625330686,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027625907898986807,
        "hf_subset": "dif_Latn-eng_Latn",
        "languages": [
          "dif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027625907898986807,
        "precision": 0.02625503326330532,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015140892094017092,
        "hf_subset": "eng_Latn-dik_Latn",
        "languages": [
          "eng-Latn",
          "dik-Latn"
        ],
        "main_score": 0.015140892094017092,
        "precision": 0.012315538194444444,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004022854477611941,
        "hf_subset": "dik_Latn-eng_Latn",
        "languages": [
          "dik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004022854477611941,
        "precision": 0.003965435606060606,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1,
        "f1": 0.05698876070067205,
        "hf_subset": "eng_Latn-dji_Latn",
        "languages": [
          "eng-Latn",
          "dji-Latn"
        ],
        "main_score": 0.05698876070067205,
        "precision": 0.04893692564745196,
        "recall": 0.1
      },
      {
        "accuracy": 0.042105263157894736,
        "f1": 0.02694702180984376,
        "hf_subset": "dji_Latn-eng_Latn",
        "languages": [
          "dji-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02694702180984376,
        "precision": 0.025026697177726924,
        "recall": 0.042105263157894736
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0027248538372859022,
        "hf_subset": "eng_Latn-djk_Latn",
        "languages": [
          "eng-Latn",
          "djk-Latn"
        ],
        "main_score": 0.0027248538372859022,
        "precision": 0.001491794338474026,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004950161637931034,
        "hf_subset": "djk_Latn-eng_Latn",
        "languages": [
          "djk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004950161637931034,
        "precision": 0.004498253105590062,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007356770833333333,
        "hf_subset": "eng_Latn-djr_Latn",
        "languages": [
          "eng-Latn",
          "djr-Latn"
        ],
        "main_score": 0.007356770833333333,
        "precision": 0.006326228408029879,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0010917793144355646,
        "hf_subset": "djr_Latn-eng_Latn",
        "languages": [
          "djr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010917793144355646,
        "precision": 0.0005777261636636635,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013012378246753246,
        "hf_subset": "eng_Latn-dob_Latn",
        "languages": [
          "eng-Latn",
          "dob-Latn"
        ],
        "main_score": 0.013012378246753246,
        "precision": 0.01246063468992248,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001732336956521739,
        "hf_subset": "dob_Latn-eng_Latn",
        "languages": [
          "dob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001732336956521739,
        "precision": 0.0010633680555555555,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008680555555555555,
        "hf_subset": "eng_Latn-dop_Latn",
        "languages": [
          "eng-Latn",
          "dop-Latn"
        ],
        "main_score": 0.0008680555555555555,
        "precision": 0.00048828125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "dop_Latn-eng_Latn",
        "languages": [
          "dop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004275867937372362,
        "hf_subset": "eng_Latn-dov_Latn",
        "languages": [
          "eng-Latn",
          "dov-Latn"
        ],
        "main_score": 0.004275867937372362,
        "precision": 0.004097377232142857,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008994030898876404,
        "hf_subset": "dov_Latn-eng_Latn",
        "languages": [
          "dov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008994030898876404,
        "precision": 0.0084536773989899,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00701827811716792,
        "hf_subset": "eng_Latn-dwr_Latn",
        "languages": [
          "eng-Latn",
          "dwr-Latn"
        ],
        "main_score": 0.00701827811716792,
        "precision": 0.0057045326576576575,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.002539561133311133,
        "hf_subset": "dwr_Latn-eng_Latn",
        "languages": [
          "dwr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002539561133311133,
        "precision": 0.0014335427588823173,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011369157037815126,
        "hf_subset": "eng_Latn-dww_Latn",
        "languages": [
          "eng-Latn",
          "dww-Latn"
        ],
        "main_score": 0.011369157037815126,
        "precision": 0.009891719608516484,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001957904616240267,
        "hf_subset": "dww_Latn-eng_Latn",
        "languages": [
          "dww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001957904616240267,
        "precision": 0.0011801083138173302,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.10526315789473684,
        "f1": 0.05707517824943742,
        "hf_subset": "eng_Latn-dwy_Latn",
        "languages": [
          "eng-Latn",
          "dwy-Latn"
        ],
        "main_score": 0.05707517824943742,
        "precision": 0.048473266499582286,
        "recall": 0.10526315789473684
      },
      {
        "accuracy": 0.08270676691729323,
        "f1": 0.03669292278314834,
        "hf_subset": "dwy_Latn-eng_Latn",
        "languages": [
          "dwy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03669292278314834,
        "precision": 0.02731829573934837,
        "recall": 0.08270676691729323
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021052970467032965,
        "hf_subset": "eng_Latn-ebk_Latn",
        "languages": [
          "eng-Latn",
          "ebk-Latn"
        ],
        "main_score": 0.021052970467032965,
        "precision": 0.0165922619047619,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.025364178830640502,
        "hf_subset": "ebk_Latn-eng_Latn",
        "languages": [
          "ebk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025364178830640502,
        "precision": 0.021695701121829947,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016811183608058607,
        "hf_subset": "eng_Latn-eko_Latn",
        "languages": [
          "eng-Latn",
          "eko-Latn"
        ],
        "main_score": 0.016811183608058607,
        "precision": 0.013774671052631578,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0012248602092352094,
        "hf_subset": "eko_Latn-eng_Latn",
        "languages": [
          "eko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0012248602092352094,
        "precision": 0.0006592211375212225,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028941761363636364,
        "hf_subset": "eng_Latn-emi_Latn",
        "languages": [
          "eng-Latn",
          "emi-Latn"
        ],
        "main_score": 0.028941761363636364,
        "precision": 0.0247314453125,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013952616013676868,
        "hf_subset": "emi_Latn-eng_Latn",
        "languages": [
          "emi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013952616013676868,
        "precision": 0.011434962606837608,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017000097352024922,
        "hf_subset": "eng_Latn-emp_Latn",
        "languages": [
          "eng-Latn",
          "emp-Latn"
        ],
        "main_score": 0.017000097352024922,
        "precision": 0.01566185141509434,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011810661764705882,
        "hf_subset": "emp_Latn-eng_Latn",
        "languages": [
          "emp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011810661764705882,
        "precision": 0.009812127976190476,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006126469017094016,
        "hf_subset": "eng_Latn-enq_Latn",
        "languages": [
          "eng-Latn",
          "enq-Latn"
        ],
        "main_score": 0.006126469017094016,
        "precision": 0.004119740936147186,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002418154761904762,
        "hf_subset": "enq_Latn-eng_Latn",
        "languages": [
          "enq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002418154761904762,
        "precision": 0.0013627996016196448,
        "recall": 0.015625
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.10694782647907647,
        "hf_subset": "eng_Latn-epo_Latn",
        "languages": [
          "eng-Latn",
          "epo-Latn"
        ],
        "main_score": 0.10694782647907647,
        "precision": 0.09313616071428571,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.13083261142100516,
        "hf_subset": "epo_Latn-eng_Latn",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13083261142100516,
        "precision": 0.11544518849206348,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00583183092948718,
        "hf_subset": "eng_Latn-eri_Latn",
        "languages": [
          "eng-Latn",
          "eri-Latn"
        ],
        "main_score": 0.00583183092948718,
        "precision": 0.0038258225274865115,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006195175438596491,
        "hf_subset": "eri_Latn-eng_Latn",
        "languages": [
          "eri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006195175438596491,
        "precision": 0.005380115284776302,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0067708333333333336,
        "hf_subset": "eng_Latn-ese_Latn",
        "languages": [
          "eng-Latn",
          "ese-Latn"
        ],
        "main_score": 0.0067708333333333336,
        "precision": 0.005555555555555555,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ese_Latn-eng_Latn",
        "languages": [
          "ese-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05437225877192982,
        "hf_subset": "eng_Latn-esk_Latn",
        "languages": [
          "eng-Latn",
          "esk-Latn"
        ],
        "main_score": 0.05437225877192982,
        "precision": 0.04970733974640225,
        "recall": 0.078125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05225059278148122,
        "hf_subset": "esk_Latn-eng_Latn",
        "languages": [
          "esk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05225059278148122,
        "precision": 0.04806190561713191,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009765625,
        "hf_subset": "eng_Latn-etr_Latn",
        "languages": [
          "eng-Latn",
          "etr-Latn"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0005580357142857143,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005113400703972738,
        "hf_subset": "etr_Latn-eng_Latn",
        "languages": [
          "etr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005113400703972738,
        "precision": 0.004547091530409276,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013101465489437187,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ],
        "main_score": 0.013101465489437187,
        "precision": 0.010498841490037311,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004499716553287982,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004499716553287982,
        "precision": 0.002967708949599955,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008234126984126984,
        "hf_subset": "eng_Latn-faa_Latn",
        "languages": [
          "eng-Latn",
          "faa-Latn"
        ],
        "main_score": 0.008234126984126984,
        "precision": 0.006827615914786967,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004935958758503401,
        "hf_subset": "faa_Latn-eng_Latn",
        "languages": [
          "faa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004935958758503401,
        "precision": 0.0044910408512720155,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007161458333333333,
        "hf_subset": "eng_Latn-fai_Latn",
        "languages": [
          "eng-Latn",
          "fai-Latn"
        ],
        "main_score": 0.007161458333333333,
        "precision": 0.005989583333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "fai_Latn-eng_Latn",
        "languages": [
          "fai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015234375,
        "hf_subset": "eng_Latn-far_Latn",
        "languages": [
          "eng-Latn",
          "far-Latn"
        ],
        "main_score": 0.015234375,
        "precision": 0.012825520833333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015994157678479712,
        "hf_subset": "far_Latn-eng_Latn",
        "languages": [
          "far-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015994157678479712,
        "precision": 0.014574340085351668,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011745925362782758,
        "hf_subset": "eng_Latn-ffm_Latn",
        "languages": [
          "eng-Latn",
          "ffm-Latn"
        ],
        "main_score": 0.011745925362782758,
        "precision": 0.00884890353912883,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0078125,
        "hf_subset": "ffm_Latn-eng_Latn",
        "languages": [
          "ffm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.006640625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-for_Latn",
        "languages": [
          "eng-Latn",
          "for-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0029166666666666664,
        "hf_subset": "for_Latn-eng_Latn",
        "languages": [
          "for-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0029166666666666664,
        "precision": 0.0021158854166666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.578125,
        "f1": 0.4870194692460318,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ],
        "main_score": 0.4870194692460318,
        "precision": 0.4527824280753968,
        "recall": 0.578125
      },
      {
        "accuracy": 0.6640625,
        "f1": 0.5891276041666667,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5891276041666667,
        "precision": 0.5598028273809523,
        "recall": 0.6640625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.027706755050505048,
        "hf_subset": "eng_Latn-fue_Latn",
        "languages": [
          "eng-Latn",
          "fue-Latn"
        ],
        "main_score": 0.027706755050505048,
        "precision": 0.022555634469696967,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018470982142857143,
        "hf_subset": "fue_Latn-eng_Latn",
        "languages": [
          "fue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018470982142857143,
        "precision": 0.017401413690476188,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009033203125,
        "hf_subset": "eng_Latn-fuf_Latn",
        "languages": [
          "eng-Latn",
          "fuf-Latn"
        ],
        "main_score": 0.009033203125,
        "precision": 0.007324668778801844,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "fuf_Latn-eng_Latn",
        "languages": [
          "fuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016876619816586922,
        "hf_subset": "eng_Latn-fuh_Latn",
        "languages": [
          "eng-Latn",
          "fuh-Latn"
        ],
        "main_score": 0.016876619816586922,
        "precision": 0.013961147359584859,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005212886072261072,
        "hf_subset": "fuh_Latn-eng_Latn",
        "languages": [
          "fuh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005212886072261072,
        "precision": 0.003597470238095238,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01328125,
        "hf_subset": "eng_Latn-gah_Latn",
        "languages": [
          "eng-Latn",
          "gah-Latn"
        ],
        "main_score": 0.01328125,
        "precision": 0.0126953125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004240230747713142,
        "hf_subset": "gah_Latn-eng_Latn",
        "languages": [
          "gah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004240230747713142,
        "precision": 0.004075659999247328,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011067708333333332,
        "hf_subset": "eng_Latn-gai_Latn",
        "languages": [
          "eng-Latn",
          "gai-Latn"
        ],
        "main_score": 0.011067708333333332,
        "precision": 0.009824810606060606,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007924107142857142,
        "hf_subset": "gai_Latn-eng_Latn",
        "languages": [
          "gai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007924107142857142,
        "precision": 0.00786911231884058,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01328125,
        "hf_subset": "eng_Latn-gam_Latn",
        "languages": [
          "eng-Latn",
          "gam-Latn"
        ],
        "main_score": 0.01328125,
        "precision": 0.011393229166666668,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006141675420168067,
        "hf_subset": "gam_Latn-eng_Latn",
        "languages": [
          "gam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006141675420168067,
        "precision": 0.005241595508036739,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01031130393967932,
        "hf_subset": "eng_Latn-gaw_Latn",
        "languages": [
          "eng-Latn",
          "gaw-Latn"
        ],
        "main_score": 0.01031130393967932,
        "precision": 0.009191739533111816,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007031249999999999,
        "hf_subset": "gaw_Latn-eng_Latn",
        "languages": [
          "gaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007031249999999999,
        "precision": 0.006138392857142857,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "eng_Latn-gdn_Latn",
        "languages": [
          "eng-Latn",
          "gdn-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004216598252118644,
        "hf_subset": "gdn_Latn-eng_Latn",
        "languages": [
          "gdn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004216598252118644,
        "precision": 0.004065644816652881,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017615609217171715,
        "hf_subset": "eng_Latn-gdr_Latn",
        "languages": [
          "eng-Latn",
          "gdr-Latn"
        ],
        "main_score": 0.017615609217171715,
        "precision": 0.014199273459383755,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0018362374378952122,
        "hf_subset": "gdr_Latn-eng_Latn",
        "languages": [
          "gdr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0018362374378952122,
        "precision": 0.0009965945512820512,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003666580815018315,
        "hf_subset": "eng_Latn-geb_Latn",
        "languages": [
          "eng-Latn",
          "geb-Latn"
        ],
        "main_score": 0.003666580815018315,
        "precision": 0.0022586354617604616,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00103759765625,
        "hf_subset": "geb_Latn-eng_Latn",
        "languages": [
          "geb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00103759765625,
        "precision": 0.0005887935883014622,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004590338389680495,
        "hf_subset": "eng_Latn-gfk_Latn",
        "languages": [
          "eng-Latn",
          "gfk-Latn"
        ],
        "main_score": 0.004590338389680495,
        "precision": 0.0026642628205128206,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016690120341614906,
        "hf_subset": "gfk_Latn-eng_Latn",
        "languages": [
          "gfk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016690120341614906,
        "precision": 0.013358191287878787,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-ghs_Latn",
        "languages": [
          "eng-Latn",
          "ghs-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.002734375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005194241522366522,
        "hf_subset": "ghs_Latn-eng_Latn",
        "languages": [
          "ghs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005194241522366522,
        "precision": 0.004601704099471957,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03225806451612903,
        "f1": 0.014934289127837515,
        "hf_subset": "eng_Latn-glk_Arab",
        "languages": [
          "eng-Latn",
          "glk-Arab"
        ],
        "main_score": 0.014934289127837515,
        "precision": 0.010304659498207884,
        "recall": 0.03225806451612903
      },
      {
        "accuracy": 0.03225806451612903,
        "f1": 0.012181694661138052,
        "hf_subset": "glk_Arab-eng_Latn",
        "languages": [
          "glk-Arab",
          "eng-Latn"
        ],
        "main_score": 0.012181694661138052,
        "precision": 0.011492092137253428,
        "recall": 0.03225806451612903
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006088312728937729,
        "hf_subset": "eng_Latn-gmv_Latn",
        "languages": [
          "eng-Latn",
          "gmv-Latn"
        ],
        "main_score": 0.006088312728937729,
        "precision": 0.005157696759259259,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0030625699705940815,
        "hf_subset": "gmv_Latn-eng_Latn",
        "languages": [
          "gmv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0030625699705940815,
        "precision": 0.001887513528138528,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011269221230158728,
        "hf_subset": "eng_Latn-gng_Latn",
        "languages": [
          "eng-Latn",
          "gng-Latn"
        ],
        "main_score": 0.011269221230158728,
        "precision": 0.007750744047619046,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013170572916666666,
        "hf_subset": "gng_Latn-eng_Latn",
        "languages": [
          "gng-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013170572916666666,
        "precision": 0.011490885416666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0029743668300653593,
        "hf_subset": "eng_Latn-gnn_Latn",
        "languages": [
          "eng-Latn",
          "gnn-Latn"
        ],
        "main_score": 0.0029743668300653593,
        "precision": 0.0018684895833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.000864499140654032,
        "hf_subset": "gnn_Latn-eng_Latn",
        "languages": [
          "gnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000864499140654032,
        "precision": 0.00044945862960568846,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012925801107480029,
        "hf_subset": "eng_Latn-gnw_Latn",
        "languages": [
          "eng-Latn",
          "gnw-Latn"
        ],
        "main_score": 0.012925801107480029,
        "precision": 0.008756510416666665,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00926226293252895,
        "hf_subset": "gnw_Latn-eng_Latn",
        "languages": [
          "gnw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00926226293252895,
        "precision": 0.007477841739766082,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005185489766081871,
        "hf_subset": "eng_Latn-gof_Latn",
        "languages": [
          "eng-Latn",
          "gof-Latn"
        ],
        "main_score": 0.005185489766081871,
        "precision": 0.003309461805555555,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007412345888908389,
        "hf_subset": "gof_Latn-eng_Latn",
        "languages": [
          "gof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007412345888908389,
        "precision": 0.006062103660908808,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00654389880952381,
        "hf_subset": "eng_Latn-grc_Grek",
        "languages": [
          "eng-Latn",
          "grc-Grek"
        ],
        "main_score": 0.00654389880952381,
        "precision": 0.00556640625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0017581125192012287,
        "hf_subset": "grc_Grek-eng_Latn",
        "languages": [
          "grc-Grek",
          "eng-Latn"
        ],
        "main_score": 0.0017581125192012287,
        "precision": 0.0010190217391304348,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-gub_Latn",
        "languages": [
          "eng-Latn",
          "gub-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0029296875,
        "hf_subset": "gub_Latn-eng_Latn",
        "languages": [
          "gub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0029296875,
        "precision": 0.002122961956521739,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0039692540322580645,
        "hf_subset": "eng_Latn-guh_Latn",
        "languages": [
          "eng-Latn",
          "guh-Latn"
        ],
        "main_score": 0.0039692540322580645,
        "precision": 0.0039380081300813006,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007862903225806451,
        "hf_subset": "guh_Latn-eng_Latn",
        "languages": [
          "guh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007862903225806451,
        "precision": 0.00783786525974026,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009186921296296295,
        "hf_subset": "eng_Latn-gui_Latn",
        "languages": [
          "eng-Latn",
          "gui-Latn"
        ],
        "main_score": 0.009186921296296295,
        "precision": 0.007849007009345795,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006005792265441829,
        "hf_subset": "gui_Latn-eng_Latn",
        "languages": [
          "gui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006005792265441829,
        "precision": 0.003905306461352657,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0029999192675603963,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0029999192675603963,
        "precision": 0.0018548427483974358,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005702955898268398,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.005702955898268398,
        "precision": 0.004913140527950311,
        "recall": 0.015625
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.4791351877289377,
        "hf_subset": "eng_Latn-gul_Latn",
        "languages": [
          "eng-Latn",
          "gul-Latn"
        ],
        "main_score": 0.4791351877289377,
        "precision": 0.4521484375,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.5234375,
        "f1": 0.453577628968254,
        "hf_subset": "gul_Latn-eng_Latn",
        "languages": [
          "gul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.453577628968254,
        "precision": 0.4308159722222222,
        "recall": 0.5234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019466145833333334,
        "hf_subset": "eng_Latn-gum_Latn",
        "languages": [
          "eng-Latn",
          "gum-Latn"
        ],
        "main_score": 0.019466145833333334,
        "precision": 0.01696877565681445,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016248640394912986,
        "hf_subset": "gum_Latn-eng_Latn",
        "languages": [
          "gum-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016248640394912986,
        "precision": 0.013719512195121951,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02957785087719298,
        "hf_subset": "eng_Latn-gun_Latn",
        "languages": [
          "eng-Latn",
          "gun-Latn"
        ],
        "main_score": 0.02957785087719298,
        "precision": 0.025607638888888888,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01182001736588148,
        "hf_subset": "gun_Latn-eng_Latn",
        "languages": [
          "gun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01182001736588148,
        "precision": 0.008985150049603173,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007501132246376812,
        "hf_subset": "eng_Latn-guo_Latn",
        "languages": [
          "eng-Latn",
          "guo-Latn"
        ],
        "main_score": 0.007501132246376812,
        "precision": 0.005385890151515151,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006981981981981982,
        "hf_subset": "guo_Latn-eng_Latn",
        "languages": [
          "guo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006981981981981982,
        "precision": 0.006102580220306512,
        "recall": 0.015625
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08688068977591036,
        "hf_subset": "eng_Latn-gup_Latn",
        "languages": [
          "eng-Latn",
          "gup-Latn"
        ],
        "main_score": 0.08688068977591036,
        "precision": 0.08167413449754901,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.055056863419224084,
        "hf_subset": "gup_Latn-eng_Latn",
        "languages": [
          "gup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.055056863419224084,
        "precision": 0.051522435897435895,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020833333333333332,
        "hf_subset": "eng_Latn-gux_Latn",
        "languages": [
          "eng-Latn",
          "gux-Latn"
        ],
        "main_score": 0.020833333333333332,
        "precision": 0.017578125,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.011624063618067977,
        "hf_subset": "gux_Latn-eng_Latn",
        "languages": [
          "gux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011624063618067977,
        "precision": 0.00880629817545165,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01097470238095238,
        "hf_subset": "eng_Latn-gvc_Latn",
        "languages": [
          "eng-Latn",
          "gvc-Latn"
        ],
        "main_score": 0.01097470238095238,
        "precision": 0.010066105769230768,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002663352272727273,
        "hf_subset": "gvc_Latn-eng_Latn",
        "languages": [
          "gvc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002663352272727273,
        "precision": 0.0016927083333333334,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009229473039215686,
        "hf_subset": "eng_Latn-gvf_Latn",
        "languages": [
          "eng-Latn",
          "gvf-Latn"
        ],
        "main_score": 0.009229473039215686,
        "precision": 0.00865205223880597,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002170060117967332,
        "hf_subset": "gvf_Latn-eng_Latn",
        "languages": [
          "gvf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002170060117967332,
        "precision": 0.001412169886151549,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07362847222222221,
        "hf_subset": "eng_Latn-gvn_Latn",
        "languages": [
          "eng-Latn",
          "gvn-Latn"
        ],
        "main_score": 0.07362847222222221,
        "precision": 0.068883533239002,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.046886931439788004,
        "hf_subset": "gvn_Latn-eng_Latn",
        "languages": [
          "gvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.046886931439788004,
        "precision": 0.03918698489010988,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.015625,
        "hf_subset": "eng_Latn-gvs_Latn",
        "languages": [
          "eng-Latn",
          "gvs-Latn"
        ],
        "main_score": 0.015625,
        "precision": 0.014322916666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0031238600726787406,
        "hf_subset": "gvs_Latn-eng_Latn",
        "languages": [
          "gvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0031238600726787406,
        "precision": 0.0019231263843332807,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06097146126443001,
        "hf_subset": "eng_Latn-gwi_Latn",
        "languages": [
          "eng-Latn",
          "gwi-Latn"
        ],
        "main_score": 0.06097146126443001,
        "precision": 0.05367024739583334,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07413353012285093,
        "hf_subset": "gwi_Latn-eng_Latn",
        "languages": [
          "gwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07413353012285093,
        "precision": 0.068515125453859,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011571636811171009,
        "hf_subset": "eng_Latn-gym_Latn",
        "languages": [
          "eng-Latn",
          "gym-Latn"
        ],
        "main_score": 0.011571636811171009,
        "precision": 0.009196780065496098,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004059677512737378,
        "hf_subset": "gym_Latn-eng_Latn",
        "languages": [
          "gym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004059677512737378,
        "precision": 0.00398375496031746,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009422348484848485,
        "hf_subset": "eng_Latn-gyr_Latn",
        "languages": [
          "eng-Latn",
          "gyr-Latn"
        ],
        "main_score": 0.009422348484848485,
        "precision": 0.008697248931623932,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00487813995215311,
        "hf_subset": "gyr_Latn-eng_Latn",
        "languages": [
          "gyr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00487813995215311,
        "precision": 0.004414850117975118,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02903968114021217,
        "hf_subset": "eng_Latn-hat_Latn",
        "languages": [
          "eng-Latn",
          "hat-Latn"
        ],
        "main_score": 0.02903968114021217,
        "precision": 0.02599921037935018,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03052096015963203,
        "hf_subset": "hat_Latn-eng_Latn",
        "languages": [
          "hat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03052096015963203,
        "precision": 0.026345403101845948,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028893729967948714,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ],
        "main_score": 0.028893729967948714,
        "precision": 0.02705592105263158,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0150836471716008,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0150836471716008,
        "precision": 0.011633256066849817,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02501430860805861,
        "hf_subset": "eng_Latn-haw_Latn",
        "languages": [
          "eng-Latn",
          "haw-Latn"
        ],
        "main_score": 0.02501430860805861,
        "precision": 0.023106268274853802,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010146233974358973,
        "hf_subset": "haw_Latn-eng_Latn",
        "languages": [
          "haw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010146233974358973,
        "precision": 0.008199055989583332,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0018424968671679196,
        "hf_subset": "eng_Latn-hbo_Hebr",
        "languages": [
          "eng-Latn",
          "hbo-Hebr"
        ],
        "main_score": 0.0018424968671679196,
        "precision": 0.001035633848133848,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023251488095238095,
        "hf_subset": "hbo_Hebr-eng_Latn",
        "languages": [
          "hbo-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0023251488095238095,
        "precision": 0.0014973958333333332,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003552827380952381,
        "hf_subset": "eng_Latn-hch_Latn",
        "languages": [
          "eng-Latn",
          "hch-Latn"
        ],
        "main_score": 0.003552827380952381,
        "precision": 0.0024591978744939267,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00014112903225806453,
        "hf_subset": "hch_Latn-eng_Latn",
        "languages": [
          "hch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00014112903225806453,
        "precision": 7.121520078837153e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007021795929592959,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ],
        "main_score": 0.007021795929592959,
        "precision": 0.006128216911764706,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020633950467934842,
        "hf_subset": "eng_Latn-heg_Latn",
        "languages": [
          "eng-Latn",
          "heg-Latn"
        ],
        "main_score": 0.020633950467934842,
        "precision": 0.01627935341708023,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008344396786492375,
        "hf_subset": "heg_Latn-eng_Latn",
        "languages": [
          "heg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008344396786492375,
        "precision": 0.008093147634345793,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008114769345238094,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.008114769345238094,
        "precision": 0.0067708333333333336,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00546875,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.003580729166666666,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0046875,
        "hf_subset": "eng_Latn-hix_Latn",
        "languages": [
          "eng-Latn",
          "hix-Latn"
        ],
        "main_score": 0.0046875,
        "precision": 0.004340277777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006510416666666666,
        "hf_subset": "hix_Latn-eng_Latn",
        "languages": [
          "hix-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.0003551136363636364,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016927083333333332,
        "hf_subset": "eng_Latn-hla_Latn",
        "languages": [
          "eng-Latn",
          "hla-Latn"
        ],
        "main_score": 0.016927083333333332,
        "precision": 0.014322916666666668,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.009503801520608243,
        "hf_subset": "hla_Latn-eng_Latn",
        "languages": [
          "hla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009503801520608243,
        "precision": 0.0075354784827441085,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.025944627409471156,
        "hf_subset": "eng_Latn-hlt_Latn",
        "languages": [
          "eng-Latn",
          "hlt-Latn"
        ],
        "main_score": 0.025944627409471156,
        "precision": 0.019744925213675213,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015511988993710691,
        "hf_subset": "hlt_Latn-eng_Latn",
        "languages": [
          "hlt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015511988993710691,
        "precision": 0.014307700933934487,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011290922619047619,
        "hf_subset": "eng_Latn-hmo_Latn",
        "languages": [
          "eng-Latn",
          "hmo-Latn"
        ],
        "main_score": 0.011290922619047619,
        "precision": 0.010235628342245989,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010173348063973063,
        "hf_subset": "hmo_Latn-eng_Latn",
        "languages": [
          "hmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010173348063973063,
        "precision": 0.007917340868876886,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007155593093093092,
        "hf_subset": "eng_Latn-hns_Latn",
        "languages": [
          "eng-Latn",
          "hns-Latn"
        ],
        "main_score": 0.007155593093093092,
        "precision": 0.00619766135620915,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008536184210526316,
        "hf_subset": "hns_Latn-eng_Latn",
        "languages": [
          "hns-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008536184210526316,
        "precision": 0.006239149305555556,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.046335847312409806,
        "hf_subset": "eng_Latn-hop_Latn",
        "languages": [
          "eng-Latn",
          "hop-Latn"
        ],
        "main_score": 0.046335847312409806,
        "precision": 0.041410668834841624,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.053953269675925924,
        "hf_subset": "hop_Latn-eng_Latn",
        "languages": [
          "hop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.053953269675925924,
        "precision": 0.049524967711141066,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006429036458333333,
        "hf_subset": "eng_Latn-hot_Latn",
        "languages": [
          "eng-Latn",
          "hot-Latn"
        ],
        "main_score": 0.006429036458333333,
        "precision": 0.004590293778801843,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0065183265186915884,
        "hf_subset": "hot_Latn-eng_Latn",
        "languages": [
          "hot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0065183265186915884,
        "precision": 0.005477699629380054,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02648292824074074,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ],
        "main_score": 0.02648292824074074,
        "precision": 0.024012608485264732,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025,
        "precision": 0.021158854166666664,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018424479166666667,
        "hf_subset": "eng_Latn-hto_Latn",
        "languages": [
          "eng-Latn",
          "hto-Latn"
        ],
        "main_score": 0.018424479166666667,
        "precision": 0.016462053571428572,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016927083333333332,
        "hf_subset": "hto_Latn-eng_Latn",
        "languages": [
          "hto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016927083333333332,
        "precision": 0.013971185064935065,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015592447916666665,
        "hf_subset": "eng_Latn-hub_Latn",
        "languages": [
          "eng-Latn",
          "hub-Latn"
        ],
        "main_score": 0.015592447916666665,
        "precision": 0.014366319444444445,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00849609375,
        "hf_subset": "hub_Latn-eng_Latn",
        "languages": [
          "hub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00849609375,
        "precision": 0.008173076923076922,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008407738095238095,
        "hf_subset": "eng_Latn-hui_Latn",
        "languages": [
          "eng-Latn",
          "hui-Latn"
        ],
        "main_score": 0.008407738095238095,
        "precision": 0.006944444444444444,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004665798611111111,
        "hf_subset": "hui_Latn-eng_Latn",
        "languages": [
          "hui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004665798611111111,
        "precision": 0.004316381241997439,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028674060314685314,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ],
        "main_score": 0.028674060314685314,
        "precision": 0.024309895833333334,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03660318231658692,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03660318231658692,
        "precision": 0.032678517512077294,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008964829985905566,
        "hf_subset": "eng_Latn-hus_Latn",
        "languages": [
          "eng-Latn",
          "hus-Latn"
        ],
        "main_score": 0.008964829985905566,
        "precision": 0.007224020285153591,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009274022108843538,
        "hf_subset": "hus_Latn-eng_Latn",
        "languages": [
          "hus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009274022108843538,
        "precision": 0.008675130208333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022632575757575754,
        "hf_subset": "eng_Latn-huu_Latn",
        "languages": [
          "eng-Latn",
          "huu-Latn"
        ],
        "main_score": 0.022632575757575754,
        "precision": 0.0206298828125,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00827752976190476,
        "hf_subset": "huu_Latn-eng_Latn",
        "languages": [
          "huu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00827752976190476,
        "precision": 0.006640625000000001,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004996512623305656,
        "hf_subset": "eng_Latn-huv_Latn",
        "languages": [
          "eng-Latn",
          "huv-Latn"
        ],
        "main_score": 0.004996512623305656,
        "precision": 0.0029554263565891472,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005192358193277311,
        "hf_subset": "huv_Latn-eng_Latn",
        "languages": [
          "huv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005192358193277311,
        "precision": 0.003471376713564213,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.047619047619047616,
        "f1": 0.023809523809523808,
        "hf_subset": "eng_Latn-hvn_Latn",
        "languages": [
          "eng-Latn",
          "hvn-Latn"
        ],
        "main_score": 0.023809523809523808,
        "precision": 0.01863876863876864,
        "recall": 0.047619047619047616
      },
      {
        "accuracy": 0.031746031746031744,
        "f1": 0.014413676098458705,
        "hf_subset": "hvn_Latn-eng_Latn",
        "languages": [
          "hvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014413676098458705,
        "precision": 0.012521528650560908,
        "recall": 0.031746031746031744
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004464285714285714,
        "hf_subset": "eng_Latn-ian_Latn",
        "languages": [
          "eng-Latn",
          "ian-Latn"
        ],
        "main_score": 0.004464285714285714,
        "precision": 0.004206730769230769,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010850694444444444,
        "hf_subset": "ian_Latn-eng_Latn",
        "languages": [
          "ian-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00010850694444444444,
        "precision": 5.501760563380282e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007261434019246519,
        "hf_subset": "eng_Latn-ign_Latn",
        "languages": [
          "eng-Latn",
          "ign-Latn"
        ],
        "main_score": 0.007261434019246519,
        "precision": 0.0059878923160173155,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0075721153846153855,
        "hf_subset": "ign_Latn-eng_Latn",
        "languages": [
          "ign-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0075721153846153855,
        "precision": 0.006261488970588235,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010821187417654808,
        "hf_subset": "eng_Latn-ikk_Latn",
        "languages": [
          "eng-Latn",
          "ikk-Latn"
        ],
        "main_score": 0.010821187417654808,
        "precision": 0.008571571657509158,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009457430739758325,
        "hf_subset": "ikk_Latn-eng_Latn",
        "languages": [
          "ikk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009457430739758325,
        "precision": 0.008691829004329006,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007534722222222222,
        "hf_subset": "eng_Latn-ikw_Latn",
        "languages": [
          "eng-Latn",
          "ikw-Latn"
        ],
        "main_score": 0.007534722222222222,
        "precision": 0.006427375637755102,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007626488095238095,
        "hf_subset": "ikw_Latn-eng_Latn",
        "languages": [
          "ikw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007626488095238095,
        "precision": 0.0004009046052631579,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014280243347338933,
        "hf_subset": "eng_Latn-ilo_Latn",
        "languages": [
          "eng-Latn",
          "ilo-Latn"
        ],
        "main_score": 0.014280243347338933,
        "precision": 0.010939825148809524,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017439829192546583,
        "hf_subset": "ilo_Latn-eng_Latn",
        "languages": [
          "ilo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017439829192546583,
        "precision": 0.013364239926739928,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.016276041666666664,
        "hf_subset": "eng_Latn-imo_Latn",
        "languages": [
          "eng-Latn",
          "imo-Latn"
        ],
        "main_score": 0.016276041666666664,
        "precision": 0.014973958333333332,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020532852564102565,
        "hf_subset": "imo_Latn-eng_Latn",
        "languages": [
          "imo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0020532852564102565,
        "precision": 0.0013528138528138528,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002176339285714286,
        "hf_subset": "eng_Latn-inb_Latn",
        "languages": [
          "eng-Latn",
          "inb-Latn"
        ],
        "main_score": 0.002176339285714286,
        "precision": 0.0014169730392156862,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0027342677948325885,
        "hf_subset": "inb_Latn-eng_Latn",
        "languages": [
          "inb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027342677948325885,
        "precision": 0.001718790753781951,
        "recall": 0.015625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.03785938089511413,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ],
        "main_score": 0.03785938089511413,
        "precision": 0.03091362847222222,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.034157469411375666,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.034157469411375666,
        "precision": 0.0298556676189149,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002647934173669468,
        "hf_subset": "eng_Latn-ino_Latn",
        "languages": [
          "eng-Latn",
          "ino-Latn"
        ],
        "main_score": 0.002647934173669468,
        "precision": 0.0015506628787878788,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027858527131782943,
        "hf_subset": "ino_Latn-eng_Latn",
        "languages": [
          "ino-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027858527131782943,
        "precision": 0.0020461309523809525,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0088796977124183,
        "hf_subset": "eng_Latn-iou_Latn",
        "languages": [
          "eng-Latn",
          "iou-Latn"
        ],
        "main_score": 0.0088796977124183,
        "precision": 0.006951827811716792,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011121544471153846,
        "hf_subset": "iou_Latn-eng_Latn",
        "languages": [
          "iou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011121544471153846,
        "precision": 0.010129127393009777,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0046875,
        "hf_subset": "eng_Latn-ipi_Latn",
        "languages": [
          "eng-Latn",
          "ipi-Latn"
        ],
        "main_score": 0.0046875,
        "precision": 0.004340277777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00028935185185185184,
        "hf_subset": "ipi_Latn-eng_Latn",
        "languages": [
          "ipi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00028935185185185184,
        "precision": 0.00015024038461538462,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008940972222222222,
        "hf_subset": "eng_Latn-isn_Latn",
        "languages": [
          "eng-Latn",
          "isn-Latn"
        ],
        "main_score": 0.008940972222222222,
        "precision": 0.006022135416666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00030048076923076925,
        "hf_subset": "isn_Latn-eng_Latn",
        "languages": [
          "isn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00030048076923076925,
        "precision": 0.00015625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.2890625,
        "f1": 0.21242071007696006,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ],
        "main_score": 0.21242071007696006,
        "precision": 0.19034312743526896,
        "recall": 0.2890625
      },
      {
        "accuracy": 0.37109375,
        "f1": 0.2860925099206349,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2860925099206349,
        "precision": 0.25805613274593053,
        "recall": 0.37109375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007869632227891157,
        "hf_subset": "eng_Latn-iws_Latn",
        "languages": [
          "eng-Latn",
          "iws-Latn"
        ],
        "main_score": 0.007869632227891157,
        "precision": 0.006355690204070758,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00011488970588235294,
        "hf_subset": "iws_Latn-eng_Latn",
        "languages": [
          "iws-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00011488970588235294,
        "precision": 5.830223880597015e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008711134785353535,
        "hf_subset": "eng_Latn-ixl_Latn",
        "languages": [
          "eng-Latn",
          "ixl-Latn"
        ],
        "main_score": 0.008711134785353535,
        "precision": 0.0071118903882575754,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012240859885620915,
        "hf_subset": "ixl_Latn-eng_Latn",
        "languages": [
          "ixl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012240859885620915,
        "precision": 0.00926437762605042,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019821526472431076,
        "hf_subset": "eng_Latn-jac_Latn",
        "languages": [
          "eng-Latn",
          "jac-Latn"
        ],
        "main_score": 0.019821526472431076,
        "precision": 0.01725668337510443,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016015625,
        "hf_subset": "jac_Latn-eng_Latn",
        "languages": [
          "jac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016015625,
        "precision": 0.014609088827838828,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02411538285818713,
        "hf_subset": "eng_Latn-jae_Latn",
        "languages": [
          "eng-Latn",
          "jae-Latn"
        ],
        "main_score": 0.02411538285818713,
        "precision": 0.020611049107142856,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01953659188034188,
        "hf_subset": "jae_Latn-eng_Latn",
        "languages": [
          "jae-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01953659188034188,
        "precision": 0.01685442429812834,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.031496062992125984,
        "f1": 0.007946613056346679,
        "hf_subset": "eng_Latn-jao_Latn",
        "languages": [
          "eng-Latn",
          "jao-Latn"
        ],
        "main_score": 0.007946613056346679,
        "precision": 0.005386431439153109,
        "recall": 0.031496062992125984
      },
      {
        "accuracy": 0.015748031496062992,
        "f1": 0.002110378094630063,
        "hf_subset": "jao_Latn-eng_Latn",
        "languages": [
          "jao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002110378094630063,
        "precision": 0.0011964413539216688,
        "recall": 0.015748031496062992
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-jic_Latn",
        "languages": [
          "eng-Latn",
          "jic-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.009244791666666667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014366079650092081,
        "hf_subset": "jic_Latn-eng_Latn",
        "languages": [
          "jic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014366079650092081,
        "precision": 0.013693576388888889,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013808389719848053,
        "hf_subset": "eng_Latn-jid_Latn",
        "languages": [
          "eng-Latn",
          "jid-Latn"
        ],
        "main_score": 0.013808389719848053,
        "precision": 0.010730251736111111,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02085700757575757,
        "hf_subset": "jid_Latn-eng_Latn",
        "languages": [
          "jid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02085700757575757,
        "precision": 0.017959449404761903,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.054123711340206e-05,
        "hf_subset": "eng_Latn-jiv_Latn",
        "languages": [
          "eng-Latn",
          "jiv-Latn"
        ],
        "main_score": 8.054123711340206e-05,
        "precision": 4.0690104166666664e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014753069196428572,
        "hf_subset": "jiv_Latn-eng_Latn",
        "languages": [
          "jiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014753069196428572,
        "precision": 0.013893157454760031,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006194196428571428,
        "hf_subset": "eng_Latn-jni_Latn",
        "languages": [
          "eng-Latn",
          "jni-Latn"
        ],
        "main_score": 0.006194196428571428,
        "precision": 0.003856169871794872,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00929363222561752,
        "hf_subset": "jni_Latn-eng_Latn",
        "languages": [
          "jni-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00929363222561752,
        "precision": 0.008602782507127019,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03912140376984127,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ],
        "main_score": 0.03912140376984127,
        "precision": 0.03398396588290741,
        "recall": 0.0625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015174994276556776,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.015174994276556776,
        "precision": 0.01412503087944664,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014761305337352332,
        "hf_subset": "eng_Latn-jvn_Latn",
        "languages": [
          "eng-Latn",
          "jvn-Latn"
        ],
        "main_score": 0.014761305337352332,
        "precision": 0.013473706279210011,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006548158212560386,
        "hf_subset": "jvn_Latn-eng_Latn",
        "languages": [
          "jvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006548158212560386,
        "precision": 0.005878337378640777,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004698714114832536,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.004698714114832536,
        "precision": 0.00433843085106383,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0018667387693122987,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0018667387693122987,
        "precision": 0.0010706779970760232,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011792834051724137,
        "hf_subset": "eng_Latn-kaq_Latn",
        "languages": [
          "eng-Latn",
          "kaq-Latn"
        ],
        "main_score": 0.011792834051724137,
        "precision": 0.008778352723665223,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004372451816160119,
        "hf_subset": "kaq_Latn-eng_Latn",
        "languages": [
          "kaq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004372451816160119,
        "precision": 0.0041509677895981084,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.028711484593837537,
        "hf_subset": "eng_Latn-kbc_Latn",
        "languages": [
          "eng-Latn",
          "kbc-Latn"
        ],
        "main_score": 0.028711484593837537,
        "precision": 0.02815810381355932,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009396983225108225,
        "hf_subset": "kbc_Latn-eng_Latn",
        "languages": [
          "kbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009396983225108225,
        "precision": 0.007512341030789826,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03127987132352941,
        "hf_subset": "eng_Latn-kbh_Latn",
        "languages": [
          "eng-Latn",
          "kbh-Latn"
        ],
        "main_score": 0.03127987132352941,
        "precision": 0.028596995580387953,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008439244030340728,
        "hf_subset": "kbh_Latn-eng_Latn",
        "languages": [
          "kbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008439244030340728,
        "precision": 0.008135092170865197,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017229352678571428,
        "hf_subset": "eng_Latn-kbm_Latn",
        "languages": [
          "eng-Latn",
          "kbm-Latn"
        ],
        "main_score": 0.017229352678571428,
        "precision": 0.014062499999999999,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009494826273532668,
        "hf_subset": "kbm_Latn-eng_Latn",
        "languages": [
          "kbm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009494826273532668,
        "precision": 0.008765403091060987,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013830885176651304,
        "hf_subset": "eng_Latn-kbq_Latn",
        "languages": [
          "eng-Latn",
          "kbq-Latn"
        ],
        "main_score": 0.013830885176651304,
        "precision": 0.011758814102564102,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008041654526029526,
        "hf_subset": "kbq_Latn-eng_Latn",
        "languages": [
          "kbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008041654526029526,
        "precision": 0.007928952831132452,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "eng_Latn-kdc_Latn",
        "languages": [
          "eng-Latn",
          "kdc-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0009668017535017012,
        "hf_subset": "kdc_Latn-eng_Latn",
        "languages": [
          "kdc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009668017535017012,
        "precision": 0.0005015851449275363,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0009915865384615384,
        "hf_subset": "eng_Latn-kde_Latn",
        "languages": [
          "eng-Latn",
          "kde-Latn"
        ],
        "main_score": 0.0009915865384615384,
        "precision": 0.0005311129385964911,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009342757936507937,
        "hf_subset": "kde_Latn-eng_Latn",
        "languages": [
          "kde-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009342757936507937,
        "precision": 0.007928291194420227,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013250612745098037,
        "hf_subset": "eng_Latn-kdl_Latn",
        "languages": [
          "eng-Latn",
          "kdl-Latn"
        ],
        "main_score": 0.013250612745098037,
        "precision": 0.011446496212121213,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "kdl_Latn-eng_Latn",
        "languages": [
          "kdl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01901827932500434,
        "hf_subset": "eng_Latn-kek_Latn",
        "languages": [
          "eng-Latn",
          "kek-Latn"
        ],
        "main_score": 0.01901827932500434,
        "precision": 0.016359747023809525,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.003920444921778763,
        "hf_subset": "kek_Latn-eng_Latn",
        "languages": [
          "kek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003920444921778763,
        "precision": 0.002394369633099141,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008874194631442948,
        "hf_subset": "eng_Latn-ken_Latn",
        "languages": [
          "eng-Latn",
          "ken-Latn"
        ],
        "main_score": 0.008874194631442948,
        "precision": 0.008398820465686276,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006366581879844961,
        "hf_subset": "ken_Latn-eng_Latn",
        "languages": [
          "ken-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006366581879844961,
        "precision": 0.005338541666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0117268632852077,
        "hf_subset": "eng_Latn-kew_Latn",
        "languages": [
          "eng-Latn",
          "kew-Latn"
        ],
        "main_score": 0.0117268632852077,
        "precision": 0.009081455795110686,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0009645314547837484,
        "hf_subset": "kew_Latn-eng_Latn",
        "languages": [
          "kew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009645314547837484,
        "precision": 0.0005268090780998389,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012536015070921985,
        "hf_subset": "eng_Latn-kgf_Latn",
        "languages": [
          "eng-Latn",
          "kgf-Latn"
        ],
        "main_score": 0.012536015070921985,
        "precision": 0.011152626811594204,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0005445348502304147,
        "hf_subset": "kgf_Latn-eng_Latn",
        "languages": [
          "kgf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005445348502304147,
        "precision": 0.00028093709477968896,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017975232233044734,
        "hf_subset": "eng_Latn-kgk_Latn",
        "languages": [
          "eng-Latn",
          "kgk-Latn"
        ],
        "main_score": 0.017975232233044734,
        "precision": 0.015529612187862949,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002372685185185185,
        "hf_subset": "kgk_Latn-eng_Latn",
        "languages": [
          "kgk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002372685185185185,
        "precision": 0.0013023288241578682,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.030313740079365076,
        "hf_subset": "eng_Latn-kgp_Latn",
        "languages": [
          "eng-Latn",
          "kgp-Latn"
        ],
        "main_score": 0.030313740079365076,
        "precision": 0.026023582175925927,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016536458333333334,
        "hf_subset": "kgp_Latn-eng_Latn",
        "languages": [
          "kgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016536458333333334,
        "precision": 0.013997395833333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-khs_Latn",
        "languages": [
          "eng-Latn",
          "khs-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013392857142857143,
        "hf_subset": "khs_Latn-eng_Latn",
        "languages": [
          "khs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013392857142857143,
        "precision": 0.0007659313725490196,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01800595238095238,
        "hf_subset": "eng_Latn-khz_Latn",
        "languages": [
          "eng-Latn",
          "khz-Latn"
        ],
        "main_score": 0.01800595238095238,
        "precision": 0.01698574862637363,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011120345823284626,
        "hf_subset": "khz_Latn-eng_Latn",
        "languages": [
          "khz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011120345823284626,
        "precision": 0.008707805037078933,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02435458764097744,
        "hf_subset": "eng_Latn-kik_Latn",
        "languages": [
          "eng-Latn",
          "kik-Latn"
        ],
        "main_score": 0.02435458764097744,
        "precision": 0.022746505696873344,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007492941086691086,
        "hf_subset": "kik_Latn-eng_Latn",
        "languages": [
          "kik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007492941086691086,
        "precision": 0.005201822916666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.13253012048192772,
        "f1": 0.09320137693631668,
        "hf_subset": "eng_Latn-kiw_Latn",
        "languages": [
          "eng-Latn",
          "kiw-Latn"
        ],
        "main_score": 0.09320137693631668,
        "precision": 0.08338114362210748,
        "recall": 0.13253012048192772
      },
      {
        "accuracy": 0.10843373493975904,
        "f1": 0.06628050664195242,
        "hf_subset": "kiw_Latn-eng_Latn",
        "languages": [
          "kiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06628050664195242,
        "precision": 0.05960181578444102,
        "recall": 0.10843373493975904
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01960136217948718,
        "hf_subset": "eng_Latn-kiz_Latn",
        "languages": [
          "eng-Latn",
          "kiz-Latn"
        ],
        "main_score": 0.01960136217948718,
        "precision": 0.01702987938596491,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013887206160873439,
        "hf_subset": "kiz_Latn-eng_Latn",
        "languages": [
          "kiz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013887206160873439,
        "precision": 0.011871279761904762,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026228918650793652,
        "hf_subset": "eng_Latn-kje_Latn",
        "languages": [
          "eng-Latn",
          "kje-Latn"
        ],
        "main_score": 0.026228918650793652,
        "precision": 0.022765421272675734,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023982931091096723,
        "hf_subset": "kje_Latn-eng_Latn",
        "languages": [
          "kje-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023982931091096723,
        "precision": 0.021356336805555556,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008641098484848484,
        "hf_subset": "eng_Latn-kjs_Latn",
        "languages": [
          "eng-Latn",
          "kjs-Latn"
        ],
        "main_score": 0.008641098484848484,
        "precision": 0.005764206118493909,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00020525799024918745,
        "hf_subset": "kjs_Latn-eng_Latn",
        "languages": [
          "kjs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00020525799024918745,
        "precision": 0.00010429703796412182,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023871527777777776,
        "hf_subset": "eng_Latn-kkc_Latn",
        "languages": [
          "eng-Latn",
          "kkc-Latn"
        ],
        "main_score": 0.023871527777777776,
        "precision": 0.020131138392857142,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009784249519728458,
        "hf_subset": "kkc_Latn-eng_Latn",
        "languages": [
          "kkc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009784249519728458,
        "precision": 0.008940717660475725,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.039515612991326304,
        "hf_subset": "eng_Latn-kkl_Latn",
        "languages": [
          "eng-Latn",
          "kkl-Latn"
        ],
        "main_score": 0.039515612991326304,
        "precision": 0.03452000473484848,
        "recall": 0.0625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011364850427350427,
        "hf_subset": "kkl_Latn-eng_Latn",
        "languages": [
          "kkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011364850427350427,
        "precision": 0.009047623346815614,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.027394480519480516,
        "hf_subset": "eng_Latn-klt_Latn",
        "languages": [
          "eng-Latn",
          "klt-Latn"
        ],
        "main_score": 0.027394480519480516,
        "precision": 0.022488592679022368,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01822081997863248,
        "hf_subset": "klt_Latn-eng_Latn",
        "languages": [
          "klt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01822081997863248,
        "precision": 0.016071005817099568,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005749685755136336,
        "hf_subset": "eng_Latn-klv_Latn",
        "languages": [
          "eng-Latn",
          "klv-Latn"
        ],
        "main_score": 0.005749685755136336,
        "precision": 0.0049012445887445895,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005185081845238095,
        "hf_subset": "klv_Latn-eng_Latn",
        "languages": [
          "klv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005185081845238095,
        "precision": 0.004640403368794326,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0026515151515151512,
        "hf_subset": "eng_Latn-kmg_Latn",
        "languages": [
          "eng-Latn",
          "kmg-Latn"
        ],
        "main_score": 0.0026515151515151512,
        "precision": 0.0016719442137320042,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "kmg_Latn-eng_Latn",
        "languages": [
          "kmg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.007947198275862068,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010730131172839507,
        "hf_subset": "eng_Latn-kmh_Latn",
        "languages": [
          "eng-Latn",
          "kmh-Latn"
        ],
        "main_score": 0.010730131172839507,
        "precision": 0.008479817708333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008270444662034554,
        "hf_subset": "kmh_Latn-eng_Latn",
        "languages": [
          "kmh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008270444662034554,
        "precision": 0.008046228002070393,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01494140625,
        "hf_subset": "eng_Latn-kmk_Latn",
        "languages": [
          "eng-Latn",
          "kmk-Latn"
        ],
        "main_score": 0.01494140625,
        "precision": 0.013715277777777778,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022734484418767506,
        "hf_subset": "kmk_Latn-eng_Latn",
        "languages": [
          "kmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022734484418767506,
        "precision": 0.021799538352272725,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015701941287878787,
        "hf_subset": "eng_Latn-kmo_Latn",
        "languages": [
          "eng-Latn",
          "kmo-Latn"
        ],
        "main_score": 0.015701941287878787,
        "precision": 0.012153811177248678,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007083714896214896,
        "hf_subset": "kmo_Latn-eng_Latn",
        "languages": [
          "kmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007083714896214896,
        "precision": 0.0058809671013189445,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02182491987179487,
        "hf_subset": "eng_Latn-kms_Latn",
        "languages": [
          "eng-Latn",
          "kms-Latn"
        ],
        "main_score": 0.02182491987179487,
        "precision": 0.01976643490829346,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006736241131257391,
        "hf_subset": "kms_Latn-eng_Latn",
        "languages": [
          "kms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006736241131257391,
        "precision": 0.00597457555465368,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004557291666666666,
        "hf_subset": "eng_Latn-kmu_Latn",
        "languages": [
          "eng-Latn",
          "kmu-Latn"
        ],
        "main_score": 0.004557291666666666,
        "precision": 0.003255208333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "kmu_Latn-eng_Latn",
        "languages": [
          "kmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.035017881916198514,
        "hf_subset": "eng_Latn-kne_Latn",
        "languages": [
          "eng-Latn",
          "kne-Latn"
        ],
        "main_score": 0.035017881916198514,
        "precision": 0.03120944922534362,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029978120938921375,
        "hf_subset": "kne_Latn-eng_Latn",
        "languages": [
          "kne-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029978120938921375,
        "precision": 0.02704732875631313,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012636170253357754,
        "hf_subset": "eng_Latn-knf_Latn",
        "languages": [
          "eng-Latn",
          "knf-Latn"
        ],
        "main_score": 0.012636170253357754,
        "precision": 0.00868954613095238,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009670472756410257,
        "hf_subset": "knf_Latn-eng_Latn",
        "languages": [
          "knf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009670472756410257,
        "precision": 0.008855294011544012,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02052671370967742,
        "hf_subset": "eng_Latn-knj_Latn",
        "languages": [
          "eng-Latn",
          "knj-Latn"
        ],
        "main_score": 0.02052671370967742,
        "precision": 0.017760093167701864,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016664391181229775,
        "hf_subset": "knj_Latn-eng_Latn",
        "languages": [
          "knj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016664391181229775,
        "precision": 0.013872931985294119,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006680253623188406,
        "hf_subset": "eng_Latn-knv_Latn",
        "languages": [
          "eng-Latn",
          "knv-Latn"
        ],
        "main_score": 0.006680253623188406,
        "precision": 0.005946180555555555,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027207711442786067,
        "hf_subset": "knv_Latn-eng_Latn",
        "languages": [
          "knv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027207711442786067,
        "precision": 0.002012310606060606,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07373728526220615,
        "hf_subset": "eng_Latn-kos_Latn",
        "languages": [
          "eng-Latn",
          "kos-Latn"
        ],
        "main_score": 0.07373728526220615,
        "precision": 0.06569523141788766,
        "recall": 0.109375
      },
      {
        "accuracy": 0.125,
        "f1": 0.08451857344895028,
        "hf_subset": "kos_Latn-eng_Latn",
        "languages": [
          "kos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08451857344895028,
        "precision": 0.07751859680340296,
        "recall": 0.125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015476919934640523,
        "hf_subset": "eng_Latn-kpf_Latn",
        "languages": [
          "eng-Latn",
          "kpf-Latn"
        ],
        "main_score": 0.015476919934640523,
        "precision": 0.011442057291666665,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00017361111111111112,
        "hf_subset": "kpf_Latn-eng_Latn",
        "languages": [
          "kpf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00017361111111111112,
        "precision": 8.87784090909091e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.09404141865079364,
        "hf_subset": "eng_Latn-kpg_Latn",
        "languages": [
          "eng-Latn",
          "kpg-Latn"
        ],
        "main_score": 0.09404141865079364,
        "precision": 0.0884084990530303,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0705069918592437,
        "hf_subset": "kpg_Latn-eng_Latn",
        "languages": [
          "kpg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0705069918592437,
        "precision": 0.06367748271183474,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017080269607843136,
        "hf_subset": "eng_Latn-kpj_Latn",
        "languages": [
          "eng-Latn",
          "kpj-Latn"
        ],
        "main_score": 0.017080269607843136,
        "precision": 0.015703125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001688508064516129,
        "hf_subset": "kpj_Latn-eng_Latn",
        "languages": [
          "kpj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001688508064516129,
        "precision": 0.0010405993852459017,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.040603706531954886,
        "hf_subset": "eng_Latn-kpr_Latn",
        "languages": [
          "eng-Latn",
          "kpr-Latn"
        ],
        "main_score": 0.040603706531954886,
        "precision": 0.03876035533840331,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020584259679370838,
        "hf_subset": "kpr_Latn-eng_Latn",
        "languages": [
          "kpr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020584259679370838,
        "precision": 0.018971990523182953,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01095610119047619,
        "hf_subset": "eng_Latn-kpw_Latn",
        "languages": [
          "eng-Latn",
          "kpw-Latn"
        ],
        "main_score": 0.01095610119047619,
        "precision": 0.00849313446969697,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0035292477696674774,
        "hf_subset": "kpw_Latn-eng_Latn",
        "languages": [
          "kpw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0035292477696674774,
        "precision": 0.002470128676470588,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009976773648648648,
        "hf_subset": "eng_Latn-kpx_Latn",
        "languages": [
          "eng-Latn",
          "kpx-Latn"
        ],
        "main_score": 0.009976773648648648,
        "precision": 0.009223090277777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0071351882309941515,
        "hf_subset": "kpx_Latn-eng_Latn",
        "languages": [
          "kpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0071351882309941515,
        "precision": 0.004994122815349544,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.06349206349206349,
        "f1": 0.0419501133786848,
        "hf_subset": "eng_Latn-kqa_Latn",
        "languages": [
          "eng-Latn",
          "kqa-Latn"
        ],
        "main_score": 0.0419501133786848,
        "precision": 0.03825803825803826,
        "recall": 0.06349206349206349
      },
      {
        "accuracy": 0.047619047619047616,
        "f1": 0.02275132275132275,
        "hf_subset": "kqa_Latn-eng_Latn",
        "languages": [
          "kqa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02275132275132275,
        "precision": 0.019883040935672513,
        "recall": 0.047619047619047616
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.07570142873391228,
        "hf_subset": "eng_Latn-kqc_Latn",
        "languages": [
          "eng-Latn",
          "kqc-Latn"
        ],
        "main_score": 0.07570142873391228,
        "precision": 0.06845238817558322,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05627463231105839,
        "hf_subset": "kqc_Latn-eng_Latn",
        "languages": [
          "kqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05627463231105839,
        "precision": 0.052167830287645,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027083333333333334,
        "hf_subset": "eng_Latn-kqf_Latn",
        "languages": [
          "eng-Latn",
          "kqf-Latn"
        ],
        "main_score": 0.027083333333333334,
        "precision": 0.023250078914141412,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020636470734126985,
        "hf_subset": "kqf_Latn-eng_Latn",
        "languages": [
          "kqf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020636470734126985,
        "precision": 0.017413145005543678,
        "recall": 0.046875
      },
      {
        "accuracy": 0.07142857142857142,
        "f1": 0.04461430726136609,
        "hf_subset": "eng_Latn-kql_Latn",
        "languages": [
          "eng-Latn",
          "kql-Latn"
        ],
        "main_score": 0.04461430726136609,
        "precision": 0.04120284477427335,
        "recall": 0.07142857142857142
      },
      {
        "accuracy": 0.07857142857142857,
        "f1": 0.03117165242165242,
        "hf_subset": "kql_Latn-eng_Latn",
        "languages": [
          "kql-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03117165242165242,
        "precision": 0.023012820512820515,
        "recall": 0.07857142857142857
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02623850743348983,
        "hf_subset": "eng_Latn-kqw_Latn",
        "languages": [
          "eng-Latn",
          "kqw-Latn"
        ],
        "main_score": 0.02623850743348983,
        "precision": 0.022958519345238095,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021087571282883782,
        "hf_subset": "kqw_Latn-eng_Latn",
        "languages": [
          "kqw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021087571282883782,
        "precision": 0.019348534378484935,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023095238095238092,
        "hf_subset": "eng_Latn-ksd_Latn",
        "languages": [
          "eng-Latn",
          "ksd-Latn"
        ],
        "main_score": 0.023095238095238092,
        "precision": 0.019692544106606605,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017672691546813016,
        "hf_subset": "ksd_Latn-eng_Latn",
        "languages": [
          "ksd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017672691546813016,
        "precision": 0.01576808608058608,
        "recall": 0.03125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.05208333333333333,
        "hf_subset": "eng_Latn-ksj_Latn",
        "languages": [
          "eng-Latn",
          "ksj-Latn"
        ],
        "main_score": 0.05208333333333333,
        "precision": 0.047135416666666666,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016142745686331214,
        "hf_subset": "ksj_Latn-eng_Latn",
        "languages": [
          "ksj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016142745686331214,
        "precision": 0.014404592803030303,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008121899801587302,
        "hf_subset": "eng_Latn-ksr_Latn",
        "languages": [
          "eng-Latn",
          "ksr-Latn"
        ],
        "main_score": 0.008121899801587302,
        "precision": 0.0053463750557041,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006699672965116279,
        "hf_subset": "ksr_Latn-eng_Latn",
        "languages": [
          "ksr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006699672965116279,
        "precision": 0.00035342261904761904,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.05101018772893773,
        "hf_subset": "eng_Latn-ktm_Latn",
        "languages": [
          "eng-Latn",
          "ktm-Latn"
        ],
        "main_score": 0.05101018772893773,
        "precision": 0.04108024288340658,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.054526584181490305,
        "hf_subset": "ktm_Latn-eng_Latn",
        "languages": [
          "ktm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.054526584181490305,
        "precision": 0.04980533047453278,
        "recall": 0.09375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021809357782369143,
        "hf_subset": "eng_Latn-kto_Latn",
        "languages": [
          "eng-Latn",
          "kto-Latn"
        ],
        "main_score": 0.021809357782369143,
        "precision": 0.019780815972222223,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012934027777777777,
        "hf_subset": "kto_Latn-eng_Latn",
        "languages": [
          "kto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012934027777777777,
        "precision": 0.011363695372216683,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02630208333333333,
        "hf_subset": "eng_Latn-kud_Latn",
        "languages": [
          "eng-Latn",
          "kud-Latn"
        ],
        "main_score": 0.02630208333333333,
        "precision": 0.023111979166666664,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012710210945663531,
        "hf_subset": "kud_Latn-eng_Latn",
        "languages": [
          "kud-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012710210945663531,
        "precision": 0.011243054417868064,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014072760318949343,
        "hf_subset": "eng_Latn-kue_Latn",
        "languages": [
          "eng-Latn",
          "kue-Latn"
        ],
        "main_score": 0.014072760318949343,
        "precision": 0.013118489583333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008278508771929824,
        "hf_subset": "kue_Latn-eng_Latn",
        "languages": [
          "kue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008278508771929824,
        "precision": 0.006941511824324324,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-kup_Latn",
        "languages": [
          "eng-Latn",
          "kup-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.00625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002589142628205128,
        "hf_subset": "kup_Latn-eng_Latn",
        "languages": [
          "kup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002589142628205128,
        "precision": 0.0015597998271889401,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012137276785714286,
        "hf_subset": "eng_Latn-kvg_Latn",
        "languages": [
          "eng-Latn",
          "kvg-Latn"
        ],
        "main_score": 0.012137276785714286,
        "precision": 0.009542410714285715,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002833946078431372,
        "hf_subset": "kvg_Latn-eng_Latn",
        "languages": [
          "kvg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002833946078431372,
        "precision": 0.00014433262711864407,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01804315476190476,
        "hf_subset": "eng_Latn-kvn_Latn",
        "languages": [
          "eng-Latn",
          "kvn-Latn"
        ],
        "main_score": 0.01804315476190476,
        "precision": 0.016276041666666664,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01584102746212121,
        "hf_subset": "kvn_Latn-eng_Latn",
        "languages": [
          "kvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01584102746212121,
        "precision": 0.013363369342755638,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009253771551724138,
        "hf_subset": "eng_Latn-kwd_Latn",
        "languages": [
          "eng-Latn",
          "kwd-Latn"
        ],
        "main_score": 0.009253771551724138,
        "precision": 0.007300967261904762,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004248615967365968,
        "hf_subset": "kwd_Latn-eng_Latn",
        "languages": [
          "kwd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004248615967365968,
        "precision": 0.0040813840155945426,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02369791666666667,
        "hf_subset": "eng_Latn-kwf_Latn",
        "languages": [
          "eng-Latn",
          "kwf-Latn"
        ],
        "main_score": 0.02369791666666667,
        "precision": 0.02097284226190476,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005920410156249999,
        "hf_subset": "kwf_Latn-eng_Latn",
        "languages": [
          "kwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005920410156249999,
        "precision": 0.004067216207349081,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01115141369047619,
        "hf_subset": "eng_Latn-kwi_Latn",
        "languages": [
          "eng-Latn",
          "kwi-Latn"
        ],
        "main_score": 0.01115141369047619,
        "precision": 0.009781124106871389,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013822115384615384,
        "hf_subset": "kwi_Latn-eng_Latn",
        "languages": [
          "kwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013822115384615384,
        "precision": 0.013097426470588234,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007936507936507936,
        "hf_subset": "eng_Latn-kwj_Latn",
        "languages": [
          "eng-Latn",
          "kwj-Latn"
        ],
        "main_score": 0.007936507936507936,
        "precision": 0.006648137019230769,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000832312091503268,
        "hf_subset": "kwj_Latn-eng_Latn",
        "languages": [
          "kwj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000832312091503268,
        "precision": 0.00045972679093567246,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004117398648648648,
        "hf_subset": "eng_Latn-kyc_Latn",
        "languages": [
          "eng-Latn",
          "kyc-Latn"
        ],
        "main_score": 0.004117398648648648,
        "precision": 0.004014756944444444,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.763719512195122e-05,
        "hf_subset": "kyc_Latn-eng_Latn",
        "languages": [
          "kyc-Latn",
          "eng-Latn"
        ],
        "main_score": 4.763719512195122e-05,
        "precision": 2.396472392638037e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007486979166666666,
        "hf_subset": "eng_Latn-kyf_Latn",
        "languages": [
          "eng-Latn",
          "kyf-Latn"
        ],
        "main_score": 0.007486979166666666,
        "precision": 0.006417410714285714,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004298397904483431,
        "hf_subset": "kyf_Latn-eng_Latn",
        "languages": [
          "kyf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004298397904483431,
        "precision": 0.004108573717948719,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00427827380952381,
        "hf_subset": "eng_Latn-kyg_Latn",
        "languages": [
          "eng-Latn",
          "kyg-Latn"
        ],
        "main_score": 0.00427827380952381,
        "precision": 0.0041015625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kyg_Latn-eng_Latn",
        "languages": [
          "kyg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0043680726600985225,
        "hf_subset": "eng_Latn-kyq_Latn",
        "languages": [
          "eng-Latn",
          "kyq-Latn"
        ],
        "main_score": 0.0043680726600985225,
        "precision": 0.004146984011627907,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0019400126854020297,
        "hf_subset": "kyq_Latn-eng_Latn",
        "languages": [
          "kyq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019400126854020297,
        "precision": 0.0011065323565323565,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023686079545454545,
        "hf_subset": "eng_Latn-kyz_Latn",
        "languages": [
          "eng-Latn",
          "kyz-Latn"
        ],
        "main_score": 0.023686079545454545,
        "precision": 0.021327457264957266,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00018601190476190475,
        "hf_subset": "kyz_Latn-eng_Latn",
        "languages": [
          "kyz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00018601190476190475,
        "precision": 9.527439024390244e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006111391129032258,
        "hf_subset": "eng_Latn-kze_Latn",
        "languages": [
          "eng-Latn",
          "kze-Latn"
        ],
        "main_score": 0.006111391129032258,
        "precision": 0.005338541666666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006707339225322342,
        "hf_subset": "kze_Latn-eng_Latn",
        "languages": [
          "kze-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006707339225322342,
        "precision": 0.005959095528455285,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01941034226190476,
        "hf_subset": "eng_Latn-lac_Latn",
        "languages": [
          "eng-Latn",
          "lac-Latn"
        ],
        "main_score": 0.01941034226190476,
        "precision": 0.01703966948621554,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008463541666666666,
        "hf_subset": "lac_Latn-eng_Latn",
        "languages": [
          "lac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008463541666666666,
        "precision": 0.007161458333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.4765625,
        "f1": 0.39044828869047615,
        "hf_subset": "eng_Latn-lat_Latn",
        "languages": [
          "eng-Latn",
          "lat-Latn"
        ],
        "main_score": 0.39044828869047615,
        "precision": 0.36221168154761907,
        "recall": 0.4765625
      },
      {
        "accuracy": 0.375,
        "f1": 0.3037690662202381,
        "hf_subset": "lat_Latn-eng_Latn",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3037690662202381,
        "precision": 0.2820394505248336,
        "recall": 0.375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018371158413765604,
        "hf_subset": "eng_Latn-lbb_Latn",
        "languages": [
          "eng-Latn",
          "lbb-Latn"
        ],
        "main_score": 0.018371158413765604,
        "precision": 0.01604689029723787,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007133458232658814,
        "hf_subset": "lbb_Latn-eng_Latn",
        "languages": [
          "lbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007133458232658814,
        "precision": 0.005704541227002164,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025394886573050272,
        "hf_subset": "eng_Latn-lbk_Latn",
        "languages": [
          "eng-Latn",
          "lbk-Latn"
        ],
        "main_score": 0.025394886573050272,
        "precision": 0.02229929322979696,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.031248289545703335,
        "hf_subset": "lbk_Latn-eng_Latn",
        "languages": [
          "lbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031248289545703335,
        "precision": 0.028592771181437132,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014145728403540905,
        "hf_subset": "eng_Latn-lcm_Latn",
        "languages": [
          "eng-Latn",
          "lcm-Latn"
        ],
        "main_score": 0.014145728403540905,
        "precision": 0.01165829613095238,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013545501610676485,
        "hf_subset": "lcm_Latn-eng_Latn",
        "languages": [
          "lcm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013545501610676485,
        "precision": 0.01283017113095238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017830141129032258,
        "hf_subset": "eng_Latn-leu_Latn",
        "languages": [
          "eng-Latn",
          "leu-Latn"
        ],
        "main_score": 0.017830141129032258,
        "precision": 0.015104166666666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005390625,
        "hf_subset": "leu_Latn-eng_Latn",
        "languages": [
          "leu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005390625,
        "precision": 0.0036873653017241376,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022274925595238096,
        "hf_subset": "eng_Latn-lex_Latn",
        "languages": [
          "eng-Latn",
          "lex-Latn"
        ],
        "main_score": 0.022274925595238096,
        "precision": 0.01874490306362658,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025553385416666664,
        "hf_subset": "lex_Latn-eng_Latn",
        "languages": [
          "lex-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025553385416666664,
        "precision": 0.021914628623188406,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02486559139784946,
        "hf_subset": "eng_Latn-lgl_Latn",
        "languages": [
          "eng-Latn",
          "lgl-Latn"
        ],
        "main_score": 0.02486559139784946,
        "precision": 0.0242827868852459,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.017659406565656566,
        "hf_subset": "lgl_Latn-eng_Latn",
        "languages": [
          "lgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017659406565656566,
        "precision": 0.014243105701876708,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019203869047619046,
        "hf_subset": "eng_Latn-lid_Latn",
        "languages": [
          "eng-Latn",
          "lid-Latn"
        ],
        "main_score": 0.019203869047619046,
        "precision": 0.015383751293349509,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00655334249084249,
        "hf_subset": "lid_Latn-eng_Latn",
        "languages": [
          "lid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00655334249084249,
        "precision": 0.0058809564917127076,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01674413275302284,
        "hf_subset": "eng_Latn-lif_Deva",
        "languages": [
          "eng-Latn",
          "lif-Deva"
        ],
        "main_score": 0.01674413275302284,
        "precision": 0.013503790329537614,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0011447975852272728,
        "hf_subset": "lif_Deva-eng_Latn",
        "languages": [
          "lif-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0011447975852272728,
        "precision": 0.0006153893849206349,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017143143315018313,
        "hf_subset": "eng_Latn-lin_Latn",
        "languages": [
          "eng-Latn",
          "lin-Latn"
        ],
        "main_score": 0.017143143315018313,
        "precision": 0.015432731586224234,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002493351063829787,
        "hf_subset": "lin_Latn-eng_Latn",
        "languages": [
          "lin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002493351063829787,
        "precision": 0.0001269211664329126,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01616166948198198,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ],
        "main_score": 0.01616166948198198,
        "precision": 0.014468625992063491,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014571340460526315,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014571340460526315,
        "precision": 0.011425210160818714,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012606136204481793,
        "hf_subset": "eng_Latn-llg_Latn",
        "languages": [
          "eng-Latn",
          "llg-Latn"
        ],
        "main_score": 0.012606136204481793,
        "precision": 0.00949319386471694,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013029431996855346,
        "hf_subset": "llg_Latn-eng_Latn",
        "languages": [
          "llg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013029431996855346,
        "precision": 0.010035342261904761,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-lug_Latn",
        "languages": [
          "eng-Latn",
          "lug-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002924028290465984,
        "hf_subset": "lug_Latn-eng_Latn",
        "languages": [
          "lug-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002924028290465984,
        "precision": 0.0018139683667027415,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020150220975692672,
        "hf_subset": "eng_Latn-luo_Latn",
        "languages": [
          "eng-Latn",
          "luo-Latn"
        ],
        "main_score": 0.020150220975692672,
        "precision": 0.016098636606449106,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.016829258309318265,
        "hf_subset": "luo_Latn-eng_Latn",
        "languages": [
          "luo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016829258309318265,
        "precision": 0.012825420826932924,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005837180397727273,
        "hf_subset": "eng_Latn-lww_Latn",
        "languages": [
          "eng-Latn",
          "lww-Latn"
        ],
        "main_score": 0.005837180397727273,
        "precision": 0.004980918778801843,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006609309071729958,
        "hf_subset": "lww_Latn-eng_Latn",
        "languages": [
          "lww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006609309071729958,
        "precision": 0.005909455128205128,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02590813669217687,
        "hf_subset": "eng_Latn-maa_Latn",
        "languages": [
          "eng-Latn",
          "maa-Latn"
        ],
        "main_score": 0.02590813669217687,
        "precision": 0.022477213541666666,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016036184210526314,
        "hf_subset": "maa_Latn-eng_Latn",
        "languages": [
          "maa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016036184210526314,
        "precision": 0.013470362103174604,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.035876225490196076,
        "hf_subset": "eng_Latn-maj_Latn",
        "languages": [
          "eng-Latn",
          "maj-Latn"
        ],
        "main_score": 0.035876225490196076,
        "precision": 0.033251953125,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016612554112554113,
        "hf_subset": "maj_Latn-eng_Latn",
        "languages": [
          "maj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016612554112554113,
        "precision": 0.013727678571428571,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0031490039235190096,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.0031490039235190096,
        "precision": 0.001804315476190476,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.001852784514682105,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.001852784514682105,
        "precision": 0.0010644061443036911,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.016311813186813188,
        "hf_subset": "eng_Latn-mam_Latn",
        "languages": [
          "eng-Latn",
          "mam-Latn"
        ],
        "main_score": 0.016311813186813188,
        "precision": 0.012433525219298244,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015336980834997477,
        "hf_subset": "mam_Latn-eng_Latn",
        "languages": [
          "mam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015336980834997477,
        "precision": 0.012726707076820484,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014827106829573933,
        "hf_subset": "eng_Latn-maq_Latn",
        "languages": [
          "eng-Latn",
          "maq-Latn"
        ],
        "main_score": 0.014827106829573933,
        "precision": 0.013935952141900937,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005910669191919192,
        "hf_subset": "maq_Latn-eng_Latn",
        "languages": [
          "maq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005910669191919192,
        "precision": 0.003995709115213882,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011718749999999998,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.011718749999999998,
        "precision": 0.010546875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008142118298368299,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.008142118298368299,
        "precision": 0.0064569805194805195,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014525866240805266,
        "hf_subset": "eng_Latn-mau_Latn",
        "languages": [
          "eng-Latn",
          "mau-Latn"
        ],
        "main_score": 0.014525866240805266,
        "precision": 0.012204649390243903,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018603547030339784,
        "hf_subset": "mau_Latn-eng_Latn",
        "languages": [
          "mau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018603547030339784,
        "precision": 0.015227787078373013,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0013908080349777263,
        "hf_subset": "eng_Latn-mav_Latn",
        "languages": [
          "eng-Latn",
          "mav-Latn"
        ],
        "main_score": 0.0013908080349777263,
        "precision": 0.0007471478174603174,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013469827586206896,
        "hf_subset": "mav_Latn-eng_Latn",
        "languages": [
          "mav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00013469827586206896,
        "precision": 6.853070175438596e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03248510835727969,
        "hf_subset": "eng_Latn-maz_Latn",
        "languages": [
          "eng-Latn",
          "maz-Latn"
        ],
        "main_score": 0.03248510835727969,
        "precision": 0.030755361381103075,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.012824779684844023,
        "hf_subset": "maz_Latn-eng_Latn",
        "languages": [
          "maz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012824779684844023,
        "precision": 0.008740479865824536,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.061572265625000004,
        "hf_subset": "eng_Latn-mbb_Latn",
        "languages": [
          "eng-Latn",
          "mbb-Latn"
        ],
        "main_score": 0.061572265625000004,
        "precision": 0.05488030324849881,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.051064661186444274,
        "hf_subset": "mbb_Latn-eng_Latn",
        "languages": [
          "mbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.051064661186444274,
        "precision": 0.042985790175078246,
        "recall": 0.09375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01583837515835755,
        "hf_subset": "eng_Latn-mbc_Latn",
        "languages": [
          "eng-Latn",
          "mbc-Latn"
        ],
        "main_score": 0.01583837515835755,
        "precision": 0.014528960622710623,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010230654761904762,
        "hf_subset": "mbc_Latn-eng_Latn",
        "languages": [
          "mbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010230654761904762,
        "precision": 0.007942708333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.021914493013382816,
        "hf_subset": "eng_Latn-mbh_Latn",
        "languages": [
          "eng-Latn",
          "mbh-Latn"
        ],
        "main_score": 0.021914493013382816,
        "precision": 0.018346831764800512,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007880434782608695,
        "hf_subset": "mbh_Latn-eng_Latn",
        "languages": [
          "mbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007880434782608695,
        "precision": 0.007846765350877194,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-mbj_Latn",
        "languages": [
          "eng-Latn",
          "mbj-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005074786324786325,
        "hf_subset": "mbj_Latn-eng_Latn",
        "languages": [
          "mbj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005074786324786325,
        "precision": 0.00455078125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003515625,
        "hf_subset": "eng_Latn-mbl_Latn",
        "languages": [
          "eng-Latn",
          "mbl-Latn"
        ],
        "main_score": 0.003515625,
        "precision": 0.002278645833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0005248438359393415,
        "hf_subset": "mbl_Latn-eng_Latn",
        "languages": [
          "mbl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005248438359393415,
        "precision": 0.0002692555696770335,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027194463522588523,
        "hf_subset": "eng_Latn-mbs_Latn",
        "languages": [
          "eng-Latn",
          "mbs-Latn"
        ],
        "main_score": 0.027194463522588523,
        "precision": 0.022298177083333332,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016264447773972603,
        "hf_subset": "mbs_Latn-eng_Latn",
        "languages": [
          "mbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016264447773972603,
        "precision": 0.014845214111694153,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009579613095238094,
        "hf_subset": "eng_Latn-mbt_Latn",
        "languages": [
          "eng-Latn",
          "mbt-Latn"
        ],
        "main_score": 0.009579613095238094,
        "precision": 0.0078125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009289429482836495,
        "hf_subset": "mbt_Latn-eng_Latn",
        "languages": [
          "mbt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009289429482836495,
        "precision": 0.007515901353116369,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02257735947309746,
        "hf_subset": "eng_Latn-mca_Latn",
        "languages": [
          "eng-Latn",
          "mca-Latn"
        ],
        "main_score": 0.02257735947309746,
        "precision": 0.017873830806500547,
        "recall": 0.046875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.019172660383597884,
        "hf_subset": "mca_Latn-eng_Latn",
        "languages": [
          "mca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019172660383597884,
        "precision": 0.013303786057692307,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0032039141414141417,
        "hf_subset": "eng_Latn-mcb_Latn",
        "languages": [
          "eng-Latn",
          "mcb-Latn"
        ],
        "main_score": 0.0032039141414141417,
        "precision": 0.001992984693877551,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006905498381128584,
        "hf_subset": "mcb_Latn-eng_Latn",
        "languages": [
          "mcb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006905498381128584,
        "precision": 0.006064833603896104,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007654389880952381,
        "hf_subset": "eng_Latn-mcd_Latn",
        "languages": [
          "eng-Latn",
          "mcd-Latn"
        ],
        "main_score": 0.007654389880952381,
        "precision": 0.005090287316849816,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007868303571428571,
        "hf_subset": "mcd_Latn-eng_Latn",
        "languages": [
          "mcd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007868303571428571,
        "precision": 0.007840602517985611,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-mcf_Latn",
        "languages": [
          "eng-Latn",
          "mcf-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003988486842105263,
        "hf_subset": "mcf_Latn-eng_Latn",
        "languages": [
          "mcf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003988486842105263,
        "precision": 0.00394780585106383,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025152745715059516,
        "hf_subset": "eng_Latn-mco_Latn",
        "languages": [
          "eng-Latn",
          "mco-Latn"
        ],
        "main_score": 0.025152745715059516,
        "precision": 0.022067095971440482,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01544228428320562,
        "hf_subset": "mco_Latn-eng_Latn",
        "languages": [
          "mco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01544228428320562,
        "precision": 0.011570788643680743,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.005706491513741394,
        "hf_subset": "eng_Latn-mcp_Latn",
        "languages": [
          "eng-Latn",
          "mcp-Latn"
        ],
        "main_score": 0.005706491513741394,
        "precision": 0.0034499497441520467,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00032775312626058897,
        "hf_subset": "mcp_Latn-eng_Latn",
        "languages": [
          "mcp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00032775312626058897,
        "precision": 0.0001676925505050505,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008796600877192981,
        "hf_subset": "eng_Latn-mcq_Latn",
        "languages": [
          "eng-Latn",
          "mcq-Latn"
        ],
        "main_score": 0.008796600877192981,
        "precision": 0.007215711805555556,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010791676740812379,
        "hf_subset": "mcq_Latn-eng_Latn",
        "languages": [
          "mcq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010791676740812379,
        "precision": 0.009562702922077922,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01308555734882043,
        "hf_subset": "eng_Latn-mcr_Latn",
        "languages": [
          "eng-Latn",
          "mcr-Latn"
        ],
        "main_score": 0.01308555734882043,
        "precision": 0.011258633848825174,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005541087962962963,
        "hf_subset": "mcr_Latn-eng_Latn",
        "languages": [
          "mcr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005541087962962963,
        "precision": 0.004919319509345795,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00487689393939394,
        "hf_subset": "eng_Latn-mdy_Latn",
        "languages": [
          "eng-Latn",
          "mdy-Latn"
        ],
        "main_score": 0.00487689393939394,
        "precision": 0.0033203125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0019404844119968428,
        "hf_subset": "mdy_Latn-eng_Latn",
        "languages": [
          "mdy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019404844119968428,
        "precision": 0.0011067708333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014680716036414564,
        "hf_subset": "eng_Latn-med_Latn",
        "languages": [
          "eng-Latn",
          "med-Latn"
        ],
        "main_score": 0.014680716036414564,
        "precision": 0.012653508771929826,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004445507981018119,
        "hf_subset": "med_Latn-eng_Latn",
        "languages": [
          "med-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004445507981018119,
        "precision": 0.004188368055555555,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00473804658426369,
        "hf_subset": "eng_Latn-mee_Latn",
        "languages": [
          "eng-Latn",
          "mee-Latn"
        ],
        "main_score": 0.00473804658426369,
        "precision": 0.0031080004070426622,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0032108191287878785,
        "hf_subset": "mee_Latn-eng_Latn",
        "languages": [
          "mee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0032108191287878785,
        "precision": 0.0022736378205128207,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.030785248699030508,
        "hf_subset": "eng_Latn-mek_Latn",
        "languages": [
          "eng-Latn",
          "mek-Latn"
        ],
        "main_score": 0.030785248699030508,
        "precision": 0.027537118583027764,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.009406921028998996,
        "hf_subset": "mek_Latn-eng_Latn",
        "languages": [
          "mek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009406921028998996,
        "precision": 0.007462599664792797,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.011774488532301031,
        "hf_subset": "eng_Latn-meq_Latn",
        "languages": [
          "eng-Latn",
          "meq-Latn"
        ],
        "main_score": 0.011774488532301031,
        "precision": 0.0092694291988463,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008613782051282052,
        "hf_subset": "meq_Latn-eng_Latn",
        "languages": [
          "meq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008613782051282052,
        "precision": 0.007238051470588236,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.008265746202327083,
        "hf_subset": "eng_Latn-met_Latn",
        "languages": [
          "eng-Latn",
          "met-Latn"
        ],
        "main_score": 0.008265746202327083,
        "precision": 0.005538616369843392,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008079452220077221,
        "hf_subset": "met_Latn-eng_Latn",
        "languages": [
          "met-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008079452220077221,
        "precision": 0.007949109462430055,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017717633928571428,
        "hf_subset": "eng_Latn-meu_Latn",
        "languages": [
          "eng-Latn",
          "meu-Latn"
        ],
        "main_score": 0.017717633928571428,
        "precision": 0.014524147727272726,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022243609098228666,
        "hf_subset": "meu_Latn-eng_Latn",
        "languages": [
          "meu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022243609098228666,
        "precision": 0.01912119998057498,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03177083333333333,
        "hf_subset": "eng_Latn-mgc_Latn",
        "languages": [
          "eng-Latn",
          "mgc-Latn"
        ],
        "main_score": 0.03177083333333333,
        "precision": 0.026953125,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01989965691137566,
        "hf_subset": "mgc_Latn-eng_Latn",
        "languages": [
          "mgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01989965691137566,
        "precision": 0.017342230327144117,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02234315035635965,
        "hf_subset": "eng_Latn-mgh_Latn",
        "languages": [
          "eng-Latn",
          "mgh-Latn"
        ],
        "main_score": 0.02234315035635965,
        "precision": 0.02007237554112554,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006720610119047619,
        "hf_subset": "mgh_Latn-eng_Latn",
        "languages": [
          "mgh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006720610119047619,
        "precision": 0.004483945412404091,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.07177033492822966,
        "f1": 0.037238930659983294,
        "hf_subset": "eng_Latn-mgw_Latn",
        "languages": [
          "eng-Latn",
          "mgw-Latn"
        ],
        "main_score": 0.037238930659983294,
        "precision": 0.03078954069666144,
        "recall": 0.07177033492822966
      },
      {
        "accuracy": 0.03349282296650718,
        "f1": 0.023790536948431685,
        "hf_subset": "mgw_Latn-eng_Latn",
        "languages": [
          "mgw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023790536948431685,
        "precision": 0.022337216559184525,
        "recall": 0.03349282296650718
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01285208532330243,
        "hf_subset": "eng_Latn-mhl_Latn",
        "languages": [
          "eng-Latn",
          "mhl-Latn"
        ],
        "main_score": 0.01285208532330243,
        "precision": 0.008653593223905723,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002438562776613091,
        "hf_subset": "mhl_Latn-eng_Latn",
        "languages": [
          "mhl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002438562776613091,
        "precision": 0.0001239483173076923,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025636817226890755,
        "hf_subset": "eng_Latn-mib_Latn",
        "languages": [
          "eng-Latn",
          "mib-Latn"
        ],
        "main_score": 0.025636817226890755,
        "precision": 0.023660300925925925,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012956832627118645,
        "hf_subset": "mib_Latn-eng_Latn",
        "languages": [
          "mib-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012956832627118645,
        "precision": 0.00980929135739991,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009852430555555555,
        "hf_subset": "eng_Latn-mic_Latn",
        "languages": [
          "eng-Latn",
          "mic-Latn"
        ],
        "main_score": 0.009852430555555555,
        "precision": 0.00792875744047619,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009834558823529412,
        "hf_subset": "mic_Latn-eng_Latn",
        "languages": [
          "mic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009834558823529412,
        "precision": 0.009033203125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.034857438568376066,
        "hf_subset": "eng_Latn-mie_Latn",
        "languages": [
          "eng-Latn",
          "mie-Latn"
        ],
        "main_score": 0.034857438568376066,
        "precision": 0.031126622486614262,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02584008984822451,
        "hf_subset": "mie_Latn-eng_Latn",
        "languages": [
          "mie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02584008984822451,
        "precision": 0.02234247303324739,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017515524839743588,
        "hf_subset": "eng_Latn-mig_Latn",
        "languages": [
          "eng-Latn",
          "mig-Latn"
        ],
        "main_score": 0.017515524839743588,
        "precision": 0.014464613970588236,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025595801767676767,
        "hf_subset": "mig_Latn-eng_Latn",
        "languages": [
          "mig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025595801767676767,
        "precision": 0.023273835358796294,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03104876893939394,
        "hf_subset": "eng_Latn-mih_Latn",
        "languages": [
          "eng-Latn",
          "mih-Latn"
        ],
        "main_score": 0.03104876893939394,
        "precision": 0.02736235119047619,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013211382113821137,
        "hf_subset": "mih_Latn-eng_Latn",
        "languages": [
          "mih-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013211382113821137,
        "precision": 0.01034860321969697,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0108316163003663,
        "hf_subset": "eng_Latn-mil_Latn",
        "languages": [
          "eng-Latn",
          "mil-Latn"
        ],
        "main_score": 0.0108316163003663,
        "precision": 0.009570312499999999,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0025828350262123195,
        "hf_subset": "mil_Latn-eng_Latn",
        "languages": [
          "mil-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0025828350262123195,
        "precision": 0.001638733084045584,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02519188130788785,
        "hf_subset": "eng_Latn-mio_Latn",
        "languages": [
          "eng-Latn",
          "mio-Latn"
        ],
        "main_score": 0.02519188130788785,
        "precision": 0.020879289215686273,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004925119248035915,
        "hf_subset": "mio_Latn-eng_Latn",
        "languages": [
          "mio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004925119248035915,
        "precision": 0.0033445749223602484,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010750311014557336,
        "hf_subset": "eng_Latn-mir_Latn",
        "languages": [
          "eng-Latn",
          "mir-Latn"
        ],
        "main_score": 0.010750311014557336,
        "precision": 0.007548466435185185,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015998276823223856,
        "hf_subset": "mir_Latn-eng_Latn",
        "languages": [
          "mir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015998276823223856,
        "precision": 0.013337509966685611,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03099468954248366,
        "hf_subset": "eng_Latn-mit_Latn",
        "languages": [
          "eng-Latn",
          "mit-Latn"
        ],
        "main_score": 0.03099468954248366,
        "precision": 0.026990692110177406,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008815056471306471,
        "hf_subset": "mit_Latn-eng_Latn",
        "languages": [
          "mit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008815056471306471,
        "precision": 0.007162529125548246,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018102340367965368,
        "hf_subset": "eng_Latn-miz_Latn",
        "languages": [
          "eng-Latn",
          "miz-Latn"
        ],
        "main_score": 0.018102340367965368,
        "precision": 0.016015625,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009489889705882352,
        "hf_subset": "miz_Latn-eng_Latn",
        "languages": [
          "miz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009489889705882352,
        "precision": 0.007545281405472637,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00945406092370744,
        "hf_subset": "eng_Latn-mjc_Latn",
        "languages": [
          "eng-Latn",
          "mjc-Latn"
        ],
        "main_score": 0.00945406092370744,
        "precision": 0.008728339605470287,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007530381944444444,
        "hf_subset": "mjc_Latn-eng_Latn",
        "languages": [
          "mjc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007530381944444444,
        "precision": 0.006439233339984038,
        "recall": 0.015625
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.0961405348124098,
        "hf_subset": "eng_Latn-mkj_Latn",
        "languages": [
          "eng-Latn",
          "mkj-Latn"
        ],
        "main_score": 0.0961405348124098,
        "precision": 0.07959175857843137,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.140625,
        "f1": 0.08854721702188939,
        "hf_subset": "mkj_Latn-eng_Latn",
        "languages": [
          "mkj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08854721702188939,
        "precision": 0.07731384537817383,
        "recall": 0.140625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012872023809523809,
        "hf_subset": "eng_Latn-mkl_Latn",
        "languages": [
          "eng-Latn",
          "mkl-Latn"
        ],
        "main_score": 0.012872023809523809,
        "precision": 0.012348090277777777,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mkl_Latn-eng_Latn",
        "languages": [
          "mkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01766284165181224,
        "hf_subset": "eng_Latn-mkn_Latn",
        "languages": [
          "eng-Latn",
          "mkn-Latn"
        ],
        "main_score": 0.01766284165181224,
        "precision": 0.014339192708333334,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01779744142351901,
        "hf_subset": "mkn_Latn-eng_Latn",
        "languages": [
          "mkn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01779744142351901,
        "precision": 0.01609002976190476,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018179086538461536,
        "hf_subset": "eng_Latn-mks_Latn",
        "languages": [
          "eng-Latn",
          "mks-Latn"
        ],
        "main_score": 0.018179086538461536,
        "precision": 0.015299479166666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005143229166666667,
        "hf_subset": "mks_Latn-eng_Latn",
        "languages": [
          "mks-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005143229166666667,
        "precision": 0.003487723214285714,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007219885149572648,
        "hf_subset": "eng_Latn-mle_Latn",
        "languages": [
          "eng-Latn",
          "mle-Latn"
        ],
        "main_score": 0.007219885149572648,
        "precision": 0.006239913438967136,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00023247722672064777,
        "hf_subset": "mle_Latn-eng_Latn",
        "languages": [
          "mle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00023247722672064777,
        "precision": 0.00011814898831873175,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01285208532330243,
        "hf_subset": "eng_Latn-mlh_Latn",
        "languages": [
          "eng-Latn",
          "mlh-Latn"
        ],
        "main_score": 0.01285208532330243,
        "precision": 0.008653593223905723,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002438562776613091,
        "hf_subset": "mlh_Latn-eng_Latn",
        "languages": [
          "mlh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002438562776613091,
        "precision": 0.0001239483173076923,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.024180453431372546,
        "hf_subset": "eng_Latn-mlp_Latn",
        "languages": [
          "eng-Latn",
          "mlp-Latn"
        ],
        "main_score": 0.024180453431372546,
        "precision": 0.022832961309523808,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005905330882352941,
        "hf_subset": "mlp_Latn-eng_Latn",
        "languages": [
          "mlp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005905330882352941,
        "precision": 0.005231447238658777,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01218377976190476,
        "hf_subset": "eng_Latn-mmo_Latn",
        "languages": [
          "eng-Latn",
          "mmo-Latn"
        ],
        "main_score": 0.01218377976190476,
        "precision": 0.010546875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "mmo_Latn-eng_Latn",
        "languages": [
          "mmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010652765769104082,
        "hf_subset": "eng_Latn-mmx_Latn",
        "languages": [
          "eng-Latn",
          "mmx-Latn"
        ],
        "main_score": 0.010652765769104082,
        "precision": 0.008641098484848484,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004340277777777778,
        "hf_subset": "mmx_Latn-eng_Latn",
        "languages": [
          "mmx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004340277777777778,
        "precision": 0.004136029411764706,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013591242302179802,
        "hf_subset": "eng_Latn-mna_Latn",
        "languages": [
          "eng-Latn",
          "mna-Latn"
        ],
        "main_score": 0.013591242302179802,
        "precision": 0.010488104174938787,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014938186813186812,
        "hf_subset": "mna_Latn-eng_Latn",
        "languages": [
          "mna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014938186813186812,
        "precision": 0.013748468137254902,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021354166666666667,
        "hf_subset": "eng_Latn-mop_Latn",
        "languages": [
          "eng-Latn",
          "mop-Latn"
        ],
        "main_score": 0.021354166666666667,
        "precision": 0.016927083333333332,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023623511904761904,
        "hf_subset": "mop_Latn-eng_Latn",
        "languages": [
          "mop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023623511904761904,
        "precision": 0.022330729166666667,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012865823412698412,
        "hf_subset": "eng_Latn-mox_Latn",
        "languages": [
          "eng-Latn",
          "mox-Latn"
        ],
        "main_score": 0.012865823412698412,
        "precision": 0.010904947916666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006324404761904762,
        "hf_subset": "mox_Latn-eng_Latn",
        "languages": [
          "mox-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006324404761904762,
        "precision": 0.004557291666666666,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.13253012048192772,
        "f1": 0.09497991967871486,
        "hf_subset": "eng_Latn-mph_Latn",
        "languages": [
          "eng-Latn",
          "mph-Latn"
        ],
        "main_score": 0.09497991967871486,
        "precision": 0.0840504876649455,
        "recall": 0.13253012048192772
      },
      {
        "accuracy": 0.060240963855421686,
        "f1": 0.02006916555109326,
        "hf_subset": "mph_Latn-eng_Latn",
        "languages": [
          "mph-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02006916555109326,
        "precision": 0.013314797652147051,
        "recall": 0.060240963855421686
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00078125,
        "hf_subset": "eng_Latn-mpj_Latn",
        "languages": [
          "eng-Latn",
          "mpj-Latn"
        ],
        "main_score": 0.00078125,
        "precision": 0.00043402777777777775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0016316529332504146,
        "hf_subset": "mpj_Latn-eng_Latn",
        "languages": [
          "mpj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016316529332504146,
        "precision": 0.0008896753602756892,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015391891464032421,
        "hf_subset": "eng_Latn-mpm_Latn",
        "languages": [
          "eng-Latn",
          "mpm-Latn"
        ],
        "main_score": 0.015391891464032421,
        "precision": 0.012872013464034111,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009569128787878786,
        "hf_subset": "mpm_Latn-eng_Latn",
        "languages": [
          "mpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009569128787878786,
        "precision": 0.00804759837962963,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013922551178410552,
        "hf_subset": "eng_Latn-mpp_Latn",
        "languages": [
          "eng-Latn",
          "mpp-Latn"
        ],
        "main_score": 0.013922551178410552,
        "precision": 0.013025101899204476,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011179681101556102,
        "hf_subset": "mpp_Latn-eng_Latn",
        "languages": [
          "mpp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011179681101556102,
        "precision": 0.0101828231292517,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014992559523809523,
        "hf_subset": "eng_Latn-mps_Latn",
        "languages": [
          "eng-Latn",
          "mps-Latn"
        ],
        "main_score": 0.014992559523809523,
        "precision": 0.009971217105263157,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.6781437125748506e-05,
        "hf_subset": "mps_Latn-eng_Latn",
        "languages": [
          "mps-Latn",
          "eng-Latn"
        ],
        "main_score": 4.6781437125748506e-05,
        "precision": 2.3531626506024098e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013174019607843136,
        "hf_subset": "eng_Latn-mpt_Latn",
        "languages": [
          "eng-Latn",
          "mpt-Latn"
        ],
        "main_score": 0.013174019607843136,
        "precision": 0.011796875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010579745596868886,
        "hf_subset": "mpt_Latn-eng_Latn",
        "languages": [
          "mpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010579745596868886,
        "precision": 0.0005758571388325445,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015656001984126984,
        "hf_subset": "eng_Latn-mpx_Latn",
        "languages": [
          "eng-Latn",
          "mpx-Latn"
        ],
        "main_score": 0.015656001984126984,
        "precision": 0.013213186553030302,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014424098966509681,
        "hf_subset": "mpx_Latn-eng_Latn",
        "languages": [
          "mpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014424098966509681,
        "precision": 0.013412666451890033,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027990542443667443,
        "hf_subset": "eng_Latn-mqb_Latn",
        "languages": [
          "eng-Latn",
          "mqb-Latn"
        ],
        "main_score": 0.027990542443667443,
        "precision": 0.024998163205329153,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020672686688311688,
        "hf_subset": "mqb_Latn-eng_Latn",
        "languages": [
          "mqb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020672686688311688,
        "precision": 0.01896989729020979,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011823195187165774,
        "hf_subset": "eng_Latn-mqj_Latn",
        "languages": [
          "eng-Latn",
          "mqj-Latn"
        ],
        "main_score": 0.011823195187165774,
        "precision": 0.01053790656887755,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007952008928571428,
        "hf_subset": "mqj_Latn-eng_Latn",
        "languages": [
          "mqj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007952008928571428,
        "precision": 0.005245535714285714,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.030890376984126982,
        "hf_subset": "eng_Latn-msb_Latn",
        "languages": [
          "eng-Latn",
          "msb-Latn"
        ],
        "main_score": 0.030890376984126982,
        "precision": 0.025813802083333334,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03674854892205638,
        "hf_subset": "msb_Latn-eng_Latn",
        "languages": [
          "msb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03674854892205638,
        "precision": 0.03145714962121212,
        "recall": 0.0625
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05206163194444444,
        "hf_subset": "eng_Latn-msc_Latn",
        "languages": [
          "eng-Latn",
          "msc-Latn"
        ],
        "main_score": 0.05206163194444444,
        "precision": 0.04440760679271708,
        "recall": 0.078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027949901956364945,
        "hf_subset": "msc_Latn-eng_Latn",
        "languages": [
          "msc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027949901956364945,
        "precision": 0.02508765043721419,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022302350427350424,
        "hf_subset": "eng_Latn-msk_Latn",
        "languages": [
          "eng-Latn",
          "msk-Latn"
        ],
        "main_score": 0.022302350427350424,
        "precision": 0.018581321022727273,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015214170258620688,
        "hf_subset": "msk_Latn-eng_Latn",
        "languages": [
          "msk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015214170258620688,
        "precision": 0.012654478830418136,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020751953125,
        "hf_subset": "eng_Latn-msm_Latn",
        "languages": [
          "eng-Latn",
          "msm-Latn"
        ],
        "main_score": 0.020751953125,
        "precision": 0.01891321044546851,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011067708333333332,
        "hf_subset": "msm_Latn-eng_Latn",
        "languages": [
          "msm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011067708333333332,
        "precision": 0.009895833333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.029162379158223575,
        "hf_subset": "eng_Latn-msy_Latn",
        "languages": [
          "eng-Latn",
          "msy-Latn"
        ],
        "main_score": 0.029162379158223575,
        "precision": 0.024314786343239025,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02287730135658915,
        "hf_subset": "msy_Latn-eng_Latn",
        "languages": [
          "msy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02287730135658915,
        "precision": 0.021885444518716577,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012390010351966874,
        "hf_subset": "eng_Latn-mti_Latn",
        "languages": [
          "eng-Latn",
          "mti-Latn"
        ],
        "main_score": 0.012390010351966874,
        "precision": 0.012076675622171946,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01587504546281142,
        "hf_subset": "mti_Latn-eng_Latn",
        "languages": [
          "mti-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01587504546281142,
        "precision": 0.014527679771505375,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008203125,
        "hf_subset": "eng_Latn-mto_Latn",
        "languages": [
          "eng-Latn",
          "mto-Latn"
        ],
        "main_score": 0.008203125,
        "precision": 0.006902145127118644,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008923100490196078,
        "hf_subset": "mto_Latn-eng_Latn",
        "languages": [
          "mto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008923100490196078,
        "precision": 0.006987072172619047,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004746685606060606,
        "hf_subset": "eng_Latn-mux_Latn",
        "languages": [
          "eng-Latn",
          "mux-Latn"
        ],
        "main_score": 0.004746685606060606,
        "precision": 0.003191207627118644,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0041387272267206475,
        "hf_subset": "mux_Latn-eng_Latn",
        "languages": [
          "mux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0041387272267206475,
        "precision": 0.004024398988318732,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012829545129349817,
        "hf_subset": "eng_Latn-muy_Latn",
        "languages": [
          "eng-Latn",
          "muy-Latn"
        ],
        "main_score": 0.012829545129349817,
        "precision": 0.010848595848595849,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "muy_Latn-eng_Latn",
        "languages": [
          "muy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020666956018518517,
        "hf_subset": "eng_Latn-mva_Latn",
        "languages": [
          "eng-Latn",
          "mva-Latn"
        ],
        "main_score": 0.020666956018518517,
        "precision": 0.017635359432234432,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012483016304347826,
        "hf_subset": "mva_Latn-eng_Latn",
        "languages": [
          "mva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012483016304347826,
        "precision": 0.01112515318627451,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.016244703064855717,
        "hf_subset": "eng_Latn-mvn_Latn",
        "languages": [
          "eng-Latn",
          "mvn-Latn"
        ],
        "main_score": 0.016244703064855717,
        "precision": 0.012926347740800866,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005612088585434173,
        "hf_subset": "mvn_Latn-eng_Latn",
        "languages": [
          "mvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005612088585434173,
        "precision": 0.004867639918785311,
        "recall": 0.015625
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.1716362847222222,
        "hf_subset": "eng_Latn-mwc_Latn",
        "languages": [
          "eng-Latn",
          "mwc-Latn"
        ],
        "main_score": 0.1716362847222222,
        "precision": 0.1555602058531746,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.1407264462054758,
        "hf_subset": "mwc_Latn-eng_Latn",
        "languages": [
          "mwc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1407264462054758,
        "precision": 0.1275884593146469,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005195455586080587,
        "hf_subset": "eng_Latn-mwe_Latn",
        "languages": [
          "eng-Latn",
          "mwe-Latn"
        ],
        "main_score": 0.005195455586080587,
        "precision": 0.0031433627136752142,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002559216421429919,
        "hf_subset": "mwe_Latn-eng_Latn",
        "languages": [
          "mwe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002559216421429919,
        "precision": 0.0016136532738095237,
        "recall": 0.015625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08019241962135731,
        "hf_subset": "eng_Latn-mwf_Latn",
        "languages": [
          "eng-Latn",
          "mwf-Latn"
        ],
        "main_score": 0.08019241962135731,
        "precision": 0.07106209921869389,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07937127976190476,
        "hf_subset": "mwf_Latn-eng_Latn",
        "languages": [
          "mwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07937127976190476,
        "precision": 0.07526830808080809,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007834610137158311,
        "hf_subset": "eng_Latn-mwp_Latn",
        "languages": [
          "eng-Latn",
          "mwp-Latn"
        ],
        "main_score": 0.007834610137158311,
        "precision": 0.00485413566468254,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010882935360777059,
        "hf_subset": "mwp_Latn-eng_Latn",
        "languages": [
          "mwp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010882935360777059,
        "precision": 0.009720335144927535,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.028813244047619046,
        "hf_subset": "eng_Latn-mxb_Latn",
        "languages": [
          "eng-Latn",
          "mxb-Latn"
        ],
        "main_score": 0.028813244047619046,
        "precision": 0.0260166266025641,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016341727120535714,
        "hf_subset": "mxb_Latn-eng_Latn",
        "languages": [
          "mxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016341727120535714,
        "precision": 0.012635926143246518,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026516249528657616,
        "hf_subset": "eng_Latn-mxp_Latn",
        "languages": [
          "eng-Latn",
          "mxp-Latn"
        ],
        "main_score": 0.026516249528657616,
        "precision": 0.02272057911706349,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011653510346144726,
        "hf_subset": "mxp_Latn-eng_Latn",
        "languages": [
          "mxp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011653510346144726,
        "precision": 0.009222169653040502,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.003511299141749723,
        "hf_subset": "eng_Latn-mxq_Latn",
        "languages": [
          "eng-Latn",
          "mxq-Latn"
        ],
        "main_score": 0.003511299141749723,
        "precision": 0.0021786375022982162,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00099444826007326,
        "hf_subset": "mxq_Latn-eng_Latn",
        "languages": [
          "mxq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00099444826007326,
        "precision": 0.0005159132880582788,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020005580357142855,
        "hf_subset": "eng_Latn-mxt_Latn",
        "languages": [
          "eng-Latn",
          "mxt-Latn"
        ],
        "main_score": 0.020005580357142855,
        "precision": 0.0185598544973545,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020182291666666664,
        "hf_subset": "mxt_Latn-eng_Latn",
        "languages": [
          "mxt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020182291666666664,
        "precision": 0.017578125,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.620762711864407e-05,
        "hf_subset": "eng_Latn-mya_Latn",
        "languages": [
          "eng-Latn",
          "mya-Latn"
        ],
        "main_score": 6.620762711864407e-05,
        "precision": 3.338675213675214e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mya_Latn-eng_Latn",
        "languages": [
          "mya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008138020833333334,
        "hf_subset": "eng_Latn-myk_Latn",
        "languages": [
          "eng-Latn",
          "myk-Latn"
        ],
        "main_score": 0.008138020833333334,
        "precision": 0.00798233695652174,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003720238095238095,
        "hf_subset": "myk_Latn-eng_Latn",
        "languages": [
          "myk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003720238095238095,
        "precision": 0.0001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016505349445812806,
        "hf_subset": "eng_Latn-myu_Latn",
        "languages": [
          "eng-Latn",
          "myu-Latn"
        ],
        "main_score": 0.016505349445812806,
        "precision": 0.014926373892580289,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013098184818481847,
        "hf_subset": "myu_Latn-eng_Latn",
        "languages": [
          "myu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013098184818481847,
        "precision": 0.0125390625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007751225490196078,
        "hf_subset": "eng_Latn-myw_Latn",
        "languages": [
          "eng-Latn",
          "myw-Latn"
        ],
        "main_score": 0.007751225490196078,
        "precision": 0.006537543402777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0013400855577482345,
        "hf_subset": "myw_Latn-eng_Latn",
        "languages": [
          "myw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013400855577482345,
        "precision": 0.000745181837979094,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02197265625,
        "hf_subset": "eng_Latn-myy_Latn",
        "languages": [
          "eng-Latn",
          "myy-Latn"
        ],
        "main_score": 0.02197265625,
        "precision": 0.019921875,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008852066532258064,
        "hf_subset": "myy_Latn-eng_Latn",
        "languages": [
          "myy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008852066532258064,
        "precision": 0.008402293844367015,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08,
        "f1": 0.04493333333333333,
        "hf_subset": "eng_Latn-mzz_Latn",
        "languages": [
          "eng-Latn",
          "mzz-Latn"
        ],
        "main_score": 0.04493333333333333,
        "precision": 0.03609235209235209,
        "recall": 0.08
      },
      {
        "accuracy": 0.04,
        "f1": 0.026666666666666665,
        "hf_subset": "mzz_Latn-eng_Latn",
        "languages": [
          "mzz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026666666666666665,
        "precision": 0.023393939393939394,
        "recall": 0.04
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013276143790849674,
        "hf_subset": "eng_Latn-nab_Latn",
        "languages": [
          "eng-Latn",
          "nab-Latn"
        ],
        "main_score": 0.0013276143790849674,
        "precision": 0.000732421875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000690699027072758,
        "hf_subset": "nab_Latn-eng_Latn",
        "languages": [
          "nab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000690699027072758,
        "precision": 0.0003750434833024119,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02597064393939394,
        "hf_subset": "eng_Latn-naf_Latn",
        "languages": [
          "eng-Latn",
          "naf-Latn"
        ],
        "main_score": 0.02597064393939394,
        "precision": 0.023828125,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004098714806435394,
        "hf_subset": "naf_Latn-eng_Latn",
        "languages": [
          "naf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004098714806435394,
        "precision": 0.0027525658700980394,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007649739583333332,
        "hf_subset": "eng_Latn-nak_Latn",
        "languages": [
          "eng-Latn",
          "nak-Latn"
        ],
        "main_score": 0.007649739583333332,
        "precision": 0.00546875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013469827586206896,
        "hf_subset": "nak_Latn-eng_Latn",
        "languages": [
          "nak-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00013469827586206896,
        "precision": 6.853070175438596e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0087890625,
        "hf_subset": "eng_Latn-nas_Latn",
        "languages": [
          "eng-Latn",
          "nas-Latn"
        ],
        "main_score": 0.0087890625,
        "precision": 0.008346688034188034,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0036604485544217687,
        "hf_subset": "nas_Latn-eng_Latn",
        "languages": [
          "nas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0036604485544217687,
        "precision": 0.002551431332842415,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020610400883838385,
        "hf_subset": "eng_Latn-nbq_Latn",
        "languages": [
          "eng-Latn",
          "nbq-Latn"
        ],
        "main_score": 0.020610400883838385,
        "precision": 0.01748407459574739,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009642321654040404,
        "hf_subset": "nbq_Latn-eng_Latn",
        "languages": [
          "nbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009642321654040404,
        "precision": 0.008783778070887446,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006091889880952381,
        "hf_subset": "eng_Latn-nca_Latn",
        "languages": [
          "eng-Latn",
          "nca-Latn"
        ],
        "main_score": 0.006091889880952381,
        "precision": 0.00511988011988012,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00048053075396825394,
        "hf_subset": "nca_Latn-eng_Latn",
        "languages": [
          "nca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00048053075396825394,
        "precision": 0.00025317013032758015,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016298870400432902,
        "hf_subset": "eng_Latn-nch_Latn",
        "languages": [
          "eng-Latn",
          "nch-Latn"
        ],
        "main_score": 0.016298870400432902,
        "precision": 0.014752885632048872,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014456626120358515,
        "hf_subset": "nch_Latn-eng_Latn",
        "languages": [
          "nch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014456626120358515,
        "precision": 0.012182176211001643,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014636049257759784,
        "hf_subset": "eng_Latn-ncj_Latn",
        "languages": [
          "eng-Latn",
          "ncj-Latn"
        ],
        "main_score": 0.014636049257759784,
        "precision": 0.013428030303030303,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022316659035409032,
        "hf_subset": "ncj_Latn-eng_Latn",
        "languages": [
          "ncj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022316659035409032,
        "precision": 0.0200961243872549,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015922752922640466,
        "hf_subset": "eng_Latn-ncl_Latn",
        "languages": [
          "eng-Latn",
          "ncl-Latn"
        ],
        "main_score": 0.015922752922640466,
        "precision": 0.01345968364197531,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012639508928571429,
        "hf_subset": "ncl_Latn-eng_Latn",
        "languages": [
          "ncl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012639508928571429,
        "precision": 0.012223800505050505,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006442698098228526,
        "hf_subset": "eng_Latn-ncu_Latn",
        "languages": [
          "eng-Latn",
          "ncu-Latn"
        ],
        "main_score": 0.006442698098228526,
        "precision": 0.0042029365555071195,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004013270547945206,
        "hf_subset": "ncu_Latn-eng_Latn",
        "languages": [
          "ncu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004013270547945206,
        "precision": 0.003960503472222222,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0174124053030303,
        "hf_subset": "eng_Latn-ndg_Latn",
        "languages": [
          "eng-Latn",
          "ndg-Latn"
        ],
        "main_score": 0.0174124053030303,
        "precision": 0.015203373015873017,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004627403846153846,
        "hf_subset": "ndg_Latn-eng_Latn",
        "languages": [
          "ndg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004627403846153846,
        "precision": 0.004292805989583333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013411458333333334,
        "hf_subset": "eng_Latn-ndj_Latn",
        "languages": [
          "eng-Latn",
          "ndj-Latn"
        ],
        "main_score": 0.013411458333333334,
        "precision": 0.01013454861111111,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026864035087719295,
        "hf_subset": "ndj_Latn-eng_Latn",
        "languages": [
          "ndj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026864035087719295,
        "precision": 0.0019946808510638296,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01274678333977269,
        "hf_subset": "eng_Latn-nfa_Latn",
        "languages": [
          "eng-Latn",
          "nfa-Latn"
        ],
        "main_score": 0.01274678333977269,
        "precision": 0.011083132587812353,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0023995535714285716,
        "hf_subset": "nfa_Latn-eng_Latn",
        "languages": [
          "nfa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0023995535714285716,
        "precision": 0.0015357779565821027,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010972100815850816,
        "hf_subset": "eng_Latn-ngp_Latn",
        "languages": [
          "eng-Latn",
          "ngp-Latn"
        ],
        "main_score": 0.010972100815850816,
        "precision": 0.00875234962406015,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001220703125,
        "hf_subset": "ngp_Latn-eng_Latn",
        "languages": [
          "ngp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001220703125,
        "precision": 0.0006840437788018433,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01498895294751273,
        "hf_subset": "eng_Latn-ngu_Latn",
        "languages": [
          "eng-Latn",
          "ngu-Latn"
        ],
        "main_score": 0.01498895294751273,
        "precision": 0.012064657934791315,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022614123774509803,
        "hf_subset": "ngu_Latn-eng_Latn",
        "languages": [
          "ngu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022614123774509803,
        "precision": 0.019843804709383753,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022334500841583886,
        "hf_subset": "eng_Latn-nhe_Latn",
        "languages": [
          "eng-Latn",
          "nhe-Latn"
        ],
        "main_score": 0.022334500841583886,
        "precision": 0.019127096861471862,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003967765748031496,
        "hf_subset": "nhe_Latn-eng_Latn",
        "languages": [
          "nhe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003967765748031496,
        "precision": 0.003937251984126984,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023689432709059235,
        "hf_subset": "eng_Latn-nhg_Latn",
        "languages": [
          "eng-Latn",
          "nhg-Latn"
        ],
        "main_score": 0.023689432709059235,
        "precision": 0.020675223214285714,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01895357396103095,
        "hf_subset": "nhg_Latn-eng_Latn",
        "languages": [
          "nhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01895357396103095,
        "precision": 0.01756235301157176,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014862351190476191,
        "hf_subset": "eng_Latn-nhi_Latn",
        "languages": [
          "eng-Latn",
          "nhi-Latn"
        ],
        "main_score": 0.014862351190476191,
        "precision": 0.011537905092592593,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015099966397849463,
        "hf_subset": "nhi_Latn-eng_Latn",
        "languages": [
          "nhi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015099966397849463,
        "precision": 0.012919150521609538,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05335477941176471,
        "hf_subset": "eng_Latn-nho_Latn",
        "languages": [
          "eng-Latn",
          "nho-Latn"
        ],
        "main_score": 0.05335477941176471,
        "precision": 0.049225514069264065,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.03236330638674388,
        "hf_subset": "nho_Latn-eng_Latn",
        "languages": [
          "nho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03236330638674388,
        "precision": 0.02560143849206349,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02734375,
        "hf_subset": "eng_Latn-nhr_Latn",
        "languages": [
          "eng-Latn",
          "nhr-Latn"
        ],
        "main_score": 0.02734375,
        "precision": 0.024088541666666664,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00543494549902817,
        "hf_subset": "nhr_Latn-eng_Latn",
        "languages": [
          "nhr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00543494549902817,
        "precision": 0.004739064292786291,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0099609375,
        "hf_subset": "eng_Latn-nhu_Latn",
        "languages": [
          "eng-Latn",
          "nhu-Latn"
        ],
        "main_score": 0.0099609375,
        "precision": 0.007746940559440559,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002976190476190476,
        "hf_subset": "nhu_Latn-eng_Latn",
        "languages": [
          "nhu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002976190476190476,
        "precision": 0.0021484375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020016209608843538,
        "hf_subset": "eng_Latn-nhw_Latn",
        "languages": [
          "eng-Latn",
          "nhw-Latn"
        ],
        "main_score": 0.020016209608843538,
        "precision": 0.019782467164855072,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01238296075357291,
        "hf_subset": "nhw_Latn-eng_Latn",
        "languages": [
          "nhw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01238296075357291,
        "precision": 0.010863339990601503,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020112168996997623,
        "hf_subset": "eng_Latn-nhy_Latn",
        "languages": [
          "eng-Latn",
          "nhy-Latn"
        ],
        "main_score": 0.020112168996997623,
        "precision": 0.017137896825396823,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01598625469924812,
        "hf_subset": "nhy_Latn-eng_Latn",
        "languages": [
          "nhy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01598625469924812,
        "precision": 0.013558182453627932,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02786939622877123,
        "hf_subset": "eng_Latn-nif_Latn",
        "languages": [
          "eng-Latn",
          "nif-Latn"
        ],
        "main_score": 0.02786939622877123,
        "precision": 0.02258093341503268,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.0396957353988604,
        "hf_subset": "nif_Latn-eng_Latn",
        "languages": [
          "nif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0396957353988604,
        "precision": 0.036764823717948716,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007691271551724138,
        "hf_subset": "eng_Latn-nii_Latn",
        "languages": [
          "eng-Latn",
          "nii-Latn"
        ],
        "main_score": 0.007691271551724138,
        "precision": 0.006324404761904762,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.945707070707071e-05,
        "hf_subset": "nii_Latn-eng_Latn",
        "languages": [
          "nii-Latn",
          "eng-Latn"
        ],
        "main_score": 3.945707070707071e-05,
        "precision": 1.9828680203045684e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014012896825396824,
        "hf_subset": "eng_Latn-nin_Latn",
        "languages": [
          "eng-Latn",
          "nin-Latn"
        ],
        "main_score": 0.014012896825396824,
        "precision": 0.011098160282258065,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010583600427350428,
        "hf_subset": "nin_Latn-eng_Latn",
        "languages": [
          "nin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010583600427350428,
        "precision": 0.009407552083333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02988967764525165,
        "hf_subset": "eng_Latn-nko_Latn",
        "languages": [
          "eng-Latn",
          "nko-Latn"
        ],
        "main_score": 0.02988967764525165,
        "precision": 0.026853538784584977,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012113230992125109,
        "hf_subset": "nko_Latn-eng_Latn",
        "languages": [
          "nko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012113230992125109,
        "precision": 0.01071672211423445,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.12220982142857142,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ],
        "main_score": 0.12220982142857142,
        "precision": 0.10924422057748538,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.20703125,
        "f1": 0.16804315476190473,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16804315476190473,
        "precision": 0.15520833333333334,
        "recall": 0.20703125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07613904936974789,
        "hf_subset": "eng_Latn-nlg_Latn",
        "languages": [
          "eng-Latn",
          "nlg-Latn"
        ],
        "main_score": 0.07613904936974789,
        "precision": 0.06906875510620915,
        "recall": 0.109375
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06258088699494949,
        "hf_subset": "nlg_Latn-eng_Latn",
        "languages": [
          "nlg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06258088699494949,
        "precision": 0.05780715630922363,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.11960634534639351,
        "hf_subset": "eng_Latn-nna_Latn",
        "languages": [
          "eng-Latn",
          "nna-Latn"
        ],
        "main_score": 0.11960634534639351,
        "precision": 0.11012201043408584,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.13344739613836337,
        "hf_subset": "nna_Latn-eng_Latn",
        "languages": [
          "nna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13344739613836337,
        "precision": 0.12484748280646718,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008907433712121212,
        "hf_subset": "eng_Latn-nnq_Latn",
        "languages": [
          "eng-Latn",
          "nnq-Latn"
        ],
        "main_score": 0.008907433712121212,
        "precision": 0.006477506868131868,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0006940738324899853,
        "hf_subset": "nnq_Latn-eng_Latn",
        "languages": [
          "nnq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006940738324899853,
        "precision": 0.00036319511587970445,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02528916396103896,
        "hf_subset": "eng_Latn-noa_Latn",
        "languages": [
          "eng-Latn",
          "noa-Latn"
        ],
        "main_score": 0.02528916396103896,
        "precision": 0.02223081242885022,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014748543906810036,
        "hf_subset": "noa_Latn-eng_Latn",
        "languages": [
          "noa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014748543906810036,
        "precision": 0.013890861742424241,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02109875801282051,
        "hf_subset": "eng_Latn-nop_Latn",
        "languages": [
          "eng-Latn",
          "nop-Latn"
        ],
        "main_score": 0.02109875801282051,
        "precision": 0.017959264953597762,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009893425223573036,
        "hf_subset": "nop_Latn-eng_Latn",
        "languages": [
          "nop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009893425223573036,
        "precision": 0.008967347756410258,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005425347222222222,
        "hf_subset": "eng_Latn-not_Latn",
        "languages": [
          "eng-Latn",
          "not-Latn"
        ],
        "main_score": 0.005425347222222222,
        "precision": 0.004799107142857142,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002904647435897436,
        "hf_subset": "not_Latn-eng_Latn",
        "languages": [
          "not-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002904647435897436,
        "precision": 0.002109375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.060046138757076255,
        "hf_subset": "eng_Latn-nou_Latn",
        "languages": [
          "eng-Latn",
          "nou-Latn"
        ],
        "main_score": 0.060046138757076255,
        "precision": 0.0544983878968254,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05613004449676083,
        "hf_subset": "nou_Latn-eng_Latn",
        "languages": [
          "nou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05613004449676083,
        "precision": 0.05191165710922482,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008717757936507935,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.008717757936507935,
        "precision": 0.007082164797008547,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0014322916666666668,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0014322916666666668,
        "precision": 0.0007891414141414141,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01611328125,
        "hf_subset": "eng_Latn-npl_Latn",
        "languages": [
          "eng-Latn",
          "npl-Latn"
        ],
        "main_score": 0.01611328125,
        "precision": 0.013932291666666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01057610544217687,
        "hf_subset": "npl_Latn-eng_Latn",
        "languages": [
          "npl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01057610544217687,
        "precision": 0.008544921875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.014797810696248196,
        "hf_subset": "eng_Latn-nsn_Latn",
        "languages": [
          "eng-Latn",
          "nsn-Latn"
        ],
        "main_score": 0.014797810696248196,
        "precision": 0.009735341354529616,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015509435431310429,
        "hf_subset": "nsn_Latn-eng_Latn",
        "languages": [
          "nsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015509435431310429,
        "precision": 0.01329514036266742,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02523002095812779,
        "hf_subset": "eng_Latn-nss_Latn",
        "languages": [
          "eng-Latn",
          "nss-Latn"
        ],
        "main_score": 0.02523002095812779,
        "precision": 0.021218852761821512,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015668890733023196,
        "hf_subset": "nss_Latn-eng_Latn",
        "languages": [
          "nss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015668890733023196,
        "precision": 0.011861823327815975,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0017485119047619048,
        "hf_subset": "eng_Latn-ntj_Latn",
        "languages": [
          "eng-Latn",
          "ntj-Latn"
        ],
        "main_score": 0.0017485119047619048,
        "precision": 0.0010718368902439025,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011897742587601077,
        "hf_subset": "ntj_Latn-eng_Latn",
        "languages": [
          "ntj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011897742587601077,
        "precision": 0.0006882440476190476,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00548735119047619,
        "hf_subset": "eng_Latn-ntp_Latn",
        "languages": [
          "eng-Latn",
          "ntp-Latn"
        ],
        "main_score": 0.00548735119047619,
        "precision": 0.0036603009259259262,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006760817307692308,
        "hf_subset": "ntp_Latn-eng_Latn",
        "languages": [
          "ntp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006760817307692308,
        "precision": 0.005690104166666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006552150106837607,
        "hf_subset": "eng_Latn-ntu_Latn",
        "languages": [
          "eng-Latn",
          "ntu-Latn"
        ],
        "main_score": 0.006552150106837607,
        "precision": 0.005433735994397759,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004471882735148515,
        "hf_subset": "ntu_Latn-eng_Latn",
        "languages": [
          "ntu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004471882735148515,
        "precision": 0.004205729166666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019525812728937726,
        "hf_subset": "eng_Latn-nuy_Latn",
        "languages": [
          "eng-Latn",
          "nuy-Latn"
        ],
        "main_score": 0.019525812728937726,
        "precision": 0.017275053879310345,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003672635048643113,
        "hf_subset": "nuy_Latn-eng_Latn",
        "languages": [
          "nuy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003672635048643113,
        "precision": 0.0025430032313997477,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010983109698681732,
        "hf_subset": "eng_Latn-nvm_Latn",
        "languages": [
          "eng-Latn",
          "nvm-Latn"
        ],
        "main_score": 0.010983109698681732,
        "precision": 0.010062753549695741,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005729166666666666,
        "hf_subset": "nvm_Latn-eng_Latn",
        "languages": [
          "nvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005729166666666666,
        "precision": 0.004966517857142857,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01673865685096154,
        "hf_subset": "eng_Latn-nwi_Latn",
        "languages": [
          "eng-Latn",
          "nwi-Latn"
        ],
        "main_score": 0.01673865685096154,
        "precision": 0.016218116906850457,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009216069240196079,
        "hf_subset": "nwi_Latn-eng_Latn",
        "languages": [
          "nwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009216069240196079,
        "precision": 0.007401905104905438,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014473157051282052,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ],
        "main_score": 0.014473157051282052,
        "precision": 0.012277275219298245,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.87784090909091e-05,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ],
        "main_score": 8.87784090909091e-05,
        "precision": 4.489942528735632e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.12295081967213115,
        "f1": 0.08091745757837217,
        "hf_subset": "eng_Latn-nys_Latn",
        "languages": [
          "eng-Latn",
          "nys-Latn"
        ],
        "main_score": 0.08091745757837217,
        "precision": 0.071100347739692,
        "recall": 0.12295081967213115
      },
      {
        "accuracy": 0.13934426229508196,
        "f1": 0.07694920361011817,
        "hf_subset": "nys_Latn-eng_Latn",
        "languages": [
          "nys-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07694920361011817,
        "precision": 0.06284434970421876,
        "recall": 0.13934426229508196
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012310309390901495,
        "hf_subset": "eng_Latn-nyu_Latn",
        "languages": [
          "eng-Latn",
          "nyu-Latn"
        ],
        "main_score": 0.012310309390901495,
        "precision": 0.009225063131313133,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01413690476190476,
        "hf_subset": "nyu_Latn-eng_Latn",
        "languages": [
          "nyu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01413690476190476,
        "precision": 0.011729029605263157,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025295128956903126,
        "hf_subset": "eng_Latn-obo_Latn",
        "languages": [
          "eng-Latn",
          "obo-Latn"
        ],
        "main_score": 0.025295128956903126,
        "precision": 0.021815532557720056,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013602283133533132,
        "hf_subset": "obo_Latn-eng_Latn",
        "languages": [
          "obo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013602283133533132,
        "precision": 0.011730238970588235,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.0724168727348233,
        "hf_subset": "eng_Latn-okv_Latn",
        "languages": [
          "eng-Latn",
          "okv-Latn"
        ],
        "main_score": 0.0724168727348233,
        "precision": 0.059298947580197575,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.08149181547619047,
        "hf_subset": "okv_Latn-eng_Latn",
        "languages": [
          "okv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08149181547619047,
        "precision": 0.07129207147108703,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0012408088235294117,
        "hf_subset": "eng_Latn-omw_Latn",
        "languages": [
          "eng-Latn",
          "omw-Latn"
        ],
        "main_score": 0.0012408088235294117,
        "precision": 0.0006781684027777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003358314479638009,
        "hf_subset": "omw_Latn-eng_Latn",
        "languages": [
          "omw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003358314479638009,
        "precision": 0.0023567708333333335,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02562302470330237,
        "hf_subset": "eng_Latn-ong_Latn",
        "languages": [
          "eng-Latn",
          "ong-Latn"
        ],
        "main_score": 0.02562302470330237,
        "precision": 0.02252000884813385,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006881218905472636,
        "hf_subset": "ong_Latn-eng_Latn",
        "languages": [
          "ong-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006881218905472636,
        "precision": 0.006051505717418546,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.030981919556138306,
        "hf_subset": "eng_Latn-ons_Latn",
        "languages": [
          "eng-Latn",
          "ons-Latn"
        ],
        "main_score": 0.030981919556138306,
        "precision": 0.029393627025462964,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01949386524359304,
        "hf_subset": "ons_Latn-eng_Latn",
        "languages": [
          "ons-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01949386524359304,
        "precision": 0.018236133702131747,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.035321800595238095,
        "hf_subset": "eng_Latn-ood_Latn",
        "languages": [
          "eng-Latn",
          "ood-Latn"
        ],
        "main_score": 0.035321800595238095,
        "precision": 0.03253879676870748,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.024826388888888887,
        "hf_subset": "ood_Latn-eng_Latn",
        "languages": [
          "ood-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024826388888888887,
        "precision": 0.024262640449438204,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011195782103825137,
        "hf_subset": "eng_Latn-opm_Latn",
        "languages": [
          "eng-Latn",
          "opm-Latn"
        ],
        "main_score": 0.011195782103825137,
        "precision": 0.010185842803030302,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004071367416829745,
        "hf_subset": "opm_Latn-eng_Latn",
        "languages": [
          "opm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004071367416829745,
        "precision": 0.003989801974012994,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005022321428571428,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.005022321428571428,
        "precision": 0.004557291666666667,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00615530303030303,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.00615530303030303,
        "precision": 0.0044189453125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022428449119373778,
        "hf_subset": "eng_Latn-ote_Latn",
        "languages": [
          "eng-Latn",
          "ote-Latn"
        ],
        "main_score": 0.022428449119373778,
        "precision": 0.01793285924145299,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004600694444444444,
        "hf_subset": "ote_Latn-eng_Latn",
        "languages": [
          "ote-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004600694444444444,
        "precision": 0.003159466911764706,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01646205357142857,
        "hf_subset": "eng_Latn-otm_Latn",
        "languages": [
          "eng-Latn",
          "otm-Latn"
        ],
        "main_score": 0.01646205357142857,
        "precision": 0.013346354166666666,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007174813034188035,
        "hf_subset": "otm_Latn-eng_Latn",
        "languages": [
          "otm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007174813034188035,
        "precision": 0.005922871042356337,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019923666484260995,
        "hf_subset": "eng_Latn-otn_Latn",
        "languages": [
          "eng-Latn",
          "otn-Latn"
        ],
        "main_score": 0.019923666484260995,
        "precision": 0.01627001350308642,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01419735863095238,
        "hf_subset": "otn_Latn-eng_Latn",
        "languages": [
          "otn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01419735863095238,
        "precision": 0.01209405637254902,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00595703125,
        "hf_subset": "eng_Latn-otq_Latn",
        "languages": [
          "eng-Latn",
          "otq-Latn"
        ],
        "main_score": 0.00595703125,
        "precision": 0.0036127101608187133,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0027878752345215758,
        "hf_subset": "otq_Latn-eng_Latn",
        "languages": [
          "otq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027878752345215758,
        "precision": 0.002046178598872951,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02474658897649969,
        "hf_subset": "eng_Latn-ots_Latn",
        "languages": [
          "eng-Latn",
          "ots-Latn"
        ],
        "main_score": 0.02474658897649969,
        "precision": 0.024133785865564594,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012589019982993197,
        "hf_subset": "ots_Latn-eng_Latn",
        "languages": [
          "ots-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012589019982993197,
        "precision": 0.010883073648859732,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011136845501474925,
        "hf_subset": "eng_Latn-pab_Latn",
        "languages": [
          "eng-Latn",
          "pab-Latn"
        ],
        "main_score": 0.011136845501474925,
        "precision": 0.00914946056547619,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00980282738095238,
        "hf_subset": "pab_Latn-eng_Latn",
        "languages": [
          "pab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00980282738095238,
        "precision": 0.007642549364123159,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005262586805555556,
        "hf_subset": "eng_Latn-pad_Latn",
        "languages": [
          "eng-Latn",
          "pad-Latn"
        ],
        "main_score": 0.005262586805555556,
        "precision": 0.004654947916666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01968615301724138,
        "hf_subset": "pad_Latn-eng_Latn",
        "languages": [
          "pad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01968615301724138,
        "precision": 0.01838717433117678,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02828125,
        "hf_subset": "eng_Latn-pah_Latn",
        "languages": [
          "eng-Latn",
          "pah-Latn"
        ],
        "main_score": 0.02828125,
        "precision": 0.025383538832199546,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00650291019955654,
        "hf_subset": "pah_Latn-eng_Latn",
        "languages": [
          "pah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00650291019955654,
        "precision": 0.004328893442622951,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009256856424825174,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.009256856424825174,
        "precision": 0.008584449404761905,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002232142857142857,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.002232142857142857,
        "precision": 0.0013020833333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02618840939153439,
        "hf_subset": "eng_Latn-pao_Latn",
        "languages": [
          "eng-Latn",
          "pao-Latn"
        ],
        "main_score": 0.02618840939153439,
        "precision": 0.02284095729638009,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03284372836778389,
        "hf_subset": "pao_Latn-eng_Latn",
        "languages": [
          "pao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03284372836778389,
        "precision": 0.02876419260324186,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009862075617283951,
        "hf_subset": "eng_Latn-pes_Arab",
        "languages": [
          "eng-Latn",
          "pes-Arab"
        ],
        "main_score": 0.009862075617283951,
        "precision": 0.009163411458333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006412448700410397,
        "hf_subset": "pes_Arab-eng_Latn",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0006412448700410397,
        "precision": 0.0003371465773809524,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008112980769230768,
        "hf_subset": "eng_Latn-pib_Latn",
        "languages": [
          "eng-Latn",
          "pib-Latn"
        ],
        "main_score": 0.008112980769230768,
        "precision": 0.00796875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0037039989606953887,
        "hf_subset": "pib_Latn-eng_Latn",
        "languages": [
          "pib-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0037039989606953887,
        "precision": 0.0023149539262820513,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016740952190170938,
        "hf_subset": "eng_Latn-pio_Latn",
        "languages": [
          "eng-Latn",
          "pio-Latn"
        ],
        "main_score": 0.016740952190170938,
        "precision": 0.016239320589786548,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010646832912457913,
        "hf_subset": "pio_Latn-eng_Latn",
        "languages": [
          "pio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010646832912457913,
        "precision": 0.00812878587391202,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015033143939393938,
        "hf_subset": "eng_Latn-pir_Latn",
        "languages": [
          "eng-Latn",
          "pir-Latn"
        ],
        "main_score": 0.015033143939393938,
        "precision": 0.012890625,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0035317786654135335,
        "hf_subset": "pir_Latn-eng_Latn",
        "languages": [
          "pir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0035317786654135335,
        "precision": 0.0022241105248917746,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000250552398989899,
        "hf_subset": "eng_Latn-piu_Latn",
        "languages": [
          "eng-Latn",
          "piu-Latn"
        ],
        "main_score": 0.000250552398989899,
        "precision": 0.00012735556859676578,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00020945397882513663,
        "hf_subset": "piu_Latn-eng_Latn",
        "languages": [
          "piu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00020945397882513663,
        "precision": 0.00010622258771929825,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019083049886621316,
        "hf_subset": "eng_Latn-pjt_Latn",
        "languages": [
          "eng-Latn",
          "pjt-Latn"
        ],
        "main_score": 0.019083049886621316,
        "precision": 0.015610638786764707,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015019914215686275,
        "hf_subset": "pjt_Latn-eng_Latn",
        "languages": [
          "pjt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015019914215686275,
        "precision": 0.013825197238658778,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03165509259259259,
        "hf_subset": "eng_Latn-pls_Latn",
        "languages": [
          "eng-Latn",
          "pls-Latn"
        ],
        "main_score": 0.03165509259259259,
        "precision": 0.03034714033018868,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010756655092592592,
        "hf_subset": "pls_Latn-eng_Latn",
        "languages": [
          "pls-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010756655092592592,
        "precision": 0.008345433361466478,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005631510416666667,
        "hf_subset": "eng_Latn-plu_Latn",
        "languages": [
          "eng-Latn",
          "plu-Latn"
        ],
        "main_score": 0.005631510416666667,
        "precision": 0.004824862637362637,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.913716814159292e-05,
        "hf_subset": "plu_Latn-eng_Latn",
        "languages": [
          "plu-Latn",
          "eng-Latn"
        ],
        "main_score": 6.913716814159292e-05,
        "precision": 3.487723214285714e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01511346726190476,
        "hf_subset": "eng_Latn-pma_Latn",
        "languages": [
          "eng-Latn",
          "pma-Latn"
        ],
        "main_score": 0.01511346726190476,
        "precision": 0.01384171195652174,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028754340277777775,
        "hf_subset": "pma_Latn-eng_Latn",
        "languages": [
          "pma-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028754340277777775,
        "precision": 0.0020920485764235764,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02489276960784314,
        "hf_subset": "eng_Latn-poe_Latn",
        "languages": [
          "eng-Latn",
          "poe-Latn"
        ],
        "main_score": 0.02489276960784314,
        "precision": 0.020593091804029302,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01255906174173491,
        "hf_subset": "poe_Latn-eng_Latn",
        "languages": [
          "poe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01255906174173491,
        "precision": 0.009697659111721612,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009905133928571428,
        "hf_subset": "eng_Latn-poh_Latn",
        "languages": [
          "eng-Latn",
          "poh-Latn"
        ],
        "main_score": 0.009905133928571428,
        "precision": 0.00784970238095238,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007455779514603044,
        "hf_subset": "poh_Latn-eng_Latn",
        "languages": [
          "poh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007455779514603044,
        "precision": 0.00040838068181818185,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02704339548319328,
        "hf_subset": "eng_Latn-poi_Latn",
        "languages": [
          "eng-Latn",
          "poi-Latn"
        ],
        "main_score": 0.02704339548319328,
        "precision": 0.023217881957998916,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014091435185185184,
        "hf_subset": "poi_Latn-eng_Latn",
        "languages": [
          "poi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014091435185185184,
        "precision": 0.010814922924297924,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01947225840910028,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ],
        "main_score": 0.01947225840910028,
        "precision": 0.01723101582849128,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015234739729225023,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015234739729225023,
        "precision": 0.012670627946382712,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017211824633699635,
        "hf_subset": "eng_Latn-pon_Latn",
        "languages": [
          "eng-Latn",
          "pon-Latn"
        ],
        "main_score": 0.017211824633699635,
        "precision": 0.014116182383040935,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011503762285012285,
        "hf_subset": "pon_Latn-eng_Latn",
        "languages": [
          "pon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011503762285012285,
        "precision": 0.009948536706349206,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.45703125,
        "f1": 0.3814579951298701,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ],
        "main_score": 0.3814579951298701,
        "precision": 0.35522693452380955,
        "recall": 0.45703125
      },
      {
        "accuracy": 0.46875,
        "f1": 0.3945532332251082,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3945532332251082,
        "precision": 0.3699869791666667,
        "recall": 0.46875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006111391129032258,
        "hf_subset": "eng_Latn-poy_Latn",
        "languages": [
          "eng-Latn",
          "poy-Latn"
        ],
        "main_score": 0.006111391129032258,
        "precision": 0.00517282196969697,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003114043959007551,
        "hf_subset": "poy_Latn-eng_Latn",
        "languages": [
          "poy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003114043959007551,
        "precision": 0.0022212009803921568,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018320167883587,
        "hf_subset": "eng_Latn-ppo_Latn",
        "languages": [
          "eng-Latn",
          "ppo-Latn"
        ],
        "main_score": 0.018320167883587,
        "precision": 0.016370516134085213,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007965016754079254,
        "hf_subset": "ppo_Latn-eng_Latn",
        "languages": [
          "ppo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007965016754079254,
        "precision": 0.006664503737541528,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.032421875,
        "hf_subset": "eng_Latn-prf_Latn",
        "languages": [
          "eng-Latn",
          "prf-Latn"
        ],
        "main_score": 0.032421875,
        "precision": 0.029296874999999997,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03636846941112777,
        "hf_subset": "prf_Latn-eng_Latn",
        "languages": [
          "prf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03636846941112777,
        "precision": 0.03299052407296651,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019725194765406164,
        "hf_subset": "eng_Latn-pri_Latn",
        "languages": [
          "eng-Latn",
          "pri-Latn"
        ],
        "main_score": 0.019725194765406164,
        "precision": 0.016504616341370074,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011985258284600389,
        "hf_subset": "pri_Latn-eng_Latn",
        "languages": [
          "pri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011985258284600389,
        "precision": 0.010621160523504274,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020158617424242423,
        "hf_subset": "eng_Latn-ptp_Latn",
        "languages": [
          "eng-Latn",
          "ptp-Latn"
        ],
        "main_score": 0.020158617424242423,
        "precision": 0.017122149226641414,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007954545454545454,
        "hf_subset": "ptp_Latn-eng_Latn",
        "languages": [
          "ptp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007954545454545454,
        "precision": 0.007884837962962963,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020194538985148516,
        "hf_subset": "eng_Latn-ptu_Latn",
        "languages": [
          "eng-Latn",
          "ptu-Latn"
        ],
        "main_score": 0.020194538985148516,
        "precision": 0.015705754823481115,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.016292508294301324,
        "hf_subset": "ptu_Latn-eng_Latn",
        "languages": [
          "ptu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016292508294301324,
        "precision": 0.012967456004140787,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016015625,
        "hf_subset": "eng_Latn-pwg_Latn",
        "languages": [
          "eng-Latn",
          "pwg-Latn"
        ],
        "main_score": 0.016015625,
        "precision": 0.012457986966338258,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.004893990709862194,
        "hf_subset": "pwg_Latn-eng_Latn",
        "languages": [
          "pwg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004893990709862194,
        "precision": 0.0028947826969226422,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013504875025557146,
        "hf_subset": "eng_Latn-qub_Latn",
        "languages": [
          "eng-Latn",
          "qub-Latn"
        ],
        "main_score": 0.013504875025557146,
        "precision": 0.012808751578282828,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020630516543198987,
        "hf_subset": "qub_Latn-eng_Latn",
        "languages": [
          "qub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020630516543198987,
        "precision": 0.018599499458874458,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015838490936147188,
        "hf_subset": "eng_Latn-quc_Latn",
        "languages": [
          "eng-Latn",
          "quc-Latn"
        ],
        "main_score": 0.015838490936147188,
        "precision": 0.014478018553089198,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013820010567632851,
        "hf_subset": "quc_Latn-eng_Latn",
        "languages": [
          "quc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013820010567632851,
        "precision": 0.011584314123376623,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0055233828671328675,
        "hf_subset": "eng_Latn-quf_Latn",
        "languages": [
          "eng-Latn",
          "quf-Latn"
        ],
        "main_score": 0.0055233828671328675,
        "precision": 0.004910321302816901,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.301401869158878e-05,
        "hf_subset": "quf_Latn-eng_Latn",
        "languages": [
          "quf-Latn",
          "eng-Latn"
        ],
        "main_score": 7.301401869158878e-05,
        "precision": 3.685141509433962e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013684443371943371,
        "hf_subset": "eng_Latn-quh_Latn",
        "languages": [
          "eng-Latn",
          "quh-Latn"
        ],
        "main_score": 0.013684443371943371,
        "precision": 0.012072741043203373,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01869532867494824,
        "hf_subset": "quh_Latn-eng_Latn",
        "languages": [
          "quh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01869532867494824,
        "precision": 0.016616358901515152,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02379500182748538,
        "hf_subset": "eng_Latn-qul_Latn",
        "languages": [
          "eng-Latn",
          "qul-Latn"
        ],
        "main_score": 0.02379500182748538,
        "precision": 0.01905553712194337,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018368675595238096,
        "hf_subset": "qul_Latn-eng_Latn",
        "languages": [
          "qul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018368675595238096,
        "precision": 0.013906733532272324,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0044202302631578955,
        "hf_subset": "eng_Latn-qup_Latn",
        "languages": [
          "eng-Latn",
          "qup-Latn"
        ],
        "main_score": 0.0044202302631578955,
        "precision": 0.004175347222222223,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "qup_Latn-eng_Latn",
        "languages": [
          "qup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008463541666666667,
        "hf_subset": "eng_Latn-qvc_Latn",
        "languages": [
          "eng-Latn",
          "qvc-Latn"
        ],
        "main_score": 0.0008463541666666667,
        "precision": 0.00045527389277389275,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013512185534591194,
        "hf_subset": "qvc_Latn-eng_Latn",
        "languages": [
          "qvc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013512185534591194,
        "precision": 0.0008059731012658229,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02055593297101449,
        "hf_subset": "eng_Latn-qve_Latn",
        "languages": [
          "eng-Latn",
          "qve-Latn"
        ],
        "main_score": 0.02055593297101449,
        "precision": 0.016268382352941174,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019294221093886274,
        "hf_subset": "qve_Latn-eng_Latn",
        "languages": [
          "qve-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019294221093886274,
        "precision": 0.016688082510964913,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006565434272300469,
        "hf_subset": "eng_Latn-qvh_Latn",
        "languages": [
          "eng-Latn",
          "qvh-Latn"
        ],
        "main_score": 0.006565434272300469,
        "precision": 0.0058870789007092195,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009582300573738265,
        "hf_subset": "qvh_Latn-eng_Latn",
        "languages": [
          "qvh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009582300573738265,
        "precision": 0.007556464228683898,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008839465725806451,
        "hf_subset": "eng_Latn-qvm_Latn",
        "languages": [
          "eng-Latn",
          "qvm-Latn"
        ],
        "main_score": 0.008839465725806451,
        "precision": 0.00709381764069264,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012937817733253589,
        "hf_subset": "qvm_Latn-eng_Latn",
        "languages": [
          "qvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012937817733253589,
        "precision": 0.01095920138888889,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0038273358585858585,
        "hf_subset": "eng_Latn-qvn_Latn",
        "languages": [
          "eng-Latn",
          "qvn-Latn"
        ],
        "main_score": 0.0038273358585858585,
        "precision": 0.002627418154761905,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013553174182808717,
        "hf_subset": "qvn_Latn-eng_Latn",
        "languages": [
          "qvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013553174182808717,
        "precision": 0.01163041526111944,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0021870765582655827,
        "hf_subset": "eng_Latn-qvs_Latn",
        "languages": [
          "eng-Latn",
          "qvs-Latn"
        ],
        "main_score": 0.0021870765582655827,
        "precision": 0.001303998161764706,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003013392857142857,
        "hf_subset": "qvs_Latn-eng_Latn",
        "languages": [
          "qvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003013392857142857,
        "precision": 0.001880787037037037,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014756944444444444,
        "hf_subset": "eng_Latn-qvw_Latn",
        "languages": [
          "eng-Latn",
          "qvw-Latn"
        ],
        "main_score": 0.014756944444444444,
        "precision": 0.012784090909090908,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01505174512987013,
        "hf_subset": "qvw_Latn-eng_Latn",
        "languages": [
          "qvw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01505174512987013,
        "precision": 0.013768551421404682,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018939393939393936,
        "hf_subset": "eng_Latn-qvz_Latn",
        "languages": [
          "eng-Latn",
          "qvz-Latn"
        ],
        "main_score": 0.018939393939393936,
        "precision": 0.01796875,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.925879396984925e-05,
        "hf_subset": "qvz_Latn-eng_Latn",
        "languages": [
          "qvz-Latn",
          "eng-Latn"
        ],
        "main_score": 3.925879396984925e-05,
        "precision": 1.9728535353535355e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012389823717948719,
        "hf_subset": "eng_Latn-qwh_Latn",
        "languages": [
          "eng-Latn",
          "qwh-Latn"
        ],
        "main_score": 0.012389823717948719,
        "precision": 0.012074360994397758,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024900925150005554,
        "hf_subset": "qwh_Latn-eng_Latn",
        "languages": [
          "qwh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024900925150005554,
        "precision": 0.02420264595794684,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008419103304641094,
        "hf_subset": "eng_Latn-qxh_Latn",
        "languages": [
          "eng-Latn",
          "qxh-Latn"
        ],
        "main_score": 0.008419103304641094,
        "precision": 0.008125202120778868,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01107507305806938,
        "hf_subset": "qxh_Latn-eng_Latn",
        "languages": [
          "qxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01107507305806938,
        "precision": 0.01012008101851852,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020442708333333334,
        "hf_subset": "eng_Latn-qxn_Latn",
        "languages": [
          "eng-Latn",
          "qxn-Latn"
        ],
        "main_score": 0.020442708333333334,
        "precision": 0.018616691468253968,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011711786987522281,
        "hf_subset": "qxn_Latn-eng_Latn",
        "languages": [
          "qxn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011711786987522281,
        "precision": 0.010452023184240662,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012369791666666666,
        "hf_subset": "eng_Latn-qxo_Latn",
        "languages": [
          "eng-Latn",
          "qxo-Latn"
        ],
        "main_score": 0.012369791666666666,
        "precision": 0.011067708333333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006461178221288515,
        "hf_subset": "qxo_Latn-eng_Latn",
        "languages": [
          "qxo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006461178221288515,
        "precision": 0.005522017045454545,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.033719883534850635,
        "hf_subset": "eng_Latn-rai_Latn",
        "languages": [
          "eng-Latn",
          "rai-Latn"
        ],
        "main_score": 0.033719883534850635,
        "precision": 0.03086948249619482,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014578731375606377,
        "hf_subset": "rai_Latn-eng_Latn",
        "languages": [
          "rai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014578731375606377,
        "precision": 0.013801978411227505,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02045181381118881,
        "hf_subset": "eng_Latn-reg_Latn",
        "languages": [
          "eng-Latn",
          "reg-Latn"
        ],
        "main_score": 0.02045181381118881,
        "precision": 0.018619791666666666,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005073361280487805,
        "hf_subset": "reg_Latn-eng_Latn",
        "languages": [
          "reg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005073361280487805,
        "precision": 0.004561941964285714,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011966145833333332,
        "hf_subset": "eng_Latn-rgu_Latn",
        "languages": [
          "eng-Latn",
          "rgu-Latn"
        ],
        "main_score": 0.011966145833333332,
        "precision": 0.00950985863095238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008260569852941177,
        "hf_subset": "rgu_Latn-eng_Latn",
        "languages": [
          "rgu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008260569852941177,
        "precision": 0.006875152290448342,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005667892156862745,
        "hf_subset": "eng_Latn-rkb_Latn",
        "languages": [
          "eng-Latn",
          "rkb-Latn"
        ],
        "main_score": 0.005667892156862745,
        "precision": 0.004931640625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00936539700634417,
        "hf_subset": "rkb_Latn-eng_Latn",
        "languages": [
          "rkb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00936539700634417,
        "precision": 0.008637117984529338,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.032181436596982485,
        "hf_subset": "eng_Latn-rmc_Latn",
        "languages": [
          "eng-Latn",
          "rmc-Latn"
        ],
        "main_score": 0.032181436596982485,
        "precision": 0.027091560782967032,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.029129504001174734,
        "hf_subset": "rmc_Latn-eng_Latn",
        "languages": [
          "rmc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029129504001174734,
        "precision": 0.02472495848429952,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012704613095238095,
        "hf_subset": "eng_Latn-rmy_Latn",
        "languages": [
          "eng-Latn",
          "rmy-Latn"
        ],
        "main_score": 0.012704613095238095,
        "precision": 0.011056286549707603,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014366319444444444,
        "hf_subset": "rmy_Latn-eng_Latn",
        "languages": [
          "rmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014366319444444444,
        "precision": 0.012274050245098039,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.1572107355068607,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ],
        "main_score": 0.1572107355068607,
        "precision": 0.1397887214781746,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.17246046054639802,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.17246046054639802,
        "precision": 0.15491705560064933,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005176360597423062,
        "hf_subset": "eng_Latn-roo_Latn",
        "languages": [
          "eng-Latn",
          "roo-Latn"
        ],
        "main_score": 0.005176360597423062,
        "precision": 0.0034598214285714284,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0007152474284027993,
        "hf_subset": "roo_Latn-eng_Latn",
        "languages": [
          "roo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007152474284027993,
        "precision": 0.0003743489583333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015620986919804205,
        "hf_subset": "eng_Latn-rop_Latn",
        "languages": [
          "eng-Latn",
          "rop-Latn"
        ],
        "main_score": 0.015620986919804205,
        "precision": 0.01293349778364595,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011979166666666666,
        "hf_subset": "rop_Latn-eng_Latn",
        "languages": [
          "rop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011979166666666666,
        "precision": 0.0107421875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014162435807656396,
        "hf_subset": "eng_Latn-row_Latn",
        "languages": [
          "eng-Latn",
          "row-Latn"
        ],
        "main_score": 0.014162435807656396,
        "precision": 0.013102213541666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013335129310344826,
        "hf_subset": "row_Latn-eng_Latn",
        "languages": [
          "row-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013335129310344826,
        "precision": 0.01155056423611111,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004157027867965368,
        "hf_subset": "eng_Latn-rro_Latn",
        "languages": [
          "eng-Latn",
          "rro-Latn"
        ],
        "main_score": 0.004157027867965368,
        "precision": 0.002407168823905401,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008992087688734031,
        "hf_subset": "rro_Latn-eng_Latn",
        "languages": [
          "rro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008992087688734031,
        "precision": 0.008495560109289618,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012803819444444444,
        "hf_subset": "eng_Latn-ruf_Latn",
        "languages": [
          "eng-Latn",
          "ruf-Latn"
        ],
        "main_score": 0.012803819444444444,
        "precision": 0.01012561274509804,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007471137493458921,
        "hf_subset": "ruf_Latn-eng_Latn",
        "languages": [
          "ruf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007471137493458921,
        "precision": 0.005066988760964912,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009635416666666667,
        "hf_subset": "eng_Latn-rug_Latn",
        "languages": [
          "eng-Latn",
          "rug-Latn"
        ],
        "main_score": 0.009635416666666667,
        "precision": 0.008872767857142857,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0096712711352657,
        "hf_subset": "rug_Latn-eng_Latn",
        "languages": [
          "rug-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0096712711352657,
        "precision": 0.007827296401515152,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.058090249594155846,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.058090249594155846,
        "precision": 0.051748273427960935,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02075643464860398,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.02075643464860398,
        "precision": 0.016020275297619048,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006009615384615385,
        "hf_subset": "eng_Latn-rwo_Latn",
        "languages": [
          "eng-Latn",
          "rwo-Latn"
        ],
        "main_score": 0.0006009615384615385,
        "precision": 0.0003255208333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008332422785547786,
        "hf_subset": "rwo_Latn-eng_Latn",
        "languages": [
          "rwo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008332422785547786,
        "precision": 0.006968552254921655,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017857142857142856,
        "hf_subset": "eng_Latn-sab_Latn",
        "languages": [
          "eng-Latn",
          "sab-Latn"
        ],
        "main_score": 0.017857142857142856,
        "precision": 0.015624999999999997,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008389559659090908,
        "hf_subset": "sab_Latn-eng_Latn",
        "languages": [
          "sab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008389559659090908,
        "precision": 0.008117816091954024,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000992063492063492,
        "hf_subset": "eng_Latn-san_Latn",
        "languages": [
          "eng-Latn",
          "san-Latn"
        ],
        "main_score": 0.000992063492063492,
        "precision": 0.0005302601809954752,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026369922969187672,
        "hf_subset": "san_Latn-eng_Latn",
        "languages": [
          "san-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026369922969187672,
        "precision": 0.0019696070675105483,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008658854166666667,
        "hf_subset": "eng_Latn-sbe_Latn",
        "languages": [
          "eng-Latn",
          "sbe-Latn"
        ],
        "main_score": 0.008658854166666667,
        "precision": 0.008267773892773892,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005010384835752483,
        "hf_subset": "sbe_Latn-eng_Latn",
        "languages": [
          "sbe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005010384835752483,
        "precision": 0.004499853164731896,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008524197722567288,
        "hf_subset": "eng_Latn-sbk_Latn",
        "languages": [
          "eng-Latn",
          "sbk-Latn"
        ],
        "main_score": 0.008524197722567288,
        "precision": 0.005816579254079254,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00021701388888888888,
        "hf_subset": "sbk_Latn-eng_Latn",
        "languages": [
          "sbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00021701388888888888,
        "precision": 0.00011160714285714285,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014716824229691877,
        "hf_subset": "eng_Latn-sbs_Latn",
        "languages": [
          "eng-Latn",
          "sbs-Latn"
        ],
        "main_score": 0.014716824229691877,
        "precision": 0.013434249208502941,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011229415546706487,
        "hf_subset": "sbs_Latn-eng_Latn",
        "languages": [
          "sbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011229415546706487,
        "precision": 0.010195711286206078,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004879546740752174,
        "hf_subset": "eng_Latn-seh_Latn",
        "languages": [
          "eng-Latn",
          "seh-Latn"
        ],
        "main_score": 0.004879546740752174,
        "precision": 0.004430666349531616,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022092013888888887,
        "hf_subset": "seh_Latn-eng_Latn",
        "languages": [
          "seh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022092013888888887,
        "precision": 0.019861703950648055,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022352430555555552,
        "hf_subset": "eng_Latn-sey_Latn",
        "languages": [
          "eng-Latn",
          "sey-Latn"
        ],
        "main_score": 0.022352430555555552,
        "precision": 0.020149739583333333,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01446410000681942,
        "hf_subset": "sey_Latn-eng_Latn",
        "languages": [
          "sey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01446410000681942,
        "precision": 0.012517954192546584,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02450635302197802,
        "hf_subset": "eng_Latn-sgb_Latn",
        "languages": [
          "eng-Latn",
          "sgb-Latn"
        ],
        "main_score": 0.02450635302197802,
        "precision": 0.02147386711595696,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02814710576259489,
        "hf_subset": "sgb_Latn-eng_Latn",
        "languages": [
          "sgb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02814710576259489,
        "precision": 0.024581375655594404,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01789630325814536,
        "hf_subset": "eng_Latn-sgz_Latn",
        "languages": [
          "eng-Latn",
          "sgz-Latn"
        ],
        "main_score": 0.01789630325814536,
        "precision": 0.016142494658119656,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006535947712418301,
        "hf_subset": "sgz_Latn-eng_Latn",
        "languages": [
          "sgz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006535947712418301,
        "precision": 0.005564081101190476,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08791208791208792,
        "f1": 0.04603174603174603,
        "hf_subset": "eng_Latn-shj_Latn",
        "languages": [
          "eng-Latn",
          "shj-Latn"
        ],
        "main_score": 0.04603174603174603,
        "precision": 0.03470695970695971,
        "recall": 0.08791208791208792
      },
      {
        "accuracy": 0.054945054945054944,
        "f1": 0.02839905192846369,
        "hf_subset": "shj_Latn-eng_Latn",
        "languages": [
          "shj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02839905192846369,
        "precision": 0.02344976452119309,
        "recall": 0.054945054945054944
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019349888392857142,
        "hf_subset": "eng_Latn-shp_Latn",
        "languages": [
          "eng-Latn",
          "shp-Latn"
        ],
        "main_score": 0.019349888392857142,
        "precision": 0.015755208333333333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013156049679487178,
        "hf_subset": "shp_Latn-eng_Latn",
        "languages": [
          "shp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013156049679487178,
        "precision": 0.011403019266917294,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00818142361111111,
        "hf_subset": "eng_Latn-sim_Latn",
        "languages": [
          "eng-Latn",
          "sim-Latn"
        ],
        "main_score": 0.00818142361111111,
        "precision": 0.006500330105633802,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008510044642857142,
        "hf_subset": "sim_Latn-eng_Latn",
        "languages": [
          "sim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008510044642857142,
        "precision": 0.00696783685064935,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017844565129091338,
        "hf_subset": "eng_Latn-sja_Latn",
        "languages": [
          "eng-Latn",
          "sja-Latn"
        ],
        "main_score": 0.017844565129091338,
        "precision": 0.015549413222646916,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006727430555555556,
        "hf_subset": "sja_Latn-eng_Latn",
        "languages": [
          "sja-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006727430555555556,
        "precision": 0.0059709821428571425,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "eng_Latn-sll_Latn",
        "languages": [
          "eng-Latn",
          "sll-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.0046875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001477191091954023,
        "hf_subset": "sll_Latn-eng_Latn",
        "languages": [
          "sll-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001477191091954023,
        "precision": 0.0008117208939102002,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026354166666666665,
        "hf_subset": "eng_Latn-smk_Latn",
        "languages": [
          "eng-Latn",
          "smk-Latn"
        ],
        "main_score": 0.026354166666666665,
        "precision": 0.02229817708333333,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017838541666666666,
        "hf_subset": "smk_Latn-eng_Latn",
        "languages": [
          "smk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017838541666666666,
        "precision": 0.015950520833333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.0212828621031746,
        "hf_subset": "eng_Latn-snc_Latn",
        "languages": [
          "eng-Latn",
          "snc-Latn"
        ],
        "main_score": 0.0212828621031746,
        "precision": 0.01903196079911433,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009744866840249302,
        "hf_subset": "snc_Latn-eng_Latn",
        "languages": [
          "snc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009744866840249302,
        "precision": 0.007843545343545344,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019574652777777778,
        "hf_subset": "eng_Latn-snn_Latn",
        "languages": [
          "eng-Latn",
          "snn-Latn"
        ],
        "main_score": 0.019574652777777778,
        "precision": 0.016958333333333332,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01003274356617647,
        "hf_subset": "snn_Latn-eng_Latn",
        "languages": [
          "snn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01003274356617647,
        "precision": 0.008295650921658987,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022079613095238097,
        "hf_subset": "eng_Latn-snp_Latn",
        "languages": [
          "eng-Latn",
          "snp-Latn"
        ],
        "main_score": 0.022079613095238097,
        "precision": 0.017826140873015872,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0075975521945261856,
        "hf_subset": "snp_Latn-eng_Latn",
        "languages": [
          "snp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0075975521945261856,
        "precision": 0.0052870704237891735,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05,
        "f1": 0.03634746206174777,
        "hf_subset": "eng_Latn-snx_Latn",
        "languages": [
          "eng-Latn",
          "snx-Latn"
        ],
        "main_score": 0.03634746206174777,
        "precision": 0.03400793650793651,
        "recall": 0.05
      },
      {
        "accuracy": 0.09285714285714286,
        "f1": 0.054594938604372575,
        "hf_subset": "snx_Latn-eng_Latn",
        "languages": [
          "snx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.054594938604372575,
        "precision": 0.04633634222919937,
        "recall": 0.09285714285714286
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007499137839558573,
        "hf_subset": "eng_Latn-sny_Latn",
        "languages": [
          "eng-Latn",
          "sny-Latn"
        ],
        "main_score": 0.007499137839558573,
        "precision": 0.00611359126984127,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009765625,
        "hf_subset": "sny_Latn-eng_Latn",
        "languages": [
          "sny-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0005580357142857143,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012812500000000001,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ],
        "main_score": 0.012812500000000001,
        "precision": 0.010904947916666668,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0009208427177177177,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009208427177177177,
        "precision": 0.0005148543792517007,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020641915954415953,
        "hf_subset": "eng_Latn-soq_Latn",
        "languages": [
          "eng-Latn",
          "soq-Latn"
        ],
        "main_score": 0.020641915954415953,
        "precision": 0.02011675824175824,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014858025332225912,
        "hf_subset": "soq_Latn-eng_Latn",
        "languages": [
          "soq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014858025332225912,
        "precision": 0.012412161044973544,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002043968023255814,
        "hf_subset": "eng_Latn-soy_Latn",
        "languages": [
          "eng-Latn",
          "soy-Latn"
        ],
        "main_score": 0.002043968023255814,
        "precision": 0.0013480392156862745,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020429238505747125,
        "hf_subset": "soy_Latn-eng_Latn",
        "languages": [
          "soy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0020429238505747125,
        "precision": 0.0013475048449612403,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.515625,
        "f1": 0.43547867063492063,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ],
        "main_score": 0.43547867063492063,
        "precision": 0.4074311755952381,
        "recall": 0.515625
      },
      {
        "accuracy": 0.62890625,
        "f1": 0.5578404017857143,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5578404017857143,
        "precision": 0.530961681547619,
        "recall": 0.62890625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002191840277777778,
        "hf_subset": "eng_Latn-spl_Latn",
        "languages": [
          "eng-Latn",
          "spl-Latn"
        ],
        "main_score": 0.002191840277777778,
        "precision": 0.001221842903828198,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "spl_Latn-eng_Latn",
        "languages": [
          "spl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.028515625,
        "hf_subset": "eng_Latn-spm_Latn",
        "languages": [
          "eng-Latn",
          "spm-Latn"
        ],
        "main_score": 0.028515625,
        "precision": 0.026806006493506493,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017925032709339775,
        "hf_subset": "spm_Latn-eng_Latn",
        "languages": [
          "spm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017925032709339775,
        "precision": 0.01474564769504898,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012295386904761904,
        "hf_subset": "eng_Latn-spp_Latn",
        "languages": [
          "eng-Latn",
          "spp-Latn"
        ],
        "main_score": 0.012295386904761904,
        "precision": 0.010817571271929824,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013469827586206896,
        "hf_subset": "spp_Latn-eng_Latn",
        "languages": [
          "spp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00013469827586206896,
        "precision": 6.853070175438596e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016741071428571428,
        "hf_subset": "eng_Latn-sps_Latn",
        "languages": [
          "eng-Latn",
          "sps-Latn"
        ],
        "main_score": 0.016741071428571428,
        "precision": 0.014973958333333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006584821428571428,
        "hf_subset": "sps_Latn-eng_Latn",
        "languages": [
          "sps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006584821428571428,
        "precision": 0.005533854166666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004640758547008547,
        "hf_subset": "eng_Latn-spy_Latn",
        "languages": [
          "eng-Latn",
          "spy-Latn"
        ],
        "main_score": 0.004640758547008547,
        "precision": 0.004292279411764706,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002387152777777778,
        "hf_subset": "spy_Latn-eng_Latn",
        "languages": [
          "spy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002387152777777778,
        "precision": 0.0015318627450980392,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01316823899371069,
        "hf_subset": "eng_Latn-sri_Latn",
        "languages": [
          "eng-Latn",
          "sri-Latn"
        ],
        "main_score": 0.01316823899371069,
        "precision": 0.011793870192307692,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00407318376068376,
        "hf_subset": "sri_Latn-eng_Latn",
        "languages": [
          "sri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00407318376068376,
        "precision": 0.002766927083333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019414171918767507,
        "hf_subset": "eng_Latn-srm_Latn",
        "languages": [
          "eng-Latn",
          "srm-Latn"
        ],
        "main_score": 0.019414171918767507,
        "precision": 0.016725774396929825,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004302390885750963,
        "hf_subset": "srm_Latn-eng_Latn",
        "languages": [
          "srm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004302390885750963,
        "precision": 0.004109480574324325,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021724776350598718,
        "hf_subset": "eng_Latn-srn_Latn",
        "languages": [
          "eng-Latn",
          "srn-Latn"
        ],
        "main_score": 0.021724776350598718,
        "precision": 0.017277286515567765,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01824312342370744,
        "hf_subset": "srn_Latn-eng_Latn",
        "languages": [
          "srn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01824312342370744,
        "precision": 0.01598280389118457,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017488563712522043,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ],
        "main_score": 0.017488563712522043,
        "precision": 0.013720703124999999,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017295122561825145,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017295122561825145,
        "precision": 0.013178426752645502,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029173519736842107,
        "hf_subset": "eng_Latn-srq_Latn",
        "languages": [
          "eng-Latn",
          "srq-Latn"
        ],
        "main_score": 0.029173519736842107,
        "precision": 0.025812091629036672,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01701221955128205,
        "hf_subset": "srq_Latn-eng_Latn",
        "languages": [
          "srq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01701221955128205,
        "precision": 0.012809108018207283,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007129968128983876,
        "hf_subset": "eng_Latn-ssd_Latn",
        "languages": [
          "eng-Latn",
          "ssd-Latn"
        ],
        "main_score": 0.007129968128983876,
        "precision": 0.006190857753357753,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005563872819307602,
        "hf_subset": "ssd_Latn-eng_Latn",
        "languages": [
          "ssd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005563872819307602,
        "precision": 0.004806114440639269,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017698317307692307,
        "hf_subset": "eng_Latn-ssg_Latn",
        "languages": [
          "eng-Latn",
          "ssg-Latn"
        ],
        "main_score": 0.017698317307692307,
        "precision": 0.015500023251488094,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009912892713903743,
        "hf_subset": "ssg_Latn-eng_Latn",
        "languages": [
          "ssg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009912892713903743,
        "precision": 0.007862723214285714,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023643092105263158,
        "hf_subset": "eng_Latn-ssx_Latn",
        "languages": [
          "eng-Latn",
          "ssx-Latn"
        ],
        "main_score": 0.0023643092105263158,
        "precision": 0.001519097222222222,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.0479274611398965e-05,
        "hf_subset": "ssx_Latn-eng_Latn",
        "languages": [
          "ssx-Latn",
          "eng-Latn"
        ],
        "main_score": 4.0479274611398965e-05,
        "precision": 2.0345052083333332e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "eng_Latn-stp_Latn",
        "languages": [
          "eng-Latn",
          "stp-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00394802807486631,
        "hf_subset": "stp_Latn-eng_Latn",
        "languages": [
          "stp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00394802807486631,
        "precision": 0.0039272513440860215,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004608210076960077,
        "hf_subset": "eng_Latn-sua_Latn",
        "languages": [
          "eng-Latn",
          "sua-Latn"
        ],
        "main_score": 0.004608210076960077,
        "precision": 0.003042907868275515,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002197265625,
        "hf_subset": "sua_Latn-eng_Latn",
        "languages": [
          "sua-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002197265625,
        "precision": 0.0014280913978494624,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008693321078431373,
        "hf_subset": "eng_Latn-sue_Latn",
        "languages": [
          "eng-Latn",
          "sue-Latn"
        ],
        "main_score": 0.008693321078431373,
        "precision": 0.007279829545454545,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00637149309024309,
        "hf_subset": "sue_Latn-eng_Latn",
        "languages": [
          "sue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00637149309024309,
        "precision": 0.0053625274122807015,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005896935096153846,
        "hf_subset": "eng_Latn-sus_Arab",
        "languages": [
          "eng-Latn",
          "sus-Arab"
        ],
        "main_score": 0.005896935096153846,
        "precision": 0.004269462719298246,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00044679330065359476,
        "hf_subset": "sus_Arab-eng_Latn",
        "languages": [
          "sus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00044679330065359476,
        "precision": 0.00022997835497835496,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003999255952380952,
        "hf_subset": "eng_Latn-suz_Latn",
        "languages": [
          "eng-Latn",
          "suz-Latn"
        ],
        "main_score": 0.003999255952380952,
        "precision": 0.003953313253012048,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.4115720524017465e-05,
        "hf_subset": "suz_Latn-eng_Latn",
        "languages": [
          "suz-Latn",
          "eng-Latn"
        ],
        "main_score": 3.4115720524017465e-05,
        "precision": 1.713267543859649e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.06870212307224025,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ],
        "main_score": 0.06870212307224025,
        "precision": 0.058081978785103794,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.06954526459556425,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06954526459556425,
        "precision": 0.060510984241452986,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03225164592352092,
        "hf_subset": "eng_Latn-swh_Latn",
        "languages": [
          "eng-Latn",
          "swh-Latn"
        ],
        "main_score": 0.03225164592352092,
        "precision": 0.02919921875,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012323679471788716,
        "hf_subset": "swh_Latn-eng_Latn",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012323679471788716,
        "precision": 0.010835543054454137,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017017722722040468,
        "hf_subset": "eng_Latn-swp_Latn",
        "languages": [
          "eng-Latn",
          "swp-Latn"
        ],
        "main_score": 0.017017722722040468,
        "precision": 0.014971454326923076,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010755997474747474,
        "hf_subset": "swp_Latn-eng_Latn",
        "languages": [
          "swp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010755997474747474,
        "precision": 0.007526838860544218,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010026041666666666,
        "hf_subset": "eng_Latn-sxb_Latn",
        "languages": [
          "eng-Latn",
          "sxb-Latn"
        ],
        "main_score": 0.010026041666666666,
        "precision": 0.008138020833333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004809307795698925,
        "hf_subset": "sxb_Latn-eng_Latn",
        "languages": [
          "sxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004809307795698925,
        "precision": 0.00439157196969697,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00820893327686806,
        "hf_subset": "eng_Latn-tac_Latn",
        "languages": [
          "eng-Latn",
          "tac-Latn"
        ],
        "main_score": 0.00820893327686806,
        "precision": 0.006771984600648394,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004828337585034013,
        "hf_subset": "tac_Latn-eng_Latn",
        "languages": [
          "tac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004828337585034013,
        "precision": 0.003393200860507246,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028645833333333336,
        "hf_subset": "eng_Latn-taj_Deva",
        "languages": [
          "eng-Latn",
          "taj-Deva"
        ],
        "main_score": 0.0028645833333333336,
        "precision": 0.0016493055555555556,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003960129310344828,
        "hf_subset": "taj_Deva-eng_Latn",
        "languages": [
          "taj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003960129310344828,
        "precision": 0.003933376736111111,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0109375,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.0109375,
        "precision": 0.009654017857142858,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002334128694581281,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.002334128694581281,
        "precision": 0.0014982045807453415,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01926859745102145,
        "hf_subset": "eng_Latn-tav_Latn",
        "languages": [
          "eng-Latn",
          "tav-Latn"
        ],
        "main_score": 0.01926859745102145,
        "precision": 0.017008793780193238,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008052611901815183,
        "hf_subset": "tav_Latn-eng_Latn",
        "languages": [
          "tav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008052611901815183,
        "precision": 0.00793467420212766,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.022376018428815807,
        "hf_subset": "eng_Latn-taw_Latn",
        "languages": [
          "eng-Latn",
          "taw-Latn"
        ],
        "main_score": 0.022376018428815807,
        "precision": 0.018490616732804235,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010144872572815534,
        "hf_subset": "taw_Latn-eng_Latn",
        "languages": [
          "taw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010144872572815534,
        "precision": 0.0005770905923344948,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00912734885620915,
        "hf_subset": "eng_Latn-tbc_Latn",
        "languages": [
          "eng-Latn",
          "tbc-Latn"
        ],
        "main_score": 0.00912734885620915,
        "precision": 0.007173295454545454,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012560205768353854,
        "hf_subset": "tbc_Latn-eng_Latn",
        "languages": [
          "tbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012560205768353854,
        "precision": 0.01216209495161701,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01769778073489011,
        "hf_subset": "eng_Latn-tbf_Latn",
        "languages": [
          "eng-Latn",
          "tbf-Latn"
        ],
        "main_score": 0.01769778073489011,
        "precision": 0.014415201124983502,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008561360514485514,
        "hf_subset": "tbf_Latn-eng_Latn",
        "languages": [
          "tbf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008561360514485514,
        "precision": 0.006652113970588234,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008723958333333334,
        "hf_subset": "eng_Latn-tbg_Latn",
        "languages": [
          "eng-Latn",
          "tbg-Latn"
        ],
        "main_score": 0.008723958333333334,
        "precision": 0.006902956495098039,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008078898295050912,
        "hf_subset": "tbg_Latn-eng_Latn",
        "languages": [
          "tbg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008078898295050912,
        "precision": 0.00794845281862745,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004115715579710145,
        "hf_subset": "eng_Latn-tbo_Latn",
        "languages": [
          "eng-Latn",
          "tbo-Latn"
        ],
        "main_score": 0.004115715579710145,
        "precision": 0.002770301701222754,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008177530880773363,
        "hf_subset": "tbo_Latn-eng_Latn",
        "languages": [
          "tbo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008177530880773363,
        "precision": 0.007999454532657657,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007220643939393939,
        "hf_subset": "eng_Latn-tbz_Latn",
        "languages": [
          "eng-Latn",
          "tbz-Latn"
        ],
        "main_score": 0.007220643939393939,
        "precision": 0.00625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007572115384615384,
        "hf_subset": "tbz_Latn-eng_Latn",
        "languages": [
          "tbz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007572115384615384,
        "precision": 0.006261488970588236,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0108316163003663,
        "hf_subset": "eng_Latn-tca_Latn",
        "languages": [
          "eng-Latn",
          "tca-Latn"
        ],
        "main_score": 0.0108316163003663,
        "precision": 0.0087890625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004132306134259259,
        "hf_subset": "tca_Latn-eng_Latn",
        "languages": [
          "tca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004132306134259259,
        "precision": 0.004021071251241311,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04145171957671957,
        "hf_subset": "eng_Latn-tcs_Latn",
        "languages": [
          "eng-Latn",
          "tcs-Latn"
        ],
        "main_score": 0.04145171957671957,
        "precision": 0.036173963246855345,
        "recall": 0.0625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.016169695466570464,
        "hf_subset": "tcs_Latn-eng_Latn",
        "languages": [
          "tcs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016169695466570464,
        "precision": 0.011898818878146013,
        "recall": 0.046875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.037862723214285715,
        "hf_subset": "eng_Latn-tcz_Latn",
        "languages": [
          "eng-Latn",
          "tcz-Latn"
        ],
        "main_score": 0.037862723214285715,
        "precision": 0.03215781393747495,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.037902113970588236,
        "hf_subset": "tcz_Latn-eng_Latn",
        "languages": [
          "tcz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.037902113970588236,
        "precision": 0.03430139464354044,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.0308014368657299,
        "hf_subset": "eng_Latn-tdt_Latn",
        "languages": [
          "eng-Latn",
          "tdt-Latn"
        ],
        "main_score": 0.0308014368657299,
        "precision": 0.027213541666666667,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012819381705251268,
        "hf_subset": "tdt_Latn-eng_Latn",
        "languages": [
          "tdt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012819381705251268,
        "precision": 0.008857865767045454,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011818910256410256,
        "hf_subset": "eng_Latn-tee_Latn",
        "languages": [
          "eng-Latn",
          "tee-Latn"
        ],
        "main_score": 0.011818910256410256,
        "precision": 0.009520427489177488,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008127934272300468,
        "hf_subset": "tee_Latn-eng_Latn",
        "languages": [
          "tee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008127934272300468,
        "precision": 0.005720647196448568,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004631696428571429,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.004631696428571429,
        "precision": 0.0029296875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002949254326047359,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.002949254326047359,
        "precision": 0.00185546875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "eng_Latn-ter_Latn",
        "languages": [
          "eng-Latn",
          "ter-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00041118421052631577,
        "hf_subset": "ter_Latn-eng_Latn",
        "languages": [
          "ter-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00041118421052631577,
        "precision": 0.00021701388888888888,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025493213383838385,
        "hf_subset": "eng_Latn-tet_Latn",
        "languages": [
          "eng-Latn",
          "tet-Latn"
        ],
        "main_score": 0.025493213383838385,
        "precision": 0.021128216911764707,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004486268939393939,
        "hf_subset": "tet_Latn-eng_Latn",
        "languages": [
          "tet-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004486268939393939,
        "precision": 0.0030019459706959704,
        "recall": 0.015625
      },
      {
        "accuracy": 0.125,
        "f1": 0.08946474155373613,
        "hf_subset": "eng_Latn-tew_Latn",
        "languages": [
          "eng-Latn",
          "tew-Latn"
        ],
        "main_score": 0.08946474155373613,
        "precision": 0.08310907842157841,
        "recall": 0.125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.05650707799145299,
        "hf_subset": "tew_Latn-eng_Latn",
        "languages": [
          "tew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05650707799145299,
        "precision": 0.05495535714285714,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01875,
        "hf_subset": "eng_Latn-tfr_Latn",
        "languages": [
          "eng-Latn",
          "tfr-Latn"
        ],
        "main_score": 0.01875,
        "precision": 0.01655505952380952,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011113936143984222,
        "hf_subset": "tfr_Latn-eng_Latn",
        "languages": [
          "tfr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011113936143984222,
        "precision": 0.009137834821428572,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001166044776119403,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0001166044776119403,
        "precision": 5.918560606060606e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03824600563909775,
        "hf_subset": "eng_Latn-tgl_Latn",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ],
        "main_score": 0.03824600563909775,
        "precision": 0.03303881448412698,
        "recall": 0.0625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028910900297619047,
        "hf_subset": "tgl_Latn-eng_Latn",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028910900297619047,
        "precision": 0.025224208580957815,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020052083333333335,
        "hf_subset": "eng_Latn-tgo_Latn",
        "languages": [
          "eng-Latn",
          "tgo-Latn"
        ],
        "main_score": 0.020052083333333335,
        "precision": 0.01700391433747412,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0030940809643255295,
        "hf_subset": "tgo_Latn-eng_Latn",
        "languages": [
          "tgo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0030940809643255295,
        "precision": 0.00220727495543672,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07599768649472409,
        "hf_subset": "eng_Latn-tgp_Latn",
        "languages": [
          "eng-Latn",
          "tgp-Latn"
        ],
        "main_score": 0.07599768649472409,
        "precision": 0.07075047348484848,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.060022491789124846,
        "hf_subset": "tgp_Latn-eng_Latn",
        "languages": [
          "tgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.060022491789124846,
        "precision": 0.0554595446977459,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006513798701298701,
        "hf_subset": "eng_Latn-tif_Latn",
        "languages": [
          "eng-Latn",
          "tif-Latn"
        ],
        "main_score": 0.006513798701298701,
        "precision": 0.005381944444444445,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.659313725490196e-05,
        "hf_subset": "tif_Latn-eng_Latn",
        "languages": [
          "tif-Latn",
          "eng-Latn"
        ],
        "main_score": 7.659313725490196e-05,
        "precision": 3.8675742574257426e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004830838585434174,
        "hf_subset": "eng_Latn-tim_Latn",
        "languages": [
          "eng-Latn",
          "tim-Latn"
        ],
        "main_score": 0.004830838585434174,
        "precision": 0.003203420928030303,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002717391304347826,
        "hf_subset": "tim_Latn-eng_Latn",
        "languages": [
          "tim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002717391304347826,
        "precision": 0.0020105698529411763,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09302325581395349,
        "f1": 0.06259249794133515,
        "hf_subset": "eng_Latn-tiw_Latn",
        "languages": [
          "eng-Latn",
          "tiw-Latn"
        ],
        "main_score": 0.06259249794133515,
        "precision": 0.05622861634489542,
        "recall": 0.09302325581395349
      },
      {
        "accuracy": 0.09767441860465116,
        "f1": 0.06063502689546873,
        "hf_subset": "tiw_Latn-eng_Latn",
        "languages": [
          "tiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06063502689546873,
        "precision": 0.05414963735287295,
        "recall": 0.09767441860465116
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006371156417112299,
        "hf_subset": "eng_Latn-tiy_Latn",
        "languages": [
          "eng-Latn",
          "tiy-Latn"
        ],
        "main_score": 0.0006371156417112299,
        "precision": 0.00033498364825581395,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0062890624999999995,
        "hf_subset": "tiy_Latn-eng_Latn",
        "languages": [
          "tiy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0062890624999999995,
        "precision": 0.005298322876447876,
        "recall": 0.015625
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.020696091348265264,
        "hf_subset": "eng_Latn-tke_Latn",
        "languages": [
          "eng-Latn",
          "tke-Latn"
        ],
        "main_score": 0.020696091348265264,
        "precision": 0.01693840579710145,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.020531400966183576,
        "hf_subset": "tke_Latn-eng_Latn",
        "languages": [
          "tke-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020531400966183576,
        "precision": 0.017663043478260868,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015648598525230987,
        "hf_subset": "eng_Latn-tku_Latn",
        "languages": [
          "eng-Latn",
          "tku-Latn"
        ],
        "main_score": 0.015648598525230987,
        "precision": 0.013380499708624708,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018249746028342725,
        "hf_subset": "tku_Latn-eng_Latn",
        "languages": [
          "tku-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018249746028342725,
        "precision": 0.014918870192307691,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0055493816844919795,
        "hf_subset": "eng_Latn-tlf_Latn",
        "languages": [
          "eng-Latn",
          "tlf-Latn"
        ],
        "main_score": 0.0055493816844919795,
        "precision": 0.004783598734051037,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "tlf_Latn-eng_Latn",
        "languages": [
          "tlf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005295138888888889,
        "hf_subset": "eng_Latn-tmd_Latn",
        "languages": [
          "eng-Latn",
          "tmd-Latn"
        ],
        "main_score": 0.005295138888888889,
        "precision": 0.004673549107142857,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.830223880597015e-05,
        "hf_subset": "tmd_Latn-eng_Latn",
        "languages": [
          "tmd-Latn",
          "eng-Latn"
        ],
        "main_score": 5.830223880597015e-05,
        "precision": 2.9370300751879698e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017836427895021642,
        "hf_subset": "eng_Latn-tna_Latn",
        "languages": [
          "eng-Latn",
          "tna-Latn"
        ],
        "main_score": 0.017836427895021642,
        "precision": 0.014403907496012757,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014440818791631484,
        "hf_subset": "tna_Latn-eng_Latn",
        "languages": [
          "tna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014440818791631484,
        "precision": 0.012464735243055556,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020287024456521738,
        "hf_subset": "eng_Latn-tnc_Latn",
        "languages": [
          "eng-Latn",
          "tnc-Latn"
        ],
        "main_score": 0.020287024456521738,
        "precision": 0.017376612103174604,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007889331004140786,
        "hf_subset": "tnc_Latn-eng_Latn",
        "languages": [
          "tnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007889331004140786,
        "precision": 0.005595619658119657,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01357041396103896,
        "hf_subset": "eng_Latn-tnk_Latn",
        "languages": [
          "eng-Latn",
          "tnk-Latn"
        ],
        "main_score": 0.01357041396103896,
        "precision": 0.009828327760740552,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008603050595238094,
        "hf_subset": "tnk_Latn-eng_Latn",
        "languages": [
          "tnk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008603050595238094,
        "precision": 0.007232481060606061,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009840029761904762,
        "hf_subset": "eng_Latn-tnn_Latn",
        "languages": [
          "eng-Latn",
          "tnn-Latn"
        ],
        "main_score": 0.009840029761904762,
        "precision": 0.006420080741626794,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002232142857142857,
        "hf_subset": "tnn_Latn-eng_Latn",
        "languages": [
          "tnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002232142857142857,
        "precision": 0.0014467592592592592,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022782118055555557,
        "hf_subset": "eng_Latn-tnp_Latn",
        "languages": [
          "eng-Latn",
          "tnp-Latn"
        ],
        "main_score": 0.022782118055555557,
        "precision": 0.01932827079311454,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01220703125,
        "hf_subset": "tnp_Latn-eng_Latn",
        "languages": [
          "tnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01220703125,
        "precision": 0.011979166666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021389818948412697,
        "hf_subset": "eng_Latn-toc_Latn",
        "languages": [
          "eng-Latn",
          "toc-Latn"
        ],
        "main_score": 0.021389818948412697,
        "precision": 0.019341728779732812,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002806774136715997,
        "hf_subset": "toc_Latn-eng_Latn",
        "languages": [
          "toc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002806774136715997,
        "precision": 0.002055980541087963,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.0812083099192474,
        "hf_subset": "eng_Latn-tod_Latn",
        "languages": [
          "eng-Latn",
          "tod-Latn"
        ],
        "main_score": 0.0812083099192474,
        "precision": 0.07474937343358395,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04398375496031746,
        "hf_subset": "tod_Latn-eng_Latn",
        "languages": [
          "tod-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04398375496031746,
        "precision": 0.04006679685339582,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012491861979166666,
        "hf_subset": "eng_Latn-tof_Latn",
        "languages": [
          "eng-Latn",
          "tof-Latn"
        ],
        "main_score": 0.012491861979166666,
        "precision": 0.011129712301587302,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01306246937660184,
        "hf_subset": "tof_Latn-eng_Latn",
        "languages": [
          "tof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01306246937660184,
        "precision": 0.011228824705387205,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011844758064516129,
        "hf_subset": "eng_Latn-toj_Latn",
        "languages": [
          "eng-Latn",
          "toj-Latn"
        ],
        "main_score": 0.011844758064516129,
        "precision": 0.010610911885245902,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01110526842948718,
        "hf_subset": "toj_Latn-eng_Latn",
        "languages": [
          "toj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01110526842948718,
        "precision": 0.009832909688995216,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009235491071428572,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ],
        "main_score": 0.009235491071428572,
        "precision": 0.006178695436507937,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.002541880862193362,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002541880862193362,
        "precision": 0.001414806768667063,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008604029605263158,
        "hf_subset": "eng_Latn-too_Latn",
        "languages": [
          "eng-Latn",
          "too-Latn"
        ],
        "main_score": 0.008604029605263158,
        "precision": 0.006848505871943371,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012520176426426426,
        "hf_subset": "too_Latn-eng_Latn",
        "languages": [
          "too-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012520176426426426,
        "precision": 0.009793005743964252,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006632486979166666,
        "hf_subset": "eng_Latn-top_Latn",
        "languages": [
          "eng-Latn",
          "top-Latn"
        ],
        "main_score": 0.006632486979166666,
        "precision": 0.005921378968253968,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00938839824879227,
        "hf_subset": "top_Latn-eng_Latn",
        "languages": [
          "top-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00938839824879227,
        "precision": 0.008679519392984466,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023387419871794872,
        "hf_subset": "eng_Latn-tos_Latn",
        "languages": [
          "eng-Latn",
          "tos-Latn"
        ],
        "main_score": 0.023387419871794872,
        "precision": 0.01998697916666667,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0032033050115207375,
        "hf_subset": "tos_Latn-eng_Latn",
        "languages": [
          "tos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0032033050115207375,
        "precision": 0.00200037401324166,
        "recall": 0.015625
      },
      {
        "accuracy": 0.15602836879432624,
        "f1": 0.09959518995814365,
        "hf_subset": "eng_Latn-tpa_Latn",
        "languages": [
          "eng-Latn",
          "tpa-Latn"
        ],
        "main_score": 0.09959518995814365,
        "precision": 0.08737642381259403,
        "recall": 0.15602836879432624
      },
      {
        "accuracy": 0.14893617021276595,
        "f1": 0.09758097092264802,
        "hf_subset": "tpa_Latn-eng_Latn",
        "languages": [
          "tpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09758097092264802,
        "precision": 0.08289007092198583,
        "recall": 0.14893617021276595
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06632223462301587,
        "hf_subset": "eng_Latn-tpi_Latn",
        "languages": [
          "eng-Latn",
          "tpi-Latn"
        ],
        "main_score": 0.06632223462301587,
        "precision": 0.06119990216831413,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03153674555759804,
        "hf_subset": "tpi_Latn-eng_Latn",
        "languages": [
          "tpi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03153674555759804,
        "precision": 0.02763671133325739,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.026475694444444444,
        "hf_subset": "eng_Latn-tpt_Latn",
        "languages": [
          "eng-Latn",
          "tpt-Latn"
        ],
        "main_score": 0.026475694444444444,
        "precision": 0.022830225840336137,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01265625,
        "hf_subset": "tpt_Latn-eng_Latn",
        "languages": [
          "tpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01265625,
        "precision": 0.012232497165532881,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009900510905425219,
        "hf_subset": "eng_Latn-tpz_Latn",
        "languages": [
          "eng-Latn",
          "tpz-Latn"
        ],
        "main_score": 0.009900510905425219,
        "precision": 0.009058281399873561,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.403688524590164e-05,
        "hf_subset": "tpz_Latn-eng_Latn",
        "languages": [
          "tpz-Latn",
          "eng-Latn"
        ],
        "main_score": 6.403688524590164e-05,
        "precision": 3.228305785123967e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0087890625,
        "hf_subset": "eng_Latn-trc_Latn",
        "languages": [
          "eng-Latn",
          "trc-Latn"
        ],
        "main_score": 0.0087890625,
        "precision": 0.006940670289855072,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01450892857142857,
        "hf_subset": "trc_Latn-eng_Latn",
        "languages": [
          "trc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01450892857142857,
        "precision": 0.013767149390243903,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "eng_Latn-tsw_Latn",
        "languages": [
          "eng-Latn",
          "tsw-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00400390625,
        "hf_subset": "tsw_Latn-eng_Latn",
        "languages": [
          "tsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00400390625,
        "precision": 0.003955696202531646,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.005537257881007881,
        "hf_subset": "eng_Latn-ttc_Latn",
        "languages": [
          "eng-Latn",
          "ttc-Latn"
        ],
        "main_score": 0.005537257881007881,
        "precision": 0.0033569677871148457,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010105298913043478,
        "hf_subset": "ttc_Latn-eng_Latn",
        "languages": [
          "ttc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010105298913043478,
        "precision": 0.009292140151515152,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004557291666666666,
        "hf_subset": "eng_Latn-tte_Latn",
        "languages": [
          "eng-Latn",
          "tte-Latn"
        ],
        "main_score": 0.004557291666666666,
        "precision": 0.0028296493902439024,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010986260701463683,
        "hf_subset": "tte_Latn-eng_Latn",
        "languages": [
          "tte-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010986260701463683,
        "precision": 0.010065569196428571,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.0312922605994152,
        "hf_subset": "eng_Latn-tuc_Latn",
        "languages": [
          "eng-Latn",
          "tuc-Latn"
        ],
        "main_score": 0.0312922605994152,
        "precision": 0.027119964625104426,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.024419297934405552,
        "hf_subset": "tuc_Latn-eng_Latn",
        "languages": [
          "tuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024419297934405552,
        "precision": 0.023959334935897435,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010130044549266248,
        "hf_subset": "eng_Latn-tue_Latn",
        "languages": [
          "eng-Latn",
          "tue-Latn"
        ],
        "main_score": 0.010130044549266248,
        "precision": 0.008079973412004662,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015409395292207792,
        "hf_subset": "tue_Latn-eng_Latn",
        "languages": [
          "tue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015409395292207792,
        "precision": 0.012789481026785714,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0052875905797101445,
        "hf_subset": "eng_Latn-tuf_Latn",
        "languages": [
          "eng-Latn",
          "tuf-Latn"
        ],
        "main_score": 0.0052875905797101445,
        "precision": 0.004660866477272727,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005976005459001782,
        "hf_subset": "tuf_Latn-eng_Latn",
        "languages": [
          "tuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005976005459001782,
        "precision": 0.004325810185185185,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0055575284090909095,
        "hf_subset": "eng_Latn-tuo_Latn",
        "languages": [
          "eng-Latn",
          "tuo-Latn"
        ],
        "main_score": 0.0055575284090909095,
        "precision": 0.003676161361283644,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006701989672680667,
        "hf_subset": "tuo_Latn-eng_Latn",
        "languages": [
          "tuo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006701989672680667,
        "precision": 0.005467270359848485,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008687789351851851,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.008687789351851851,
        "precision": 0.006893171932234432,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0124447601010101,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0124447601010101,
        "precision": 0.009868552842442644,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018193655303030302,
        "hf_subset": "eng_Latn-tvk_Latn",
        "languages": [
          "eng-Latn",
          "tvk-Latn"
        ],
        "main_score": 0.018193655303030302,
        "precision": 0.014834449404761904,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007369542464114832,
        "hf_subset": "tvk_Latn-eng_Latn",
        "languages": [
          "tvk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007369542464114832,
        "precision": 0.0053139249535823505,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02547554347826087,
        "hf_subset": "eng_Latn-twi_Latn",
        "languages": [
          "eng-Latn",
          "twi-Latn"
        ],
        "main_score": 0.02547554347826087,
        "precision": 0.022318830429438982,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013268849206349206,
        "hf_subset": "twi_Latn-eng_Latn",
        "languages": [
          "twi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013268849206349206,
        "precision": 0.011427696078431374,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01212471563697318,
        "hf_subset": "eng_Latn-txq_Latn",
        "languages": [
          "eng-Latn",
          "txq-Latn"
        ],
        "main_score": 0.01212471563697318,
        "precision": 0.010454560113519092,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004616477272727273,
        "hf_subset": "txq_Latn-eng_Latn",
        "languages": [
          "txq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004616477272727273,
        "precision": 0.004296875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013230298913043477,
        "hf_subset": "eng_Latn-txu_Latn",
        "languages": [
          "eng-Latn",
          "txu-Latn"
        ],
        "main_score": 0.013230298913043477,
        "precision": 0.011524283008658008,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003973023504273504,
        "hf_subset": "txu_Latn-eng_Latn",
        "languages": [
          "txu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003973023504273504,
        "precision": 0.003939924568965517,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03410935758082497,
        "hf_subset": "eng_Latn-tzj_Latn",
        "languages": [
          "eng-Latn",
          "tzj-Latn"
        ],
        "main_score": 0.03410935758082497,
        "precision": 0.029626259157509157,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.0322191158695695,
        "hf_subset": "tzj_Latn-eng_Latn",
        "languages": [
          "tzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0322191158695695,
        "precision": 0.024599651650432902,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009123563218390805,
        "hf_subset": "eng_Latn-tzo_Latn",
        "languages": [
          "eng-Latn",
          "tzo-Latn"
        ],
        "main_score": 0.009123563218390805,
        "precision": 0.007409474206349207,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010157030066811413,
        "hf_subset": "tzo_Latn-eng_Latn",
        "languages": [
          "tzo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010157030066811413,
        "precision": 0.007943063802438803,
        "recall": 0.03125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0700689223057644,
        "hf_subset": "eng_Latn-ubr_Latn",
        "languages": [
          "eng-Latn",
          "ubr-Latn"
        ],
        "main_score": 0.0700689223057644,
        "precision": 0.06388592960858586,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.05890227936126374,
        "hf_subset": "ubr_Latn-eng_Latn",
        "languages": [
          "ubr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05890227936126374,
        "precision": 0.05272610572076613,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014360413546569676,
        "hf_subset": "eng_Latn-ubu_Latn",
        "languages": [
          "eng-Latn",
          "ubu-Latn"
        ],
        "main_score": 0.014360413546569676,
        "precision": 0.012149677579365078,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00619803026172301,
        "hf_subset": "ubu_Latn-eng_Latn",
        "languages": [
          "ubu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00619803026172301,
        "precision": 0.00523838141025641,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006610576923076922,
        "hf_subset": "eng_Latn-udu_Latn",
        "languages": [
          "eng-Latn",
          "udu-Latn"
        ],
        "main_score": 0.006610576923076922,
        "precision": 0.005910105519480519,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003162202380952381,
        "hf_subset": "udu_Latn-eng_Latn",
        "languages": [
          "udu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003162202380952381,
        "precision": 0.002253605769230769,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016117860187553283,
        "hf_subset": "eng_Latn-uig_Latn",
        "languages": [
          "eng-Latn",
          "uig-Latn"
        ],
        "main_score": 0.016117860187553283,
        "precision": 0.014708806818181817,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010254563071697604,
        "hf_subset": "uig_Latn-eng_Latn",
        "languages": [
          "uig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010254563071697604,
        "precision": 0.007754291102216749,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023893229166666665,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ],
        "main_score": 0.023893229166666665,
        "precision": 0.019481646825396826,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.011453461592970521,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.011453461592970521,
        "precision": 0.008352113381410257,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.07118055555555555,
        "hf_subset": "eng_Latn-uli_Latn",
        "languages": [
          "eng-Latn",
          "uli-Latn"
        ],
        "main_score": 0.07118055555555555,
        "precision": 0.06602647569444445,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.0593687996031746,
        "hf_subset": "uli_Latn-eng_Latn",
        "languages": [
          "uli-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0593687996031746,
        "precision": 0.05667897469443179,
        "recall": 0.078125
      },
      {
        "accuracy": 0.041884816753926704,
        "f1": 0.02662677636499626,
        "hf_subset": "eng_Latn-ulk_Latn",
        "languages": [
          "eng-Latn",
          "ulk-Latn"
        ],
        "main_score": 0.02662677636499626,
        "precision": 0.02323610072301172,
        "recall": 0.041884816753926704
      },
      {
        "accuracy": 0.05235602094240838,
        "f1": 0.03517092700954728,
        "hf_subset": "ulk_Latn-eng_Latn",
        "languages": [
          "ulk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03517092700954728,
        "precision": 0.032114809274495136,
        "recall": 0.05235602094240838
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012699142156862745,
        "hf_subset": "eng_Latn-upv_Latn",
        "languages": [
          "eng-Latn",
          "upv-Latn"
        ],
        "main_score": 0.012699142156862745,
        "precision": 0.011020853061868688,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007695625263379687,
        "hf_subset": "upv_Latn-eng_Latn",
        "languages": [
          "upv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007695625263379687,
        "precision": 0.006545293898809524,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009359313669987922,
        "hf_subset": "eng_Latn-ura_Latn",
        "languages": [
          "eng-Latn",
          "ura-Latn"
        ],
        "main_score": 0.009359313669987922,
        "precision": 0.007630798531533825,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010416666666666667,
        "hf_subset": "ura_Latn-eng_Latn",
        "languages": [
          "ura-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00010416666666666667,
        "precision": 5.2787162162162165e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012630208333333334,
        "hf_subset": "eng_Latn-urb_Latn",
        "languages": [
          "eng-Latn",
          "urb-Latn"
        ],
        "main_score": 0.012630208333333334,
        "precision": 0.010686383928571429,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004142992424242424,
        "hf_subset": "urb_Latn-eng_Latn",
        "languages": [
          "urb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004142992424242424,
        "precision": 0.0040283203125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028045124299719885,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.028045124299719885,
        "precision": 0.024286179315476192,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01960565476190476,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.01960565476190476,
        "precision": 0.01677551671607378,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.027777777777777776,
        "f1": 0.01280321472737998,
        "hf_subset": "eng_Latn-uri_Latn",
        "languages": [
          "eng-Latn",
          "uri-Latn"
        ],
        "main_score": 0.01280321472737998,
        "precision": 0.011143095671784196,
        "recall": 0.027777777777777776
      },
      {
        "accuracy": 0.01984126984126984,
        "f1": 0.0052410505340844,
        "hf_subset": "uri_Latn-eng_Latn",
        "languages": [
          "uri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0052410505340844,
        "precision": 0.00464593061642751,
        "recall": 0.01984126984126984
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021123817431561998,
        "hf_subset": "eng_Latn-urt_Latn",
        "languages": [
          "eng-Latn",
          "urt-Latn"
        ],
        "main_score": 0.021123817431561998,
        "precision": 0.018198890952797205,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006158952067669173,
        "hf_subset": "urt_Latn-eng_Latn",
        "languages": [
          "urt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006158952067669173,
        "precision": 0.005244502314814815,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03333333333333333,
        "f1": 0.006261022927689594,
        "hf_subset": "eng_Latn-urw_Latn",
        "languages": [
          "eng-Latn",
          "urw-Latn"
        ],
        "main_score": 0.006261022927689594,
        "precision": 0.003558201058201058,
        "recall": 0.03333333333333333
      },
      {
        "accuracy": 0.06666666666666667,
        "f1": 0.0435016835016835,
        "hf_subset": "urw_Latn-eng_Latn",
        "languages": [
          "urw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0435016835016835,
        "precision": 0.037222222222222226,
        "recall": 0.06666666666666667
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011328125,
        "hf_subset": "eng_Latn-usa_Latn",
        "languages": [
          "eng-Latn",
          "usa-Latn"
        ],
        "main_score": 0.0011328125,
        "precision": 0.0006377551020408163,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004235525732031943,
        "hf_subset": "usa_Latn-eng_Latn",
        "languages": [
          "usa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004235525732031943,
        "precision": 0.004074435763888888,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.025390625,
        "hf_subset": "eng_Latn-usp_Latn",
        "languages": [
          "eng-Latn",
          "usp-Latn"
        ],
        "main_score": 0.025390625,
        "precision": 0.022786458333333332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007977884440813363,
        "hf_subset": "usp_Latn-eng_Latn",
        "languages": [
          "usp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007977884440813363,
        "precision": 0.006477864583333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014248675989040362,
        "hf_subset": "eng_Latn-uvh_Latn",
        "languages": [
          "eng-Latn",
          "uvh-Latn"
        ],
        "main_score": 0.014248675989040362,
        "precision": 0.011744159760195943,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001814236111111111,
        "hf_subset": "uvh_Latn-eng_Latn",
        "languages": [
          "uvh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001814236111111111,
        "precision": 0.0010504864824717767,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00985488071236559,
        "hf_subset": "eng_Latn-uvl_Latn",
        "languages": [
          "eng-Latn",
          "uvl-Latn"
        ],
        "main_score": 0.00985488071236559,
        "precision": 0.007421875,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015531994047619046,
        "hf_subset": "uvl_Latn-eng_Latn",
        "languages": [
          "uvl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015531994047619046,
        "precision": 0.012019230769230768,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011217948717948717,
        "hf_subset": "eng_Latn-vid_Latn",
        "languages": [
          "eng-Latn",
          "vid-Latn"
        ],
        "main_score": 0.0011217948717948717,
        "precision": 0.0006045386904761905,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005858770404934544,
        "hf_subset": "vid_Latn-eng_Latn",
        "languages": [
          "vid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005858770404934544,
        "precision": 0.004961079519337983,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010244807841614906,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ],
        "main_score": 0.010244807841614906,
        "precision": 0.009199134199134198,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0027075066137566134,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027075066137566134,
        "precision": 0.0015291547220895045,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-viv_Latn",
        "languages": [
          "eng-Latn",
          "viv-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005181640965681145,
        "hf_subset": "viv_Latn-eng_Latn",
        "languages": [
          "viv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005181640965681145,
        "precision": 0.0046019507981198806,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013109459984459984,
        "hf_subset": "eng_Latn-vmy_Latn",
        "languages": [
          "eng-Latn",
          "vmy-Latn"
        ],
        "main_score": 0.013109459984459984,
        "precision": 0.011363841869212963,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02097567287784679,
        "hf_subset": "vmy_Latn-eng_Latn",
        "languages": [
          "vmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02097567287784679,
        "precision": 0.01699094148724083,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003125,
        "hf_subset": "eng_Latn-waj_Latn",
        "languages": [
          "eng-Latn",
          "waj-Latn"
        ],
        "main_score": 0.003125,
        "precision": 0.001953125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002675840978593272,
        "hf_subset": "waj_Latn-eng_Latn",
        "languages": [
          "waj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002675840978593272,
        "precision": 0.0019892939814814816,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-wal_Ethi",
        "languages": [
          "eng-Latn",
          "wal-Ethi"
        ],
        "main_score": 0.00390625,
        "precision": 0.0026041666666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007102272727272727,
        "hf_subset": "wal_Ethi-eng_Latn",
        "languages": [
          "wal-Ethi",
          "eng-Latn"
        ],
        "main_score": 0.0007102272727272727,
        "precision": 0.000390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07842012512479446,
        "hf_subset": "eng_Latn-wap_Latn",
        "languages": [
          "eng-Latn",
          "wap-Latn"
        ],
        "main_score": 0.07842012512479446,
        "precision": 0.07480003720238096,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.078125,
        "f1": 0.06401909722222222,
        "hf_subset": "wap_Latn-eng_Latn",
        "languages": [
          "wap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06401909722222222,
        "precision": 0.05986328125,
        "recall": 0.078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03738839285714285,
        "hf_subset": "eng_Latn-wat_Latn",
        "languages": [
          "eng-Latn",
          "wat-Latn"
        ],
        "main_score": 0.03738839285714285,
        "precision": 0.033203125,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022245074878426172,
        "hf_subset": "wat_Latn-eng_Latn",
        "languages": [
          "wat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022245074878426172,
        "precision": 0.018884200991609458,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019931175595238097,
        "hf_subset": "eng_Latn-wbi_Latn",
        "languages": [
          "eng-Latn",
          "wbi-Latn"
        ],
        "main_score": 0.019931175595238097,
        "precision": 0.015822003517316018,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008998842592592593,
        "hf_subset": "wbi_Latn-eng_Latn",
        "languages": [
          "wbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008998842592592593,
        "precision": 0.008454928883828526,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0034718796796584105,
        "hf_subset": "eng_Latn-wbp_Latn",
        "languages": [
          "eng-Latn",
          "wbp-Latn"
        ],
        "main_score": 0.0034718796796584105,
        "precision": 0.002001017720306513,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003583511396011396,
        "hf_subset": "wbp_Latn-eng_Latn",
        "languages": [
          "wbp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003583511396011396,
        "precision": 0.00018540111940298508,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.0643207098217874,
        "hf_subset": "eng_Latn-wed_Latn",
        "languages": [
          "eng-Latn",
          "wed-Latn"
        ],
        "main_score": 0.0643207098217874,
        "precision": 0.054957217261904764,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.06831921333874459,
        "hf_subset": "wed_Latn-eng_Latn",
        "languages": [
          "wed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06831921333874459,
        "precision": 0.059927630240130245,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.004726541385848451,
        "hf_subset": "eng_Latn-wer_Latn",
        "languages": [
          "eng-Latn",
          "wer-Latn"
        ],
        "main_score": 0.004726541385848451,
        "precision": 0.002609662472943723,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00825079565408253,
        "hf_subset": "wer_Latn-eng_Latn",
        "languages": [
          "wer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00825079565408253,
        "precision": 0.008036559794372294,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.05142919146825396,
        "hf_subset": "eng_Latn-wim_Latn",
        "languages": [
          "eng-Latn",
          "wim-Latn"
        ],
        "main_score": 0.05142919146825396,
        "precision": 0.04208130707341465,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.033563679465620326,
        "hf_subset": "wim_Latn-eng_Latn",
        "languages": [
          "wim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.033563679465620326,
        "precision": 0.030523548101673098,
        "recall": 0.046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-wiu_Latn",
        "languages": [
          "eng-Latn",
          "wiu-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.963740458015267e-05,
        "hf_subset": "wiu_Latn-eng_Latn",
        "languages": [
          "wiu-Latn",
          "eng-Latn"
        ],
        "main_score": 5.963740458015267e-05,
        "precision": 3.0048076923076925e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009188502611066948,
        "hf_subset": "eng_Latn-wiv_Latn",
        "languages": [
          "eng-Latn",
          "wiv-Latn"
        ],
        "main_score": 0.009188502611066948,
        "precision": 0.006309678819444444,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020373464834046826,
        "hf_subset": "wiv_Latn-eng_Latn",
        "languages": [
          "wiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020373464834046826,
        "precision": 0.017771616404428904,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005467178858722976,
        "hf_subset": "eng_Latn-wmt_Latn",
        "languages": [
          "eng-Latn",
          "wmt-Latn"
        ],
        "main_score": 0.005467178858722976,
        "precision": 0.004766555059523809,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007477873688811189,
        "hf_subset": "wmt_Latn-eng_Latn",
        "languages": [
          "wmt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007477873688811189,
        "precision": 0.0004094957729468599,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007567107371794871,
        "hf_subset": "eng_Latn-wmw_Latn",
        "languages": [
          "eng-Latn",
          "wmw-Latn"
        ],
        "main_score": 0.007567107371794871,
        "precision": 0.006045386904761904,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00784199163105413,
        "hf_subset": "wmw_Latn-eng_Latn",
        "languages": [
          "wmw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00784199163105413,
        "precision": 0.006568461532720325,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009019000292941825,
        "hf_subset": "eng_Latn-wnc_Latn",
        "languages": [
          "eng-Latn",
          "wnc-Latn"
        ],
        "main_score": 0.009019000292941825,
        "precision": 0.007262970927700348,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00581387208781362,
        "hf_subset": "wnc_Latn-eng_Latn",
        "languages": [
          "wnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00581387208781362,
        "precision": 0.0049843250943670155,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020453042328042327,
        "hf_subset": "eng_Latn-wnu_Latn",
        "languages": [
          "eng-Latn",
          "wnu-Latn"
        ],
        "main_score": 0.020453042328042327,
        "precision": 0.018900240384615383,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010378370098039215,
        "hf_subset": "wnu_Latn-eng_Latn",
        "languages": [
          "wnu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010378370098039215,
        "precision": 0.009436848958333334,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019965277777777776,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ],
        "main_score": 0.019965277777777776,
        "precision": 0.017807904411764705,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.011370228015448604,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011370228015448604,
        "precision": 0.008243815104166666,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01458643353174603,
        "hf_subset": "eng_Latn-wos_Latn",
        "languages": [
          "eng-Latn",
          "wos-Latn"
        ],
        "main_score": 0.01458643353174603,
        "precision": 0.011090862262737262,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004922876602564102,
        "hf_subset": "wos_Latn-eng_Latn",
        "languages": [
          "wos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004922876602564102,
        "precision": 0.0044844210235640645,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005002755064270812,
        "hf_subset": "eng_Latn-wrk_Latn",
        "languages": [
          "eng-Latn",
          "wrk-Latn"
        ],
        "main_score": 0.005002755064270812,
        "precision": 0.004492552229225023,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.616898148148148e-05,
        "hf_subset": "wrk_Latn-eng_Latn",
        "languages": [
          "wrk-Latn",
          "eng-Latn"
        ],
        "main_score": 3.616898148148148e-05,
        "precision": 1.816860465116279e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.171875,
        "f1": 0.10977186511228584,
        "hf_subset": "eng_Latn-wro_Latn",
        "languages": [
          "eng-Latn",
          "wro-Latn"
        ],
        "main_score": 0.10977186511228584,
        "precision": 0.09713951448923806,
        "recall": 0.171875
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.09174325195089997,
        "hf_subset": "wro_Latn-eng_Latn",
        "languages": [
          "wro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09174325195089997,
        "precision": 0.08481201358384263,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011848958333333333,
        "hf_subset": "eng_Latn-wrs_Latn",
        "languages": [
          "eng-Latn",
          "wrs-Latn"
        ],
        "main_score": 0.011848958333333333,
        "precision": 0.01037016369047619,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "wrs_Latn-eng_Latn",
        "languages": [
          "wrs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.00390625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07944123641304347,
        "hf_subset": "eng_Latn-wsk_Latn",
        "languages": [
          "eng-Latn",
          "wsk-Latn"
        ],
        "main_score": 0.07944123641304347,
        "precision": 0.07255721520327499,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07231902394951606,
        "hf_subset": "wsk_Latn-eng_Latn",
        "languages": [
          "wsk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07231902394951606,
        "precision": 0.06761881436508568,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.125,
        "f1": 0.09077361440642691,
        "hf_subset": "eng_Latn-wuv_Latn",
        "languages": [
          "eng-Latn",
          "wuv-Latn"
        ],
        "main_score": 0.09077361440642691,
        "precision": 0.08286830357142858,
        "recall": 0.125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08749395757506824,
        "hf_subset": "wuv_Latn-eng_Latn",
        "languages": [
          "wuv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08749395757506824,
        "precision": 0.08034188034188033,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016493055555555552,
        "hf_subset": "eng_Latn-xav_Latn",
        "languages": [
          "eng-Latn",
          "xav-Latn"
        ],
        "main_score": 0.016493055555555552,
        "precision": 0.013783482142857142,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "xav_Latn-eng_Latn",
        "languages": [
          "xav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008142248376623376,
        "hf_subset": "eng_Latn-xbi_Latn",
        "languages": [
          "eng-Latn",
          "xbi-Latn"
        ],
        "main_score": 0.008142248376623376,
        "precision": 0.0065359477124183,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012287476053639846,
        "hf_subset": "xbi_Latn-eng_Latn",
        "languages": [
          "xbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012287476053639846,
        "precision": 0.010899496610845294,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021763392857142856,
        "hf_subset": "eng_Latn-xed_Latn",
        "languages": [
          "eng-Latn",
          "xed-Latn"
        ],
        "main_score": 0.021763392857142856,
        "precision": 0.01885822510822511,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009241071428571428,
        "hf_subset": "xed_Latn-eng_Latn",
        "languages": [
          "xed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009241071428571428,
        "precision": 0.008626302083333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005605811403508772,
        "hf_subset": "eng_Latn-xla_Latn",
        "languages": [
          "eng-Latn",
          "xla-Latn"
        ],
        "main_score": 0.005605811403508772,
        "precision": 0.004952566964285714,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010543050234142187,
        "hf_subset": "xla_Latn-eng_Latn",
        "languages": [
          "xla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010543050234142187,
        "precision": 0.000582530886627907,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022056255918560603,
        "hf_subset": "eng_Latn-xnn_Latn",
        "languages": [
          "eng-Latn",
          "xnn-Latn"
        ],
        "main_score": 0.022056255918560603,
        "precision": 0.020189471073517123,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018534958964646464,
        "hf_subset": "xnn_Latn-eng_Latn",
        "languages": [
          "xnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018534958964646464,
        "precision": 0.017460264008620687,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010324214870903674,
        "hf_subset": "eng_Latn-xon_Latn",
        "languages": [
          "eng-Latn",
          "xon-Latn"
        ],
        "main_score": 0.010324214870903674,
        "precision": 0.007453592414529914,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0032660590277777775,
        "hf_subset": "xon_Latn-eng_Latn",
        "languages": [
          "xon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0032660590277777775,
        "precision": 0.0023014039855072466,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007691874098124098,
        "hf_subset": "eng_Latn-xsi_Latn",
        "languages": [
          "eng-Latn",
          "xsi-Latn"
        ],
        "main_score": 0.007691874098124098,
        "precision": 0.005292585784313726,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.370283018867924e-05,
        "hf_subset": "xsi_Latn-eng_Latn",
        "languages": [
          "xsi-Latn",
          "eng-Latn"
        ],
        "main_score": 7.370283018867924e-05,
        "precision": 3.7202380952380956e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021802076304543408,
        "hf_subset": "eng_Latn-xtd_Latn",
        "languages": [
          "eng-Latn",
          "xtd-Latn"
        ],
        "main_score": 0.021802076304543408,
        "precision": 0.01881453307748538,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01088915400493701,
        "hf_subset": "xtd_Latn-eng_Latn",
        "languages": [
          "xtd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01088915400493701,
        "precision": 0.008805549918831168,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020727541955504202,
        "hf_subset": "eng_Latn-xtm_Latn",
        "languages": [
          "eng-Latn",
          "xtm-Latn"
        ],
        "main_score": 0.020727541955504202,
        "precision": 0.0187255859375,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010967371323529412,
        "hf_subset": "xtm_Latn-eng_Latn",
        "languages": [
          "xtm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010967371323529412,
        "precision": 0.008499083227040816,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018243319746376812,
        "hf_subset": "eng_Latn-yaa_Latn",
        "languages": [
          "eng-Latn",
          "yaa-Latn"
        ],
        "main_score": 0.018243319746376812,
        "precision": 0.016360592532467532,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009378895121082621,
        "hf_subset": "yaa_Latn-eng_Latn",
        "languages": [
          "yaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009378895121082621,
        "precision": 0.007637785674470456,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00946969696969697,
        "hf_subset": "eng_Latn-yad_Latn",
        "languages": [
          "eng-Latn",
          "yad-Latn"
        ],
        "main_score": 0.00946969696969697,
        "precision": 0.008779761904761905,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001240079365079365,
        "hf_subset": "yad_Latn-eng_Latn",
        "languages": [
          "yad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001240079365079365,
        "precision": 6.300403225806451e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01025390625,
        "hf_subset": "eng_Latn-yal_Latn",
        "languages": [
          "eng-Latn",
          "yal-Latn"
        ],
        "main_score": 0.01025390625,
        "precision": 0.009375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0008713942307692307,
        "hf_subset": "yal_Latn-eng_Latn",
        "languages": [
          "yal-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008713942307692307,
        "precision": 0.00046687931209415587,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05413049768518518,
        "hf_subset": "eng_Latn-yap_Latn",
        "languages": [
          "eng-Latn",
          "yap-Latn"
        ],
        "main_score": 0.05413049768518518,
        "precision": 0.0493410885989011,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03519454656862745,
        "hf_subset": "yap_Latn-eng_Latn",
        "languages": [
          "yap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03519454656862745,
        "precision": 0.03167953083221925,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0018446180555555555,
        "hf_subset": "eng_Latn-yaq_Latn",
        "languages": [
          "eng-Latn",
          "yaq-Latn"
        ],
        "main_score": 0.0018446180555555555,
        "precision": 0.0010091145833333332,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010552536231884057,
        "hf_subset": "yaq_Latn-eng_Latn",
        "languages": [
          "yaq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010552536231884057,
        "precision": 0.0005736204954954955,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008874725877192981,
        "hf_subset": "eng_Latn-yby_Latn",
        "languages": [
          "eng-Latn",
          "yby-Latn"
        ],
        "main_score": 0.008874725877192981,
        "precision": 0.007378472222222222,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00017361111111111112,
        "hf_subset": "yby_Latn-eng_Latn",
        "languages": [
          "yby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00017361111111111112,
        "precision": 8.87784090909091e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00610991256550467,
        "hf_subset": "eng_Latn-ycn_Latn",
        "languages": [
          "eng-Latn",
          "ycn-Latn"
        ],
        "main_score": 0.00610991256550467,
        "precision": 0.004378672542735043,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004138764880952381,
        "hf_subset": "ycn_Latn-eng_Latn",
        "languages": [
          "ycn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004138764880952381,
        "precision": 0.002811641483516483,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019534632034632033,
        "hf_subset": "eng_Latn-yka_Latn",
        "languages": [
          "eng-Latn",
          "yka-Latn"
        ],
        "main_score": 0.019534632034632033,
        "precision": 0.017080382799671594,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016619063620071685,
        "hf_subset": "yka_Latn-eng_Latn",
        "languages": [
          "yka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016619063620071685,
        "precision": 0.0161773181352459,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00671073717948718,
        "hf_subset": "eng_Latn-yle_Latn",
        "languages": [
          "eng-Latn",
          "yle-Latn"
        ],
        "main_score": 0.00671073717948718,
        "precision": 0.005962171052631578,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0039420871559633025,
        "hf_subset": "yle_Latn-eng_Latn",
        "languages": [
          "yle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0039420871559633025,
        "precision": 0.003924251152073733,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011979166666666666,
        "hf_subset": "eng_Latn-yml_Latn",
        "languages": [
          "eng-Latn",
          "yml-Latn"
        ],
        "main_score": 0.011979166666666666,
        "precision": 0.0107421875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0048828125,
        "hf_subset": "yml_Latn-eng_Latn",
        "languages": [
          "yml-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0048828125,
        "precision": 0.004464285714285714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007848434117965368,
        "hf_subset": "eng_Latn-yon_Latn",
        "languages": [
          "eng-Latn",
          "yon-Latn"
        ],
        "main_score": 0.007848434117965368,
        "precision": 0.006213182974057483,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004988953991628865,
        "hf_subset": "yon_Latn-eng_Latn",
        "languages": [
          "yon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004988953991628865,
        "precision": 0.0033650269001831504,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03516808712121212,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ],
        "main_score": 0.03516808712121212,
        "precision": 0.029203493265993263,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018135315205627705,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018135315205627705,
        "precision": 0.01599876254904796,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010230654761904762,
        "hf_subset": "eng_Latn-yrb_Latn",
        "languages": [
          "eng-Latn",
          "yrb-Latn"
        ],
        "main_score": 0.010230654761904762,
        "precision": 0.009244791666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004111842105263158,
        "hf_subset": "yrb_Latn-eng_Latn",
        "languages": [
          "yrb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004111842105263158,
        "precision": 0.004011824324324324,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0022966269841269843,
        "hf_subset": "eng_Latn-yre_Latn",
        "languages": [
          "eng-Latn",
          "yre-Latn"
        ],
        "main_score": 0.0022966269841269843,
        "precision": 0.0013020833333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0030215992647058825,
        "hf_subset": "yre_Latn-eng_Latn",
        "languages": [
          "yre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0030215992647058825,
        "precision": 0.0019066220238095238,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006336805555555556,
        "hf_subset": "eng_Latn-yss_Latn",
        "languages": [
          "eng-Latn",
          "yss-Latn"
        ],
        "main_score": 0.006336805555555556,
        "precision": 0.00537109375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013821402862466125,
        "hf_subset": "yss_Latn-eng_Latn",
        "languages": [
          "yss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013821402862466125,
        "precision": 0.011864631558641973,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013023047760770975,
        "hf_subset": "eng_Latn-yuj_Latn",
        "languages": [
          "eng-Latn",
          "yuj-Latn"
        ],
        "main_score": 0.013023047760770975,
        "precision": 0.011244752411273788,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009765625,
        "hf_subset": "yuj_Latn-eng_Latn",
        "languages": [
          "yuj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.009114583333333332,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02173410938654841,
        "hf_subset": "eng_Latn-yut_Latn",
        "languages": [
          "eng-Latn",
          "yut-Latn"
        ],
        "main_score": 0.02173410938654841,
        "precision": 0.02080078125,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00987884963768116,
        "hf_subset": "yut_Latn-eng_Latn",
        "languages": [
          "yut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00987884963768116,
        "precision": 0.00917202818627451,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0151075487012987,
        "hf_subset": "eng_Latn-yuw_Latn",
        "languages": [
          "eng-Latn",
          "yuw-Latn"
        ],
        "main_score": 0.0151075487012987,
        "precision": 0.013736979166666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001173516281512605,
        "hf_subset": "yuw_Latn-eng_Latn",
        "languages": [
          "yuw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001173516281512605,
        "precision": 0.0006799768518518519,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005625,
        "hf_subset": "eng_Latn-yva_Latn",
        "languages": [
          "eng-Latn",
          "yva-Latn"
        ],
        "main_score": 0.005625,
        "precision": 0.003790656887755102,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0068175613239247305,
        "hf_subset": "yva_Latn-eng_Latn",
        "languages": [
          "yva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0068175613239247305,
        "precision": 0.0060171411945974295,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.0430182443957115,
        "hf_subset": "eng_Latn-zaa_Latn",
        "languages": [
          "eng-Latn",
          "zaa-Latn"
        ],
        "main_score": 0.0430182443957115,
        "precision": 0.039784867909867905,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03373898237179487,
        "hf_subset": "zaa_Latn-eng_Latn",
        "languages": [
          "zaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03373898237179487,
        "precision": 0.029017857142857144,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.023577008928571428,
        "hf_subset": "eng_Latn-zab_Latn",
        "languages": [
          "eng-Latn",
          "zab-Latn"
        ],
        "main_score": 0.023577008928571428,
        "precision": 0.023508522727272725,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00954483695652174,
        "hf_subset": "zab_Latn-eng_Latn",
        "languages": [
          "zab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00954483695652174,
        "precision": 0.007573784722222222,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025,
        "hf_subset": "eng_Latn-zac_Latn",
        "languages": [
          "eng-Latn",
          "zac-Latn"
        ],
        "main_score": 0.025,
        "precision": 0.02194010416666667,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011894117292870906,
        "hf_subset": "zac_Latn-eng_Latn",
        "languages": [
          "zac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011894117292870906,
        "precision": 0.009571321866925065,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021150150401069517,
        "hf_subset": "eng_Latn-zad_Latn",
        "languages": [
          "eng-Latn",
          "zad-Latn"
        ],
        "main_score": 0.021150150401069517,
        "precision": 0.017940848214285713,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01218527183600713,
        "hf_subset": "zad_Latn-eng_Latn",
        "languages": [
          "zad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01218527183600713,
        "precision": 0.010657108191287878,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013229446684587812,
        "hf_subset": "eng_Latn-zai_Latn",
        "languages": [
          "eng-Latn",
          "zai-Latn"
        ],
        "main_score": 0.013229446684587812,
        "precision": 0.01254283168859649,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014163187415654522,
        "hf_subset": "zai_Latn-eng_Latn",
        "languages": [
          "zai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014163187415654522,
        "precision": 0.011918853715728716,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004997772346117934,
        "hf_subset": "eng_Latn-zaj_Latn",
        "languages": [
          "eng-Latn",
          "zaj-Latn"
        ],
        "main_score": 0.004997772346117934,
        "precision": 0.003011067708333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004909003831417624,
        "hf_subset": "zaj_Latn-eng_Latn",
        "languages": [
          "zaj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004909003831417624,
        "precision": 0.003435346177944862,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01702987938596491,
        "hf_subset": "eng_Latn-zam_Latn",
        "languages": [
          "eng-Latn",
          "zam-Latn"
        ],
        "main_score": 0.01702987938596491,
        "precision": 0.013984375,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011639421393557423,
        "hf_subset": "zam_Latn-eng_Latn",
        "languages": [
          "zam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011639421393557423,
        "precision": 0.01014649920709372,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006834451103500762,
        "hf_subset": "eng_Latn-zao_Latn",
        "languages": [
          "eng-Latn",
          "zao-Latn"
        ],
        "main_score": 0.006834451103500762,
        "precision": 0.005750868055555555,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00875422010223024,
        "hf_subset": "zao_Latn-eng_Latn",
        "languages": [
          "zao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00875422010223024,
        "precision": 0.007190393518518519,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03292518028846154,
        "hf_subset": "eng_Latn-zap_Latn",
        "languages": [
          "eng-Latn",
          "zap-Latn"
        ],
        "main_score": 0.03292518028846154,
        "precision": 0.028789396367521366,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013386824324324325,
        "hf_subset": "zap_Latn-eng_Latn",
        "languages": [
          "zap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013386824324324325,
        "precision": 0.012748822773972603,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014379370629370627,
        "hf_subset": "eng_Latn-zar_Latn",
        "languages": [
          "eng-Latn",
          "zar-Latn"
        ],
        "main_score": 0.014379370629370627,
        "precision": 0.012057834201388888,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014647439989785495,
        "hf_subset": "zar_Latn-eng_Latn",
        "languages": [
          "zar-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014647439989785495,
        "precision": 0.01253625118371212,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015885416666666666,
        "hf_subset": "eng_Latn-zas_Latn",
        "languages": [
          "eng-Latn",
          "zas-Latn"
        ],
        "main_score": 0.015885416666666666,
        "precision": 0.012399384469696968,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012352701822916666,
        "hf_subset": "zas_Latn-eng_Latn",
        "languages": [
          "zas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012352701822916666,
        "precision": 0.010935705790682416,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025031001984126982,
        "hf_subset": "eng_Latn-zat_Latn",
        "languages": [
          "eng-Latn",
          "zat-Latn"
        ],
        "main_score": 0.025031001984126982,
        "precision": 0.021777343749999997,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009393780048076924,
        "hf_subset": "zat_Latn-eng_Latn",
        "languages": [
          "zat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009393780048076924,
        "precision": 0.007570711798282363,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01010545444139194,
        "hf_subset": "eng_Latn-zav_Latn",
        "languages": [
          "eng-Latn",
          "zav-Latn"
        ],
        "main_score": 0.01010545444139194,
        "precision": 0.00912437343358396,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.403688524590164e-05,
        "hf_subset": "zav_Latn-eng_Latn",
        "languages": [
          "zav-Latn",
          "eng-Latn"
        ],
        "main_score": 6.403688524590164e-05,
        "precision": 3.228305785123967e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02134576612903226,
        "hf_subset": "eng_Latn-zaw_Latn",
        "languages": [
          "eng-Latn",
          "zaw-Latn"
        ],
        "main_score": 0.02134576612903226,
        "precision": 0.019466145833333334,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020258206040111942,
        "hf_subset": "zaw_Latn-eng_Latn",
        "languages": [
          "zaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020258206040111942,
        "precision": 0.018610772907647906,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01755487351190476,
        "hf_subset": "eng_Latn-zca_Latn",
        "languages": [
          "eng-Latn",
          "zca-Latn"
        ],
        "main_score": 0.01755487351190476,
        "precision": 0.013754986702127658,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004995492788461538,
        "hf_subset": "zca_Latn-eng_Latn",
        "languages": [
          "zca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004995492788461538,
        "precision": 0.0033203125000000003,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012463831018518518,
        "hf_subset": "eng_Latn-zga_Latn",
        "languages": [
          "eng-Latn",
          "zga-Latn"
        ],
        "main_score": 0.012463831018518518,
        "precision": 0.01069666011072261,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005521334134615384,
        "hf_subset": "zga_Latn-eng_Latn",
        "languages": [
          "zga-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005521334134615384,
        "precision": 0.004065954839382562,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010062056737588651,
        "hf_subset": "eng_Latn-zia_Latn",
        "languages": [
          "eng-Latn",
          "zia-Latn"
        ],
        "main_score": 0.010062056737588651,
        "precision": 0.007810612922705315,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "zia_Latn-eng_Latn",
        "languages": [
          "zia-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0055496369949494945,
        "hf_subset": "eng_Latn-ziw_Latn",
        "languages": [
          "eng-Latn",
          "ziw-Latn"
        ],
        "main_score": 0.0055496369949494945,
        "precision": 0.003595659069548872,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0008442735791275279,
        "hf_subset": "ziw_Latn-eng_Latn",
        "languages": [
          "ziw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008442735791275279,
        "precision": 0.00043635852528281315,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022934857536764705,
        "hf_subset": "eng_Latn-zlm_Latn",
        "languages": [
          "eng-Latn",
          "zlm-Latn"
        ],
        "main_score": 0.022934857536764705,
        "precision": 0.018944776102034166,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02312955771524615,
        "hf_subset": "zlm_Latn-eng_Latn",
        "languages": [
          "zlm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02312955771524615,
        "precision": 0.02101004464285714,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00669892723880597,
        "hf_subset": "eng_Latn-zos_Latn",
        "languages": [
          "eng-Latn",
          "zos-Latn"
        ],
        "main_score": 0.00669892723880597,
        "precision": 0.005671731411862991,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013561942268724182,
        "hf_subset": "zos_Latn-eng_Latn",
        "languages": [
          "zos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013561942268724182,
        "precision": 0.010462522644927537,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02267947965571205,
        "hf_subset": "eng_Latn-zpc_Latn",
        "languages": [
          "eng-Latn",
          "zpc-Latn"
        ],
        "main_score": 0.02267947965571205,
        "precision": 0.02065239448051948,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004225218430395414,
        "hf_subset": "zpc_Latn-eng_Latn",
        "languages": [
          "zpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004225218430395414,
        "precision": 0.0028711508589181287,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01295107886904762,
        "hf_subset": "eng_Latn-zpl_Latn",
        "languages": [
          "eng-Latn",
          "zpl-Latn"
        ],
        "main_score": 0.01295107886904762,
        "precision": 0.011072838492808004,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008004964806435394,
        "hf_subset": "zpl_Latn-eng_Latn",
        "languages": [
          "zpl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008004964806435394,
        "precision": 0.006658815870098039,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017838541666666666,
        "hf_subset": "eng_Latn-zpm_Latn",
        "languages": [
          "eng-Latn",
          "zpm-Latn"
        ],
        "main_score": 0.017838541666666666,
        "precision": 0.015950520833333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01505552912763466,
        "hf_subset": "zpm_Latn-eng_Latn",
        "languages": [
          "zpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01505552912763466,
        "precision": 0.013643973214285714,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02108226973185881,
        "hf_subset": "eng_Latn-zpo_Latn",
        "languages": [
          "eng-Latn",
          "zpo-Latn"
        ],
        "main_score": 0.02108226973185881,
        "precision": 0.01845494879349046,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02052094275210084,
        "hf_subset": "zpo_Latn-eng_Latn",
        "languages": [
          "zpo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02052094275210084,
        "precision": 0.018936058479391372,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01139511442245817,
        "hf_subset": "eng_Latn-zpq_Latn",
        "languages": [
          "eng-Latn",
          "zpq-Latn"
        ],
        "main_score": 0.01139511442245817,
        "precision": 0.008646453373015874,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015040731837606836,
        "hf_subset": "zpq_Latn-eng_Latn",
        "languages": [
          "zpq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015040731837606836,
        "precision": 0.01305450790229885,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.036318329373079876,
        "hf_subset": "eng_Latn-zpu_Latn",
        "languages": [
          "eng-Latn",
          "zpu-Latn"
        ],
        "main_score": 0.036318329373079876,
        "precision": 0.03210938735373181,
        "recall": 0.0625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019006170742753622,
        "hf_subset": "zpu_Latn-eng_Latn",
        "languages": [
          "zpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019006170742753622,
        "precision": 0.016566051136363637,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024348958333333334,
        "hf_subset": "eng_Latn-zpv_Latn",
        "languages": [
          "eng-Latn",
          "zpv-Latn"
        ],
        "main_score": 0.024348958333333334,
        "precision": 0.02023018438697318,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012630696004993757,
        "hf_subset": "zpv_Latn-eng_Latn",
        "languages": [
          "zpv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012630696004993757,
        "precision": 0.010275975459039547,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02237723214285714,
        "hf_subset": "eng_Latn-zpz_Latn",
        "languages": [
          "eng-Latn",
          "zpz-Latn"
        ],
        "main_score": 0.02237723214285714,
        "precision": 0.020110748626373628,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004277998643984221,
        "hf_subset": "zpz_Latn-eng_Latn",
        "languages": [
          "zpz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004277998643984221,
        "precision": 0.004099338444616977,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02679423983134921,
        "hf_subset": "eng_Latn-zsr_Latn",
        "languages": [
          "eng-Latn",
          "zsr-Latn"
        ],
        "main_score": 0.02679423983134921,
        "precision": 0.02291246639784946,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005290415612583255,
        "hf_subset": "zsr_Latn-eng_Latn",
        "languages": [
          "zsr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005290415612583255,
        "precision": 0.00343135597041847,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01648726851851852,
        "hf_subset": "eng_Latn-ztq_Latn",
        "languages": [
          "eng-Latn",
          "ztq-Latn"
        ],
        "main_score": 0.01648726851851852,
        "precision": 0.014961438301282052,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016648554981203007,
        "hf_subset": "ztq_Latn-eng_Latn",
        "languages": [
          "ztq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016648554981203007,
        "precision": 0.014716021825396823,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01000513865663322,
        "hf_subset": "eng_Latn-zty_Latn",
        "languages": [
          "eng-Latn",
          "zty-Latn"
        ],
        "main_score": 0.01000513865663322,
        "precision": 0.00899621212121212,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.015625,
        "hf_subset": "zty_Latn-eng_Latn",
        "languages": [
          "zty-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015625,
        "precision": 0.014322916666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.014857432693874226,
        "hf_subset": "eng_Latn-zyp_Latn",
        "languages": [
          "eng-Latn",
          "zyp-Latn"
        ],
        "main_score": 0.014857432693874226,
        "precision": 0.01190706814992257,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0053116732804232795,
        "hf_subset": "zyp_Latn-eng_Latn",
        "languages": [
          "zyp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0053116732804232795,
        "precision": 0.004707532051282052,
        "recall": 0.01171875
      }
    ]
  },
  "task_name": "BibleNLPBitextMining"
}