{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.8",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.31126,
            "f1": 0.293079,
            "f1_weighted": 0.293047,
            "precision": 0.317221,
            "precision_weighted": 0.317168,
            "recall": 0.31127,
            "recall_weighted": 0.31126,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.292531,
            "f1": 0.281294,
            "f1_weighted": 0.281283,
            "precision": 0.304384,
            "precision_weighted": 0.304388,
            "recall": 0.292556,
            "recall_weighted": 0.292531,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.319287,
            "f1": 0.301708,
            "f1_weighted": 0.30174,
            "precision": 0.324401,
            "precision_weighted": 0.324547,
            "recall": 0.319324,
            "recall_weighted": 0.319287,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.328651,
            "f1": 0.312522,
            "f1_weighted": 0.312515,
            "precision": 0.32267,
            "precision_weighted": 0.322629,
            "recall": 0.328658,
            "recall_weighted": 0.328651,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.283166,
            "f1": 0.257959,
            "f1_weighted": 0.258009,
            "precision": 0.293315,
            "precision_weighted": 0.293301,
            "recall": 0.283041,
            "recall_weighted": 0.283166,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.298774,
            "f1": 0.283202,
            "f1_weighted": 0.28313,
            "precision": 0.311262,
            "precision_weighted": 0.311196,
            "recall": 0.298866,
            "recall_weighted": 0.298774,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.304125,
            "f1": 0.28067,
            "f1_weighted": 0.280704,
            "precision": 0.305917,
            "precision_weighted": 0.305906,
            "recall": 0.304026,
            "recall_weighted": 0.304125,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.299889,
            "f1": 0.281925,
            "f1_weighted": 0.281848,
            "precision": 0.302339,
            "precision_weighted": 0.302263,
            "recall": 0.299945,
            "recall_weighted": 0.299889,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.281828,
            "f1": 0.263627,
            "f1_weighted": 0.263559,
            "precision": 0.283132,
            "precision_weighted": 0.283055,
            "recall": 0.281915,
            "recall_weighted": 0.281828,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.292531,
            "f1": 0.26963,
            "f1_weighted": 0.269676,
            "precision": 0.30095,
            "precision_weighted": 0.30084,
            "recall": 0.292403,
            "recall_weighted": 0.292531,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.301204,
        "f1": 0.282561,
        "f1_weighted": 0.282551,
        "precision": 0.306559,
        "precision_weighted": 0.306529,
        "recall": 0.301201,
        "recall_weighted": 0.301204,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.282561,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 64.2535240650177,
  "kg_co2_emissions": null
}