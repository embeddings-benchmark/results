{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 322.7057957649231,
  "kg_co2_emissions": 0.014635550030818817,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.01901938641069076,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.01901938641069076,
        "precision": 0.018232361092181185,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.11462450592885376,
        "f1": 0.06464649434260812,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.06464649434260812,
        "precision": 0.05452674588246088,
        "recall": 0.11462450592885376
      },
      {
        "accuracy": 0.058300395256917,
        "f1": 0.04923525044648715,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.04923525044648715,
        "precision": 0.04806152465280167,
        "recall": 0.058300395256917
      },
      {
        "accuracy": 0.11758893280632411,
        "f1": 0.0693079285554058,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0693079285554058,
        "precision": 0.060115592583655716,
        "recall": 0.11758893280632411
      },
      {
        "accuracy": 0.05434782608695652,
        "f1": 0.04448818500531191,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.04448818500531191,
        "precision": 0.04263707858710729,
        "recall": 0.05434782608695652
      },
      {
        "accuracy": 0.17391304347826086,
        "f1": 0.12229219039117899,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.12229219039117899,
        "precision": 0.10828117726586105,
        "recall": 0.17391304347826086
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.05263689065143283,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.05263689065143283,
        "precision": 0.05083012350042068,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.13537549407114624,
        "f1": 0.07982857731010846,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.07982857731010846,
        "precision": 0.06902249685952636,
        "recall": 0.13537549407114624
      },
      {
        "accuracy": 0.05731225296442688,
        "f1": 0.045975584201462825,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.045975584201462825,
        "precision": 0.043773932129321486,
        "recall": 0.05731225296442688
      },
      {
        "accuracy": 0.12549407114624506,
        "f1": 0.08023058305736425,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.08023058305736425,
        "precision": 0.06983845826171041,
        "recall": 0.12549407114624506
      },
      {
        "accuracy": 0.05632411067193676,
        "f1": 0.04585997277851693,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.04585997277851693,
        "precision": 0.04358598863013737,
        "recall": 0.05632411067193676
      },
      {
        "accuracy": 0.13932806324110672,
        "f1": 0.08832092564179742,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.08832092564179742,
        "precision": 0.07560660639924412,
        "recall": 0.13932806324110672
      },
      {
        "accuracy": 0.07608695652173914,
        "f1": 0.06547982936957067,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.06547982936957067,
        "precision": 0.06334267917472984,
        "recall": 0.07608695652173914
      },
      {
        "accuracy": 0.14624505928853754,
        "f1": 0.09389345508765726,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.09389345508765726,
        "precision": 0.0822251492732574,
        "recall": 0.14624505928853754
      },
      {
        "accuracy": 0.11363636363636363,
        "f1": 0.09894837057245157,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.09894837057245157,
        "precision": 0.09614855064169797,
        "recall": 0.11363636363636363
      },
      {
        "accuracy": 0.17588932806324112,
        "f1": 0.10203735718556323,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.10203735718556323,
        "precision": 0.08634271194104663,
        "recall": 0.17588932806324112
      },
      {
        "accuracy": 0.040513833992094864,
        "f1": 0.03388135531681275,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.03388135531681275,
        "precision": 0.032299233363268495,
        "recall": 0.040513833992094864
      },
      {
        "accuracy": 0.1274703557312253,
        "f1": 0.08666094619366317,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.08666094619366317,
        "precision": 0.07726998173562026,
        "recall": 0.1274703557312253
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.02555682156958488,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.02555682156958488,
        "precision": 0.02463737842696638,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.1007905138339921,
        "f1": 0.0561572368402517,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0561572368402517,
        "precision": 0.04592845861480937,
        "recall": 0.1007905138339921
      },
      {
        "accuracy": 0.06422924901185771,
        "f1": 0.05468675714197725,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05468675714197725,
        "precision": 0.052545461072078664,
        "recall": 0.06422924901185771
      },
      {
        "accuracy": 0.1650197628458498,
        "f1": 0.11702404788255386,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.11702404788255386,
        "precision": 0.10441314727159436,
        "recall": 0.1650197628458498
      },
      {
        "accuracy": 0.07905138339920949,
        "f1": 0.06922551742480992,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06922551742480992,
        "precision": 0.06723646859764583,
        "recall": 0.07905138339920949
      },
      {
        "accuracy": 0.17687747035573123,
        "f1": 0.12087804937757665,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.12087804937757665,
        "precision": 0.10761339697851556,
        "recall": 0.17687747035573123
      },
      {
        "accuracy": 0.05632411067193676,
        "f1": 0.04611495030583615,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.04611495030583615,
        "precision": 0.04412716788516021,
        "recall": 0.05632411067193676
      },
      {
        "accuracy": 0.13932806324110672,
        "f1": 0.08281778131423534,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.08281778131423534,
        "precision": 0.07195054136461305,
        "recall": 0.13932806324110672
      },
      {
        "accuracy": 0.06027667984189723,
        "f1": 0.04921805314131988,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.04921805314131988,
        "precision": 0.0477616840624052,
        "recall": 0.06027667984189723
      },
      {
        "accuracy": 0.13142292490118576,
        "f1": 0.08119505550080074,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.08119505550080074,
        "precision": 0.0715980914009878,
        "recall": 0.13142292490118576
      },
      {
        "accuracy": 0.12055335968379446,
        "f1": 0.11267928622955965,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.11267928622955965,
        "precision": 0.1104991352212896,
        "recall": 0.12055335968379446
      },
      {
        "accuracy": 0.1976284584980237,
        "f1": 0.11769853264353472,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.11769853264353472,
        "precision": 0.09930327703150348,
        "recall": 0.1976284584980237
      },
      {
        "accuracy": 0.06126482213438735,
        "f1": 0.053561402602323324,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.053561402602323324,
        "precision": 0.05179844874039814,
        "recall": 0.06126482213438735
      },
      {
        "accuracy": 0.13339920948616601,
        "f1": 0.08065911002665081,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.08065911002665081,
        "precision": 0.06975306867687538,
        "recall": 0.13339920948616601
      },
      {
        "accuracy": 0.046442687747035576,
        "f1": 0.03615805259889548,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03615805259889548,
        "precision": 0.03448600201377182,
        "recall": 0.046442687747035576
      },
      {
        "accuracy": 0.15316205533596838,
        "f1": 0.10531581258428101,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.10531581258428101,
        "precision": 0.09330515060258143,
        "recall": 0.15316205533596838
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.022902182965565596,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.022902182965565596,
        "precision": 0.021583918982779712,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.15118577075098813,
        "f1": 0.10699509829944613,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.10699509829944613,
        "precision": 0.09443551924148753,
        "recall": 0.15118577075098813
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.027088208373585,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.027088208373585,
        "precision": 0.026103856019826094,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.09683794466403162,
        "f1": 0.05351799473353598,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.05351799473353598,
        "precision": 0.04580005108773378,
        "recall": 0.09683794466403162
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.027595324639727966,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.027595324639727966,
        "precision": 0.02675219645252965,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.14525691699604742,
        "f1": 0.09672700218137406,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.09672700218137406,
        "precision": 0.085235296864096,
        "recall": 0.14525691699604742
      },
      {
        "accuracy": 0.040513833992094864,
        "f1": 0.03208504521430243,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03208504521430243,
        "precision": 0.03070039706961348,
        "recall": 0.040513833992094864
      },
      {
        "accuracy": 0.15019762845849802,
        "f1": 0.10031253621988336,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.10031253621988336,
        "precision": 0.08806916238627327,
        "recall": 0.15019762845849802
      },
      {
        "accuracy": 0.09090909090909091,
        "f1": 0.08066176512868321,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08066176512868321,
        "precision": 0.07826456138481488,
        "recall": 0.09090909090909091
      },
      {
        "accuracy": 0.18280632411067194,
        "f1": 0.12426083312706986,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.12426083312706986,
        "precision": 0.10944605291079183,
        "recall": 0.18280632411067194
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.025125554094435745,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.025125554094435745,
        "precision": 0.023788564809192482,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.1274703557312253,
        "f1": 0.08582175248544163,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.08582175248544163,
        "precision": 0.0762745695330135,
        "recall": 0.1274703557312253
      },
      {
        "accuracy": 0.05533596837944664,
        "f1": 0.046326234798689435,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.046326234798689435,
        "precision": 0.04462391022950029,
        "recall": 0.05533596837944664
      },
      {
        "accuracy": 0.17588932806324112,
        "f1": 0.12101639691807675,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.12101639691807675,
        "precision": 0.10815853829322425,
        "recall": 0.17588932806324112
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.05175280723380312,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05175280723380312,
        "precision": 0.04934841395133495,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.18181818181818182,
        "f1": 0.12549245181559845,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.12549245181559845,
        "precision": 0.11105479848068782,
        "recall": 0.18181818181818182
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.03551270908431209,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.03551270908431209,
        "precision": 0.03434035780986551,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.1383399209486166,
        "f1": 0.08023444542568148,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.08023444542568148,
        "precision": 0.06879261214168453,
        "recall": 0.1383399209486166
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.028899777017567727,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.028899777017567727,
        "precision": 0.027370958124662236,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.1492094861660079,
        "f1": 0.10588336783988957,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.10588336783988957,
        "precision": 0.0935451344906913,
        "recall": 0.1492094861660079
      },
      {
        "accuracy": 0.04940711462450593,
        "f1": 0.0402995610829194,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0402995610829194,
        "precision": 0.0383345005927341,
        "recall": 0.04940711462450593
      },
      {
        "accuracy": 0.17687747035573123,
        "f1": 0.12164577416319668,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.12164577416319668,
        "precision": 0.10688889411715499,
        "recall": 0.17687747035573123
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.01059812636988225,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.01059812636988225,
        "precision": 0.00983632120819209,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.006270676028611636,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.006270676028611636,
        "precision": 0.0044449052139424695,
        "recall": 0.02766798418972332
      }
    ],
    "validation": [
      {
        "accuracy": 0.034102306920762285,
        "f1": 0.02893380190601367,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.02893380190601367,
        "precision": 0.027577272046023126,
        "recall": 0.034102306920762285
      },
      {
        "accuracy": 0.11434302908726178,
        "f1": 0.06507229743822515,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.06507229743822515,
        "precision": 0.05511734480770318,
        "recall": 0.11434302908726178
      },
      {
        "accuracy": 0.055165496489468405,
        "f1": 0.04642330728800665,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.04642330728800665,
        "precision": 0.04454975688214283,
        "recall": 0.055165496489468405
      },
      {
        "accuracy": 0.10932798395185557,
        "f1": 0.06210883234812194,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.06210883234812194,
        "precision": 0.052970037075722044,
        "recall": 0.10932798395185557
      },
      {
        "accuracy": 0.09327983951855567,
        "f1": 0.07985937230646968,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07985937230646968,
        "precision": 0.07679900363556062,
        "recall": 0.09327983951855567
      },
      {
        "accuracy": 0.1624874623871615,
        "f1": 0.11962929010502224,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.11962929010502224,
        "precision": 0.10741764643469759,
        "recall": 0.1624874623871615
      },
      {
        "accuracy": 0.07422266800401203,
        "f1": 0.0612426858985938,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0612426858985938,
        "precision": 0.05774337052672058,
        "recall": 0.07422266800401203
      },
      {
        "accuracy": 0.12938816449348045,
        "f1": 0.07767364715849705,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.07767364715849705,
        "precision": 0.0679796080755069,
        "recall": 0.12938816449348045
      },
      {
        "accuracy": 0.08124373119358075,
        "f1": 0.06489854408989172,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.06489854408989172,
        "precision": 0.06048210553545373,
        "recall": 0.08124373119358075
      },
      {
        "accuracy": 0.13841524573721165,
        "f1": 0.08460935516931088,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.08460935516931088,
        "precision": 0.07345394796033242,
        "recall": 0.13841524573721165
      },
      {
        "accuracy": 0.08525576730190572,
        "f1": 0.07266112158905796,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07266112158905796,
        "precision": 0.06939226272138803,
        "recall": 0.08525576730190572
      },
      {
        "accuracy": 0.13640922768304914,
        "f1": 0.08900222780605348,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.08900222780605348,
        "precision": 0.07750889563960356,
        "recall": 0.13640922768304914
      },
      {
        "accuracy": 0.10431293881644935,
        "f1": 0.09521170348652795,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.09521170348652795,
        "precision": 0.0921275731957778,
        "recall": 0.10431293881644935
      },
      {
        "accuracy": 0.15747241725175526,
        "f1": 0.09615042160441517,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.09615042160441517,
        "precision": 0.08251853898177913,
        "recall": 0.15747241725175526
      },
      {
        "accuracy": 0.11634904714142427,
        "f1": 0.10508823715084287,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.10508823715084287,
        "precision": 0.10150097311581764,
        "recall": 0.11634904714142427
      },
      {
        "accuracy": 0.14944834503510532,
        "f1": 0.0827872215750246,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.0827872215750246,
        "precision": 0.0684645008536353,
        "recall": 0.14944834503510532
      },
      {
        "accuracy": 0.07422266800401203,
        "f1": 0.06457482149026773,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.06457482149026773,
        "precision": 0.062032361621722036,
        "recall": 0.07422266800401203
      },
      {
        "accuracy": 0.14042126379137412,
        "f1": 0.09550354271266483,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.09550354271266483,
        "precision": 0.08492093025356609,
        "recall": 0.14042126379137412
      },
      {
        "accuracy": 0.04513540621865597,
        "f1": 0.03924806769485384,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.03924806769485384,
        "precision": 0.03777552168701225,
        "recall": 0.04513540621865597
      },
      {
        "accuracy": 0.10732196589769308,
        "f1": 0.06023402781961702,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.06023402781961702,
        "precision": 0.0493252709278932,
        "recall": 0.10732196589769308
      },
      {
        "accuracy": 0.1123370110330993,
        "f1": 0.09806997817826711,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09806997817826711,
        "precision": 0.09436651769650765,
        "recall": 0.1123370110330993
      },
      {
        "accuracy": 0.17953861584754263,
        "f1": 0.12646974922806997,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.12646974922806997,
        "precision": 0.11187028799240434,
        "recall": 0.17953861584754263
      },
      {
        "accuracy": 0.10531594784353059,
        "f1": 0.09013020828052612,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09013020828052612,
        "precision": 0.08640299506021673,
        "recall": 0.10531594784353059
      },
      {
        "accuracy": 0.17352056168505517,
        "f1": 0.11740146916226667,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.11740146916226667,
        "precision": 0.10363214858127986,
        "recall": 0.17352056168505517
      },
      {
        "accuracy": 0.07823470411233702,
        "f1": 0.06891064652091634,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.06891064652091634,
        "precision": 0.06588250757361143,
        "recall": 0.07823470411233702
      },
      {
        "accuracy": 0.1374122367101304,
        "f1": 0.07616732815635369,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.07616732815635369,
        "precision": 0.06371959271829918,
        "recall": 0.1374122367101304
      },
      {
        "accuracy": 0.0802407221664995,
        "f1": 0.07080584215234537,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.07080584215234537,
        "precision": 0.06813140397723028,
        "recall": 0.0802407221664995
      },
      {
        "accuracy": 0.13440320962888666,
        "f1": 0.08202446570184392,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.08202446570184392,
        "precision": 0.07207992222161881,
        "recall": 0.13440320962888666
      },
      {
        "accuracy": 0.16349047141424272,
        "f1": 0.15484711710890245,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.15484711710890245,
        "precision": 0.15173616086354302,
        "recall": 0.16349047141424272
      },
      {
        "accuracy": 0.21063189568706117,
        "f1": 0.12607938235200827,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.12607938235200827,
        "precision": 0.10553683778452624,
        "recall": 0.21063189568706117
      },
      {
        "accuracy": 0.0802407221664995,
        "f1": 0.06869299645787003,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06869299645787003,
        "precision": 0.06567958720409449,
        "recall": 0.0802407221664995
      },
      {
        "accuracy": 0.15045135406218657,
        "f1": 0.09299868618888558,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.09299868618888558,
        "precision": 0.08005141412921037,
        "recall": 0.15045135406218657
      },
      {
        "accuracy": 0.07522567703109329,
        "f1": 0.06428730174622412,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06428730174622412,
        "precision": 0.06182913440387081,
        "recall": 0.07522567703109329
      },
      {
        "accuracy": 0.16349047141424272,
        "f1": 0.11665762813765647,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.11665762813765647,
        "precision": 0.1038845721414964,
        "recall": 0.16349047141424272
      },
      {
        "accuracy": 0.08425275827482448,
        "f1": 0.06911017768590487,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06911017768590487,
        "precision": 0.06606109792829168,
        "recall": 0.08425275827482448
      },
      {
        "accuracy": 0.16349047141424272,
        "f1": 0.11888266162264628,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.11888266162264628,
        "precision": 0.10589859462641601,
        "recall": 0.16349047141424272
      },
      {
        "accuracy": 0.04312938816449348,
        "f1": 0.035164130496123866,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.035164130496123866,
        "precision": 0.03306196798002001,
        "recall": 0.04312938816449348
      },
      {
        "accuracy": 0.10531594784353059,
        "f1": 0.057030984179063035,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.057030984179063035,
        "precision": 0.0477435859845589,
        "recall": 0.10531594784353059
      },
      {
        "accuracy": 0.06118355065195587,
        "f1": 0.05034231403665794,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05034231403665794,
        "precision": 0.04794006122793974,
        "recall": 0.06118355065195587
      },
      {
        "accuracy": 0.14343029087261785,
        "f1": 0.09357274832819112,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.09357274832819112,
        "precision": 0.08080556673150494,
        "recall": 0.14343029087261785
      },
      {
        "accuracy": 0.08324974924774323,
        "f1": 0.07004165210844181,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07004165210844181,
        "precision": 0.06705472100807042,
        "recall": 0.08324974924774323
      },
      {
        "accuracy": 0.16449348044132397,
        "f1": 0.11350953528256551,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.11350953528256551,
        "precision": 0.10167269135960925,
        "recall": 0.16449348044132397
      },
      {
        "accuracy": 0.13139418254764293,
        "f1": 0.11612240101948357,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11612240101948357,
        "precision": 0.11233619239642942,
        "recall": 0.13139418254764293
      },
      {
        "accuracy": 0.17953861584754263,
        "f1": 0.11978790359194728,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.11978790359194728,
        "precision": 0.10399217131915227,
        "recall": 0.17953861584754263
      },
      {
        "accuracy": 0.06118355065195587,
        "f1": 0.05258453652932865,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05258453652932865,
        "precision": 0.050494687371808095,
        "recall": 0.06118355065195587
      },
      {
        "accuracy": 0.1444332998996991,
        "f1": 0.09845135454463437,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.09845135454463437,
        "precision": 0.08627568749674196,
        "recall": 0.1444332998996991
      },
      {
        "accuracy": 0.08425275827482448,
        "f1": 0.07343616929493203,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07343616929493203,
        "precision": 0.07056001899727779,
        "recall": 0.08425275827482448
      },
      {
        "accuracy": 0.17753259779338015,
        "f1": 0.12189832778743474,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.12189832778743474,
        "precision": 0.10787924093073101,
        "recall": 0.17753259779338015
      },
      {
        "accuracy": 0.09227683049147442,
        "f1": 0.07981903682427025,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07981903682427025,
        "precision": 0.0764709035817049,
        "recall": 0.09227683049147442
      },
      {
        "accuracy": 0.1765295887662989,
        "f1": 0.1225648306892038,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.1225648306892038,
        "precision": 0.10808913193148699,
        "recall": 0.1765295887662989
      },
      {
        "accuracy": 0.05416248746238716,
        "f1": 0.0469450367910454,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0469450367910454,
        "precision": 0.04501119901056553,
        "recall": 0.05416248746238716
      },
      {
        "accuracy": 0.14844533600802406,
        "f1": 0.08840423853599566,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.08840423853599566,
        "precision": 0.07493759165116562,
        "recall": 0.14844533600802406
      },
      {
        "accuracy": 0.0732196589769308,
        "f1": 0.06129179032366994,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06129179032366994,
        "precision": 0.05887718099353004,
        "recall": 0.0732196589769308
      },
      {
        "accuracy": 0.15947843530591777,
        "f1": 0.11728149539082337,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.11728149539082337,
        "precision": 0.10553033949222514,
        "recall": 0.15947843530591777
      },
      {
        "accuracy": 0.08324974924774323,
        "f1": 0.07297363285327177,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07297363285327177,
        "precision": 0.07010953495406855,
        "recall": 0.08324974924774323
      },
      {
        "accuracy": 0.1815446339017051,
        "f1": 0.131359311276899,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.131359311276899,
        "precision": 0.11716057865756964,
        "recall": 0.1815446339017051
      },
      {
        "accuracy": 0.013039117352056168,
        "f1": 0.010210256520677799,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.010210256520677799,
        "precision": 0.009869444584459193,
        "recall": 0.013039117352056168
      },
      {
        "accuracy": 0.022066198595787363,
        "f1": 0.004591360063752473,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.004591360063752473,
        "precision": 0.002822295033998154,
        "recall": 0.022066198595787363
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}