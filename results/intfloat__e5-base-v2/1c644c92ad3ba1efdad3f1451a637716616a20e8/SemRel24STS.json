{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 20.467928886413574,
  "kg_co2_emissions": 0.0008263790359029293,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.7730906792930915,
        "cosine_spearman": 0.7716860690347854,
        "euclidean_pearson": 0.755794958138371,
        "euclidean_spearman": 0.7716860690347854,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7716860690347854,
        "manhattan_pearson": 0.7554741400342206,
        "manhattan_spearman": 0.7705057110214897,
        "pearson": 0.7730906792930915,
        "spearman": 0.7716860690347854
      },
      {
        "cosine_pearson": 0.17882080762588115,
        "cosine_spearman": 0.15545852476436203,
        "euclidean_pearson": 0.14486525167707565,
        "euclidean_spearman": 0.15546719272562862,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.15545852476436203,
        "manhattan_pearson": 0.14829318563742605,
        "manhattan_spearman": 0.15991568402516212,
        "pearson": 0.17882080762588115,
        "spearman": 0.15545852476436203
      },
      {
        "cosine_pearson": 0.2901538880367114,
        "cosine_spearman": 0.27586113218503305,
        "euclidean_pearson": 0.2990898997627286,
        "euclidean_spearman": 0.27586113218503305,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.27586113218503305,
        "manhattan_pearson": 0.29896909271216365,
        "manhattan_spearman": 0.27665622795067374,
        "pearson": 0.2901538880367114,
        "spearman": 0.27586113218503305
      },
      {
        "cosine_pearson": 0.4223618598603892,
        "cosine_spearman": 0.4042617455184668,
        "euclidean_pearson": 0.42450754686668485,
        "euclidean_spearman": 0.4042617455184668,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.4042617455184668,
        "manhattan_pearson": 0.4224949499901131,
        "manhattan_spearman": 0.40442963691613254,
        "pearson": 0.4223618598603892,
        "spearman": 0.4042617455184668
      },
      {
        "cosine_pearson": 0.1669322342265352,
        "cosine_spearman": 0.12357035833817039,
        "euclidean_pearson": 0.18724389872864092,
        "euclidean_spearman": 0.12357035833817039,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.12357035833817039,
        "manhattan_pearson": 0.18809309977989608,
        "manhattan_spearman": 0.12645621509897703,
        "pearson": 0.1669322342265352,
        "spearman": 0.12357035833817039
      },
      {
        "cosine_pearson": 0.8279979779376034,
        "cosine_spearman": 0.8137860140406038,
        "euclidean_pearson": 0.8213863626938632,
        "euclidean_spearman": 0.8137860683707291,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8137860140406038,
        "manhattan_pearson": 0.8214580158252278,
        "manhattan_spearman": 0.8141784855870166,
        "pearson": 0.8279979779376034,
        "spearman": 0.8137860140406038
      },
      {
        "cosine_pearson": 0.44352076953875313,
        "cosine_spearman": 0.4130358983339678,
        "euclidean_pearson": 0.4468344401068875,
        "euclidean_spearman": 0.4130358983339678,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.4130358983339678,
        "manhattan_pearson": 0.44347506674835985,
        "manhattan_spearman": 0.40678368846869845,
        "pearson": 0.44352076953875313,
        "spearman": 0.4130358983339678
      },
      {
        "cosine_pearson": 0.49508948061417485,
        "cosine_spearman": 0.47289355613677686,
        "euclidean_pearson": 0.508987687566207,
        "euclidean_spearman": 0.4728918608961655,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.47289355613677686,
        "manhattan_pearson": 0.509561999699296,
        "manhattan_spearman": 0.47469350930611076,
        "pearson": 0.49508948061417485,
        "spearman": 0.47289355613677686
      },
      {
        "cosine_pearson": 0.5080480385543377,
        "cosine_spearman": 0.5198995441461747,
        "euclidean_pearson": 0.5279178841454713,
        "euclidean_spearman": 0.5198995441461747,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.5198995441461747,
        "manhattan_pearson": 0.5285323662275149,
        "manhattan_spearman": 0.5209973859151863,
        "pearson": 0.5080480385543377,
        "spearman": 0.5198995441461747
      },
      {
        "cosine_pearson": 0.5090259966180524,
        "cosine_spearman": 0.4941731134063922,
        "euclidean_pearson": 0.5133604099546605,
        "euclidean_spearman": 0.4941731134063922,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.4941731134063922,
        "manhattan_pearson": 0.5156127085211203,
        "manhattan_spearman": 0.49519003891701013,
        "pearson": 0.5090259966180524,
        "spearman": 0.4941731134063922
      },
      {
        "cosine_pearson": 0.5868454469952139,
        "cosine_spearman": 0.5420340689228512,
        "euclidean_pearson": 0.6000808647020777,
        "euclidean_spearman": 0.5420340689228512,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.5420340689228512,
        "manhattan_pearson": 0.599871680832801,
        "manhattan_spearman": 0.5466562445497547,
        "pearson": 0.5868454469952139,
        "spearman": 0.5420340689228512
      },
      {
        "cosine_pearson": 0.2613304814710368,
        "cosine_spearman": 0.2924154282909375,
        "euclidean_pearson": 0.3234950838577572,
        "euclidean_spearman": 0.29263308338929245,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.2924154282909375,
        "manhattan_pearson": 0.32475341070130026,
        "manhattan_spearman": 0.29334418872693274,
        "pearson": 0.2613304814710368,
        "spearman": 0.2924154282909375
      }
    ]
  },
  "task_name": "SemRel24STS"
}