{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.14",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.22735,
            "f1": 0.26036,
            "f1_weighted": 0.203595,
            "precision": 0.298334,
            "precision_weighted": 0.356887,
            "recall": 0.415807,
            "recall_weighted": 0.22735,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.240171,
            "f1": 0.281512,
            "f1_weighted": 0.210749,
            "precision": 0.324099,
            "precision_weighted": 0.411769,
            "recall": 0.432343,
            "recall_weighted": 0.240171,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.253846,
            "f1": 0.28506,
            "f1_weighted": 0.219853,
            "precision": 0.330889,
            "precision_weighted": 0.377401,
            "recall": 0.423936,
            "recall_weighted": 0.253846,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.247009,
            "f1": 0.256441,
            "f1_weighted": 0.217466,
            "precision": 0.294852,
            "precision_weighted": 0.390422,
            "recall": 0.403124,
            "recall_weighted": 0.247009,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.247863,
            "f1": 0.273515,
            "f1_weighted": 0.209528,
            "precision": 0.325139,
            "precision_weighted": 0.415022,
            "recall": 0.422773,
            "recall_weighted": 0.247863,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.252137,
            "f1": 0.279581,
            "f1_weighted": 0.234569,
            "precision": 0.333747,
            "precision_weighted": 0.449857,
            "recall": 0.410817,
            "recall_weighted": 0.252137,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.246154,
            "f1": 0.270974,
            "f1_weighted": 0.199446,
            "precision": 0.320544,
            "precision_weighted": 0.288006,
            "recall": 0.412993,
            "recall_weighted": 0.246154,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.230769,
            "f1": 0.247287,
            "f1_weighted": 0.194541,
            "precision": 0.267577,
            "precision_weighted": 0.340325,
            "recall": 0.398699,
            "recall_weighted": 0.230769,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.248718,
            "f1": 0.278265,
            "f1_weighted": 0.211171,
            "precision": 0.30313,
            "precision_weighted": 0.322185,
            "recall": 0.425732,
            "recall_weighted": 0.248718,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.255556,
            "f1": 0.286517,
            "f1_weighted": 0.226816,
            "precision": 0.327182,
            "precision_weighted": 0.427201,
            "recall": 0.439731,
            "recall_weighted": 0.255556,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.244957,
        "f1": 0.271951,
        "f1_weighted": 0.212774,
        "precision": 0.312549,
        "precision_weighted": 0.377907,
        "recall": 0.418595,
        "recall_weighted": 0.244957,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.271951,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 41.484192848205566,
  "kg_co2_emissions": null
}