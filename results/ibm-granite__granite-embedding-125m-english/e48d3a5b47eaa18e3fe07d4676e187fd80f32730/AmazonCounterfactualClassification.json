{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.24.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.673613,
        "f1": 0.550794,
        "f1_weighted": 0.735512,
        "ap": 0.176439,
        "ap_weighted": 0.176439,
        "scores_per_experiment": [
          {
            "accuracy": 0.763118,
            "f1": 0.614667,
            "f1_weighted": 0.803996,
            "ap": 0.209899,
            "ap_weighted": 0.209899
          },
          {
            "accuracy": 0.704648,
            "f1": 0.581325,
            "f1_weighted": 0.761199,
            "ap": 0.201399,
            "ap_weighted": 0.201399
          },
          {
            "accuracy": 0.653673,
            "f1": 0.534011,
            "f1_weighted": 0.720939,
            "ap": 0.163863,
            "ap_weighted": 0.163863
          },
          {
            "accuracy": 0.608696,
            "f1": 0.496369,
            "f1_weighted": 0.68465,
            "ap": 0.141425,
            "ap_weighted": 0.141425
          },
          {
            "accuracy": 0.562969,
            "f1": 0.480686,
            "f1_weighted": 0.644321,
            "ap": 0.152839,
            "ap_weighted": 0.152839
          },
          {
            "accuracy": 0.737631,
            "f1": 0.601334,
            "f1_weighted": 0.785859,
            "ap": 0.208095,
            "ap_weighted": 0.208095
          },
          {
            "accuracy": 0.701649,
            "f1": 0.562678,
            "f1_weighted": 0.757829,
            "ap": 0.172686,
            "ap_weighted": 0.172686
          },
          {
            "accuracy": 0.677661,
            "f1": 0.549258,
            "f1_weighted": 0.739699,
            "ap": 0.169505,
            "ap_weighted": 0.169505
          },
          {
            "accuracy": 0.684408,
            "f1": 0.561139,
            "f1_weighted": 0.745258,
            "ap": 0.183388,
            "ap_weighted": 0.183388
          },
          {
            "accuracy": 0.641679,
            "f1": 0.52647,
            "f1_weighted": 0.711365,
            "ap": 0.16129,
            "ap_weighted": 0.16129
          }
        ],
        "main_score": 0.673613,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "accuracy": 0.63403,
        "f1": 0.574178,
        "f1_weighted": 0.669704,
        "ap": 0.268923,
        "ap_weighted": 0.268923,
        "scores_per_experiment": [
          {
            "accuracy": 0.604478,
            "f1": 0.551119,
            "f1_weighted": 0.645363,
            "ap": 0.253265,
            "ap_weighted": 0.253265
          },
          {
            "accuracy": 0.623881,
            "f1": 0.56745,
            "f1_weighted": 0.662589,
            "ap": 0.263218,
            "ap_weighted": 0.263218
          },
          {
            "accuracy": 0.491045,
            "f1": 0.468836,
            "f1_weighted": 0.534976,
            "ap": 0.227242,
            "ap_weighted": 0.227242
          },
          {
            "accuracy": 0.647761,
            "f1": 0.584175,
            "f1_weighted": 0.683195,
            "ap": 0.270984,
            "ap_weighted": 0.270984
          },
          {
            "accuracy": 0.713433,
            "f1": 0.641571,
            "f1_weighted": 0.739303,
            "ap": 0.315681,
            "ap_weighted": 0.315681
          },
          {
            "accuracy": 0.646269,
            "f1": 0.584122,
            "f1_weighted": 0.682021,
            "ap": 0.272024,
            "ap_weighted": 0.272024
          },
          {
            "accuracy": 0.697015,
            "f1": 0.620401,
            "f1_weighted": 0.72425,
            "ap": 0.292599,
            "ap_weighted": 0.292599
          },
          {
            "accuracy": 0.644776,
            "f1": 0.592487,
            "f1_weighted": 0.681379,
            "ap": 0.287527,
            "ap_weighted": 0.287527
          },
          {
            "accuracy": 0.650746,
            "f1": 0.584222,
            "f1_weighted": 0.685498,
            "ap": 0.268904,
            "ap_weighted": 0.268904
          },
          {
            "accuracy": 0.620896,
            "f1": 0.547394,
            "f1_weighted": 0.658463,
            "ap": 0.237792,
            "ap_weighted": 0.237792
          }
        ],
        "main_score": 0.63403,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 3.1106953620910645,
  "kg_co2_emissions": null
}