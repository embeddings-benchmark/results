{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.033301,
        "f1": 0.016629,
        "f1_weighted": 0.021601,
        "scores_per_experiment": [
          {
            "accuracy": 0.026855,
            "f1": 0.013329,
            "f1_weighted": 0.017157
          },
          {
            "accuracy": 0.03125,
            "f1": 0.01501,
            "f1_weighted": 0.020062
          },
          {
            "accuracy": 0.030273,
            "f1": 0.015201,
            "f1_weighted": 0.020037
          },
          {
            "accuracy": 0.030762,
            "f1": 0.016359,
            "f1_weighted": 0.019607
          },
          {
            "accuracy": 0.031738,
            "f1": 0.014849,
            "f1_weighted": 0.021412
          },
          {
            "accuracy": 0.036133,
            "f1": 0.015816,
            "f1_weighted": 0.021457
          },
          {
            "accuracy": 0.039551,
            "f1": 0.020542,
            "f1_weighted": 0.027158
          },
          {
            "accuracy": 0.036621,
            "f1": 0.016592,
            "f1_weighted": 0.024102
          },
          {
            "accuracy": 0.036621,
            "f1": 0.01939,
            "f1_weighted": 0.023694
          },
          {
            "accuracy": 0.033203,
            "f1": 0.019201,
            "f1_weighted": 0.021319
          }
        ],
        "main_score": 0.033301,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.033008,
        "f1": 0.016356,
        "f1_weighted": 0.019415,
        "scores_per_experiment": [
          {
            "accuracy": 0.026367,
            "f1": 0.009868,
            "f1_weighted": 0.01178
          },
          {
            "accuracy": 0.030273,
            "f1": 0.01768,
            "f1_weighted": 0.017845
          },
          {
            "accuracy": 0.026367,
            "f1": 0.012409,
            "f1_weighted": 0.016281
          },
          {
            "accuracy": 0.034668,
            "f1": 0.018348,
            "f1_weighted": 0.020298
          },
          {
            "accuracy": 0.031738,
            "f1": 0.013867,
            "f1_weighted": 0.016881
          },
          {
            "accuracy": 0.033203,
            "f1": 0.016905,
            "f1_weighted": 0.02217
          },
          {
            "accuracy": 0.043945,
            "f1": 0.021762,
            "f1_weighted": 0.026572
          },
          {
            "accuracy": 0.036133,
            "f1": 0.016083,
            "f1_weighted": 0.020964
          },
          {
            "accuracy": 0.031738,
            "f1": 0.015839,
            "f1_weighted": 0.016344
          },
          {
            "accuracy": 0.035645,
            "f1": 0.020797,
            "f1_weighted": 0.025019
          }
        ],
        "main_score": 0.033008,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 342.5377264022827,
  "kg_co2_emissions": 0.0174057143789918
}