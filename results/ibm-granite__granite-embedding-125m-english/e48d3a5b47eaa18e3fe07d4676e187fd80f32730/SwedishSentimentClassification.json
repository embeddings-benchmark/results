{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.657227,
        "f1": 0.652727,
        "f1_weighted": 0.652739,
        "ap": 0.605637,
        "ap_weighted": 0.605637,
        "scores_per_experiment": [
          {
            "accuracy": 0.677734,
            "f1": 0.673397,
            "f1_weighted": 0.673508,
            "ap": 0.615728,
            "ap_weighted": 0.615728
          },
          {
            "accuracy": 0.693848,
            "f1": 0.693539,
            "f1_weighted": 0.693567,
            "ap": 0.63364,
            "ap_weighted": 0.63364
          },
          {
            "accuracy": 0.634766,
            "f1": 0.633995,
            "f1_weighted": 0.633945,
            "ap": 0.588962,
            "ap_weighted": 0.588962
          },
          {
            "accuracy": 0.663086,
            "f1": 0.661365,
            "f1_weighted": 0.661436,
            "ap": 0.606117,
            "ap_weighted": 0.606117
          },
          {
            "accuracy": 0.662109,
            "f1": 0.658519,
            "f1_weighted": 0.658416,
            "ap": 0.615881,
            "ap_weighted": 0.615881
          },
          {
            "accuracy": 0.632324,
            "f1": 0.613234,
            "f1_weighted": 0.612982,
            "ap": 0.599854,
            "ap_weighted": 0.599854
          },
          {
            "accuracy": 0.673828,
            "f1": 0.661292,
            "f1_weighted": 0.661483,
            "ap": 0.609762,
            "ap_weighted": 0.609762
          },
          {
            "accuracy": 0.61084,
            "f1": 0.60848,
            "f1_weighted": 0.608569,
            "ap": 0.567361,
            "ap_weighted": 0.567361
          },
          {
            "accuracy": 0.615234,
            "f1": 0.615102,
            "f1_weighted": 0.615123,
            "ap": 0.571848,
            "ap_weighted": 0.571848
          },
          {
            "accuracy": 0.708496,
            "f1": 0.708342,
            "f1_weighted": 0.708362,
            "ap": 0.647214,
            "ap_weighted": 0.647214
          }
        ],
        "main_score": 0.657227,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.65542,
        "f1": 0.650973,
        "f1_weighted": 0.650983,
        "ap": 0.603044,
        "ap_weighted": 0.603044,
        "scores_per_experiment": [
          {
            "accuracy": 0.672363,
            "f1": 0.667204,
            "f1_weighted": 0.667285,
            "ap": 0.610748,
            "ap_weighted": 0.610748
          },
          {
            "accuracy": 0.687988,
            "f1": 0.687729,
            "f1_weighted": 0.687747,
            "ap": 0.628335,
            "ap_weighted": 0.628335
          },
          {
            "accuracy": 0.627441,
            "f1": 0.626604,
            "f1_weighted": 0.626569,
            "ap": 0.582716,
            "ap_weighted": 0.582716
          },
          {
            "accuracy": 0.674805,
            "f1": 0.673051,
            "f1_weighted": 0.673098,
            "ap": 0.614911,
            "ap_weighted": 0.614911
          },
          {
            "accuracy": 0.651855,
            "f1": 0.648192,
            "f1_weighted": 0.648121,
            "ap": 0.60607,
            "ap_weighted": 0.60607
          },
          {
            "accuracy": 0.63623,
            "f1": 0.618034,
            "f1_weighted": 0.617871,
            "ap": 0.6025,
            "ap_weighted": 0.6025
          },
          {
            "accuracy": 0.666504,
            "f1": 0.655062,
            "f1_weighted": 0.655185,
            "ap": 0.604276,
            "ap_weighted": 0.604276
          },
          {
            "accuracy": 0.65332,
            "f1": 0.650915,
            "f1_weighted": 0.650972,
            "ap": 0.597669,
            "ap_weighted": 0.597669
          },
          {
            "accuracy": 0.612793,
            "f1": 0.6123,
            "f1_weighted": 0.612327,
            "ap": 0.569199,
            "ap_weighted": 0.569199
          },
          {
            "accuracy": 0.670898,
            "f1": 0.670634,
            "f1_weighted": 0.670652,
            "ap": 0.61402,
            "ap_weighted": 0.61402
          }
        ],
        "main_score": 0.65542,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 17.448079586029053,
  "kg_co2_emissions": 0.0006744149159506128
}