{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "task_name": "ToxicConversationsClassification",
  "mteb_version": "1.36.5",
  "scores": {
    "test": [
      {
        "accuracy": 0.856885,
        "f1": 0.713175,
        "f1_weighted": 0.884028,
        "ap": 0.333754,
        "ap_weighted": 0.333754,
        "scores_per_experiment": [
          {
            "accuracy": 0.851074,
            "f1": 0.70425,
            "f1_weighted": 0.879666,
            "ap": 0.319378,
            "ap_weighted": 0.319378
          },
          {
            "accuracy": 0.873047,
            "f1": 0.731092,
            "f1_weighted": 0.895561,
            "ap": 0.354826,
            "ap_weighted": 0.354826
          },
          {
            "accuracy": 0.851562,
            "f1": 0.706422,
            "f1_weighted": 0.880187,
            "ap": 0.324653,
            "ap_weighted": 0.324653
          },
          {
            "accuracy": 0.831543,
            "f1": 0.688051,
            "f1_weighted": 0.866151,
            "ap": 0.308587,
            "ap_weighted": 0.308587
          },
          {
            "accuracy": 0.875488,
            "f1": 0.734263,
            "f1_weighted": 0.897339,
            "ap": 0.359266,
            "ap_weighted": 0.359266
          },
          {
            "accuracy": 0.844727,
            "f1": 0.700185,
            "f1_weighted": 0.875424,
            "ap": 0.319413,
            "ap_weighted": 0.319413
          },
          {
            "accuracy": 0.865723,
            "f1": 0.721818,
            "f1_weighted": 0.890244,
            "ap": 0.342152,
            "ap_weighted": 0.342152
          },
          {
            "accuracy": 0.836426,
            "f1": 0.691773,
            "f1_weighted": 0.869522,
            "ap": 0.310462,
            "ap_weighted": 0.310462
          },
          {
            "accuracy": 0.87793,
            "f1": 0.737476,
            "f1_weighted": 0.89912,
            "ap": 0.36382,
            "ap_weighted": 0.36382
          },
          {
            "accuracy": 0.861328,
            "f1": 0.716417,
            "f1_weighted": 0.887064,
            "ap": 0.33498,
            "ap_weighted": 0.33498
          }
        ],
        "main_score": 0.856885,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.903000593185425,
  "kg_co2_emissions": null
}