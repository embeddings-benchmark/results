{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "task_name": "ToxicConversationsClassification",
  "mteb_version": "1.34.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.782129,
        "f1": 0.609322,
        "f1_weighted": 0.826954,
        "ap": 0.190474,
        "ap_weighted": 0.190474,
        "scores_per_experiment": [
          {
            "accuracy": 0.817383,
            "f1": 0.633832,
            "f1_weighted": 0.852068,
            "ap": 0.202011,
            "ap_weighted": 0.202011
          },
          {
            "accuracy": 0.80127,
            "f1": 0.596472,
            "f1_weighted": 0.838467,
            "ap": 0.154381,
            "ap_weighted": 0.154381
          },
          {
            "accuracy": 0.865234,
            "f1": 0.682336,
            "f1_weighted": 0.885243,
            "ap": 0.246781,
            "ap_weighted": 0.246781
          },
          {
            "accuracy": 0.838867,
            "f1": 0.661738,
            "f1_weighted": 0.867791,
            "ap": 0.234233,
            "ap_weighted": 0.234233
          },
          {
            "accuracy": 0.719727,
            "f1": 0.562393,
            "f1_weighted": 0.783275,
            "ap": 0.160971,
            "ap_weighted": 0.160971
          },
          {
            "accuracy": 0.708496,
            "f1": 0.558776,
            "f1_weighted": 0.775136,
            "ap": 0.164342,
            "ap_weighted": 0.164342
          },
          {
            "accuracy": 0.822754,
            "f1": 0.627359,
            "f1_weighted": 0.854507,
            "ap": 0.186036,
            "ap_weighted": 0.186036
          },
          {
            "accuracy": 0.691406,
            "f1": 0.551445,
            "f1_weighted": 0.762366,
            "ap": 0.166567,
            "ap_weighted": 0.166567
          },
          {
            "accuracy": 0.749512,
            "f1": 0.580036,
            "f1_weighted": 0.804614,
            "ap": 0.166417,
            "ap_weighted": 0.166417
          },
          {
            "accuracy": 0.806641,
            "f1": 0.638828,
            "f1_weighted": 0.846069,
            "ap": 0.223001,
            "ap_weighted": 0.223001
          }
        ],
        "main_score": 0.782129,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 12.252830982208252,
  "kg_co2_emissions": null
}