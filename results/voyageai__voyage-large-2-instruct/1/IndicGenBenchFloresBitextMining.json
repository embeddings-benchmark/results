{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.246914,
        "recall": 0.297894,
        "f1": 0.257494,
        "accuracy": 0.297894,
        "main_score": 0.257494,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.338024,
        "recall": 0.442327,
        "f1": 0.363608,
        "accuracy": 0.442327,
        "main_score": 0.363608,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.031647,
        "recall": 0.037111,
        "f1": 0.032685,
        "accuracy": 0.037111,
        "main_score": 0.032685,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056239,
        "recall": 0.122367,
        "f1": 0.067446,
        "accuracy": 0.122367,
        "main_score": 0.067446,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.615819,
        "recall": 0.683049,
        "f1": 0.633021,
        "accuracy": 0.683049,
        "main_score": 0.633021,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.559173,
        "recall": 0.662989,
        "f1": 0.587928,
        "accuracy": 0.662989,
        "main_score": 0.587928,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.029544,
        "recall": 0.037111,
        "f1": 0.030821,
        "accuracy": 0.037111,
        "main_score": 0.030821,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.043591,
        "recall": 0.094283,
        "f1": 0.051024,
        "accuracy": 0.094283,
        "main_score": 0.051024,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.069465,
        "recall": 0.082247,
        "f1": 0.071371,
        "accuracy": 0.082247,
        "main_score": 0.071371,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.109338,
        "recall": 0.175527,
        "f1": 0.122316,
        "accuracy": 0.175527,
        "main_score": 0.122316,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.295977,
        "recall": 0.352056,
        "f1": 0.307838,
        "accuracy": 0.352056,
        "main_score": 0.307838,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.314801,
        "recall": 0.432297,
        "f1": 0.344511,
        "accuracy": 0.432297,
        "main_score": 0.344511,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.054063,
        "recall": 0.065196,
        "f1": 0.055682,
        "accuracy": 0.065196,
        "main_score": 0.055682,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.070959,
        "recall": 0.137412,
        "f1": 0.083254,
        "accuracy": 0.137412,
        "main_score": 0.083254,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.084764,
        "recall": 0.092277,
        "f1": 0.086446,
        "accuracy": 0.092277,
        "main_score": 0.086446,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.053693,
        "recall": 0.136409,
        "f1": 0.06785,
        "accuracy": 0.136409,
        "main_score": 0.06785,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.447858,
        "recall": 0.51655,
        "f1": 0.464601,
        "accuracy": 0.51655,
        "main_score": 0.464601,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.445402,
        "recall": 0.565697,
        "f1": 0.477527,
        "accuracy": 0.565697,
        "main_score": 0.477527,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.098326,
        "recall": 0.130391,
        "f1": 0.10471,
        "accuracy": 0.130391,
        "main_score": 0.10471,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.149087,
        "recall": 0.235707,
        "f1": 0.168484,
        "accuracy": 0.235707,
        "main_score": 0.168484,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.402035,
        "recall": 0.460381,
        "f1": 0.414955,
        "accuracy": 0.460381,
        "main_score": 0.414955,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.400137,
        "recall": 0.520562,
        "f1": 0.43194,
        "accuracy": 0.520562,
        "main_score": 0.43194,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.334527,
        "recall": 0.390171,
        "f1": 0.346749,
        "accuracy": 0.390171,
        "main_score": 0.346749,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.349023,
        "recall": 0.471414,
        "f1": 0.380503,
        "accuracy": 0.471414,
        "main_score": 0.380503,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.039993,
        "recall": 0.05015,
        "f1": 0.042371,
        "accuracy": 0.05015,
        "main_score": 0.042371,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042362,
        "recall": 0.10331,
        "f1": 0.051635,
        "accuracy": 0.10331,
        "main_score": 0.051635,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.032397,
        "recall": 0.038114,
        "f1": 0.033263,
        "accuracy": 0.038114,
        "main_score": 0.033263,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042084,
        "recall": 0.102307,
        "f1": 0.051899,
        "accuracy": 0.102307,
        "main_score": 0.051899,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.278603,
        "recall": 0.320963,
        "f1": 0.288253,
        "accuracy": 0.320963,
        "main_score": 0.288253,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.249837,
        "recall": 0.372116,
        "f1": 0.28079,
        "accuracy": 0.372116,
        "main_score": 0.28079,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.19454,
        "recall": 0.228686,
        "f1": 0.201904,
        "accuracy": 0.228686,
        "main_score": 0.201904,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.230973,
        "recall": 0.342026,
        "f1": 0.257225,
        "accuracy": 0.342026,
        "main_score": 0.257225,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.474722,
        "recall": 0.547643,
        "f1": 0.491776,
        "accuracy": 0.547643,
        "main_score": 0.491776,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.460042,
        "recall": 0.577733,
        "f1": 0.492241,
        "accuracy": 0.577733,
        "main_score": 0.492241,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.427084,
        "recall": 0.49348,
        "f1": 0.442126,
        "accuracy": 0.49348,
        "main_score": 0.442126,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.434818,
        "recall": 0.548646,
        "f1": 0.465275,
        "accuracy": 0.548646,
        "main_score": 0.465275,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.030543,
        "recall": 0.037111,
        "f1": 0.031563,
        "accuracy": 0.037111,
        "main_score": 0.031563,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025995,
        "recall": 0.077232,
        "f1": 0.032208,
        "accuracy": 0.077232,
        "main_score": 0.032208,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.078372,
        "recall": 0.096289,
        "f1": 0.081781,
        "accuracy": 0.096289,
        "main_score": 0.081781,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.112275,
        "recall": 0.190572,
        "f1": 0.128202,
        "accuracy": 0.190572,
        "main_score": 0.128202,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.38821,
        "recall": 0.448345,
        "f1": 0.40141,
        "accuracy": 0.448345,
        "main_score": 0.40141,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.397718,
        "recall": 0.523571,
        "f1": 0.430875,
        "accuracy": 0.523571,
        "main_score": 0.430875,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.196288,
        "recall": 0.237713,
        "f1": 0.205145,
        "accuracy": 0.237713,
        "main_score": 0.205145,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.204924,
        "recall": 0.314945,
        "f1": 0.229764,
        "accuracy": 0.314945,
        "main_score": 0.229764,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.35362,
        "recall": 0.415246,
        "f1": 0.367158,
        "accuracy": 0.415246,
        "main_score": 0.367158,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.387819,
        "recall": 0.504514,
        "f1": 0.41731,
        "accuracy": 0.504514,
        "main_score": 0.41731,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.393079,
        "recall": 0.451354,
        "f1": 0.406232,
        "accuracy": 0.451354,
        "main_score": 0.406232,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.413557,
        "recall": 0.528586,
        "f1": 0.443683,
        "accuracy": 0.528586,
        "main_score": 0.443683,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.380854,
        "recall": 0.445336,
        "f1": 0.395744,
        "accuracy": 0.445336,
        "main_score": 0.395744,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.379865,
        "recall": 0.499498,
        "f1": 0.410254,
        "accuracy": 0.499498,
        "main_score": 0.410254,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.061074,
        "recall": 0.074223,
        "f1": 0.063404,
        "accuracy": 0.074223,
        "main_score": 0.063404,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.101878,
        "recall": 0.187563,
        "f1": 0.118322,
        "accuracy": 0.187563,
        "main_score": 0.118322,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.424216,
        "recall": 0.491474,
        "f1": 0.439239,
        "accuracy": 0.491474,
        "main_score": 0.439239,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.417018,
        "recall": 0.533601,
        "f1": 0.447036,
        "accuracy": 0.533601,
        "main_score": 0.447036,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.454484,
        "recall": 0.515547,
        "f1": 0.468221,
        "accuracy": 0.515547,
        "main_score": 0.468221,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.434563,
        "recall": 0.554664,
        "f1": 0.466963,
        "accuracy": 0.554664,
        "main_score": 0.466963,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.004019,
        "recall": 0.006018,
        "f1": 0.004025,
        "accuracy": 0.006018,
        "main_score": 0.004025,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002013,
        "recall": 0.015045,
        "f1": 0.002632,
        "accuracy": 0.015045,
        "main_score": 0.002632,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.249216,
        "recall": 0.288538,
        "f1": 0.257336,
        "accuracy": 0.288538,
        "main_score": 0.257336,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.311997,
        "recall": 0.422925,
        "f1": 0.339407,
        "accuracy": 0.422925,
        "main_score": 0.339407,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.029956,
        "recall": 0.035573,
        "f1": 0.030546,
        "accuracy": 0.035573,
        "main_score": 0.030546,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.052601,
        "recall": 0.102767,
        "f1": 0.061919,
        "accuracy": 0.102767,
        "main_score": 0.061919,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.578093,
        "recall": 0.634387,
        "f1": 0.59177,
        "accuracy": 0.634387,
        "main_score": 0.59177,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.536327,
        "recall": 0.640316,
        "f1": 0.56455,
        "accuracy": 0.640316,
        "main_score": 0.56455,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.035813,
        "recall": 0.041502,
        "f1": 0.036659,
        "accuracy": 0.041502,
        "main_score": 0.036659,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037153,
        "recall": 0.08498,
        "f1": 0.045373,
        "accuracy": 0.08498,
        "main_score": 0.045373,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.034307,
        "recall": 0.045455,
        "f1": 0.035851,
        "accuracy": 0.045455,
        "main_score": 0.035851,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.104008,
        "recall": 0.170949,
        "f1": 0.117653,
        "accuracy": 0.170949,
        "main_score": 0.117653,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.265738,
        "recall": 0.3083,
        "f1": 0.274816,
        "accuracy": 0.3083,
        "main_score": 0.274816,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.309311,
        "recall": 0.425889,
        "f1": 0.339072,
        "accuracy": 0.425889,
        "main_score": 0.339072,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.04426,
        "recall": 0.051383,
        "f1": 0.045272,
        "accuracy": 0.051383,
        "main_score": 0.045272,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.068672,
        "recall": 0.129447,
        "f1": 0.08089,
        "accuracy": 0.129447,
        "main_score": 0.08089,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.079575,
        "recall": 0.089921,
        "f1": 0.081661,
        "accuracy": 0.089921,
        "main_score": 0.081661,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.066268,
        "recall": 0.147233,
        "f1": 0.079647,
        "accuracy": 0.147233,
        "main_score": 0.079647,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.405496,
        "recall": 0.447628,
        "f1": 0.415428,
        "accuracy": 0.447628,
        "main_score": 0.415428,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.402937,
        "recall": 0.516798,
        "f1": 0.432608,
        "accuracy": 0.516798,
        "main_score": 0.432608,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.085424,
        "recall": 0.108696,
        "f1": 0.089418,
        "accuracy": 0.108696,
        "main_score": 0.089418,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.144861,
        "recall": 0.230237,
        "f1": 0.163888,
        "accuracy": 0.230237,
        "main_score": 0.163888,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.375855,
        "recall": 0.428854,
        "f1": 0.387729,
        "accuracy": 0.428854,
        "main_score": 0.387729,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.376797,
        "recall": 0.488142,
        "f1": 0.404477,
        "accuracy": 0.488142,
        "main_score": 0.404477,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.316442,
        "recall": 0.357708,
        "f1": 0.325772,
        "accuracy": 0.357708,
        "main_score": 0.325772,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.306009,
        "recall": 0.422925,
        "f1": 0.334568,
        "accuracy": 0.422925,
        "main_score": 0.334568,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.041462,
        "recall": 0.049407,
        "f1": 0.043008,
        "accuracy": 0.049407,
        "main_score": 0.043008,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.044788,
        "recall": 0.105731,
        "f1": 0.054566,
        "accuracy": 0.105731,
        "main_score": 0.054566,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03733,
        "recall": 0.043478,
        "f1": 0.038454,
        "accuracy": 0.043478,
        "main_score": 0.038454,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.047263,
        "recall": 0.099802,
        "f1": 0.056821,
        "accuracy": 0.099802,
        "main_score": 0.056821,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.224867,
        "recall": 0.248024,
        "f1": 0.230508,
        "accuracy": 0.248024,
        "main_score": 0.230508,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.218177,
        "recall": 0.322134,
        "f1": 0.243691,
        "accuracy": 0.322134,
        "main_score": 0.243691,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.172853,
        "recall": 0.208498,
        "f1": 0.180257,
        "accuracy": 0.208498,
        "main_score": 0.180257,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.197766,
        "recall": 0.306324,
        "f1": 0.222028,
        "accuracy": 0.306324,
        "main_score": 0.222028,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.431688,
        "recall": 0.480237,
        "f1": 0.442847,
        "accuracy": 0.480237,
        "main_score": 0.442847,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.443055,
        "recall": 0.548419,
        "f1": 0.469887,
        "accuracy": 0.548419,
        "main_score": 0.469887,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.404181,
        "recall": 0.452569,
        "f1": 0.415862,
        "accuracy": 0.452569,
        "main_score": 0.415862,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.411159,
        "recall": 0.528656,
        "f1": 0.441741,
        "accuracy": 0.528656,
        "main_score": 0.441741,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.029487,
        "recall": 0.033597,
        "f1": 0.030153,
        "accuracy": 0.033597,
        "main_score": 0.030153,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027055,
        "recall": 0.075099,
        "f1": 0.033685,
        "accuracy": 0.075099,
        "main_score": 0.033685,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.083982,
        "recall": 0.098814,
        "f1": 0.087459,
        "accuracy": 0.098814,
        "main_score": 0.087459,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.112766,
        "recall": 0.194664,
        "f1": 0.130276,
        "accuracy": 0.194664,
        "main_score": 0.130276,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.365365,
        "recall": 0.408103,
        "f1": 0.374845,
        "accuracy": 0.408103,
        "main_score": 0.374845,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.362476,
        "recall": 0.483202,
        "f1": 0.393872,
        "accuracy": 0.483202,
        "main_score": 0.393872,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.211377,
        "recall": 0.241107,
        "f1": 0.217755,
        "accuracy": 0.241107,
        "main_score": 0.217755,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.235851,
        "recall": 0.346838,
        "f1": 0.262675,
        "accuracy": 0.346838,
        "main_score": 0.262675,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.327143,
        "recall": 0.365613,
        "f1": 0.335252,
        "accuracy": 0.365613,
        "main_score": 0.335252,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.34843,
        "recall": 0.462451,
        "f1": 0.37707,
        "accuracy": 0.462451,
        "main_score": 0.37707,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.378477,
        "recall": 0.422925,
        "f1": 0.388753,
        "accuracy": 0.422925,
        "main_score": 0.388753,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.371076,
        "recall": 0.480237,
        "f1": 0.398741,
        "accuracy": 0.480237,
        "main_score": 0.398741,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.347038,
        "recall": 0.391304,
        "f1": 0.357958,
        "accuracy": 0.391304,
        "main_score": 0.357958,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.360863,
        "recall": 0.478261,
        "f1": 0.391713,
        "accuracy": 0.478261,
        "main_score": 0.391713,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.071287,
        "recall": 0.083004,
        "f1": 0.074654,
        "accuracy": 0.083004,
        "main_score": 0.074654,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.099037,
        "recall": 0.18083,
        "f1": 0.115929,
        "accuracy": 0.18083,
        "main_score": 0.115929,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.364114,
        "recall": 0.411067,
        "f1": 0.374983,
        "accuracy": 0.411067,
        "main_score": 0.374983,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.351422,
        "recall": 0.476285,
        "f1": 0.383057,
        "accuracy": 0.476285,
        "main_score": 0.383057,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.392533,
        "recall": 0.438735,
        "f1": 0.402941,
        "accuracy": 0.438735,
        "main_score": 0.402941,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.387317,
        "recall": 0.505929,
        "f1": 0.417968,
        "accuracy": 0.505929,
        "main_score": 0.417968,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.006944,
        "recall": 0.009881,
        "f1": 0.007299,
        "accuracy": 0.009881,
        "main_score": 0.007299,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004034,
        "recall": 0.024704,
        "f1": 0.005779,
        "accuracy": 0.024704,
        "main_score": 0.005779,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 7487.710063695908,
  "kg_co2_emissions": null
}