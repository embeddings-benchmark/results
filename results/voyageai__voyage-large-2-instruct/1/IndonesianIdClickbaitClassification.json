{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.581104,
        "f1": 0.574156,
        "f1_weighted": 0.580318,
        "ap": 0.469294,
        "ap_weighted": 0.469294,
        "scores_per_experiment": [
          {
            "accuracy": 0.650391,
            "f1": 0.621258,
            "f1_weighted": 0.638184,
            "ap": 0.506463,
            "ap_weighted": 0.506463
          },
          {
            "accuracy": 0.557617,
            "f1": 0.553358,
            "f1_weighted": 0.560386,
            "ap": 0.45058,
            "ap_weighted": 0.45058
          },
          {
            "accuracy": 0.541992,
            "f1": 0.534133,
            "f1_weighted": 0.543883,
            "ap": 0.437989,
            "ap_weighted": 0.437989
          },
          {
            "accuracy": 0.58252,
            "f1": 0.5823,
            "f1_weighted": 0.583844,
            "ap": 0.474344,
            "ap_weighted": 0.474344
          },
          {
            "accuracy": 0.612793,
            "f1": 0.612426,
            "f1_weighted": 0.614347,
            "ap": 0.495667,
            "ap_weighted": 0.495667
          },
          {
            "accuracy": 0.556641,
            "f1": 0.542178,
            "f1_weighted": 0.55529,
            "ap": 0.442411,
            "ap_weighted": 0.442411
          },
          {
            "accuracy": 0.655273,
            "f1": 0.643642,
            "f1_weighted": 0.654016,
            "ap": 0.517863,
            "ap_weighted": 0.517863
          },
          {
            "accuracy": 0.577637,
            "f1": 0.577632,
            "f1_weighted": 0.577399,
            "ap": 0.473502,
            "ap_weighted": 0.473502
          },
          {
            "accuracy": 0.558594,
            "f1": 0.557496,
            "f1_weighted": 0.561047,
            "ap": 0.455744,
            "ap_weighted": 0.455744
          },
          {
            "accuracy": 0.517578,
            "f1": 0.517136,
            "f1_weighted": 0.51478,
            "ap": 0.438378,
            "ap_weighted": 0.438378
          }
        ],
        "main_score": 0.574156,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 439.670423746109,
  "kg_co2_emissions": null
}