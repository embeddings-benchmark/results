{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.65045,
        "f1": 0.624378,
        "f1_weighted": 0.658909,
        "scores_per_experiment": [
          {
            "accuracy": 0.667,
            "f1": 0.632784,
            "f1_weighted": 0.674719
          },
          {
            "accuracy": 0.6515,
            "f1": 0.623138,
            "f1_weighted": 0.65905
          },
          {
            "accuracy": 0.665,
            "f1": 0.633671,
            "f1_weighted": 0.67282
          },
          {
            "accuracy": 0.6695,
            "f1": 0.62532,
            "f1_weighted": 0.679186
          },
          {
            "accuracy": 0.625,
            "f1": 0.603003,
            "f1_weighted": 0.634511
          },
          {
            "accuracy": 0.6525,
            "f1": 0.623322,
            "f1_weighted": 0.658934
          },
          {
            "accuracy": 0.6475,
            "f1": 0.629417,
            "f1_weighted": 0.656526
          },
          {
            "accuracy": 0.622,
            "f1": 0.612249,
            "f1_weighted": 0.631434
          },
          {
            "accuracy": 0.6585,
            "f1": 0.636262,
            "f1_weighted": 0.666602
          },
          {
            "accuracy": 0.646,
            "f1": 0.624612,
            "f1_weighted": 0.655305
          }
        ],
        "main_score": 0.65045,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.64465,
        "f1": 0.6061,
        "f1_weighted": 0.657974,
        "scores_per_experiment": [
          {
            "accuracy": 0.6535,
            "f1": 0.609725,
            "f1_weighted": 0.666968
          },
          {
            "accuracy": 0.6245,
            "f1": 0.583303,
            "f1_weighted": 0.636824
          },
          {
            "accuracy": 0.6495,
            "f1": 0.602802,
            "f1_weighted": 0.663418
          },
          {
            "accuracy": 0.6575,
            "f1": 0.609096,
            "f1_weighted": 0.670566
          },
          {
            "accuracy": 0.627,
            "f1": 0.593266,
            "f1_weighted": 0.641577
          },
          {
            "accuracy": 0.6495,
            "f1": 0.607135,
            "f1_weighted": 0.660687
          },
          {
            "accuracy": 0.6405,
            "f1": 0.606348,
            "f1_weighted": 0.654672
          },
          {
            "accuracy": 0.6265,
            "f1": 0.600052,
            "f1_weighted": 0.642337
          },
          {
            "accuracy": 0.6625,
            "f1": 0.625684,
            "f1_weighted": 0.674844
          },
          {
            "accuracy": 0.6555,
            "f1": 0.623588,
            "f1_weighted": 0.667845
          }
        ],
        "main_score": 0.64465,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 443.54068303108215,
  "kg_co2_emissions": null
}