{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.944141,
        "f1": 0.944002,
        "f1_weighted": 0.944009,
        "ap": 0.905846,
        "ap_weighted": 0.905846,
        "scores_per_experiment": [
          {
            "accuracy": 0.947754,
            "f1": 0.947668,
            "f1_weighted": 0.947674,
            "ap": 0.910602,
            "ap_weighted": 0.910602
          },
          {
            "accuracy": 0.947754,
            "f1": 0.947704,
            "f1_weighted": 0.947709,
            "ap": 0.91406,
            "ap_weighted": 0.91406
          },
          {
            "accuracy": 0.960449,
            "f1": 0.960435,
            "f1_weighted": 0.960437,
            "ap": 0.935833,
            "ap_weighted": 0.935833
          },
          {
            "accuracy": 0.947266,
            "f1": 0.947246,
            "f1_weighted": 0.947249,
            "ap": 0.917532,
            "ap_weighted": 0.917532
          },
          {
            "accuracy": 0.952637,
            "f1": 0.952583,
            "f1_weighted": 0.952588,
            "ap": 0.919568,
            "ap_weighted": 0.919568
          },
          {
            "accuracy": 0.954102,
            "f1": 0.954045,
            "f1_weighted": 0.954049,
            "ap": 0.921009,
            "ap_weighted": 0.921009
          },
          {
            "accuracy": 0.931152,
            "f1": 0.930911,
            "f1_weighted": 0.930923,
            "ap": 0.883024,
            "ap_weighted": 0.883024
          },
          {
            "accuracy": 0.94873,
            "f1": 0.948629,
            "f1_weighted": 0.948636,
            "ap": 0.910546,
            "ap_weighted": 0.910546
          },
          {
            "accuracy": 0.932617,
            "f1": 0.932361,
            "f1_weighted": 0.932373,
            "ap": 0.884149,
            "ap_weighted": 0.884149
          },
          {
            "accuracy": 0.918945,
            "f1": 0.918435,
            "f1_weighted": 0.918454,
            "ap": 0.862141,
            "ap_weighted": 0.862141
          }
        ],
        "main_score": 0.944141,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.941846,
        "f1": 0.941684,
        "f1_weighted": 0.941689,
        "ap": 0.903444,
        "ap_weighted": 0.903444,
        "scores_per_experiment": [
          {
            "accuracy": 0.951172,
            "f1": 0.951108,
            "f1_weighted": 0.951111,
            "ap": 0.916283,
            "ap_weighted": 0.916283
          },
          {
            "accuracy": 0.947754,
            "f1": 0.947711,
            "f1_weighted": 0.947713,
            "ap": 0.914322,
            "ap_weighted": 0.914322
          },
          {
            "accuracy": 0.968262,
            "f1": 0.968254,
            "f1_weighted": 0.968255,
            "ap": 0.947883,
            "ap_weighted": 0.947883
          },
          {
            "accuracy": 0.939941,
            "f1": 0.939936,
            "f1_weighted": 0.939937,
            "ap": 0.910942,
            "ap_weighted": 0.910942
          },
          {
            "accuracy": 0.949219,
            "f1": 0.949156,
            "f1_weighted": 0.949159,
            "ap": 0.914014,
            "ap_weighted": 0.914014
          },
          {
            "accuracy": 0.955078,
            "f1": 0.955053,
            "f1_weighted": 0.955055,
            "ap": 0.926262,
            "ap_weighted": 0.926262
          },
          {
            "accuracy": 0.927246,
            "f1": 0.926956,
            "f1_weighted": 0.926965,
            "ap": 0.876529,
            "ap_weighted": 0.876529
          },
          {
            "accuracy": 0.947754,
            "f1": 0.947659,
            "f1_weighted": 0.947664,
            "ap": 0.909503,
            "ap_weighted": 0.909503
          },
          {
            "accuracy": 0.924316,
            "f1": 0.924015,
            "f1_weighted": 0.924024,
            "ap": 0.872849,
            "ap_weighted": 0.872849
          },
          {
            "accuracy": 0.907715,
            "f1": 0.906988,
            "f1_weighted": 0.907004,
            "ap": 0.845852,
            "ap_weighted": 0.845852
          }
        ],
        "main_score": 0.941846,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 124.74550032615662,
  "kg_co2_emissions": null
}