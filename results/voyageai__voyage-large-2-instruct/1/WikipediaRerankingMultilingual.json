{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.867401,
        "mrr": 0.867401,
        "nAUC_map_max": 0.458762,
        "nAUC_map_std": 0.298096,
        "nAUC_map_diff1": 0.779151,
        "nAUC_mrr_max": 0.458762,
        "nAUC_mrr_std": 0.298096,
        "nAUC_mrr_diff1": 0.779151,
        "main_score": 0.867401,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.690976,
        "mrr": 0.690976,
        "nAUC_map_max": 0.343261,
        "nAUC_map_std": 0.15547,
        "nAUC_map_diff1": 0.557377,
        "nAUC_mrr_max": 0.343261,
        "nAUC_mrr_std": 0.15547,
        "nAUC_mrr_diff1": 0.557377,
        "main_score": 0.690976,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.868273,
        "mrr": 0.868273,
        "nAUC_map_max": 0.429585,
        "nAUC_map_std": 0.274609,
        "nAUC_map_diff1": 0.761703,
        "nAUC_mrr_max": 0.429585,
        "nAUC_mrr_std": 0.274609,
        "nAUC_mrr_diff1": 0.761703,
        "main_score": 0.868273,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.875845,
        "mrr": 0.876289,
        "nAUC_map_max": 0.465503,
        "nAUC_map_std": 0.313607,
        "nAUC_map_diff1": 0.774059,
        "nAUC_mrr_max": 0.467682,
        "nAUC_mrr_std": 0.311349,
        "nAUC_mrr_diff1": 0.772821,
        "main_score": 0.875845,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.871127,
        "mrr": 0.871127,
        "nAUC_map_max": 0.438248,
        "nAUC_map_std": 0.267288,
        "nAUC_map_diff1": 0.782723,
        "nAUC_mrr_max": 0.438248,
        "nAUC_mrr_std": 0.267288,
        "nAUC_mrr_diff1": 0.782723,
        "main_score": 0.871127,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.910512,
        "mrr": 0.910512,
        "nAUC_map_max": 0.417578,
        "nAUC_map_std": 0.343342,
        "nAUC_map_diff1": 0.837566,
        "nAUC_mrr_max": 0.417578,
        "nAUC_mrr_std": 0.343342,
        "nAUC_mrr_diff1": 0.837566,
        "main_score": 0.910512,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.813023,
        "mrr": 0.813023,
        "nAUC_map_max": 0.390488,
        "nAUC_map_std": 0.293366,
        "nAUC_map_diff1": 0.688466,
        "nAUC_mrr_max": 0.390488,
        "nAUC_mrr_std": 0.293366,
        "nAUC_mrr_diff1": 0.688466,
        "main_score": 0.813023,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.843691,
        "mrr": 0.843691,
        "nAUC_map_max": 0.368163,
        "nAUC_map_std": 0.270618,
        "nAUC_map_diff1": 0.742087,
        "nAUC_mrr_max": 0.368163,
        "nAUC_mrr_std": 0.270618,
        "nAUC_mrr_diff1": 0.742087,
        "main_score": 0.843691,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.770595,
        "mrr": 0.771327,
        "nAUC_map_max": 0.299732,
        "nAUC_map_std": 0.19234,
        "nAUC_map_diff1": 0.577063,
        "nAUC_mrr_max": 0.300845,
        "nAUC_mrr_std": 0.196426,
        "nAUC_mrr_diff1": 0.57512,
        "main_score": 0.770595,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.869035,
        "mrr": 0.869035,
        "nAUC_map_max": 0.462679,
        "nAUC_map_std": 0.283872,
        "nAUC_map_diff1": 0.77248,
        "nAUC_mrr_max": 0.462679,
        "nAUC_mrr_std": 0.283872,
        "nAUC_mrr_diff1": 0.77248,
        "main_score": 0.869035,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.876516,
        "mrr": 0.876849,
        "nAUC_map_max": 0.391282,
        "nAUC_map_std": 0.263119,
        "nAUC_map_diff1": 0.731669,
        "nAUC_mrr_max": 0.393856,
        "nAUC_mrr_std": 0.268725,
        "nAUC_mrr_diff1": 0.730632,
        "main_score": 0.876516,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.861205,
        "mrr": 0.861205,
        "nAUC_map_max": 0.441833,
        "nAUC_map_std": 0.276585,
        "nAUC_map_diff1": 0.777137,
        "nAUC_mrr_max": 0.441833,
        "nAUC_mrr_std": 0.276585,
        "nAUC_mrr_diff1": 0.777137,
        "main_score": 0.861205,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.862871,
        "mrr": 0.863205,
        "nAUC_map_max": 0.391279,
        "nAUC_map_std": 0.34074,
        "nAUC_map_diff1": 0.800404,
        "nAUC_mrr_max": 0.391695,
        "nAUC_mrr_std": 0.341061,
        "nAUC_mrr_diff1": 0.799307,
        "main_score": 0.862871,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.872354,
        "mrr": 0.872688,
        "nAUC_map_max": 0.365734,
        "nAUC_map_std": 0.293242,
        "nAUC_map_diff1": 0.788763,
        "nAUC_mrr_max": 0.369794,
        "nAUC_mrr_std": 0.298753,
        "nAUC_mrr_diff1": 0.787895,
        "main_score": 0.872354,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.84769,
        "mrr": 0.84769,
        "nAUC_map_max": 0.418929,
        "nAUC_map_std": 0.173739,
        "nAUC_map_diff1": 0.74905,
        "nAUC_mrr_max": 0.418929,
        "nAUC_mrr_std": 0.173739,
        "nAUC_mrr_diff1": 0.74905,
        "main_score": 0.84769,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.87993,
        "mrr": 0.87993,
        "nAUC_map_max": 0.345737,
        "nAUC_map_std": 0.272317,
        "nAUC_map_diff1": 0.794201,
        "nAUC_mrr_max": 0.345737,
        "nAUC_mrr_std": 0.272317,
        "nAUC_mrr_diff1": 0.794201,
        "main_score": 0.87993,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 4088.8618426322937,
  "kg_co2_emissions": null
}