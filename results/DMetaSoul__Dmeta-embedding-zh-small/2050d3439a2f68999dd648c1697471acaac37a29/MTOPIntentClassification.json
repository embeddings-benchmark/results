{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "task_name": "MTOPIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.387934,
        "f1": 0.244788,
        "f1_weighted": 0.4326,
        "scores_per_experiment": [
          {
            "accuracy": 0.386777,
            "f1": 0.256181,
            "f1_weighted": 0.432356
          },
          {
            "accuracy": 0.386226,
            "f1": 0.258305,
            "f1_weighted": 0.426946
          },
          {
            "accuracy": 0.399449,
            "f1": 0.242769,
            "f1_weighted": 0.448783
          },
          {
            "accuracy": 0.341047,
            "f1": 0.22414,
            "f1_weighted": 0.370827
          },
          {
            "accuracy": 0.380165,
            "f1": 0.244062,
            "f1_weighted": 0.423195
          },
          {
            "accuracy": 0.351515,
            "f1": 0.218581,
            "f1_weighted": 0.394848
          },
          {
            "accuracy": 0.398898,
            "f1": 0.24722,
            "f1_weighted": 0.443823
          },
          {
            "accuracy": 0.415978,
            "f1": 0.259379,
            "f1_weighted": 0.467116
          },
          {
            "accuracy": 0.414325,
            "f1": 0.252706,
            "f1_weighted": 0.463261
          },
          {
            "accuracy": 0.404959,
            "f1": 0.244534,
            "f1_weighted": 0.454843
          }
        ],
        "main_score": 0.387934,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.393463,
        "f1": 0.240413,
        "f1_weighted": 0.43853,
        "scores_per_experiment": [
          {
            "accuracy": 0.388278,
            "f1": 0.235628,
            "f1_weighted": 0.427989
          },
          {
            "accuracy": 0.389405,
            "f1": 0.242653,
            "f1_weighted": 0.429859
          },
          {
            "accuracy": 0.39645,
            "f1": 0.227221,
            "f1_weighted": 0.449676
          },
          {
            "accuracy": 0.35672,
            "f1": 0.231341,
            "f1_weighted": 0.397702
          },
          {
            "accuracy": 0.384897,
            "f1": 0.242467,
            "f1_weighted": 0.430853
          },
          {
            "accuracy": 0.354184,
            "f1": 0.224073,
            "f1_weighted": 0.392052
          },
          {
            "accuracy": 0.426036,
            "f1": 0.253239,
            "f1_weighted": 0.474861
          },
          {
            "accuracy": 0.409693,
            "f1": 0.254175,
            "f1_weighted": 0.460117
          },
          {
            "accuracy": 0.418146,
            "f1": 0.252305,
            "f1_weighted": 0.463663
          },
          {
            "accuracy": 0.41082,
            "f1": 0.241026,
            "f1_weighted": 0.458527
          }
        ],
        "main_score": 0.393463,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 22.96266508102417,
  "kg_co2_emissions": null
}