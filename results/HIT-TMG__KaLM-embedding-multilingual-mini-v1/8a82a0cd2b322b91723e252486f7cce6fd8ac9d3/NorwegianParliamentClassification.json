{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.560417,
        "f1": 0.559439,
        "f1_weighted": 0.559439,
        "ap": 0.534615,
        "ap_weighted": 0.534615,
        "scores_per_experiment": [
          {
            "accuracy": 0.545,
            "f1": 0.543263,
            "f1_weighted": 0.543263,
            "ap": 0.52481,
            "ap_weighted": 0.52481
          },
          {
            "accuracy": 0.519167,
            "f1": 0.518605,
            "f1_weighted": 0.518605,
            "ap": 0.509927,
            "ap_weighted": 0.509927
          },
          {
            "accuracy": 0.594167,
            "f1": 0.592575,
            "f1_weighted": 0.592575,
            "ap": 0.554965,
            "ap_weighted": 0.554965
          },
          {
            "accuracy": 0.56,
            "f1": 0.558665,
            "f1_weighted": 0.558665,
            "ap": 0.533243,
            "ap_weighted": 0.533243
          },
          {
            "accuracy": 0.589167,
            "f1": 0.588302,
            "f1_weighted": 0.588302,
            "ap": 0.553336,
            "ap_weighted": 0.553336
          },
          {
            "accuracy": 0.541667,
            "f1": 0.541655,
            "f1_weighted": 0.541655,
            "ap": 0.522552,
            "ap_weighted": 0.522552
          },
          {
            "accuracy": 0.535833,
            "f1": 0.535794,
            "f1_weighted": 0.535794,
            "ap": 0.519178,
            "ap_weighted": 0.519178
          },
          {
            "accuracy": 0.55,
            "f1": 0.548635,
            "f1_weighted": 0.548635,
            "ap": 0.527252,
            "ap_weighted": 0.527252
          },
          {
            "accuracy": 0.6075,
            "f1": 0.606483,
            "f1_weighted": 0.606483,
            "ap": 0.566614,
            "ap_weighted": 0.566614
          },
          {
            "accuracy": 0.561667,
            "f1": 0.560416,
            "f1_weighted": 0.560416,
            "ap": 0.53427,
            "ap_weighted": 0.53427
          }
        ],
        "main_score": 0.560417,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.564167,
        "f1": 0.563194,
        "f1_weighted": 0.563194,
        "ap": 0.538286,
        "ap_weighted": 0.538286,
        "scores_per_experiment": [
          {
            "accuracy": 0.56,
            "f1": 0.558228,
            "f1_weighted": 0.558228,
            "ap": 0.534122,
            "ap_weighted": 0.534122
          },
          {
            "accuracy": 0.5175,
            "f1": 0.516484,
            "f1_weighted": 0.516484,
            "ap": 0.509031,
            "ap_weighted": 0.509031
          },
          {
            "accuracy": 0.620833,
            "f1": 0.620757,
            "f1_weighted": 0.620757,
            "ap": 0.574615,
            "ap_weighted": 0.574615
          },
          {
            "accuracy": 0.585833,
            "f1": 0.584538,
            "f1_weighted": 0.584538,
            "ap": 0.549544,
            "ap_weighted": 0.549544
          },
          {
            "accuracy": 0.61,
            "f1": 0.607381,
            "f1_weighted": 0.607381,
            "ap": 0.569462,
            "ap_weighted": 0.569462
          },
          {
            "accuracy": 0.508333,
            "f1": 0.508333,
            "f1_weighted": 0.508333,
            "ap": 0.504236,
            "ap_weighted": 0.504236
          },
          {
            "accuracy": 0.545,
            "f1": 0.544954,
            "f1_weighted": 0.544954,
            "ap": 0.524566,
            "ap_weighted": 0.524566
          },
          {
            "accuracy": 0.511667,
            "f1": 0.511471,
            "f1_weighted": 0.511471,
            "ap": 0.505964,
            "ap_weighted": 0.505964
          },
          {
            "accuracy": 0.625833,
            "f1": 0.625208,
            "f1_weighted": 0.625208,
            "ap": 0.580159,
            "ap_weighted": 0.580159
          },
          {
            "accuracy": 0.556667,
            "f1": 0.554587,
            "f1_weighted": 0.554587,
            "ap": 0.531158,
            "ap_weighted": 0.531158
          }
        ],
        "main_score": 0.564167,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 36.05793046951294,
  "kg_co2_emissions": 0.00222057316141261
}