{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.337354,
        "f1": 0.287086,
        "f1_weighted": 0.328479,
        "scores_per_experiment": [
          {
            "accuracy": 0.342773,
            "f1": 0.292115,
            "f1_weighted": 0.336618
          },
          {
            "accuracy": 0.331543,
            "f1": 0.27582,
            "f1_weighted": 0.32132
          },
          {
            "accuracy": 0.338379,
            "f1": 0.286733,
            "f1_weighted": 0.326774
          },
          {
            "accuracy": 0.329102,
            "f1": 0.280016,
            "f1_weighted": 0.317731
          },
          {
            "accuracy": 0.324219,
            "f1": 0.27956,
            "f1_weighted": 0.319983
          },
          {
            "accuracy": 0.339844,
            "f1": 0.284153,
            "f1_weighted": 0.329726
          },
          {
            "accuracy": 0.34668,
            "f1": 0.295885,
            "f1_weighted": 0.343278
          },
          {
            "accuracy": 0.338379,
            "f1": 0.294167,
            "f1_weighted": 0.32313
          },
          {
            "accuracy": 0.336426,
            "f1": 0.284943,
            "f1_weighted": 0.32882
          },
          {
            "accuracy": 0.346191,
            "f1": 0.297466,
            "f1_weighted": 0.337406
          }
        ],
        "main_score": 0.337354,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.320557,
        "f1": 0.29312,
        "f1_weighted": 0.312431,
        "scores_per_experiment": [
          {
            "accuracy": 0.332031,
            "f1": 0.28668,
            "f1_weighted": 0.326354
          },
          {
            "accuracy": 0.321777,
            "f1": 0.300772,
            "f1_weighted": 0.310213
          },
          {
            "accuracy": 0.330078,
            "f1": 0.305741,
            "f1_weighted": 0.32399
          },
          {
            "accuracy": 0.317383,
            "f1": 0.287198,
            "f1_weighted": 0.306353
          },
          {
            "accuracy": 0.297852,
            "f1": 0.27436,
            "f1_weighted": 0.289157
          },
          {
            "accuracy": 0.316895,
            "f1": 0.304465,
            "f1_weighted": 0.305862
          },
          {
            "accuracy": 0.321289,
            "f1": 0.281584,
            "f1_weighted": 0.314317
          },
          {
            "accuracy": 0.324219,
            "f1": 0.294797,
            "f1_weighted": 0.319632
          },
          {
            "accuracy": 0.323242,
            "f1": 0.302864,
            "f1_weighted": 0.318881
          },
          {
            "accuracy": 0.320801,
            "f1": 0.292734,
            "f1_weighted": 0.309554
          }
        ],
        "main_score": 0.320557,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 682.2324562072754,
  "kg_co2_emissions": 0.047594951078209845
}