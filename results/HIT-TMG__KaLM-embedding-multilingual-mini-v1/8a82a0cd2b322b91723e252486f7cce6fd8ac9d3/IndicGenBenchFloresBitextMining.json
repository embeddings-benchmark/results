{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.980441,
        "recall": 0.986961,
        "f1": 0.982615,
        "accuracy": 0.986961,
        "main_score": 0.982615,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.974758,
        "recall": 0.982949,
        "f1": 0.977432,
        "accuracy": 0.982949,
        "main_score": 0.977432,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.709594,
        "recall": 0.776329,
        "f1": 0.727888,
        "accuracy": 0.776329,
        "main_score": 0.727888,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.756814,
        "recall": 0.818455,
        "f1": 0.774962,
        "accuracy": 0.818455,
        "main_score": 0.774962,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.984955,
        "recall": 0.98997,
        "f1": 0.986627,
        "accuracy": 0.98997,
        "main_score": 0.986627,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.993982,
        "recall": 0.995988,
        "f1": 0.994651,
        "accuracy": 0.995988,
        "main_score": 0.994651,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.711293,
        "recall": 0.775326,
        "f1": 0.728403,
        "accuracy": 0.775326,
        "main_score": 0.728403,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.753212,
        "recall": 0.817452,
        "f1": 0.772838,
        "accuracy": 0.817452,
        "main_score": 0.772838,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.714172,
        "recall": 0.775326,
        "f1": 0.731034,
        "accuracy": 0.775326,
        "main_score": 0.731034,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.776105,
        "recall": 0.831494,
        "f1": 0.79268,
        "accuracy": 0.831494,
        "main_score": 0.79268,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.93564,
        "recall": 0.956871,
        "f1": 0.942661,
        "accuracy": 0.956871,
        "main_score": 0.942661,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.949097,
        "recall": 0.964895,
        "f1": 0.954096,
        "accuracy": 0.964895,
        "main_score": 0.954096,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.708181,
        "recall": 0.774323,
        "f1": 0.726409,
        "accuracy": 0.774323,
        "main_score": 0.726409,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.767335,
        "recall": 0.825476,
        "f1": 0.784444,
        "accuracy": 0.825476,
        "main_score": 0.784444,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.955533,
        "recall": 0.96991,
        "f1": 0.960214,
        "accuracy": 0.96991,
        "main_score": 0.960214,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.960715,
        "recall": 0.972919,
        "f1": 0.964728,
        "accuracy": 0.972919,
        "main_score": 0.964728,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.927951,
        "recall": 0.948847,
        "f1": 0.934269,
        "accuracy": 0.948847,
        "main_score": 0.934269,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.943163,
        "recall": 0.961886,
        "f1": 0.949348,
        "accuracy": 0.961886,
        "main_score": 0.949348,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.860498,
        "recall": 0.901705,
        "f1": 0.873487,
        "accuracy": 0.901705,
        "main_score": 0.873487,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.87653,
        "recall": 0.911735,
        "f1": 0.887496,
        "accuracy": 0.911735,
        "main_score": 0.887496,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.974423,
        "recall": 0.982949,
        "f1": 0.977265,
        "accuracy": 0.982949,
        "main_score": 0.977265,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.979271,
        "recall": 0.985958,
        "f1": 0.981444,
        "accuracy": 0.985958,
        "main_score": 0.981444,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.933801,
        "recall": 0.953862,
        "f1": 0.940154,
        "accuracy": 0.953862,
        "main_score": 0.940154,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.939318,
        "recall": 0.957874,
        "f1": 0.945336,
        "accuracy": 0.957874,
        "main_score": 0.945336,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.563463,
        "recall": 0.633902,
        "f1": 0.580244,
        "accuracy": 0.633902,
        "main_score": 0.580244,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.607189,
        "recall": 0.686058,
        "f1": 0.629391,
        "accuracy": 0.686058,
        "main_score": 0.629391,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.647364,
        "recall": 0.724173,
        "f1": 0.668168,
        "accuracy": 0.724173,
        "main_score": 0.668168,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.682648,
        "recall": 0.756269,
        "f1": 0.703468,
        "accuracy": 0.756269,
        "main_score": 0.703468,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.713978,
        "recall": 0.775326,
        "f1": 0.731053,
        "accuracy": 0.775326,
        "main_score": 0.731053,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.703828,
        "recall": 0.779338,
        "f1": 0.7262,
        "accuracy": 0.779338,
        "main_score": 0.7262,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.798629,
        "recall": 0.848546,
        "f1": 0.812934,
        "accuracy": 0.848546,
        "main_score": 0.812934,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.827516,
        "recall": 0.875627,
        "f1": 0.842126,
        "accuracy": 0.875627,
        "main_score": 0.842126,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.97877,
        "recall": 0.984955,
        "f1": 0.980776,
        "accuracy": 0.984955,
        "main_score": 0.980776,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980441,
        "recall": 0.985958,
        "f1": 0.98228,
        "accuracy": 0.985958,
        "main_score": 0.98228,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.975176,
        "recall": 0.982949,
        "f1": 0.977666,
        "accuracy": 0.982949,
        "main_score": 0.977666,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.984955,
        "recall": 0.98997,
        "f1": 0.986627,
        "accuracy": 0.98997,
        "main_score": 0.986627,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.050404,
        "recall": 0.065196,
        "f1": 0.053558,
        "accuracy": 0.065196,
        "main_score": 0.053558,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060887,
        "recall": 0.111334,
        "f1": 0.069651,
        "accuracy": 0.111334,
        "main_score": 0.069651,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.364426,
        "recall": 0.425276,
        "f1": 0.378936,
        "accuracy": 0.425276,
        "main_score": 0.378936,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.391041,
        "recall": 0.474423,
        "f1": 0.413155,
        "accuracy": 0.474423,
        "main_score": 0.413155,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.971749,
        "recall": 0.980943,
        "f1": 0.974758,
        "accuracy": 0.980943,
        "main_score": 0.974758,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.984955,
        "recall": 0.98997,
        "f1": 0.986627,
        "accuracy": 0.98997,
        "main_score": 0.986627,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.809939,
        "recall": 0.860582,
        "f1": 0.825326,
        "accuracy": 0.860582,
        "main_score": 0.825326,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.830608,
        "recall": 0.874624,
        "f1": 0.8446,
        "accuracy": 0.874624,
        "main_score": 0.8446,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.972584,
        "recall": 0.980943,
        "f1": 0.975259,
        "accuracy": 0.980943,
        "main_score": 0.975259,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976764,
        "recall": 0.983952,
        "f1": 0.979104,
        "accuracy": 0.983952,
        "main_score": 0.979104,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.969074,
        "recall": 0.978937,
        "f1": 0.97225,
        "accuracy": 0.978937,
        "main_score": 0.97225,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.965731,
        "recall": 0.976931,
        "f1": 0.969408,
        "accuracy": 0.976931,
        "main_score": 0.969408,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.979271,
        "recall": 0.985958,
        "f1": 0.981444,
        "accuracy": 0.985958,
        "main_score": 0.981444,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986459,
        "recall": 0.990973,
        "f1": 0.987964,
        "accuracy": 0.990973,
        "main_score": 0.987964,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.346465,
        "recall": 0.406219,
        "f1": 0.360591,
        "accuracy": 0.406219,
        "main_score": 0.360591,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.369591,
        "recall": 0.466399,
        "f1": 0.393691,
        "accuracy": 0.466399,
        "main_score": 0.393691,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.979605,
        "recall": 0.985958,
        "f1": 0.981612,
        "accuracy": 0.985958,
        "main_score": 0.981612,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97225,
        "recall": 0.980943,
        "f1": 0.975092,
        "accuracy": 0.980943,
        "main_score": 0.975092,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.984955,
        "f1": 0.980107,
        "accuracy": 0.984955,
        "main_score": 0.980107,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972919,
        "recall": 0.981946,
        "f1": 0.975928,
        "accuracy": 0.981946,
        "main_score": 0.975928,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.008087,
        "recall": 0.012036,
        "f1": 0.008479,
        "accuracy": 0.012036,
        "main_score": 0.008479,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002645,
        "recall": 0.017051,
        "f1": 0.003687,
        "accuracy": 0.017051,
        "main_score": 0.003687,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.98666,
        "recall": 0.991107,
        "f1": 0.988142,
        "accuracy": 0.991107,
        "main_score": 0.988142,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.983696,
        "recall": 0.98913,
        "f1": 0.985507,
        "accuracy": 0.98913,
        "main_score": 0.985507,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.761012,
        "recall": 0.818182,
        "f1": 0.777168,
        "accuracy": 0.818182,
        "main_score": 0.777168,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.763818,
        "recall": 0.827075,
        "f1": 0.782646,
        "accuracy": 0.827075,
        "main_score": 0.782646,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998518,
        "recall": 0.999012,
        "f1": 0.998682,
        "accuracy": 0.999012,
        "main_score": 0.998682,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998518,
        "recall": 0.999012,
        "f1": 0.998682,
        "accuracy": 0.999012,
        "main_score": 0.998682,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.718395,
        "recall": 0.781621,
        "f1": 0.735637,
        "accuracy": 0.781621,
        "main_score": 0.735637,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.769178,
        "recall": 0.825099,
        "f1": 0.785943,
        "accuracy": 0.825099,
        "main_score": 0.785943,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.720818,
        "recall": 0.784585,
        "f1": 0.739095,
        "accuracy": 0.784585,
        "main_score": 0.739095,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.789585,
        "recall": 0.842885,
        "f1": 0.805009,
        "accuracy": 0.842885,
        "main_score": 0.805009,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.94944,
        "recall": 0.965415,
        "f1": 0.954545,
        "accuracy": 0.965415,
        "main_score": 0.954545,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.959157,
        "recall": 0.972332,
        "f1": 0.963439,
        "accuracy": 0.972332,
        "main_score": 0.963439,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.70034,
        "recall": 0.769763,
        "f1": 0.719824,
        "accuracy": 0.769763,
        "main_score": 0.719824,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.769384,
        "recall": 0.831028,
        "f1": 0.787935,
        "accuracy": 0.831028,
        "main_score": 0.787935,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.955698,
        "recall": 0.969368,
        "f1": 0.95998,
        "accuracy": 0.969368,
        "main_score": 0.95998,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.949934,
        "recall": 0.966403,
        "f1": 0.955369,
        "accuracy": 0.966403,
        "main_score": 0.955369,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.937335,
        "recall": 0.956522,
        "f1": 0.943412,
        "accuracy": 0.956522,
        "main_score": 0.943412,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.938406,
        "recall": 0.958498,
        "f1": 0.944993,
        "accuracy": 0.958498,
        "main_score": 0.944993,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.844015,
        "recall": 0.88834,
        "f1": 0.857757,
        "accuracy": 0.88834,
        "main_score": 0.857757,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.863472,
        "recall": 0.903162,
        "f1": 0.875922,
        "accuracy": 0.903162,
        "main_score": 0.875922,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.967721,
        "recall": 0.978261,
        "f1": 0.971179,
        "accuracy": 0.978261,
        "main_score": 0.971179,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976285,
        "recall": 0.98419,
        "f1": 0.97892,
        "accuracy": 0.98419,
        "main_score": 0.97892,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.948617,
        "recall": 0.964427,
        "f1": 0.953722,
        "accuracy": 0.964427,
        "main_score": 0.953722,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.949769,
        "recall": 0.964427,
        "f1": 0.954545,
        "accuracy": 0.964427,
        "main_score": 0.954545,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.532596,
        "recall": 0.606719,
        "f1": 0.551379,
        "accuracy": 0.606719,
        "main_score": 0.551379,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.596172,
        "recall": 0.682806,
        "f1": 0.620581,
        "accuracy": 0.682806,
        "main_score": 0.620581,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.65903,
        "recall": 0.725296,
        "f1": 0.676994,
        "accuracy": 0.725296,
        "main_score": 0.676994,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.679471,
        "recall": 0.755929,
        "f1": 0.701528,
        "accuracy": 0.755929,
        "main_score": 0.701528,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.719479,
        "recall": 0.782609,
        "f1": 0.737509,
        "accuracy": 0.782609,
        "main_score": 0.737509,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.747101,
        "recall": 0.809289,
        "f1": 0.765373,
        "accuracy": 0.809289,
        "main_score": 0.765373,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.813413,
        "recall": 0.862648,
        "f1": 0.827884,
        "accuracy": 0.862648,
        "main_score": 0.827884,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.834931,
        "recall": 0.881423,
        "f1": 0.849341,
        "accuracy": 0.881423,
        "main_score": 0.849341,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.98419,
        "f1": 0.979908,
        "accuracy": 0.98419,
        "main_score": 0.979908,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972661,
        "recall": 0.980237,
        "f1": 0.975132,
        "accuracy": 0.980237,
        "main_score": 0.975132,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.982213,
        "recall": 0.988142,
        "f1": 0.98419,
        "accuracy": 0.988142,
        "main_score": 0.98419,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.985178,
        "recall": 0.990119,
        "f1": 0.986825,
        "accuracy": 0.990119,
        "main_score": 0.986825,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.042193,
        "recall": 0.051383,
        "f1": 0.044256,
        "accuracy": 0.051383,
        "main_score": 0.044256,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054907,
        "recall": 0.099802,
        "f1": 0.062337,
        "accuracy": 0.099802,
        "main_score": 0.062337,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.341631,
        "recall": 0.411067,
        "f1": 0.358201,
        "accuracy": 0.411067,
        "main_score": 0.358201,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.374171,
        "recall": 0.448617,
        "f1": 0.393946,
        "accuracy": 0.448617,
        "main_score": 0.393946,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.991107,
        "recall": 0.994071,
        "f1": 0.992095,
        "accuracy": 0.994071,
        "main_score": 0.992095,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98666,
        "recall": 0.991107,
        "f1": 0.988142,
        "accuracy": 0.991107,
        "main_score": 0.988142,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.831498,
        "recall": 0.876482,
        "f1": 0.845043,
        "accuracy": 0.876482,
        "main_score": 0.845043,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.836199,
        "recall": 0.883399,
        "f1": 0.85112,
        "accuracy": 0.883399,
        "main_score": 0.85112,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.978426,
        "recall": 0.985178,
        "f1": 0.980567,
        "accuracy": 0.985178,
        "main_score": 0.980567,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978261,
        "recall": 0.985178,
        "f1": 0.980567,
        "accuracy": 0.985178,
        "main_score": 0.980567,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.978096,
        "recall": 0.985178,
        "f1": 0.980402,
        "accuracy": 0.985178,
        "main_score": 0.980402,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980072,
        "recall": 0.986166,
        "f1": 0.982049,
        "accuracy": 0.986166,
        "main_score": 0.982049,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.988142,
        "recall": 0.992095,
        "f1": 0.98946,
        "accuracy": 0.992095,
        "main_score": 0.98946,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98666,
        "recall": 0.991107,
        "f1": 0.988142,
        "accuracy": 0.991107,
        "main_score": 0.988142,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.315204,
        "recall": 0.360672,
        "f1": 0.326144,
        "accuracy": 0.360672,
        "main_score": 0.326144,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.348353,
        "recall": 0.443676,
        "f1": 0.371614,
        "accuracy": 0.443676,
        "main_score": 0.371614,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.979908,
        "recall": 0.986166,
        "f1": 0.981884,
        "accuracy": 0.986166,
        "main_score": 0.981884,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.983696,
        "recall": 0.98913,
        "f1": 0.985507,
        "accuracy": 0.98913,
        "main_score": 0.985507,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.985178,
        "f1": 0.980237,
        "accuracy": 0.985178,
        "main_score": 0.980237,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976779,
        "recall": 0.98419,
        "f1": 0.979249,
        "accuracy": 0.98419,
        "main_score": 0.979249,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.006431,
        "recall": 0.009881,
        "f1": 0.006933,
        "accuracy": 0.009881,
        "main_score": 0.006933,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006449,
        "recall": 0.024704,
        "f1": 0.008763,
        "accuracy": 0.024704,
        "main_score": 0.008763,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 479.6485059261322,
  "kg_co2_emissions": 0.04143080031300078
}