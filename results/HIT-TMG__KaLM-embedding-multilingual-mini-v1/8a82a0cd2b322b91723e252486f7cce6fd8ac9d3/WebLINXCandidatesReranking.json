{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.146643,
        "mrr": 0.129529,
        "nAUC_map_max": -0.086044,
        "nAUC_map_std": 0.014452,
        "nAUC_map_diff1": 0.068207,
        "nAUC_mrr_max": -0.081875,
        "nAUC_mrr_std": 0.020677,
        "nAUC_mrr_diff1": 0.078683,
        "main_score": 0.129529,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.117502,
        "mrr": 0.099271,
        "nAUC_map_max": 0.032107,
        "nAUC_map_std": 0.118814,
        "nAUC_map_diff1": 0.073041,
        "nAUC_mrr_max": 0.038624,
        "nAUC_mrr_std": 0.106794,
        "nAUC_mrr_diff1": 0.076922,
        "main_score": 0.099271,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.089465,
        "mrr": 0.070358,
        "nAUC_map_max": 0.141614,
        "nAUC_map_std": 0.306741,
        "nAUC_map_diff1": 0.012144,
        "nAUC_mrr_max": 0.125366,
        "nAUC_mrr_std": 0.283901,
        "nAUC_mrr_diff1": 0.007069,
        "main_score": 0.070358,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.129805,
        "mrr": 0.111418,
        "nAUC_map_max": -0.05136,
        "nAUC_map_std": 0.041084,
        "nAUC_map_diff1": 0.057465,
        "nAUC_mrr_max": -0.040877,
        "nAUC_mrr_std": 0.037524,
        "nAUC_mrr_diff1": 0.058938,
        "main_score": 0.111418,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.125301,
        "mrr": 0.107256,
        "nAUC_map_max": 0.044332,
        "nAUC_map_std": 0.090982,
        "nAUC_map_diff1": 0.095293,
        "nAUC_mrr_max": 0.051972,
        "nAUC_mrr_std": 0.082073,
        "nAUC_mrr_diff1": 0.096703,
        "main_score": 0.107256,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.096847,
        "mrr": 0.077857,
        "nAUC_map_max": 0.076806,
        "nAUC_map_std": 0.152463,
        "nAUC_map_diff1": 0.092129,
        "nAUC_mrr_max": 0.074475,
        "nAUC_mrr_std": 0.145327,
        "nAUC_mrr_diff1": 0.101944,
        "main_score": 0.077857,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7120.167430400848,
  "kg_co2_emissions": 0.6593539403154355
}