{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "task_name": "KorSarcasmClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.549072,
        "f1": 0.544131,
        "f1_weighted": 0.544157,
        "ap": 0.52698,
        "ap_weighted": 0.52698,
        "scores_per_experiment": [
          {
            "accuracy": 0.605957,
            "f1": 0.604754,
            "f1_weighted": 0.604796,
            "ap": 0.56454,
            "ap_weighted": 0.56454
          },
          {
            "accuracy": 0.558594,
            "f1": 0.555603,
            "f1_weighted": 0.555532,
            "ap": 0.531368,
            "ap_weighted": 0.531368
          },
          {
            "accuracy": 0.533691,
            "f1": 0.523811,
            "f1_weighted": 0.523945,
            "ap": 0.517296,
            "ap_weighted": 0.517296
          },
          {
            "accuracy": 0.53125,
            "f1": 0.526364,
            "f1_weighted": 0.526458,
            "ap": 0.51576,
            "ap_weighted": 0.51576
          },
          {
            "accuracy": 0.518066,
            "f1": 0.50654,
            "f1_weighted": 0.506688,
            "ap": 0.508363,
            "ap_weighted": 0.508363
          },
          {
            "accuracy": 0.571289,
            "f1": 0.570422,
            "f1_weighted": 0.570384,
            "ap": 0.539388,
            "ap_weighted": 0.539388
          },
          {
            "accuracy": 0.572266,
            "f1": 0.570936,
            "f1_weighted": 0.57089,
            "ap": 0.539926,
            "ap_weighted": 0.539926
          },
          {
            "accuracy": 0.561035,
            "f1": 0.560718,
            "f1_weighted": 0.560695,
            "ap": 0.53311,
            "ap_weighted": 0.53311
          },
          {
            "accuracy": 0.554199,
            "f1": 0.547179,
            "f1_weighted": 0.547069,
            "ap": 0.52862,
            "ap_weighted": 0.52862
          },
          {
            "accuracy": 0.484375,
            "f1": 0.474977,
            "f1_weighted": 0.475115,
            "ap": 0.491425,
            "ap_weighted": 0.491425
          }
        ],
        "main_score": 0.549072,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 9.785842180252075,
  "kg_co2_emissions": 0.0003903526399592595
}