{
  "dataset_revision": "426c4f4779901e731f0ba7157de727750325a68b",
  "task_name": "VocalSound",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.520746,
            "f1": 0.513878,
            "f1_weighted": 0.513868,
            "precision": 0.529649,
            "precision_weighted": 0.529635,
            "recall": 0.520742,
            "recall_weighted": 0.520746,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.549429,
            "f1": 0.554406,
            "f1_weighted": 0.554425,
            "precision": 0.569135,
            "precision_weighted": 0.569146,
            "recall": 0.549402,
            "recall_weighted": 0.549429,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.487886,
            "f1": 0.49157,
            "f1_weighted": 0.491588,
            "precision": 0.502616,
            "precision_weighted": 0.502609,
            "recall": 0.487849,
            "recall_weighted": 0.487886,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.556948,
            "f1": 0.555714,
            "f1_weighted": 0.555696,
            "precision": 0.567857,
            "precision_weighted": 0.56784,
            "recall": 0.556962,
            "recall_weighted": 0.556948,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.582289,
            "f1": 0.583031,
            "f1_weighted": 0.583049,
            "precision": 0.587456,
            "precision_weighted": 0.587454,
            "recall": 0.582253,
            "recall_weighted": 0.582289,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.527708,
            "f1": 0.524189,
            "f1_weighted": 0.524191,
            "precision": 0.530943,
            "precision_weighted": 0.53093,
            "recall": 0.527692,
            "recall_weighted": 0.527708,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.538847,
            "f1": 0.536661,
            "f1_weighted": 0.536663,
            "precision": 0.547002,
            "precision_weighted": 0.546972,
            "recall": 0.538821,
            "recall_weighted": 0.538847,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.540518,
            "f1": 0.542533,
            "f1_weighted": 0.542533,
            "precision": 0.548467,
            "precision_weighted": 0.548454,
            "recall": 0.540508,
            "recall_weighted": 0.540518,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.502367,
            "f1": 0.502479,
            "f1_weighted": 0.502515,
            "precision": 0.517603,
            "precision_weighted": 0.517638,
            "recall": 0.50233,
            "recall_weighted": 0.502367,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.515734,
            "f1": 0.531728,
            "f1_weighted": 0.531719,
            "precision": 0.570864,
            "precision_weighted": 0.570831,
            "recall": 0.515724,
            "recall_weighted": 0.515734,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.532247,
        "f1": 0.533619,
        "f1_weighted": 0.533625,
        "precision": 0.547159,
        "precision_weighted": 0.547151,
        "recall": 0.532228,
        "recall_weighted": 0.532247,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.532247,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 356.7296335697174,
  "kg_co2_emissions": null
}