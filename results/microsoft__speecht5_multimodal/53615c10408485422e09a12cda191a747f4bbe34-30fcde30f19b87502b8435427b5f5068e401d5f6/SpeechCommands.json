{
  "dataset_revision": "3ac713aa0829eeadda73182f38bbbd788d21254b",
  "task_name": "SpeechCommands",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.773211,
            "f1": 0.633742,
            "f1_weighted": 0.797036,
            "precision": 0.634742,
            "precision_weighted": 0.907337,
            "recall": 0.775631,
            "recall_weighted": 0.773211,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.798773,
            "f1": 0.661874,
            "f1_weighted": 0.80213,
            "precision": 0.637118,
            "precision_weighted": 0.885234,
            "recall": 0.827157,
            "recall_weighted": 0.798773,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.795092,
            "f1": 0.644214,
            "f1_weighted": 0.797781,
            "precision": 0.600718,
            "precision_weighted": 0.884286,
            "recall": 0.838804,
            "recall_weighted": 0.795092,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.777505,
            "f1": 0.642796,
            "f1_weighted": 0.788261,
            "precision": 0.621468,
            "precision_weighted": 0.893016,
            "recall": 0.823637,
            "recall_weighted": 0.777505,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.779141,
            "f1": 0.62662,
            "f1_weighted": 0.800477,
            "precision": 0.613353,
            "precision_weighted": 0.917994,
            "recall": 0.809718,
            "recall_weighted": 0.779141,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.780368,
            "f1": 0.650654,
            "f1_weighted": 0.78566,
            "precision": 0.617389,
            "precision_weighted": 0.870826,
            "recall": 0.825574,
            "recall_weighted": 0.780368,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.787526,
            "f1": 0.618004,
            "f1_weighted": 0.80277,
            "precision": 0.595413,
            "precision_weighted": 0.907575,
            "recall": 0.831217,
            "recall_weighted": 0.787526,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.777505,
            "f1": 0.60609,
            "f1_weighted": 0.794399,
            "precision": 0.587862,
            "precision_weighted": 0.910357,
            "recall": 0.777625,
            "recall_weighted": 0.777505,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.788344,
            "f1": 0.63235,
            "f1_weighted": 0.804852,
            "precision": 0.613704,
            "precision_weighted": 0.91238,
            "recall": 0.824777,
            "recall_weighted": 0.788344,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.801227,
            "f1": 0.664211,
            "f1_weighted": 0.792097,
            "precision": 0.62962,
            "precision_weighted": 0.872533,
            "recall": 0.831648,
            "recall_weighted": 0.801227,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.785869,
        "f1": 0.638056,
        "f1_weighted": 0.796546,
        "precision": 0.615139,
        "precision_weighted": 0.896154,
        "recall": 0.816579,
        "recall_weighted": 0.785869,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.785869,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 200.68910932540894,
  "kg_co2_emissions": null
}