{
  "dataset_revision": "f333c1fcfa3ab43f008a327c8bd0140441354d34",
  "task_name": "BrazilianToxicTweetsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.18999,
        "f1": 0.160147,
        "lrap": 0.797538,
        "scores_per_experiment": [
          {
            "accuracy": 0.162598,
            "f1": 0.156875,
            "lrap": 0.805271
          },
          {
            "accuracy": 0.197266,
            "f1": 0.183945,
            "lrap": 0.804484
          },
          {
            "accuracy": 0.111328,
            "f1": 0.156888,
            "lrap": 0.809041
          },
          {
            "accuracy": 0.289551,
            "f1": 0.165478,
            "lrap": 0.808797
          },
          {
            "accuracy": 0.260742,
            "f1": 0.150952,
            "lrap": 0.782301
          },
          {
            "accuracy": 0.21875,
            "f1": 0.176224,
            "lrap": 0.820353
          },
          {
            "accuracy": 0.21582,
            "f1": 0.114887,
            "lrap": 0.729777
          },
          {
            "accuracy": 0.099609,
            "f1": 0.173971,
            "lrap": 0.79836
          },
          {
            "accuracy": 0.1875,
            "f1": 0.161671,
            "lrap": 0.8176
          },
          {
            "accuracy": 0.156738,
            "f1": 0.160577,
            "lrap": 0.799398
          }
        ],
        "main_score": 0.18999,
        "hf_subset": "default",
        "languages": [
          "por-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 3.4561145305633545,
  "kg_co2_emissions": 0.00012588359242290593
}