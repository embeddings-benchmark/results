{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.4617,
        "f1": 0.417461,
        "f1_weighted": 0.481163,
        "scores_per_experiment": [
          {
            "accuracy": 0.504,
            "f1": 0.446994,
            "f1_weighted": 0.52444
          },
          {
            "accuracy": 0.457,
            "f1": 0.400548,
            "f1_weighted": 0.467503
          },
          {
            "accuracy": 0.439,
            "f1": 0.390613,
            "f1_weighted": 0.459867
          },
          {
            "accuracy": 0.4325,
            "f1": 0.39654,
            "f1_weighted": 0.456961
          },
          {
            "accuracy": 0.475,
            "f1": 0.436679,
            "f1_weighted": 0.49619
          },
          {
            "accuracy": 0.461,
            "f1": 0.41666,
            "f1_weighted": 0.479474
          },
          {
            "accuracy": 0.4685,
            "f1": 0.417845,
            "f1_weighted": 0.490959
          },
          {
            "accuracy": 0.425,
            "f1": 0.394697,
            "f1_weighted": 0.438905
          },
          {
            "accuracy": 0.4955,
            "f1": 0.455097,
            "f1_weighted": 0.510586
          },
          {
            "accuracy": 0.4595,
            "f1": 0.418933,
            "f1_weighted": 0.486749
          }
        ],
        "main_score": 0.4617,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.46325,
        "f1": 0.414585,
        "f1_weighted": 0.485733,
        "scores_per_experiment": [
          {
            "accuracy": 0.503,
            "f1": 0.450421,
            "f1_weighted": 0.524428
          },
          {
            "accuracy": 0.446,
            "f1": 0.390908,
            "f1_weighted": 0.454418
          },
          {
            "accuracy": 0.4425,
            "f1": 0.39501,
            "f1_weighted": 0.467749
          },
          {
            "accuracy": 0.426,
            "f1": 0.386516,
            "f1_weighted": 0.458983
          },
          {
            "accuracy": 0.474,
            "f1": 0.433228,
            "f1_weighted": 0.498269
          },
          {
            "accuracy": 0.47,
            "f1": 0.422133,
            "f1_weighted": 0.492304
          },
          {
            "accuracy": 0.476,
            "f1": 0.417736,
            "f1_weighted": 0.501265
          },
          {
            "accuracy": 0.4435,
            "f1": 0.401171,
            "f1_weighted": 0.464226
          },
          {
            "accuracy": 0.497,
            "f1": 0.439087,
            "f1_weighted": 0.515469
          },
          {
            "accuracy": 0.4545,
            "f1": 0.40964,
            "f1_weighted": 0.480221
          }
        ],
        "main_score": 0.46325,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 14.922759532928467,
  "kg_co2_emissions": 0.000497727902472729
}