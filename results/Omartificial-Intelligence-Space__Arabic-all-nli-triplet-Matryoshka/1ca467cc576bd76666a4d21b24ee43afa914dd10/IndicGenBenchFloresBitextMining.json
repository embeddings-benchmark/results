{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.947342,
        "recall": 0.963892,
        "f1": 0.952658,
        "accuracy": 0.963892,
        "main_score": 0.952658,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.912655,
        "recall": 0.938816,
        "f1": 0.920829,
        "accuracy": 0.938816,
        "main_score": 0.920829,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.98228,
        "recall": 0.987964,
        "f1": 0.984119,
        "accuracy": 0.987964,
        "main_score": 0.984119,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.964226,
        "recall": 0.975928,
        "f1": 0.968071,
        "accuracy": 0.975928,
        "main_score": 0.968071,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998495,
        "recall": 0.998997,
        "f1": 0.998663,
        "accuracy": 0.998997,
        "main_score": 0.998663,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995486,
        "recall": 0.996991,
        "f1": 0.995988,
        "accuracy": 0.996991,
        "main_score": 0.995988,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.919626,
        "recall": 0.942828,
        "f1": 0.926747,
        "accuracy": 0.942828,
        "main_score": 0.926747,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.895186,
        "recall": 0.927783,
        "f1": 0.905684,
        "accuracy": 0.927783,
        "main_score": 0.905684,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.95127,
        "recall": 0.965898,
        "f1": 0.955934,
        "accuracy": 0.965898,
        "main_score": 0.955934,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.925861,
        "recall": 0.947844,
        "f1": 0.932865,
        "accuracy": 0.947844,
        "main_score": 0.932865,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.977509,
        "recall": 0.980943,
        "f1": 0.9782,
        "accuracy": 0.980943,
        "main_score": 0.9782,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.946172,
        "recall": 0.963892,
        "f1": 0.952023,
        "accuracy": 0.963892,
        "main_score": 0.952023,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.949097,
        "recall": 0.964895,
        "f1": 0.954096,
        "accuracy": 0.964895,
        "main_score": 0.954096,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.934888,
        "recall": 0.955868,
        "f1": 0.941725,
        "accuracy": 0.955868,
        "main_score": 0.941725,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.940856,
        "recall": 0.958877,
        "f1": 0.946506,
        "accuracy": 0.958877,
        "main_score": 0.946506,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.910231,
        "recall": 0.938816,
        "f1": 0.919425,
        "accuracy": 0.938816,
        "main_score": 0.919425,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.990973,
        "recall": 0.993982,
        "f1": 0.991976,
        "accuracy": 0.993982,
        "main_score": 0.991976,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.971749,
        "recall": 0.980943,
        "f1": 0.974758,
        "accuracy": 0.980943,
        "main_score": 0.974758,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.528113,
        "recall": 0.605817,
        "f1": 0.548689,
        "accuracy": 0.605817,
        "main_score": 0.548689,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.520813,
        "recall": 0.625878,
        "f1": 0.549858,
        "accuracy": 0.625878,
        "main_score": 0.549858,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.935306,
        "recall": 0.954865,
        "f1": 0.941658,
        "accuracy": 0.954865,
        "main_score": 0.941658,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.876212,
        "recall": 0.913741,
        "f1": 0.888064,
        "accuracy": 0.913741,
        "main_score": 0.888064,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.980943,
        "recall": 0.986961,
        "f1": 0.982949,
        "accuracy": 0.986961,
        "main_score": 0.982949,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.974089,
        "recall": 0.981946,
        "f1": 0.976596,
        "accuracy": 0.981946,
        "main_score": 0.976596,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.867529,
        "recall": 0.904714,
        "f1": 0.87892,
        "accuracy": 0.904714,
        "main_score": 0.87892,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.82999,
        "recall": 0.880642,
        "f1": 0.846005,
        "accuracy": 0.880642,
        "main_score": 0.846005,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.886302,
        "recall": 0.917753,
        "f1": 0.895823,
        "accuracy": 0.917753,
        "main_score": 0.895823,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.857406,
        "recall": 0.901705,
        "f1": 0.871581,
        "accuracy": 0.901705,
        "main_score": 0.871581,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.85606,
        "recall": 0.893681,
        "f1": 0.867458,
        "accuracy": 0.893681,
        "main_score": 0.867458,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.761594,
        "recall": 0.829488,
        "f1": 0.782297,
        "accuracy": 0.829488,
        "main_score": 0.782297,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.810983,
        "recall": 0.85657,
        "f1": 0.824427,
        "accuracy": 0.85657,
        "main_score": 0.824427,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.775168,
        "recall": 0.83651,
        "f1": 0.793851,
        "accuracy": 0.83651,
        "main_score": 0.793851,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.985958,
        "recall": 0.98997,
        "f1": 0.987295,
        "accuracy": 0.98997,
        "main_score": 0.987295,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.970244,
        "recall": 0.978937,
        "f1": 0.973086,
        "accuracy": 0.978937,
        "main_score": 0.973086,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.984955,
        "f1": 0.980107,
        "accuracy": 0.984955,
        "main_score": 0.980107,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.951354,
        "recall": 0.966901,
        "f1": 0.956369,
        "accuracy": 0.966901,
        "main_score": 0.956369,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.029008,
        "recall": 0.034102,
        "f1": 0.029784,
        "accuracy": 0.034102,
        "main_score": 0.029784,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015236,
        "recall": 0.068205,
        "f1": 0.020697,
        "accuracy": 0.068205,
        "main_score": 0.020697,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.081602,
        "recall": 0.111334,
        "f1": 0.086352,
        "accuracy": 0.111334,
        "main_score": 0.086352,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.113648,
        "recall": 0.199599,
        "f1": 0.131901,
        "accuracy": 0.199599,
        "main_score": 0.131901,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.942052,
        "recall": 0.957874,
        "f1": 0.946991,
        "accuracy": 0.957874,
        "main_score": 0.946991,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.913825,
        "recall": 0.940822,
        "f1": 0.922501,
        "accuracy": 0.940822,
        "main_score": 0.922501,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.712839,
        "recall": 0.77332,
        "f1": 0.72938,
        "accuracy": 0.77332,
        "main_score": 0.72938,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.672711,
        "recall": 0.759278,
        "f1": 0.698164,
        "accuracy": 0.759278,
        "main_score": 0.698164,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.929455,
        "recall": 0.950853,
        "f1": 0.936108,
        "accuracy": 0.950853,
        "main_score": 0.936108,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.893096,
        "recall": 0.923771,
        "f1": 0.902441,
        "accuracy": 0.923771,
        "main_score": 0.902441,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.952984,
        "recall": 0.965898,
        "f1": 0.956926,
        "accuracy": 0.965898,
        "main_score": 0.956926,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.894634,
        "recall": 0.925777,
        "f1": 0.904232,
        "accuracy": 0.925777,
        "main_score": 0.904232,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.972919,
        "recall": 0.981946,
        "f1": 0.975928,
        "accuracy": 0.981946,
        "main_score": 0.975928,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.926195,
        "recall": 0.94985,
        "f1": 0.933868,
        "accuracy": 0.94985,
        "main_score": 0.933868,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.043098,
        "recall": 0.060181,
        "f1": 0.046193,
        "accuracy": 0.060181,
        "main_score": 0.046193,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0545,
        "recall": 0.119358,
        "f1": 0.066119,
        "accuracy": 0.119358,
        "main_score": 0.066119,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.960047,
        "recall": 0.972919,
        "f1": 0.964226,
        "accuracy": 0.972919,
        "main_score": 0.964226,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.9221,
        "recall": 0.946841,
        "f1": 0.93009,
        "accuracy": 0.946841,
        "main_score": 0.93009,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.958626,
        "recall": 0.971916,
        "f1": 0.962956,
        "accuracy": 0.971916,
        "main_score": 0.962956,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.911234,
        "recall": 0.938816,
        "f1": 0.920094,
        "accuracy": 0.938816,
        "main_score": 0.920094,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.004053,
        "recall": 0.006018,
        "f1": 0.004091,
        "accuracy": 0.006018,
        "main_score": 0.004091,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000828,
        "recall": 0.016048,
        "f1": 0.001473,
        "accuracy": 0.016048,
        "main_score": 0.001473,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.952075,
        "recall": 0.967391,
        "f1": 0.957016,
        "accuracy": 0.967391,
        "main_score": 0.957016,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.91469,
        "recall": 0.9417,
        "f1": 0.923584,
        "accuracy": 0.9417,
        "main_score": 0.923584,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.994071,
        "recall": 0.996047,
        "f1": 0.99473,
        "accuracy": 0.996047,
        "main_score": 0.99473,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.962121,
        "recall": 0.974308,
        "f1": 0.966074,
        "accuracy": 0.974308,
        "main_score": 0.966074,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994565,
        "recall": 0.996047,
        "f1": 0.995059,
        "accuracy": 0.996047,
        "main_score": 0.995059,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.994071,
        "recall": 0.996047,
        "f1": 0.99473,
        "accuracy": 0.996047,
        "main_score": 0.99473,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.92556,
        "recall": 0.947628,
        "f1": 0.932444,
        "accuracy": 0.947628,
        "main_score": 0.932444,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.885705,
        "recall": 0.920949,
        "f1": 0.896904,
        "accuracy": 0.920949,
        "main_score": 0.896904,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.943594,
        "recall": 0.960474,
        "f1": 0.948847,
        "accuracy": 0.960474,
        "main_score": 0.948847,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.91469,
        "recall": 0.940711,
        "f1": 0.922925,
        "accuracy": 0.940711,
        "main_score": 0.922925,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.978211,
        "recall": 0.98419,
        "f1": 0.979974,
        "accuracy": 0.98419,
        "main_score": 0.979974,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.946146,
        "recall": 0.963439,
        "f1": 0.951746,
        "accuracy": 0.963439,
        "main_score": 0.951746,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.946805,
        "recall": 0.963439,
        "f1": 0.952075,
        "accuracy": 0.963439,
        "main_score": 0.952075,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.910655,
        "recall": 0.938735,
        "f1": 0.919697,
        "accuracy": 0.938735,
        "main_score": 0.919697,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.929134,
        "recall": 0.949605,
        "f1": 0.935474,
        "accuracy": 0.949605,
        "main_score": 0.935474,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.905962,
        "recall": 0.934783,
        "f1": 0.915152,
        "accuracy": 0.934783,
        "main_score": 0.915152,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.991107,
        "recall": 0.994071,
        "f1": 0.992095,
        "accuracy": 0.994071,
        "main_score": 0.992095,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97365,
        "recall": 0.982213,
        "f1": 0.976449,
        "accuracy": 0.982213,
        "main_score": 0.976449,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.49104,
        "recall": 0.56917,
        "f1": 0.511409,
        "accuracy": 0.56917,
        "main_score": 0.511409,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.492852,
        "recall": 0.606719,
        "f1": 0.523923,
        "accuracy": 0.606719,
        "main_score": 0.523923,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.920125,
        "recall": 0.945652,
        "f1": 0.928524,
        "accuracy": 0.945652,
        "main_score": 0.928524,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.880229,
        "recall": 0.91502,
        "f1": 0.891162,
        "accuracy": 0.91502,
        "main_score": 0.891162,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.987154,
        "recall": 0.991107,
        "f1": 0.988472,
        "accuracy": 0.991107,
        "main_score": 0.988472,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972661,
        "recall": 0.981225,
        "f1": 0.975461,
        "accuracy": 0.981225,
        "main_score": 0.975461,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.849614,
        "recall": 0.892292,
        "f1": 0.863027,
        "accuracy": 0.892292,
        "main_score": 0.863027,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.834601,
        "recall": 0.884387,
        "f1": 0.850362,
        "accuracy": 0.884387,
        "main_score": 0.850362,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.841026,
        "recall": 0.879447,
        "f1": 0.851822,
        "accuracy": 0.879447,
        "main_score": 0.851822,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.824473,
        "recall": 0.87747,
        "f1": 0.841041,
        "accuracy": 0.87747,
        "main_score": 0.841041,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.839839,
        "recall": 0.885375,
        "f1": 0.853953,
        "accuracy": 0.885375,
        "main_score": 0.853953,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.773715,
        "recall": 0.837945,
        "f1": 0.793347,
        "accuracy": 0.837945,
        "main_score": 0.793347,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.840794,
        "recall": 0.885375,
        "f1": 0.854315,
        "accuracy": 0.885375,
        "main_score": 0.854315,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.790464,
        "recall": 0.852767,
        "f1": 0.80998,
        "accuracy": 0.852767,
        "main_score": 0.80998,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.980567,
        "recall": 0.986166,
        "f1": 0.982378,
        "accuracy": 0.986166,
        "main_score": 0.982378,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.963603,
        "recall": 0.974308,
        "f1": 0.967062,
        "accuracy": 0.974308,
        "main_score": 0.967062,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.97332,
        "recall": 0.982213,
        "f1": 0.976285,
        "accuracy": 0.982213,
        "main_score": 0.976285,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.944335,
        "recall": 0.961462,
        "f1": 0.949736,
        "accuracy": 0.961462,
        "main_score": 0.949736,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.036949,
        "recall": 0.041502,
        "f1": 0.037956,
        "accuracy": 0.041502,
        "main_score": 0.037956,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015647,
        "recall": 0.071146,
        "f1": 0.021794,
        "accuracy": 0.071146,
        "main_score": 0.021794,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.069102,
        "recall": 0.106719,
        "f1": 0.075229,
        "accuracy": 0.106719,
        "main_score": 0.075229,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.099576,
        "recall": 0.189723,
        "f1": 0.118312,
        "accuracy": 0.189723,
        "main_score": 0.118312,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.956686,
        "recall": 0.970356,
        "f1": 0.961133,
        "accuracy": 0.970356,
        "main_score": 0.961133,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.945158,
        "recall": 0.963439,
        "f1": 0.951252,
        "accuracy": 0.963439,
        "main_score": 0.951252,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.72328,
        "recall": 0.785573,
        "f1": 0.740863,
        "accuracy": 0.785573,
        "main_score": 0.740863,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.66229,
        "recall": 0.749012,
        "f1": 0.687877,
        "accuracy": 0.749012,
        "main_score": 0.687877,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.947628,
        "recall": 0.964427,
        "f1": 0.953063,
        "accuracy": 0.964427,
        "main_score": 0.953063,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.917572,
        "recall": 0.943676,
        "f1": 0.92612,
        "accuracy": 0.943676,
        "main_score": 0.92612,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.935968,
        "recall": 0.953557,
        "f1": 0.94129,
        "accuracy": 0.953557,
        "main_score": 0.94129,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.918396,
        "recall": 0.943676,
        "f1": 0.926449,
        "accuracy": 0.943676,
        "main_score": 0.926449,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.969532,
        "recall": 0.979249,
        "f1": 0.972661,
        "accuracy": 0.979249,
        "main_score": 0.972661,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.925107,
        "recall": 0.947628,
        "f1": 0.932268,
        "accuracy": 0.947628,
        "main_score": 0.932268,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.032899,
        "recall": 0.050395,
        "f1": 0.035653,
        "accuracy": 0.050395,
        "main_score": 0.035653,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.071087,
        "recall": 0.137352,
        "f1": 0.083459,
        "accuracy": 0.137352,
        "main_score": 0.083459,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.957345,
        "recall": 0.971344,
        "f1": 0.961957,
        "accuracy": 0.971344,
        "main_score": 0.961957,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.932559,
        "recall": 0.953557,
        "f1": 0.939295,
        "accuracy": 0.953557,
        "main_score": 0.939295,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.962121,
        "recall": 0.974308,
        "f1": 0.966074,
        "accuracy": 0.974308,
        "main_score": 0.966074,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.93778,
        "recall": 0.95751,
        "f1": 0.94417,
        "accuracy": 0.95751,
        "main_score": 0.94417,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.006424,
        "recall": 0.008893,
        "f1": 0.006708,
        "accuracy": 0.008893,
        "main_score": 0.006708,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002398,
        "recall": 0.025692,
        "f1": 0.003562,
        "accuracy": 0.025692,
        "main_score": 0.003562,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 84.49268698692322,
  "kg_co2_emissions": 0.005890879923765755
}