{
  "dataset_revision": "cf24d44e517efa534f048e5fc5981f399ed25bee",
  "task_name": "CataloniaTweetClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.439206,
        "f1": 0.433685,
        "f1_weighted": 0.434584,
        "scores_per_experiment": [
          {
            "accuracy": 0.440199,
            "f1": 0.446444,
            "f1_weighted": 0.438682
          },
          {
            "accuracy": 0.43871,
            "f1": 0.432142,
            "f1_weighted": 0.441064
          },
          {
            "accuracy": 0.419355,
            "f1": 0.419796,
            "f1_weighted": 0.418925
          },
          {
            "accuracy": 0.396526,
            "f1": 0.396998,
            "f1_weighted": 0.396643
          },
          {
            "accuracy": 0.430273,
            "f1": 0.412126,
            "f1_weighted": 0.418801
          },
          {
            "accuracy": 0.458065,
            "f1": 0.451962,
            "f1_weighted": 0.457885
          },
          {
            "accuracy": 0.435732,
            "f1": 0.429714,
            "f1_weighted": 0.428027
          },
          {
            "accuracy": 0.469975,
            "f1": 0.475461,
            "f1_weighted": 0.468264
          },
          {
            "accuracy": 0.411414,
            "f1": 0.377144,
            "f1_weighted": 0.385425
          },
          {
            "accuracy": 0.491811,
            "f1": 0.495063,
            "f1_weighted": 0.492127
          }
        ],
        "main_score": 0.439206,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ]
      },
      {
        "accuracy": 0.462438,
        "f1": 0.45216,
        "f1_weighted": 0.459802,
        "scores_per_experiment": [
          {
            "accuracy": 0.453731,
            "f1": 0.446454,
            "f1_weighted": 0.450469
          },
          {
            "accuracy": 0.452736,
            "f1": 0.434579,
            "f1_weighted": 0.448931
          },
          {
            "accuracy": 0.474627,
            "f1": 0.45558,
            "f1_weighted": 0.461372
          },
          {
            "accuracy": 0.458209,
            "f1": 0.448023,
            "f1_weighted": 0.458787
          },
          {
            "accuracy": 0.445274,
            "f1": 0.435425,
            "f1_weighted": 0.450003
          },
          {
            "accuracy": 0.457214,
            "f1": 0.448701,
            "f1_weighted": 0.453819
          },
          {
            "accuracy": 0.490547,
            "f1": 0.478732,
            "f1_weighted": 0.488486
          },
          {
            "accuracy": 0.455224,
            "f1": 0.459074,
            "f1_weighted": 0.453945
          },
          {
            "accuracy": 0.481592,
            "f1": 0.463472,
            "f1_weighted": 0.479258
          },
          {
            "accuracy": 0.455224,
            "f1": 0.451562,
            "f1_weighted": 0.452948
          }
        ],
        "main_score": 0.462438,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.437252,
        "f1": 0.434637,
        "f1_weighted": 0.431941,
        "scores_per_experiment": [
          {
            "accuracy": 0.449405,
            "f1": 0.45322,
            "f1_weighted": 0.448513
          },
          {
            "accuracy": 0.415179,
            "f1": 0.414841,
            "f1_weighted": 0.414632
          },
          {
            "accuracy": 0.409226,
            "f1": 0.410808,
            "f1_weighted": 0.405119
          },
          {
            "accuracy": 0.419643,
            "f1": 0.415419,
            "f1_weighted": 0.41996
          },
          {
            "accuracy": 0.404266,
            "f1": 0.394039,
            "f1_weighted": 0.397574
          },
          {
            "accuracy": 0.450397,
            "f1": 0.450255,
            "f1_weighted": 0.450516
          },
          {
            "accuracy": 0.434028,
            "f1": 0.426986,
            "f1_weighted": 0.422381
          },
          {
            "accuracy": 0.477183,
            "f1": 0.484133,
            "f1_weighted": 0.473105
          },
          {
            "accuracy": 0.405258,
            "f1": 0.378166,
            "f1_weighted": 0.379784
          },
          {
            "accuracy": 0.507937,
            "f1": 0.518502,
            "f1_weighted": 0.507826
          }
        ],
        "main_score": 0.437252,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ]
      },
      {
        "accuracy": 0.46204,
        "f1": 0.452146,
        "f1_weighted": 0.459281,
        "scores_per_experiment": [
          {
            "accuracy": 0.467164,
            "f1": 0.456395,
            "f1_weighted": 0.462416
          },
          {
            "accuracy": 0.432836,
            "f1": 0.417756,
            "f1_weighted": 0.429379
          },
          {
            "accuracy": 0.481592,
            "f1": 0.456182,
            "f1_weighted": 0.465858
          },
          {
            "accuracy": 0.454726,
            "f1": 0.448794,
            "f1_weighted": 0.454942
          },
          {
            "accuracy": 0.431841,
            "f1": 0.42063,
            "f1_weighted": 0.435006
          },
          {
            "accuracy": 0.48209,
            "f1": 0.474565,
            "f1_weighted": 0.479656
          },
          {
            "accuracy": 0.469154,
            "f1": 0.456379,
            "f1_weighted": 0.468304
          },
          {
            "accuracy": 0.458706,
            "f1": 0.463137,
            "f1_weighted": 0.457432
          },
          {
            "accuracy": 0.480597,
            "f1": 0.467769,
            "f1_weighted": 0.479762
          },
          {
            "accuracy": 0.461692,
            "f1": 0.459854,
            "f1_weighted": 0.46006
          }
        ],
        "main_score": 0.46204,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 35.02164816856384,
  "kg_co2_emissions": 0.0010755422882286487
}