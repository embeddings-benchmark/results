{
  "dataset_revision": "f333c1fcfa3ab43f008a327c8bd0140441354d34",
  "task_name": "BrazilianToxicTweetsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.205762,
        "f1": 0.137481,
        "lrap": 0.789703,
        "scores_per_experiment": [
          {
            "accuracy": 0.192383,
            "f1": 0.158248,
            "lrap": 0.804199
          },
          {
            "accuracy": 0.137695,
            "f1": 0.153069,
            "lrap": 0.806641
          },
          {
            "accuracy": 0.209961,
            "f1": 0.136026,
            "lrap": 0.791843
          },
          {
            "accuracy": 0.225586,
            "f1": 0.123125,
            "lrap": 0.832655
          },
          {
            "accuracy": 0.191895,
            "f1": 0.119736,
            "lrap": 0.772827
          },
          {
            "accuracy": 0.164062,
            "f1": 0.159796,
            "lrap": 0.819621
          },
          {
            "accuracy": 0.199219,
            "f1": 0.148017,
            "lrap": 0.76591
          },
          {
            "accuracy": 0.16748,
            "f1": 0.139495,
            "lrap": 0.786479
          },
          {
            "accuracy": 0.305664,
            "f1": 0.122097,
            "lrap": 0.7551
          },
          {
            "accuracy": 0.263672,
            "f1": 0.115204,
            "lrap": 0.761759
          }
        ],
        "main_score": 0.205762,
        "hf_subset": "default",
        "languages": [
          "por-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 2.9691858291625977,
  "kg_co2_emissions": 9.286909061665605e-05
}