{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.190186,
        "f1": 0.130357,
        "f1_weighted": 0.179091,
        "scores_per_experiment": [
          {
            "accuracy": 0.186523,
            "f1": 0.123908,
            "f1_weighted": 0.174059
          },
          {
            "accuracy": 0.185059,
            "f1": 0.126649,
            "f1_weighted": 0.169877
          },
          {
            "accuracy": 0.194336,
            "f1": 0.13455,
            "f1_weighted": 0.184686
          },
          {
            "accuracy": 0.187988,
            "f1": 0.128247,
            "f1_weighted": 0.176329
          },
          {
            "accuracy": 0.196289,
            "f1": 0.130253,
            "f1_weighted": 0.186828
          },
          {
            "accuracy": 0.179688,
            "f1": 0.122372,
            "f1_weighted": 0.172002
          },
          {
            "accuracy": 0.205566,
            "f1": 0.147112,
            "f1_weighted": 0.197553
          },
          {
            "accuracy": 0.175781,
            "f1": 0.121488,
            "f1_weighted": 0.162089
          },
          {
            "accuracy": 0.201172,
            "f1": 0.136403,
            "f1_weighted": 0.18901
          },
          {
            "accuracy": 0.189453,
            "f1": 0.132585,
            "f1_weighted": 0.178477
          }
        ],
        "main_score": 0.190186,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.185352,
        "f1": 0.141392,
        "f1_weighted": 0.169745,
        "scores_per_experiment": [
          {
            "accuracy": 0.188477,
            "f1": 0.137463,
            "f1_weighted": 0.173701
          },
          {
            "accuracy": 0.201172,
            "f1": 0.151302,
            "f1_weighted": 0.18129
          },
          {
            "accuracy": 0.188477,
            "f1": 0.144682,
            "f1_weighted": 0.171957
          },
          {
            "accuracy": 0.180664,
            "f1": 0.140512,
            "f1_weighted": 0.164825
          },
          {
            "accuracy": 0.189453,
            "f1": 0.142022,
            "f1_weighted": 0.176446
          },
          {
            "accuracy": 0.175293,
            "f1": 0.134501,
            "f1_weighted": 0.160253
          },
          {
            "accuracy": 0.187988,
            "f1": 0.141124,
            "f1_weighted": 0.175706
          },
          {
            "accuracy": 0.178711,
            "f1": 0.141986,
            "f1_weighted": 0.164671
          },
          {
            "accuracy": 0.180664,
            "f1": 0.137316,
            "f1_weighted": 0.166533
          },
          {
            "accuracy": 0.182617,
            "f1": 0.143015,
            "f1_weighted": 0.16207
          }
        ],
        "main_score": 0.185352,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 387.7525956630707,
  "kg_co2_emissions": 0.012100507556052726
}