{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.009116,
        "recall": 0.014042,
        "f1": 0.009197,
        "accuracy": 0.014042,
        "main_score": 0.009197,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.080758,
        "recall": 0.165496,
        "f1": 0.09657,
        "accuracy": 0.165496,
        "main_score": 0.09657,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.343397,
        "recall": 0.359077,
        "f1": 0.346293,
        "accuracy": 0.359077,
        "main_score": 0.346293,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.406738,
        "recall": 0.531595,
        "f1": 0.439301,
        "accuracy": 0.531595,
        "main_score": 0.439301,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.847053,
        "recall": 0.864594,
        "f1": 0.851405,
        "accuracy": 0.864594,
        "main_score": 0.851405,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.890672,
        "recall": 0.923771,
        "f1": 0.901371,
        "accuracy": 0.923771,
        "main_score": 0.901371,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00535,
        "recall": 0.008024,
        "f1": 0.005853,
        "accuracy": 0.008024,
        "main_score": 0.005853,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023542,
        "recall": 0.078235,
        "f1": 0.029779,
        "accuracy": 0.078235,
        "main_score": 0.029779,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003512,
        "recall": 0.005015,
        "f1": 0.00368,
        "accuracy": 0.005015,
        "main_score": 0.00368,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036301,
        "recall": 0.104313,
        "f1": 0.04623,
        "accuracy": 0.104313,
        "main_score": 0.04623,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.388322,
        "recall": 0.412237,
        "f1": 0.392736,
        "accuracy": 0.412237,
        "main_score": 0.392736,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.510367,
        "recall": 0.623872,
        "f1": 0.542493,
        "accuracy": 0.623872,
        "main_score": 0.542493,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005104,
        "recall": 0.009027,
        "f1": 0.005186,
        "accuracy": 0.009027,
        "main_score": 0.005186,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060474,
        "recall": 0.145436,
        "f1": 0.074878,
        "accuracy": 0.145436,
        "main_score": 0.074878,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.006121,
        "recall": 0.012036,
        "f1": 0.006766,
        "accuracy": 0.012036,
        "main_score": 0.006766,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.071318,
        "recall": 0.156469,
        "f1": 0.085346,
        "accuracy": 0.156469,
        "main_score": 0.085346,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.835175,
        "recall": 0.872618,
        "f1": 0.845433,
        "accuracy": 0.872618,
        "main_score": 0.845433,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.88783,
        "recall": 0.919759,
        "f1": 0.89766,
        "accuracy": 0.919759,
        "main_score": 0.89766,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001817,
        "recall": 0.006018,
        "f1": 0.002191,
        "accuracy": 0.006018,
        "main_score": 0.002191,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042642,
        "recall": 0.105316,
        "f1": 0.054482,
        "accuracy": 0.105316,
        "main_score": 0.054482,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.340764,
        "recall": 0.374122,
        "f1": 0.347161,
        "accuracy": 0.374122,
        "main_score": 0.347161,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.548027,
        "recall": 0.645938,
        "f1": 0.57592,
        "accuracy": 0.645938,
        "main_score": 0.57592,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.079838,
        "recall": 0.092277,
        "f1": 0.081384,
        "accuracy": 0.092277,
        "main_score": 0.081384,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.254441,
        "recall": 0.373119,
        "f1": 0.283704,
        "accuracy": 0.373119,
        "main_score": 0.283704,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.010202,
        "recall": 0.015045,
        "f1": 0.010687,
        "accuracy": 0.015045,
        "main_score": 0.010687,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.048386,
        "recall": 0.12337,
        "f1": 0.060571,
        "accuracy": 0.12337,
        "main_score": 0.060571,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.004459,
        "recall": 0.01003,
        "f1": 0.00473,
        "accuracy": 0.01003,
        "main_score": 0.00473,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.087812,
        "recall": 0.177533,
        "f1": 0.105886,
        "accuracy": 0.177533,
        "main_score": 0.105886,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.101354,
        "recall": 0.125376,
        "f1": 0.105082,
        "accuracy": 0.125376,
        "main_score": 0.105082,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.260376,
        "recall": 0.377131,
        "f1": 0.29068,
        "accuracy": 0.377131,
        "main_score": 0.29068,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.095535,
        "recall": 0.109328,
        "f1": 0.097341,
        "accuracy": 0.109328,
        "main_score": 0.097341,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.254,
        "recall": 0.367101,
        "f1": 0.282652,
        "accuracy": 0.367101,
        "main_score": 0.282652,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.690103,
        "recall": 0.730191,
        "f1": 0.699349,
        "accuracy": 0.730191,
        "main_score": 0.699349,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.777074,
        "recall": 0.831494,
        "f1": 0.7928,
        "accuracy": 0.831494,
        "main_score": 0.7928,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.410023,
        "recall": 0.447342,
        "f1": 0.41776,
        "accuracy": 0.447342,
        "main_score": 0.41776,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.615623,
        "recall": 0.704112,
        "f1": 0.640911,
        "accuracy": 0.704112,
        "main_score": 0.640911,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.008349,
        "recall": 0.013039,
        "f1": 0.008972,
        "accuracy": 0.013039,
        "main_score": 0.008972,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010176,
        "recall": 0.018054,
        "f1": 0.011228,
        "accuracy": 0.018054,
        "main_score": 0.011228,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.014183,
        "recall": 0.018054,
        "f1": 0.0143,
        "accuracy": 0.018054,
        "main_score": 0.0143,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.046672,
        "recall": 0.079238,
        "f1": 0.053732,
        "accuracy": 0.079238,
        "main_score": 0.053732,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.472446,
        "recall": 0.522568,
        "f1": 0.484449,
        "accuracy": 0.522568,
        "main_score": 0.484449,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.655425,
        "recall": 0.734203,
        "f1": 0.678983,
        "accuracy": 0.734203,
        "main_score": 0.678983,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.126494,
        "recall": 0.149448,
        "f1": 0.130231,
        "accuracy": 0.149448,
        "main_score": 0.130231,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.264207,
        "recall": 0.372116,
        "f1": 0.292057,
        "accuracy": 0.372116,
        "main_score": 0.292057,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.560145,
        "recall": 0.605817,
        "f1": 0.570783,
        "accuracy": 0.605817,
        "main_score": 0.570783,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.675436,
        "recall": 0.74323,
        "f1": 0.69524,
        "accuracy": 0.74323,
        "main_score": 0.69524,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.484531,
        "recall": 0.531595,
        "f1": 0.494306,
        "accuracy": 0.531595,
        "main_score": 0.494306,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.632466,
        "recall": 0.711133,
        "f1": 0.654366,
        "accuracy": 0.711133,
        "main_score": 0.654366,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.475556,
        "recall": 0.527583,
        "f1": 0.486986,
        "accuracy": 0.527583,
        "main_score": 0.486986,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.657991,
        "recall": 0.739218,
        "f1": 0.681717,
        "accuracy": 0.739218,
        "main_score": 0.681717,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001003,
        "f1": 7e-06,
        "accuracy": 0.001003,
        "main_score": 7e-06,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005755,
        "recall": 0.01003,
        "f1": 0.00662,
        "accuracy": 0.01003,
        "main_score": 0.00662,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.585003,
        "recall": 0.631896,
        "f1": 0.596668,
        "accuracy": 0.631896,
        "main_score": 0.596668,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.692695,
        "recall": 0.76329,
        "f1": 0.713188,
        "accuracy": 0.76329,
        "main_score": 0.713188,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.581508,
        "recall": 0.624875,
        "f1": 0.591477,
        "accuracy": 0.624875,
        "main_score": 0.591477,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.678399,
        "recall": 0.749248,
        "f1": 0.698074,
        "accuracy": 0.749248,
        "main_score": 0.698074,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.00301,
        "recall": 0.004012,
        "f1": 0.003011,
        "accuracy": 0.004012,
        "main_score": 0.003011,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.001003,
        "f1": 1.7e-05,
        "accuracy": 0.001003,
        "main_score": 1.7e-05,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.00529,
        "recall": 0.008893,
        "f1": 0.005525,
        "accuracy": 0.008893,
        "main_score": 0.005525,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.081645,
        "recall": 0.18083,
        "f1": 0.10179,
        "accuracy": 0.18083,
        "main_score": 0.10179,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.382574,
        "recall": 0.40415,
        "f1": 0.387559,
        "accuracy": 0.40415,
        "main_score": 0.387559,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.422208,
        "recall": 0.546443,
        "f1": 0.454093,
        "accuracy": 0.546443,
        "main_score": 0.454093,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.834518,
        "recall": 0.854743,
        "f1": 0.840305,
        "accuracy": 0.854743,
        "main_score": 0.840305,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.879974,
        "recall": 0.913043,
        "f1": 0.889888,
        "accuracy": 0.913043,
        "main_score": 0.889888,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.008181,
        "recall": 0.013834,
        "f1": 0.008727,
        "accuracy": 0.013834,
        "main_score": 0.008727,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028626,
        "recall": 0.085968,
        "f1": 0.035306,
        "accuracy": 0.085968,
        "main_score": 0.035306,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002004,
        "recall": 0.003953,
        "f1": 0.00203,
        "accuracy": 0.003953,
        "main_score": 0.00203,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.038389,
        "recall": 0.107708,
        "f1": 0.048925,
        "accuracy": 0.107708,
        "main_score": 0.048925,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.395189,
        "recall": 0.423913,
        "f1": 0.401838,
        "accuracy": 0.423913,
        "main_score": 0.401838,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.518094,
        "recall": 0.632411,
        "f1": 0.549939,
        "accuracy": 0.632411,
        "main_score": 0.549939,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002141,
        "recall": 0.004941,
        "f1": 0.002269,
        "accuracy": 0.004941,
        "main_score": 0.002269,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.061715,
        "recall": 0.151186,
        "f1": 0.07642,
        "accuracy": 0.151186,
        "main_score": 0.07642,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.003311,
        "recall": 0.005929,
        "f1": 0.003493,
        "accuracy": 0.005929,
        "main_score": 0.003493,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.059988,
        "recall": 0.158103,
        "f1": 0.076778,
        "accuracy": 0.158103,
        "main_score": 0.076778,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.790037,
        "recall": 0.83498,
        "f1": 0.803164,
        "accuracy": 0.83498,
        "main_score": 0.803164,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.854974,
        "recall": 0.893281,
        "f1": 0.86685,
        "accuracy": 0.893281,
        "main_score": 0.86685,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.00712,
        "recall": 0.009881,
        "f1": 0.007258,
        "accuracy": 0.009881,
        "main_score": 0.007258,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042927,
        "recall": 0.109684,
        "f1": 0.055663,
        "accuracy": 0.109684,
        "main_score": 0.055663,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.391062,
        "recall": 0.431818,
        "f1": 0.40037,
        "accuracy": 0.431818,
        "main_score": 0.40037,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.560368,
        "recall": 0.660079,
        "f1": 0.58886,
        "accuracy": 0.660079,
        "main_score": 0.58886,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.115263,
        "recall": 0.133399,
        "f1": 0.119139,
        "accuracy": 0.133399,
        "main_score": 0.119139,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.262406,
        "recall": 0.389328,
        "f1": 0.294292,
        "accuracy": 0.389328,
        "main_score": 0.294292,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.01595,
        "recall": 0.020751,
        "f1": 0.016536,
        "accuracy": 0.020751,
        "main_score": 0.016536,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056812,
        "recall": 0.142292,
        "f1": 0.07159,
        "accuracy": 0.142292,
        "main_score": 0.07159,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.009931,
        "recall": 0.014822,
        "f1": 0.010426,
        "accuracy": 0.014822,
        "main_score": 0.010426,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.071442,
        "recall": 0.156126,
        "f1": 0.087922,
        "accuracy": 0.156126,
        "main_score": 0.087922,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.057437,
        "recall": 0.065217,
        "f1": 0.058767,
        "accuracy": 0.065217,
        "main_score": 0.058767,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.164554,
        "recall": 0.272727,
        "f1": 0.18906,
        "accuracy": 0.272727,
        "main_score": 0.18906,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.119317,
        "recall": 0.140316,
        "f1": 0.124084,
        "accuracy": 0.140316,
        "main_score": 0.124084,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.246687,
        "recall": 0.363636,
        "f1": 0.277561,
        "accuracy": 0.363636,
        "main_score": 0.277561,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.691984,
        "recall": 0.738142,
        "f1": 0.703496,
        "accuracy": 0.738142,
        "main_score": 0.703496,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.741709,
        "recall": 0.807312,
        "f1": 0.761347,
        "accuracy": 0.807312,
        "main_score": 0.761347,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.500835,
        "recall": 0.545455,
        "f1": 0.511502,
        "accuracy": 0.545455,
        "main_score": 0.511502,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.607484,
        "recall": 0.69664,
        "f1": 0.632852,
        "accuracy": 0.69664,
        "main_score": 0.632852,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.011263,
        "recall": 0.014822,
        "f1": 0.011529,
        "accuracy": 0.014822,
        "main_score": 0.011529,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012405,
        "recall": 0.020751,
        "f1": 0.013848,
        "accuracy": 0.020751,
        "main_score": 0.013848,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.00844,
        "recall": 0.01581,
        "f1": 0.009134,
        "accuracy": 0.01581,
        "main_score": 0.009134,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033917,
        "recall": 0.064229,
        "f1": 0.040554,
        "accuracy": 0.064229,
        "main_score": 0.040554,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.491804,
        "recall": 0.545455,
        "f1": 0.504606,
        "accuracy": 0.545455,
        "main_score": 0.504606,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.648147,
        "recall": 0.729249,
        "f1": 0.671829,
        "accuracy": 0.729249,
        "main_score": 0.671829,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.148368,
        "recall": 0.183794,
        "f1": 0.15514,
        "accuracy": 0.183794,
        "main_score": 0.15514,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.24979,
        "recall": 0.358696,
        "f1": 0.277364,
        "accuracy": 0.358696,
        "main_score": 0.277364,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.533579,
        "recall": 0.585968,
        "f1": 0.545127,
        "accuracy": 0.585968,
        "main_score": 0.545127,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.655355,
        "recall": 0.733202,
        "f1": 0.677409,
        "accuracy": 0.733202,
        "main_score": 0.677409,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.497172,
        "recall": 0.559289,
        "f1": 0.511841,
        "accuracy": 0.559289,
        "main_score": 0.511841,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.628113,
        "recall": 0.70751,
        "f1": 0.650204,
        "accuracy": 0.70751,
        "main_score": 0.650204,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.467959,
        "recall": 0.532609,
        "f1": 0.483877,
        "accuracy": 0.532609,
        "main_score": 0.483877,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.644527,
        "recall": 0.730237,
        "f1": 0.670473,
        "accuracy": 0.730237,
        "main_score": 0.670473,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000993,
        "recall": 0.002964,
        "f1": 0.000997,
        "accuracy": 0.002964,
        "main_score": 0.000997,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004389,
        "recall": 0.011858,
        "f1": 0.00563,
        "accuracy": 0.011858,
        "main_score": 0.00563,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.576086,
        "recall": 0.625494,
        "f1": 0.588037,
        "accuracy": 0.625494,
        "main_score": 0.588037,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.683844,
        "recall": 0.758893,
        "f1": 0.706046,
        "accuracy": 0.758893,
        "main_score": 0.706046,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.617651,
        "recall": 0.668972,
        "f1": 0.630242,
        "accuracy": 0.668972,
        "main_score": 0.630242,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.657764,
        "recall": 0.735178,
        "f1": 0.680343,
        "accuracy": 0.735178,
        "main_score": 0.680343,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.004447,
        "recall": 0.004941,
        "f1": 0.004611,
        "accuracy": 0.004941,
        "main_score": 0.004611,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001895,
        "recall": 0.004941,
        "f1": 0.002327,
        "accuracy": 0.004941,
        "main_score": 0.002327,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 58.50963473320007,
  "kg_co2_emissions": 0.0025850356210453014
}