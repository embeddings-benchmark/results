{
  "dataset_revision": "349481ec73fff722f88e0453ca05c77a447d967c",
  "task_name": "KLUE-TC",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.404346,
        "f1": 0.401051,
        "f1_weighted": 0.406111,
        "scores_per_experiment": [
          {
            "accuracy": 0.333984,
            "f1": 0.342299,
            "f1_weighted": 0.334431
          },
          {
            "accuracy": 0.449707,
            "f1": 0.429862,
            "f1_weighted": 0.461806
          },
          {
            "accuracy": 0.430176,
            "f1": 0.433137,
            "f1_weighted": 0.440797
          },
          {
            "accuracy": 0.41748,
            "f1": 0.425123,
            "f1_weighted": 0.417143
          },
          {
            "accuracy": 0.390137,
            "f1": 0.403471,
            "f1_weighted": 0.379181
          },
          {
            "accuracy": 0.358887,
            "f1": 0.377615,
            "f1_weighted": 0.347308
          },
          {
            "accuracy": 0.475098,
            "f1": 0.423049,
            "f1_weighted": 0.47613
          },
          {
            "accuracy": 0.395508,
            "f1": 0.387814,
            "f1_weighted": 0.399354
          },
          {
            "accuracy": 0.423828,
            "f1": 0.412297,
            "f1_weighted": 0.429739
          },
          {
            "accuracy": 0.368652,
            "f1": 0.375843,
            "f1_weighted": 0.375216
          }
        ],
        "main_score": 0.404346,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 7.70483922958374,
  "kg_co2_emissions": 0.00021474189131001197
}