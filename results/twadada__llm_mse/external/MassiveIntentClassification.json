{
    "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.02219233355749832,
                "f1": 0.001932870095686131,
                "f1_weighted": 0.0025123548763933703,
                "main_score": 0.02219233355749832
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.012844653665097511,
                "f1": 0.0018710410412943544,
                "f1_weighted": 0.0027399071744620015,
                "main_score": 0.012844653665097511
            },
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.32982515131136514,
                "f1": 0.29879476335364974,
                "f1_weighted": 0.3259262194412672,
                "main_score": 0.32982515131136514
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.022125084061869537,
                "f1": 0.005736320148349802,
                "f1_weighted": 0.007371018417507616,
                "main_score": 0.022125084061869537
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.27165433759246804,
                "f1": 0.2568362075943369,
                "f1_weighted": 0.2571202157696122,
                "main_score": 0.27165433759246804
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.10665770006724948,
                "f1": 0.051146112831808324,
                "f1_weighted": 0.07526848175428076,
                "main_score": 0.10665770006724948
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.3166106254203093,
                "f1": 0.31298953203005986,
                "f1_weighted": 0.30183076634560135,
                "main_score": 0.3166106254203093
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.27995965030262276,
                "f1": 0.25849404737727466,
                "f1_weighted": 0.26922571545761637,
                "main_score": 0.27995965030262276
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.3673839946200404,
                "f1": 0.356799981256784,
                "f1_weighted": 0.3565583276626004,
                "main_score": 0.3673839946200404
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.011062542030934768,
                "f1": 0.003829753109058956,
                "f1_weighted": 0.004245953384117374,
                "main_score": 0.011062542030934768
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.02360457296570275,
                "f1": 0.009096234324517042,
                "f1_weighted": 0.009394595549389106,
                "main_score": 0.02360457296570275
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.32689979825151316,
                "f1": 0.2998657224895215,
                "f1_weighted": 0.3222231191644284,
                "main_score": 0.32689979825151316
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.3670477471418964,
                "f1": 0.3350288534893127,
                "f1_weighted": 0.34846130335010267,
                "main_score": 0.3670477471418964
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.0296906523201076,
                "f1": 0.007797856721437596,
                "f1_weighted": 0.006236996914225641,
                "main_score": 0.0296906523201076
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3101882985877606,
                "f1": 0.2952783595153932,
                "f1_weighted": 0.3066568514409952,
                "main_score": 0.3101882985877606
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.032178883658372556,
                "f1": 0.005240681583697773,
                "f1_weighted": 0.009198214868347652,
                "main_score": 0.032178883658372556
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.3711499663752522,
                "f1": 0.3636396173693096,
                "f1_weighted": 0.3550337761684995,
                "main_score": 0.3711499663752522
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.267350369872226,
                "f1": 0.25812896452146233,
                "f1_weighted": 0.262226872478251,
                "main_score": 0.267350369872226
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.34979825151311367,
                "f1": 0.32923163207299333,
                "f1_weighted": 0.3368424734170567,
                "main_score": 0.34979825151311367
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.01546738399462004,
                "f1": 0.006491922803798055,
                "f1_weighted": 0.003641605988268443,
                "main_score": 0.01546738399462004
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.2516476126429052,
                "f1": 0.23672187736335493,
                "f1_weighted": 0.236371559019449,
                "main_score": 0.2516476126429052
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.3379959650302623,
                "f1": 0.3251301308582213,
                "f1_weighted": 0.32526479564865307,
                "main_score": 0.3379959650302623
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.2949226630800269,
                "f1": 0.2894940260858102,
                "f1_weighted": 0.2863948113059682,
                "main_score": 0.2949226630800269
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.016778749159381306,
                "f1": 0.009744693901937154,
                "f1_weighted": 0.00691053805319416,
                "main_score": 0.016778749159381306
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.30114324142568927,
                "f1": 0.2943074303924215,
                "f1_weighted": 0.2904299307313548,
                "main_score": 0.30114324142568927
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.02797579018157364,
                "f1": 0.011440336883989878,
                "f1_weighted": 0.010884768126381035,
                "main_score": 0.02797579018157364
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.32545393409549417,
                "f1": 0.31521139537198317,
                "f1_weighted": 0.31530360085026093,
                "main_score": 0.32545393409549417
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.3078345662407532,
                "f1": 0.29604725003907867,
                "f1_weighted": 0.2968561702471573,
                "main_score": 0.3078345662407532
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.018426361802286483,
                "f1": 0.003354266679954325,
                "f1_weighted": 0.0027112769869272317,
                "main_score": 0.018426361802286483
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.3017821116341627,
                "f1": 0.29371324314631453,
                "f1_weighted": 0.2949445277730883,
                "main_score": 0.3017821116341627
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.02649630127774042,
                "f1": 0.017505098874789994,
                "f1_weighted": 0.014639682364635814,
                "main_score": 0.02649630127774042
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.04468728984532616,
                "f1": 0.020904611090427273,
                "f1_weighted": 0.027853674561791296,
                "main_score": 0.04468728984532616
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.33271687962340285,
                "f1": 0.3200481372908824,
                "f1_weighted": 0.32159041657111764,
                "main_score": 0.33271687962340285
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.00749831876260928,
                "f1": 0.0011432947296104062,
                "f1_weighted": 0.000764038848837725,
                "main_score": 0.00749831876260928
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.32125084061869535,
                "f1": 0.3015424794735825,
                "f1_weighted": 0.3087288096360447,
                "main_score": 0.32125084061869535
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.01617350369872226,
                "f1": 0.009905489260231543,
                "f1_weighted": 0.007953294182207199,
                "main_score": 0.01617350369872226
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.03806321452589106,
                "f1": 0.019196646149428953,
                "f1_weighted": 0.016645242984042585,
                "main_score": 0.03806321452589106
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.35776731674512446,
                "f1": 0.33180416181869754,
                "f1_weighted": 0.35833046113268785,
                "main_score": 0.35776731674512446
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.534969737726967,
                "f1": 0.5188341293441036,
                "f1_weighted": 0.5320514357568628,
                "main_score": 0.534969737726967
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.04784801613987895,
                "f1": 0.01969274839533907,
                "f1_weighted": 0.024942212470758018,
                "main_score": 0.04784801613987895
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.31069266980497645,
                "f1": 0.3148265427665997,
                "f1_weighted": 0.303696521492686,
                "main_score": 0.31069266980497645
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.01967047747141897,
                "f1": 0.004569736583152743,
                "f1_weighted": 0.002853963696007572,
                "main_score": 0.01967047747141897
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.021015467383994613,
                "f1": 0.005210481229705188,
                "f1_weighted": 0.005924944385210995,
                "main_score": 0.021015467383994613
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.31318090114324143,
                "f1": 0.3005810538658039,
                "f1_weighted": 0.30360376696442504,
                "main_score": 0.31318090114324143
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.19078681909885678,
                "f1": 0.18360818504390086,
                "f1_weighted": 0.1815470646878023,
                "main_score": 0.19078681909885678
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.35564895763281773,
                "f1": 0.35587064959631187,
                "f1_weighted": 0.344349962874478,
                "main_score": 0.35564895763281773
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.03211163416274378,
                "f1": 0.014524341197394975,
                "f1_weighted": 0.013395307357797507,
                "main_score": 0.03211163416274378
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.3399798251513114,
                "f1": 0.3269281167233965,
                "f1_weighted": 0.32228276413270845,
                "main_score": 0.3399798251513114
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.2966039004707465,
                "f1": 0.28090771859451535,
                "f1_weighted": 0.2950058846849659,
                "main_score": 0.2966039004707465
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.02118359112306658,
                "f1": 0.010794128790274702,
                "f1_weighted": 0.010149237288074577,
                "main_score": 0.02118359112306658
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.02242770679219906,
                "f1": 0.006772746623940161,
                "f1_weighted": 0.005935033259869644,
                "main_score": 0.02242770679219906
            }
        ]
    }
}