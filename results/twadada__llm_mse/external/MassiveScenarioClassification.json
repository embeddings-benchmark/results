{
    "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.047679892400807,
                "f1": 0.006958635242707643,
                "f1_weighted": 0.007383116540131966,
                "main_score": 0.047679892400807
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.04599865501008742,
                "f1": 0.008680195452904774,
                "f1_weighted": 0.013022709162006495,
                "main_score": 0.04599865501008742
            },
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.45800268997982513,
                "f1": 0.42091620849048555,
                "f1_weighted": 0.459378999845549,
                "main_score": 0.45800268997982513
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.07935440484196368,
                "f1": 0.02054473625082069,
                "f1_weighted": 0.02331310360179839,
                "main_score": 0.07935440484196368
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.39525891055817086,
                "f1": 0.3564315129468117,
                "f1_weighted": 0.38873288696604064,
                "main_score": 0.39525891055817086
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.16822461331540015,
                "f1": 0.09528868617590787,
                "f1_weighted": 0.12052833175443745,
                "main_score": 0.16822461331540015
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.4144922663080027,
                "f1": 0.38296945928165305,
                "f1_weighted": 0.4049468204923807,
                "main_score": 0.4144922663080027
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.3637525218560861,
                "f1": 0.32742079476295716,
                "f1_weighted": 0.3641453434396975,
                "main_score": 0.3637525218560861
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.4379959650302623,
                "f1": 0.4174604131799107,
                "f1_weighted": 0.4189697637112924,
                "main_score": 0.4379959650302623
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.0628446536650975,
                "f1": 0.011363404526147562,
                "f1_weighted": 0.01507290141564863,
                "main_score": 0.0628446536650975
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.05406859448554135,
                "f1": 0.025608171137075558,
                "f1_weighted": 0.02408341973383642,
                "main_score": 0.05406859448554135
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.43080026899798246,
                "f1": 0.39314911794007495,
                "f1_weighted": 0.42387701010649736,
                "main_score": 0.43080026899798246
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.4630127774041695,
                "f1": 0.43177548916667774,
                "f1_weighted": 0.46026411555293223,
                "main_score": 0.4630127774041695
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.05968392737054471,
                "f1": 0.015586443501019792,
                "f1_weighted": 0.021842777489914852,
                "main_score": 0.05968392737054471
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3908204438466712,
                "f1": 0.3719465931596499,
                "f1_weighted": 0.3792508333682256,
                "main_score": 0.3908204438466712
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.05712844653665097,
                "f1": 0.023513952725160447,
                "f1_weighted": 0.02591355133449796,
                "main_score": 0.05712844653665097
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.4479488903833221,
                "f1": 0.4221645601108651,
                "f1_weighted": 0.4363836497077992,
                "main_score": 0.4479488903833221
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.38910558170813725,
                "f1": 0.36658118919837707,
                "f1_weighted": 0.38285047658406185,
                "main_score": 0.38910558170813725
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.4282447881640888,
                "f1": 0.39711835765806264,
                "f1_weighted": 0.4299955794883917,
                "main_score": 0.4282447881640888
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.06956960322797578,
                "f1": 0.013249507928345722,
                "f1_weighted": 0.021526435195273513,
                "main_score": 0.06956960322797578
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.3547747141896436,
                "f1": 0.3268368628376791,
                "f1_weighted": 0.344862278541928,
                "main_score": 0.3547747141896436
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.4420645595158036,
                "f1": 0.4046275245484104,
                "f1_weighted": 0.4307451372640555,
                "main_score": 0.4420645595158036
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.3756556825823807,
                "f1": 0.34342284914676346,
                "f1_weighted": 0.36715470304700304,
                "main_score": 0.3756556825823807
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.044283792871553464,
                "f1": 0.02118733356397359,
                "f1_weighted": 0.016597464958411214,
                "main_score": 0.044283792871553464
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.34677202420981845,
                "f1": 0.31648714845929626,
                "f1_weighted": 0.34627828350618034,
                "main_score": 0.34677202420981845
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.08006052454606591,
                "f1": 0.021079480174137237,
                "f1_weighted": 0.021631918405037757,
                "main_score": 0.08006052454606591
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.39229993275050434,
                "f1": 0.3716721131021293,
                "f1_weighted": 0.3939761394985373,
                "main_score": 0.39229993275050434
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.4155010087424344,
                "f1": 0.3832223910141539,
                "f1_weighted": 0.41724988461607415,
                "main_score": 0.4155010087424344
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.03036314727639543,
                "f1": 0.004951111891349476,
                "f1_weighted": 0.004456347917226148,
                "main_score": 0.03036314727639543
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.4284801613987895,
                "f1": 0.4077209890733345,
                "f1_weighted": 0.4229511181907119,
                "main_score": 0.4284801613987895
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.08140551445864155,
                "f1": 0.03088889182397252,
                "f1_weighted": 0.03382529160821981,
                "main_score": 0.08140551445864155
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.10063887020847342,
                "f1": 0.04395390629812042,
                "f1_weighted": 0.06103036063037068,
                "main_score": 0.10063887020847342
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.4086079354404843,
                "f1": 0.38128484307335886,
                "f1_weighted": 0.39613998182070775,
                "main_score": 0.4086079354404843
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.031809011432414255,
                "f1": 0.006663078501713696,
                "f1_weighted": 0.006161504543566888,
                "main_score": 0.031809011432414255
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.38991257565568255,
                "f1": 0.358711142606479,
                "f1_weighted": 0.39270589149968216,
                "main_score": 0.38991257565568255
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.07511768661735037,
                "f1": 0.027303332361770002,
                "f1_weighted": 0.02476626926704587,
                "main_score": 0.07511768661735037
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.0832548755884331,
                "f1": 0.030996007067176996,
                "f1_weighted": 0.030676442629069968,
                "main_score": 0.0832548755884331
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.47579018157363817,
                "f1": 0.43473657423573087,
                "f1_weighted": 0.47581511497169765,
                "main_score": 0.47579018157363817
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6384330867518494,
                "f1": 0.6180623184800081,
                "f1_weighted": 0.6366823920852459,
                "main_score": 0.6384330867518494
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.10060524546065905,
                "f1": 0.04697788726183898,
                "f1_weighted": 0.080688374518688,
                "main_score": 0.10060524546065905
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.3902824478816409,
                "f1": 0.3725613303442762,
                "f1_weighted": 0.3822861284484312,
                "main_score": 0.3902824478816409
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.05063887020847344,
                "f1": 0.010753261358276471,
                "f1_weighted": 0.010802883978030118,
                "main_score": 0.05063887020847344
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.06321452589105583,
                "f1": 0.015829376262790663,
                "f1_weighted": 0.02232184358298365,
                "main_score": 0.06321452589105583
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.3721923335574983,
                "f1": 0.36993268170979576,
                "f1_weighted": 0.3567645464322424,
                "main_score": 0.3721923335574983
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.25934767989240076,
                "f1": 0.24616943306685748,
                "f1_weighted": 0.24743092855694168,
                "main_score": 0.25934767989240076
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.4469401479488904,
                "f1": 0.4241464498194295,
                "f1_weighted": 0.4426134318268762,
                "main_score": 0.4469401479488904
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.0847343644922663,
                "f1": 0.029718553546241505,
                "f1_weighted": 0.03944993022942082,
                "main_score": 0.0847343644922663
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.4292199058507061,
                "f1": 0.4000185738475351,
                "f1_weighted": 0.42538384351130887,
                "main_score": 0.4292199058507061
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.36856086079354405,
                "f1": 0.3585809216604705,
                "f1_weighted": 0.36503220372495354,
                "main_score": 0.36856086079354405
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.07427706792199058,
                "f1": 0.023556492212814327,
                "f1_weighted": 0.023635737714890095,
                "main_score": 0.07427706792199058
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.07249495628782784,
                "f1": 0.030267066892790784,
                "f1_weighted": 0.02228737132597149,
                "main_score": 0.07249495628782784
            }
        ]
    }
}