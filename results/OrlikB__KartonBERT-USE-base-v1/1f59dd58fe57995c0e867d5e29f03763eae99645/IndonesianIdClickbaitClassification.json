{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.583447,
        "f1": 0.579352,
        "f1_weighted": 0.583995,
        "ap": 0.471783,
        "ap_weighted": 0.471783,
        "scores_per_experiment": [
          {
            "accuracy": 0.650879,
            "f1": 0.638634,
            "f1_weighted": 0.649352,
            "ap": 0.513607,
            "ap_weighted": 0.513607
          },
          {
            "accuracy": 0.588379,
            "f1": 0.586474,
            "f1_weighted": 0.590996,
            "ap": 0.474152,
            "ap_weighted": 0.474152
          },
          {
            "accuracy": 0.557129,
            "f1": 0.551522,
            "f1_weighted": 0.559602,
            "ap": 0.448931,
            "ap_weighted": 0.448931
          },
          {
            "accuracy": 0.591797,
            "f1": 0.5907,
            "f1_weighted": 0.587287,
            "ap": 0.488055,
            "ap_weighted": 0.488055
          },
          {
            "accuracy": 0.580078,
            "f1": 0.579529,
            "f1_weighted": 0.581977,
            "ap": 0.471384,
            "ap_weighted": 0.471384
          },
          {
            "accuracy": 0.54541,
            "f1": 0.53924,
            "f1_weighted": 0.547831,
            "ap": 0.441332,
            "ap_weighted": 0.441332
          },
          {
            "accuracy": 0.567383,
            "f1": 0.558901,
            "f1_weighted": 0.568757,
            "ap": 0.452984,
            "ap_weighted": 0.452984
          },
          {
            "accuracy": 0.616211,
            "f1": 0.616149,
            "f1_weighted": 0.616934,
            "ap": 0.499976,
            "ap_weighted": 0.499976
          },
          {
            "accuracy": 0.558594,
            "f1": 0.558189,
            "f1_weighted": 0.556034,
            "ap": 0.463364,
            "ap_weighted": 0.463364
          },
          {
            "accuracy": 0.578613,
            "f1": 0.574179,
            "f1_weighted": 0.581181,
            "ap": 0.464044,
            "ap_weighted": 0.464044
          }
        ],
        "main_score": 0.579352,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.657482147216797,
  "kg_co2_emissions": 0.0002373145644194551
}