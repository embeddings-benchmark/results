{
    "dataset_revision": "e6b647fcb6299a2f686f742f4d4c023e553ea67e",
    "task_name": "FloresBitextMining",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "devtest": [
            {
                "hf_subset": "ace_Arab-pol_Latn",
                "languages": [
                    "ace-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.00592885375494071,
                "f1": 0.0031813502689031644,
                "main_score": 0.0031813502689031644,
                "precision": 0.0030839411484572775,
                "recall": 0.00592885375494071
            },
            {
                "hf_subset": "bam_Latn-pol_Latn",
                "languages": [
                    "bam-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.22727272727272727,
                "f1": 0.18856205163673437,
                "main_score": 0.18856205163673437,
                "precision": 0.1785357415508634,
                "recall": 0.22727272727272727
            },
            {
                "hf_subset": "dzo_Tibt-pol_Latn",
                "languages": [
                    "dzo-Tibt",
                    "pol-Latn"
                ],
                "accuracy": 0.001976284584980237,
                "f1": 0.0009900990099009901,
                "main_score": 0.0009900990099009901,
                "precision": 0.0009891216208275716,
                "recall": 0.001976284584980237
            },
            {
                "hf_subset": "hin_Deva-pol_Latn",
                "languages": [
                    "hin-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.039525691699604744,
                "f1": 0.028974961138992762,
                "main_score": 0.028974961138992762,
                "precision": 0.02611381778726582,
                "recall": 0.039525691699604744
            },
            {
                "hf_subset": "khm_Khmr-pol_Latn",
                "languages": [
                    "khm-Khmr",
                    "pol-Latn"
                ],
                "accuracy": 0.2341897233201581,
                "f1": 0.21422759388174406,
                "main_score": 0.21422759388174406,
                "precision": 0.207400345871417,
                "recall": 0.2341897233201581
            },
            {
                "hf_subset": "mag_Deva-pol_Latn",
                "languages": [
                    "mag-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.03458498023715415,
                "f1": 0.02622018112486536,
                "main_score": 0.02622018112486536,
                "precision": 0.02453759557785889,
                "recall": 0.03458498023715415
            },
            {
                "hf_subset": "pap_Latn-pol_Latn",
                "languages": [
                    "pap-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.39031620553359686,
                "f1": 0.3530015219760418,
                "main_score": 0.3530015219760418,
                "precision": 0.3415844644794522,
                "recall": 0.39031620553359686
            },
            {
                "hf_subset": "sot_Latn-pol_Latn",
                "languages": [
                    "sot-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2015810276679842,
                "f1": 0.1769223633337849,
                "main_score": 0.1769223633337849,
                "precision": 0.1709807029485207,
                "recall": 0.2015810276679842
            },
            {
                "hf_subset": "tur_Latn-pol_Latn",
                "languages": [
                    "tur-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.24703557312252966,
                "f1": 0.21291771228038509,
                "main_score": 0.21291771228038509,
                "precision": 0.20347923439427462,
                "recall": 0.24703557312252966
            },
            {
                "hf_subset": "ace_Latn-pol_Latn",
                "languages": [
                    "ace-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.25889328063241107,
                "f1": 0.2306308953172751,
                "main_score": 0.2306308953172751,
                "precision": 0.2224893068053073,
                "recall": 0.25889328063241107
            },
            {
                "hf_subset": "ban_Latn-pol_Latn",
                "languages": [
                    "ban-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2549407114624506,
                "f1": 0.22007814923395513,
                "main_score": 0.22007814923395513,
                "precision": 0.21188010298532411,
                "recall": 0.2549407114624506
            },
            {
                "hf_subset": "ell_Grek-pol_Latn",
                "languages": [
                    "ell-Grek",
                    "pol-Latn"
                ],
                "accuracy": 0.08102766798418973,
                "f1": 0.06988965766514098,
                "main_score": 0.06988965766514098,
                "precision": 0.06712602330760323,
                "recall": 0.08102766798418973
            },
            {
                "hf_subset": "hne_Deva-pol_Latn",
                "languages": [
                    "hne-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.02371541501976284,
                "f1": 0.016313787028973608,
                "main_score": 0.016313787028973608,
                "precision": 0.014932697009729146,
                "recall": 0.02371541501976284
            },
            {
                "hf_subset": "kik_Latn-pol_Latn",
                "languages": [
                    "kik-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3231225296442688,
                "f1": 0.2711144962100094,
                "main_score": 0.2711144962100094,
                "precision": 0.2553133982182309,
                "recall": 0.3231225296442688
            },
            {
                "hf_subset": "mai_Deva-pol_Latn",
                "languages": [
                    "mai-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.05039525691699605,
                "f1": 0.03966855997318039,
                "main_score": 0.03966855997318039,
                "precision": 0.036789065258502125,
                "recall": 0.05039525691699605
            },
            {
                "hf_subset": "pbt_Arab-pol_Latn",
                "languages": [
                    "pbt-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.09782608695652174,
                "f1": 0.09121288821137288,
                "main_score": 0.09121288821137288,
                "precision": 0.08943568976230727,
                "recall": 0.09782608695652174
            },
            {
                "hf_subset": "spa_Latn-pol_Latn",
                "languages": [
                    "spa-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3142292490118577,
                "f1": 0.29667689384840473,
                "main_score": 0.29667689384840473,
                "precision": 0.29105673047225344,
                "recall": 0.3142292490118577
            },
            {
                "hf_subset": "twi_Latn-pol_Latn",
                "languages": [
                    "twi-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3616600790513834,
                "f1": 0.31626095086908773,
                "main_score": 0.31626095086908773,
                "precision": 0.3019878488870083,
                "recall": 0.3616600790513834
            },
            {
                "hf_subset": "acm_Arab-pol_Latn",
                "languages": [
                    "acm-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.03557312252964427,
                "f1": 0.02721978575559138,
                "main_score": 0.02721978575559138,
                "precision": 0.02528307139720183,
                "recall": 0.03557312252964427
            },
            {
                "hf_subset": "bel_Cyrl-pol_Latn",
                "languages": [
                    "bel-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.036561264822134384,
                "f1": 0.02831898415680433,
                "main_score": 0.02831898415680433,
                "precision": 0.02683681277663466,
                "recall": 0.036561264822134384
            },
            {
                "hf_subset": "eng_Latn-pol_Latn",
                "languages": [
                    "eng-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.9990118577075099,
                "f1": 0.9986824769433464,
                "main_score": 0.9986824769433464,
                "precision": 0.9985177865612649,
                "recall": 0.9990118577075099
            },
            {
                "hf_subset": "hrv_Latn-pol_Latn",
                "languages": [
                    "hrv-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3952569169960474,
                "f1": 0.3467037471251808,
                "main_score": 0.3467037471251808,
                "precision": 0.33328422364463184,
                "recall": 0.3952569169960474
            },
            {
                "hf_subset": "kin_Latn-pol_Latn",
                "languages": [
                    "kin-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.16798418972332016,
                "f1": 0.14429336215660468,
                "main_score": 0.14429336215660468,
                "precision": 0.137941640217131,
                "recall": 0.16798418972332016
            },
            {
                "hf_subset": "mal_Mlym-pol_Latn",
                "languages": [
                    "mal-Mlym",
                    "pol-Latn"
                ],
                "accuracy": 0.03359683794466403,
                "f1": 0.024283903952876284,
                "main_score": 0.024283903952876284,
                "precision": 0.022272021456804066,
                "recall": 0.03359683794466403
            },
            {
                "hf_subset": "pes_Arab-pol_Latn",
                "languages": [
                    "pes-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.07312252964426877,
                "f1": 0.061336451830851436,
                "main_score": 0.061336451830851436,
                "precision": 0.05840438054980056,
                "recall": 0.07312252964426877
            },
            {
                "hf_subset": "srd_Latn-pol_Latn",
                "languages": [
                    "srd-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2737154150197628,
                "f1": 0.24557303562561367,
                "main_score": 0.24557303562561367,
                "precision": 0.23697336179036038,
                "recall": 0.2737154150197628
            },
            {
                "hf_subset": "tzm_Tfng-pol_Latn",
                "languages": [
                    "tzm-Tfng",
                    "pol-Latn"
                ],
                "accuracy": 0.036561264822134384,
                "f1": 0.027323453897955784,
                "main_score": 0.027323453897955784,
                "precision": 0.025125182239806743,
                "recall": 0.036561264822134384
            },
            {
                "hf_subset": "acq_Arab-pol_Latn",
                "languages": [
                    "acq-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.036561264822134384,
                "f1": 0.027828303630661636,
                "main_score": 0.027828303630661636,
                "precision": 0.026216215063238377,
                "recall": 0.036561264822134384
            },
            {
                "hf_subset": "bem_Latn-pol_Latn",
                "languages": [
                    "bem-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2341897233201581,
                "f1": 0.2018154247440937,
                "main_score": 0.2018154247440937,
                "precision": 0.19337227107086583,
                "recall": 0.2341897233201581
            },
            {
                "hf_subset": "epo_Latn-pol_Latn",
                "languages": [
                    "epo-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3458498023715415,
                "f1": 0.31141139192708855,
                "main_score": 0.31141139192708855,
                "precision": 0.30228963674031845,
                "recall": 0.3458498023715415
            },
            {
                "hf_subset": "hun_Latn-pol_Latn",
                "languages": [
                    "hun-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.21837944664031622,
                "f1": 0.18382660044834967,
                "main_score": 0.18382660044834967,
                "precision": 0.17623881542048112,
                "recall": 0.21837944664031622
            },
            {
                "hf_subset": "kir_Cyrl-pol_Latn",
                "languages": [
                    "kir-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.05731225296442687,
                "f1": 0.04390398521734955,
                "main_score": 0.04390398521734955,
                "precision": 0.04083283520585645,
                "recall": 0.05731225296442687
            },
            {
                "hf_subset": "mar_Deva-pol_Latn",
                "languages": [
                    "mar-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.03359683794466403,
                "f1": 0.028885124537298447,
                "main_score": 0.028885124537298447,
                "precision": 0.027483235363670144,
                "recall": 0.03359683794466403
            },
            {
                "hf_subset": "plt_Latn-pol_Latn",
                "languages": [
                    "plt-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.17490118577075098,
                "f1": 0.14096422773395406,
                "main_score": 0.14096422773395406,
                "precision": 0.13352882758512802,
                "recall": 0.17490118577075098
            },
            {
                "hf_subset": "srp_Cyrl-pol_Latn",
                "languages": [
                    "srp-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.04940711462450593,
                "f1": 0.03946413096320095,
                "main_score": 0.03946413096320095,
                "precision": 0.036485591702983,
                "recall": 0.04940711462450593
            },
            {
                "hf_subset": "uig_Arab-pol_Latn",
                "languages": [
                    "uig-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.06422924901185771,
                "f1": 0.05005627451279625,
                "main_score": 0.05005627451279625,
                "precision": 0.046413820989596954,
                "recall": 0.06422924901185771
            },
            {
                "hf_subset": "aeb_Arab-pol_Latn",
                "languages": [
                    "aeb-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.03557312252964427,
                "f1": 0.026480295253947593,
                "main_score": 0.026480295253947593,
                "precision": 0.024734523333559955,
                "recall": 0.03557312252964427
            },
            {
                "hf_subset": "ben_Beng-pol_Latn",
                "languages": [
                    "ben-Beng",
                    "pol-Latn"
                ],
                "accuracy": 0.03458498023715415,
                "f1": 0.029105495953322034,
                "main_score": 0.029105495953322034,
                "precision": 0.027819736015310455,
                "recall": 0.03458498023715415
            },
            {
                "hf_subset": "est_Latn-pol_Latn",
                "languages": [
                    "est-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.23122529644268774,
                "f1": 0.19955099258098155,
                "main_score": 0.19955099258098155,
                "precision": 0.19234950747940383,
                "recall": 0.23122529644268774
            },
            {
                "hf_subset": "hye_Armn-pol_Latn",
                "languages": [
                    "hye-Armn",
                    "pol-Latn"
                ],
                "accuracy": 0.04446640316205533,
                "f1": 0.03276824071174438,
                "main_score": 0.03276824071174438,
                "precision": 0.030602119144770373,
                "recall": 0.04446640316205533
            },
            {
                "hf_subset": "kmb_Latn-pol_Latn",
                "languages": [
                    "kmb-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1432806324110672,
                "f1": 0.12331135021968531,
                "main_score": 0.12331135021968531,
                "precision": 0.11919953641888731,
                "recall": 0.1432806324110672
            },
            {
                "hf_subset": "min_Arab-pol_Latn",
                "languages": [
                    "min-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.003952569169960474,
                "f1": 0.0020182057731464847,
                "main_score": 0.0020182057731464847,
                "precision": 0.001997649956026004,
                "recall": 0.003952569169960474
            },
            {
                "hf_subset": "pol_Latn-ace_Arab",
                "languages": [
                    "pol-Latn",
                    "ace-Arab"
                ],
                "accuracy": 0.00592885375494071,
                "f1": 0.0007409945181279336,
                "main_score": 0.0007409945181279336,
                "precision": 0.0004302453996987383,
                "recall": 0.00592885375494071
            },
            {
                "hf_subset": "pol_Latn-bam_Latn",
                "languages": [
                    "pol-Latn",
                    "bam-Latn"
                ],
                "accuracy": 0.2440711462450593,
                "f1": 0.19400581302755213,
                "main_score": 0.19400581302755213,
                "precision": 0.17845439584570016,
                "recall": 0.2440711462450593
            },
            {
                "hf_subset": "pol_Latn-dzo_Tibt",
                "languages": [
                    "pol-Latn",
                    "dzo-Tibt"
                ],
                "accuracy": 0.002964426877470355,
                "f1": 9.811695142164987e-05,
                "main_score": 9.811695142164987e-05,
                "precision": 5.0884024043885246e-05,
                "recall": 0.002964426877470355
            },
            {
                "hf_subset": "pol_Latn-hin_Deva",
                "languages": [
                    "pol-Latn",
                    "hin-Deva"
                ],
                "accuracy": 0.07806324110671936,
                "f1": 0.04700948820933142,
                "main_score": 0.04700948820933142,
                "precision": 0.040854030940120814,
                "recall": 0.07806324110671936
            },
            {
                "hf_subset": "pol_Latn-khm_Khmr",
                "languages": [
                    "pol-Latn",
                    "khm-Khmr"
                ],
                "accuracy": 0.2845849802371542,
                "f1": 0.2092065310102013,
                "main_score": 0.2092065310102013,
                "precision": 0.18878444679295003,
                "recall": 0.2845849802371542
            },
            {
                "hf_subset": "pol_Latn-mag_Deva",
                "languages": [
                    "pol-Latn",
                    "mag-Deva"
                ],
                "accuracy": 0.07905138339920949,
                "f1": 0.047160981251785764,
                "main_score": 0.047160981251785764,
                "precision": 0.04084836368220641,
                "recall": 0.07905138339920949
            },
            {
                "hf_subset": "pol_Latn-pap_Latn",
                "languages": [
                    "pol-Latn",
                    "pap-Latn"
                ],
                "accuracy": 0.484189723320158,
                "f1": 0.39218444953739073,
                "main_score": 0.39218444953739073,
                "precision": 0.35952518194366023,
                "recall": 0.484189723320158
            },
            {
                "hf_subset": "pol_Latn-sot_Latn",
                "languages": [
                    "pol-Latn",
                    "sot-Latn"
                ],
                "accuracy": 0.2924901185770751,
                "f1": 0.20207185491276397,
                "main_score": 0.20207185491276397,
                "precision": 0.1768396896330731,
                "recall": 0.2924901185770751
            },
            {
                "hf_subset": "pol_Latn-tur_Latn",
                "languages": [
                    "pol-Latn",
                    "tur-Latn"
                ],
                "accuracy": 0.2984189723320158,
                "f1": 0.23310580092941754,
                "main_score": 0.23310580092941754,
                "precision": 0.21514647110720042,
                "recall": 0.2984189723320158
            },
            {
                "hf_subset": "pol_Latn-ace_Latn",
                "languages": [
                    "pol-Latn",
                    "ace-Latn"
                ],
                "accuracy": 0.35276679841897235,
                "f1": 0.2656043312355645,
                "main_score": 0.2656043312355645,
                "precision": 0.24029183691544187,
                "recall": 0.35276679841897235
            },
            {
                "hf_subset": "pol_Latn-ban_Latn",
                "languages": [
                    "pol-Latn",
                    "ban-Latn"
                ],
                "accuracy": 0.34288537549407117,
                "f1": 0.2531387739735394,
                "main_score": 0.2531387739735394,
                "precision": 0.22630872914963823,
                "recall": 0.34288537549407117
            },
            {
                "hf_subset": "pol_Latn-ell_Grek",
                "languages": [
                    "pol-Latn",
                    "ell-Grek"
                ],
                "accuracy": 0.12944664031620554,
                "f1": 0.07700420087043759,
                "main_score": 0.07700420087043759,
                "precision": 0.06557677527690299,
                "recall": 0.12944664031620554
            },
            {
                "hf_subset": "pol_Latn-hne_Deva",
                "languages": [
                    "pol-Latn",
                    "hne-Deva"
                ],
                "accuracy": 0.06027667984189724,
                "f1": 0.03744915337258828,
                "main_score": 0.03744915337258828,
                "precision": 0.03233029505119999,
                "recall": 0.06027667984189724
            },
            {
                "hf_subset": "pol_Latn-kik_Latn",
                "languages": [
                    "pol-Latn",
                    "kik-Latn"
                ],
                "accuracy": 0.33794466403162055,
                "f1": 0.27039119650545695,
                "main_score": 0.27039119650545695,
                "precision": 0.24780510943296644,
                "recall": 0.33794466403162055
            },
            {
                "hf_subset": "pol_Latn-mai_Deva",
                "languages": [
                    "pol-Latn",
                    "mai-Deva"
                ],
                "accuracy": 0.09683794466403162,
                "f1": 0.06347035635402815,
                "main_score": 0.06347035635402815,
                "precision": 0.05645462573386804,
                "recall": 0.09683794466403162
            },
            {
                "hf_subset": "pol_Latn-pbt_Arab",
                "languages": [
                    "pol-Latn",
                    "pbt-Arab"
                ],
                "accuracy": 0.1383399209486166,
                "f1": 0.08577476120246123,
                "main_score": 0.08577476120246123,
                "precision": 0.0730730110742227,
                "recall": 0.1383399209486166
            },
            {
                "hf_subset": "pol_Latn-spa_Latn",
                "languages": [
                    "pol-Latn",
                    "spa-Latn"
                ],
                "accuracy": 0.5543478260869565,
                "f1": 0.4704059938743733,
                "main_score": 0.4704059938743733,
                "precision": 0.43965198997313626,
                "recall": 0.5543478260869565
            },
            {
                "hf_subset": "pol_Latn-twi_Latn",
                "languages": [
                    "pol-Latn",
                    "twi-Latn"
                ],
                "accuracy": 0.3695652173913043,
                "f1": 0.2921397478622543,
                "main_score": 0.2921397478622543,
                "precision": 0.2667718658701861,
                "recall": 0.3695652173913043
            },
            {
                "hf_subset": "pol_Latn-acm_Arab",
                "languages": [
                    "pol-Latn",
                    "acm-Arab"
                ],
                "accuracy": 0.07015810276679842,
                "f1": 0.03868978838437569,
                "main_score": 0.03868978838437569,
                "precision": 0.03295533948722674,
                "recall": 0.07015810276679842
            },
            {
                "hf_subset": "pol_Latn-bel_Cyrl",
                "languages": [
                    "pol-Latn",
                    "bel-Cyrl"
                ],
                "accuracy": 0.07312252964426877,
                "f1": 0.04433740291213768,
                "main_score": 0.04433740291213768,
                "precision": 0.03768579954549665,
                "recall": 0.07312252964426877
            },
            {
                "hf_subset": "pol_Latn-eng_Latn",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 0.9881422924901186,
                "f1": 0.9841897233201581,
                "main_score": 0.9841897233201581,
                "precision": 0.9822134387351779,
                "recall": 0.9881422924901186
            },
            {
                "hf_subset": "pol_Latn-hrv_Latn",
                "languages": [
                    "pol-Latn",
                    "hrv-Latn"
                ],
                "accuracy": 0.41798418972332013,
                "f1": 0.3401400189073114,
                "main_score": 0.3401400189073114,
                "precision": 0.314615696984529,
                "recall": 0.41798418972332013
            },
            {
                "hf_subset": "pol_Latn-kin_Latn",
                "languages": [
                    "pol-Latn",
                    "kin-Latn"
                ],
                "accuracy": 0.22134387351778656,
                "f1": 0.14941913199793064,
                "main_score": 0.14941913199793064,
                "precision": 0.1309437075957867,
                "recall": 0.22134387351778656
            },
            {
                "hf_subset": "pol_Latn-mal_Mlym",
                "languages": [
                    "pol-Latn",
                    "mal-Mlym"
                ],
                "accuracy": 0.07905138339920949,
                "f1": 0.04676431663013731,
                "main_score": 0.04676431663013731,
                "precision": 0.03963416458591999,
                "recall": 0.07905138339920949
            },
            {
                "hf_subset": "pol_Latn-pes_Arab",
                "languages": [
                    "pol-Latn",
                    "pes-Arab"
                ],
                "accuracy": 0.116600790513834,
                "f1": 0.07168267060928982,
                "main_score": 0.07168267060928982,
                "precision": 0.06158810820381868,
                "recall": 0.116600790513834
            },
            {
                "hf_subset": "pol_Latn-srd_Latn",
                "languages": [
                    "pol-Latn",
                    "srd-Latn"
                ],
                "accuracy": 0.39723320158102765,
                "f1": 0.31331230254155157,
                "main_score": 0.31331230254155157,
                "precision": 0.2857614114037038,
                "recall": 0.39723320158102765
            },
            {
                "hf_subset": "pol_Latn-tzm_Tfng",
                "languages": [
                    "pol-Latn",
                    "tzm-Tfng"
                ],
                "accuracy": 0.07312252964426877,
                "f1": 0.03953050110519504,
                "main_score": 0.03953050110519504,
                "precision": 0.033006450734694784,
                "recall": 0.07312252964426877
            },
            {
                "hf_subset": "pol_Latn-acq_Arab",
                "languages": [
                    "pol-Latn",
                    "acq-Arab"
                ],
                "accuracy": 0.06521739130434782,
                "f1": 0.037118615772057086,
                "main_score": 0.037118615772057086,
                "precision": 0.03140963634812984,
                "recall": 0.06521739130434782
            },
            {
                "hf_subset": "pol_Latn-bem_Latn",
                "languages": [
                    "pol-Latn",
                    "bem-Latn"
                ],
                "accuracy": 0.2994071146245059,
                "f1": 0.21838134223625963,
                "main_score": 0.21838134223625963,
                "precision": 0.19601437433830296,
                "recall": 0.2994071146245059
            },
            {
                "hf_subset": "pol_Latn-epo_Latn",
                "languages": [
                    "pol-Latn",
                    "epo-Latn"
                ],
                "accuracy": 0.4525691699604743,
                "f1": 0.37470343665995837,
                "main_score": 0.37470343665995837,
                "precision": 0.3491015394428969,
                "recall": 0.4525691699604743
            },
            {
                "hf_subset": "pol_Latn-hun_Latn",
                "languages": [
                    "pol-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.2776679841897233,
                "f1": 0.19856585262886126,
                "main_score": 0.19856585262886126,
                "precision": 0.17632943238979626,
                "recall": 0.2776679841897233
            },
            {
                "hf_subset": "pol_Latn-kir_Cyrl",
                "languages": [
                    "pol-Latn",
                    "kir-Cyrl"
                ],
                "accuracy": 0.099802371541502,
                "f1": 0.059767120306820375,
                "main_score": 0.059767120306820375,
                "precision": 0.0511681055512279,
                "recall": 0.099802371541502
            },
            {
                "hf_subset": "pol_Latn-mar_Deva",
                "languages": [
                    "pol-Latn",
                    "mar-Deva"
                ],
                "accuracy": 0.07312252964426877,
                "f1": 0.04145286234223563,
                "main_score": 0.04145286234223563,
                "precision": 0.035337956030345036,
                "recall": 0.07312252964426877
            },
            {
                "hf_subset": "pol_Latn-plt_Latn",
                "languages": [
                    "pol-Latn",
                    "plt-Latn"
                ],
                "accuracy": 0.2490118577075099,
                "f1": 0.18082595637436008,
                "main_score": 0.18082595637436008,
                "precision": 0.1616756856262583,
                "recall": 0.2490118577075099
            },
            {
                "hf_subset": "pol_Latn-srp_Cyrl",
                "languages": [
                    "pol-Latn",
                    "srp-Cyrl"
                ],
                "accuracy": 0.07806324110671936,
                "f1": 0.04668414246710413,
                "main_score": 0.04668414246710413,
                "precision": 0.0407016381507616,
                "recall": 0.07806324110671936
            },
            {
                "hf_subset": "pol_Latn-uig_Arab",
                "languages": [
                    "pol-Latn",
                    "uig-Arab"
                ],
                "accuracy": 0.0958498023715415,
                "f1": 0.05958798680475491,
                "main_score": 0.05958798680475491,
                "precision": 0.05117749787379275,
                "recall": 0.0958498023715415
            },
            {
                "hf_subset": "pol_Latn-aeb_Arab",
                "languages": [
                    "pol-Latn",
                    "aeb-Arab"
                ],
                "accuracy": 0.06818181818181818,
                "f1": 0.0375515263763757,
                "main_score": 0.0375515263763757,
                "precision": 0.03158241617055616,
                "recall": 0.06818181818181818
            },
            {
                "hf_subset": "pol_Latn-ben_Beng",
                "languages": [
                    "pol-Latn",
                    "ben-Beng"
                ],
                "accuracy": 0.07608695652173914,
                "f1": 0.04041225756257413,
                "main_score": 0.04041225756257413,
                "precision": 0.03324217301397562,
                "recall": 0.07608695652173914
            },
            {
                "hf_subset": "pol_Latn-est_Latn",
                "languages": [
                    "pol-Latn",
                    "est-Latn"
                ],
                "accuracy": 0.29347826086956524,
                "f1": 0.2232776391373229,
                "main_score": 0.2232776391373229,
                "precision": 0.2028155876476035,
                "recall": 0.29347826086956524
            },
            {
                "hf_subset": "pol_Latn-hye_Armn",
                "languages": [
                    "pol-Latn",
                    "hye-Armn"
                ],
                "accuracy": 0.08992094861660078,
                "f1": 0.05410264691947379,
                "main_score": 0.05410264691947379,
                "precision": 0.04551435410943297,
                "recall": 0.08992094861660078
            },
            {
                "hf_subset": "pol_Latn-kmb_Latn",
                "languages": [
                    "pol-Latn",
                    "kmb-Latn"
                ],
                "accuracy": 0.22332015810276679,
                "f1": 0.15508983949241995,
                "main_score": 0.15508983949241995,
                "precision": 0.1384626446237118,
                "recall": 0.22332015810276679
            },
            {
                "hf_subset": "pol_Latn-min_Arab",
                "languages": [
                    "pol-Latn",
                    "min-Arab"
                ],
                "accuracy": 0.004940711462450593,
                "f1": 0.001263500946050829,
                "main_score": 0.001263500946050829,
                "precision": 0.001133716826651609,
                "recall": 0.004940711462450593
            },
            {
                "hf_subset": "pol_Latn-ssw_Latn",
                "languages": [
                    "pol-Latn",
                    "ssw-Latn"
                ],
                "accuracy": 0.20948616600790515,
                "f1": 0.1373781897880792,
                "main_score": 0.1373781897880792,
                "precision": 0.118912676418156,
                "recall": 0.20948616600790515
            },
            {
                "hf_subset": "pol_Latn-ukr_Cyrl",
                "languages": [
                    "pol-Latn",
                    "ukr-Cyrl"
                ],
                "accuracy": 0.07015810276679842,
                "f1": 0.03949638010614578,
                "main_score": 0.03949638010614578,
                "precision": 0.03351660503470364,
                "recall": 0.07015810276679842
            },
            {
                "hf_subset": "pol_Latn-afr_Latn",
                "languages": [
                    "pol-Latn",
                    "afr-Latn"
                ],
                "accuracy": 0.4278656126482213,
                "f1": 0.34601393789613416,
                "main_score": 0.34601393789613416,
                "precision": 0.3204002903113575,
                "recall": 0.4278656126482213
            },
            {
                "hf_subset": "pol_Latn-bho_Deva",
                "languages": [
                    "pol-Latn",
                    "bho-Deva"
                ],
                "accuracy": 0.08893280632411066,
                "f1": 0.05424250733521232,
                "main_score": 0.05424250733521232,
                "precision": 0.04684065066948802,
                "recall": 0.08893280632411066
            },
            {
                "hf_subset": "pol_Latn-eus_Latn",
                "languages": [
                    "pol-Latn",
                    "eus-Latn"
                ],
                "accuracy": 0.37944664031620545,
                "f1": 0.29129736096139264,
                "main_score": 0.29129736096139264,
                "precision": 0.2627383239290354,
                "recall": 0.37944664031620545
            },
            {
                "hf_subset": "pol_Latn-ibo_Latn",
                "languages": [
                    "pol-Latn",
                    "ibo-Latn"
                ],
                "accuracy": 0.22826086956521738,
                "f1": 0.18160396366918102,
                "main_score": 0.18160396366918102,
                "precision": 0.16684985798128088,
                "recall": 0.22826086956521738
            },
            {
                "hf_subset": "pol_Latn-kmr_Latn",
                "languages": [
                    "pol-Latn",
                    "kmr-Latn"
                ],
                "accuracy": 0.21837944664031622,
                "f1": 0.1669834842262613,
                "main_score": 0.1669834842262613,
                "precision": 0.15096012124362324,
                "recall": 0.21837944664031622
            },
            {
                "hf_subset": "pol_Latn-min_Latn",
                "languages": [
                    "pol-Latn",
                    "min-Latn"
                ],
                "accuracy": 0.33992094861660077,
                "f1": 0.2543466716638653,
                "main_score": 0.2543466716638653,
                "precision": 0.2289181280773553,
                "recall": 0.33992094861660077
            },
            {
                "hf_subset": "pol_Latn-por_Latn",
                "languages": [
                    "pol-Latn",
                    "por-Latn"
                ],
                "accuracy": 0.48715415019762853,
                "f1": 0.39942804779761304,
                "main_score": 0.39942804779761304,
                "precision": 0.36890331890331896,
                "recall": 0.48715415019762853
            },
            {
                "hf_subset": "pol_Latn-sun_Latn",
                "languages": [
                    "pol-Latn",
                    "sun-Latn"
                ],
                "accuracy": 0.3438735177865613,
                "f1": 0.26088610555013714,
                "main_score": 0.26088610555013714,
                "precision": 0.23446165940473382,
                "recall": 0.3438735177865613
            },
            {
                "hf_subset": "pol_Latn-umb_Latn",
                "languages": [
                    "pol-Latn",
                    "umb-Latn"
                ],
                "accuracy": 0.2134387351778656,
                "f1": 0.1503361444124914,
                "main_score": 0.1503361444124914,
                "precision": 0.1345762792310757,
                "recall": 0.2134387351778656
            },
            {
                "hf_subset": "pol_Latn-ajp_Arab",
                "languages": [
                    "pol-Latn",
                    "ajp-Arab"
                ],
                "accuracy": 0.09288537549407115,
                "f1": 0.054140323353600375,
                "main_score": 0.054140323353600375,
                "precision": 0.04607723748005992,
                "recall": 0.09288537549407115
            },
            {
                "hf_subset": "pol_Latn-bjn_Arab",
                "languages": [
                    "pol-Latn",
                    "bjn-Arab"
                ],
                "accuracy": 0.004940711462450593,
                "f1": 0.0011765254656700864,
                "main_score": 0.0011765254656700864,
                "precision": 0.0010873873255364524,
                "recall": 0.004940711462450593
            },
            {
                "hf_subset": "pol_Latn-ewe_Latn",
                "languages": [
                    "pol-Latn",
                    "ewe-Latn"
                ],
                "accuracy": 0.26976284584980237,
                "f1": 0.2194531423780436,
                "main_score": 0.2194531423780436,
                "precision": 0.20516700032510307,
                "recall": 0.26976284584980237
            },
            {
                "hf_subset": "pol_Latn-ilo_Latn",
                "languages": [
                    "pol-Latn",
                    "ilo-Latn"
                ],
                "accuracy": 0.3932806324110672,
                "f1": 0.3038183785911059,
                "main_score": 0.3038183785911059,
                "precision": 0.27592691125299823,
                "recall": 0.3932806324110672
            },
            {
                "hf_subset": "pol_Latn-knc_Arab",
                "languages": [
                    "pol-Latn",
                    "knc-Arab"
                ],
                "accuracy": 0.09881422924901186,
                "f1": 0.056206395484966816,
                "main_score": 0.056206395484966816,
                "precision": 0.04632203265894544,
                "recall": 0.09881422924901186
            },
            {
                "hf_subset": "pol_Latn-mkd_Cyrl",
                "languages": [
                    "pol-Latn",
                    "mkd-Cyrl"
                ],
                "accuracy": 0.08201581027667984,
                "f1": 0.05756667198483056,
                "main_score": 0.05756667198483056,
                "precision": 0.05172948249340367,
                "recall": 0.08201581027667984
            },
            {
                "hf_subset": "pol_Latn-prs_Arab",
                "languages": [
                    "pol-Latn",
                    "prs-Arab"
                ],
                "accuracy": 0.09782608695652174,
                "f1": 0.05919630385538823,
                "main_score": 0.05919630385538823,
                "precision": 0.05130159105954237,
                "recall": 0.09782608695652174
            },
            {
                "hf_subset": "pol_Latn-swe_Latn",
                "languages": [
                    "pol-Latn",
                    "swe-Latn"
                ],
                "accuracy": 0.4535573122529645,
                "f1": 0.36275005188048665,
                "main_score": 0.36275005188048665,
                "precision": 0.3326172976123569,
                "recall": 0.4535573122529645
            },
            {
                "hf_subset": "pol_Latn-urd_Arab",
                "languages": [
                    "pol-Latn",
                    "urd-Arab"
                ],
                "accuracy": 0.05632411067193676,
                "f1": 0.03569460684222274,
                "main_score": 0.03569460684222274,
                "precision": 0.03124048837874237,
                "recall": 0.05632411067193676
            },
            {
                "hf_subset": "pol_Latn-aka_Latn",
                "languages": [
                    "pol-Latn",
                    "aka-Latn"
                ],
                "accuracy": 0.3656126482213439,
                "f1": 0.29486626632613916,
                "main_score": 0.29486626632613916,
                "precision": 0.27144587132235354,
                "recall": 0.3656126482213439
            },
            {
                "hf_subset": "pol_Latn-bjn_Latn",
                "languages": [
                    "pol-Latn",
                    "bjn-Latn"
                ],
                "accuracy": 0.3102766798418972,
                "f1": 0.23143749721435147,
                "main_score": 0.23143749721435147,
                "precision": 0.20753021818980316,
                "recall": 0.3102766798418972
            },
            {
                "hf_subset": "pol_Latn-fao_Latn",
                "languages": [
                    "pol-Latn",
                    "fao-Latn"
                ],
                "accuracy": 0.30434782608695654,
                "f1": 0.22605249989130635,
                "main_score": 0.22605249989130635,
                "precision": 0.202527359827261,
                "recall": 0.30434782608695654
            },
            {
                "hf_subset": "pol_Latn-ind_Latn",
                "languages": [
                    "pol-Latn",
                    "ind-Latn"
                ],
                "accuracy": 0.37648221343873517,
                "f1": 0.2881205301932887,
                "main_score": 0.2881205301932887,
                "precision": 0.2610980623345404,
                "recall": 0.37648221343873517
            },
            {
                "hf_subset": "pol_Latn-knc_Latn",
                "languages": [
                    "pol-Latn",
                    "knc-Latn"
                ],
                "accuracy": 0.31719367588932806,
                "f1": 0.2527159873503747,
                "main_score": 0.2527159873503747,
                "precision": 0.23153872856640986,
                "recall": 0.31719367588932806
            },
            {
                "hf_subset": "pol_Latn-mlt_Latn",
                "languages": [
                    "pol-Latn",
                    "mlt-Latn"
                ],
                "accuracy": 0.37747035573122534,
                "f1": 0.2991421484751524,
                "main_score": 0.2991421484751524,
                "precision": 0.27373131717945176,
                "recall": 0.37747035573122534
            },
            {
                "hf_subset": "pol_Latn-quy_Latn",
                "languages": [
                    "pol-Latn",
                    "quy-Latn"
                ],
                "accuracy": 0.3132411067193676,
                "f1": 0.2265035601201609,
                "main_score": 0.2265035601201609,
                "precision": 0.20250536856528123,
                "recall": 0.3132411067193676
            },
            {
                "hf_subset": "pol_Latn-swh_Latn",
                "languages": [
                    "pol-Latn",
                    "swh-Latn"
                ],
                "accuracy": 0.242094861660079,
                "f1": 0.17217401340425054,
                "main_score": 0.17217401340425054,
                "precision": 0.15316212104443727,
                "recall": 0.242094861660079
            },
            {
                "hf_subset": "pol_Latn-uzn_Latn",
                "languages": [
                    "pol-Latn",
                    "uzn-Latn"
                ],
                "accuracy": 0.2628458498023715,
                "f1": 0.18861504835791654,
                "main_score": 0.18861504835791654,
                "precision": 0.1675885497785852,
                "recall": 0.2628458498023715
            },
            {
                "hf_subset": "pol_Latn-als_Latn",
                "languages": [
                    "pol-Latn",
                    "als-Latn"
                ],
                "accuracy": 0.3290513833992095,
                "f1": 0.2620568763315395,
                "main_score": 0.2620568763315395,
                "precision": 0.24225254735383192,
                "recall": 0.3290513833992095
            },
            {
                "hf_subset": "pol_Latn-bod_Tibt",
                "languages": [
                    "pol-Latn",
                    "bod-Tibt"
                ],
                "accuracy": 0.05434782608695652,
                "f1": 0.020762499375776594,
                "main_score": 0.020762499375776594,
                "precision": 0.01584450632089665,
                "recall": 0.05434782608695652
            },
            {
                "hf_subset": "pol_Latn-fij_Latn",
                "languages": [
                    "pol-Latn",
                    "fij-Latn"
                ],
                "accuracy": 0.24110671936758896,
                "f1": 0.16493571645324778,
                "main_score": 0.16493571645324778,
                "precision": 0.1449307097329739,
                "recall": 0.24110671936758896
            },
            {
                "hf_subset": "pol_Latn-isl_Latn",
                "languages": [
                    "pol-Latn",
                    "isl-Latn"
                ],
                "accuracy": 0.25592885375494073,
                "f1": 0.1880255539753331,
                "main_score": 0.1880255539753331,
                "precision": 0.16858735659377955,
                "recall": 0.25592885375494073
            },
            {
                "hf_subset": "pol_Latn-kon_Latn",
                "languages": [
                    "pol-Latn",
                    "kon-Latn"
                ],
                "accuracy": 0.2717391304347826,
                "f1": 0.1947492125577922,
                "main_score": 0.1947492125577922,
                "precision": 0.1742934918318192,
                "recall": 0.2717391304347826
            },
            {
                "hf_subset": "pol_Latn-mni_Beng",
                "languages": [
                    "pol-Latn",
                    "mni-Beng"
                ],
                "accuracy": 0.05731225296442687,
                "f1": 0.02689272043641225,
                "main_score": 0.02689272043641225,
                "precision": 0.0213032205646918,
                "recall": 0.05731225296442687
            },
            {
                "hf_subset": "pol_Latn-ron_Latn",
                "languages": [
                    "pol-Latn",
                    "ron-Latn"
                ],
                "accuracy": 0.5039525691699605,
                "f1": 0.4286300765549777,
                "main_score": 0.4286300765549777,
                "precision": 0.4016924253831368,
                "recall": 0.5039525691699605
            },
            {
                "hf_subset": "pol_Latn-szl_Latn",
                "languages": [
                    "pol-Latn",
                    "szl-Latn"
                ],
                "accuracy": 0.8794466403162056,
                "f1": 0.8461791831357048,
                "main_score": 0.8461791831357048,
                "precision": 0.8306982872200266,
                "recall": 0.8794466403162056
            },
            {
                "hf_subset": "pol_Latn-vec_Latn",
                "languages": [
                    "pol-Latn",
                    "vec-Latn"
                ],
                "accuracy": 0.4703557312252965,
                "f1": 0.39261103411301046,
                "main_score": 0.39261103411301046,
                "precision": 0.36655608883869756,
                "recall": 0.4703557312252965
            },
            {
                "hf_subset": "pol_Latn-amh_Ethi",
                "languages": [
                    "pol-Latn",
                    "amh-Ethi"
                ],
                "accuracy": 0.07213438735177866,
                "f1": 0.042295921899194046,
                "main_score": 0.042295921899194046,
                "precision": 0.036053747800289304,
                "recall": 0.07213438735177866
            },
            {
                "hf_subset": "pol_Latn-bos_Latn",
                "languages": [
                    "pol-Latn",
                    "bos-Latn"
                ],
                "accuracy": 0.41205533596837945,
                "f1": 0.33108342799054263,
                "main_score": 0.33108342799054263,
                "precision": 0.30403204886900537,
                "recall": 0.41205533596837945
            },
            {
                "hf_subset": "pol_Latn-fin_Latn",
                "languages": [
                    "pol-Latn",
                    "fin-Latn"
                ],
                "accuracy": 0.2984189723320158,
                "f1": 0.21713522647146744,
                "main_score": 0.21713522647146744,
                "precision": 0.19350322170716575,
                "recall": 0.2984189723320158
            },
            {
                "hf_subset": "pol_Latn-ita_Latn",
                "languages": [
                    "pol-Latn",
                    "ita-Latn"
                ],
                "accuracy": 0.5029644268774703,
                "f1": 0.40906659765355413,
                "main_score": 0.40906659765355413,
                "precision": 0.37682571052136266,
                "recall": 0.5029644268774703
            },
            {
                "hf_subset": "pol_Latn-kor_Hang",
                "languages": [
                    "pol-Latn",
                    "kor-Hang"
                ],
                "accuracy": 0.11264822134387352,
                "f1": 0.05931697077593314,
                "main_score": 0.05931697077593314,
                "precision": 0.049535659231074884,
                "recall": 0.11264822134387352
            },
            {
                "hf_subset": "pol_Latn-mos_Latn",
                "languages": [
                    "pol-Latn",
                    "mos-Latn"
                ],
                "accuracy": 0.2440711462450593,
                "f1": 0.18514184619660326,
                "main_score": 0.18514184619660326,
                "precision": 0.16817790607446315,
                "recall": 0.2440711462450593
            },
            {
                "hf_subset": "pol_Latn-run_Latn",
                "languages": [
                    "pol-Latn",
                    "run-Latn"
                ],
                "accuracy": 0.22134387351778656,
                "f1": 0.1538932603408888,
                "main_score": 0.1538932603408888,
                "precision": 0.13646404187542108,
                "recall": 0.22134387351778656
            },
            {
                "hf_subset": "pol_Latn-tam_Taml",
                "languages": [
                    "pol-Latn",
                    "tam-Taml"
                ],
                "accuracy": 0.09782608695652174,
                "f1": 0.05617889443884255,
                "main_score": 0.05617889443884255,
                "precision": 0.0475356748528658,
                "recall": 0.09782608695652174
            },
            {
                "hf_subset": "pol_Latn-vie_Latn",
                "languages": [
                    "pol-Latn",
                    "vie-Latn"
                ],
                "accuracy": 0.29446640316205536,
                "f1": 0.23583836014666051,
                "main_score": 0.23583836014666051,
                "precision": 0.21797658108799411,
                "recall": 0.29446640316205536
            },
            {
                "hf_subset": "pol_Latn-apc_Arab",
                "languages": [
                    "pol-Latn",
                    "apc-Arab"
                ],
                "accuracy": 0.0958498023715415,
                "f1": 0.05606078233293074,
                "main_score": 0.05606078233293074,
                "precision": 0.04687138313620527,
                "recall": 0.0958498023715415
            },
            {
                "hf_subset": "pol_Latn-bug_Latn",
                "languages": [
                    "pol-Latn",
                    "bug-Latn"
                ],
                "accuracy": 0.3231225296442688,
                "f1": 0.24075721425289762,
                "main_score": 0.24075721425289762,
                "precision": 0.2167035670741204,
                "recall": 0.3231225296442688
            },
            {
                "hf_subset": "pol_Latn-fon_Latn",
                "languages": [
                    "pol-Latn",
                    "fon-Latn"
                ],
                "accuracy": 0.2707509881422925,
                "f1": 0.21335438002928123,
                "main_score": 0.21335438002928123,
                "precision": 0.19557752665590195,
                "recall": 0.2707509881422925
            },
            {
                "hf_subset": "pol_Latn-jav_Latn",
                "languages": [
                    "pol-Latn",
                    "jav-Latn"
                ],
                "accuracy": 0.3250988142292491,
                "f1": 0.23972031207703143,
                "main_score": 0.23972031207703143,
                "precision": 0.2151591043098832,
                "recall": 0.3250988142292491
            },
            {
                "hf_subset": "pol_Latn-lao_Laoo",
                "languages": [
                    "pol-Latn",
                    "lao-Laoo"
                ],
                "accuracy": 0.3537549407114625,
                "f1": 0.28995182737771663,
                "main_score": 0.28995182737771663,
                "precision": 0.27077181737448885,
                "recall": 0.3537549407114625
            },
            {
                "hf_subset": "pol_Latn-mri_Latn",
                "languages": [
                    "pol-Latn",
                    "mri-Latn"
                ],
                "accuracy": 0.22134387351778656,
                "f1": 0.15354442612607785,
                "main_score": 0.15354442612607785,
                "precision": 0.13594571086102247,
                "recall": 0.22134387351778656
            },
            {
                "hf_subset": "pol_Latn-rus_Cyrl",
                "languages": [
                    "pol-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.08992094861660078,
                "f1": 0.05813561215219575,
                "main_score": 0.05813561215219575,
                "precision": 0.05163711679758252,
                "recall": 0.08992094861660078
            },
            {
                "hf_subset": "pol_Latn-taq_Latn",
                "languages": [
                    "pol-Latn",
                    "taq-Latn"
                ],
                "accuracy": 0.32806324110671936,
                "f1": 0.2683270577364974,
                "main_score": 0.2683270577364974,
                "precision": 0.24997938399618239,
                "recall": 0.32806324110671936
            },
            {
                "hf_subset": "pol_Latn-war_Latn",
                "languages": [
                    "pol-Latn",
                    "war-Latn"
                ],
                "accuracy": 0.4614624505928854,
                "f1": 0.3738924037095973,
                "main_score": 0.3738924037095973,
                "precision": 0.3453650072646034,
                "recall": 0.4614624505928854
            },
            {
                "hf_subset": "pol_Latn-arb_Arab",
                "languages": [
                    "pol-Latn",
                    "arb-Arab"
                ],
                "accuracy": 0.06521739130434782,
                "f1": 0.035196469175927975,
                "main_score": 0.035196469175927975,
                "precision": 0.029206974315601583,
                "recall": 0.06521739130434782
            },
            {
                "hf_subset": "pol_Latn-bul_Cyrl",
                "languages": [
                    "pol-Latn",
                    "bul-Cyrl"
                ],
                "accuracy": 0.09782608695652174,
                "f1": 0.07091825892667408,
                "main_score": 0.07091825892667408,
                "precision": 0.06346137894299089,
                "recall": 0.09782608695652174
            },
            {
                "hf_subset": "pol_Latn-fra_Latn",
                "languages": [
                    "pol-Latn",
                    "fra-Latn"
                ],
                "accuracy": 0.5938735177865613,
                "f1": 0.5129611330698287,
                "main_score": 0.5129611330698287,
                "precision": 0.4824640353252885,
                "recall": 0.5938735177865613
            },
            {
                "hf_subset": "pol_Latn-jpn_Jpan",
                "languages": [
                    "pol-Latn",
                    "jpn-Jpan"
                ],
                "accuracy": 0.029644268774703556,
                "f1": 0.00944206619732386,
                "main_score": 0.00944206619732386,
                "precision": 0.006727116823200326,
                "recall": 0.029644268774703556
            },
            {
                "hf_subset": "pol_Latn-lij_Latn",
                "languages": [
                    "pol-Latn",
                    "lij-Latn"
                ],
                "accuracy": 0.43774703557312256,
                "f1": 0.352610249582756,
                "main_score": 0.352610249582756,
                "precision": 0.3237751886343784,
                "recall": 0.43774703557312256
            },
            {
                "hf_subset": "pol_Latn-mya_Mymr",
                "languages": [
                    "pol-Latn",
                    "mya-Mymr"
                ],
                "accuracy": 0.09486166007905136,
                "f1": 0.04685784685126671,
                "main_score": 0.04685784685126671,
                "precision": 0.037744225331158544,
                "recall": 0.09486166007905136
            },
            {
                "hf_subset": "pol_Latn-sag_Latn",
                "languages": [
                    "pol-Latn",
                    "sag-Latn"
                ],
                "accuracy": 0.24604743083003952,
                "f1": 0.187955635422213,
                "main_score": 0.187955635422213,
                "precision": 0.17210956257762233,
                "recall": 0.24604743083003952
            },
            {
                "hf_subset": "pol_Latn-taq_Tfng",
                "languages": [
                    "pol-Latn",
                    "taq-Tfng"
                ],
                "accuracy": 0.10375494071146245,
                "f1": 0.05969657887031101,
                "main_score": 0.05969657887031101,
                "precision": 0.051133236858562546,
                "recall": 0.10375494071146245
            },
            {
                "hf_subset": "pol_Latn-wol_Latn",
                "languages": [
                    "pol-Latn",
                    "wol-Latn"
                ],
                "accuracy": 0.29446640316205536,
                "f1": 0.22516172232601395,
                "main_score": 0.22516172232601395,
                "precision": 0.2050913832737827,
                "recall": 0.29446640316205536
            },
            {
                "hf_subset": "pol_Latn-arb_Latn",
                "languages": [
                    "pol-Latn",
                    "arb-Latn"
                ],
                "accuracy": 0.17885375494071146,
                "f1": 0.11136634966921527,
                "main_score": 0.11136634966921527,
                "precision": 0.09470246749242751,
                "recall": 0.17885375494071146
            },
            {
                "hf_subset": "pol_Latn-cat_Latn",
                "languages": [
                    "pol-Latn",
                    "cat-Latn"
                ],
                "accuracy": 0.5395256916996047,
                "f1": 0.45598134847146704,
                "main_score": 0.45598134847146704,
                "precision": 0.42588854382332647,
                "recall": 0.5395256916996047
            },
            {
                "hf_subset": "pol_Latn-fur_Latn",
                "languages": [
                    "pol-Latn",
                    "fur-Latn"
                ],
                "accuracy": 0.4397233201581028,
                "f1": 0.3583473509362837,
                "main_score": 0.3583473509362837,
                "precision": 0.33147622853650527,
                "recall": 0.4397233201581028
            },
            {
                "hf_subset": "pol_Latn-kab_Latn",
                "languages": [
                    "pol-Latn",
                    "kab-Latn"
                ],
                "accuracy": 0.11857707509881422,
                "f1": 0.07397762207050744,
                "main_score": 0.07397762207050744,
                "precision": 0.06311522971296096,
                "recall": 0.11857707509881422
            },
            {
                "hf_subset": "pol_Latn-lim_Latn",
                "languages": [
                    "pol-Latn",
                    "lim-Latn"
                ],
                "accuracy": 0.458498023715415,
                "f1": 0.377763778885611,
                "main_score": 0.377763778885611,
                "precision": 0.34853639582711615,
                "recall": 0.458498023715415
            },
            {
                "hf_subset": "pol_Latn-nld_Latn",
                "languages": [
                    "pol-Latn",
                    "nld-Latn"
                ],
                "accuracy": 0.475296442687747,
                "f1": 0.3840575295367785,
                "main_score": 0.3840575295367785,
                "precision": 0.3527487609009349,
                "recall": 0.475296442687747
            },
            {
                "hf_subset": "pol_Latn-san_Deva",
                "languages": [
                    "pol-Latn",
                    "san-Deva"
                ],
                "accuracy": 0.09189723320158101,
                "f1": 0.05205993892335911,
                "main_score": 0.05205993892335911,
                "precision": 0.04337201997808373,
                "recall": 0.09189723320158101
            },
            {
                "hf_subset": "pol_Latn-tat_Cyrl",
                "languages": [
                    "pol-Latn",
                    "tat-Cyrl"
                ],
                "accuracy": 0.09189723320158101,
                "f1": 0.053146751443047285,
                "main_score": 0.053146751443047285,
                "precision": 0.04492476362336001,
                "recall": 0.09189723320158101
            },
            {
                "hf_subset": "pol_Latn-xho_Latn",
                "languages": [
                    "pol-Latn",
                    "xho-Latn"
                ],
                "accuracy": 0.2490118577075099,
                "f1": 0.1650000499061764,
                "main_score": 0.1650000499061764,
                "precision": 0.14219926880064057,
                "recall": 0.2490118577075099
            },
            {
                "hf_subset": "pol_Latn-ars_Arab",
                "languages": [
                    "pol-Latn",
                    "ars-Arab"
                ],
                "accuracy": 0.041501976284584984,
                "f1": 0.019884773395885486,
                "main_score": 0.019884773395885486,
                "precision": 0.016176875636726987,
                "recall": 0.041501976284584984
            },
            {
                "hf_subset": "pol_Latn-ceb_Latn",
                "languages": [
                    "pol-Latn",
                    "ceb-Latn"
                ],
                "accuracy": 0.39426877470355737,
                "f1": 0.30411252669157807,
                "main_score": 0.30411252669157807,
                "precision": 0.276250185365798,
                "recall": 0.39426877470355737
            },
            {
                "hf_subset": "pol_Latn-fuv_Latn",
                "languages": [
                    "pol-Latn",
                    "fuv-Latn"
                ],
                "accuracy": 0.25889328063241107,
                "f1": 0.1816006406557946,
                "main_score": 0.1816006406557946,
                "precision": 0.16093802710132557,
                "recall": 0.25889328063241107
            },
            {
                "hf_subset": "pol_Latn-kac_Latn",
                "languages": [
                    "pol-Latn",
                    "kac-Latn"
                ],
                "accuracy": 0.28063241106719367,
                "f1": 0.20537588393674425,
                "main_score": 0.20537588393674425,
                "precision": 0.18555593378125912,
                "recall": 0.28063241106719367
            },
            {
                "hf_subset": "pol_Latn-lin_Latn",
                "languages": [
                    "pol-Latn",
                    "lin-Latn"
                ],
                "accuracy": 0.2756916996047431,
                "f1": 0.1959550667924326,
                "main_score": 0.1959550667924326,
                "precision": 0.17366118810405023,
                "recall": 0.2756916996047431
            },
            {
                "hf_subset": "pol_Latn-nno_Latn",
                "languages": [
                    "pol-Latn",
                    "nno-Latn"
                ],
                "accuracy": 0.44466403162055335,
                "f1": 0.3652365909233498,
                "main_score": 0.3652365909233498,
                "precision": 0.3402154307045611,
                "recall": 0.44466403162055335
            },
            {
                "hf_subset": "pol_Latn-sat_Olck",
                "languages": [
                    "pol-Latn",
                    "sat-Olck"
                ],
                "accuracy": 0.017786561264822136,
                "f1": 0.005308103241702219,
                "main_score": 0.005308103241702219,
                "precision": 0.003879325601322212,
                "recall": 0.017786561264822136
            },
            {
                "hf_subset": "pol_Latn-tel_Telu",
                "languages": [
                    "pol-Latn",
                    "tel-Telu"
                ],
                "accuracy": 0.13043478260869565,
                "f1": 0.07211621994490727,
                "main_score": 0.07211621994490727,
                "precision": 0.06072556380043011,
                "recall": 0.13043478260869565
            },
            {
                "hf_subset": "pol_Latn-ydd_Hebr",
                "languages": [
                    "pol-Latn",
                    "ydd-Hebr"
                ],
                "accuracy": 0.10177865612648221,
                "f1": 0.0604945869467265,
                "main_score": 0.0604945869467265,
                "precision": 0.053131308980813065,
                "recall": 0.10177865612648221
            },
            {
                "hf_subset": "pol_Latn-ary_Arab",
                "languages": [
                    "pol-Latn",
                    "ary-Arab"
                ],
                "accuracy": 0.07905138339920949,
                "f1": 0.04544108401407499,
                "main_score": 0.04544108401407499,
                "precision": 0.03869493506162304,
                "recall": 0.07905138339920949
            },
            {
                "hf_subset": "pol_Latn-ces_Latn",
                "languages": [
                    "pol-Latn",
                    "ces-Latn"
                ],
                "accuracy": 0.45454545454545453,
                "f1": 0.38024558240445855,
                "main_score": 0.38024558240445855,
                "precision": 0.35546957063319534,
                "recall": 0.45454545454545453
            },
            {
                "hf_subset": "pol_Latn-gaz_Latn",
                "languages": [
                    "pol-Latn",
                    "gaz-Latn"
                ],
                "accuracy": 0.11166007905138339,
                "f1": 0.061592344562874664,
                "main_score": 0.061592344562874664,
                "precision": 0.05133667829697058,
                "recall": 0.11166007905138339
            },
            {
                "hf_subset": "pol_Latn-kam_Latn",
                "languages": [
                    "pol-Latn",
                    "kam-Latn"
                ],
                "accuracy": 0.23221343873517786,
                "f1": 0.18353962970667775,
                "main_score": 0.18353962970667775,
                "precision": 0.1688928967302209,
                "recall": 0.23221343873517786
            },
            {
                "hf_subset": "pol_Latn-lit_Latn",
                "languages": [
                    "pol-Latn",
                    "lit-Latn"
                ],
                "accuracy": 0.274703557312253,
                "f1": 0.2164822878200428,
                "main_score": 0.2164822878200428,
                "precision": 0.19899989111993022,
                "recall": 0.274703557312253
            },
            {
                "hf_subset": "pol_Latn-nob_Latn",
                "languages": [
                    "pol-Latn",
                    "nob-Latn"
                ],
                "accuracy": 0.4743083003952569,
                "f1": 0.38246988518727654,
                "main_score": 0.38246988518727654,
                "precision": 0.35016858690277664,
                "recall": 0.4743083003952569
            },
            {
                "hf_subset": "pol_Latn-scn_Latn",
                "languages": [
                    "pol-Latn",
                    "scn-Latn"
                ],
                "accuracy": 0.31225296442687744,
                "f1": 0.2421253976589945,
                "main_score": 0.2421253976589945,
                "precision": 0.2216210944903703,
                "recall": 0.31225296442687744
            },
            {
                "hf_subset": "pol_Latn-tgk_Cyrl",
                "languages": [
                    "pol-Latn",
                    "tgk-Cyrl"
                ],
                "accuracy": 0.09387351778656126,
                "f1": 0.05610273847874256,
                "main_score": 0.05610273847874256,
                "precision": 0.04867386506350517,
                "recall": 0.09387351778656126
            },
            {
                "hf_subset": "pol_Latn-yor_Latn",
                "languages": [
                    "pol-Latn",
                    "yor-Latn"
                ],
                "accuracy": 0.274703557312253,
                "f1": 0.20594022523370348,
                "main_score": 0.20594022523370348,
                "precision": 0.18623894947569672,
                "recall": 0.274703557312253
            },
            {
                "hf_subset": "pol_Latn-arz_Arab",
                "languages": [
                    "pol-Latn",
                    "arz-Arab"
                ],
                "accuracy": 0.05928853754940711,
                "f1": 0.03528829796217057,
                "main_score": 0.03528829796217057,
                "precision": 0.030691475575368856,
                "recall": 0.05928853754940711
            },
            {
                "hf_subset": "pol_Latn-cjk_Latn",
                "languages": [
                    "pol-Latn",
                    "cjk-Latn"
                ],
                "accuracy": 0.23221343873517786,
                "f1": 0.16159405299721502,
                "main_score": 0.16159405299721502,
                "precision": 0.14393576878448816,
                "recall": 0.23221343873517786
            },
            {
                "hf_subset": "pol_Latn-gla_Latn",
                "languages": [
                    "pol-Latn",
                    "gla-Latn"
                ],
                "accuracy": 0.20355731225296442,
                "f1": 0.13720070726259617,
                "main_score": 0.13720070726259617,
                "precision": 0.12052392225429522,
                "recall": 0.20355731225296442
            },
            {
                "hf_subset": "pol_Latn-kan_Knda",
                "languages": [
                    "pol-Latn",
                    "kan-Knda"
                ],
                "accuracy": 0.08201581027667984,
                "f1": 0.044371711615716916,
                "main_score": 0.044371711615716916,
                "precision": 0.03749542197197035,
                "recall": 0.08201581027667984
            },
            {
                "hf_subset": "pol_Latn-lmo_Latn",
                "languages": [
                    "pol-Latn",
                    "lmo-Latn"
                ],
                "accuracy": 0.3883399209486166,
                "f1": 0.31714524774447495,
                "main_score": 0.31714524774447495,
                "precision": 0.29391946711610745,
                "recall": 0.3883399209486166
            },
            {
                "hf_subset": "pol_Latn-npi_Deva",
                "languages": [
                    "pol-Latn",
                    "npi-Deva"
                ],
                "accuracy": 0.10968379446640317,
                "f1": 0.06473612825827703,
                "main_score": 0.06473612825827703,
                "precision": 0.0549084990741001,
                "recall": 0.10968379446640317
            },
            {
                "hf_subset": "pol_Latn-shn_Mymr",
                "languages": [
                    "pol-Latn",
                    "shn-Mymr"
                ],
                "accuracy": 0.3843873517786561,
                "f1": 0.29396836145848004,
                "main_score": 0.29396836145848004,
                "precision": 0.2653433687524597,
                "recall": 0.3843873517786561
            },
            {
                "hf_subset": "pol_Latn-tgl_Latn",
                "languages": [
                    "pol-Latn",
                    "tgl-Latn"
                ],
                "accuracy": 0.32707509881422925,
                "f1": 0.2407600574274401,
                "main_score": 0.2407600574274401,
                "precision": 0.216550168649971,
                "recall": 0.32707509881422925
            },
            {
                "hf_subset": "pol_Latn-yue_Hant",
                "languages": [
                    "pol-Latn",
                    "yue-Hant"
                ],
                "accuracy": 0.099802371541502,
                "f1": 0.058668208558696075,
                "main_score": 0.058668208558696075,
                "precision": 0.049944633151410726,
                "recall": 0.099802371541502
            },
            {
                "hf_subset": "pol_Latn-asm_Beng",
                "languages": [
                    "pol-Latn",
                    "asm-Beng"
                ],
                "accuracy": 0.06027667984189724,
                "f1": 0.029919947985546754,
                "main_score": 0.029919947985546754,
                "precision": 0.02396787621140054,
                "recall": 0.06027667984189724
            },
            {
                "hf_subset": "pol_Latn-ckb_Arab",
                "languages": [
                    "pol-Latn",
                    "ckb-Arab"
                ],
                "accuracy": 0.05039525691699605,
                "f1": 0.026313333428590335,
                "main_score": 0.026313333428590335,
                "precision": 0.021441980481557245,
                "recall": 0.05039525691699605
            },
            {
                "hf_subset": "pol_Latn-gle_Latn",
                "languages": [
                    "pol-Latn",
                    "gle-Latn"
                ],
                "accuracy": 0.2292490118577075,
                "f1": 0.16366565597793156,
                "main_score": 0.16366565597793156,
                "precision": 0.14427773313642878,
                "recall": 0.2292490118577075
            },
            {
                "hf_subset": "pol_Latn-kas_Arab",
                "languages": [
                    "pol-Latn",
                    "kas-Arab"
                ],
                "accuracy": 0.0741106719367589,
                "f1": 0.04268493390151144,
                "main_score": 0.04268493390151144,
                "precision": 0.03631812409756493,
                "recall": 0.0741106719367589
            },
            {
                "hf_subset": "pol_Latn-ltg_Latn",
                "languages": [
                    "pol-Latn",
                    "ltg-Latn"
                ],
                "accuracy": 0.2885375494071146,
                "f1": 0.21831210848523186,
                "main_score": 0.21831210848523186,
                "precision": 0.19654908798930537,
                "recall": 0.2885375494071146
            },
            {
                "hf_subset": "pol_Latn-nso_Latn",
                "languages": [
                    "pol-Latn",
                    "nso-Latn"
                ],
                "accuracy": 0.29051383399209485,
                "f1": 0.21425082008345997,
                "main_score": 0.21425082008345997,
                "precision": 0.1924843153307464,
                "recall": 0.29051383399209485
            },
            {
                "hf_subset": "pol_Latn-sin_Sinh",
                "languages": [
                    "pol-Latn",
                    "sin-Sinh"
                ],
                "accuracy": 0.08992094861660078,
                "f1": 0.05979100944100412,
                "main_score": 0.05979100944100412,
                "precision": 0.053855434811788755,
                "recall": 0.08992094861660078
            },
            {
                "hf_subset": "pol_Latn-tha_Thai",
                "languages": [
                    "pol-Latn",
                    "tha-Thai"
                ],
                "accuracy": 0.1590909090909091,
                "f1": 0.09796795116437666,
                "main_score": 0.09796795116437666,
                "precision": 0.08360619704129169,
                "recall": 0.1590909090909091
            },
            {
                "hf_subset": "pol_Latn-zho_Hans",
                "languages": [
                    "pol-Latn",
                    "zho-Hans"
                ],
                "accuracy": 0.1650197628458498,
                "f1": 0.10270309138975882,
                "main_score": 0.10270309138975882,
                "precision": 0.0873478574565531,
                "recall": 0.1650197628458498
            },
            {
                "hf_subset": "pol_Latn-ast_Latn",
                "languages": [
                    "pol-Latn",
                    "ast-Latn"
                ],
                "accuracy": 0.4792490118577075,
                "f1": 0.3926617464660943,
                "main_score": 0.3926617464660943,
                "precision": 0.3618855836741212,
                "recall": 0.4792490118577075
            },
            {
                "hf_subset": "pol_Latn-crh_Latn",
                "languages": [
                    "pol-Latn",
                    "crh-Latn"
                ],
                "accuracy": 0.2519762845849802,
                "f1": 0.18670974077359065,
                "main_score": 0.18670974077359065,
                "precision": 0.16954646692788983,
                "recall": 0.2519762845849802
            },
            {
                "hf_subset": "pol_Latn-glg_Latn",
                "languages": [
                    "pol-Latn",
                    "glg-Latn"
                ],
                "accuracy": 0.5237154150197628,
                "f1": 0.4388566144000926,
                "main_score": 0.4388566144000926,
                "precision": 0.4096642597630741,
                "recall": 0.5237154150197628
            },
            {
                "hf_subset": "pol_Latn-kas_Deva",
                "languages": [
                    "pol-Latn",
                    "kas-Deva"
                ],
                "accuracy": 0.242094861660079,
                "f1": 0.16853008476346326,
                "main_score": 0.16853008476346326,
                "precision": 0.14851243130407094,
                "recall": 0.242094861660079
            },
            {
                "hf_subset": "pol_Latn-ltz_Latn",
                "languages": [
                    "pol-Latn",
                    "ltz-Latn"
                ],
                "accuracy": 0.44861660079051385,
                "f1": 0.3653990936599632,
                "main_score": 0.3653990936599632,
                "precision": 0.3371791123723814,
                "recall": 0.44861660079051385
            },
            {
                "hf_subset": "pol_Latn-nus_Latn",
                "languages": [
                    "pol-Latn",
                    "nus-Latn"
                ],
                "accuracy": 0.15612648221343872,
                "f1": 0.10556552033824762,
                "main_score": 0.10556552033824762,
                "precision": 0.09225857138021011,
                "recall": 0.15612648221343872
            },
            {
                "hf_subset": "pol_Latn-slk_Latn",
                "languages": [
                    "pol-Latn",
                    "slk-Latn"
                ],
                "accuracy": 0.4160079051383399,
                "f1": 0.3467679197175244,
                "main_score": 0.3467679197175244,
                "precision": 0.32459547104075914,
                "recall": 0.4160079051383399
            },
            {
                "hf_subset": "pol_Latn-tir_Ethi",
                "languages": [
                    "pol-Latn",
                    "tir-Ethi"
                ],
                "accuracy": 0.06719367588932806,
                "f1": 0.033274360285725495,
                "main_score": 0.033274360285725495,
                "precision": 0.028253990375336113,
                "recall": 0.06719367588932806
            },
            {
                "hf_subset": "pol_Latn-zho_Hant",
                "languages": [
                    "pol-Latn",
                    "zho-Hant"
                ],
                "accuracy": 0.12648221343873517,
                "f1": 0.07529818632617995,
                "main_score": 0.07529818632617995,
                "precision": 0.06454425829925467,
                "recall": 0.12648221343873517
            },
            {
                "hf_subset": "pol_Latn-awa_Deva",
                "languages": [
                    "pol-Latn",
                    "awa-Deva"
                ],
                "accuracy": 0.08300395256916997,
                "f1": 0.0453959024560111,
                "main_score": 0.0453959024560111,
                "precision": 0.03890776976863834,
                "recall": 0.08300395256916997
            },
            {
                "hf_subset": "pol_Latn-cym_Latn",
                "languages": [
                    "pol-Latn",
                    "cym-Latn"
                ],
                "accuracy": 0.274703557312253,
                "f1": 0.19680631990509367,
                "main_score": 0.19680631990509367,
                "precision": 0.17529989174140934,
                "recall": 0.274703557312253
            },
            {
                "hf_subset": "pol_Latn-grn_Latn",
                "languages": [
                    "pol-Latn",
                    "grn-Latn"
                ],
                "accuracy": 0.37450592885375494,
                "f1": 0.2871171428483681,
                "main_score": 0.2871171428483681,
                "precision": 0.25925313793526816,
                "recall": 0.37450592885375494
            },
            {
                "hf_subset": "pol_Latn-kat_Geor",
                "languages": [
                    "pol-Latn",
                    "kat-Geor"
                ],
                "accuracy": 0.0958498023715415,
                "f1": 0.055219657006276054,
                "main_score": 0.055219657006276054,
                "precision": 0.046367511696542865,
                "recall": 0.0958498023715415
            },
            {
                "hf_subset": "pol_Latn-lua_Latn",
                "languages": [
                    "pol-Latn",
                    "lua-Latn"
                ],
                "accuracy": 0.3092885375494071,
                "f1": 0.225116731094992,
                "main_score": 0.225116731094992,
                "precision": 0.20106998654559505,
                "recall": 0.3092885375494071
            },
            {
                "hf_subset": "pol_Latn-nya_Latn",
                "languages": [
                    "pol-Latn",
                    "nya-Latn"
                ],
                "accuracy": 0.30335968379446643,
                "f1": 0.21866230950695634,
                "main_score": 0.21866230950695634,
                "precision": 0.19365828866947027,
                "recall": 0.30335968379446643
            },
            {
                "hf_subset": "pol_Latn-slv_Latn",
                "languages": [
                    "pol-Latn",
                    "slv-Latn"
                ],
                "accuracy": 0.37549407114624506,
                "f1": 0.3026678570994605,
                "main_score": 0.3026678570994605,
                "precision": 0.27977184847374154,
                "recall": 0.37549407114624506
            },
            {
                "hf_subset": "pol_Latn-tpi_Latn",
                "languages": [
                    "pol-Latn",
                    "tpi-Latn"
                ],
                "accuracy": 0.5484189723320159,
                "f1": 0.45945094650628254,
                "main_score": 0.45945094650628254,
                "precision": 0.4274126894186182,
                "recall": 0.5484189723320159
            },
            {
                "hf_subset": "pol_Latn-zsm_Latn",
                "languages": [
                    "pol-Latn",
                    "zsm-Latn"
                ],
                "accuracy": 0.3231225296442688,
                "f1": 0.23805788858652943,
                "main_score": 0.23805788858652943,
                "precision": 0.2137002869388159,
                "recall": 0.3231225296442688
            },
            {
                "hf_subset": "pol_Latn-ayr_Latn",
                "languages": [
                    "pol-Latn",
                    "ayr-Latn"
                ],
                "accuracy": 0.2450592885375494,
                "f1": 0.17067550491891828,
                "main_score": 0.17067550491891828,
                "precision": 0.15074182726898094,
                "recall": 0.2450592885375494
            },
            {
                "hf_subset": "pol_Latn-dan_Latn",
                "languages": [
                    "pol-Latn",
                    "dan-Latn"
                ],
                "accuracy": 0.4772727272727273,
                "f1": 0.39431434643013347,
                "main_score": 0.39431434643013347,
                "precision": 0.3654565995598604,
                "recall": 0.4772727272727273
            },
            {
                "hf_subset": "pol_Latn-guj_Gujr",
                "languages": [
                    "pol-Latn",
                    "guj-Gujr"
                ],
                "accuracy": 0.06324110671936758,
                "f1": 0.033326388017378736,
                "main_score": 0.033326388017378736,
                "precision": 0.02757544255992551,
                "recall": 0.06324110671936758
            },
            {
                "hf_subset": "pol_Latn-kaz_Cyrl",
                "languages": [
                    "pol-Latn",
                    "kaz-Cyrl"
                ],
                "accuracy": 0.11758893280632413,
                "f1": 0.07071173491888075,
                "main_score": 0.07071173491888075,
                "precision": 0.060509638258340465,
                "recall": 0.11758893280632413
            },
            {
                "hf_subset": "pol_Latn-lug_Latn",
                "languages": [
                    "pol-Latn",
                    "lug-Latn"
                ],
                "accuracy": 0.25889328063241107,
                "f1": 0.18129380500922,
                "main_score": 0.18129380500922,
                "precision": 0.1607441905468527,
                "recall": 0.25889328063241107
            },
            {
                "hf_subset": "pol_Latn-oci_Latn",
                "languages": [
                    "pol-Latn",
                    "oci-Latn"
                ],
                "accuracy": 0.5355731225296443,
                "f1": 0.4499836022563295,
                "main_score": 0.4499836022563295,
                "precision": 0.4204267049375744,
                "recall": 0.5355731225296443
            },
            {
                "hf_subset": "pol_Latn-smo_Latn",
                "languages": [
                    "pol-Latn",
                    "smo-Latn"
                ],
                "accuracy": 0.25889328063241107,
                "f1": 0.18157441837399987,
                "main_score": 0.18157441837399987,
                "precision": 0.16178864593379544,
                "recall": 0.25889328063241107
            },
            {
                "hf_subset": "pol_Latn-tsn_Latn",
                "languages": [
                    "pol-Latn",
                    "tsn-Latn"
                ],
                "accuracy": 0.27865612648221344,
                "f1": 0.19498233309640386,
                "main_score": 0.19498233309640386,
                "precision": 0.17179968828931277,
                "recall": 0.27865612648221344
            },
            {
                "hf_subset": "pol_Latn-zul_Latn",
                "languages": [
                    "pol-Latn",
                    "zul-Latn"
                ],
                "accuracy": 0.18774703557312253,
                "f1": 0.11903397061759863,
                "main_score": 0.11903397061759863,
                "precision": 0.10198701796150064,
                "recall": 0.18774703557312253
            },
            {
                "hf_subset": "pol_Latn-azb_Arab",
                "languages": [
                    "pol-Latn",
                    "azb-Arab"
                ],
                "accuracy": 0.045454545454545456,
                "f1": 0.02132585793652987,
                "main_score": 0.02132585793652987,
                "precision": 0.01643447767589644,
                "recall": 0.045454545454545456
            },
            {
                "hf_subset": "pol_Latn-deu_Latn",
                "languages": [
                    "pol-Latn",
                    "deu-Latn"
                ],
                "accuracy": 0.5118577075098815,
                "f1": 0.4236153594267986,
                "main_score": 0.4236153594267986,
                "precision": 0.39023099073741363,
                "recall": 0.5118577075098815
            },
            {
                "hf_subset": "pol_Latn-hat_Latn",
                "languages": [
                    "pol-Latn",
                    "hat-Latn"
                ],
                "accuracy": 0.2756916996047431,
                "f1": 0.21147938933628305,
                "main_score": 0.21147938933628305,
                "precision": 0.1918156560959233,
                "recall": 0.2756916996047431
            },
            {
                "hf_subset": "pol_Latn-kbp_Latn",
                "languages": [
                    "pol-Latn",
                    "kbp-Latn"
                ],
                "accuracy": 0.2490118577075099,
                "f1": 0.19400134514030917,
                "main_score": 0.19400134514030917,
                "precision": 0.1788038314123646,
                "recall": 0.2490118577075099
            },
            {
                "hf_subset": "pol_Latn-luo_Latn",
                "languages": [
                    "pol-Latn",
                    "luo-Latn"
                ],
                "accuracy": 0.2598814229249012,
                "f1": 0.18495583232417695,
                "main_score": 0.18495583232417695,
                "precision": 0.16526610238319728,
                "recall": 0.2598814229249012
            },
            {
                "hf_subset": "pol_Latn-ory_Orya",
                "languages": [
                    "pol-Latn",
                    "ory-Orya"
                ],
                "accuracy": 0.08201581027667984,
                "f1": 0.043473890336954826,
                "main_score": 0.043473890336954826,
                "precision": 0.036527450801940746,
                "recall": 0.08201581027667984
            },
            {
                "hf_subset": "pol_Latn-sna_Latn",
                "languages": [
                    "pol-Latn",
                    "sna-Latn"
                ],
                "accuracy": 0.21936758893280633,
                "f1": 0.13626286791374995,
                "main_score": 0.13626286791374995,
                "precision": 0.11587003974907657,
                "recall": 0.21936758893280633
            },
            {
                "hf_subset": "pol_Latn-tso_Latn",
                "languages": [
                    "pol-Latn",
                    "tso-Latn"
                ],
                "accuracy": 0.2361660079051383,
                "f1": 0.15920835945002468,
                "main_score": 0.15920835945002468,
                "precision": 0.13785758159275946,
                "recall": 0.2361660079051383
            },
            {
                "hf_subset": "pol_Latn-azj_Latn",
                "languages": [
                    "pol-Latn",
                    "azj-Latn"
                ],
                "accuracy": 0.21739130434782608,
                "f1": 0.1654747537902312,
                "main_score": 0.1654747537902312,
                "precision": 0.15108106759292533,
                "recall": 0.21739130434782608
            },
            {
                "hf_subset": "pol_Latn-dik_Latn",
                "languages": [
                    "pol-Latn",
                    "dik-Latn"
                ],
                "accuracy": 0.35968379446640314,
                "f1": 0.28780955713033934,
                "main_score": 0.28780955713033934,
                "precision": 0.2650347346987663,
                "recall": 0.35968379446640314
            },
            {
                "hf_subset": "pol_Latn-hau_Latn",
                "languages": [
                    "pol-Latn",
                    "hau-Latn"
                ],
                "accuracy": 0.2509881422924901,
                "f1": 0.1750488293385294,
                "main_score": 0.1750488293385294,
                "precision": 0.15584319377114658,
                "recall": 0.2509881422924901
            },
            {
                "hf_subset": "pol_Latn-kea_Latn",
                "languages": [
                    "pol-Latn",
                    "kea-Latn"
                ],
                "accuracy": 0.3962450592885375,
                "f1": 0.3127085016819962,
                "main_score": 0.3127085016819962,
                "precision": 0.285303983878318,
                "recall": 0.3962450592885375
            },
            {
                "hf_subset": "pol_Latn-lus_Latn",
                "languages": [
                    "pol-Latn",
                    "lus-Latn"
                ],
                "accuracy": 0.4624505928853755,
                "f1": 0.37202998472761317,
                "main_score": 0.37202998472761317,
                "precision": 0.34138708513708516,
                "recall": 0.4624505928853755
            },
            {
                "hf_subset": "pol_Latn-pag_Latn",
                "languages": [
                    "pol-Latn",
                    "pag-Latn"
                ],
                "accuracy": 0.5177865612648221,
                "f1": 0.42621375385703447,
                "main_score": 0.42621375385703447,
                "precision": 0.39347084623764467,
                "recall": 0.5177865612648221
            },
            {
                "hf_subset": "pol_Latn-snd_Arab",
                "languages": [
                    "pol-Latn",
                    "snd-Arab"
                ],
                "accuracy": 0.0958498023715415,
                "f1": 0.06147964402087744,
                "main_score": 0.06147964402087744,
                "precision": 0.05414916392558302,
                "recall": 0.0958498023715415
            },
            {
                "hf_subset": "pol_Latn-tuk_Latn",
                "languages": [
                    "pol-Latn",
                    "tuk-Latn"
                ],
                "accuracy": 0.23023715415019763,
                "f1": 0.1726881292064288,
                "main_score": 0.1726881292064288,
                "precision": 0.15607159530883666,
                "recall": 0.23023715415019763
            },
            {
                "hf_subset": "pol_Latn-bak_Cyrl",
                "languages": [
                    "pol-Latn",
                    "bak-Cyrl"
                ],
                "accuracy": 0.09288537549407115,
                "f1": 0.055277284063519956,
                "main_score": 0.055277284063519956,
                "precision": 0.04713201013355736,
                "recall": 0.09288537549407115
            },
            {
                "hf_subset": "pol_Latn-dyu_Latn",
                "languages": [
                    "pol-Latn",
                    "dyu-Latn"
                ],
                "accuracy": 0.2391304347826087,
                "f1": 0.17018730336418084,
                "main_score": 0.17018730336418084,
                "precision": 0.14966286314060392,
                "recall": 0.2391304347826087
            },
            {
                "hf_subset": "pol_Latn-heb_Hebr",
                "languages": [
                    "pol-Latn",
                    "heb-Hebr"
                ],
                "accuracy": 0.099802371541502,
                "f1": 0.054971546949165874,
                "main_score": 0.054971546949165874,
                "precision": 0.04676576441810379,
                "recall": 0.099802371541502
            },
            {
                "hf_subset": "pol_Latn-khk_Cyrl",
                "languages": [
                    "pol-Latn",
                    "khk-Cyrl"
                ],
                "accuracy": 0.07707509881422925,
                "f1": 0.04622123733606832,
                "main_score": 0.04622123733606832,
                "precision": 0.03945659270620892,
                "recall": 0.07707509881422925
            },
            {
                "hf_subset": "pol_Latn-lvs_Latn",
                "languages": [
                    "pol-Latn",
                    "lvs-Latn"
                ],
                "accuracy": 0.23122529644268774,
                "f1": 0.16608556682667355,
                "main_score": 0.16608556682667355,
                "precision": 0.1473247944226003,
                "recall": 0.23122529644268774
            },
            {
                "hf_subset": "pol_Latn-pan_Guru",
                "languages": [
                    "pol-Latn",
                    "pan-Guru"
                ],
                "accuracy": 0.08992094861660078,
                "f1": 0.04812667361152259,
                "main_score": 0.04812667361152259,
                "precision": 0.03990044582465575,
                "recall": 0.08992094861660078
            },
            {
                "hf_subset": "pol_Latn-som_Latn",
                "languages": [
                    "pol-Latn",
                    "som-Latn"
                ],
                "accuracy": 0.2361660079051383,
                "f1": 0.16280717795842148,
                "main_score": 0.16280717795842148,
                "precision": 0.1438424443365155,
                "recall": 0.2361660079051383
            },
            {
                "hf_subset": "pol_Latn-tum_Latn",
                "languages": [
                    "pol-Latn",
                    "tum-Latn"
                ],
                "accuracy": 0.2717391304347826,
                "f1": 0.19455088718922708,
                "main_score": 0.19455088718922708,
                "precision": 0.17333758687513626,
                "recall": 0.2717391304347826
            },
            {
                "hf_subset": "ssw_Latn-pol_Latn",
                "languages": [
                    "ssw-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.13636363636363635,
                "f1": 0.11545325158304745,
                "main_score": 0.11545325158304745,
                "precision": 0.11048490340500139,
                "recall": 0.13636363636363635
            },
            {
                "hf_subset": "ukr_Cyrl-pol_Latn",
                "languages": [
                    "ukr-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.043478260869565216,
                "f1": 0.0336055023938623,
                "main_score": 0.0336055023938623,
                "precision": 0.03145713238288773,
                "recall": 0.043478260869565216
            },
            {
                "hf_subset": "afr_Latn-pol_Latn",
                "languages": [
                    "afr-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.37351778656126483,
                "f1": 0.32657254375087674,
                "main_score": 0.32657254375087674,
                "precision": 0.3131990798417892,
                "recall": 0.37351778656126483
            },
            {
                "hf_subset": "bho_Deva-pol_Latn",
                "languages": [
                    "bho-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.05434782608695652,
                "f1": 0.042485384618563285,
                "main_score": 0.042485384618563285,
                "precision": 0.039363477747469754,
                "recall": 0.05434782608695652
            },
            {
                "hf_subset": "eus_Latn-pol_Latn",
                "languages": [
                    "eus-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2924901185770751,
                "f1": 0.24621199842181066,
                "main_score": 0.24621199842181066,
                "precision": 0.23318479076012708,
                "recall": 0.2924901185770751
            },
            {
                "hf_subset": "ibo_Latn-pol_Latn",
                "languages": [
                    "ibo-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1966403162055336,
                "f1": 0.1636606547617802,
                "main_score": 0.1636606547617802,
                "precision": 0.15483095342831796,
                "recall": 0.1966403162055336
            },
            {
                "hf_subset": "kmr_Latn-pol_Latn",
                "languages": [
                    "kmr-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.15810276679841898,
                "f1": 0.13131433621845695,
                "main_score": 0.13131433621845695,
                "precision": 0.12496160503188007,
                "recall": 0.15810276679841898
            },
            {
                "hf_subset": "min_Latn-pol_Latn",
                "languages": [
                    "min-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.23221343873517786,
                "f1": 0.20460829297482325,
                "main_score": 0.20460829297482325,
                "precision": 0.19666039753880404,
                "recall": 0.23221343873517786
            },
            {
                "hf_subset": "por_Latn-pol_Latn",
                "languages": [
                    "por-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.32608695652173914,
                "f1": 0.30038782875813896,
                "main_score": 0.30038782875813896,
                "precision": 0.293346482933393,
                "recall": 0.32608695652173914
            },
            {
                "hf_subset": "sun_Latn-pol_Latn",
                "languages": [
                    "sun-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2628458498023715,
                "f1": 0.23167693438533704,
                "main_score": 0.23167693438533704,
                "precision": 0.22344726485619382,
                "recall": 0.2628458498023715
            },
            {
                "hf_subset": "umb_Latn-pol_Latn",
                "languages": [
                    "umb-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1422924901185771,
                "f1": 0.11720324470434869,
                "main_score": 0.11720324470434869,
                "precision": 0.11113345808470575,
                "recall": 0.1422924901185771
            },
            {
                "hf_subset": "ajp_Arab-pol_Latn",
                "languages": [
                    "ajp-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.06027667984189724,
                "f1": 0.049063834468092954,
                "main_score": 0.049063834468092954,
                "precision": 0.04626812580140678,
                "recall": 0.06027667984189724
            },
            {
                "hf_subset": "bjn_Arab-pol_Latn",
                "languages": [
                    "bjn-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.002964426877470355,
                "f1": 0.00014739619645471455,
                "main_score": 0.00014739619645471455,
                "precision": 7.793259862334742e-05,
                "recall": 0.002964426877470355
            },
            {
                "hf_subset": "ewe_Latn-pol_Latn",
                "languages": [
                    "ewe-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.233201581027668,
                "f1": 0.19752939023865143,
                "main_score": 0.19752939023865143,
                "precision": 0.18695225242144134,
                "recall": 0.233201581027668
            },
            {
                "hf_subset": "ilo_Latn-pol_Latn",
                "languages": [
                    "ilo-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.26877470355731226,
                "f1": 0.24036761426467307,
                "main_score": 0.24036761426467307,
                "precision": 0.23214768526844648,
                "recall": 0.26877470355731226
            },
            {
                "hf_subset": "knc_Arab-pol_Latn",
                "languages": [
                    "knc-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.06422924901185771,
                "f1": 0.05471861993108544,
                "main_score": 0.05471861993108544,
                "precision": 0.05208482825359429,
                "recall": 0.06422924901185771
            },
            {
                "hf_subset": "mkd_Cyrl-pol_Latn",
                "languages": [
                    "mkd-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.04743083003952568,
                "f1": 0.038745999077711125,
                "main_score": 0.038745999077711125,
                "precision": 0.0366629005741631,
                "recall": 0.04743083003952568
            },
            {
                "hf_subset": "prs_Arab-pol_Latn",
                "languages": [
                    "prs-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.058300395256917,
                "f1": 0.0467672888868541,
                "main_score": 0.0467672888868541,
                "precision": 0.04385871767652376,
                "recall": 0.058300395256917
            },
            {
                "hf_subset": "swe_Latn-pol_Latn",
                "languages": [
                    "swe-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.391304347826087,
                "f1": 0.35408999166485877,
                "main_score": 0.35408999166485877,
                "precision": 0.34375008390818673,
                "recall": 0.391304347826087
            },
            {
                "hf_subset": "urd_Arab-pol_Latn",
                "languages": [
                    "urd-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.028656126482213436,
                "f1": 0.021988149976173207,
                "main_score": 0.021988149976173207,
                "precision": 0.020934232972037385,
                "recall": 0.028656126482213436
            },
            {
                "hf_subset": "aka_Latn-pol_Latn",
                "languages": [
                    "aka-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3488142292490119,
                "f1": 0.2974508937764049,
                "main_score": 0.2974508937764049,
                "precision": 0.28153705393466194,
                "recall": 0.3488142292490119
            },
            {
                "hf_subset": "bjn_Latn-pol_Latn",
                "languages": [
                    "bjn-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.18675889328063242,
                "f1": 0.1643948645657555,
                "main_score": 0.1643948645657555,
                "precision": 0.15862834370794615,
                "recall": 0.18675889328063242
            },
            {
                "hf_subset": "fao_Latn-pol_Latn",
                "languages": [
                    "fao-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.25395256916996045,
                "f1": 0.21625753426979183,
                "main_score": 0.21625753426979183,
                "precision": 0.20774449730898925,
                "recall": 0.25395256916996045
            },
            {
                "hf_subset": "ind_Latn-pol_Latn",
                "languages": [
                    "ind-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2549407114624506,
                "f1": 0.2289853629340138,
                "main_score": 0.2289853629340138,
                "precision": 0.2219346819224176,
                "recall": 0.2549407114624506
            },
            {
                "hf_subset": "knc_Latn-pol_Latn",
                "languages": [
                    "knc-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.26778656126482214,
                "f1": 0.2313512157580445,
                "main_score": 0.2313512157580445,
                "precision": 0.22197098986477734,
                "recall": 0.26778656126482214
            },
            {
                "hf_subset": "mlt_Latn-pol_Latn",
                "languages": [
                    "mlt-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2727272727272727,
                "f1": 0.2326113833343015,
                "main_score": 0.2326113833343015,
                "precision": 0.22291588018440425,
                "recall": 0.2727272727272727
            },
            {
                "hf_subset": "quy_Latn-pol_Latn",
                "languages": [
                    "quy-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.21640316205533597,
                "f1": 0.18324982985871474,
                "main_score": 0.18324982985871474,
                "precision": 0.17384170773661003,
                "recall": 0.21640316205533597
            },
            {
                "hf_subset": "swh_Latn-pol_Latn",
                "languages": [
                    "swh-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1650197628458498,
                "f1": 0.13784780581928224,
                "main_score": 0.13784780581928224,
                "precision": 0.1315906973436561,
                "recall": 0.1650197628458498
            },
            {
                "hf_subset": "uzn_Latn-pol_Latn",
                "languages": [
                    "uzn-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1373517786561265,
                "f1": 0.117621999636561,
                "main_score": 0.117621999636561,
                "precision": 0.11218645609306821,
                "recall": 0.1373517786561265
            },
            {
                "hf_subset": "als_Latn-pol_Latn",
                "languages": [
                    "als-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2964426877470356,
                "f1": 0.25093862889528457,
                "main_score": 0.25093862889528457,
                "precision": 0.2385649046493975,
                "recall": 0.2964426877470356
            },
            {
                "hf_subset": "bod_Tibt-pol_Latn",
                "languages": [
                    "bod-Tibt",
                    "pol-Latn"
                ],
                "accuracy": 0.018774703557312252,
                "f1": 0.014824273223482709,
                "main_score": 0.014824273223482709,
                "precision": 0.013969415351679186,
                "recall": 0.018774703557312252
            },
            {
                "hf_subset": "fij_Latn-pol_Latn",
                "languages": [
                    "fij-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.17588932806324112,
                "f1": 0.15044924633719348,
                "main_score": 0.15044924633719348,
                "precision": 0.14422284220226056,
                "recall": 0.17588932806324112
            },
            {
                "hf_subset": "isl_Latn-pol_Latn",
                "languages": [
                    "isl-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.20059288537549405,
                "f1": 0.16993604061124348,
                "main_score": 0.16993604061124348,
                "precision": 0.1638307404546514,
                "recall": 0.20059288537549405
            },
            {
                "hf_subset": "kon_Latn-pol_Latn",
                "languages": [
                    "kon-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.20059288537549405,
                "f1": 0.1730021401344778,
                "main_score": 0.1730021401344778,
                "precision": 0.165997172620091,
                "recall": 0.20059288537549405
            },
            {
                "hf_subset": "mni_Beng-pol_Latn",
                "languages": [
                    "mni-Beng",
                    "pol-Latn"
                ],
                "accuracy": 0.02766798418972332,
                "f1": 0.018188857320273998,
                "main_score": 0.018188857320273998,
                "precision": 0.01596105526645877,
                "recall": 0.02766798418972332
            },
            {
                "hf_subset": "ron_Latn-pol_Latn",
                "languages": [
                    "ron-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.44762845849802374,
                "f1": 0.4020969594868712,
                "main_score": 0.4020969594868712,
                "precision": 0.3892095571914066,
                "recall": 0.44762845849802374
            },
            {
                "hf_subset": "szl_Latn-pol_Latn",
                "languages": [
                    "szl-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.8893280632411067,
                "f1": 0.8611989459815547,
                "main_score": 0.8611989459815547,
                "precision": 0.8489295125164689,
                "recall": 0.8893280632411067
            },
            {
                "hf_subset": "vec_Latn-pol_Latn",
                "languages": [
                    "vec-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.33201581027667987,
                "f1": 0.3053786572808312,
                "main_score": 0.3053786572808312,
                "precision": 0.29781267755341256,
                "recall": 0.33201581027667987
            },
            {
                "hf_subset": "amh_Ethi-pol_Latn",
                "languages": [
                    "amh-Ethi",
                    "pol-Latn"
                ],
                "accuracy": 0.028656126482213436,
                "f1": 0.023343702175686536,
                "main_score": 0.023343702175686536,
                "precision": 0.02225088157792761,
                "recall": 0.028656126482213436
            },
            {
                "hf_subset": "bos_Latn-pol_Latn",
                "languages": [
                    "bos-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.4081027667984189,
                "f1": 0.35816068036824283,
                "main_score": 0.35816068036824283,
                "precision": 0.3436131947680184,
                "recall": 0.4081027667984189
            },
            {
                "hf_subset": "fin_Latn-pol_Latn",
                "languages": [
                    "fin-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.21047430830039526,
                "f1": 0.1832388688372778,
                "main_score": 0.1832388688372778,
                "precision": 0.17658364519639838,
                "recall": 0.21047430830039526
            },
            {
                "hf_subset": "ita_Latn-pol_Latn",
                "languages": [
                    "ita-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2628458498023715,
                "f1": 0.25328031148557845,
                "main_score": 0.25328031148557845,
                "precision": 0.250573427033527,
                "recall": 0.2628458498023715
            },
            {
                "hf_subset": "kor_Hang-pol_Latn",
                "languages": [
                    "kor-Hang",
                    "pol-Latn"
                ],
                "accuracy": 0.06225296442687747,
                "f1": 0.05624717838156572,
                "main_score": 0.05624717838156572,
                "precision": 0.054367762291103267,
                "recall": 0.06225296442687747
            },
            {
                "hf_subset": "mos_Latn-pol_Latn",
                "languages": [
                    "mos-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.19861660079051383,
                "f1": 0.16686949600048273,
                "main_score": 0.16686949600048273,
                "precision": 0.15759010718370875,
                "recall": 0.19861660079051383
            },
            {
                "hf_subset": "run_Latn-pol_Latn",
                "languages": [
                    "run-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1541501976284585,
                "f1": 0.12844131292483732,
                "main_score": 0.12844131292483732,
                "precision": 0.12239314986108213,
                "recall": 0.1541501976284585
            },
            {
                "hf_subset": "tam_Taml-pol_Latn",
                "languages": [
                    "tam-Taml",
                    "pol-Latn"
                ],
                "accuracy": 0.051383399209486175,
                "f1": 0.04107577623493304,
                "main_score": 0.04107577623493304,
                "precision": 0.038837297105930646,
                "recall": 0.051383399209486175
            },
            {
                "hf_subset": "vie_Latn-pol_Latn",
                "languages": [
                    "vie-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.25889328063241107,
                "f1": 0.2257939734887474,
                "main_score": 0.2257939734887474,
                "precision": 0.2159563855148396,
                "recall": 0.25889328063241107
            },
            {
                "hf_subset": "apc_Arab-pol_Latn",
                "languages": [
                    "apc-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.058300395256917,
                "f1": 0.04771345020289305,
                "main_score": 0.04771345020289305,
                "precision": 0.04531490987141249,
                "recall": 0.058300395256917
            },
            {
                "hf_subset": "bug_Latn-pol_Latn",
                "languages": [
                    "bug-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2391304347826087,
                "f1": 0.2007699048356012,
                "main_score": 0.2007699048356012,
                "precision": 0.19080003820912877,
                "recall": 0.2391304347826087
            },
            {
                "hf_subset": "fon_Latn-pol_Latn",
                "languages": [
                    "fon-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.24802371541501977,
                "f1": 0.21068053623570576,
                "main_score": 0.21068053623570576,
                "precision": 0.20049528384718315,
                "recall": 0.24802371541501977
            },
            {
                "hf_subset": "jav_Latn-pol_Latn",
                "languages": [
                    "jav-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.19861660079051383,
                "f1": 0.17825206026603302,
                "main_score": 0.17825206026603302,
                "precision": 0.17232613108208084,
                "recall": 0.19861660079051383
            },
            {
                "hf_subset": "lao_Laoo-pol_Latn",
                "languages": [
                    "lao-Laoo",
                    "pol-Latn"
                ],
                "accuracy": 0.28952569169960474,
                "f1": 0.2654588165457731,
                "main_score": 0.2654588165457731,
                "precision": 0.25711840655780316,
                "recall": 0.28952569169960474
            },
            {
                "hf_subset": "mri_Latn-pol_Latn",
                "languages": [
                    "mri-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.17786561264822132,
                "f1": 0.15783709557066813,
                "main_score": 0.15783709557066813,
                "precision": 0.15323213600988494,
                "recall": 0.17786561264822132
            },
            {
                "hf_subset": "rus_Cyrl-pol_Latn",
                "languages": [
                    "rus-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.05731225296442687,
                "f1": 0.046339809597844166,
                "main_score": 0.046339809597844166,
                "precision": 0.04381700463126679,
                "recall": 0.05731225296442687
            },
            {
                "hf_subset": "taq_Latn-pol_Latn",
                "languages": [
                    "taq-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2885375494071146,
                "f1": 0.24701670712301202,
                "main_score": 0.24701670712301202,
                "precision": 0.2347897679898959,
                "recall": 0.2885375494071146
            },
            {
                "hf_subset": "war_Latn-pol_Latn",
                "languages": [
                    "war-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.38636363636363635,
                "f1": 0.34295490067770984,
                "main_score": 0.34295490067770984,
                "precision": 0.33218625192208295,
                "recall": 0.38636363636363635
            },
            {
                "hf_subset": "arb_Arab-pol_Latn",
                "languages": [
                    "arb-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.036561264822134384,
                "f1": 0.027736769193664062,
                "main_score": 0.027736769193664062,
                "precision": 0.026137121358188072,
                "recall": 0.036561264822134384
            },
            {
                "hf_subset": "bul_Cyrl-pol_Latn",
                "languages": [
                    "bul-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.05632411067193676,
                "f1": 0.04504705439488048,
                "main_score": 0.04504705439488048,
                "precision": 0.042225823018678096,
                "recall": 0.05632411067193676
            },
            {
                "hf_subset": "fra_Latn-pol_Latn",
                "languages": [
                    "fra-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.45652173913043476,
                "f1": 0.42319337266121365,
                "main_score": 0.42319337266121365,
                "precision": 0.41337433711384974,
                "recall": 0.45652173913043476
            },
            {
                "hf_subset": "jpn_Jpan-pol_Latn",
                "languages": [
                    "jpn-Jpan",
                    "pol-Latn"
                ],
                "accuracy": 0.017786561264822136,
                "f1": 0.015436431670974948,
                "main_score": 0.015436431670974948,
                "precision": 0.014988121544095526,
                "recall": 0.017786561264822136
            },
            {
                "hf_subset": "lij_Latn-pol_Latn",
                "languages": [
                    "lij-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3211462450592885,
                "f1": 0.2984986909716806,
                "main_score": 0.2984986909716806,
                "precision": 0.29154947704114287,
                "recall": 0.3211462450592885
            },
            {
                "hf_subset": "mya_Mymr-pol_Latn",
                "languages": [
                    "mya-Mymr",
                    "pol-Latn"
                ],
                "accuracy": 0.05039525691699605,
                "f1": 0.04519431283756074,
                "main_score": 0.04519431283756074,
                "precision": 0.04356224477087554,
                "recall": 0.05039525691699605
            },
            {
                "hf_subset": "sag_Latn-pol_Latn",
                "languages": [
                    "sag-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.17094861660079055,
                "f1": 0.14637628173381545,
                "main_score": 0.14637628173381545,
                "precision": 0.14112004954025323,
                "recall": 0.17094861660079055
            },
            {
                "hf_subset": "taq_Tfng-pol_Latn",
                "languages": [
                    "taq-Tfng",
                    "pol-Latn"
                ],
                "accuracy": 0.05632411067193676,
                "f1": 0.049099143122330664,
                "main_score": 0.049099143122330664,
                "precision": 0.047246269450408024,
                "recall": 0.05632411067193676
            },
            {
                "hf_subset": "wol_Latn-pol_Latn",
                "languages": [
                    "wol-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2361660079051383,
                "f1": 0.20279347388097183,
                "main_score": 0.20279347388097183,
                "precision": 0.1946070794354514,
                "recall": 0.2361660079051383
            },
            {
                "hf_subset": "arb_Latn-pol_Latn",
                "languages": [
                    "arb-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.09288537549407115,
                "f1": 0.08086159010072054,
                "main_score": 0.08086159010072054,
                "precision": 0.07813028740140765,
                "recall": 0.09288537549407115
            },
            {
                "hf_subset": "cat_Latn-pol_Latn",
                "languages": [
                    "cat-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.38241106719367596,
                "f1": 0.3527552312466981,
                "main_score": 0.3527552312466981,
                "precision": 0.34317917226981665,
                "recall": 0.38241106719367596
            },
            {
                "hf_subset": "fur_Latn-pol_Latn",
                "languages": [
                    "fur-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3438735177865613,
                "f1": 0.31058068019828705,
                "main_score": 0.31058068019828705,
                "precision": 0.30052825623033735,
                "recall": 0.3438735177865613
            },
            {
                "hf_subset": "kab_Latn-pol_Latn",
                "languages": [
                    "kab-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.07806324110671936,
                "f1": 0.059028749973331435,
                "main_score": 0.059028749973331435,
                "precision": 0.05423746587330392,
                "recall": 0.07806324110671936
            },
            {
                "hf_subset": "lim_Latn-pol_Latn",
                "languages": [
                    "lim-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.39723320158102765,
                "f1": 0.35389001290356087,
                "main_score": 0.35389001290356087,
                "precision": 0.3413435535421377,
                "recall": 0.39723320158102765
            },
            {
                "hf_subset": "nld_Latn-pol_Latn",
                "languages": [
                    "nld-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.4209486166007905,
                "f1": 0.3793291320500714,
                "main_score": 0.3793291320500714,
                "precision": 0.36767114618952357,
                "recall": 0.4209486166007905
            },
            {
                "hf_subset": "san_Deva-pol_Latn",
                "languages": [
                    "san-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.05632411067193676,
                "f1": 0.046607417593965667,
                "main_score": 0.046607417593965667,
                "precision": 0.044309567526363815,
                "recall": 0.05632411067193676
            },
            {
                "hf_subset": "tat_Cyrl-pol_Latn",
                "languages": [
                    "tat-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.05928853754940711,
                "f1": 0.04929180488481535,
                "main_score": 0.04929180488481535,
                "precision": 0.04674956123463861,
                "recall": 0.05928853754940711
            },
            {
                "hf_subset": "xho_Latn-pol_Latn",
                "languages": [
                    "xho-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.16403162055335968,
                "f1": 0.141584637782076,
                "main_score": 0.141584637782076,
                "precision": 0.13551169277747055,
                "recall": 0.16403162055335968
            },
            {
                "hf_subset": "ars_Arab-pol_Latn",
                "languages": [
                    "ars-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.020750988142292492,
                "f1": 0.01566300172914419,
                "main_score": 0.01566300172914419,
                "precision": 0.015034847066262734,
                "recall": 0.020750988142292492
            },
            {
                "hf_subset": "ceb_Latn-pol_Latn",
                "languages": [
                    "ceb-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2776679841897233,
                "f1": 0.25138248191646634,
                "main_score": 0.25138248191646634,
                "precision": 0.2452148356634336,
                "recall": 0.2776679841897233
            },
            {
                "hf_subset": "fuv_Latn-pol_Latn",
                "languages": [
                    "fuv-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.20652173913043476,
                "f1": 0.18497889827878236,
                "main_score": 0.18497889827878236,
                "precision": 0.17894908363824175,
                "recall": 0.20652173913043476
            },
            {
                "hf_subset": "kac_Latn-pol_Latn",
                "languages": [
                    "kac-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.18675889328063242,
                "f1": 0.16475002640909453,
                "main_score": 0.16475002640909453,
                "precision": 0.15965045864487637,
                "recall": 0.18675889328063242
            },
            {
                "hf_subset": "lin_Latn-pol_Latn",
                "languages": [
                    "lin-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.19861660079051383,
                "f1": 0.16669395867367937,
                "main_score": 0.16669395867367937,
                "precision": 0.15996611411786904,
                "recall": 0.19861660079051383
            },
            {
                "hf_subset": "nno_Latn-pol_Latn",
                "languages": [
                    "nno-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.37747035573122534,
                "f1": 0.33437501473239356,
                "main_score": 0.33437501473239356,
                "precision": 0.3226544682279166,
                "recall": 0.37747035573122534
            },
            {
                "hf_subset": "sat_Olck-pol_Latn",
                "languages": [
                    "sat-Olck",
                    "pol-Latn"
                ],
                "accuracy": 0.009881422924901186,
                "f1": 0.00738017708056005,
                "main_score": 0.00738017708056005,
                "precision": 0.0069180210913027075,
                "recall": 0.009881422924901186
            },
            {
                "hf_subset": "tel_Telu-pol_Latn",
                "languages": [
                    "tel-Telu",
                    "pol-Latn"
                ],
                "accuracy": 0.07806324110671936,
                "f1": 0.06455909948121061,
                "main_score": 0.06455909948121061,
                "precision": 0.0610016680289029,
                "recall": 0.07806324110671936
            },
            {
                "hf_subset": "ydd_Hebr-pol_Latn",
                "languages": [
                    "ydd-Hebr",
                    "pol-Latn"
                ],
                "accuracy": 0.058300395256917,
                "f1": 0.04714103592822127,
                "main_score": 0.04714103592822127,
                "precision": 0.044186103202901617,
                "recall": 0.058300395256917
            },
            {
                "hf_subset": "ary_Arab-pol_Latn",
                "languages": [
                    "ary-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.039525691699604744,
                "f1": 0.03038700967670975,
                "main_score": 0.03038700967670975,
                "precision": 0.02852792175238853,
                "recall": 0.039525691699604744
            },
            {
                "hf_subset": "ces_Latn-pol_Latn",
                "languages": [
                    "ces-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.43379446640316205,
                "f1": 0.3833097409419722,
                "main_score": 0.3833097409419722,
                "precision": 0.3681077971825639,
                "recall": 0.43379446640316205
            },
            {
                "hf_subset": "gaz_Latn-pol_Latn",
                "languages": [
                    "gaz-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.04841897233201581,
                "f1": 0.03749327265034994,
                "main_score": 0.03749327265034994,
                "precision": 0.035976880947568186,
                "recall": 0.04841897233201581
            },
            {
                "hf_subset": "kam_Latn-pol_Latn",
                "languages": [
                    "kam-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.22826086956521738,
                "f1": 0.1926086834997352,
                "main_score": 0.1926086834997352,
                "precision": 0.18374103098537437,
                "recall": 0.22826086956521738
            },
            {
                "hf_subset": "lit_Latn-pol_Latn",
                "languages": [
                    "lit-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2450592885375494,
                "f1": 0.2041895151835619,
                "main_score": 0.2041895151835619,
                "precision": 0.19338293047532176,
                "recall": 0.2450592885375494
            },
            {
                "hf_subset": "nob_Latn-pol_Latn",
                "languages": [
                    "nob-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.366600790513834,
                "f1": 0.32779729506686694,
                "main_score": 0.32779729506686694,
                "precision": 0.31673807638587903,
                "recall": 0.366600790513834
            },
            {
                "hf_subset": "scn_Latn-pol_Latn",
                "languages": [
                    "scn-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.20652173913043476,
                "f1": 0.19096313327161268,
                "main_score": 0.19096313327161268,
                "precision": 0.18581988487605428,
                "recall": 0.20652173913043476
            },
            {
                "hf_subset": "tgk_Cyrl-pol_Latn",
                "languages": [
                    "tgk-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.05533596837944664,
                "f1": 0.045542630094656505,
                "main_score": 0.045542630094656505,
                "precision": 0.04305510392181988,
                "recall": 0.05533596837944664
            },
            {
                "hf_subset": "yor_Latn-pol_Latn",
                "languages": [
                    "yor-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.24011857707509882,
                "f1": 0.20485228368008498,
                "main_score": 0.20485228368008498,
                "precision": 0.19307145104230647,
                "recall": 0.24011857707509882
            },
            {
                "hf_subset": "arz_Arab-pol_Latn",
                "languages": [
                    "arz-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.028656126482213436,
                "f1": 0.020503823433892912,
                "main_score": 0.020503823433892912,
                "precision": 0.019244732677291966,
                "recall": 0.028656126482213436
            },
            {
                "hf_subset": "cjk_Latn-pol_Latn",
                "languages": [
                    "cjk-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1590909090909091,
                "f1": 0.1309469707904024,
                "main_score": 0.1309469707904024,
                "precision": 0.12451127946209137,
                "recall": 0.1590909090909091
            },
            {
                "hf_subset": "gla_Latn-pol_Latn",
                "languages": [
                    "gla-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1422924901185771,
                "f1": 0.118958091961019,
                "main_score": 0.118958091961019,
                "precision": 0.11308813312132354,
                "recall": 0.1422924901185771
            },
            {
                "hf_subset": "kan_Knda-pol_Latn",
                "languages": [
                    "kan-Knda",
                    "pol-Latn"
                ],
                "accuracy": 0.04446640316205533,
                "f1": 0.03543866950918991,
                "main_score": 0.03543866950918991,
                "precision": 0.03344953602611705,
                "recall": 0.04446640316205533
            },
            {
                "hf_subset": "lmo_Latn-pol_Latn",
                "languages": [
                    "lmo-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3181818181818182,
                "f1": 0.2884565227513798,
                "main_score": 0.2884565227513798,
                "precision": 0.27901861094548847,
                "recall": 0.3181818181818182
            },
            {
                "hf_subset": "npi_Deva-pol_Latn",
                "languages": [
                    "npi-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.06126482213438735,
                "f1": 0.049952967747036815,
                "main_score": 0.049952967747036815,
                "precision": 0.04716743907131579,
                "recall": 0.06126482213438735
            },
            {
                "hf_subset": "shn_Mymr-pol_Latn",
                "languages": [
                    "shn-Mymr",
                    "pol-Latn"
                ],
                "accuracy": 0.3241106719367589,
                "f1": 0.2933468087609507,
                "main_score": 0.2933468087609507,
                "precision": 0.28217299436243537,
                "recall": 0.3241106719367589
            },
            {
                "hf_subset": "tgl_Latn-pol_Latn",
                "languages": [
                    "tgl-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.199604743083004,
                "f1": 0.17358391772917464,
                "main_score": 0.17358391772917464,
                "precision": 0.16714674395610596,
                "recall": 0.199604743083004
            },
            {
                "hf_subset": "yue_Hant-pol_Latn",
                "languages": [
                    "yue-Hant",
                    "pol-Latn"
                ],
                "accuracy": 0.058300395256917,
                "f1": 0.051056101485728575,
                "main_score": 0.051056101485728575,
                "precision": 0.04867798538747156,
                "recall": 0.058300395256917
            },
            {
                "hf_subset": "asm_Beng-pol_Latn",
                "languages": [
                    "asm-Beng",
                    "pol-Latn"
                ],
                "accuracy": 0.02766798418972332,
                "f1": 0.02107641729569896,
                "main_score": 0.02107641729569896,
                "precision": 0.019539846461201958,
                "recall": 0.02766798418972332
            },
            {
                "hf_subset": "ckb_Arab-pol_Latn",
                "languages": [
                    "ckb-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.024703557312252964,
                "f1": 0.01760325609342171,
                "main_score": 0.01760325609342171,
                "precision": 0.015924946194322373,
                "recall": 0.024703557312252964
            },
            {
                "hf_subset": "gle_Latn-pol_Latn",
                "languages": [
                    "gle-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.17490118577075098,
                "f1": 0.151736996743734,
                "main_score": 0.151736996743734,
                "precision": 0.14611817031828728,
                "recall": 0.17490118577075098
            },
            {
                "hf_subset": "kas_Arab-pol_Latn",
                "languages": [
                    "kas-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.041501976284584984,
                "f1": 0.034109750619615437,
                "main_score": 0.034109750619615437,
                "precision": 0.032236152439722526,
                "recall": 0.041501976284584984
            },
            {
                "hf_subset": "ltg_Latn-pol_Latn",
                "languages": [
                    "ltg-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.26778656126482214,
                "f1": 0.22413478254607036,
                "main_score": 0.22413478254607036,
                "precision": 0.21276900635762036,
                "recall": 0.26778656126482214
            },
            {
                "hf_subset": "nso_Latn-pol_Latn",
                "languages": [
                    "nso-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.24011857707509882,
                "f1": 0.20924527200344736,
                "main_score": 0.20924527200344736,
                "precision": 0.2022077114271249,
                "recall": 0.24011857707509882
            },
            {
                "hf_subset": "sin_Sinh-pol_Latn",
                "languages": [
                    "sin-Sinh",
                    "pol-Latn"
                ],
                "accuracy": 0.043478260869565216,
                "f1": 0.03346071948603057,
                "main_score": 0.03346071948603057,
                "precision": 0.030958155100771288,
                "recall": 0.043478260869565216
            },
            {
                "hf_subset": "tha_Thai-pol_Latn",
                "languages": [
                    "tha-Thai",
                    "pol-Latn"
                ],
                "accuracy": 0.10177865612648221,
                "f1": 0.0903960816616096,
                "main_score": 0.0903960816616096,
                "precision": 0.08720792794162359,
                "recall": 0.10177865612648221
            },
            {
                "hf_subset": "zho_Hans-pol_Latn",
                "languages": [
                    "zho-Hans",
                    "pol-Latn"
                ],
                "accuracy": 0.11166007905138339,
                "f1": 0.09816083127794206,
                "main_score": 0.09816083127794206,
                "precision": 0.09449149883932492,
                "recall": 0.11166007905138339
            },
            {
                "hf_subset": "ast_Latn-pol_Latn",
                "languages": [
                    "ast-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.30434782608695654,
                "f1": 0.2820427596119296,
                "main_score": 0.2820427596119296,
                "precision": 0.27513652569681574,
                "recall": 0.30434782608695654
            },
            {
                "hf_subset": "crh_Latn-pol_Latn",
                "languages": [
                    "crh-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2075098814229249,
                "f1": 0.1777221970878066,
                "main_score": 0.1777221970878066,
                "precision": 0.1705363389516053,
                "recall": 0.2075098814229249
            },
            {
                "hf_subset": "glg_Latn-pol_Latn",
                "languages": [
                    "glg-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3537549407114625,
                "f1": 0.32855499945461086,
                "main_score": 0.32855499945461086,
                "precision": 0.32226121353357784,
                "recall": 0.3537549407114625
            },
            {
                "hf_subset": "kas_Deva-pol_Latn",
                "languages": [
                    "kas-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.16403162055335968,
                "f1": 0.1419769011598097,
                "main_score": 0.1419769011598097,
                "precision": 0.13509038094724146,
                "recall": 0.16403162055335968
            },
            {
                "hf_subset": "ltz_Latn-pol_Latn",
                "languages": [
                    "ltz-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3784584980237154,
                "f1": 0.3344048344372484,
                "main_score": 0.3344048344372484,
                "precision": 0.3205143506407127,
                "recall": 0.3784584980237154
            },
            {
                "hf_subset": "nus_Latn-pol_Latn",
                "languages": [
                    "nus-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.12845849802371542,
                "f1": 0.10896227857585186,
                "main_score": 0.10896227857585186,
                "precision": 0.10294754358350082,
                "recall": 0.12845849802371542
            },
            {
                "hf_subset": "slk_Latn-pol_Latn",
                "languages": [
                    "slk-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.41007905138339923,
                "f1": 0.3601972871344834,
                "main_score": 0.3601972871344834,
                "precision": 0.3453039152909103,
                "recall": 0.41007905138339923
            },
            {
                "hf_subset": "tir_Ethi-pol_Latn",
                "languages": [
                    "tir-Ethi",
                    "pol-Latn"
                ],
                "accuracy": 0.0266798418972332,
                "f1": 0.022198721083844956,
                "main_score": 0.022198721083844956,
                "precision": 0.021499716421629077,
                "recall": 0.0266798418972332
            },
            {
                "hf_subset": "zho_Hant-pol_Latn",
                "languages": [
                    "zho-Hant",
                    "pol-Latn"
                ],
                "accuracy": 0.07312252964426877,
                "f1": 0.06340388250223482,
                "main_score": 0.06340388250223482,
                "precision": 0.06111030998564803,
                "recall": 0.07312252964426877
            },
            {
                "hf_subset": "awa_Deva-pol_Latn",
                "languages": [
                    "awa-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.03359683794466403,
                "f1": 0.02579158411169609,
                "main_score": 0.02579158411169609,
                "precision": 0.024039193627267582,
                "recall": 0.03359683794466403
            },
            {
                "hf_subset": "cym_Latn-pol_Latn",
                "languages": [
                    "cym-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.20355731225296442,
                "f1": 0.18287058620527255,
                "main_score": 0.18287058620527255,
                "precision": 0.17703828843123412,
                "recall": 0.20355731225296442
            },
            {
                "hf_subset": "grn_Latn-pol_Latn",
                "languages": [
                    "grn-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2855731225296443,
                "f1": 0.249187073406344,
                "main_score": 0.249187073406344,
                "precision": 0.2394005390404111,
                "recall": 0.2855731225296443
            },
            {
                "hf_subset": "kat_Geor-pol_Latn",
                "languages": [
                    "kat-Geor",
                    "pol-Latn"
                ],
                "accuracy": 0.06027667984189724,
                "f1": 0.04838828225825765,
                "main_score": 0.04838828225825765,
                "precision": 0.045303763753105464,
                "recall": 0.06027667984189724
            },
            {
                "hf_subset": "lua_Latn-pol_Latn",
                "languages": [
                    "lua-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.21936758893280633,
                "f1": 0.19137345487494034,
                "main_score": 0.19137345487494034,
                "precision": 0.1850076951838475,
                "recall": 0.21936758893280633
            },
            {
                "hf_subset": "nya_Latn-pol_Latn",
                "languages": [
                    "nya-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.22727272727272727,
                "f1": 0.19352203630458406,
                "main_score": 0.19352203630458406,
                "precision": 0.18403212982984027,
                "recall": 0.22727272727272727
            },
            {
                "hf_subset": "slv_Latn-pol_Latn",
                "languages": [
                    "slv-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3458498023715415,
                "f1": 0.29987852862596537,
                "main_score": 0.29987852862596537,
                "precision": 0.2867320439878897,
                "recall": 0.3458498023715415
            },
            {
                "hf_subset": "tpi_Latn-pol_Latn",
                "languages": [
                    "tpi-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.4950592885375494,
                "f1": 0.4507371755426884,
                "main_score": 0.4507371755426884,
                "precision": 0.43583045144983984,
                "recall": 0.4950592885375494
            },
            {
                "hf_subset": "zsm_Latn-pol_Latn",
                "languages": [
                    "zsm-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2440711462450593,
                "f1": 0.2196257404337446,
                "main_score": 0.2196257404337446,
                "precision": 0.21242868844120003,
                "recall": 0.2440711462450593
            },
            {
                "hf_subset": "ayr_Latn-pol_Latn",
                "languages": [
                    "ayr-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1976284584980237,
                "f1": 0.1661210544522444,
                "main_score": 0.1661210544522444,
                "precision": 0.1590306566825407,
                "recall": 0.1976284584980237
            },
            {
                "hf_subset": "dan_Latn-pol_Latn",
                "languages": [
                    "dan-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.41798418972332013,
                "f1": 0.3728920180969047,
                "main_score": 0.3728920180969047,
                "precision": 0.35936571335209405,
                "recall": 0.41798418972332013
            },
            {
                "hf_subset": "guj_Gujr-pol_Latn",
                "languages": [
                    "guj-Gujr",
                    "pol-Latn"
                ],
                "accuracy": 0.03260869565217391,
                "f1": 0.025249735724995687,
                "main_score": 0.025249735724995687,
                "precision": 0.02388309383138791,
                "recall": 0.03260869565217391
            },
            {
                "hf_subset": "kaz_Cyrl-pol_Latn",
                "languages": [
                    "kaz-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.0741106719367589,
                "f1": 0.06058280483075661,
                "main_score": 0.06058280483075661,
                "precision": 0.057575799525617824,
                "recall": 0.0741106719367589
            },
            {
                "hf_subset": "lug_Latn-pol_Latn",
                "languages": [
                    "lug-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.17885375494071146,
                "f1": 0.15521929947232882,
                "main_score": 0.15521929947232882,
                "precision": 0.14947095140298922,
                "recall": 0.17885375494071146
            },
            {
                "hf_subset": "oci_Latn-pol_Latn",
                "languages": [
                    "oci-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.43478260869565216,
                "f1": 0.40473186347521906,
                "main_score": 0.40473186347521906,
                "precision": 0.3959450765088603,
                "recall": 0.43478260869565216
            },
            {
                "hf_subset": "smo_Latn-pol_Latn",
                "languages": [
                    "smo-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.17588932806324112,
                "f1": 0.15690160809698228,
                "main_score": 0.15690160809698228,
                "precision": 0.1515656476627905,
                "recall": 0.17588932806324112
            },
            {
                "hf_subset": "tsn_Latn-pol_Latn",
                "languages": [
                    "tsn-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2134387351778656,
                "f1": 0.18434350717459363,
                "main_score": 0.18434350717459363,
                "precision": 0.17774574235822616,
                "recall": 0.2134387351778656
            },
            {
                "hf_subset": "zul_Latn-pol_Latn",
                "languages": [
                    "zul-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.116600790513834,
                "f1": 0.09735829734910534,
                "main_score": 0.09735829734910534,
                "precision": 0.09312566681548638,
                "recall": 0.116600790513834
            },
            {
                "hf_subset": "azb_Arab-pol_Latn",
                "languages": [
                    "azb-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.021739130434782608,
                "f1": 0.015873015873015872,
                "main_score": 0.015873015873015872,
                "precision": 0.014545689817428948,
                "recall": 0.021739130434782608
            },
            {
                "hf_subset": "deu_Latn-pol_Latn",
                "languages": [
                    "deu-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.44762845849802374,
                "f1": 0.41122929875875225,
                "main_score": 0.41122929875875225,
                "precision": 0.3992950680327162,
                "recall": 0.44762845849802374
            },
            {
                "hf_subset": "hat_Latn-pol_Latn",
                "languages": [
                    "hat-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.22332015810276679,
                "f1": 0.18967394150492095,
                "main_score": 0.18967394150492095,
                "precision": 0.18182537641253294,
                "recall": 0.22332015810276679
            },
            {
                "hf_subset": "kbp_Latn-pol_Latn",
                "languages": [
                    "kbp-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.21245059288537546,
                "f1": 0.1809991436613242,
                "main_score": 0.1809991436613242,
                "precision": 0.17252105388177374,
                "recall": 0.21245059288537546
            },
            {
                "hf_subset": "luo_Latn-pol_Latn",
                "languages": [
                    "luo-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.22233201581027667,
                "f1": 0.18449176192713168,
                "main_score": 0.18449176192713168,
                "precision": 0.17624851982025028,
                "recall": 0.22233201581027667
            },
            {
                "hf_subset": "ory_Orya-pol_Latn",
                "languages": [
                    "ory-Orya",
                    "pol-Latn"
                ],
                "accuracy": 0.043478260869565216,
                "f1": 0.03611531226271985,
                "main_score": 0.03611531226271985,
                "precision": 0.03468918020129858,
                "recall": 0.043478260869565216
            },
            {
                "hf_subset": "sna_Latn-pol_Latn",
                "languages": [
                    "sna-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.15217391304347827,
                "f1": 0.12702456926626832,
                "main_score": 0.12702456926626832,
                "precision": 0.12135158314143617,
                "recall": 0.15217391304347827
            },
            {
                "hf_subset": "tso_Latn-pol_Latn",
                "languages": [
                    "tso-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.18181818181818182,
                "f1": 0.15288851001752626,
                "main_score": 0.15288851001752626,
                "precision": 0.1465094599135298,
                "recall": 0.18181818181818182
            },
            {
                "hf_subset": "azj_Latn-pol_Latn",
                "languages": [
                    "azj-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1857707509881423,
                "f1": 0.14966220609361827,
                "main_score": 0.14966220609361827,
                "precision": 0.13961871486067762,
                "recall": 0.1857707509881423
            },
            {
                "hf_subset": "dik_Latn-pol_Latn",
                "languages": [
                    "dik-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.32707509881422925,
                "f1": 0.2822133496338573,
                "main_score": 0.2822133496338573,
                "precision": 0.26929658124002465,
                "recall": 0.32707509881422925
            },
            {
                "hf_subset": "hau_Latn-pol_Latn",
                "languages": [
                    "hau-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.17490118577075098,
                "f1": 0.15013241657524787,
                "main_score": 0.15013241657524787,
                "precision": 0.14360189776791413,
                "recall": 0.17490118577075098
            },
            {
                "hf_subset": "kea_Latn-pol_Latn",
                "languages": [
                    "kea-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2924901185770751,
                "f1": 0.25728171141197725,
                "main_score": 0.25728171141197725,
                "precision": 0.2484571473523488,
                "recall": 0.2924901185770751
            },
            {
                "hf_subset": "lus_Latn-pol_Latn",
                "languages": [
                    "lus-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.37450592885375494,
                "f1": 0.34152227333915497,
                "main_score": 0.34152227333915497,
                "precision": 0.3311133967978197,
                "recall": 0.37450592885375494
            },
            {
                "hf_subset": "pag_Latn-pol_Latn",
                "languages": [
                    "pag-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.4644268774703557,
                "f1": 0.4255956424045618,
                "main_score": 0.4255956424045618,
                "precision": 0.41308049408906067,
                "recall": 0.4644268774703557
            },
            {
                "hf_subset": "snd_Arab-pol_Latn",
                "languages": [
                    "snd-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.05731225296442687,
                "f1": 0.04418129345402073,
                "main_score": 0.04418129345402073,
                "precision": 0.040807353936948336,
                "recall": 0.05731225296442687
            },
            {
                "hf_subset": "tuk_Latn-pol_Latn",
                "languages": [
                    "tuk-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.18478260869565216,
                "f1": 0.1455948958426208,
                "main_score": 0.1455948958426208,
                "precision": 0.13576842652514323,
                "recall": 0.18478260869565216
            },
            {
                "hf_subset": "bak_Cyrl-pol_Latn",
                "languages": [
                    "bak-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.05731225296442687,
                "f1": 0.045234598834399536,
                "main_score": 0.045234598834399536,
                "precision": 0.042460184752788496,
                "recall": 0.05731225296442687
            },
            {
                "hf_subset": "dyu_Latn-pol_Latn",
                "languages": [
                    "dyu-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.17885375494071146,
                "f1": 0.15287973467865343,
                "main_score": 0.15287973467865343,
                "precision": 0.14602748983645134,
                "recall": 0.17885375494071146
            },
            {
                "hf_subset": "heb_Hebr-pol_Latn",
                "languages": [
                    "heb-Hebr",
                    "pol-Latn"
                ],
                "accuracy": 0.05434782608695652,
                "f1": 0.044141709247667194,
                "main_score": 0.044141709247667194,
                "precision": 0.041908471870733245,
                "recall": 0.05434782608695652
            },
            {
                "hf_subset": "khk_Cyrl-pol_Latn",
                "languages": [
                    "khk-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.038537549407114624,
                "f1": 0.027896363021461555,
                "main_score": 0.027896363021461555,
                "precision": 0.025541764629021538,
                "recall": 0.038537549407114624
            },
            {
                "hf_subset": "lvs_Latn-pol_Latn",
                "languages": [
                    "lvs-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.1976284584980237,
                "f1": 0.1595516453180757,
                "main_score": 0.1595516453180757,
                "precision": 0.1479353339363382,
                "recall": 0.1976284584980237
            },
            {
                "hf_subset": "pan_Guru-pol_Latn",
                "languages": [
                    "pan-Guru",
                    "pol-Latn"
                ],
                "accuracy": 0.041501976284584984,
                "f1": 0.0319295355133975,
                "main_score": 0.0319295355133975,
                "precision": 0.029599821585651342,
                "recall": 0.041501976284584984
            },
            {
                "hf_subset": "som_Latn-pol_Latn",
                "languages": [
                    "som-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.15217391304347827,
                "f1": 0.13211426918534308,
                "main_score": 0.13211426918534308,
                "precision": 0.12706032748562593,
                "recall": 0.15217391304347827
            },
            {
                "hf_subset": "tum_Latn-pol_Latn",
                "languages": [
                    "tum-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.21739130434782608,
                "f1": 0.1812344158190285,
                "main_score": 0.1812344158190285,
                "precision": 0.17177114905727348,
                "recall": 0.21739130434782608
            }
        ]
    }
}