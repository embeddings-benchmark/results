{
    "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
    "task_name": "NTREXBitextMining",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "arb_Arab-pol_Latn",
                "languages": [
                    "arb-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.026039058587881823,
                "f1": 0.017420063165137074,
                "main_score": 0.017420063165137074,
                "precision": 0.015987458678183387,
                "recall": 0.026039058587881823
            },
            {
                "hf_subset": "bel_Cyrl-pol_Latn",
                "languages": [
                    "bel-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.0671006509764647,
                "f1": 0.05379820175253383,
                "main_score": 0.05379820175253383,
                "precision": 0.050060278870963246,
                "recall": 0.0671006509764647
            },
            {
                "hf_subset": "ben_Beng-pol_Latn",
                "languages": [
                    "ben-Beng",
                    "pol-Latn"
                ],
                "accuracy": 0.010015022533800702,
                "f1": 0.00657269658938351,
                "main_score": 0.00657269658938351,
                "precision": 0.005774496357952187,
                "recall": 0.010015022533800702
            },
            {
                "hf_subset": "bos_Latn-pol_Latn",
                "languages": [
                    "bos-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.414621932899349,
                "f1": 0.36566294033782604,
                "main_score": 0.36566294033782604,
                "precision": 0.3494809949228646,
                "recall": 0.414621932899349
            },
            {
                "hf_subset": "bul_Cyrl-pol_Latn",
                "languages": [
                    "bul-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.07611417125688533,
                "f1": 0.06256776694331179,
                "main_score": 0.06256776694331179,
                "precision": 0.059087199342302624,
                "recall": 0.07611417125688533
            },
            {
                "hf_subset": "ces_Latn-pol_Latn",
                "languages": [
                    "ces-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.4456685027541312,
                "f1": 0.39631029957278474,
                "main_score": 0.39631029957278474,
                "precision": 0.37921731033511913,
                "recall": 0.4456685027541312
            },
            {
                "hf_subset": "deu_Latn-pol_Latn",
                "languages": [
                    "deu-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.414621932899349,
                "f1": 0.3733454445419768,
                "main_score": 0.3733454445419768,
                "precision": 0.3595442215997948,
                "recall": 0.414621932899349
            },
            {
                "hf_subset": "ell_Grek-pol_Latn",
                "languages": [
                    "ell-Grek",
                    "pol-Latn"
                ],
                "accuracy": 0.08462694041061593,
                "f1": 0.06808768489495289,
                "main_score": 0.06808768489495289,
                "precision": 0.06376933631700837,
                "recall": 0.08462694041061593
            },
            {
                "hf_subset": "eng_Latn-pol_Latn",
                "languages": [
                    "eng-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.9684526790185278,
                "f1": 0.959472542146553,
                "main_score": 0.959472542146553,
                "precision": 0.9552411951260225,
                "recall": 0.9684526790185278
            },
            {
                "hf_subset": "fas_Arab-pol_Latn",
                "languages": [
                    "fas-Arab",
                    "pol-Latn"
                ],
                "accuracy": 0.11817726589884828,
                "f1": 0.10601177340803875,
                "main_score": 0.10601177340803875,
                "precision": 0.10223703198232055,
                "recall": 0.11817726589884828
            },
            {
                "hf_subset": "fin_Latn-pol_Latn",
                "languages": [
                    "fin-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.24136204306459688,
                "f1": 0.2011481738578615,
                "main_score": 0.2011481738578615,
                "precision": 0.19018296909416654,
                "recall": 0.24136204306459688
            },
            {
                "hf_subset": "fra_Latn-pol_Latn",
                "languages": [
                    "fra-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.4341512268402605,
                "f1": 0.39735128280412835,
                "main_score": 0.39735128280412835,
                "precision": 0.38615475266726035,
                "recall": 0.4341512268402605
            },
            {
                "hf_subset": "heb_Hebr-pol_Latn",
                "languages": [
                    "heb-Hebr",
                    "pol-Latn"
                ],
                "accuracy": 0.05107661492238358,
                "f1": 0.03746932046939864,
                "main_score": 0.03746932046939864,
                "precision": 0.034073111528601915,
                "recall": 0.05107661492238358
            },
            {
                "hf_subset": "hin_Deva-pol_Latn",
                "languages": [
                    "hin-Deva",
                    "pol-Latn"
                ],
                "accuracy": 0.03755633450175263,
                "f1": 0.02697943041104679,
                "main_score": 0.02697943041104679,
                "precision": 0.02476982778272265,
                "recall": 0.03755633450175263
            },
            {
                "hf_subset": "hrv_Latn-pol_Latn",
                "languages": [
                    "hrv-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.41612418627941916,
                "f1": 0.36743103861321136,
                "main_score": 0.36743103861321136,
                "precision": 0.3508204010628832,
                "recall": 0.41612418627941916
            },
            {
                "hf_subset": "hun_Latn-pol_Latn",
                "languages": [
                    "hun-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.25187781672508763,
                "f1": 0.21589008204041268,
                "main_score": 0.21589008204041268,
                "precision": 0.20550856861808545,
                "recall": 0.25187781672508763
            },
            {
                "hf_subset": "ind_Latn-pol_Latn",
                "languages": [
                    "ind-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2538808212318478,
                "f1": 0.22027865588136555,
                "main_score": 0.22027865588136555,
                "precision": 0.2102193156294836,
                "recall": 0.2538808212318478
            },
            {
                "hf_subset": "jpn_Jpan-pol_Latn",
                "languages": [
                    "jpn-Jpan",
                    "pol-Latn"
                ],
                "accuracy": 0.014521782674011018,
                "f1": 0.011551267029994832,
                "main_score": 0.011551267029994832,
                "precision": 0.010709350063506406,
                "recall": 0.014521782674011018
            },
            {
                "hf_subset": "kor_Hang-pol_Latn",
                "languages": [
                    "kor-Hang",
                    "pol-Latn"
                ],
                "accuracy": 0.08662994491737606,
                "f1": 0.07702831195040925,
                "main_score": 0.07702831195040925,
                "precision": 0.07399493724590964,
                "recall": 0.08662994491737606
            },
            {
                "hf_subset": "lit_Latn-pol_Latn",
                "languages": [
                    "lit-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.27240861291937907,
                "f1": 0.22675680128857242,
                "main_score": 0.22675680128857242,
                "precision": 0.21345389137270301,
                "recall": 0.27240861291937907
            },
            {
                "hf_subset": "mkd_Cyrl-pol_Latn",
                "languages": [
                    "mkd-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.05257886830245369,
                "f1": 0.04206059607176409,
                "main_score": 0.04206059607176409,
                "precision": 0.039704622621726124,
                "recall": 0.05257886830245369
            },
            {
                "hf_subset": "nld_Latn-pol_Latn",
                "languages": [
                    "nld-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.4166249374061092,
                "f1": 0.37072982587430486,
                "main_score": 0.37072982587430486,
                "precision": 0.35627870316142846,
                "recall": 0.4166249374061092
            },
            {
                "hf_subset": "pol_Latn-arb_Arab",
                "languages": [
                    "pol-Latn",
                    "arb-Arab"
                ],
                "accuracy": 0.04606910365548322,
                "f1": 0.0246942582684724,
                "main_score": 0.0246942582684724,
                "precision": 0.021050793953671144,
                "recall": 0.04606910365548322
            },
            {
                "hf_subset": "pol_Latn-bel_Cyrl",
                "languages": [
                    "pol-Latn",
                    "bel-Cyrl"
                ],
                "accuracy": 0.08662994491737606,
                "f1": 0.05182695919286112,
                "main_score": 0.05182695919286112,
                "precision": 0.04489760167778365,
                "recall": 0.08662994491737606
            },
            {
                "hf_subset": "pol_Latn-ben_Beng",
                "languages": [
                    "pol-Latn",
                    "ben-Beng"
                ],
                "accuracy": 0.026539809714571858,
                "f1": 0.01258614201836631,
                "main_score": 0.01258614201836631,
                "precision": 0.010713961698889642,
                "recall": 0.026539809714571858
            },
            {
                "hf_subset": "pol_Latn-bos_Latn",
                "languages": [
                    "pol-Latn",
                    "bos-Latn"
                ],
                "accuracy": 0.36554832248372565,
                "f1": 0.29774094494365305,
                "main_score": 0.29774094494365305,
                "precision": 0.2780072080015492,
                "recall": 0.36554832248372565
            },
            {
                "hf_subset": "pol_Latn-bul_Cyrl",
                "languages": [
                    "pol-Latn",
                    "bul-Cyrl"
                ],
                "accuracy": 0.10015022533800702,
                "f1": 0.06883913130592241,
                "main_score": 0.06883913130592241,
                "precision": 0.0616024442614442,
                "recall": 0.10015022533800702
            },
            {
                "hf_subset": "pol_Latn-ces_Latn",
                "languages": [
                    "pol-Latn",
                    "ces-Latn"
                ],
                "accuracy": 0.4206309464196295,
                "f1": 0.3437855522401382,
                "main_score": 0.3437855522401382,
                "precision": 0.3196283943995953,
                "recall": 0.4206309464196295
            },
            {
                "hf_subset": "pol_Latn-deu_Latn",
                "languages": [
                    "pol-Latn",
                    "deu-Latn"
                ],
                "accuracy": 0.43465197796695043,
                "f1": 0.35448522434000646,
                "main_score": 0.35448522434000646,
                "precision": 0.3292927940126679,
                "recall": 0.43465197796695043
            },
            {
                "hf_subset": "pol_Latn-ell_Grek",
                "languages": [
                    "pol-Latn",
                    "ell-Grek"
                ],
                "accuracy": 0.10665998998497747,
                "f1": 0.06412653388709864,
                "main_score": 0.06412653388709864,
                "precision": 0.05553629367440621,
                "recall": 0.10665998998497747
            },
            {
                "hf_subset": "pol_Latn-eng_Latn",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 0.956434651977967,
                "f1": 0.943281589050242,
                "main_score": 0.943281589050242,
                "precision": 0.9369470872976131,
                "recall": 0.956434651977967
            },
            {
                "hf_subset": "pol_Latn-fas_Arab",
                "languages": [
                    "pol-Latn",
                    "fas-Arab"
                ],
                "accuracy": 0.14521782674011016,
                "f1": 0.09839275942729991,
                "main_score": 0.09839275942729991,
                "precision": 0.08762366993974262,
                "recall": 0.14521782674011016
            },
            {
                "hf_subset": "pol_Latn-fin_Latn",
                "languages": [
                    "pol-Latn",
                    "fin-Latn"
                ],
                "accuracy": 0.24837255883825737,
                "f1": 0.1781630308485758,
                "main_score": 0.1781630308485758,
                "precision": 0.16061892651768322,
                "recall": 0.24837255883825737
            },
            {
                "hf_subset": "pol_Latn-fra_Latn",
                "languages": [
                    "pol-Latn",
                    "fra-Latn"
                ],
                "accuracy": 0.4621932899349023,
                "f1": 0.3728976220463451,
                "main_score": 0.3728976220463451,
                "precision": 0.3435696093911357,
                "recall": 0.4621932899349023
            },
            {
                "hf_subset": "pol_Latn-heb_Hebr",
                "languages": [
                    "pol-Latn",
                    "heb-Hebr"
                ],
                "accuracy": 0.07811717576364546,
                "f1": 0.04325980977253967,
                "main_score": 0.04325980977253967,
                "precision": 0.03692034397493451,
                "recall": 0.07811717576364546
            },
            {
                "hf_subset": "pol_Latn-hin_Deva",
                "languages": [
                    "pol-Latn",
                    "hin-Deva"
                ],
                "accuracy": 0.05408112168252378,
                "f1": 0.033012026283157955,
                "main_score": 0.033012026283157955,
                "precision": 0.029200987844982304,
                "recall": 0.05408112168252378
            },
            {
                "hf_subset": "pol_Latn-hrv_Latn",
                "languages": [
                    "pol-Latn",
                    "hrv-Latn"
                ],
                "accuracy": 0.3565348022033049,
                "f1": 0.2887968630538368,
                "main_score": 0.2887968630538368,
                "precision": 0.26862013496119064,
                "recall": 0.3565348022033049
            },
            {
                "hf_subset": "pol_Latn-hun_Latn",
                "languages": [
                    "pol-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.2558838257386079,
                "f1": 0.1848609113402143,
                "main_score": 0.1848609113402143,
                "precision": 0.16572961977441888,
                "recall": 0.2558838257386079
            },
            {
                "hf_subset": "pol_Latn-ind_Latn",
                "languages": [
                    "pol-Latn",
                    "ind-Latn"
                ],
                "accuracy": 0.2909364046069104,
                "f1": 0.21347745568207063,
                "main_score": 0.21347745568207063,
                "precision": 0.19290524664413103,
                "recall": 0.2909364046069104
            },
            {
                "hf_subset": "pol_Latn-jpn_Jpan",
                "languages": [
                    "pol-Latn",
                    "jpn-Jpan"
                ],
                "accuracy": 0.031547320981472206,
                "f1": 0.013591775209486017,
                "main_score": 0.013591775209486017,
                "precision": 0.010911488276885473,
                "recall": 0.031547320981472206
            },
            {
                "hf_subset": "pol_Latn-kor_Hang",
                "languages": [
                    "pol-Latn",
                    "kor-Hang"
                ],
                "accuracy": 0.10866299449173761,
                "f1": 0.06470438882301942,
                "main_score": 0.06470438882301942,
                "precision": 0.055886448167365,
                "recall": 0.10866299449173761
            },
            {
                "hf_subset": "pol_Latn-lit_Latn",
                "languages": [
                    "pol-Latn",
                    "lit-Latn"
                ],
                "accuracy": 0.2538808212318478,
                "f1": 0.1936819478745752,
                "main_score": 0.1936819478745752,
                "precision": 0.17739499047326585,
                "recall": 0.2538808212318478
            },
            {
                "hf_subset": "pol_Latn-mkd_Cyrl",
                "languages": [
                    "pol-Latn",
                    "mkd-Cyrl"
                ],
                "accuracy": 0.07361041562343515,
                "f1": 0.04620503162223216,
                "main_score": 0.04620503162223216,
                "precision": 0.040633841300538,
                "recall": 0.07361041562343515
            },
            {
                "hf_subset": "pol_Latn-nld_Latn",
                "languages": [
                    "pol-Latn",
                    "nld-Latn"
                ],
                "accuracy": 0.42163244867300953,
                "f1": 0.34454357275206193,
                "main_score": 0.34454357275206193,
                "precision": 0.32166089205243137,
                "recall": 0.42163244867300953
            },
            {
                "hf_subset": "pol_Latn-por_Latn",
                "languages": [
                    "pol-Latn",
                    "por-Latn"
                ],
                "accuracy": 0.38457686529794693,
                "f1": 0.30772146637068243,
                "main_score": 0.30772146637068243,
                "precision": 0.28392073335240375,
                "recall": 0.38457686529794693
            },
            {
                "hf_subset": "pol_Latn-rus_Cyrl",
                "languages": [
                    "pol-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.09013520280420631,
                "f1": 0.05746982904290555,
                "main_score": 0.05746982904290555,
                "precision": 0.05093509037970949,
                "recall": 0.09013520280420631
            },
            {
                "hf_subset": "pol_Latn-slk_Latn",
                "languages": [
                    "pol-Latn",
                    "slk-Latn"
                ],
                "accuracy": 0.38407611417125687,
                "f1": 0.3111590026725889,
                "main_score": 0.3111590026725889,
                "precision": 0.2888764140353986,
                "recall": 0.38407611417125687
            },
            {
                "hf_subset": "pol_Latn-slv_Latn",
                "languages": [
                    "pol-Latn",
                    "slv-Latn"
                ],
                "accuracy": 0.3324987481221833,
                "f1": 0.25950822457683553,
                "main_score": 0.25950822457683553,
                "precision": 0.23846365535044156,
                "recall": 0.3324987481221833
            },
            {
                "hf_subset": "pol_Latn-spa_Latn",
                "languages": [
                    "pol-Latn",
                    "spa-Latn"
                ],
                "accuracy": 0.4506760140210315,
                "f1": 0.36824239877433806,
                "main_score": 0.36824239877433806,
                "precision": 0.34216717950181047,
                "recall": 0.4506760140210315
            },
            {
                "hf_subset": "pol_Latn-srp_Cyrl",
                "languages": [
                    "pol-Latn",
                    "srp-Cyrl"
                ],
                "accuracy": 0.07911867801702553,
                "f1": 0.050362359723815114,
                "main_score": 0.050362359723815114,
                "precision": 0.04412580264338375,
                "recall": 0.07911867801702553
            },
            {
                "hf_subset": "pol_Latn-srp_Latn",
                "languages": [
                    "pol-Latn",
                    "srp-Latn"
                ],
                "accuracy": 0.2543815723585378,
                "f1": 0.18921733221569645,
                "main_score": 0.18921733221569645,
                "precision": 0.1732003570311133,
                "recall": 0.2543815723585378
            },
            {
                "hf_subset": "pol_Latn-swa_Latn",
                "languages": [
                    "pol-Latn",
                    "swa-Latn"
                ],
                "accuracy": 0.21732598898347522,
                "f1": 0.158802907971782,
                "main_score": 0.158802907971782,
                "precision": 0.14395403694763725,
                "recall": 0.21732598898347522
            },
            {
                "hf_subset": "pol_Latn-swe_Latn",
                "languages": [
                    "pol-Latn",
                    "swe-Latn"
                ],
                "accuracy": 0.40610916374561845,
                "f1": 0.32421490223283655,
                "main_score": 0.32421490223283655,
                "precision": 0.29896983936859545,
                "recall": 0.40610916374561845
            },
            {
                "hf_subset": "pol_Latn-tam_Taml",
                "languages": [
                    "pol-Latn",
                    "tam-Taml"
                ],
                "accuracy": 0.07961942914371557,
                "f1": 0.04558103071505523,
                "main_score": 0.04558103071505523,
                "precision": 0.03866260246917977,
                "recall": 0.07961942914371557
            },
            {
                "hf_subset": "pol_Latn-tur_Latn",
                "languages": [
                    "pol-Latn",
                    "tur-Latn"
                ],
                "accuracy": 0.2839258888332499,
                "f1": 0.22030266589108036,
                "main_score": 0.22030266589108036,
                "precision": 0.20308934108335674,
                "recall": 0.2839258888332499
            },
            {
                "hf_subset": "pol_Latn-ukr_Cyrl",
                "languages": [
                    "pol-Latn",
                    "ukr-Cyrl"
                ],
                "accuracy": 0.08512769153730596,
                "f1": 0.0529671854202711,
                "main_score": 0.0529671854202711,
                "precision": 0.04650127564300294,
                "recall": 0.08512769153730596
            },
            {
                "hf_subset": "pol_Latn-vie_Latn",
                "languages": [
                    "pol-Latn",
                    "vie-Latn"
                ],
                "accuracy": 0.3014521782674011,
                "f1": 0.23615731420822927,
                "main_score": 0.23615731420822927,
                "precision": 0.2167325222681889,
                "recall": 0.3014521782674011
            },
            {
                "hf_subset": "pol_Latn-zho_Hant",
                "languages": [
                    "pol-Latn",
                    "zho-Hant"
                ],
                "accuracy": 0.24036054081121683,
                "f1": 0.1792926410467618,
                "main_score": 0.1792926410467618,
                "precision": 0.16264283236205312,
                "recall": 0.24036054081121683
            },
            {
                "hf_subset": "pol_Latn-zul_Latn",
                "languages": [
                    "pol-Latn",
                    "zul-Latn"
                ],
                "accuracy": 0.2383575363044567,
                "f1": 0.16400739962706365,
                "main_score": 0.16400739962706365,
                "precision": 0.14601613184463366,
                "recall": 0.2383575363044567
            },
            {
                "hf_subset": "por_Latn-pol_Latn",
                "languages": [
                    "por-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.3740610916374562,
                "f1": 0.3381913602762965,
                "main_score": 0.3381913602762965,
                "precision": 0.32675346971067115,
                "recall": 0.3740610916374562
            },
            {
                "hf_subset": "rus_Cyrl-pol_Latn",
                "languages": [
                    "rus-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.06609914872308463,
                "f1": 0.05344181532448552,
                "main_score": 0.05344181532448552,
                "precision": 0.05016035805663429,
                "recall": 0.06609914872308463
            },
            {
                "hf_subset": "slk_Latn-pol_Latn",
                "languages": [
                    "slk-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.43214822233350025,
                "f1": 0.38594026070011933,
                "main_score": 0.38594026070011933,
                "precision": 0.370591862586631,
                "recall": 0.43214822233350025
            },
            {
                "hf_subset": "slv_Latn-pol_Latn",
                "languages": [
                    "slv-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.34501752628943416,
                "f1": 0.3033534542042949,
                "main_score": 0.3033534542042949,
                "precision": 0.289518422565815,
                "recall": 0.34501752628943416
            },
            {
                "hf_subset": "spa_Latn-pol_Latn",
                "languages": [
                    "spa-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.37656484727090633,
                "f1": 0.3398078952477611,
                "main_score": 0.3398078952477611,
                "precision": 0.3290989855225763,
                "recall": 0.37656484727090633
            },
            {
                "hf_subset": "srp_Cyrl-pol_Latn",
                "languages": [
                    "srp-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.05808713069604407,
                "f1": 0.04451889762512087,
                "main_score": 0.04451889762512087,
                "precision": 0.04125584144733145,
                "recall": 0.05808713069604407
            },
            {
                "hf_subset": "srp_Latn-pol_Latn",
                "languages": [
                    "srp-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2814221331997997,
                "f1": 0.23519592978318649,
                "main_score": 0.23519592978318649,
                "precision": 0.22110666143488064,
                "recall": 0.2814221331997997
            },
            {
                "hf_subset": "swa_Latn-pol_Latn",
                "languages": [
                    "swa-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.19779669504256384,
                "f1": 0.16604335328648057,
                "main_score": 0.16604335328648057,
                "precision": 0.15768002918453658,
                "recall": 0.19779669504256384
            },
            {
                "hf_subset": "swe_Latn-pol_Latn",
                "languages": [
                    "swe-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.40861291937906863,
                "f1": 0.3623109651947736,
                "main_score": 0.3623109651947736,
                "precision": 0.34744974799932826,
                "recall": 0.40861291937906863
            },
            {
                "hf_subset": "tam_Taml-pol_Latn",
                "languages": [
                    "tam-Taml",
                    "pol-Latn"
                ],
                "accuracy": 0.05107661492238358,
                "f1": 0.037687687480859794,
                "main_score": 0.037687687480859794,
                "precision": 0.03435683292066821,
                "recall": 0.05107661492238358
            },
            {
                "hf_subset": "tur_Latn-pol_Latn",
                "languages": [
                    "tur-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.29944917376064095,
                "f1": 0.24863268061783939,
                "main_score": 0.24863268061783939,
                "precision": 0.23360639803316421,
                "recall": 0.29944917376064095
            },
            {
                "hf_subset": "ukr_Cyrl-pol_Latn",
                "languages": [
                    "ukr-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.07260891337005508,
                "f1": 0.05704027989612987,
                "main_score": 0.05704027989612987,
                "precision": 0.05270309095078216,
                "recall": 0.07260891337005508
            },
            {
                "hf_subset": "vie_Latn-pol_Latn",
                "languages": [
                    "vie-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.2909364046069104,
                "f1": 0.24651820126812274,
                "main_score": 0.24651820126812274,
                "precision": 0.2325686506040681,
                "recall": 0.2909364046069104
            },
            {
                "hf_subset": "zho_Hant-pol_Latn",
                "languages": [
                    "zho-Hant",
                    "pol-Latn"
                ],
                "accuracy": 0.21732598898347522,
                "f1": 0.18829299781805905,
                "main_score": 0.18829299781805905,
                "precision": 0.1789806400969999,
                "recall": 0.21732598898347522
            },
            {
                "hf_subset": "zul_Latn-pol_Latn",
                "languages": [
                    "zul-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.23084626940410616,
                "f1": 0.19616655275302847,
                "main_score": 0.19616655275302847,
                "precision": 0.1861171758782464,
                "recall": 0.23084626940410616
            }
        ]
    }
}