{
  "dataset_revision": "2fe05ee6b5832cda29f2ef7aaad7b7fe6a3609eb",
  "task_name": "HeadlineClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.710107,
        "f1": 0.710148,
        "f1_weighted": 0.710136,
        "scores_per_experiment": [
          {
            "accuracy": 0.70752,
            "f1": 0.709202,
            "f1_weighted": 0.709201
          },
          {
            "accuracy": 0.727051,
            "f1": 0.728617,
            "f1_weighted": 0.728608
          },
          {
            "accuracy": 0.700684,
            "f1": 0.697521,
            "f1_weighted": 0.697522
          },
          {
            "accuracy": 0.712402,
            "f1": 0.713685,
            "f1_weighted": 0.713657
          },
          {
            "accuracy": 0.740234,
            "f1": 0.740154,
            "f1_weighted": 0.740129
          },
          {
            "accuracy": 0.70459,
            "f1": 0.705135,
            "f1_weighted": 0.705099
          },
          {
            "accuracy": 0.736328,
            "f1": 0.737011,
            "f1_weighted": 0.736967
          },
          {
            "accuracy": 0.670898,
            "f1": 0.674018,
            "f1_weighted": 0.67403
          },
          {
            "accuracy": 0.683594,
            "f1": 0.677039,
            "f1_weighted": 0.677074
          },
          {
            "accuracy": 0.717773,
            "f1": 0.719094,
            "f1_weighted": 0.719077
          }
        ],
        "main_score": 0.710107,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 19.357810020446777,
  "kg_co2_emissions": 0.000998123338868454
}