{
  "dataset_revision": "cf24d44e517efa534f048e5fc5981f399ed25bee",
  "task_name": "CataloniaTweetClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.464417,
        "f1": 0.476726,
        "f1_weighted": 0.461246,
        "scores_per_experiment": [
          {
            "accuracy": 0.472457,
            "f1": 0.494855,
            "f1_weighted": 0.47734
          },
          {
            "accuracy": 0.466998,
            "f1": 0.477952,
            "f1_weighted": 0.46675
          },
          {
            "accuracy": 0.410422,
            "f1": 0.411308,
            "f1_weighted": 0.404178
          },
          {
            "accuracy": 0.470968,
            "f1": 0.465485,
            "f1_weighted": 0.450544
          },
          {
            "accuracy": 0.486849,
            "f1": 0.501519,
            "f1_weighted": 0.483235
          },
          {
            "accuracy": 0.504715,
            "f1": 0.521817,
            "f1_weighted": 0.50263
          },
          {
            "accuracy": 0.463524,
            "f1": 0.477084,
            "f1_weighted": 0.460543
          },
          {
            "accuracy": 0.416377,
            "f1": 0.427553,
            "f1_weighted": 0.41497
          },
          {
            "accuracy": 0.470968,
            "f1": 0.489148,
            "f1_weighted": 0.467278
          },
          {
            "accuracy": 0.480893,
            "f1": 0.500541,
            "f1_weighted": 0.484989
          }
        ],
        "main_score": 0.464417,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ]
      },
      {
        "accuracy": 0.487363,
        "f1": 0.485375,
        "f1_weighted": 0.484235,
        "scores_per_experiment": [
          {
            "accuracy": 0.471642,
            "f1": 0.465443,
            "f1_weighted": 0.459746
          },
          {
            "accuracy": 0.492537,
            "f1": 0.495458,
            "f1_weighted": 0.49243
          },
          {
            "accuracy": 0.542289,
            "f1": 0.533331,
            "f1_weighted": 0.542818
          },
          {
            "accuracy": 0.526866,
            "f1": 0.520157,
            "f1_weighted": 0.522044
          },
          {
            "accuracy": 0.440299,
            "f1": 0.434298,
            "f1_weighted": 0.440395
          },
          {
            "accuracy": 0.448259,
            "f1": 0.448308,
            "f1_weighted": 0.446304
          },
          {
            "accuracy": 0.491542,
            "f1": 0.494382,
            "f1_weighted": 0.48859
          },
          {
            "accuracy": 0.477114,
            "f1": 0.477229,
            "f1_weighted": 0.469635
          },
          {
            "accuracy": 0.464179,
            "f1": 0.466289,
            "f1_weighted": 0.46246
          },
          {
            "accuracy": 0.518905,
            "f1": 0.518857,
            "f1_weighted": 0.517929
          }
        ],
        "main_score": 0.487363,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.470784,
        "f1": 0.486336,
        "f1_weighted": 0.466557,
        "scores_per_experiment": [
          {
            "accuracy": 0.468254,
            "f1": 0.491461,
            "f1_weighted": 0.47244
          },
          {
            "accuracy": 0.462798,
            "f1": 0.481621,
            "f1_weighted": 0.461935
          },
          {
            "accuracy": 0.430556,
            "f1": 0.431257,
            "f1_weighted": 0.423161
          },
          {
            "accuracy": 0.457837,
            "f1": 0.462285,
            "f1_weighted": 0.43847
          },
          {
            "accuracy": 0.499504,
            "f1": 0.514842,
            "f1_weighted": 0.495777
          },
          {
            "accuracy": 0.498016,
            "f1": 0.516175,
            "f1_weighted": 0.494684
          },
          {
            "accuracy": 0.473214,
            "f1": 0.485827,
            "f1_weighted": 0.467168
          },
          {
            "accuracy": 0.438492,
            "f1": 0.456115,
            "f1_weighted": 0.43229
          },
          {
            "accuracy": 0.49504,
            "f1": 0.511547,
            "f1_weighted": 0.492022
          },
          {
            "accuracy": 0.484127,
            "f1": 0.512226,
            "f1_weighted": 0.487621
          }
        ],
        "main_score": 0.470784,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ]
      },
      {
        "accuracy": 0.491343,
        "f1": 0.489802,
        "f1_weighted": 0.488363,
        "scores_per_experiment": [
          {
            "accuracy": 0.49602,
            "f1": 0.487006,
            "f1_weighted": 0.489885
          },
          {
            "accuracy": 0.507463,
            "f1": 0.513027,
            "f1_weighted": 0.507409
          },
          {
            "accuracy": 0.533333,
            "f1": 0.530428,
            "f1_weighted": 0.533638
          },
          {
            "accuracy": 0.520896,
            "f1": 0.512353,
            "f1_weighted": 0.514606
          },
          {
            "accuracy": 0.445771,
            "f1": 0.441158,
            "f1_weighted": 0.447794
          },
          {
            "accuracy": 0.460199,
            "f1": 0.456958,
            "f1_weighted": 0.454876
          },
          {
            "accuracy": 0.49005,
            "f1": 0.492161,
            "f1_weighted": 0.485894
          },
          {
            "accuracy": 0.479602,
            "f1": 0.481537,
            "f1_weighted": 0.472999
          },
          {
            "accuracy": 0.456716,
            "f1": 0.45917,
            "f1_weighted": 0.4537
          },
          {
            "accuracy": 0.523383,
            "f1": 0.524226,
            "f1_weighted": 0.522826
          }
        ],
        "main_score": 0.491343,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 97.86960005760193,
  "kg_co2_emissions": 0.007242289567957626
}