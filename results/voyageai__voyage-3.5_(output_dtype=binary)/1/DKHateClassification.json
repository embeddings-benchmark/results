{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.1.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.656535,
            "f1": 0.531428,
            "f1_weighted": 0.713201,
            "precision": 0.554804,
            "precision_weighted": 0.824993,
            "recall": 0.615557,
            "recall_weighted": 0.656535,
            "ap": 0.901724,
            "ap_weighted": 0.901724
          },
          {
            "accuracy": 0.638298,
            "f1": 0.543381,
            "f1_weighted": 0.699678,
            "precision": 0.5799,
            "precision_weighted": 0.852057,
            "recall": 0.678354,
            "recall_weighted": 0.638298,
            "ap": 0.917273,
            "ap_weighted": 0.917273
          },
          {
            "accuracy": 0.653495,
            "f1": 0.544388,
            "f1_weighted": 0.711777,
            "precision": 0.571646,
            "precision_weighted": 0.841204,
            "recall": 0.655657,
            "recall_weighted": 0.653495,
            "ap": 0.911487,
            "ap_weighted": 0.911487
          },
          {
            "accuracy": 0.56535,
            "f1": 0.458763,
            "f1_weighted": 0.639084,
            "precision": 0.514273,
            "precision_weighted": 0.794627,
            "recall": 0.532097,
            "recall_weighted": 0.56535,
            "ap": 0.882481,
            "ap_weighted": 0.882481
          },
          {
            "accuracy": 0.653495,
            "f1": 0.525241,
            "f1_weighted": 0.710498,
            "precision": 0.549206,
            "precision_weighted": 0.820359,
            "recall": 0.603362,
            "recall_weighted": 0.653495,
            "ap": 0.898833,
            "ap_weighted": 0.898833
          },
          {
            "accuracy": 0.650456,
            "f1": 0.505793,
            "f1_weighted": 0.706533,
            "precision": 0.529307,
            "precision_weighted": 0.803837,
            "recall": 0.55979,
            "recall_weighted": 0.650456,
            "ap": 0.888717,
            "ap_weighted": 0.888717
          },
          {
            "accuracy": 0.465046,
            "f1": 0.418588,
            "f1_weighted": 0.541976,
            "precision": 0.535878,
            "precision_weighted": 0.822693,
            "recall": 0.579395,
            "recall_weighted": 0.465046,
            "ap": 0.893544,
            "ap_weighted": 0.893544
          },
          {
            "accuracy": 0.62614,
            "f1": 0.528032,
            "f1_weighted": 0.689583,
            "precision": 0.567418,
            "precision_weighted": 0.841084,
            "recall": 0.650491,
            "recall_weighted": 0.62614,
            "ap": 0.910335,
            "ap_weighted": 0.910335
          },
          {
            "accuracy": 0.729483,
            "f1": 0.585284,
            "f1_weighted": 0.768878,
            "precision": 0.584043,
            "precision_weighted": 0.838822,
            "recall": 0.657224,
            "recall_weighted": 0.729483,
            "ap": 0.911565,
            "ap_weighted": 0.911565
          },
          {
            "accuracy": 0.474164,
            "f1": 0.422965,
            "f1_weighted": 0.552008,
            "precision": 0.53315,
            "precision_weighted": 0.818829,
            "recall": 0.574145,
            "recall_weighted": 0.474164,
            "ap": 0.892264,
            "ap_weighted": 0.892264
          }
        ],
        "accuracy": 0.611246,
        "f1": 0.506386,
        "f1_weighted": 0.673321,
        "precision": 0.551962,
        "precision_weighted": 0.825851,
        "recall": 0.610607,
        "recall_weighted": 0.611246,
        "ap": 0.900822,
        "ap_weighted": 0.900822,
        "main_score": 0.611246,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.249202251434326,
  "kg_co2_emissions": null
}