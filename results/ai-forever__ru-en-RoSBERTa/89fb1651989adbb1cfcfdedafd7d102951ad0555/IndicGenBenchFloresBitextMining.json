{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.014859,
        "recall": 0.024072,
        "f1": 0.016496,
        "accuracy": 0.024072,
        "main_score": 0.016496,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0077,
        "recall": 0.026078,
        "f1": 0.010436,
        "accuracy": 0.026078,
        "main_score": 0.010436,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.01196,
        "recall": 0.014042,
        "f1": 0.01237,
        "accuracy": 0.014042,
        "main_score": 0.01237,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007742,
        "recall": 0.026078,
        "f1": 0.010149,
        "accuracy": 0.026078,
        "main_score": 0.010149,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.017053,
        "recall": 0.02006,
        "f1": 0.017723,
        "accuracy": 0.02006,
        "main_score": 0.017723,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009174,
        "recall": 0.033099,
        "f1": 0.012528,
        "accuracy": 0.033099,
        "main_score": 0.012528,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.021432,
        "recall": 0.025075,
        "f1": 0.022069,
        "accuracy": 0.025075,
        "main_score": 0.022069,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009073,
        "recall": 0.031093,
        "f1": 0.011728,
        "accuracy": 0.031093,
        "main_score": 0.011728,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006029,
        "recall": 0.011033,
        "f1": 0.007161,
        "accuracy": 0.011033,
        "main_score": 0.007161,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006753,
        "recall": 0.019057,
        "f1": 0.007354,
        "accuracy": 0.019057,
        "main_score": 0.007354,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.016418,
        "recall": 0.02006,
        "f1": 0.016954,
        "accuracy": 0.02006,
        "main_score": 0.016954,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012179,
        "recall": 0.038114,
        "f1": 0.016027,
        "accuracy": 0.038114,
        "main_score": 0.016027,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023535,
        "recall": 0.029087,
        "f1": 0.024315,
        "accuracy": 0.029087,
        "main_score": 0.024315,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01394,
        "recall": 0.041123,
        "f1": 0.017209,
        "accuracy": 0.041123,
        "main_score": 0.017209,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.060542,
        "recall": 0.066199,
        "f1": 0.061857,
        "accuracy": 0.066199,
        "main_score": 0.061857,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0258,
        "recall": 0.076229,
        "f1": 0.032145,
        "accuracy": 0.076229,
        "main_score": 0.032145,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.023154,
        "recall": 0.026078,
        "f1": 0.023641,
        "accuracy": 0.026078,
        "main_score": 0.023641,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012366,
        "recall": 0.045135,
        "f1": 0.015801,
        "accuracy": 0.045135,
        "main_score": 0.015801,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.019047,
        "recall": 0.023069,
        "f1": 0.019516,
        "accuracy": 0.023069,
        "main_score": 0.019516,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016666,
        "recall": 0.04012,
        "f1": 0.01924,
        "accuracy": 0.04012,
        "main_score": 0.01924,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.028929,
        "recall": 0.035105,
        "f1": 0.030327,
        "accuracy": 0.035105,
        "main_score": 0.030327,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019743,
        "recall": 0.05015,
        "f1": 0.024056,
        "accuracy": 0.05015,
        "main_score": 0.024056,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.039077,
        "recall": 0.045135,
        "f1": 0.040513,
        "accuracy": 0.045135,
        "main_score": 0.040513,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019718,
        "recall": 0.053159,
        "f1": 0.025224,
        "accuracy": 0.053159,
        "main_score": 0.025224,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.014965,
        "recall": 0.02006,
        "f1": 0.015711,
        "accuracy": 0.02006,
        "main_score": 0.015711,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008624,
        "recall": 0.023069,
        "f1": 0.010301,
        "accuracy": 0.023069,
        "main_score": 0.010301,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.016307,
        "recall": 0.02006,
        "f1": 0.016829,
        "accuracy": 0.02006,
        "main_score": 0.016829,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010124,
        "recall": 0.033099,
        "f1": 0.011903,
        "accuracy": 0.033099,
        "main_score": 0.011903,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.081078,
        "recall": 0.086259,
        "f1": 0.082417,
        "accuracy": 0.086259,
        "main_score": 0.082417,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039325,
        "recall": 0.109328,
        "f1": 0.049626,
        "accuracy": 0.109328,
        "main_score": 0.049626,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.033624,
        "recall": 0.042126,
        "f1": 0.035613,
        "accuracy": 0.042126,
        "main_score": 0.035613,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01856,
        "recall": 0.061184,
        "f1": 0.024372,
        "accuracy": 0.061184,
        "main_score": 0.024372,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.013542,
        "recall": 0.015045,
        "f1": 0.01371,
        "accuracy": 0.015045,
        "main_score": 0.01371,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010312,
        "recall": 0.03009,
        "f1": 0.01331,
        "accuracy": 0.03009,
        "main_score": 0.01331,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.012539,
        "recall": 0.014042,
        "f1": 0.012707,
        "accuracy": 0.014042,
        "main_score": 0.012707,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014739,
        "recall": 0.035105,
        "f1": 0.017186,
        "accuracy": 0.035105,
        "main_score": 0.017186,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.008277,
        "recall": 0.01003,
        "f1": 0.00843,
        "accuracy": 0.01003,
        "main_score": 0.00843,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007223,
        "recall": 0.019057,
        "f1": 0.008369,
        "accuracy": 0.019057,
        "main_score": 0.008369,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.014378,
        "recall": 0.018054,
        "f1": 0.015215,
        "accuracy": 0.018054,
        "main_score": 0.015215,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010577,
        "recall": 0.027081,
        "f1": 0.01236,
        "accuracy": 0.027081,
        "main_score": 0.01236,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.018055,
        "recall": 0.02006,
        "f1": 0.018391,
        "accuracy": 0.02006,
        "main_score": 0.018391,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011806,
        "recall": 0.03009,
        "f1": 0.014246,
        "accuracy": 0.03009,
        "main_score": 0.014246,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.02472,
        "recall": 0.032096,
        "f1": 0.026449,
        "accuracy": 0.032096,
        "main_score": 0.026449,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023263,
        "recall": 0.055165,
        "f1": 0.028008,
        "accuracy": 0.055165,
        "main_score": 0.028008,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.003512,
        "recall": 0.005015,
        "f1": 0.00368,
        "accuracy": 0.005015,
        "main_score": 0.00368,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009627,
        "recall": 0.021063,
        "f1": 0.010881,
        "accuracy": 0.021063,
        "main_score": 0.010881,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.021098,
        "recall": 0.026078,
        "f1": 0.022236,
        "accuracy": 0.026078,
        "main_score": 0.022236,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016343,
        "recall": 0.047141,
        "f1": 0.020523,
        "accuracy": 0.047141,
        "main_score": 0.020523,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.022903,
        "recall": 0.03009,
        "f1": 0.02463,
        "accuracy": 0.03009,
        "main_score": 0.02463,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015569,
        "recall": 0.047141,
        "f1": 0.019749,
        "accuracy": 0.047141,
        "main_score": 0.019749,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.030402,
        "recall": 0.04012,
        "f1": 0.03214,
        "accuracy": 0.04012,
        "main_score": 0.03214,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018238,
        "recall": 0.047141,
        "f1": 0.022301,
        "accuracy": 0.047141,
        "main_score": 0.022301,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.009474,
        "recall": 0.012036,
        "f1": 0.009732,
        "accuracy": 0.012036,
        "main_score": 0.009732,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00991,
        "recall": 0.023069,
        "f1": 0.011631,
        "accuracy": 0.023069,
        "main_score": 0.011631,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.01304,
        "recall": 0.015045,
        "f1": 0.013376,
        "accuracy": 0.015045,
        "main_score": 0.013376,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016768,
        "recall": 0.032096,
        "f1": 0.018348,
        "accuracy": 0.032096,
        "main_score": 0.018348,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.00836,
        "recall": 0.01003,
        "f1": 0.008529,
        "accuracy": 0.01003,
        "main_score": 0.008529,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002558,
        "recall": 0.012036,
        "f1": 0.002997,
        "accuracy": 0.012036,
        "main_score": 0.002997,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.014669,
        "recall": 0.018775,
        "f1": 0.015402,
        "accuracy": 0.018775,
        "main_score": 0.015402,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014587,
        "recall": 0.041502,
        "f1": 0.017895,
        "accuracy": 0.041502,
        "main_score": 0.017895,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.012024,
        "recall": 0.01581,
        "f1": 0.012848,
        "accuracy": 0.01581,
        "main_score": 0.012848,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012989,
        "recall": 0.030632,
        "f1": 0.015029,
        "accuracy": 0.030632,
        "main_score": 0.015029,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.009697,
        "recall": 0.016798,
        "f1": 0.010954,
        "accuracy": 0.016798,
        "main_score": 0.010954,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012478,
        "recall": 0.032609,
        "f1": 0.015492,
        "accuracy": 0.032609,
        "main_score": 0.015492,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018415,
        "recall": 0.022727,
        "f1": 0.019124,
        "accuracy": 0.022727,
        "main_score": 0.019124,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006756,
        "recall": 0.027668,
        "f1": 0.009604,
        "accuracy": 0.027668,
        "main_score": 0.009604,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006343,
        "recall": 0.012846,
        "f1": 0.006951,
        "accuracy": 0.012846,
        "main_score": 0.006951,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005639,
        "recall": 0.016798,
        "f1": 0.006685,
        "accuracy": 0.016798,
        "main_score": 0.006685,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.009005,
        "recall": 0.013834,
        "f1": 0.010082,
        "accuracy": 0.013834,
        "main_score": 0.010082,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014649,
        "recall": 0.041502,
        "f1": 0.018732,
        "accuracy": 0.041502,
        "main_score": 0.018732,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.015817,
        "recall": 0.022727,
        "f1": 0.01707,
        "accuracy": 0.022727,
        "main_score": 0.01707,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014516,
        "recall": 0.039526,
        "f1": 0.017731,
        "accuracy": 0.039526,
        "main_score": 0.017731,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.05245,
        "recall": 0.063241,
        "f1": 0.05435,
        "accuracy": 0.063241,
        "main_score": 0.05435,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023177,
        "recall": 0.077075,
        "f1": 0.029813,
        "accuracy": 0.077075,
        "main_score": 0.029813,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010454,
        "recall": 0.014822,
        "f1": 0.011017,
        "accuracy": 0.014822,
        "main_score": 0.011017,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0089,
        "recall": 0.02668,
        "f1": 0.01097,
        "accuracy": 0.02668,
        "main_score": 0.01097,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.016512,
        "recall": 0.020751,
        "f1": 0.017252,
        "accuracy": 0.020751,
        "main_score": 0.017252,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009468,
        "recall": 0.032609,
        "f1": 0.012408,
        "accuracy": 0.032609,
        "main_score": 0.012408,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.022127,
        "recall": 0.027668,
        "f1": 0.023449,
        "accuracy": 0.027668,
        "main_score": 0.023449,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016301,
        "recall": 0.045455,
        "f1": 0.020468,
        "accuracy": 0.045455,
        "main_score": 0.020468,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.033398,
        "recall": 0.039526,
        "f1": 0.034538,
        "accuracy": 0.039526,
        "main_score": 0.034538,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020659,
        "recall": 0.057312,
        "f1": 0.026034,
        "accuracy": 0.057312,
        "main_score": 0.026034,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.01567,
        "recall": 0.021739,
        "f1": 0.016799,
        "accuracy": 0.021739,
        "main_score": 0.016799,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010411,
        "recall": 0.02668,
        "f1": 0.012645,
        "accuracy": 0.02668,
        "main_score": 0.012645,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01814,
        "recall": 0.025692,
        "f1": 0.019818,
        "accuracy": 0.025692,
        "main_score": 0.019818,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010719,
        "recall": 0.037549,
        "f1": 0.013838,
        "accuracy": 0.037549,
        "main_score": 0.013838,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.066817,
        "recall": 0.074111,
        "f1": 0.068481,
        "accuracy": 0.074111,
        "main_score": 0.068481,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037789,
        "recall": 0.096838,
        "f1": 0.046354,
        "accuracy": 0.096838,
        "main_score": 0.046354,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.03234,
        "recall": 0.041502,
        "f1": 0.034524,
        "accuracy": 0.041502,
        "main_score": 0.034524,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018131,
        "recall": 0.056324,
        "f1": 0.023257,
        "accuracy": 0.056324,
        "main_score": 0.023257,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.009429,
        "recall": 0.014822,
        "f1": 0.010444,
        "accuracy": 0.014822,
        "main_score": 0.010444,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011,
        "recall": 0.031621,
        "f1": 0.013756,
        "accuracy": 0.031621,
        "main_score": 0.013756,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.002998,
        "recall": 0.006917,
        "f1": 0.003514,
        "accuracy": 0.006917,
        "main_score": 0.003514,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00957,
        "recall": 0.019763,
        "f1": 0.010917,
        "accuracy": 0.019763,
        "main_score": 0.010917,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.007012,
        "recall": 0.01087,
        "f1": 0.007423,
        "accuracy": 0.01087,
        "main_score": 0.007423,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00478,
        "recall": 0.019763,
        "f1": 0.006317,
        "accuracy": 0.019763,
        "main_score": 0.006317,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.009085,
        "recall": 0.014822,
        "f1": 0.01006,
        "accuracy": 0.014822,
        "main_score": 0.01006,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010188,
        "recall": 0.029644,
        "f1": 0.012141,
        "accuracy": 0.029644,
        "main_score": 0.012141,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.012297,
        "recall": 0.019763,
        "f1": 0.013766,
        "accuracy": 0.019763,
        "main_score": 0.013766,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012115,
        "recall": 0.031621,
        "f1": 0.015154,
        "accuracy": 0.031621,
        "main_score": 0.015154,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.02276,
        "recall": 0.030632,
        "f1": 0.024447,
        "accuracy": 0.030632,
        "main_score": 0.024447,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021027,
        "recall": 0.050395,
        "f1": 0.025292,
        "accuracy": 0.050395,
        "main_score": 0.025292,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.002151,
        "recall": 0.006917,
        "f1": 0.002813,
        "accuracy": 0.006917,
        "main_score": 0.002813,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00583,
        "recall": 0.016798,
        "f1": 0.007668,
        "accuracy": 0.016798,
        "main_score": 0.007668,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.013639,
        "recall": 0.020751,
        "f1": 0.015126,
        "accuracy": 0.020751,
        "main_score": 0.015126,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017686,
        "recall": 0.040514,
        "f1": 0.020605,
        "accuracy": 0.040514,
        "main_score": 0.020605,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.017272,
        "recall": 0.024704,
        "f1": 0.018975,
        "accuracy": 0.024704,
        "main_score": 0.018975,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016635,
        "recall": 0.044466,
        "f1": 0.020453,
        "accuracy": 0.044466,
        "main_score": 0.020453,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.017526,
        "recall": 0.025692,
        "f1": 0.01906,
        "accuracy": 0.025692,
        "main_score": 0.01906,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017267,
        "recall": 0.046443,
        "f1": 0.021225,
        "accuracy": 0.046443,
        "main_score": 0.021225,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.007947,
        "recall": 0.012846,
        "f1": 0.008804,
        "accuracy": 0.012846,
        "main_score": 0.008804,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0106,
        "recall": 0.02668,
        "f1": 0.013597,
        "accuracy": 0.02668,
        "main_score": 0.013597,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.011753,
        "recall": 0.017787,
        "f1": 0.012949,
        "accuracy": 0.017787,
        "main_score": 0.012949,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015276,
        "recall": 0.035573,
        "f1": 0.018126,
        "accuracy": 0.035573,
        "main_score": 0.018126,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.009257,
        "recall": 0.013834,
        "f1": 0.010214,
        "accuracy": 0.013834,
        "main_score": 0.010214,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004412,
        "recall": 0.018775,
        "f1": 0.005766,
        "accuracy": 0.018775,
        "main_score": 0.005766,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 582.172033071518,
  "kg_co2_emissions": 0.054143415542010576
}