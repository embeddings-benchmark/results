{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.124342,
        "mrr": 0.107194,
        "nAUC_map_max": 0.127153,
        "nAUC_map_std": 0.131153,
        "nAUC_map_diff1": 0.240837,
        "nAUC_mrr_max": 0.128283,
        "nAUC_mrr_std": 0.133054,
        "nAUC_mrr_diff1": 0.239849,
        "main_score": 0.107194,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.106111,
        "mrr": 0.089633,
        "nAUC_map_max": 0.190135,
        "nAUC_map_std": 0.188988,
        "nAUC_map_diff1": 0.216254,
        "nAUC_mrr_max": 0.214532,
        "nAUC_mrr_std": 0.176828,
        "nAUC_mrr_diff1": 0.239285,
        "main_score": 0.089633,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.076864,
        "mrr": 0.061313,
        "nAUC_map_max": 0.112766,
        "nAUC_map_std": 0.291172,
        "nAUC_map_diff1": 0.153832,
        "nAUC_mrr_max": 0.116692,
        "nAUC_mrr_std": 0.262799,
        "nAUC_mrr_diff1": 0.169736,
        "main_score": 0.061313,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.091523,
        "mrr": 0.073108,
        "nAUC_map_max": 0.120869,
        "nAUC_map_std": 0.114336,
        "nAUC_map_diff1": 0.127594,
        "nAUC_mrr_max": 0.14043,
        "nAUC_mrr_std": 0.119508,
        "nAUC_mrr_diff1": 0.132524,
        "main_score": 0.073108,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.092896,
        "mrr": 0.075893,
        "nAUC_map_max": 0.158966,
        "nAUC_map_std": 0.26712,
        "nAUC_map_diff1": 0.10794,
        "nAUC_mrr_max": 0.161559,
        "nAUC_mrr_std": 0.254344,
        "nAUC_mrr_diff1": 0.114591,
        "main_score": 0.075893,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.082235,
        "mrr": 0.065968,
        "nAUC_map_max": 0.219808,
        "nAUC_map_std": 0.279039,
        "nAUC_map_diff1": 0.131474,
        "nAUC_mrr_max": 0.230834,
        "nAUC_mrr_std": 0.289292,
        "nAUC_mrr_diff1": 0.139834,
        "main_score": 0.065968,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6304.652739524841,
  "kg_co2_emissions": 0.6046046245039275
}