{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.191453,
            "f1": 0.230053,
            "f1_weighted": 0.170431,
            "precision": 0.273315,
            "precision_weighted": 0.370233,
            "recall": 0.370536,
            "recall_weighted": 0.191453,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.210256,
            "f1": 0.230421,
            "f1_weighted": 0.176866,
            "precision": 0.248053,
            "precision_weighted": 0.287392,
            "recall": 0.375532,
            "recall_weighted": 0.210256,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.218803,
            "f1": 0.256131,
            "f1_weighted": 0.19462,
            "precision": 0.295545,
            "precision_weighted": 0.334715,
            "recall": 0.400148,
            "recall_weighted": 0.218803,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.199145,
            "f1": 0.216961,
            "f1_weighted": 0.174449,
            "precision": 0.26726,
            "precision_weighted": 0.366637,
            "recall": 0.359478,
            "recall_weighted": 0.199145,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.208547,
            "f1": 0.24206,
            "f1_weighted": 0.176071,
            "precision": 0.271724,
            "precision_weighted": 0.315975,
            "recall": 0.386059,
            "recall_weighted": 0.208547,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.219658,
            "f1": 0.254224,
            "f1_weighted": 0.195485,
            "precision": 0.294591,
            "precision_weighted": 0.378181,
            "recall": 0.403936,
            "recall_weighted": 0.219658,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.197436,
            "f1": 0.217841,
            "f1_weighted": 0.165465,
            "precision": 0.270424,
            "precision_weighted": 0.298742,
            "recall": 0.350654,
            "recall_weighted": 0.197436,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.204274,
            "f1": 0.240627,
            "f1_weighted": 0.170403,
            "precision": 0.263527,
            "precision_weighted": 0.272134,
            "recall": 0.385042,
            "recall_weighted": 0.204274,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.203419,
            "f1": 0.236187,
            "f1_weighted": 0.169906,
            "precision": 0.257803,
            "precision_weighted": 0.241468,
            "recall": 0.377085,
            "recall_weighted": 0.203419,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.207692,
            "f1": 0.238356,
            "f1_weighted": 0.174426,
            "precision": 0.267028,
            "precision_weighted": 0.346718,
            "recall": 0.379319,
            "recall_weighted": 0.207692,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.206068,
        "f1": 0.236286,
        "f1_weighted": 0.176812,
        "precision": 0.270927,
        "precision_weighted": 0.32122,
        "recall": 0.378779,
        "recall_weighted": 0.206068,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.236286,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 71.5086681842804,
  "kg_co2_emissions": null
}