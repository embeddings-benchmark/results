{
  "dataset_revision": "f5502326c4e48adc99b18b1582f68b8fb5e7ec30",
  "evaluation_time": 38.850274085998535,
  "kg_co2_emissions": 0.008530004148258696,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.57875,
        "f1": 0.28543570044671257,
        "f1_weighted": 0.5279579264745335,
        "hf_subset": "default",
        "languages": [
          "ssw-Latn"
        ],
        "main_score": 0.57875,
        "scores_per_experiment": [
          {
            "accuracy": 0.6,
            "f1": 0.3013294711824123,
            "f1_weighted": 0.5573589890501655
          },
          {
            "accuracy": 0.5625,
            "f1": 0.26952370289808714,
            "f1_weighted": 0.5162456816582432
          },
          {
            "accuracy": 0.575,
            "f1": 0.2796838578088578,
            "f1_weighted": 0.5154374271561771
          },
          {
            "accuracy": 0.6125,
            "f1": 0.28959199841552785,
            "f1_weighted": 0.5595870469399881
          },
          {
            "accuracy": 0.625,
            "f1": 0.30841609371021134,
            "f1_weighted": 0.5795855614973262
          },
          {
            "accuracy": 0.5375,
            "f1": 0.26714187801649103,
            "f1_weighted": 0.47916393032492105
          },
          {
            "accuracy": 0.55,
            "f1": 0.2730014731563661,
            "f1_weighted": 0.5080964386092248
          },
          {
            "accuracy": 0.525,
            "f1": 0.2611395728417005,
            "f1_weighted": 0.4608511945214072
          },
          {
            "accuracy": 0.6,
            "f1": 0.3050391432466904,
            "f1_weighted": 0.5565218036680302
          },
          {
            "accuracy": 0.6,
            "f1": 0.29948981319078144,
            "f1_weighted": 0.546731191319852
          }
        ]
      }
    ]
  },
  "task_name": "SiswatiNewsClassification"
}