{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 102.51450991630554,
  "kg_co2_emissions": 0.023381131929404064,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.693505859375,
        "ap": 0.14623701826180968,
        "ap_weighted": 0.14623701826180968,
        "f1": 0.5404129999580388,
        "f1_weighted": 0.7618178819912047,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.693505859375,
        "scores_per_experiment": [
          {
            "accuracy": 0.685546875,
            "ap": 0.14119275561831562,
            "ap_weighted": 0.14119275561831562,
            "f1": 0.5339665309814563,
            "f1_weighted": 0.7577032716389643
          },
          {
            "accuracy": 0.76123046875,
            "ap": 0.17727833964089748,
            "ap_weighted": 0.17727833964089748,
            "f1": 0.5919924808813698,
            "f1_weighted": 0.8131951276482526
          },
          {
            "accuracy": 0.7158203125,
            "ap": 0.15117754921636087,
            "ap_weighted": 0.15117754921636087,
            "f1": 0.5546628407460545,
            "f1_weighted": 0.780178653492647
          },
          {
            "accuracy": 0.70654296875,
            "ap": 0.14371069673496584,
            "ap_weighted": 0.14371069673496584,
            "f1": 0.5455346682454918,
            "f1_weighted": 0.7732445206407109
          },
          {
            "accuracy": 0.583984375,
            "ap": 0.12640993173889928,
            "ap_weighted": 0.12640993173889928,
            "f1": 0.4747371120800205,
            "f1_weighted": 0.6763883768273916
          },
          {
            "accuracy": 0.57861328125,
            "ap": 0.12417961774643183,
            "ap_weighted": 0.12417961774643183,
            "f1": 0.47062176387727006,
            "f1_weighted": 0.6718946027427689
          },
          {
            "accuracy": 0.78662109375,
            "ap": 0.16815276435423826,
            "ap_weighted": 0.16815276435423826,
            "f1": 0.598935784536252,
            "f1_weighted": 0.8298918681083444
          },
          {
            "accuracy": 0.669921875,
            "ap": 0.13839758556218684,
            "ap_weighted": 0.13839758556218684,
            "f1": 0.5247150586361264,
            "f1_weighted": 0.7458604220736866
          },
          {
            "accuracy": 0.6806640625,
            "ap": 0.1258636714365881,
            "ap_weighted": 0.1258636714365881,
            "f1": 0.5211634574821784,
            "f1_weighted": 0.7538022417890519
          },
          {
            "accuracy": 0.76611328125,
            "ap": 0.16600727056921255,
            "ap_weighted": 0.16600727056921255,
            "f1": 0.5878003021141689,
            "f1_weighted": 0.8160197349502288
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}