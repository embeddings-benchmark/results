{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.936621,
        "f1": 0.936442,
        "f1_weighted": 0.936451,
        "ap": 0.897661,
        "ap_weighted": 0.897661,
        "scores_per_experiment": [
          {
            "accuracy": 0.914551,
            "f1": 0.914071,
            "f1_weighted": 0.91409,
            "ap": 0.857935,
            "ap_weighted": 0.857935
          },
          {
            "accuracy": 0.950684,
            "f1": 0.950683,
            "f1_weighted": 0.950684,
            "ap": 0.92893,
            "ap_weighted": 0.92893
          },
          {
            "accuracy": 0.958496,
            "f1": 0.958468,
            "f1_weighted": 0.958471,
            "ap": 0.930461,
            "ap_weighted": 0.930461
          },
          {
            "accuracy": 0.912598,
            "f1": 0.912417,
            "f1_weighted": 0.912429,
            "ap": 0.863628,
            "ap_weighted": 0.863628
          },
          {
            "accuracy": 0.947266,
            "f1": 0.947189,
            "f1_weighted": 0.947195,
            "ap": 0.910805,
            "ap_weighted": 0.910805
          },
          {
            "accuracy": 0.956055,
            "f1": 0.956055,
            "f1_weighted": 0.956055,
            "ap": 0.936666,
            "ap_weighted": 0.936666
          },
          {
            "accuracy": 0.936035,
            "f1": 0.936007,
            "f1_weighted": 0.936011,
            "ap": 0.90185,
            "ap_weighted": 0.90185
          },
          {
            "accuracy": 0.949219,
            "f1": 0.949159,
            "f1_weighted": 0.949164,
            "ap": 0.914797,
            "ap_weighted": 0.914797
          },
          {
            "accuracy": 0.930664,
            "f1": 0.930384,
            "f1_weighted": 0.930397,
            "ap": 0.881092,
            "ap_weighted": 0.881092
          },
          {
            "accuracy": 0.910645,
            "f1": 0.909987,
            "f1_weighted": 0.91001,
            "ap": 0.850448,
            "ap_weighted": 0.850448
          }
        ],
        "main_score": 0.936621,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.937598,
        "f1": 0.937464,
        "f1_weighted": 0.937469,
        "ap": 0.900424,
        "ap_weighted": 0.900424,
        "scores_per_experiment": [
          {
            "accuracy": 0.924316,
            "f1": 0.923976,
            "f1_weighted": 0.923986,
            "ap": 0.871737,
            "ap_weighted": 0.871737
          },
          {
            "accuracy": 0.95166,
            "f1": 0.95166,
            "f1_weighted": 0.95166,
            "ap": 0.930606,
            "ap_weighted": 0.930606
          },
          {
            "accuracy": 0.956055,
            "f1": 0.95604,
            "f1_weighted": 0.956041,
            "ap": 0.929487,
            "ap_weighted": 0.929487
          },
          {
            "accuracy": 0.911133,
            "f1": 0.910997,
            "f1_weighted": 0.911004,
            "ap": 0.863209,
            "ap_weighted": 0.863209
          },
          {
            "accuracy": 0.950195,
            "f1": 0.95014,
            "f1_weighted": 0.950144,
            "ap": 0.916022,
            "ap_weighted": 0.916022
          },
          {
            "accuracy": 0.952148,
            "f1": 0.952148,
            "f1_weighted": 0.952148,
            "ap": 0.932708,
            "ap_weighted": 0.932708
          },
          {
            "accuracy": 0.934082,
            "f1": 0.934072,
            "f1_weighted": 0.934074,
            "ap": 0.901917,
            "ap_weighted": 0.901917
          },
          {
            "accuracy": 0.950195,
            "f1": 0.950161,
            "f1_weighted": 0.950163,
            "ap": 0.918512,
            "ap_weighted": 0.918512
          },
          {
            "accuracy": 0.930176,
            "f1": 0.929923,
            "f1_weighted": 0.929931,
            "ap": 0.881091,
            "ap_weighted": 0.881091
          },
          {
            "accuracy": 0.916016,
            "f1": 0.915525,
            "f1_weighted": 0.915538,
            "ap": 0.858955,
            "ap_weighted": 0.858955
          }
        ],
        "main_score": 0.937598,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 169.20624709129333,
  "kg_co2_emissions": 0.04344092250005998
}