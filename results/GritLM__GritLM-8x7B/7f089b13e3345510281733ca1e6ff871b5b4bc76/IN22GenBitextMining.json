{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 1076.9261033535004,
  "kg_co2_emissions": 0.2630499333310328,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333334,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9807942708333334,
        "precision": 0.9786783854166667,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.435546875,
        "f1": 0.36482938448270485,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.36482938448270485,
        "precision": 0.34058779761904767,
        "recall": 0.435546875
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.90771484375,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.90771484375,
        "precision": 0.8984375,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9513346354166666,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9513346354166666,
        "precision": 0.9458333333333333,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7903180803571428,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.7903180803571428,
        "precision": 0.7731770833333333,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.8958333333333333,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8958333333333333,
        "precision": 0.8844401041666667,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9689127604166667,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9689127604166667,
        "precision": 0.9651692708333333,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9200520833333333,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.9200520833333333,
        "precision": 0.91162109375,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.708984375,
        "f1": 0.6483785962301587,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.6483785962301587,
        "precision": 0.6247016059027777,
        "recall": 0.708984375
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9513997395833333,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9513997395833333,
        "precision": 0.9458821614583334,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.814453125,
        "f1": 0.7691243489583333,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.7691243489583333,
        "precision": 0.7502697172619047,
        "recall": 0.814453125
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9397786458333333,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9397786458333333,
        "precision": 0.9327799479166667,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0007815881342204919,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0007815881342204919,
        "precision": 0.00047727967793463643,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9739583333333333,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9739583333333333,
        "precision": 0.970703125,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.8623046875,
        "f1": 0.8262695312499999,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.8262695312499999,
        "precision": 0.810546875,
        "recall": 0.8623046875
      },
      {
        "accuracy": 0.8173828125,
        "f1": 0.7730305989583334,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.7730305989583334,
        "precision": 0.7536249069940477,
        "recall": 0.8173828125
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9391276041666666,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9391276041666666,
        "precision": 0.9322916666666666,
        "recall": 0.953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010260025062656642,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0010260025062656642,
        "precision": 0.0010018518242176022,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7719331287202381,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.7719331287202381,
        "precision": 0.7550874255952381,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8636253720238095,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8636253720238095,
        "precision": 0.850341796875,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.8511067708333333,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8511067708333333,
        "precision": 0.8364095052083333,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9498697916666666,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9498697916666666,
        "precision": 0.9440104166666667,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9778645833333333,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.9778645833333333,
        "precision": 0.97509765625,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.41204584261224886,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.41204584261224886,
        "precision": 0.389868586816829,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9547526041666666,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9547526041666666,
        "precision": 0.9493815104166666,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8623697916666666,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8623697916666666,
        "precision": 0.8485514322916666,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9436848958333334,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9436848958333334,
        "precision": 0.9375,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9720052083333333,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.9720052083333333,
        "precision": 0.9690755208333333,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.8017578125,
        "f1": 0.7547929067460317,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.7547929067460317,
        "precision": 0.7349527994791667,
        "recall": 0.8017578125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.880859375,
        "f1": 0.84892578125,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.84892578125,
        "precision": 0.8347005208333333,
        "recall": 0.880859375
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9781901041666666,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9781901041666666,
        "precision": 0.9755859375,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001217990451388889,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.001217990451388889,
        "precision": 0.0008078027844999827,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8574869791666666,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.8574869791666666,
        "precision": 0.8433756510416668,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8643229166666666,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.8643229166666666,
        "precision": 0.8514322916666667,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000490677722392638,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.000490677722392638,
        "precision": 0.00032672054156429153,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8545107886904763,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8545107886904763,
        "precision": 0.84228515625,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.96044921875,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.96044921875,
        "precision": 0.9560546875,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.9404296875,
        "f1": 0.9233072916666667,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.9233072916666667,
        "precision": 0.9156901041666666,
        "recall": 0.9404296875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.4228515625,
        "f1": 0.36416342511765903,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.36416342511765903,
        "precision": 0.3456467089767871,
        "recall": 0.4228515625
      },
      {
        "accuracy": 0.4375,
        "f1": 0.3812050417030886,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.3812050417030886,
        "precision": 0.3646564646743643,
        "recall": 0.4375
      },
      {
        "accuracy": 0.4462890625,
        "f1": 0.40041421523355114,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.40041421523355114,
        "precision": 0.38532885864634886,
        "recall": 0.4462890625
      },
      {
        "accuracy": 0.3896484375,
        "f1": 0.3313303474924569,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.3313303474924569,
        "precision": 0.3144955211565589,
        "recall": 0.3896484375
      },
      {
        "accuracy": 0.4306640625,
        "f1": 0.3756561976504192,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3756561976504192,
        "precision": 0.35910902790785604,
        "recall": 0.4306640625
      },
      {
        "accuracy": 0.373046875,
        "f1": 0.3201789818026454,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.3201789818026454,
        "precision": 0.3042133272486377,
        "recall": 0.373046875
      },
      {
        "accuracy": 0.431640625,
        "f1": 0.37182006777401666,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.37182006777401666,
        "precision": 0.35462679992278456,
        "recall": 0.431640625
      },
      {
        "accuracy": 0.3974609375,
        "f1": 0.33229768148224637,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.33229768148224637,
        "precision": 0.3134843913073849,
        "recall": 0.3974609375
      },
      {
        "accuracy": 0.3603515625,
        "f1": 0.31135765085098727,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.31135765085098727,
        "precision": 0.2971287073814572,
        "recall": 0.3603515625
      },
      {
        "accuracy": 0.453125,
        "f1": 0.3967867267655118,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3967867267655118,
        "precision": 0.37725975817586066,
        "recall": 0.453125
      },
      {
        "accuracy": 0.3427734375,
        "f1": 0.28201934050681754,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.28201934050681754,
        "precision": 0.26453928260324744,
        "recall": 0.3427734375
      },
      {
        "accuracy": 0.4404296875,
        "f1": 0.38108484026709766,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.38108484026709766,
        "precision": 0.3640715855516522,
        "recall": 0.4404296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0022304279073657564,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0022304279073657564,
        "precision": 0.0014738992274757959,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.42578125,
        "f1": 0.362370408528784,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.362370408528784,
        "precision": 0.3443413596380548,
        "recall": 0.42578125
      },
      {
        "accuracy": 0.314453125,
        "f1": 0.2576996268336039,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2576996268336039,
        "precision": 0.241326289385029,
        "recall": 0.314453125
      },
      {
        "accuracy": 0.32421875,
        "f1": 0.2712705748838486,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.2712705748838486,
        "precision": 0.2556844080845947,
        "recall": 0.32421875
      },
      {
        "accuracy": 0.4384765625,
        "f1": 0.37672059100667243,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.37672059100667243,
        "precision": 0.35840328910874936,
        "recall": 0.4384765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006200664768281406,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0006200664768281406,
        "precision": 0.00034720278524157837,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.4609375,
        "f1": 0.4165542562905844,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4165542562905844,
        "precision": 0.4018356081039186,
        "recall": 0.4609375
      },
      {
        "accuracy": 0.3310546875,
        "f1": 0.2761458579940025,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.2761458579940025,
        "precision": 0.25997857704807126,
        "recall": 0.3310546875
      },
      {
        "accuracy": 0.384765625,
        "f1": 0.3279330059496313,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.3279330059496313,
        "precision": 0.31199071643105236,
        "recall": 0.384765625
      },
      {
        "accuracy": 0.38671875,
        "f1": 0.332025962322775,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.332025962322775,
        "precision": 0.3159123068919303,
        "recall": 0.38671875
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9265950520833334,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9265950520833334,
        "precision": 0.91845703125,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9599609375,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9599609375,
        "precision": 0.9552408854166666,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.4814453125,
        "f1": 0.4119009571158009,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4119009571158009,
        "precision": 0.3868540873380602,
        "recall": 0.4814453125
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9794921875,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9794921875,
        "precision": 0.9772135416666666,
        "recall": 0.984375
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8459495907738095,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8459495907738095,
        "precision": 0.8315755208333333,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.9248046875,
        "f1": 0.9029622395833333,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9029622395833333,
        "precision": 0.892578125,
        "recall": 0.9248046875
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9835611979166667,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9835611979166667,
        "precision": 0.9817708333333334,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9078776041666666,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9078776041666666,
        "precision": 0.89794921875,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7414248511904762,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7414248511904762,
        "precision": 0.7208844866071429,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9650065104166667,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9650065104166667,
        "precision": 0.9607747395833334,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.7786783854166667,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7786783854166667,
        "precision": 0.7591796875,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9552408854166666,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9552408854166666,
        "precision": 0.9500325520833334,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003114305436415699,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003114305436415699,
        "precision": 0.0020988343253968253,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9683268229166666,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9683268229166666,
        "precision": 0.9649251302083334,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.783203125,
        "f1": 0.7323614211309524,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7323614211309524,
        "precision": 0.7116861979166667,
        "recall": 0.783203125
      },
      {
        "accuracy": 0.884765625,
        "f1": 0.8537923177083333,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8537923177083333,
        "precision": 0.8400971912202381,
        "recall": 0.884765625
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9479166666666666,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9479166666666666,
        "precision": 0.9420572916666667,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.591479976924186e-05,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 6.591479976924186e-05,
        "precision": 3.400963930348259e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8836263020833333,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8836263020833333,
        "precision": 0.87275390625,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.8880533854166667,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8880533854166667,
        "precision": 0.8780761718750001,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8791666666666667,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8791666666666667,
        "precision": 0.8673502604166667,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9641927083333333,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9641927083333333,
        "precision": 0.9602864583333333,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9461263020833333,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9461263020833333,
        "precision": 0.93994140625,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.431640625,
        "f1": 0.34969702606421355,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.34969702606421355,
        "precision": 0.32249859786480883,
        "recall": 0.431640625
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.9527994791666666,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.9527994791666666,
        "precision": 0.9474283854166666,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.8541852678571429,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8541852678571429,
        "precision": 0.8394694010416667,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.9462890625,
        "f1": 0.9302408854166666,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9302408854166666,
        "precision": 0.9229329427083333,
        "recall": 0.9462890625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9650065104166666,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9650065104166666,
        "precision": 0.9607747395833334,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7387137276785714,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.7387137276785714,
        "precision": 0.7171572730654762,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.8495442708333334,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8495442708333334,
        "precision": 0.8354817708333333,
        "recall": 0.8818359375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666666,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9830729166666666,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001432999320652174,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.001432999320652174,
        "precision": 0.000865343585256244,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.6956907242063493,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6956907242063493,
        "precision": 0.6736777057577839,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.8432477678571428,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8432477678571428,
        "precision": 0.828564453125,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005464804292929293,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0005464804292929293,
        "precision": 0.0002967475235504472,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.8623372395833333,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.8623372395833333,
        "precision": 0.8494303385416667,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9651692708333334,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9651692708333334,
        "precision": 0.9611002604166666,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.91533203125,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.91533203125,
        "precision": 0.9066080729166667,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.85546875,
        "f1": 0.8207682291666667,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8207682291666667,
        "precision": 0.8055664062500001,
        "recall": 0.85546875
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.879296875,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.879296875,
        "precision": 0.8674641927083333,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.4619140625,
        "f1": 0.3949314284189054,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.3949314284189054,
        "precision": 0.3715373985472503,
        "recall": 0.4619140625
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8485677083333334,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8485677083333334,
        "precision": 0.83466796875,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.870751953125,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.870751953125,
        "precision": 0.8578055245535714,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.8564453125,
        "f1": 0.8215843563988094,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8215843563988094,
        "precision": 0.8068126860119047,
        "recall": 0.8564453125
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.90859375,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.90859375,
        "precision": 0.8983561197916667,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.873046875,
        "f1": 0.8412783668154762,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8412783668154762,
        "precision": 0.8271577380952381,
        "recall": 0.873046875
      },
      {
        "accuracy": 0.681640625,
        "f1": 0.6199784536210317,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6199784536210317,
        "precision": 0.5959050254216269,
        "recall": 0.681640625
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.8942057291666666,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8942057291666666,
        "precision": 0.883984375,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.7529296875,
        "f1": 0.7014260912698412,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7014260912698412,
        "precision": 0.6799560546875,
        "recall": 0.7529296875
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9325195312499999,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9325195312499999,
        "precision": 0.925048828125,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0019883178632029734,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0019883178632029734,
        "precision": 0.0016453613093768854,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9116861979166666,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9116861979166666,
        "precision": 0.9022623697916666,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.685546875,
        "f1": 0.6234413752480159,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6234413752480159,
        "precision": 0.5989350818452381,
        "recall": 0.685546875
      },
      {
        "accuracy": 0.7490234375,
        "f1": 0.6945033482142857,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6945033482142857,
        "precision": 0.6722981770833334,
        "recall": 0.7490234375
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8792317708333333,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8792317708333333,
        "precision": 0.86669921875,
        "recall": 0.90625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00010545698587408575,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00010545698587408575,
        "precision": 5.5585753941185386e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.8251953125,
        "f1": 0.78662109375,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.78662109375,
        "precision": 0.7703613281249999,
        "recall": 0.8251953125
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7784839184253247,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7784839184253247,
        "precision": 0.7603352864583333,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7795572916666667,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7795572916666667,
        "precision": 0.7625162760416666,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8641276041666667,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8641276041666667,
        "precision": 0.849853515625,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.8968750000000001,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.8968750000000001,
        "precision": 0.885986328125,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.94970703125,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.94970703125,
        "precision": 0.9443359375,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.4130859375,
        "f1": 0.3463325988630446,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.3463325988630446,
        "precision": 0.32473122716042635,
        "recall": 0.4130859375
      },
      {
        "accuracy": 0.9248046875,
        "f1": 0.902734375,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.902734375,
        "precision": 0.892333984375,
        "recall": 0.9248046875
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9257486979166667,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9257486979166667,
        "precision": 0.9183268229166667,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.8544921875,
        "f1": 0.8166015625,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.8166015625,
        "precision": 0.7994303385416667,
        "recall": 0.8544921875
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9578450520833334,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9578450520833334,
        "precision": 0.9529622395833333,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.91845703125,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.91845703125,
        "precision": 0.90986328125,
        "recall": 0.9365234375
      },
      {
        "accuracy": 0.712890625,
        "f1": 0.6594711061507936,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.6594711061507936,
        "precision": 0.6391589936755953,
        "recall": 0.712890625
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.93212890625,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.93212890625,
        "precision": 0.92431640625,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.8408203125,
        "f1": 0.8006510416666666,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.8006510416666666,
        "precision": 0.7830240885416666,
        "recall": 0.8408203125
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9558919270833333,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.9558919270833333,
        "precision": 0.951171875,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0031930557605273514,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0031930557605273514,
        "precision": 0.0027431390224358972,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9560546875,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9560546875,
        "precision": 0.95068359375,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.865234375,
        "f1": 0.8325218563988095,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.8325218563988095,
        "precision": 0.8178478422619048,
        "recall": 0.865234375
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.8699761284722223,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.8699761284722223,
        "precision": 0.8580322265625,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9243489583333333,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.9243489583333333,
        "precision": 0.9164225260416666,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00033012726022012577,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.00033012726022012577,
        "precision": 0.000197621158392435,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.7807663690476191,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.7807663690476191,
        "precision": 0.7629231770833333,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8725260416666667,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.8725260416666667,
        "precision": 0.86103515625,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8778645833333333,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.8778645833333333,
        "precision": 0.8658854166666666,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.94873046875,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.94873046875,
        "precision": 0.94287109375,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9718424479166666,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9718424479166666,
        "precision": 0.9685872395833334,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.4541015625,
        "f1": 0.3812605634382978,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.3812605634382978,
        "precision": 0.35776095920138884,
        "recall": 0.4541015625
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9715169270833333,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9715169270833333,
        "precision": 0.9680989583333334,
        "recall": 0.978515625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8796549479166667,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8796549479166667,
        "precision": 0.8678385416666667,
        "recall": 0.90625
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9475911458333333,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9475911458333333,
        "precision": 0.9415690104166666,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9679361979166667,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9679361979166667,
        "precision": 0.96435546875,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.8017578125,
        "f1": 0.7529405381944445,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7529405381944445,
        "precision": 0.7330240885416666,
        "recall": 0.8017578125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.85517578125,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.85517578125,
        "precision": 0.8417805989583333,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001651148668325744,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001651148668325744,
        "precision": 0.0010377419473995271,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8071986607142857,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8071986607142857,
        "precision": 0.7899576822916667,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8859700520833333,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8859700520833333,
        "precision": 0.873779296875,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.4322851805728518e-06,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 2.4322851805728518e-06,
        "precision": 1.2176589775561097e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8787109375,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8787109375,
        "precision": 0.8670572916666667,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9557291666666666,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9557291666666666,
        "precision": 0.9501953125,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9254557291666666,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9254557291666666,
        "precision": 0.9168294270833334,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.935546875,
        "f1": 0.9162434895833333,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.9162434895833333,
        "precision": 0.907470703125,
        "recall": 0.935546875
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9700520833333334,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9700520833333334,
        "precision": 0.96630859375,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.3955078125,
        "f1": 0.3288308162489573,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.3288308162489573,
        "precision": 0.30816557120745725,
        "recall": 0.3955078125
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.8920572916666667,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.8920572916666667,
        "precision": 0.8816731770833333,
        "recall": 0.9150390625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9651692708333333,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9651692708333333,
        "precision": 0.9611002604166666,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8156901041666667,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.8156901041666667,
        "precision": 0.7986979166666667,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9090169270833334,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.9090169270833334,
        "precision": 0.8994466145833333,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9765625,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.9765625,
        "precision": 0.9736328125,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.6904296875,
        "f1": 0.6298284397893772,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.6298284397893772,
        "precision": 0.6064872356376263,
        "recall": 0.6904296875
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9448893229166666,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9448893229166666,
        "precision": 0.9385579427083333,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.875,
        "f1": 0.8400227864583334,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.8400227864583334,
        "precision": 0.8243908110119047,
        "recall": 0.875
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.96484375,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.96484375,
        "precision": 0.96044921875,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0038496422571465657,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0038496422571465657,
        "precision": 0.003257455741317106,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.96484375,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.96484375,
        "precision": 0.96044921875,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.7804547991071429,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.7804547991071429,
        "precision": 0.7626627604166667,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.7940483940972223,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7940483940972223,
        "precision": 0.7735363188244048,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9637044270833334,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9637044270833334,
        "precision": 0.9593098958333333,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010295198533298096,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0010295198533298096,
        "precision": 0.0007107028024500217,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.82421875,
        "f1": 0.784423828125,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.784423828125,
        "precision": 0.767822688379329,
        "recall": 0.82421875
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9289388020833333,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.9289388020833333,
        "precision": 0.9217936197916667,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9250325520833333,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.9250325520833333,
        "precision": 0.9170735677083334,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9599609375,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.9599609375,
        "precision": 0.955078125,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.75,
        "f1": 0.6951032366071428,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6951032366071428,
        "precision": 0.6716796875,
        "recall": 0.75
      },
      {
        "accuracy": 0.779296875,
        "f1": 0.7258262028769842,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7258262028769842,
        "precision": 0.7037516276041667,
        "recall": 0.779296875
      },
      {
        "accuracy": 0.3896484375,
        "f1": 0.3256080407605568,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.3256080407605568,
        "precision": 0.3047566487874105,
        "recall": 0.3896484375
      },
      {
        "accuracy": 0.791015625,
        "f1": 0.7460549975198413,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7460549975198413,
        "precision": 0.7283958798363095,
        "recall": 0.791015625
      },
      {
        "accuracy": 0.7880859375,
        "f1": 0.7385858444940476,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7385858444940476,
        "precision": 0.719339812748016,
        "recall": 0.7880859375
      },
      {
        "accuracy": 0.6884765625,
        "f1": 0.632658920940171,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.632658920940171,
        "precision": 0.6110416845524267,
        "recall": 0.6884765625
      },
      {
        "accuracy": 0.7080078125,
        "f1": 0.649662853422619,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.649662853422619,
        "precision": 0.627523949032738,
        "recall": 0.7080078125
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7729430183531747,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.7729430183531747,
        "precision": 0.7558698381696429,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.7197265625,
        "f1": 0.6605360243055556,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.6605360243055556,
        "precision": 0.6365009962910353,
        "recall": 0.7197265625
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.762939453125,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.762939453125,
        "precision": 0.7450559585813492,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.615234375,
        "f1": 0.5493706597222222,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.5493706597222222,
        "precision": 0.5240253155048077,
        "recall": 0.615234375
      },
      {
        "accuracy": 0.7666015625,
        "f1": 0.7162404598439754,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7162404598439754,
        "precision": 0.6964367094494048,
        "recall": 0.7666015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015142308829019413,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0015142308829019413,
        "precision": 0.0013272154564950979,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.7958984375,
        "f1": 0.746182105654762,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.746182105654762,
        "precision": 0.7258897569444445,
        "recall": 0.7958984375
      },
      {
        "accuracy": 0.53125,
        "f1": 0.4590843563988095,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.4590843563988095,
        "precision": 0.43355148540695415,
        "recall": 0.53125
      },
      {
        "accuracy": 0.642578125,
        "f1": 0.5808381315949676,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.5808381315949676,
        "precision": 0.557684264520202,
        "recall": 0.642578125
      },
      {
        "accuracy": 0.7666015625,
        "f1": 0.7196614583333334,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.7196614583333334,
        "precision": 0.7011904761904761,
        "recall": 0.7666015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00043477376302083337,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00043477376302083337,
        "precision": 0.00026662024347924546,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.755859375,
        "f1": 0.7092673385642135,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7092673385642135,
        "precision": 0.6907544685132576,
        "recall": 0.755859375
      },
      {
        "accuracy": 0.658203125,
        "f1": 0.5969230530753968,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.5969230530753968,
        "precision": 0.5731277249112364,
        "recall": 0.658203125
      },
      {
        "accuracy": 0.6923828125,
        "f1": 0.637410869295635,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.637410869295635,
        "precision": 0.6170557415674602,
        "recall": 0.6923828125
      },
      {
        "accuracy": 0.8896484375,
        "f1": 0.8618582589285715,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.8618582589285715,
        "precision": 0.8496031149839743,
        "recall": 0.8896484375
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.96044921875,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.96044921875,
        "precision": 0.9560546875,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.4765625,
        "f1": 0.40923020664231596,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.40923020664231596,
        "precision": 0.38652337788079977,
        "recall": 0.4765625
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9637044270833334,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9637044270833334,
        "precision": 0.9593098958333333,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9033203125,
        "f1": 0.8768229166666667,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8768229166666667,
        "precision": 0.8648274739583333,
        "recall": 0.9033203125
      },
      {
        "accuracy": 0.9462890625,
        "f1": 0.9293619791666667,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9293619791666667,
        "precision": 0.9212239583333334,
        "recall": 0.9462890625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9454752604166666,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9454752604166666,
        "precision": 0.9388020833333334,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.8115234375,
        "f1": 0.7667557973710317,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7667557973710317,
        "precision": 0.7480480375744047,
        "recall": 0.8115234375
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.79580078125,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.79580078125,
        "precision": 0.77705078125,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9752604166666666,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9752604166666666,
        "precision": 0.97216796875,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001323420942623652,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001323420942623652,
        "precision": 0.000812844669117647,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.8427734375,
        "f1": 0.8013206845238096,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8013206845238096,
        "precision": 0.7832682291666666,
        "recall": 0.8427734375
      },
      {
        "accuracy": 0.8896484375,
        "f1": 0.8578776041666667,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8578776041666667,
        "precision": 0.84326171875,
        "recall": 0.8896484375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666666,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.9830729166666666,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006537171803652968,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0006537171803652968,
        "precision": 0.0004896208419067215,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8830078125,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8830078125,
        "precision": 0.8728678385416667,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.92431640625,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.92431640625,
        "precision": 0.9156901041666666,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.9306640625,
        "f1": 0.9092447916666666,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9092447916666666,
        "precision": 0.899169921875,
        "recall": 0.9306640625
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.8115234375,
        "f1": 0.768266369047619,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.768266369047619,
        "precision": 0.7505696614583333,
        "recall": 0.8115234375
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8347330729166667,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.8347330729166667,
        "precision": 0.8205403645833333,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.3427734375,
        "f1": 0.28309303498512484,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.28309303498512484,
        "precision": 0.26342750000685355,
        "recall": 0.3427734375
      },
      {
        "accuracy": 0.7939453125,
        "f1": 0.7466037326388888,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.7466037326388888,
        "precision": 0.7270263671874999,
        "recall": 0.7939453125
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8235584077380952,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.8235584077380952,
        "precision": 0.8095486111111111,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.69921875,
        "f1": 0.640999229719933,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.640999229719933,
        "precision": 0.6189708891369047,
        "recall": 0.69921875
      },
      {
        "accuracy": 0.828125,
        "f1": 0.7904947916666667,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.7904947916666667,
        "precision": 0.7747884114583333,
        "recall": 0.828125
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.8513857886904762,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.8513857886904762,
        "precision": 0.838232421875,
        "recall": 0.8818359375
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8253487723214286,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.8253487723214286,
        "precision": 0.8106119791666666,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.5172747283098845,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.5172747283098845,
        "precision": 0.4943275031366713,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.82421875,
        "f1": 0.7840704055059524,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.7840704055059524,
        "precision": 0.7673921130952381,
        "recall": 0.82421875
      },
      {
        "accuracy": 0.8505859375,
        "f1": 0.8174525669642857,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.8174525669642857,
        "precision": 0.8041038876488096,
        "recall": 0.8505859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0005796742658473494,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.0005796742658473494,
        "precision": 0.00032957682482395755,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.880859375,
        "f1": 0.8483072916666666,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.8483072916666666,
        "precision": 0.8337673611111112,
        "recall": 0.880859375
      },
      {
        "accuracy": 0.7373046875,
        "f1": 0.6856305803571429,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.6856305803571429,
        "precision": 0.6649274553571429,
        "recall": 0.7373046875
      },
      {
        "accuracy": 0.7265625,
        "f1": 0.6741623537435808,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.6741623537435808,
        "precision": 0.6535294733127626,
        "recall": 0.7265625
      },
      {
        "accuracy": 0.875,
        "f1": 0.8422200520833333,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.8422200520833333,
        "precision": 0.82783203125,
        "recall": 0.875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003794317862036901,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0003794317862036901,
        "precision": 0.00022273409193840582,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.681640625,
        "f1": 0.6258161272321429,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.6258161272321429,
        "precision": 0.6055169322503307,
        "recall": 0.681640625
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.8024274553571429,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.8024274553571429,
        "precision": 0.7880068824404762,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.8525390625,
        "f1": 0.8159086681547618,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.8159086681547618,
        "precision": 0.7999674479166666,
        "recall": 0.8525390625
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8362676711309524,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.8362676711309524,
        "precision": 0.8234157986111111,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9521484375,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9521484375,
        "precision": 0.9471028645833333,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666666,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9820963541666666,
        "precision": 0.97998046875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.447265625,
        "f1": 0.37239512874278496,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.37239512874278496,
        "precision": 0.34691885709521275,
        "recall": 0.447265625
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.94580078125,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.94580078125,
        "precision": 0.9401041666666667,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9923502604166666,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9923502604166666,
        "precision": 0.9915364583333334,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9152669270833333,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9152669270833333,
        "precision": 0.9063313802083333,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.9361653645833333,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9361653645833333,
        "precision": 0.92919921875,
        "recall": 0.951171875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9573567708333334,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9573567708333334,
        "precision": 0.9523111979166666,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.7529296875,
        "f1": 0.7018359732715201,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7018359732715201,
        "precision": 0.6819014644209956,
        "recall": 0.7529296875
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9715169270833333,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9715169270833333,
        "precision": 0.9680989583333333,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.8623046875,
        "f1": 0.8258975074404762,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8258975074404762,
        "precision": 0.8095703125,
        "recall": 0.8623046875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0020203340032952104,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0020203340032952104,
        "precision": 0.0016032855812916956,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.97802734375,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.97802734375,
        "precision": 0.9754231770833333,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.8212890625,
        "f1": 0.7776041666666667,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7776041666666667,
        "precision": 0.7594889322916667,
        "recall": 0.8212890625
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.83466796875,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.83466796875,
        "precision": 0.8191243489583333,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9755859375,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.9755859375,
        "precision": 0.97265625,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002815250779387493,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0002815250779387493,
        "precision": 0.0001640156383890317,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8478678385416666,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8478678385416666,
        "precision": 0.8350027901785715,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9292643229166666,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9292643229166666,
        "precision": 0.9226399739583333,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8940104166666666,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8940104166666666,
        "precision": 0.8829752604166666,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666666,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9791666666666666,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016603581691335921,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0016603581691335921,
        "precision": 0.0014813548414971183,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.609918825994258e-05,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 4.609918825994258e-05,
        "precision": 2.3206738683475127e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004854225101247845,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0004854225101247845,
        "precision": 0.00026436106547906115,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006141366884689923,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0006141366884689923,
        "precision": 0.00039252123786407767,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004644426031144781,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0004644426031144781,
        "precision": 0.00026322605810346906,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00041910887788555804,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.00041910887788555804,
        "precision": 0.0002431484206137681,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008924470891709396,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0008924470891709396,
        "precision": 0.0005764633076788407,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011756023377862595,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0011756023377862595,
        "precision": 0.00108693667675802,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0003255208333333333,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0003255208333333333,
        "precision": 0.0001953125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011260814736030252,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0011260814736030252,
        "precision": 0.001053615307624507,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.5365259740259742e-05,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 2.5365259740259742e-05,
        "precision": 1.2849506578947368e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00029426521434565016,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.00029426521434565016,
        "precision": 0.00017041446749121588,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003026378372409136,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0003026378372409136,
        "precision": 0.0001660287378025788,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001982762708649469,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0001982762708649469,
        "precision": 0.00010999108198243836,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00033978667480505717,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.00033978667480505717,
        "precision": 0.00020247996398894502,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002810169615440854,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0002810169615440854,
        "precision": 0.00016376099299863386,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000492555046498906,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.000492555046498906,
        "precision": 0.00029768023574561404,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0031305801893673976,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.0031305801893673976,
        "precision": 0.0026663235177754635,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0023527294245588304,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0023527294245588304,
        "precision": 0.002178237120490501,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.25534064665127e-06,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 2.25534064665127e-06,
        "precision": 1.1289739884393064e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014076093177655678,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0014076093177655678,
        "precision": 0.0009481878579359514,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0014701224662162162,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0014701224662162162,
        "precision": 0.0013047298441734416,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.97265625,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.97265625,
        "precision": 0.96923828125,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.4638671875,
        "f1": 0.3988332760989011,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.3988332760989011,
        "precision": 0.37634119894862084,
        "recall": 0.4638671875
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9661458333333334,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9661458333333334,
        "precision": 0.9619140625,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8765950520833332,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8765950520833332,
        "precision": 0.8639322916666667,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9547526041666666,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9547526041666666,
        "precision": 0.94921875,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.96240234375,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.96240234375,
        "precision": 0.9578450520833334,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.7551254734848485,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7551254734848485,
        "precision": 0.7342447916666667,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9871419270833333,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9871419270833333,
        "precision": 0.9856770833333334,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.8430338541666667,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8430338541666667,
        "precision": 0.8274739583333334,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.974609375,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.974609375,
        "precision": 0.9716796875,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014323920328023296,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0014323920328023296,
        "precision": 0.0009836390398550725,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.83564453125,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.83564453125,
        "precision": 0.819580078125,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8805989583333333,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8805989583333333,
        "precision": 0.8684407552083333,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.978515625,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.978515625,
        "precision": 0.97607421875,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.580085865257596e-06,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 2.580085865257596e-06,
        "precision": 1.2917493386243386e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8680338541666667,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8680338541666667,
        "precision": 0.8565592447916666,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9480794270833333,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9480794270833333,
        "precision": 0.9425455729166666,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9197591145833333,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9197591145833333,
        "precision": 0.9108072916666666,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.8369140625,
        "f1": 0.7967633928571428,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.7967633928571428,
        "precision": 0.7800641741071428,
        "recall": 0.8369140625
      },
      {
        "accuracy": 0.8427734375,
        "f1": 0.8052672371031746,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.8052672371031746,
        "precision": 0.7900383226799242,
        "recall": 0.8427734375
      },
      {
        "accuracy": 0.2919921875,
        "f1": 0.2397504241856351,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.2397504241856351,
        "precision": 0.22526133279732827,
        "recall": 0.2919921875
      },
      {
        "accuracy": 0.7177734375,
        "f1": 0.6637401498241342,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.6637401498241342,
        "precision": 0.6433044169372295,
        "recall": 0.7177734375
      },
      {
        "accuracy": 0.6953125,
        "f1": 0.6398959466098137,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.6398959466098137,
        "precision": 0.6207698144954004,
        "recall": 0.6953125
      },
      {
        "accuracy": 0.630859375,
        "f1": 0.5613032041742979,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.5613032041742979,
        "precision": 0.5367889976776695,
        "recall": 0.630859375
      },
      {
        "accuracy": 0.7978515625,
        "f1": 0.7588991826698628,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.7588991826698628,
        "precision": 0.7442446754092261,
        "recall": 0.7978515625
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7636555989583333,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.7636555989583333,
        "precision": 0.7489592347947701,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.7958984375,
        "f1": 0.7474679129464286,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.7474679129464286,
        "precision": 0.7275917658730159,
        "recall": 0.7958984375
      },
      {
        "accuracy": 0.4560546875,
        "f1": 0.39937677420844564,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.39937677420844564,
        "precision": 0.3821507096610497,
        "recall": 0.4560546875
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7745349702380953,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.7745349702380953,
        "precision": 0.7564290364583334,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.71875,
        "f1": 0.6627077132936507,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.6627077132936507,
        "precision": 0.640947033110119,
        "recall": 0.71875
      },
      {
        "accuracy": 0.78125,
        "f1": 0.7369442894345237,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.7369442894345237,
        "precision": 0.72002997002997,
        "recall": 0.78125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006494537601626017,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0006494537601626017,
        "precision": 0.0003850662426001822,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.833984375,
        "f1": 0.7930896577380953,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.7930896577380953,
        "precision": 0.7761149088541667,
        "recall": 0.833984375
      },
      {
        "accuracy": 0.7392578125,
        "f1": 0.6853593129960318,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.6853593129960318,
        "precision": 0.6640047588045634,
        "recall": 0.7392578125
      },
      {
        "accuracy": 0.779296875,
        "f1": 0.7288016814297834,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.7288016814297834,
        "precision": 0.7088268461681547,
        "recall": 0.779296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0011177983116671974,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0011177983116671974,
        "precision": 0.0007418288681396903,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.6142578125,
        "f1": 0.5579768213557276,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.5579768213557276,
        "precision": 0.538748150720807,
        "recall": 0.6142578125
      },
      {
        "accuracy": 0.6796875,
        "f1": 0.6267048272907647,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.6267048272907647,
        "precision": 0.6075882288284632,
        "recall": 0.6796875
      },
      {
        "accuracy": 0.775390625,
        "f1": 0.7315562855113635,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.7315562855113635,
        "precision": 0.7147472563244047,
        "recall": 0.775390625
      },
      {
        "accuracy": 0.75,
        "f1": 0.7024206622753267,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.7024206622753267,
        "precision": 0.6848696510195533,
        "recall": 0.75
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.79228515625,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.79228515625,
        "precision": 0.7735351562499999,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.9033203125,
        "f1": 0.8750651041666666,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.8750651041666666,
        "precision": 0.862060546875,
        "recall": 0.9033203125
      },
      {
        "accuracy": 0.35546875,
        "f1": 0.29479222663073407,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.29479222663073407,
        "precision": 0.27621236855902825,
        "recall": 0.35546875
      },
      {
        "accuracy": 0.880859375,
        "f1": 0.8478190104166666,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.8478190104166666,
        "precision": 0.8330891927083334,
        "recall": 0.880859375
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8490776909722222,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.8490776909722222,
        "precision": 0.8357414476799243,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.7294921875,
        "f1": 0.6725221664186507,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.6725221664186507,
        "precision": 0.6502127511160714,
        "recall": 0.7294921875
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8735677083333333,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.8735677083333333,
        "precision": 0.8618977864583333,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.8927083333333333,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.8927083333333333,
        "precision": 0.88134765625,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8307803199404762,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.8307803199404762,
        "precision": 0.8151041666666666,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.626953125,
        "f1": 0.565667240203373,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.565667240203373,
        "precision": 0.5429536365327381,
        "recall": 0.626953125
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8670572916666667,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.8670572916666667,
        "precision": 0.8546061197916666,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.765625,
        "f1": 0.7180199032738095,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.7180199032738095,
        "precision": 0.6987955729166666,
        "recall": 0.765625
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8398949032738096,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.8398949032738096,
        "precision": 0.82587890625,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0034008540319881166,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.0034008540319881166,
        "precision": 0.002465542305577122,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9189453125,
        "f1": 0.8960286458333333,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.8960286458333333,
        "precision": 0.8855305989583333,
        "recall": 0.9189453125
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7403994605654762,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.7403994605654762,
        "precision": 0.7196544828869048,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8263532366071429,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.8263532366071429,
        "precision": 0.809326171875,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.925975177304964e-06,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 6.925975177304964e-06,
        "precision": 3.4753113879003557e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.75,
        "f1": 0.6972191220238095,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.6972191220238095,
        "precision": 0.6766884807900432,
        "recall": 0.75
      },
      {
        "accuracy": 0.82421875,
        "f1": 0.7808454241071427,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.7808454241071427,
        "precision": 0.7619954427083334,
        "recall": 0.82421875
      },
      {
        "accuracy": 0.8125,
        "f1": 0.766796875,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.766796875,
        "precision": 0.7468098958333333,
        "recall": 0.8125
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.8967122395833333,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.8967122395833333,
        "precision": 0.8858235677083334,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.9357096354166666,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9357096354166666,
        "precision": 0.92822265625,
        "recall": 0.951171875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.4599609375,
        "f1": 0.3909638790411998,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.3909638790411998,
        "precision": 0.36782955757924163,
        "recall": 0.4599609375
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.93212890625,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.93212890625,
        "precision": 0.92431640625,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.890625,
        "f1": 0.8591796875,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8591796875,
        "precision": 0.8448893229166666,
        "recall": 0.890625
      },
      {
        "accuracy": 0.939453125,
        "f1": 0.92138671875,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.92138671875,
        "precision": 0.9127604166666666,
        "recall": 0.939453125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9599609375,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9599609375,
        "precision": 0.9552408854166666,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.7607421875,
        "f1": 0.7057640438988095,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7057640438988095,
        "precision": 0.684037078373016,
        "recall": 0.7607421875
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9778645833333333,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9778645833333333,
        "precision": 0.97509765625,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8599144345238094,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8599144345238094,
        "precision": 0.84736328125,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.97265625,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.97265625,
        "precision": 0.96923828125,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00338134765625,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00338134765625,
        "precision": 0.0028333063316052223,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.8525390625,
        "f1": 0.8159040178571428,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8159040178571428,
        "precision": 0.800244140625,
        "recall": 0.8525390625
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8353701636904761,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8353701636904761,
        "precision": 0.8194010416666667,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009143013100436681,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009143013100436681,
        "precision": 0.0005493836299400713,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.84130859375,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.84130859375,
        "precision": 0.8277506510416667,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9406575520833333,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9406575520833333,
        "precision": 0.9344889322916667,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9196614583333333,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9196614583333333,
        "precision": 0.9115397135416667,
        "recall": 0.9375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166666,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9806315104166666,
        "precision": 0.9783528645833333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00025537656251836314,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.00025537656251836314,
        "precision": 0.00014514782669495103,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011745432035519124,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0011745432035519124,
        "precision": 0.00108640537125703,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012477194710419576,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0012477194710419576,
        "precision": 0.0011243859479723912,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785718878600822,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0009785718878600822,
        "precision": 0.000977568228630278,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0010336732529879805,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0010336732529879805,
        "precision": 0.0010052973041934496,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011968315972222224,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0011968315972222224,
        "precision": 0.0011002631338689482,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010308660446469774,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0010308660446469774,
        "precision": 0.0010042557175486474,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000979336825284091,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.000979336825284091,
        "precision": 0.0009779516358463726,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010111798921533287,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0010111798921533287,
        "precision": 0.0009940629778287463,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004903502383474576,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.0004903502383474576,
        "precision": 0.0003265564245316366,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010055966847569609,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0010055966847569609,
        "precision": 0.0009912462825340644,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00162999185004075,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.00162999185004075,
        "precision": 0.0014660390529375766,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009805484693877551,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0009805484693877551,
        "precision": 0.0009785595603271984,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020200280100868234,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0020200280100868234,
        "precision": 0.0019872464630777795,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009791631990679094,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0009791631990679094,
        "precision": 0.0009778645833333334,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001378412356321839,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.001378412356321839,
        "precision": 0.0012263479949421966,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001984452640170403,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.001984452640170403,
        "precision": 0.0019688806935659183,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.7986490885416666,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7986490885416666,
        "precision": 0.7803966703869047,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8724283854166667,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8724283854166667,
        "precision": 0.8589680989583334,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.4814453125,
        "f1": 0.42145041373556996,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.42145041373556996,
        "precision": 0.40051225900835274,
        "recall": 0.4814453125
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.8700846354166667,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8700846354166667,
        "precision": 0.8575846354166667,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.8678245907738095,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8678245907738095,
        "precision": 0.854736328125,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7724144345238095,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7724144345238095,
        "precision": 0.754638671875,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.7918805803571429,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7918805803571429,
        "precision": 0.7726236979166666,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9002278645833334,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9002278645833334,
        "precision": 0.8889973958333333,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.7992187499999999,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7992187499999999,
        "precision": 0.78193359375,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.6771042596726191,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6771042596726191,
        "precision": 0.6553749689980158,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.8981770833333333,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8981770833333333,
        "precision": 0.8876139322916667,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6504743303571429,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6504743303571429,
        "precision": 0.6249674479166667,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8632998511904761,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8632998511904761,
        "precision": 0.849365234375,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0015862319487089708,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0015862319487089708,
        "precision": 0.0009323981909260797,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.91015625,
        "f1": 0.8845703125,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8845703125,
        "precision": 0.87275390625,
        "recall": 0.91015625
      },
      {
        "accuracy": 0.673828125,
        "f1": 0.6155994233630953,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6155994233630953,
        "precision": 0.5923270089285714,
        "recall": 0.673828125
      },
      {
        "accuracy": 0.7666015625,
        "f1": 0.7172874813988095,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7172874813988095,
        "precision": 0.6968591467126624,
        "recall": 0.7666015625
      },
      {
        "accuracy": 0.880859375,
        "f1": 0.8478515625,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.8478515625,
        "precision": 0.8329915364583333,
        "recall": 0.880859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00013335346215780997,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00013335346215780997,
        "precision": 7.13295650921659e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.7861328125,
        "f1": 0.7363141741071428,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7363141741071428,
        "precision": 0.71591796875,
        "recall": 0.7861328125
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.7647972470238096,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7647972470238096,
        "precision": 0.7474934895833334,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8882161458333333,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8882161458333333,
        "precision": 0.8763834635416667,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8907877604166667,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.8907877604166667,
        "precision": 0.8790690104166666,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9454752604166666,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.9454752604166666,
        "precision": 0.9388020833333333,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.349609375,
        "f1": 0.2859407726376785,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.2859407726376785,
        "precision": 0.26458943138578694,
        "recall": 0.349609375
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8782087053571429,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.8782087053571429,
        "precision": 0.8660481770833334,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9650065104166667,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9650065104166667,
        "precision": 0.9607747395833334,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.798828125,
        "f1": 0.7518740699404762,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.7518740699404762,
        "precision": 0.7324381510416667,
        "recall": 0.798828125
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.87080078125,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.87080078125,
        "precision": 0.8584798177083333,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.96669921875,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.96669921875,
        "precision": 0.9629720052083333,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.935546875,
        "f1": 0.9163085937500001,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.9163085937500001,
        "precision": 0.9075520833333333,
        "recall": 0.935546875
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.5809485057043651,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5809485057043651,
        "precision": 0.5560473245287698,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.923828125,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.923828125,
        "precision": 0.9148763020833333,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.8671875,
        "f1": 0.83349609375,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.83349609375,
        "precision": 0.818994140625,
        "recall": 0.8671875
      },
      {
        "accuracy": 0.955078125,
        "f1": 0.9411458333333333,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.9411458333333333,
        "precision": 0.9344889322916666,
        "recall": 0.955078125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.002498238393297707,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.002498238393297707,
        "precision": 0.0018761076184884973,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.96142578125,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.96142578125,
        "precision": 0.9568684895833334,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.73828125,
        "f1": 0.6821529327876984,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.6821529327876984,
        "precision": 0.6600434802827381,
        "recall": 0.73828125
      },
      {
        "accuracy": 0.8125,
        "f1": 0.7683756510416666,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.7683756510416666,
        "precision": 0.7489188058035714,
        "recall": 0.8125
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9287109375,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.9287109375,
        "precision": 0.92109375,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.7924757281553396e-06,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 3.7924757281553396e-06,
        "precision": 1.8999270428015564e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.79296875,
        "f1": 0.7414574032738095,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.7414574032738095,
        "precision": 0.7197102864583333,
        "recall": 0.79296875
      },
      {
        "accuracy": 0.9033203125,
        "f1": 0.875390625,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.875390625,
        "precision": 0.862744140625,
        "recall": 0.9033203125
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.96435546875,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.96435546875,
        "precision": 0.96044921875,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8653645833333333,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8653645833333333,
        "precision": 0.8519205729166666,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.9404296875,
        "f1": 0.9220703125,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9220703125,
        "precision": 0.9134928385416667,
        "recall": 0.9404296875
      },
      {
        "accuracy": 0.4140625,
        "f1": 0.3481674935690331,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.3481674935690331,
        "precision": 0.3265940216196564,
        "recall": 0.4140625
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8662109375,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.8662109375,
        "precision": 0.853759765625,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9146484375,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9146484375,
        "precision": 0.9064127604166667,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.8115234375,
        "f1": 0.7679850260416667,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.7679850260416667,
        "precision": 0.7496023995535714,
        "recall": 0.8115234375
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8821614583333333,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8821614583333333,
        "precision": 0.8704752604166667,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9338216145833333,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9338216145833333,
        "precision": 0.9266764322916666,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9443359375,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.9443359375,
        "precision": 0.9376627604166667,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.681640625,
        "f1": 0.6220106336805555,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.6220106336805555,
        "precision": 0.5991157036323052,
        "recall": 0.681640625
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9041992187500001,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.9041992187500001,
        "precision": 0.893994140625,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.865234375,
        "f1": 0.8325869605654762,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8325869605654762,
        "precision": 0.8179292224702381,
        "recall": 0.865234375
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.9008975074404761,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.9008975074404761,
        "precision": 0.890869140625,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002539295629349454,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.002539295629349454,
        "precision": 0.001942963483185651,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9282877604166666,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.9282877604166666,
        "precision": 0.9208170572916666,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.744340587797619,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.744340587797619,
        "precision": 0.7249457465277778,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.814453125,
        "f1": 0.7717633928571428,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.7717633928571428,
        "precision": 0.7531087239583333,
        "recall": 0.814453125
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.9173828125000001,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.9173828125000001,
        "precision": 0.908447265625,
        "recall": 0.9365234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001102725452477739,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.001102725452477739,
        "precision": 0.0006951463250291375,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.7890625,
        "f1": 0.7443219866071429,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.7443219866071429,
        "precision": 0.726416015625,
        "recall": 0.7890625
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.874107142857143,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.874107142857143,
        "precision": 0.8623697916666667,
        "recall": 0.900390625
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9109049479166667,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.9109049479166667,
        "precision": 0.9013671875,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9591471354166666,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9591471354166666,
        "precision": 0.95458984375,
        "recall": 0.96875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.37197977261453824,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.37197977261453824,
        "precision": 0.3468513609871032,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.951171875,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.951171875,
        "precision": 0.9454752604166667,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.85205078125,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.85205078125,
        "precision": 0.8374837239583333,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9651692708333333,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9651692708333333,
        "precision": 0.9611002604166666,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9654947916666666,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.9654947916666666,
        "precision": 0.9615885416666667,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8634765625,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.8634765625,
        "precision": 0.8492024739583334,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8649739583333333,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8649739583333333,
        "precision": 0.851708984375,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9821614583333333,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9821614583333333,
        "precision": 0.980224609375,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0012808874115769495,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0012808874115769495,
        "precision": 0.0007827652219742063,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.8173828125,
        "f1": 0.7715680803571427,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.7715680803571427,
        "precision": 0.7517740885416666,
        "recall": 0.8173828125
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.90576171875,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.90576171875,
        "precision": 0.8967122395833333,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9793294270833333,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.9793294270833333,
        "precision": 0.9768880208333334,
        "recall": 0.984375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.6718536251709986e-06,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 2.6718536251709986e-06,
        "precision": 1.3377568493150685e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.88154296875,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.88154296875,
        "precision": 0.8712076822916666,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9549153645833333,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.9549153645833333,
        "precision": 0.9495442708333334,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9264973958333333,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.9264973958333333,
        "precision": 0.9178873697916666,
        "recall": 0.9443359375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}