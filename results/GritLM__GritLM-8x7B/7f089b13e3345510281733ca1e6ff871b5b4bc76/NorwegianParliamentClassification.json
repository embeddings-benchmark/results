{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.56175,
        "f1": 0.559746,
        "f1_weighted": 0.559746,
        "ap": 0.535604,
        "ap_weighted": 0.535604,
        "scores_per_experiment": [
          {
            "accuracy": 0.566667,
            "f1": 0.563757,
            "f1_weighted": 0.563757,
            "ap": 0.538645,
            "ap_weighted": 0.538645
          },
          {
            "accuracy": 0.530833,
            "f1": 0.526331,
            "f1_weighted": 0.526331,
            "ap": 0.516212,
            "ap_weighted": 0.516212
          },
          {
            "accuracy": 0.599167,
            "f1": 0.595451,
            "f1_weighted": 0.595451,
            "ap": 0.557836,
            "ap_weighted": 0.557836
          },
          {
            "accuracy": 0.560833,
            "f1": 0.560809,
            "f1_weighted": 0.560809,
            "ap": 0.534174,
            "ap_weighted": 0.534174
          },
          {
            "accuracy": 0.59,
            "f1": 0.59,
            "f1_weighted": 0.59,
            "ap": 0.5531,
            "ap_weighted": 0.5531
          },
          {
            "accuracy": 0.520833,
            "f1": 0.51853,
            "f1_weighted": 0.51853,
            "ap": 0.510798,
            "ap_weighted": 0.510798
          },
          {
            "accuracy": 0.545833,
            "f1": 0.543755,
            "f1_weighted": 0.543755,
            "ap": 0.525345,
            "ap_weighted": 0.525345
          },
          {
            "accuracy": 0.5475,
            "f1": 0.547069,
            "f1_weighted": 0.547069,
            "ap": 0.525875,
            "ap_weighted": 0.525875
          },
          {
            "accuracy": 0.621667,
            "f1": 0.621615,
            "f1_weighted": 0.621615,
            "ap": 0.57599,
            "ap_weighted": 0.57599
          },
          {
            "accuracy": 0.534167,
            "f1": 0.530146,
            "f1_weighted": 0.530146,
            "ap": 0.518068,
            "ap_weighted": 0.518068
          }
        ],
        "main_score": 0.56175,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.555667,
        "f1": 0.553447,
        "f1_weighted": 0.553447,
        "ap": 0.533347,
        "ap_weighted": 0.533347,
        "scores_per_experiment": [
          {
            "accuracy": 0.55,
            "f1": 0.543969,
            "f1_weighted": 0.543969,
            "ap": 0.528247,
            "ap_weighted": 0.528247
          },
          {
            "accuracy": 0.475833,
            "f1": 0.472934,
            "f1_weighted": 0.472934,
            "ap": 0.488425,
            "ap_weighted": 0.488425
          },
          {
            "accuracy": 0.609167,
            "f1": 0.607794,
            "f1_weighted": 0.607794,
            "ap": 0.56524,
            "ap_weighted": 0.56524
          },
          {
            "accuracy": 0.5725,
            "f1": 0.572414,
            "f1_weighted": 0.572414,
            "ap": 0.54166,
            "ap_weighted": 0.54166
          },
          {
            "accuracy": 0.5975,
            "f1": 0.597074,
            "f1_weighted": 0.597074,
            "ap": 0.558917,
            "ap_weighted": 0.558917
          },
          {
            "accuracy": 0.485833,
            "f1": 0.481556,
            "f1_weighted": 0.481556,
            "ap": 0.493087,
            "ap_weighted": 0.493087
          },
          {
            "accuracy": 0.564167,
            "f1": 0.562072,
            "f1_weighted": 0.562072,
            "ap": 0.536862,
            "ap_weighted": 0.536862
          },
          {
            "accuracy": 0.536667,
            "f1": 0.536337,
            "f1_weighted": 0.536337,
            "ap": 0.51961,
            "ap_weighted": 0.51961
          },
          {
            "accuracy": 0.631667,
            "f1": 0.631543,
            "f1_weighted": 0.631543,
            "ap": 0.583829,
            "ap_weighted": 0.583829
          },
          {
            "accuracy": 0.533333,
            "f1": 0.528777,
            "f1_weighted": 0.528777,
            "ap": 0.517595,
            "ap_weighted": 0.517595
          }
        ],
        "main_score": 0.555667,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 409.8761205673218,
  "kg_co2_emissions": 0.016197759811654104
}