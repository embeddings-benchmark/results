{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 8650.986232757568,
  "kg_co2_emissions": 2.055034785321741,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.9973649538866931,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9973649538866931,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9654150197628458,
        "f1": 0.9544466403162055,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9544466403162055,
        "precision": 0.9491930171277998,
        "recall": 0.9654150197628458
      },
      {
        "accuracy": 0.9426877470355731,
        "f1": 0.9247364953886692,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9247364953886692,
        "precision": 0.9163372859025033,
        "recall": 0.9426877470355731
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9703557312252964,
        "f1": 0.9606389986824769,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9606389986824769,
        "precision": 0.9558629776021079,
        "recall": 0.9703557312252964
      },
      {
        "accuracy": 0.9486166007905138,
        "f1": 0.932806324110672,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.932806324110672,
        "precision": 0.9255599472990776,
        "recall": 0.9486166007905138
      },
      {
        "accuracy": 0.8745059288537549,
        "f1": 0.840867526193613,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.840867526193613,
        "precision": 0.826269292301901,
        "recall": 0.8745059288537549
      },
      {
        "accuracy": 0.8804347826086957,
        "f1": 0.846772068511199,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.846772068511199,
        "precision": 0.8322463768115942,
        "recall": 0.8804347826086957
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733859,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9947299077733859,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9792490118577075,
        "f1": 0.9723320158102767,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9723320158102767,
        "precision": 0.9688735177865613,
        "recall": 0.9792490118577075
      },
      {
        "accuracy": 0.9733201581027668,
        "f1": 0.9645915678524374,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9645915678524374,
        "precision": 0.9603096179183135,
        "recall": 0.9733201581027668
      },
      {
        "accuracy": 0.9565217391304348,
        "f1": 0.9425230566534915,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9425230566534915,
        "precision": 0.9357707509881423,
        "recall": 0.9565217391304348
      },
      {
        "accuracy": 0.9278656126482213,
        "f1": 0.9062911725955204,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9062911725955204,
        "precision": 0.8966073781291172,
        "recall": 0.9278656126482213
      },
      {
        "accuracy": 0.9051383399209486,
        "f1": 0.8761198945981554,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8761198945981554,
        "precision": 0.8626482213438735,
        "recall": 0.9051383399209486
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.9973649538866931,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9973649538866931,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9868247694334652,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9868247694334652,
        "precision": 0.9851778656126482,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9318181818181818,
        "f1": 0.9128458498023715,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9128458498023715,
        "precision": 0.9045125164690382,
        "recall": 0.9318181818181818
      },
      {
        "accuracy": 0.9100790513833992,
        "f1": 0.8843073593073594,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8843073593073594,
        "precision": 0.8725296442687747,
        "recall": 0.9100790513833992
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034257,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9907773386034257,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9752964426877471,
        "f1": 0.9670619235836627,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9670619235836627,
        "precision": 0.9629446640316206,
        "recall": 0.9752964426877471
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9924242424242423,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9924242424242423,
        "precision": 0.991600790513834,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9861660079051383,
        "f1": 0.9822134387351779,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9822134387351779,
        "precision": 0.9802371541501976,
        "recall": 0.9861660079051383
      },
      {
        "accuracy": 0.7223320158102767,
        "f1": 0.6644375360037414,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.6644375360037414,
        "precision": 0.6434649287910158,
        "recall": 0.7223320158102767
      },
      {
        "accuracy": 0.7055335968379447,
        "f1": 0.6381635382623525,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6381635382623525,
        "precision": 0.6118577075098814,
        "recall": 0.7055335968379447
      },
      {
        "accuracy": 0.9179841897233202,
        "f1": 0.8950812472551603,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.8950812472551603,
        "precision": 0.8850049407114624,
        "recall": 0.9179841897233202
      },
      {
        "accuracy": 0.8735177865612648,
        "f1": 0.8369565217391305,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8369565217391305,
        "precision": 0.8205698287220027,
        "recall": 0.8735177865612648
      },
      {
        "accuracy": 0.8359683794466403,
        "f1": 0.7958498023715415,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7958498023715415,
        "precision": 0.7788118337525453,
        "recall": 0.8359683794466403
      },
      {
        "accuracy": 0.7885375494071146,
        "f1": 0.7335874270656879,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.7335874270656879,
        "precision": 0.7105401844532279,
        "recall": 0.7885375494071146
      },
      {
        "accuracy": 0.9861660079051383,
        "f1": 0.9817193675889329,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9817193675889329,
        "precision": 0.979578392621871,
        "recall": 0.9861660079051383
      },
      {
        "accuracy": 0.9654150197628458,
        "f1": 0.9543807641633728,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9543807641633728,
        "precision": 0.9489459815546771,
        "recall": 0.9654150197628458
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.988965744400527,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.988965744400527,
        "precision": 0.987977602108037,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9851778656126482,
        "f1": 0.9815546772068511,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9815546772068511,
        "precision": 0.9799077733860342,
        "recall": 0.9851778656126482
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433466,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433466,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.9894598155467721,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9894598155467721,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.4980237154150198,
        "f1": 0.41777344306988573,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.41777344306988573,
        "precision": 0.39249075835174235,
        "recall": 0.4980237154150198
      },
      {
        "accuracy": 0.508893280632411,
        "f1": 0.4206168831168831,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.4206168831168831,
        "precision": 0.38925673305614017,
        "recall": 0.508893280632411
      },
      {
        "accuracy": 0.32806324110671936,
        "f1": 0.2774598960195333,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2774598960195333,
        "precision": 0.2633958629386379,
        "recall": 0.32806324110671936
      },
      {
        "accuracy": 0.32608695652173914,
        "f1": 0.2551244374860976,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.2551244374860976,
        "precision": 0.23285544229480154,
        "recall": 0.32608695652173914
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9920948616600791,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9920948616600791,
        "precision": 0.991106719367589,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9100790513833992,
        "f1": 0.8853425559947298,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8853425559947298,
        "precision": 0.8742094861660079,
        "recall": 0.9100790513833992
      },
      {
        "accuracy": 0.8675889328063241,
        "f1": 0.8302371541501976,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8302371541501976,
        "precision": 0.8134881422924901,
        "recall": 0.8675889328063241
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9802371541501976,
        "f1": 0.9739789196310935,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9739789196310935,
        "precision": 0.9710144927536233,
        "recall": 0.9802371541501976
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9841897233201581,
        "f1": 0.9789196310935442,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9789196310935442,
        "precision": 0.9762845849802372,
        "recall": 0.9841897233201581
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.9828722002635046,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9828722002635046,
        "precision": 0.9807312252964426,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 0.4189723320158103,
        "f1": 0.363610293762278,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.363610293762278,
        "precision": 0.34615606313975883,
        "recall": 0.4189723320158103
      },
      {
        "accuracy": 0.4041501976284585,
        "f1": 0.3282798339122449,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.3282798339122449,
        "precision": 0.3034425951480125,
        "recall": 0.4041501976284585
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9841897233201581,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9841897233201581,
        "precision": 0.9822134387351779,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.983201581027668,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.983201581027668,
        "precision": 0.9812252964426877,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.010213077894570865,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.010213077894570865,
        "precision": 0.009882561337680552,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.008916732782969521,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.008916732782969521,
        "precision": 0.006457348727232576,
        "recall": 0.024703557312252964
      }
    ],
    "validation": [
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9618856569709128,
        "f1": 0.9496823804747576,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9496823804747576,
        "precision": 0.9438314944834504,
        "recall": 0.9618856569709128
      },
      {
        "accuracy": 0.9428284854563691,
        "f1": 0.9244399866265463,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9244399866265463,
        "precision": 0.9155800735539954,
        "recall": 0.9428284854563691
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9618856569709128,
        "f1": 0.9493480441323972,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9493480441323972,
        "precision": 0.9431628217987296,
        "recall": 0.9618856569709128
      },
      {
        "accuracy": 0.9458375125376128,
        "f1": 0.9286191909060515,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9286191909060515,
        "precision": 0.9204279505182215,
        "recall": 0.9458375125376128
      },
      {
        "accuracy": 0.8655967903711134,
        "f1": 0.8298450908280397,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.8298450908280397,
        "precision": 0.8148528920093614,
        "recall": 0.8655967903711134
      },
      {
        "accuracy": 0.8605817452357071,
        "f1": 0.8221330658642595,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8221330658642595,
        "precision": 0.8053660982948847,
        "recall": 0.8605817452357071
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9866265463055833,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9866265463055833,
        "precision": 0.9849548645937813,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.9719157472417251,
        "f1": 0.9631227014376463,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9631227014376463,
        "precision": 0.958960213975259,
        "recall": 0.9719157472417251
      },
      {
        "accuracy": 0.9809428284854563,
        "f1": 0.9745904379806085,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9745904379806085,
        "precision": 0.9714142427281846,
        "recall": 0.9809428284854563
      },
      {
        "accuracy": 0.966900702106319,
        "f1": 0.9563691073219659,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9563691073219659,
        "precision": 0.9513540621865597,
        "recall": 0.966900702106319
      },
      {
        "accuracy": 0.9227683049147443,
        "f1": 0.9002006018054163,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9002006018054163,
        "precision": 0.8899030424607155,
        "recall": 0.9227683049147443
      },
      {
        "accuracy": 0.9007021063189569,
        "f1": 0.8711802072885322,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8711802072885322,
        "precision": 0.857321965897693,
        "recall": 0.9007021063189569
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9348044132397192,
        "f1": 0.9154797726512872,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9154797726512872,
        "precision": 0.9066365763958543,
        "recall": 0.9348044132397192
      },
      {
        "accuracy": 0.9107321965897693,
        "f1": 0.8842861919090605,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8842861919090605,
        "precision": 0.8723169508525577,
        "recall": 0.9107321965897693
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444667,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9893012370444667,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9789368104312939,
        "f1": 0.9722500835840855,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9722500835840855,
        "precision": 0.9690738883316617,
        "recall": 0.9789368104312939
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9899699097291875,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9899699097291875,
        "precision": 0.9889669007021064,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9829488465396189,
        "f1": 0.9775994650618522,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9775994650618522,
        "precision": 0.9749247743229689,
        "recall": 0.9829488465396189
      },
      {
        "accuracy": 0.757271815446339,
        "f1": 0.7105828733122379,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.7105828733122379,
        "precision": 0.6932282959991084,
        "recall": 0.757271815446339
      },
      {
        "accuracy": 0.7542627883650953,
        "f1": 0.6984222508796231,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6984222508796231,
        "precision": 0.6756798172294661,
        "recall": 0.7542627883650953
      },
      {
        "accuracy": 0.9297893681043129,
        "f1": 0.9089602139752591,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9089602139752591,
        "precision": 0.8996489468405217,
        "recall": 0.9297893681043129
      },
      {
        "accuracy": 0.9037111334002006,
        "f1": 0.8737545971247075,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8737545971247075,
        "precision": 0.8597459043798061,
        "recall": 0.9037111334002006
      },
      {
        "accuracy": 0.8345035105315948,
        "f1": 0.7952739169890625,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7952739169890625,
        "precision": 0.779141392431262,
        "recall": 0.8345035105315948
      },
      {
        "accuracy": 0.7883650952858575,
        "f1": 0.7322491283373932,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.7322491283373932,
        "precision": 0.7076563022400535,
        "recall": 0.7883650952858575
      },
      {
        "accuracy": 0.9839518555667001,
        "f1": 0.9789368104312939,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9789368104312939,
        "precision": 0.9765964560347711,
        "recall": 0.9839518555667001
      },
      {
        "accuracy": 0.9568706118355065,
        "f1": 0.9440655299231027,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9440655299231027,
        "precision": 0.937897024406553,
        "recall": 0.9568706118355065
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9913072550986292,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9913072550986292,
        "precision": 0.9904714142427282,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9869608826479438,
        "f1": 0.9837846873955198,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9837846873955198,
        "precision": 0.982280173854898,
        "recall": 0.9869608826479438
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.9841190237378804,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9841190237378804,
        "precision": 0.9822801738548981,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 0.5075225677031093,
        "f1": 0.43270160028197296,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.43270160028197296,
        "precision": 0.40762695358541723,
        "recall": 0.5075225677031093
      },
      {
        "accuracy": 0.4974924774322969,
        "f1": 0.42019901877954297,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.42019901877954297,
        "precision": 0.39345247141134804,
        "recall": 0.4974924774322969
      },
      {
        "accuracy": 0.324974924774323,
        "f1": 0.27344645389041733,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.27344645389041733,
        "precision": 0.25782474704240005,
        "recall": 0.324974924774323
      },
      {
        "accuracy": 0.34804413239719156,
        "f1": 0.2687506965340466,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.2687506965340466,
        "precision": 0.24244168291309715,
        "recall": 0.34804413239719156
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9819458375125376,
        "f1": 0.9759277833500501,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9759277833500501,
        "precision": 0.9729187562688064,
        "recall": 0.9819458375125376
      },
      {
        "accuracy": 0.8756268806419257,
        "f1": 0.8423986244447628,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8423986244447628,
        "precision": 0.8276830491474424,
        "recall": 0.8756268806419257
      },
      {
        "accuracy": 0.8405215646940822,
        "f1": 0.7960213975259111,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.7960213975259111,
        "precision": 0.7760949515212303,
        "recall": 0.8405215646940822
      },
      {
        "accuracy": 0.9869608826479438,
        "f1": 0.9829488465396189,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9829488465396189,
        "precision": 0.9809428284854563,
        "recall": 0.9869608826479438
      },
      {
        "accuracy": 0.970912738214644,
        "f1": 0.9617184887997325,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9617184887997325,
        "precision": 0.9572049481778668,
        "recall": 0.970912738214644
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444667,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9893012370444667,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9658976930792377,
        "f1": 0.954864593781344,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.954864593781344,
        "precision": 0.9495152123035775,
        "recall": 0.9658976930792377
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9936476094951521,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9936476094951521,
        "precision": 0.9929789368104313,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9866265463055834,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9866265463055834,
        "precision": 0.9849548645937813,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.43329989969909727,
        "f1": 0.3740744678257216,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.3740744678257216,
        "precision": 0.3547642928786359,
        "recall": 0.43329989969909727
      },
      {
        "accuracy": 0.4202607823470411,
        "f1": 0.3439738369052628,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.3439738369052628,
        "precision": 0.31739026603620385,
        "recall": 0.4202607823470411
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9749247743229689,
        "f1": 0.9670678702774991,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9670678702774991,
        "precision": 0.9632230023403543,
        "recall": 0.9749247743229689
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9849548645937813,
        "f1": 0.9799398194583752,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9799398194583752,
        "precision": 0.977432296890672,
        "recall": 0.9849548645937813
      },
      {
        "accuracy": 0.007021063189568706,
        "f1": 0.005384574776962466,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.005384574776962466,
        "precision": 0.0050329560108898115,
        "recall": 0.007021063189568706
      },
      {
        "accuracy": 0.014042126379137413,
        "f1": 0.0030010021183541746,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0030010021183541746,
        "precision": 0.0017692449155569164,
        "recall": 0.014042126379137413
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}