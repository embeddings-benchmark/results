{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 96.76278448104858,
  "kg_co2_emissions": 0.02189854198274485,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.56494140625,
        "f1": 0.5622358006373366,
        "f1_weighted": 0.563868764929376,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.5622358006373366,
        "scores_per_experiment": [
          {
            "accuracy": 0.5693359375,
            "f1": 0.5583474256652579,
            "f1_weighted": 0.5730204523105238
          },
          {
            "accuracy": 0.60693359375,
            "f1": 0.5932217909972709,
            "f1_weighted": 0.61370590887202
          },
          {
            "accuracy": 0.5556640625,
            "f1": 0.5631968039307303,
            "f1_weighted": 0.5566204070763177
          },
          {
            "accuracy": 0.49072265625,
            "f1": 0.48673741230371453,
            "f1_weighted": 0.49670424984316364
          },
          {
            "accuracy": 0.587890625,
            "f1": 0.5788683446157669,
            "f1_weighted": 0.5870072367826571
          },
          {
            "accuracy": 0.4833984375,
            "f1": 0.4781957631452183,
            "f1_weighted": 0.4742769676048849
          },
          {
            "accuracy": 0.5439453125,
            "f1": 0.5385165579481592,
            "f1_weighted": 0.5265601131226442
          },
          {
            "accuracy": 0.60009765625,
            "f1": 0.6092857406119684,
            "f1_weighted": 0.599387040845898
          },
          {
            "accuracy": 0.60009765625,
            "f1": 0.5931001146276543,
            "f1_weighted": 0.6028557351317975
          },
          {
            "accuracy": 0.611328125,
            "f1": 0.6228880525276246,
            "f1_weighted": 0.608549537703854
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}