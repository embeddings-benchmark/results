{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 46.73146390914917,
  "kg_co2_emissions": 0.009752160795779004,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5125,
        "f1": 0.4109746247442644,
        "f1_weighted": 0.5613440219797055,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5125,
        "scores_per_experiment": [
          {
            "accuracy": 0.5288461538461539,
            "f1": 0.4104556200300881,
            "f1_weighted": 0.5811254938914513
          },
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.48591691995947317,
            "f1_weighted": 0.6413334892058297
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.39759863433056447,
            "f1_weighted": 0.5233218720587232
          },
          {
            "accuracy": 0.5673076923076923,
            "f1": 0.47377985462097616,
            "f1_weighted": 0.6505012381180606
          },
          {
            "accuracy": 0.5288461538461539,
            "f1": 0.39840475081509086,
            "f1_weighted": 0.600068073519401
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.39953870699223093,
            "f1_weighted": 0.5271317570932582
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.4001530612244898,
            "f1_weighted": 0.5271134222919938
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.37214486858573215,
            "f1_weighted": 0.5622517931067681
          },
          {
            "accuracy": 0.46153846153846156,
            "f1": 0.3754630565097326,
            "f1_weighted": 0.49864515493935574
          },
          {
            "accuracy": 0.46153846153846156,
            "f1": 0.39629077437426585,
            "f1_weighted": 0.501947925572214
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5285714285714286,
        "f1": 0.4021648124282069,
        "f1_weighted": 0.5869446696976943,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5285714285714286,
        "scores_per_experiment": [
          {
            "accuracy": 0.6095238095238096,
            "f1": 0.4426189776733255,
            "f1_weighted": 0.6516795366795367
          },
          {
            "accuracy": 0.5333333333333333,
            "f1": 0.4221014492753623,
            "f1_weighted": 0.6130434782608697
          },
          {
            "accuracy": 0.47619047619047616,
            "f1": 0.39236741519350216,
            "f1_weighted": 0.5496148158259959
          },
          {
            "accuracy": 0.5523809523809524,
            "f1": 0.4323308270676691,
            "f1_weighted": 0.6297171500179018
          },
          {
            "accuracy": 0.5523809523809524,
            "f1": 0.41379731379731377,
            "f1_weighted": 0.6174917146345719
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.37082799015700274,
            "f1_weighted": 0.5200304334120575
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.4016702456369585,
            "f1_weighted": 0.5503268503862916
          },
          {
            "accuracy": 0.5714285714285714,
            "f1": 0.39391530568001154,
            "f1_weighted": 0.6150764974294387
          },
          {
            "accuracy": 0.5333333333333333,
            "f1": 0.3842319212665811,
            "f1_weighted": 0.5795977749251177
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.3677866785343421,
            "f1_weighted": 0.542868445405161
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}