{
  "dataset_revision": "8ccc72e69e65f40c70e117d8b3c08306bb788b60",
  "task_name": "MasakhaNEWSClusteringS2S",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "v_measure": 0.43164,
        "v_measure_std": 0.464265,
        "v_measures": [
          1.0,
          0.041488,
          0.077632,
          0.039079,
          1.0
        ],
        "main_score": 0.43164,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ]
      },
      {
        "v_measure": 0.519129,
        "v_measure_std": 0.19851,
        "v_measures": [
          0.200102,
          0.581268,
          0.729993,
          0.3907,
          0.693584
        ],
        "main_score": 0.519129,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "v_measure": 0.459567,
        "v_measure_std": 0.288806,
        "v_measures": [
          1.0,
          0.133993,
          0.342112,
          0.425668,
          0.39606
        ],
        "main_score": 0.459567,
        "hf_subset": "fra",
        "languages": [
          "fra-Latn"
        ]
      },
      {
        "v_measure": 0.170884,
        "v_measure_std": 0.138729,
        "v_measures": [
          0.017462,
          0.03184,
          0.217078,
          0.191798,
          0.39624
        ],
        "main_score": 0.170884,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ]
      },
      {
        "v_measure": 0.412042,
        "v_measure_std": 0.335173,
        "v_measures": [
          0.18662,
          0.470545,
          0.010294,
          1.0,
          0.392749
        ],
        "main_score": 0.412042,
        "hf_subset": "ibo",
        "languages": [
          "ibo-Latn"
        ]
      },
      {
        "v_measure": 0.637383,
        "v_measure_std": 0.318638,
        "v_measures": [
          0.586624,
          0.214604,
          1.0,
          1.0,
          0.385687
        ],
        "main_score": 0.637383,
        "hf_subset": "lin",
        "languages": [
          "lin-Latn"
        ]
      },
      {
        "v_measure": 0.505707,
        "v_measure_std": 0.433443,
        "v_measures": [
          0.043098,
          0.02093,
          1.0,
          1.0,
          0.464509
        ],
        "main_score": 0.505707,
        "hf_subset": "lug",
        "languages": [
          "lug-Latn"
        ]
      },
      {
        "v_measure": 0.24806,
        "v_measure_std": 0.381493,
        "v_measures": [
          0.184751,
          0.012538,
          1.0,
          0.029868,
          0.013143
        ],
        "main_score": 0.24806,
        "hf_subset": "orm",
        "languages": [
          "orm-Ethi"
        ]
      },
      {
        "v_measure": 0.813191,
        "v_measure_std": 0.23799,
        "v_measures": [
          0.357624,
          1.0,
          0.88953,
          0.818802,
          1.0
        ],
        "main_score": 0.813191,
        "hf_subset": "pcm",
        "languages": [
          "pcm-Latn"
        ]
      },
      {
        "v_measure": 0.545588,
        "v_measure_std": 0.378191,
        "v_measures": [
          0.201096,
          0.153304,
          1.0,
          0.373538,
          1.0
        ],
        "main_score": 0.545588,
        "hf_subset": "run",
        "languages": [
          "run-Latn"
        ]
      },
      {
        "v_measure": 0.529303,
        "v_measure_std": 0.395932,
        "v_measures": [
          1.0,
          0.324487,
          0.278224,
          0.043803,
          1.0
        ],
        "main_score": 0.529303,
        "hf_subset": "sna",
        "languages": [
          "sna-Latn"
        ]
      },
      {
        "v_measure": 0.295221,
        "v_measure_std": 0.358767,
        "v_measures": [
          0.10962,
          1.0,
          0.039905,
          0.08452,
          0.242058
        ],
        "main_score": 0.295221,
        "hf_subset": "som",
        "languages": [
          "som-Latn"
        ]
      },
      {
        "v_measure": 0.224652,
        "v_measure_std": 0.228498,
        "v_measures": [
          0.035945,
          0.0682,
          0.011945,
          0.511252,
          0.495917
        ],
        "main_score": 0.224652,
        "hf_subset": "swa",
        "languages": [
          "swa-Latn"
        ]
      },
      {
        "v_measure": 0.460483,
        "v_measure_std": 0.440938,
        "v_measures": [
          0.135449,
          1.0,
          0.077692,
          1.0,
          0.089273
        ],
        "main_score": 0.460483,
        "hf_subset": "tir",
        "languages": [
          "tir-Ethi"
        ]
      },
      {
        "v_measure": 0.225757,
        "v_measure_std": 0.387705,
        "v_measures": [
          0.027607,
          0.069502,
          0.028379,
          0.003299,
          1.0
        ],
        "main_score": 0.225757,
        "hf_subset": "xho",
        "languages": [
          "xho-Latn"
        ]
      },
      {
        "v_measure": 0.328275,
        "v_measure_std": 0.354413,
        "v_measures": [
          1.0,
          0.124324,
          0.081981,
          0.059348,
          0.375723
        ],
        "main_score": 0.328275,
        "hf_subset": "yor",
        "languages": [
          "yor-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 9.114931344985962,
  "kg_co2_emissions": 0.00027084616250201303
}