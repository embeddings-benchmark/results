{
  "dataset_revision": "cec3923e16519efe51d535497e711932b8f1dc44",
  "task_name": "PunjabiNewsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.688535,
        "f1": 0.620714,
        "f1_weighted": 0.725298,
        "ap": 0.299905,
        "ap_weighted": 0.299905,
        "scores_per_experiment": [
          {
            "accuracy": 0.751592,
            "f1": 0.675568,
            "f1_weighted": 0.780602,
            "ap": 0.340239,
            "ap_weighted": 0.340239
          },
          {
            "accuracy": 0.630573,
            "f1": 0.574486,
            "f1_weighted": 0.677805,
            "ap": 0.261057,
            "ap_weighted": 0.261057
          },
          {
            "accuracy": 0.713376,
            "f1": 0.64226,
            "f1_weighted": 0.748934,
            "ap": 0.309905,
            "ap_weighted": 0.309905
          },
          {
            "accuracy": 0.681529,
            "f1": 0.566011,
            "f1_weighted": 0.715756,
            "ap": 0.212803,
            "ap_weighted": 0.212803
          },
          {
            "accuracy": 0.732484,
            "f1": 0.663709,
            "f1_weighted": 0.765419,
            "ap": 0.335734,
            "ap_weighted": 0.335734
          },
          {
            "accuracy": 0.738854,
            "f1": 0.664267,
            "f1_weighted": 0.770099,
            "ap": 0.329418,
            "ap_weighted": 0.329418
          },
          {
            "accuracy": 0.675159,
            "f1": 0.619602,
            "f1_weighted": 0.716827,
            "ap": 0.305674,
            "ap_weighted": 0.305674
          },
          {
            "accuracy": 0.834395,
            "f1": 0.750611,
            "f1_weighted": 0.847285,
            "ap": 0.422832,
            "ap_weighted": 0.422832
          },
          {
            "accuracy": 0.579618,
            "f1": 0.53425,
            "f1_weighted": 0.631466,
            "ap": 0.238695,
            "ap_weighted": 0.238695
          },
          {
            "accuracy": 0.547771,
            "f1": 0.516378,
            "f1_weighted": 0.598784,
            "ap": 0.242692,
            "ap_weighted": 0.242692
          }
        ],
        "main_score": 0.688535,
        "hf_subset": "default",
        "languages": [
          "pan-Guru"
        ]
      }
    ]
  },
  "evaluation_time": 7.2234039306640625,
  "kg_co2_emissions": 0.00021772784041247371
}