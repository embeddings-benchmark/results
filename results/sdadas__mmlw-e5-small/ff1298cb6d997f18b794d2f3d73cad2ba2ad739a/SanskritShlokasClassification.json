{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.767624,
        "f1": 0.764958,
        "f1_weighted": 0.763103,
        "scores_per_experiment": [
          {
            "accuracy": 0.765013,
            "f1": 0.766064,
            "f1_weighted": 0.765458
          },
          {
            "accuracy": 0.733681,
            "f1": 0.722006,
            "f1_weighted": 0.716687
          },
          {
            "accuracy": 0.736292,
            "f1": 0.735814,
            "f1_weighted": 0.73375
          },
          {
            "accuracy": 0.736292,
            "f1": 0.722225,
            "f1_weighted": 0.716485
          },
          {
            "accuracy": 0.806789,
            "f1": 0.807619,
            "f1_weighted": 0.807374
          },
          {
            "accuracy": 0.798956,
            "f1": 0.799838,
            "f1_weighted": 0.799518
          },
          {
            "accuracy": 0.780679,
            "f1": 0.779907,
            "f1_weighted": 0.780679
          },
          {
            "accuracy": 0.801567,
            "f1": 0.80242,
            "f1_weighted": 0.801663
          },
          {
            "accuracy": 0.75718,
            "f1": 0.759113,
            "f1_weighted": 0.758594
          },
          {
            "accuracy": 0.759791,
            "f1": 0.754575,
            "f1_weighted": 0.750823
          }
        ],
        "main_score": 0.767624,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.738542,
        "f1": 0.747596,
        "f1_weighted": 0.735332,
        "scores_per_experiment": [
          {
            "accuracy": 0.729167,
            "f1": 0.739845,
            "f1_weighted": 0.730987
          },
          {
            "accuracy": 0.697917,
            "f1": 0.704868,
            "f1_weighted": 0.683463
          },
          {
            "accuracy": 0.708333,
            "f1": 0.721331,
            "f1_weighted": 0.707553
          },
          {
            "accuracy": 0.697917,
            "f1": 0.707269,
            "f1_weighted": 0.68754
          },
          {
            "accuracy": 0.8125,
            "f1": 0.815934,
            "f1_weighted": 0.8125
          },
          {
            "accuracy": 0.708333,
            "f1": 0.719833,
            "f1_weighted": 0.710293
          },
          {
            "accuracy": 0.822917,
            "f1": 0.826992,
            "f1_weighted": 0.82332
          },
          {
            "accuracy": 0.760417,
            "f1": 0.77094,
            "f1_weighted": 0.759028
          },
          {
            "accuracy": 0.71875,
            "f1": 0.732404,
            "f1_weighted": 0.720532
          },
          {
            "accuracy": 0.729167,
            "f1": 0.73654,
            "f1_weighted": 0.718107
          }
        ],
        "main_score": 0.738542,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 12.709683656692505,
  "kg_co2_emissions": 0.0003543515002302828
}