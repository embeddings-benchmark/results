{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.792072,
        "f1": 0.791279,
        "f1_weighted": 0.791279,
        "ap": 0.731494,
        "ap_weighted": 0.731494,
        "scores_per_experiment": [
          {
            "accuracy": 0.79888,
            "f1": 0.79606,
            "f1_weighted": 0.79606,
            "ap": 0.766241,
            "ap_weighted": 0.766241
          },
          {
            "accuracy": 0.798,
            "f1": 0.796943,
            "f1_weighted": 0.796943,
            "ap": 0.752782,
            "ap_weighted": 0.752782
          },
          {
            "accuracy": 0.78696,
            "f1": 0.784745,
            "f1_weighted": 0.784745,
            "ap": 0.711937,
            "ap_weighted": 0.711937
          },
          {
            "accuracy": 0.8258,
            "f1": 0.825479,
            "f1_weighted": 0.825479,
            "ap": 0.760654,
            "ap_weighted": 0.760654
          },
          {
            "accuracy": 0.80968,
            "f1": 0.809279,
            "f1_weighted": 0.809279,
            "ap": 0.742688,
            "ap_weighted": 0.742688
          },
          {
            "accuracy": 0.79848,
            "f1": 0.798323,
            "f1_weighted": 0.798323,
            "ap": 0.733619,
            "ap_weighted": 0.733619
          },
          {
            "accuracy": 0.7704,
            "f1": 0.77025,
            "f1_weighted": 0.77025,
            "ap": 0.704766,
            "ap_weighted": 0.704766
          },
          {
            "accuracy": 0.79708,
            "f1": 0.796719,
            "f1_weighted": 0.796719,
            "ap": 0.729939,
            "ap_weighted": 0.729939
          },
          {
            "accuracy": 0.74568,
            "f1": 0.745359,
            "f1_weighted": 0.745359,
            "ap": 0.679195,
            "ap_weighted": 0.679195
          },
          {
            "accuracy": 0.78976,
            "f1": 0.789636,
            "f1_weighted": 0.789636,
            "ap": 0.733119,
            "ap_weighted": 0.733119
          }
        ],
        "main_score": 0.792072,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 28.3696711063385,
  "kg_co2_emissions": 0.001617464656687674
}