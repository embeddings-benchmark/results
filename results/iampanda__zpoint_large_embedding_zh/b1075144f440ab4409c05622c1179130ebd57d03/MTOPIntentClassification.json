{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "task_name": "MTOPIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.466061,
        "f1": 0.288459,
        "f1_weighted": 0.518388,
        "scores_per_experiment": [
          {
            "accuracy": 0.475482,
            "f1": 0.288825,
            "f1_weighted": 0.528098
          },
          {
            "accuracy": 0.439118,
            "f1": 0.277146,
            "f1_weighted": 0.486808
          },
          {
            "accuracy": 0.494215,
            "f1": 0.292459,
            "f1_weighted": 0.547821
          },
          {
            "accuracy": 0.475482,
            "f1": 0.29856,
            "f1_weighted": 0.529248
          },
          {
            "accuracy": 0.472176,
            "f1": 0.287344,
            "f1_weighted": 0.528558
          },
          {
            "accuracy": 0.431956,
            "f1": 0.277292,
            "f1_weighted": 0.482147
          },
          {
            "accuracy": 0.461157,
            "f1": 0.279467,
            "f1_weighted": 0.514096
          },
          {
            "accuracy": 0.473829,
            "f1": 0.297313,
            "f1_weighted": 0.532633
          },
          {
            "accuracy": 0.455647,
            "f1": 0.293417,
            "f1_weighted": 0.506134
          },
          {
            "accuracy": 0.481543,
            "f1": 0.29277,
            "f1_weighted": 0.528336
          }
        ],
        "main_score": 0.466061,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.475261,
        "f1": 0.315899,
        "f1_weighted": 0.527443,
        "scores_per_experiment": [
          {
            "accuracy": 0.484644,
            "f1": 0.312077,
            "f1_weighted": 0.538667
          },
          {
            "accuracy": 0.448014,
            "f1": 0.309498,
            "f1_weighted": 0.498194
          },
          {
            "accuracy": 0.497605,
            "f1": 0.316427,
            "f1_weighted": 0.549642
          },
          {
            "accuracy": 0.475063,
            "f1": 0.329366,
            "f1_weighted": 0.528082
          },
          {
            "accuracy": 0.49197,
            "f1": 0.337003,
            "f1_weighted": 0.543798
          },
          {
            "accuracy": 0.451113,
            "f1": 0.299751,
            "f1_weighted": 0.499744
          },
          {
            "accuracy": 0.484362,
            "f1": 0.312566,
            "f1_weighted": 0.535705
          },
          {
            "accuracy": 0.487179,
            "f1": 0.320691,
            "f1_weighted": 0.548354
          },
          {
            "accuracy": 0.453367,
            "f1": 0.313464,
            "f1_weighted": 0.506749
          },
          {
            "accuracy": 0.47929,
            "f1": 0.308151,
            "f1_weighted": 0.525494
          }
        ],
        "main_score": 0.475261,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 148.06395030021667,
  "kg_co2_emissions": null
}