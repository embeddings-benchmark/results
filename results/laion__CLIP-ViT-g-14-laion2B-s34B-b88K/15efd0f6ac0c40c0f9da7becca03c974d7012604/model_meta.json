{"name": "laion/CLIP-ViT-g-14-laion2B-s34B-b88K", "revision": "15efd0f6ac0c40c0f9da7becca03c974d7012604", "release_date": "2023-03-06", "languages": ["eng_Latn"], "n_parameters": 1367000000, "memory_usage_mb": 5215.0, "max_tokens": 77.0, "embed_dim": 1024, "license": "mit", "open_weights": true, "public_training_code": "https://github.com/mlfoundations/open_clip", "public_training_data": "https://laion.ai/blog/laion-5b/", "framework": ["PyTorch"], "reference": "https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s34B-b88K", "similarity_fn_name": null, "use_instructions": false, "training_datasets": {}, "adapted_from": null, "superseded_by": null, "is_cross_encoder": null, "modalities": ["image", "text"], "loader": "openclip_loader"}