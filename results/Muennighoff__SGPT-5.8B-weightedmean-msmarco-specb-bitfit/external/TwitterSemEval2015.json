{
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
    "task_name": "TwitterSemEval2015",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "cos_sim_accuracy": 0.8409131549144662,
                "cos_sim_ap": 0.6686677647503386,
                "cos_sim_f1": 0.6294631710362049,
                "cos_sim_precision": 0.5973933649289099,
                "cos_sim_recall": 0.6651715039577837,
                "dot_accuracy": 0.8027656911247542,
                "dot_ap": 0.5429172039861209,
                "dot_f1": 0.5477150537634409,
                "dot_precision": 0.4758660957571039,
                "dot_recall": 0.645118733509235,
                "euclidean_accuracy": 0.8276211480002386,
                "euclidean_ap": 0.6243039769075329,
                "euclidean_f1": 0.5919159053935678,
                "euclidean_precision": 0.5629611997143538,
                "euclidean_recall": 0.6240105540897097,
                "manhattan_accuracy": 0.827561542588067,
                "manhattan_ap": 0.6241882051995578,
                "manhattan_f1": 0.5932101002778785,
                "manhattan_precision": 0.5471361711611321,
                "manhattan_recall": 0.6477572559366754,
                "max_accuracy": 0.8409131549144662,
                "max_ap": 0.6686677647503386,
                "max_f1": 0.6294631710362049,
                "main_score": 0.6686677647503386
            }
        ]
    }
}