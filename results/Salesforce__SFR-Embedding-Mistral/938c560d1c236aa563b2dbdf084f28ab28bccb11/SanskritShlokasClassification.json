{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.58564,
        "f1": 0.584714,
        "f1_weighted": 0.585426,
        "scores_per_experiment": [
          {
            "accuracy": 0.584856,
            "f1": 0.589761,
            "f1_weighted": 0.59253
          },
          {
            "accuracy": 0.577023,
            "f1": 0.58375,
            "f1_weighted": 0.583493
          },
          {
            "accuracy": 0.584856,
            "f1": 0.589793,
            "f1_weighted": 0.588187
          },
          {
            "accuracy": 0.587467,
            "f1": 0.577404,
            "f1_weighted": 0.575809
          },
          {
            "accuracy": 0.678851,
            "f1": 0.670462,
            "f1_weighted": 0.673122
          },
          {
            "accuracy": 0.665796,
            "f1": 0.663148,
            "f1_weighted": 0.661421
          },
          {
            "accuracy": 0.516971,
            "f1": 0.518413,
            "f1_weighted": 0.519474
          },
          {
            "accuracy": 0.587467,
            "f1": 0.574577,
            "f1_weighted": 0.57762
          },
          {
            "accuracy": 0.561358,
            "f1": 0.560229,
            "f1_weighted": 0.560878
          },
          {
            "accuracy": 0.511749,
            "f1": 0.519603,
            "f1_weighted": 0.521727
          }
        ],
        "main_score": 0.58564,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.578125,
        "f1": 0.576234,
        "f1_weighted": 0.574499,
        "scores_per_experiment": [
          {
            "accuracy": 0.59375,
            "f1": 0.59956,
            "f1_weighted": 0.594883
          },
          {
            "accuracy": 0.614583,
            "f1": 0.616667,
            "f1_weighted": 0.614063
          },
          {
            "accuracy": 0.572917,
            "f1": 0.580618,
            "f1_weighted": 0.574041
          },
          {
            "accuracy": 0.697917,
            "f1": 0.693678,
            "f1_weighted": 0.680737
          },
          {
            "accuracy": 0.6875,
            "f1": 0.679067,
            "f1_weighted": 0.682593
          },
          {
            "accuracy": 0.645833,
            "f1": 0.642307,
            "f1_weighted": 0.630966
          },
          {
            "accuracy": 0.479167,
            "f1": 0.47623,
            "f1_weighted": 0.480765
          },
          {
            "accuracy": 0.520833,
            "f1": 0.496774,
            "f1_weighted": 0.506422
          },
          {
            "accuracy": 0.520833,
            "f1": 0.516219,
            "f1_weighted": 0.518673
          },
          {
            "accuracy": 0.447917,
            "f1": 0.46122,
            "f1_weighted": 0.461846
          }
        ],
        "main_score": 0.578125,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 40.325408935546875,
  "kg_co2_emissions": 0.008703182074120637
}