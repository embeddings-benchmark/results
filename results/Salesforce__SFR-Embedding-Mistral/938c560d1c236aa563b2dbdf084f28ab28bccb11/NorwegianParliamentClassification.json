{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.624,
        "f1": 0.614224,
        "f1_weighted": 0.614224,
        "ap": 0.58257,
        "ap_weighted": 0.58257,
        "scores_per_experiment": [
          {
            "accuracy": 0.605833,
            "f1": 0.601919,
            "f1_weighted": 0.601919,
            "ap": 0.566888,
            "ap_weighted": 0.566888
          },
          {
            "accuracy": 0.635833,
            "f1": 0.614387,
            "f1_weighted": 0.614387,
            "ap": 0.580454,
            "ap_weighted": 0.580454
          },
          {
            "accuracy": 0.6475,
            "f1": 0.631372,
            "f1_weighted": 0.631372,
            "ap": 0.611153,
            "ap_weighted": 0.611153
          },
          {
            "accuracy": 0.660833,
            "f1": 0.660831,
            "f1_weighted": 0.660831,
            "ap": 0.606155,
            "ap_weighted": 0.606155
          },
          {
            "accuracy": 0.691667,
            "f1": 0.691447,
            "f1_weighted": 0.691447,
            "ap": 0.634639,
            "ap_weighted": 0.634639
          },
          {
            "accuracy": 0.609167,
            "f1": 0.569321,
            "f1_weighted": 0.569321,
            "ap": 0.561993,
            "ap_weighted": 0.561993
          },
          {
            "accuracy": 0.525,
            "f1": 0.524995,
            "f1_weighted": 0.524995,
            "ap": 0.513121,
            "ap_weighted": 0.513121
          },
          {
            "accuracy": 0.5225,
            "f1": 0.520092,
            "f1_weighted": 0.520092,
            "ap": 0.511693,
            "ap_weighted": 0.511693
          },
          {
            "accuracy": 0.651667,
            "f1": 0.644533,
            "f1_weighted": 0.644533,
            "ap": 0.593758,
            "ap_weighted": 0.593758
          },
          {
            "accuracy": 0.69,
            "f1": 0.683342,
            "f1_weighted": 0.683342,
            "ap": 0.645845,
            "ap_weighted": 0.645845
          }
        ],
        "main_score": 0.624,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.612417,
        "f1": 0.59985,
        "f1_weighted": 0.59985,
        "ap": 0.575186,
        "ap_weighted": 0.575186,
        "scores_per_experiment": [
          {
            "accuracy": 0.578333,
            "f1": 0.572847,
            "f1_weighted": 0.572847,
            "ap": 0.547101,
            "ap_weighted": 0.547101
          },
          {
            "accuracy": 0.619167,
            "f1": 0.590597,
            "f1_weighted": 0.590597,
            "ap": 0.568875,
            "ap_weighted": 0.568875
          },
          {
            "accuracy": 0.639167,
            "f1": 0.618547,
            "f1_weighted": 0.618547,
            "ap": 0.605784,
            "ap_weighted": 0.605784
          },
          {
            "accuracy": 0.658333,
            "f1": 0.657953,
            "f1_weighted": 0.657953,
            "ap": 0.606027,
            "ap_weighted": 0.606027
          },
          {
            "accuracy": 0.690833,
            "f1": 0.690032,
            "f1_weighted": 0.690032,
            "ap": 0.635955,
            "ap_weighted": 0.635955
          },
          {
            "accuracy": 0.599167,
            "f1": 0.549903,
            "f1_weighted": 0.549903,
            "ap": 0.555502,
            "ap_weighted": 0.555502
          },
          {
            "accuracy": 0.521667,
            "f1": 0.521655,
            "f1_weighted": 0.521655,
            "ap": 0.511298,
            "ap_weighted": 0.511298
          },
          {
            "accuracy": 0.505833,
            "f1": 0.504288,
            "f1_weighted": 0.504288,
            "ap": 0.502947,
            "ap_weighted": 0.502947
          },
          {
            "accuracy": 0.633333,
            "f1": 0.624505,
            "f1_weighted": 0.624505,
            "ap": 0.580272,
            "ap_weighted": 0.580272
          },
          {
            "accuracy": 0.678333,
            "f1": 0.668171,
            "f1_weighted": 0.668171,
            "ap": 0.638094,
            "ap_weighted": 0.638094
          }
        ],
        "main_score": 0.612417,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 51.23070693016052,
  "kg_co2_emissions": 0.013935913465576603
}