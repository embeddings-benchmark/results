{
    "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.0980833893745797,
                "f1": 0.05937294768946698,
                "f1_weighted": 0.09081886869095238,
                "main_score": 0.0980833893745797
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.29919300605245464,
                "f1": 0.2861836188311232,
                "f1_weighted": 0.291331315419033,
                "main_score": 0.29919300605245464
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.4070611970410221,
                "f1": 0.36497414259722916,
                "f1_weighted": 0.408434621304316,
                "main_score": 0.4070611970410221
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.3486550100874243,
                "f1": 0.32511543017798344,
                "f1_weighted": 0.3537578537376275,
                "main_score": 0.3486550100874243
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.06540013449899126,
                "f1": 0.030183236967386794,
                "f1_weighted": 0.032437729486032005,
                "main_score": 0.06540013449899126
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.0637188971082717,
                "f1": 0.012161861106269458,
                "f1_weighted": 0.015561424935372978,
                "main_score": 0.0637188971082717
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.4438466711499663,
                "f1": 0.41839812797864767,
                "f1_weighted": 0.4427402984078753,
                "main_score": 0.4438466711499663
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.44788164088769344,
                "f1": 0.4186661326594422,
                "f1_weighted": 0.45560760425112407,
                "main_score": 0.44788164088769344
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.4155010087424344,
                "f1": 0.398637787919614,
                "f1_weighted": 0.4139157838134575,
                "main_score": 0.4155010087424344
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.07545393409549428,
                "f1": 0.04610499945114051,
                "f1_weighted": 0.0409922516617004,
                "main_score": 0.07545393409549428
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.4595158036314729,
                "f1": 0.42920579574042295,
                "f1_weighted": 0.4540140115830182,
                "main_score": 0.4595158036314729
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.44182918628110296,
                "f1": 0.4208296634278963,
                "f1_weighted": 0.43694534675475954,
                "main_score": 0.44182918628110296
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.10363147276395428,
                "f1": 0.03544838851039083,
                "f1_weighted": 0.04140024210528424,
                "main_score": 0.10363147276395428
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.0707464694014795,
                "f1": 0.04895747857203135,
                "f1_weighted": 0.04468990336651401,
                "main_score": 0.0707464694014795
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.42626092804303967,
                "f1": 0.39047362807965946,
                "f1_weighted": 0.42878863568910913,
                "main_score": 0.42626092804303967
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.03658372562205784,
                "f1": 0.005307594854274683,
                "f1_weighted": 0.00401264797645835,
                "main_score": 0.03658372562205784
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.042199058507061196,
                "f1": 0.006358533846714538,
                "f1_weighted": 0.007671477999724781,
                "main_score": 0.042199058507061196
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6864156018829859,
                "f1": 0.6751582950719383,
                "f1_weighted": 0.6850250620549031,
                "main_score": 0.6864156018829859
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.4128110289172831,
                "f1": 0.39510410678338054,
                "f1_weighted": 0.41021401243892863,
                "main_score": 0.4128110289172831
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.07636180228648286,
                "f1": 0.01671901427752137,
                "f1_weighted": 0.02630765935222266,
                "main_score": 0.07636180228648286
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.4576664425016812,
                "f1": 0.4234937453494014,
                "f1_weighted": 0.46235114257370513,
                "main_score": 0.4576664425016812
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.08439811701412239,
                "f1": 0.05041029827403152,
                "f1_weighted": 0.051478461620134794,
                "main_score": 0.08439811701412239
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.04694014794889037,
                "f1": 0.010566737135988625,
                "f1_weighted": 0.008980830102429626,
                "main_score": 0.04694014794889037
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.0722932078009415,
                "f1": 0.033528426017241646,
                "f1_weighted": 0.030009651233373826,
                "main_score": 0.0722932078009415
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.4859448554135844,
                "f1": 0.4593986390603561,
                "f1_weighted": 0.48814603772235704,
                "main_score": 0.4859448554135844
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.4310356422326833,
                "f1": 0.41100200169618534,
                "f1_weighted": 0.43412858014089617,
                "main_score": 0.4310356422326833
            },
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.4649293880295897,
                "f1": 0.43315706047343705,
                "f1_weighted": 0.46727978296884914,
                "main_score": 0.4649293880295897
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.09640215198386012,
                "f1": 0.059135378557279926,
                "f1_weighted": 0.07806751356906266,
                "main_score": 0.09640215198386012
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.3958641560188299,
                "f1": 0.36592451915818036,
                "f1_weighted": 0.39761736425592,
                "main_score": 0.3958641560188299
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.08860121049092133,
                "f1": 0.04718864746190939,
                "f1_weighted": 0.053163686100636244,
                "main_score": 0.08860121049092133
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.048924008069939476,
                "f1": 0.00916583483259345,
                "f1_weighted": 0.012544597904953058,
                "main_score": 0.048924008069939476
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.42888365837256226,
                "f1": 0.3986648771173936,
                "f1_weighted": 0.43115071124075594,
                "main_score": 0.42888365837256226
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.4024209818426361,
                "f1": 0.3747206040233386,
                "f1_weighted": 0.40901742973729166,
                "main_score": 0.4024209818426361
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.41882985877605916,
                "f1": 0.399671764356801,
                "f1_weighted": 0.41665819720648384,
                "main_score": 0.41882985877605916
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.07279757901815737,
                "f1": 0.0235312820369449,
                "f1_weighted": 0.02920332667294555,
                "main_score": 0.07279757901815737
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.364256893073302,
                "f1": 0.3447682967775262,
                "f1_weighted": 0.3630047330686327,
                "main_score": 0.364256893073302
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.4221923335574983,
                "f1": 0.3866130727259434,
                "f1_weighted": 0.42908386755942357,
                "main_score": 0.4221923335574983
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.3717215870880969,
                "f1": 0.36619973729174904,
                "f1_weighted": 0.37518134329785824,
                "main_score": 0.3717215870880969
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.06735036987222595,
                "f1": 0.032835957391008794,
                "f1_weighted": 0.0324144282213889,
                "main_score": 0.06735036987222595
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.04636852723604572,
                "f1": 0.015039726307543586,
                "f1_weighted": 0.018951629507178363,
                "main_score": 0.04636852723604572
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.07639542703429725,
                "f1": 0.03160687482851778,
                "f1_weighted": 0.030175908677497632,
                "main_score": 0.07639542703429725
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.46772024209818425,
                "f1": 0.45434290596398236,
                "f1_weighted": 0.46198187422534187,
                "main_score": 0.46772024209818425
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3902824478816409,
                "f1": 0.379732630347416,
                "f1_weighted": 0.388398108567262,
                "main_score": 0.3902824478816409
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.45635507733691993,
                "f1": 0.44245842472711444,
                "f1_weighted": 0.4556008903462169,
                "main_score": 0.45635507733691993
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.0390719569603228,
                "f1": 0.00721609151557302,
                "f1_weighted": 0.0096665799983422,
                "main_score": 0.0390719569603228
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.39969737726967053,
                "f1": 0.40660548785260503,
                "f1_weighted": 0.39587820835177095,
                "main_score": 0.39969737726967053
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.07720242098184266,
                "f1": 0.031181298559928034,
                "f1_weighted": 0.026041818295423985,
                "main_score": 0.07720242098184266
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.1659717552118359,
                "f1": 0.134695046374781,
                "f1_weighted": 0.15359866047765247,
                "main_score": 0.1659717552118359
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.35376597175521185,
                "f1": 0.33455087796949523,
                "f1_weighted": 0.3514224104129548,
                "main_score": 0.35376597175521185
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.4327841291190316,
                "f1": 0.4151990670116458,
                "f1_weighted": 0.43310601940271953,
                "main_score": 0.4327841291190316
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.08043039677202421,
                "f1": 0.029211272271217618,
                "f1_weighted": 0.03246376657700989,
                "main_score": 0.08043039677202421
            }
        ]
    }
}