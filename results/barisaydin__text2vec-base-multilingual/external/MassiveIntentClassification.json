{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.4542030934767989,
                "f1": 0.44122015435663764,
                "main_score": 0.4542030934767989
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.3767652992602556,
                "f1": 0.3542209190084316,
                "main_score": 0.3767652992602556
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.45023537323470075,
                "f1": 0.41852484084738195,
                "main_score": 0.45023537323470075
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.4870880968392737,
                "f1": 0.4690436061543505,
                "main_score": 0.4870880968392737
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.4378950907868191,
                "f1": 0.4158872353920405,
                "main_score": 0.4378950907868191
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.2875924680564896,
                "f1": 0.2741182001374226,
                "main_score": 0.2875924680564896
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.5674176193678547,
                "f1": 0.5382727354182497,
                "main_score": 0.5674176193678547
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.5155682582380632,
                "f1": 0.4941963627941866,
                "main_score": 0.5155682582380632
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.5646940147948891,
                "f1": 0.5528178711367465,
                "main_score": 0.5646940147948891
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6383322125084063,
                "f1": 0.6183617290084555,
                "main_score": 0.6383322125084063
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.5827505043712172,
                "f1": 0.5764243637436115,
                "main_score": 0.5827505043712172
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.5905178211163417,
                "f1": 0.5685899882050406,
                "main_score": 0.5905178211163417
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.5735709482178883,
                "f1": 0.5479711189260453,
                "main_score": 0.5735709482178883
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.5879959650302623,
                "f1": 0.5759158671719513,
                "main_score": 0.5879959650302623
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.511768661735037,
                "f1": 0.48886397276270516,
                "main_score": 0.511768661735037
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.5706455951580363,
                "f1": 0.5501530952684585,
                "main_score": 0.5706455951580363
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.583591123066577,
                "f1": 0.559277783370191,
                "main_score": 0.583591123066577
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.5210827168796234,
                "f1": 0.511950234006646,
                "main_score": 0.5210827168796234
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.5826832548755884,
                "f1": 0.5660774065423401,
                "main_score": 0.5826832548755884
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.35806993947545396,
                "f1": 0.34290418953173296,
                "main_score": 0.35806993947545396
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.5827841291190315,
                "f1": 0.569438998642419,
                "main_score": 0.5827841291190315
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.6078009414929388,
                "f1": 0.5915780842483667,
                "main_score": 0.6078009414929388
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.31153328850033624,
                "f1": 0.3011004596099605,
                "main_score": 0.31153328850033624
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.4450235373234701,
                "f1": 0.44040585262624743,
                "main_score": 0.4450235373234701
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.4099193006052455,
                "f1": 0.39505480119272485,
                "main_score": 0.4099193006052455
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.46956960322797575,
                "f1": 0.4309363894078533,
                "main_score": 0.46956960322797575
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.5473100201748486,
                "f1": 0.5279750744404114,
                "main_score": 0.5473100201748486
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.5486550100874243,
                "f1": 0.5364798408964839,
                "main_score": 0.5486550100874243
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.4789172831203766,
                "f1": 0.45261229414636056,
                "main_score": 0.4789172831203766
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.522259583053127,
                "f1": 0.505903419246987,
                "main_score": 0.522259583053127
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.5427706792199058,
                "f1": 0.5247204247996589,
                "main_score": 0.5427706792199058
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.5195696032279757,
                "f1": 0.4979330411854258,
                "main_score": 0.5195696032279757
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.5463685272360457,
                "f1": 0.5281267480650003,
                "main_score": 0.5463685272360457
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.5945191661062542,
                "f1": 0.5734790386645091,
                "main_score": 0.5945191661062542
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.5891055817081372,
                "f1": 0.5639195048528157,
                "main_score": 0.5891055817081372
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.5984196368527236,
                "f1": 0.5872244763127064,
                "main_score": 0.5984196368527236
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.5704102219233355,
                "f1": 0.5567040186148946,
                "main_score": 0.5704102219233355
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.5801613987895091,
                "f1": 0.5720394982548486,
                "main_score": 0.5801613987895091
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.5635843981170141,
                "f1": 0.5418656338999773,
                "main_score": 0.5635843981170141
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.5647948890383322,
                "f1": 0.5477222455713096,
                "main_score": 0.5647948890383322
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.5843981170141224,
                "f1": 0.5609260971364242,
                "main_score": 0.5843981170141224
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.339609952925353,
                "f1": 0.3318853392353405,
                "main_score": 0.339609952925353
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.4429388029589778,
                "f1": 0.41519865332844735,
                "main_score": 0.4429388029589778
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.4713517148621385,
                "f1": 0.4394784138379624,
                "main_score": 0.4713517148621385
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.5685608607935441,
                "f1": 0.5661817738474846,
                "main_score": 0.5685608607935441
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.35359784801613986,
                "f1": 0.34060680080365047,
                "main_score": 0.35359784801613986
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.596301277740417,
                "f1": 0.5746288652988266,
                "main_score": 0.596301277740417
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.527908540685945,
                "f1": 0.5146934239116157,
                "main_score": 0.527908540685945
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.546469401479489,
                "f1": 0.539903066185816,
                "main_score": 0.546469401479489
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.6085743106926698,
                "f1": 0.5931579548450755,
                "main_score": 0.6085743106926698
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.5746805648957632,
                "f1": 0.5748469733657326,
                "main_score": 0.5746805648957632
            }
        ]
    }
}