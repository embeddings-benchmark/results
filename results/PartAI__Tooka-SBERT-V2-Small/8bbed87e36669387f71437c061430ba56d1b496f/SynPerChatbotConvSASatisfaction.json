{
  "dataset_revision": "50fd9d5d09edd53af89af765636be5db6f983f0e",
  "task_name": "SynPerChatbotConvSASatisfaction",
  "mteb_version": "1.38.27",
  "scores": {
    "test": [
      {
        "accuracy": 0.741026,
        "f1": 0.728631,
        "f1_weighted": 0.744286,
        "ap": 0.779505,
        "ap_weighted": 0.779505,
        "scores_per_experiment": [
          {
            "accuracy": 0.734266,
            "f1": 0.719948,
            "f1_weighted": 0.737218,
            "ap": 0.770577,
            "ap_weighted": 0.770577
          },
          {
            "accuracy": 0.792541,
            "f1": 0.779052,
            "f1_weighted": 0.793941,
            "ap": 0.811808,
            "ap_weighted": 0.811808
          },
          {
            "accuracy": 0.74359,
            "f1": 0.732592,
            "f1_weighted": 0.747382,
            "ap": 0.784358,
            "ap_weighted": 0.784358
          },
          {
            "accuracy": 0.755245,
            "f1": 0.743446,
            "f1_weighted": 0.758451,
            "ap": 0.790532,
            "ap_weighted": 0.790532
          },
          {
            "accuracy": 0.699301,
            "f1": 0.684136,
            "f1_weighted": 0.703011,
            "ap": 0.745786,
            "ap_weighted": 0.745786
          },
          {
            "accuracy": 0.685315,
            "f1": 0.678152,
            "f1_weighted": 0.691247,
            "ap": 0.752597,
            "ap_weighted": 0.752597
          },
          {
            "accuracy": 0.736597,
            "f1": 0.723313,
            "f1_weighted": 0.739847,
            "ap": 0.774259,
            "ap_weighted": 0.774259
          },
          {
            "accuracy": 0.762238,
            "f1": 0.749427,
            "f1_weighted": 0.764879,
            "ap": 0.792903,
            "ap_weighted": 0.792903
          },
          {
            "accuracy": 0.769231,
            "f1": 0.752991,
            "f1_weighted": 0.770264,
            "ap": 0.790045,
            "ap_weighted": 0.790045
          },
          {
            "accuracy": 0.731935,
            "f1": 0.723249,
            "f1_weighted": 0.73662,
            "ap": 0.782188,
            "ap_weighted": 0.782188
          }
        ],
        "main_score": 0.741026,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 30.117730140686035,
  "kg_co2_emissions": null
}