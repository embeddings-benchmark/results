{
  "dataset_revision": "b4d5a8dd501db610b5ad89e9aa13f863b842b395",
  "task_name": "SentimentDKSF",
  "mteb_version": "1.38.27",
  "scores": {
    "test": [
      {
        "accuracy": 0.673564,
        "f1": 0.585299,
        "f1_weighted": 0.701094,
        "scores_per_experiment": [
          {
            "accuracy": 0.676026,
            "f1": 0.580096,
            "f1_weighted": 0.706857
          },
          {
            "accuracy": 0.637581,
            "f1": 0.563566,
            "f1_weighted": 0.670081
          },
          {
            "accuracy": 0.647084,
            "f1": 0.566269,
            "f1_weighted": 0.6752
          },
          {
            "accuracy": 0.666523,
            "f1": 0.588043,
            "f1_weighted": 0.701153
          },
          {
            "accuracy": 0.712311,
            "f1": 0.613641,
            "f1_weighted": 0.733933
          },
          {
            "accuracy": 0.696328,
            "f1": 0.612264,
            "f1_weighted": 0.710457
          },
          {
            "accuracy": 0.67041,
            "f1": 0.576027,
            "f1_weighted": 0.695631
          },
          {
            "accuracy": 0.67905,
            "f1": 0.57336,
            "f1_weighted": 0.701762
          },
          {
            "accuracy": 0.665659,
            "f1": 0.581922,
            "f1_weighted": 0.697503
          },
          {
            "accuracy": 0.684665,
            "f1": 0.597804,
            "f1_weighted": 0.71836
          }
        ],
        "main_score": 0.673564,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 6.073564052581787,
  "kg_co2_emissions": null
}