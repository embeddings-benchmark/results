{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.432481506388702,
                "f1": 0.40924230769590786,
                "main_score": 0.432481506388702
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.2530262273032952,
                "f1": 0.24937105830264067,
                "main_score": 0.2530262273032952
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.3207128446536651,
                "f1": 0.3180245816594883,
                "main_score": 0.3207128446536651
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3668123739071957,
                "f1": 0.36372190425083384,
                "main_score": 0.3668123739071957
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.2956624075319435,
                "f1": 0.2838604205636276,
                "main_score": 0.2956624075319435
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.421049092131809,
                "f1": 0.38926150886991295,
                "main_score": 0.421049092131809
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.4544384667114997,
                "f1": 0.42578252395460003,
                "main_score": 0.4544384667114997
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.43211163416274373,
                "f1": 0.4104465858304789,
                "main_score": 0.43211163416274373
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.3650302622730329,
                "f1": 0.3449785095312759,
                "main_score": 0.3650302622730329
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6973772696704773,
                "f1": 0.6921759502909043,
                "main_score": 0.6973772696704773
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.44078681909885675,
                "f1": 0.4305914426901129,
                "main_score": 0.44078681909885675
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.32612642905178213,
                "f1": 0.3202463177462754,
                "main_score": 0.32612642905178213
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.40356422326832553,
                "f1": 0.3813642481807678,
                "main_score": 0.40356422326832553
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.4506724949562878,
                "f1": 0.43198276083437376,
                "main_score": 0.4506724949562878
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.32178883658372553,
                "f1": 0.29979761884698775,
                "main_score": 0.32178883658372553
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.26903160726294556,
                "f1": 0.25833010434083364,
                "main_score": 0.26903160726294556
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.4037995965030262,
                "f1": 0.3793134355292882,
                "main_score": 0.4037995965030262
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.28375924680564896,
                "f1": 0.2696255693013172,
                "main_score": 0.28375924680564896
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.44361129791526566,
                "f1": 0.4354445012295126,
                "main_score": 0.44361129791526566
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.39290517821116344,
                "f1": 0.3726982052174147,
                "main_score": 0.39290517821116344
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.46469401479488903,
                "f1": 0.44060986162841564,
                "main_score": 0.46469401479488903
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.46257565568258235,
                "f1": 0.4562513945675882,
                "main_score": 0.46257565568258235
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.4112642905178212,
                "f1": 0.3954392378396527,
                "main_score": 0.4112642905178212
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.24727639542703428,
                "f1": 0.23337743140804484,
                "main_score": 0.24727639542703428
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.2974108944182918,
                "f1": 0.2757087619008375,
                "main_score": 0.2974108944182918
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.23850033624747816,
                "f1": 0.2286733484540032,
                "main_score": 0.23850033624747816
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.3656691324815064,
                "f1": 0.35504081677134564,
                "main_score": 0.3656691324815064
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.4092804303967721,
                "f1": 0.3910858913121125,
                "main_score": 0.4092804303967721
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.25527908540685945,
                "f1": 0.25333391622280477,
                "main_score": 0.25527908540685945
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.29105581708137185,
                "f1": 0.28478235012692815,
                "main_score": 0.29105581708137185
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.4378614660390047,
                "f1": 0.41964014392626703,
                "main_score": 0.4378614660390047
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.27269670477471414,
                "f1": 0.26228386764141853,
                "main_score": 0.27269670477471414
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.3901815736381977,
                "f1": 0.37641949339321856,
                "main_score": 0.3901815736381977
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.4535978480161399,
                "f1": 0.426851176096831,
                "main_score": 0.4535978480161399
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.4189307330195023,
                "f1": 0.4088871064261502,
                "main_score": 0.4189307330195023
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.45901143241425685,
                "f1": 0.44496942353920543,
                "main_score": 0.45901143241425685
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.44115669132481505,
                "f1": 0.41953945105870616,
                "main_score": 0.44115669132481505
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.3276395427034297,
                "f1": 0.31436372571600935,
                "main_score": 0.3276395427034297
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.4050437121721588,
                "f1": 0.39322752749628165,
                "main_score": 0.4050437121721588
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.4251849361129792,
                "f1": 0.414139297118463,
                "main_score": 0.4251849361129792
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.42293207800941496,
                "f1": 0.4050409536806683,
                "main_score": 0.42293207800941496
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.429993275050437,
                "f1": 0.41045416224973263,
                "main_score": 0.429993275050437
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.2832548755884331,
                "f1": 0.2727684199556187,
                "main_score": 0.2832548755884331
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.26593813046402154,
                "f1": 0.25483878616197586,
                "main_score": 0.26593813046402154
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.36788836583725626,
                "f1": 0.34603932909177687,
                "main_score": 0.36788836583725626
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.425689307330195,
                "f1": 0.40924469309079825,
                "main_score": 0.425689307330195
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.37094821788836585,
                "f1": 0.3794962882285716,
                "main_score": 0.37094821788836585
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.2883658372562206,
                "f1": 0.2780655865551234,
                "main_score": 0.2883658372562206
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.37357094821788833,
                "f1": 0.37507918961038167,
                "main_score": 0.37357094821788833
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.4937794216543375,
                "f1": 0.4720421153697707,
                "main_score": 0.4937794216543375
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.4442165433759248,
                "f1": 0.44347418611989314,
                "main_score": 0.4442165433759248
            }
        ]
    }
}