{
    "dataset_revision": "072a486a144adf7f4479a4a0dddb2152e161e1ea",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.40548083389374573,
                "f1": 0.39490307545239717,
                "main_score": 0.40548083389374573
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.2418291862811029,
                "f1": 0.23437620034727474,
                "main_score": 0.2418291862811029
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.30134498991257563,
                "f1": 0.28787175191531283,
                "main_score": 0.30134498991257563
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.35884330867518494,
                "f1": 0.36264500398782124,
                "main_score": 0.35884330867518494
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.2917283120376597,
                "f1": 0.278101616531901,
                "main_score": 0.2917283120376597
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.41788836583725625,
                "f1": 0.3971413181054801,
                "main_score": 0.41788836583725625
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.44176193678547404,
                "f1": 0.4219249982655229,
                "main_score": 0.44176193678547404
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.42074646940147953,
                "f1": 0.39441882591831623,
                "main_score": 0.42074646940147953
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.36254203093476806,
                "f1": 0.3446592715936761,
                "main_score": 0.36254203093476806
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6140887693342301,
                "f1": 0.5979854802683996,
                "main_score": 0.6140887693342301
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.42679892400807,
                "f1": 0.4204801248338172,
                "main_score": 0.42679892400807
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.3559179556153329,
                "f1": 0.34045862930486165,
                "main_score": 0.3559179556153329
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.40036987222595827,
                "f1": 0.3811770343936278,
                "main_score": 0.40036987222595827
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.4343981170141224,
                "f1": 0.427084388987865,
                "main_score": 0.4343981170141224
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.3159381304640215,
                "f1": 0.2998550522450782,
                "main_score": 0.3159381304640215
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.27044384667114996,
                "f1": 0.27313059184832666,
                "main_score": 0.27044384667114996
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.38453261600537997,
                "f1": 0.37309189326110437,
                "main_score": 0.38453261600537997
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.2797915265635508,
                "f1": 0.27430939684346445,
                "main_score": 0.2797915265635508
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.4397108271687963,
                "f1": 0.43405857056887615,
                "main_score": 0.4397108271687963
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.40302622730329524,
                "f1": 0.3910805218052074,
                "main_score": 0.40302622730329524
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.45474108944182917,
                "f1": 0.4585950328241134,
                "main_score": 0.45474108944182917
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.4560860793544048,
                "f1": 0.4394920708216737,
                "main_score": 0.4560860793544048
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.386684599865501,
                "f1": 0.37699003401885905,
                "main_score": 0.386684599865501
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.25652320107599197,
                "f1": 0.25279084273189584,
                "main_score": 0.25652320107599197
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.28295225285810355,
                "f1": 0.2664582563877155,
                "main_score": 0.28295225285810355
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.23480161398789506,
                "f1": 0.22275241866506731,
                "main_score": 0.23480161398789506
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.3655682582380632,
                "f1": 0.360047531710636,
                "main_score": 0.3655682582380632
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.41849361129791535,
                "f1": 0.4138932672359119,
                "main_score": 0.41849361129791535
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.2490921318090114,
                "f1": 0.23968687483768808,
                "main_score": 0.2490921318090114
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.2986213853396099,
                "f1": 0.2997715207525541,
                "main_score": 0.2986213853396099
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.4242098184263618,
                "f1": 0.4150877432664628,
                "main_score": 0.4242098184263618
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.25131136516476127,
                "f1": 0.23938932214086775,
                "main_score": 0.25131136516476127
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.3981506388702084,
                "f1": 0.3880958658779166,
                "main_score": 0.3981506388702084
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.4362138533960995,
                "f1": 0.4201386842914633,
                "main_score": 0.4362138533960995
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.4219569603227976,
                "f1": 0.40005565598258275,
                "main_score": 0.4219569603227976
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.4520847343644923,
                "f1": 0.44241150050290506,
                "main_score": 0.4520847343644923
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.4180901143241426,
                "f1": 0.40474074848670083,
                "main_score": 0.4180901143241426
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.3596839273705447,
                "f1": 0.35095456843621003,
                "main_score": 0.3596839273705447
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.4060524546065905,
                "f1": 0.39302383051500134,
                "main_score": 0.4060524546065905
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.42757229320780094,
                "f1": 0.4153763931497389,
                "main_score": 0.42757229320780094
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.42347007397444514,
                "f1": 0.4104366017948627,
                "main_score": 0.42347007397444514
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.4112306657700067,
                "f1": 0.3971294047328902,
                "main_score": 0.4112306657700067
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.24603227975790185,
                "f1": 0.23969236788828607,
                "main_score": 0.24603227975790185
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.2503698722259583,
                "f1": 0.2437196123281459,
                "main_score": 0.2503698722259583
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.3540013449899126,
                "f1": 0.35063600413688034,
                "main_score": 0.3540013449899126
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.4119031607262945,
                "f1": 0.40240432304273016,
                "main_score": 0.4119031607262945
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.3640551445864155,
                "f1": 0.36038449928565586,
                "main_score": 0.3640551445864155
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.25934767989240076,
                "f1": 0.252074457023531,
                "main_score": 0.25934767989240076
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.38799596503026224,
                "f1": 0.37160233794673125,
                "main_score": 0.38799596503026224
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.46244115669132474,
                "f1": 0.44367480561291905,
                "main_score": 0.46244115669132474
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.4230665770006724,
                "f1": 0.41964222328351397,
                "main_score": 0.4230665770006724
            }
        ]
    }
}