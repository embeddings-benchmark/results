{
  "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
  "task_name": "NTREXBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.11052,
        "recall": 0.131698,
        "f1": 0.114704,
        "accuracy": 0.131698,
        "main_score": 0.114704,
        "hf_subset": "afr_Latn-dan_Latn",
        "languages": [
          "afr-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.049823,
        "recall": 0.0666,
        "f1": 0.052096,
        "accuracy": 0.0666,
        "main_score": 0.052096,
        "hf_subset": "afr_Latn-deu_Latn",
        "languages": [
          "afr-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.039494,
        "recall": 0.048072,
        "f1": 0.040855,
        "accuracy": 0.048072,
        "main_score": 0.040855,
        "hf_subset": "afr_Latn-eng_Latn",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032598,
        "recall": 0.042564,
        "f1": 0.034266,
        "accuracy": 0.042564,
        "main_score": 0.034266,
        "hf_subset": "afr_Latn-fao_Latn",
        "languages": [
          "afr-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.020997,
        "recall": 0.031047,
        "f1": 0.022797,
        "accuracy": 0.031047,
        "main_score": 0.022797,
        "hf_subset": "afr_Latn-isl_Latn",
        "languages": [
          "afr-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.086459,
        "recall": 0.103655,
        "f1": 0.090065,
        "accuracy": 0.103655,
        "main_score": 0.090065,
        "hf_subset": "afr_Latn-ltz_Latn",
        "languages": [
          "afr-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.355342,
        "recall": 0.418127,
        "f1": 0.370571,
        "accuracy": 0.418127,
        "main_score": 0.370571,
        "hf_subset": "afr_Latn-nld_Latn",
        "languages": [
          "afr-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.097172,
        "recall": 0.11968,
        "f1": 0.10162,
        "accuracy": 0.11968,
        "main_score": 0.10162,
        "hf_subset": "afr_Latn-nno_Latn",
        "languages": [
          "afr-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.116939,
        "recall": 0.13971,
        "f1": 0.121494,
        "accuracy": 0.13971,
        "main_score": 0.121494,
        "hf_subset": "afr_Latn-nob_Latn",
        "languages": [
          "afr-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.096784,
        "recall": 0.121182,
        "f1": 0.101545,
        "accuracy": 0.121182,
        "main_score": 0.101545,
        "hf_subset": "afr_Latn-swe_Latn",
        "languages": [
          "afr-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.005178,
        "recall": 0.00651,
        "f1": 0.005266,
        "accuracy": 0.00651,
        "main_score": 0.005266,
        "hf_subset": "amh_Ethi-eng_Latn",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006343,
        "recall": 0.007511,
        "f1": 0.00651,
        "accuracy": 0.007511,
        "main_score": 0.00651,
        "hf_subset": "amh_Ethi-hau_Latn",
        "languages": [
          "amh-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.005538,
        "recall": 0.007511,
        "f1": 0.005733,
        "accuracy": 0.007511,
        "main_score": 0.005733,
        "hf_subset": "amh_Ethi-ibo_Latn",
        "languages": [
          "amh-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.007186,
        "recall": 0.008513,
        "f1": 0.007278,
        "accuracy": 0.008513,
        "main_score": 0.007278,
        "hf_subset": "amh_Ethi-nso_Latn",
        "languages": [
          "amh-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.004507,
        "recall": 0.006009,
        "f1": 0.004842,
        "accuracy": 0.006009,
        "main_score": 0.004842,
        "hf_subset": "amh_Ethi-orm_Ethi",
        "languages": [
          "amh-Ethi",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.00613,
        "recall": 0.008012,
        "f1": 0.006382,
        "accuracy": 0.008012,
        "main_score": 0.006382,
        "hf_subset": "amh_Ethi-som_Latn",
        "languages": [
          "amh-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.007894,
        "recall": 0.011017,
        "f1": 0.00825,
        "accuracy": 0.011017,
        "main_score": 0.00825,
        "hf_subset": "amh_Ethi-ssw_Latn",
        "languages": [
          "amh-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.004181,
        "recall": 0.006009,
        "f1": 0.00444,
        "accuracy": 0.006009,
        "main_score": 0.00444,
        "hf_subset": "amh_Ethi-swa_Latn",
        "languages": [
          "amh-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.085168,
        "recall": 0.12018,
        "f1": 0.092416,
        "accuracy": 0.12018,
        "main_score": 0.092416,
        "hf_subset": "amh_Ethi-tir_Ethi",
        "languages": [
          "amh-Ethi",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.008364,
        "recall": 0.010015,
        "f1": 0.008581,
        "accuracy": 0.010015,
        "main_score": 0.008581,
        "hf_subset": "amh_Ethi-tsn_Latn",
        "languages": [
          "amh-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.005474,
        "recall": 0.008513,
        "f1": 0.005851,
        "accuracy": 0.008513,
        "main_score": 0.005851,
        "hf_subset": "amh_Ethi-wol_Latn",
        "languages": [
          "amh-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.005769,
        "recall": 0.008012,
        "f1": 0.005932,
        "accuracy": 0.008012,
        "main_score": 0.005932,
        "hf_subset": "amh_Ethi-xho_Latn",
        "languages": [
          "amh-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.002354,
        "recall": 0.003005,
        "f1": 0.002504,
        "accuracy": 0.003005,
        "main_score": 0.002504,
        "hf_subset": "amh_Ethi-yor_Latn",
        "languages": [
          "amh-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.006769,
        "recall": 0.008513,
        "f1": 0.007094,
        "accuracy": 0.008513,
        "main_score": 0.007094,
        "hf_subset": "amh_Ethi-zul_Latn",
        "languages": [
          "amh-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.004093,
        "recall": 0.005508,
        "f1": 0.004155,
        "accuracy": 0.005508,
        "main_score": 0.004155,
        "hf_subset": "arb_Arab-ben_Beng",
        "languages": [
          "arb-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-ckb_Arab",
        "languages": [
          "arb-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.001974,
        "recall": 0.006009,
        "f1": 0.002439,
        "accuracy": 0.006009,
        "main_score": 0.002439,
        "hf_subset": "arb_Arab-deu_Latn",
        "languages": [
          "arb-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 8e-06,
        "recall": 0.001002,
        "f1": 1.6e-05,
        "accuracy": 0.001002,
        "main_score": 1.6e-05,
        "hf_subset": "arb_Arab-ell_Grek",
        "languages": [
          "arb-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.006618,
        "recall": 0.014021,
        "f1": 0.007235,
        "accuracy": 0.014021,
        "main_score": 0.007235,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000628,
        "recall": 0.002003,
        "f1": 0.000727,
        "accuracy": 0.002003,
        "main_score": 0.000727,
        "hf_subset": "arb_Arab-fas_Arab",
        "languages": [
          "arb-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "arb_Arab-fin_Latn",
        "languages": [
          "arb-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.018842,
        "recall": 0.031047,
        "f1": 0.020014,
        "accuracy": 0.031047,
        "main_score": 0.020014,
        "hf_subset": "arb_Arab-fra_Latn",
        "languages": [
          "arb-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "arb_Arab-heb_Hebr",
        "languages": [
          "arb-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.002594,
        "recall": 0.005008,
        "f1": 0.002883,
        "accuracy": 0.005008,
        "main_score": 0.002883,
        "hf_subset": "arb_Arab-hin_Deva",
        "languages": [
          "arb-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-hun_Latn",
        "languages": [
          "arb-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.006581,
        "recall": 0.011517,
        "f1": 0.007064,
        "accuracy": 0.011517,
        "main_score": 0.007064,
        "hf_subset": "arb_Arab-ind_Latn",
        "languages": [
          "arb-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001625,
        "recall": 0.004507,
        "f1": 0.001727,
        "accuracy": 0.004507,
        "main_score": 0.001727,
        "hf_subset": "arb_Arab-jpn_Jpan",
        "languages": [
          "arb-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 7e-06,
        "accuracy": 0.001002,
        "main_score": 7e-06,
        "hf_subset": "arb_Arab-kmr_Latn",
        "languages": [
          "arb-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000311,
        "recall": 0.002003,
        "f1": 0.000443,
        "accuracy": 0.002003,
        "main_score": 0.000443,
        "hf_subset": "arb_Arab-kor_Hang",
        "languages": [
          "arb-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.001174,
        "recall": 0.003505,
        "f1": 0.00129,
        "accuracy": 0.003505,
        "main_score": 0.00129,
        "hf_subset": "arb_Arab-lit_Latn",
        "languages": [
          "arb-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.332482,
        "recall": 0.403105,
        "f1": 0.348469,
        "accuracy": 0.403105,
        "main_score": 0.348469,
        "hf_subset": "arb_Arab-mey_Arab",
        "languages": [
          "arb-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.001255,
        "recall": 0.002003,
        "f1": 0.001341,
        "accuracy": 0.002003,
        "main_score": 0.001341,
        "hf_subset": "arb_Arab-nld_Latn",
        "languages": [
          "arb-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.003698,
        "recall": 0.007511,
        "f1": 0.004053,
        "accuracy": 0.007511,
        "main_score": 0.004053,
        "hf_subset": "arb_Arab-pol_Latn",
        "languages": [
          "arb-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.009663,
        "recall": 0.018528,
        "f1": 0.010674,
        "accuracy": 0.018528,
        "main_score": 0.010674,
        "hf_subset": "arb_Arab-por_Latn",
        "languages": [
          "arb-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.00073,
        "recall": 0.004006,
        "f1": 0.000906,
        "accuracy": 0.004006,
        "main_score": 0.000906,
        "hf_subset": "arb_Arab-prs_Arab",
        "languages": [
          "arb-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000143,
        "recall": 0.001502,
        "f1": 0.000235,
        "accuracy": 0.001502,
        "main_score": 0.000235,
        "hf_subset": "arb_Arab-pus_Arab",
        "languages": [
          "arb-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.008594,
        "recall": 0.017526,
        "f1": 0.009418,
        "accuracy": 0.017526,
        "main_score": 0.009418,
        "hf_subset": "arb_Arab-rus_Cyrl",
        "languages": [
          "arb-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.03358,
        "recall": 0.047571,
        "f1": 0.036012,
        "accuracy": 0.047571,
        "main_score": 0.036012,
        "hf_subset": "arb_Arab-shi_Arab",
        "languages": [
          "arb-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.00758,
        "recall": 0.012018,
        "f1": 0.008325,
        "accuracy": 0.012018,
        "main_score": 0.008325,
        "hf_subset": "arb_Arab-spa_Latn",
        "languages": [
          "arb-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001903,
        "recall": 0.005008,
        "f1": 0.002159,
        "accuracy": 0.005008,
        "main_score": 0.002159,
        "hf_subset": "arb_Arab-swa_Latn",
        "languages": [
          "arb-Arab",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-swe_Latn",
        "languages": [
          "arb-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001253,
        "recall": 0.002504,
        "f1": 0.001338,
        "accuracy": 0.002504,
        "main_score": 0.001338,
        "hf_subset": "arb_Arab-tam_Taml",
        "languages": [
          "arb-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000104,
        "recall": 0.001502,
        "f1": 0.000175,
        "accuracy": 0.001502,
        "main_score": 0.000175,
        "hf_subset": "arb_Arab-tgk_Cyrl",
        "languages": [
          "arb-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000505,
        "accuracy": 0.001502,
        "main_score": 0.000505,
        "hf_subset": "arb_Arab-tur_Latn",
        "languages": [
          "arb-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.009431,
        "recall": 0.019029,
        "f1": 0.010703,
        "accuracy": 0.019029,
        "main_score": 0.010703,
        "hf_subset": "arb_Arab-vie_Latn",
        "languages": [
          "arb-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.003565,
        "recall": 0.006009,
        "f1": 0.003783,
        "accuracy": 0.006009,
        "main_score": 0.003783,
        "hf_subset": "arb_Arab-zho_Hant",
        "languages": [
          "arb-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-zul_Latn",
        "languages": [
          "arb-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.00192,
        "recall": 0.005008,
        "f1": 0.00216,
        "accuracy": 0.005008,
        "main_score": 0.00216,
        "hf_subset": "aze_Latn-bak_Cyrl",
        "languages": [
          "aze-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.008626,
        "recall": 0.011017,
        "f1": 0.008905,
        "accuracy": 0.011017,
        "main_score": 0.008905,
        "hf_subset": "aze_Latn-eng_Latn",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000934,
        "recall": 0.004507,
        "f1": 0.001157,
        "accuracy": 0.004507,
        "main_score": 0.001157,
        "hf_subset": "aze_Latn-kaz_Cyrl",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.000781,
        "recall": 0.004507,
        "f1": 0.000962,
        "accuracy": 0.004507,
        "main_score": 0.000962,
        "hf_subset": "aze_Latn-kir_Cyrl",
        "languages": [
          "aze-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001996,
        "recall": 0.005508,
        "f1": 0.002234,
        "accuracy": 0.005508,
        "main_score": 0.002234,
        "hf_subset": "aze_Latn-tat_Cyrl",
        "languages": [
          "aze-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.078719,
        "recall": 0.107661,
        "f1": 0.084659,
        "accuracy": 0.107661,
        "main_score": 0.084659,
        "hf_subset": "aze_Latn-tuk_Latn",
        "languages": [
          "aze-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.148792,
        "recall": 0.186279,
        "f1": 0.156991,
        "accuracy": 0.186279,
        "main_score": 0.156991,
        "hf_subset": "aze_Latn-tur_Latn",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00046,
        "recall": 0.002504,
        "f1": 0.00069,
        "accuracy": 0.002504,
        "main_score": 0.00069,
        "hf_subset": "aze_Latn-uig_Arab",
        "languages": [
          "aze-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.015402,
        "recall": 0.024537,
        "f1": 0.016409,
        "accuracy": 0.024537,
        "main_score": 0.016409,
        "hf_subset": "aze_Latn-uzb_Latn",
        "languages": [
          "aze-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.005873,
        "recall": 0.007511,
        "f1": 0.006037,
        "accuracy": 0.007511,
        "main_score": 0.006037,
        "hf_subset": "bak_Cyrl-aze_Latn",
        "languages": [
          "bak-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.003759,
        "recall": 0.005008,
        "f1": 0.003846,
        "accuracy": 0.005008,
        "main_score": 0.003846,
        "hf_subset": "bak_Cyrl-eng_Latn",
        "languages": [
          "bak-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.11366,
        "recall": 0.167251,
        "f1": 0.124204,
        "accuracy": 0.167251,
        "main_score": 0.124204,
        "hf_subset": "bak_Cyrl-kaz_Cyrl",
        "languages": [
          "bak-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.139538,
        "recall": 0.18027,
        "f1": 0.149035,
        "accuracy": 0.18027,
        "main_score": 0.149035,
        "hf_subset": "bak_Cyrl-kir_Cyrl",
        "languages": [
          "bak-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.262957,
        "recall": 0.336505,
        "f1": 0.280706,
        "accuracy": 0.336505,
        "main_score": 0.280706,
        "hf_subset": "bak_Cyrl-tat_Cyrl",
        "languages": [
          "bak-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.002922,
        "recall": 0.004006,
        "f1": 0.00309,
        "accuracy": 0.004006,
        "main_score": 0.00309,
        "hf_subset": "bak_Cyrl-tuk_Latn",
        "languages": [
          "bak-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.004814,
        "recall": 0.007011,
        "f1": 0.004948,
        "accuracy": 0.007011,
        "main_score": 0.004948,
        "hf_subset": "bak_Cyrl-tur_Latn",
        "languages": [
          "bak-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000533,
        "recall": 0.002504,
        "f1": 0.000729,
        "accuracy": 0.002504,
        "main_score": 0.000729,
        "hf_subset": "bak_Cyrl-uig_Arab",
        "languages": [
          "bak-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.002506,
        "recall": 0.003505,
        "f1": 0.002509,
        "accuracy": 0.003505,
        "main_score": 0.002509,
        "hf_subset": "bak_Cyrl-uzb_Latn",
        "languages": [
          "bak-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.009782,
        "recall": 0.015023,
        "f1": 0.010391,
        "accuracy": 0.015023,
        "main_score": 0.010391,
        "hf_subset": "bel_Cyrl-bos_Latn",
        "languages": [
          "bel-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.062026,
        "recall": 0.084627,
        "f1": 0.065828,
        "accuracy": 0.084627,
        "main_score": 0.065828,
        "hf_subset": "bel_Cyrl-bul_Cyrl",
        "languages": [
          "bel-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.007528,
        "recall": 0.011017,
        "f1": 0.008222,
        "accuracy": 0.011017,
        "main_score": 0.008222,
        "hf_subset": "bel_Cyrl-ces_Latn",
        "languages": [
          "bel-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.005162,
        "recall": 0.009014,
        "f1": 0.005457,
        "accuracy": 0.009014,
        "main_score": 0.005457,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006655,
        "recall": 0.012018,
        "f1": 0.007348,
        "accuracy": 0.012018,
        "main_score": 0.007348,
        "hf_subset": "bel_Cyrl-hrv_Latn",
        "languages": [
          "bel-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.037526,
        "recall": 0.057086,
        "f1": 0.041205,
        "accuracy": 0.057086,
        "main_score": 0.041205,
        "hf_subset": "bel_Cyrl-mkd_Cyrl",
        "languages": [
          "bel-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.008034,
        "recall": 0.01352,
        "f1": 0.008491,
        "accuracy": 0.01352,
        "main_score": 0.008491,
        "hf_subset": "bel_Cyrl-pol_Latn",
        "languages": [
          "bel-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.050667,
        "recall": 0.075113,
        "f1": 0.053707,
        "accuracy": 0.075113,
        "main_score": 0.053707,
        "hf_subset": "bel_Cyrl-rus_Cyrl",
        "languages": [
          "bel-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.007255,
        "recall": 0.012018,
        "f1": 0.007808,
        "accuracy": 0.012018,
        "main_score": 0.007808,
        "hf_subset": "bel_Cyrl-slk_Latn",
        "languages": [
          "bel-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.008778,
        "recall": 0.012018,
        "f1": 0.009115,
        "accuracy": 0.012018,
        "main_score": 0.009115,
        "hf_subset": "bel_Cyrl-slv_Latn",
        "languages": [
          "bel-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.025374,
        "recall": 0.039559,
        "f1": 0.027427,
        "accuracy": 0.039559,
        "main_score": 0.027427,
        "hf_subset": "bel_Cyrl-srp_Cyrl",
        "languages": [
          "bel-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.008325,
        "recall": 0.01302,
        "f1": 0.009068,
        "accuracy": 0.01302,
        "main_score": 0.009068,
        "hf_subset": "bel_Cyrl-srp_Latn",
        "languages": [
          "bel-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.204461,
        "recall": 0.265899,
        "f1": 0.216881,
        "accuracy": 0.265899,
        "main_score": 0.216881,
        "hf_subset": "bel_Cyrl-ukr_Cyrl",
        "languages": [
          "bel-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.017614,
        "recall": 0.024537,
        "f1": 0.018742,
        "accuracy": 0.024537,
        "main_score": 0.018742,
        "hf_subset": "bem_Latn-eng_Latn",
        "languages": [
          "bem-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030941,
        "recall": 0.037556,
        "f1": 0.032343,
        "accuracy": 0.037556,
        "main_score": 0.032343,
        "hf_subset": "bem_Latn-ewe_Latn",
        "languages": [
          "bem-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.031928,
        "recall": 0.038057,
        "f1": 0.032979,
        "accuracy": 0.038057,
        "main_score": 0.032979,
        "hf_subset": "bem_Latn-fuc_Latn",
        "languages": [
          "bem-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.028262,
        "recall": 0.038057,
        "f1": 0.02995,
        "accuracy": 0.038057,
        "main_score": 0.02995,
        "hf_subset": "bem_Latn-kin_Latn",
        "languages": [
          "bem-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.044097,
        "recall": 0.056585,
        "f1": 0.046751,
        "accuracy": 0.056585,
        "main_score": 0.046751,
        "hf_subset": "bem_Latn-nde_Latn",
        "languages": [
          "bem-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.083289,
        "recall": 0.110165,
        "f1": 0.089445,
        "accuracy": 0.110165,
        "main_score": 0.089445,
        "hf_subset": "bem_Latn-nya_Latn",
        "languages": [
          "bem-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.059877,
        "recall": 0.076615,
        "f1": 0.063645,
        "accuracy": 0.076615,
        "main_score": 0.063645,
        "hf_subset": "bem_Latn-sna_Latn",
        "languages": [
          "bem-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.044668,
        "recall": 0.059589,
        "f1": 0.0476,
        "accuracy": 0.059589,
        "main_score": 0.0476,
        "hf_subset": "bem_Latn-ven_Latn",
        "languages": [
          "bem-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.040928,
        "recall": 0.06009,
        "f1": 0.044068,
        "accuracy": 0.06009,
        "main_score": 0.044068,
        "hf_subset": "ben_Beng-arb_Arab",
        "languages": [
          "ben-Beng",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.014198,
        "recall": 0.02654,
        "f1": 0.015713,
        "accuracy": 0.02654,
        "main_score": 0.015713,
        "hf_subset": "ben_Beng-deu_Latn",
        "languages": [
          "ben-Beng",
          "deu-Latn"
        ]
      },
      {
        "precision": 4e-05,
        "recall": 0.001502,
        "f1": 7.6e-05,
        "accuracy": 0.001502,
        "main_score": 7.6e-05,
        "hf_subset": "ben_Beng-div_Thaa",
        "languages": [
          "ben-Beng",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.002058,
        "recall": 0.004006,
        "f1": 0.002108,
        "accuracy": 0.004006,
        "main_score": 0.002108,
        "hf_subset": "ben_Beng-ell_Grek",
        "languages": [
          "ben-Beng",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.030807,
        "recall": 0.04657,
        "f1": 0.032956,
        "accuracy": 0.04657,
        "main_score": 0.032956,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018617,
        "recall": 0.03355,
        "f1": 0.020527,
        "accuracy": 0.03355,
        "main_score": 0.020527,
        "hf_subset": "ben_Beng-eus_Latn",
        "languages": [
          "ben-Beng",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.001339,
        "recall": 0.004006,
        "f1": 0.001571,
        "accuracy": 0.004006,
        "main_score": 0.001571,
        "hf_subset": "ben_Beng-fas_Arab",
        "languages": [
          "ben-Beng",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.003305,
        "recall": 0.007011,
        "f1": 0.003693,
        "accuracy": 0.007011,
        "main_score": 0.003693,
        "hf_subset": "ben_Beng-fin_Latn",
        "languages": [
          "ben-Beng",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.025007,
        "recall": 0.03305,
        "f1": 0.026291,
        "accuracy": 0.03305,
        "main_score": 0.026291,
        "hf_subset": "ben_Beng-fra_Latn",
        "languages": [
          "ben-Beng",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.011755,
        "recall": 0.021032,
        "f1": 0.012689,
        "accuracy": 0.021032,
        "main_score": 0.012689,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000879,
        "recall": 0.003505,
        "f1": 0.001114,
        "accuracy": 0.003505,
        "main_score": 0.001114,
        "hf_subset": "ben_Beng-heb_Hebr",
        "languages": [
          "ben-Beng",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.024182,
        "recall": 0.031547,
        "f1": 0.025177,
        "accuracy": 0.031547,
        "main_score": 0.025177,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002027,
        "recall": 0.005508,
        "f1": 0.002287,
        "accuracy": 0.005508,
        "main_score": 0.002287,
        "hf_subset": "ben_Beng-hun_Latn",
        "languages": [
          "ben-Beng",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.002504,
        "f1": 0.001175,
        "accuracy": 0.002504,
        "main_score": 0.001175,
        "hf_subset": "ben_Beng-ind_Latn",
        "languages": [
          "ben-Beng",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.012171,
        "recall": 0.023035,
        "f1": 0.013602,
        "accuracy": 0.023035,
        "main_score": 0.013602,
        "hf_subset": "ben_Beng-jpn_Jpan",
        "languages": [
          "ben-Beng",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.020489,
        "recall": 0.029544,
        "f1": 0.021774,
        "accuracy": 0.029544,
        "main_score": 0.021774,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004796,
        "recall": 0.010015,
        "f1": 0.005358,
        "accuracy": 0.010015,
        "main_score": 0.005358,
        "hf_subset": "ben_Beng-kor_Hang",
        "languages": [
          "ben-Beng",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.002319,
        "recall": 0.005508,
        "f1": 0.002772,
        "accuracy": 0.005508,
        "main_score": 0.002772,
        "hf_subset": "ben_Beng-lit_Latn",
        "languages": [
          "ben-Beng",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.011923,
        "recall": 0.016024,
        "f1": 0.012566,
        "accuracy": 0.016024,
        "main_score": 0.012566,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.014058,
        "recall": 0.017026,
        "f1": 0.014549,
        "accuracy": 0.017026,
        "main_score": 0.014549,
        "hf_subset": "ben_Beng-nep_Deva",
        "languages": [
          "ben-Beng",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.007352,
        "recall": 0.012018,
        "f1": 0.0076,
        "accuracy": 0.012018,
        "main_score": 0.0076,
        "hf_subset": "ben_Beng-nld_Latn",
        "languages": [
          "ben-Beng",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.008892,
        "recall": 0.01302,
        "f1": 0.00947,
        "accuracy": 0.01302,
        "main_score": 0.00947,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004136,
        "recall": 0.007511,
        "f1": 0.004417,
        "accuracy": 0.007511,
        "main_score": 0.004417,
        "hf_subset": "ben_Beng-pol_Latn",
        "languages": [
          "ben-Beng",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.021115,
        "recall": 0.029044,
        "f1": 0.022237,
        "accuracy": 0.029044,
        "main_score": 0.022237,
        "hf_subset": "ben_Beng-por_Latn",
        "languages": [
          "ben-Beng",
          "por-Latn"
        ]
      },
      {
        "precision": 0.007913,
        "recall": 0.011517,
        "f1": 0.008539,
        "accuracy": 0.011517,
        "main_score": 0.008539,
        "hf_subset": "ben_Beng-rus_Cyrl",
        "languages": [
          "ben-Beng",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000885,
        "recall": 0.002504,
        "f1": 0.001064,
        "accuracy": 0.002504,
        "main_score": 0.001064,
        "hf_subset": "ben_Beng-sin_Sinh",
        "languages": [
          "ben-Beng",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000532,
        "recall": 0.001002,
        "f1": 0.00056,
        "accuracy": 0.001002,
        "main_score": 0.00056,
        "hf_subset": "ben_Beng-snd_Arab",
        "languages": [
          "ben-Beng",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.025367,
        "recall": 0.038057,
        "f1": 0.027486,
        "accuracy": 0.038057,
        "main_score": 0.027486,
        "hf_subset": "ben_Beng-spa_Latn",
        "languages": [
          "ben-Beng",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.002809,
        "recall": 0.00651,
        "f1": 0.002941,
        "accuracy": 0.00651,
        "main_score": 0.002941,
        "hf_subset": "ben_Beng-swa_Latn",
        "languages": [
          "ben-Beng",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.004378,
        "recall": 0.008012,
        "f1": 0.004747,
        "accuracy": 0.008012,
        "main_score": 0.004747,
        "hf_subset": "ben_Beng-swe_Latn",
        "languages": [
          "ben-Beng",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.008462,
        "recall": 0.014522,
        "f1": 0.00952,
        "accuracy": 0.014522,
        "main_score": 0.00952,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.018503,
        "recall": 0.03305,
        "f1": 0.020467,
        "accuracy": 0.03305,
        "main_score": 0.020467,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004127,
        "recall": 0.009514,
        "f1": 0.004697,
        "accuracy": 0.009514,
        "main_score": 0.004697,
        "hf_subset": "ben_Beng-tur_Latn",
        "languages": [
          "ben-Beng",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.013472,
        "recall": 0.025038,
        "f1": 0.014311,
        "accuracy": 0.025038,
        "main_score": 0.014311,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.019861,
        "recall": 0.035053,
        "f1": 0.021847,
        "accuracy": 0.035053,
        "main_score": 0.021847,
        "hf_subset": "ben_Beng-vie_Latn",
        "languages": [
          "ben-Beng",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.027766,
        "recall": 0.042063,
        "f1": 0.029944,
        "accuracy": 0.042063,
        "main_score": 0.029944,
        "hf_subset": "ben_Beng-zho_Hant",
        "languages": [
          "ben-Beng",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.002318,
        "recall": 0.005008,
        "f1": 0.002498,
        "accuracy": 0.005008,
        "main_score": 0.002498,
        "hf_subset": "ben_Beng-zul_Latn",
        "languages": [
          "ben-Beng",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.018044,
        "recall": 0.030546,
        "f1": 0.020833,
        "accuracy": 0.030546,
        "main_score": 0.020833,
        "hf_subset": "bod_Tibt-dzo_Tibt",
        "languages": [
          "bod-Tibt",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.007174,
        "recall": 0.01302,
        "f1": 0.00765,
        "accuracy": 0.01302,
        "main_score": 0.00765,
        "hf_subset": "bod_Tibt-eng_Latn",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005776,
        "recall": 0.011517,
        "f1": 0.006475,
        "accuracy": 0.011517,
        "main_score": 0.006475,
        "hf_subset": "bod_Tibt-khm_Khmr",
        "languages": [
          "bod-Tibt",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.018543,
        "recall": 0.02654,
        "f1": 0.019692,
        "accuracy": 0.02654,
        "main_score": 0.019692,
        "hf_subset": "bod_Tibt-lao_Laoo",
        "languages": [
          "bod-Tibt",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.001553,
        "recall": 0.002504,
        "f1": 0.001594,
        "accuracy": 0.002504,
        "main_score": 0.001594,
        "hf_subset": "bod_Tibt-mon_Mong",
        "languages": [
          "bod-Tibt",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.013943,
        "recall": 0.019029,
        "f1": 0.014796,
        "accuracy": 0.019029,
        "main_score": 0.014796,
        "hf_subset": "bod_Tibt-mya_Mymr",
        "languages": [
          "bod-Tibt",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.01836,
        "recall": 0.02654,
        "f1": 0.019796,
        "accuracy": 0.02654,
        "main_score": 0.019796,
        "hf_subset": "bod_Tibt-tha_Thai",
        "languages": [
          "bod-Tibt",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.000392,
        "recall": 0.003005,
        "f1": 0.000584,
        "accuracy": 0.003005,
        "main_score": 0.000584,
        "hf_subset": "bos_Latn-bel_Cyrl",
        "languages": [
          "bos-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.001513,
        "recall": 0.003505,
        "f1": 0.001524,
        "accuracy": 0.003505,
        "main_score": 0.001524,
        "hf_subset": "bos_Latn-bul_Cyrl",
        "languages": [
          "bos-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.103069,
        "recall": 0.124186,
        "f1": 0.106995,
        "accuracy": 0.124186,
        "main_score": 0.106995,
        "hf_subset": "bos_Latn-ces_Latn",
        "languages": [
          "bos-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.021712,
        "recall": 0.031047,
        "f1": 0.023131,
        "accuracy": 0.031047,
        "main_score": 0.023131,
        "hf_subset": "bos_Latn-eng_Latn",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.708611,
        "recall": 0.772158,
        "f1": 0.726932,
        "accuracy": 0.772158,
        "main_score": 0.726932,
        "hf_subset": "bos_Latn-hrv_Latn",
        "languages": [
          "bos-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.001579,
        "recall": 0.004507,
        "f1": 0.001646,
        "accuracy": 0.004507,
        "main_score": 0.001646,
        "hf_subset": "bos_Latn-mkd_Cyrl",
        "languages": [
          "bos-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.050488,
        "recall": 0.061592,
        "f1": 0.05211,
        "accuracy": 0.061592,
        "main_score": 0.05211,
        "hf_subset": "bos_Latn-pol_Latn",
        "languages": [
          "bos-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.002508,
        "recall": 0.004006,
        "f1": 0.002512,
        "accuracy": 0.004006,
        "main_score": 0.002512,
        "hf_subset": "bos_Latn-rus_Cyrl",
        "languages": [
          "bos-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.112089,
        "recall": 0.13971,
        "f1": 0.117222,
        "accuracy": 0.13971,
        "main_score": 0.117222,
        "hf_subset": "bos_Latn-slk_Latn",
        "languages": [
          "bos-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.323261,
        "recall": 0.386079,
        "f1": 0.339141,
        "accuracy": 0.386079,
        "main_score": 0.339141,
        "hf_subset": "bos_Latn-slv_Latn",
        "languages": [
          "bos-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.002702,
        "recall": 0.005508,
        "f1": 0.003021,
        "accuracy": 0.005508,
        "main_score": 0.003021,
        "hf_subset": "bos_Latn-srp_Cyrl",
        "languages": [
          "bos-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.690045,
        "recall": 0.761142,
        "f1": 0.710956,
        "accuracy": 0.761142,
        "main_score": 0.710956,
        "hf_subset": "bos_Latn-srp_Latn",
        "languages": [
          "bos-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.000302,
        "recall": 0.003005,
        "f1": 0.000429,
        "accuracy": 0.003005,
        "main_score": 0.000429,
        "hf_subset": "bos_Latn-ukr_Cyrl",
        "languages": [
          "bos-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.087458,
        "recall": 0.123185,
        "f1": 0.093918,
        "accuracy": 0.123185,
        "main_score": 0.093918,
        "hf_subset": "bul_Cyrl-bel_Cyrl",
        "languages": [
          "bul-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.022269,
        "recall": 0.031047,
        "f1": 0.023425,
        "accuracy": 0.031047,
        "main_score": 0.023425,
        "hf_subset": "bul_Cyrl-bos_Latn",
        "languages": [
          "bul-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.012293,
        "recall": 0.017026,
        "f1": 0.013087,
        "accuracy": 0.017026,
        "main_score": 0.013087,
        "hf_subset": "bul_Cyrl-ces_Latn",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.016716,
        "recall": 0.023535,
        "f1": 0.017467,
        "accuracy": 0.023535,
        "main_score": 0.017467,
        "hf_subset": "bul_Cyrl-eng_Latn",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015848,
        "recall": 0.021532,
        "f1": 0.01682,
        "accuracy": 0.021532,
        "main_score": 0.01682,
        "hf_subset": "bul_Cyrl-hrv_Latn",
        "languages": [
          "bul-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.35541,
        "recall": 0.437156,
        "f1": 0.374815,
        "accuracy": 0.437156,
        "main_score": 0.374815,
        "hf_subset": "bul_Cyrl-mkd_Cyrl",
        "languages": [
          "bul-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.014421,
        "recall": 0.024537,
        "f1": 0.015792,
        "accuracy": 0.024537,
        "main_score": 0.015792,
        "hf_subset": "bul_Cyrl-pol_Latn",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.210175,
        "recall": 0.25989,
        "f1": 0.219914,
        "accuracy": 0.25989,
        "main_score": 0.219914,
        "hf_subset": "bul_Cyrl-rus_Cyrl",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.012061,
        "recall": 0.019529,
        "f1": 0.013132,
        "accuracy": 0.019529,
        "main_score": 0.013132,
        "hf_subset": "bul_Cyrl-slk_Latn",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.01266,
        "recall": 0.02003,
        "f1": 0.01379,
        "accuracy": 0.02003,
        "main_score": 0.01379,
        "hf_subset": "bul_Cyrl-slv_Latn",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.123236,
        "recall": 0.179269,
        "f1": 0.133053,
        "accuracy": 0.179269,
        "main_score": 0.133053,
        "hf_subset": "bul_Cyrl-srp_Cyrl",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.017437,
        "recall": 0.029044,
        "f1": 0.019038,
        "accuracy": 0.029044,
        "main_score": 0.019038,
        "hf_subset": "bul_Cyrl-srp_Latn",
        "languages": [
          "bul-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.198552,
        "recall": 0.247371,
        "f1": 0.209022,
        "accuracy": 0.247371,
        "main_score": 0.209022,
        "hf_subset": "bul_Cyrl-ukr_Cyrl",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.130213,
        "recall": 0.139209,
        "f1": 0.132566,
        "accuracy": 0.139209,
        "main_score": 0.132566,
        "hf_subset": "cat_Latn-eng_Latn",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.145825,
        "recall": 0.163245,
        "f1": 0.149929,
        "accuracy": 0.163245,
        "main_score": 0.149929,
        "hf_subset": "cat_Latn-fra_Latn",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.098731,
        "recall": 0.110666,
        "f1": 0.101362,
        "accuracy": 0.110666,
        "main_score": 0.101362,
        "hf_subset": "cat_Latn-glg_Latn",
        "languages": [
          "cat-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.055563,
        "recall": 0.068102,
        "f1": 0.058038,
        "accuracy": 0.068102,
        "main_score": 0.058038,
        "hf_subset": "cat_Latn-ita_Latn",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.012223,
        "recall": 0.016024,
        "f1": 0.012755,
        "accuracy": 0.016024,
        "main_score": 0.012755,
        "hf_subset": "cat_Latn-mlt_Latn",
        "languages": [
          "cat-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.14554,
        "recall": 0.169254,
        "f1": 0.15099,
        "accuracy": 0.169254,
        "main_score": 0.15099,
        "hf_subset": "cat_Latn-por_Latn",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.021864,
        "recall": 0.02654,
        "f1": 0.022491,
        "accuracy": 0.02654,
        "main_score": 0.022491,
        "hf_subset": "cat_Latn-ron_Latn",
        "languages": [
          "cat-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.29685,
        "recall": 0.338007,
        "f1": 0.306552,
        "accuracy": 0.338007,
        "main_score": 0.306552,
        "hf_subset": "cat_Latn-spa_Latn",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.000292,
        "recall": 0.002504,
        "f1": 0.000415,
        "accuracy": 0.002504,
        "main_score": 0.000415,
        "hf_subset": "ces_Latn-bel_Cyrl",
        "languages": [
          "ces-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.112472,
        "recall": 0.135704,
        "f1": 0.117315,
        "accuracy": 0.135704,
        "main_score": 0.117315,
        "hf_subset": "ces_Latn-bos_Latn",
        "languages": [
          "ces-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.001268,
        "recall": 0.003505,
        "f1": 0.001366,
        "accuracy": 0.003505,
        "main_score": 0.001366,
        "hf_subset": "ces_Latn-bul_Cyrl",
        "languages": [
          "ces-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.019251,
        "recall": 0.026039,
        "f1": 0.020103,
        "accuracy": 0.026039,
        "main_score": 0.020103,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.117229,
        "recall": 0.145719,
        "f1": 0.122865,
        "accuracy": 0.145719,
        "main_score": 0.122865,
        "hf_subset": "ces_Latn-hrv_Latn",
        "languages": [
          "ces-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.000642,
        "recall": 0.004006,
        "f1": 0.000752,
        "accuracy": 0.004006,
        "main_score": 0.000752,
        "hf_subset": "ces_Latn-mkd_Cyrl",
        "languages": [
          "ces-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.072221,
        "recall": 0.088633,
        "f1": 0.074918,
        "accuracy": 0.088633,
        "main_score": 0.074918,
        "hf_subset": "ces_Latn-pol_Latn",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001513,
        "recall": 0.003005,
        "f1": 0.001523,
        "accuracy": 0.003005,
        "main_score": 0.001523,
        "hf_subset": "ces_Latn-rus_Cyrl",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.493806,
        "recall": 0.569354,
        "f1": 0.51366,
        "accuracy": 0.569354,
        "main_score": 0.51366,
        "hf_subset": "ces_Latn-slk_Latn",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.141478,
        "recall": 0.162243,
        "f1": 0.145584,
        "accuracy": 0.162243,
        "main_score": 0.145584,
        "hf_subset": "ces_Latn-slv_Latn",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.001184,
        "recall": 0.003505,
        "f1": 0.001311,
        "accuracy": 0.003505,
        "main_score": 0.001311,
        "hf_subset": "ces_Latn-srp_Cyrl",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.060346,
        "recall": 0.081622,
        "f1": 0.063925,
        "accuracy": 0.081622,
        "main_score": 0.063925,
        "hf_subset": "ces_Latn-srp_Latn",
        "languages": [
          "ces-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.001035,
        "recall": 0.003505,
        "f1": 0.001067,
        "accuracy": 0.003505,
        "main_score": 0.001067,
        "hf_subset": "ces_Latn-ukr_Cyrl",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.000224,
        "recall": 0.001502,
        "f1": 0.000353,
        "accuracy": 0.001502,
        "main_score": 0.000353,
        "hf_subset": "ckb_Arab-arb_Arab",
        "languages": [
          "ckb-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000133,
        "recall": 0.001502,
        "f1": 0.000216,
        "accuracy": 0.001502,
        "main_score": 0.000216,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00187,
        "recall": 0.005508,
        "f1": 0.002257,
        "accuracy": 0.005508,
        "main_score": 0.002257,
        "hf_subset": "ckb_Arab-fas_Arab",
        "languages": [
          "ckb-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ckb_Arab-heb_Hebr",
        "languages": [
          "ckb-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00019,
        "recall": 0.001502,
        "f1": 0.000316,
        "accuracy": 0.001502,
        "main_score": 0.000316,
        "hf_subset": "ckb_Arab-kmr_Latn",
        "languages": [
          "ckb-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ckb_Arab-mey_Arab",
        "languages": [
          "ckb-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.002774,
        "recall": 0.007511,
        "f1": 0.003181,
        "accuracy": 0.007511,
        "main_score": 0.003181,
        "hf_subset": "ckb_Arab-prs_Arab",
        "languages": [
          "ckb-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.00253,
        "recall": 0.005508,
        "f1": 0.002889,
        "accuracy": 0.005508,
        "main_score": 0.002889,
        "hf_subset": "ckb_Arab-pus_Arab",
        "languages": [
          "ckb-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ckb_Arab-shi_Arab",
        "languages": [
          "ckb-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "ckb_Arab-tgk_Cyrl",
        "languages": [
          "ckb-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.008308,
        "recall": 0.011517,
        "f1": 0.008528,
        "accuracy": 0.011517,
        "main_score": 0.008528,
        "hf_subset": "cym_Latn-eng_Latn",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028628,
        "recall": 0.037556,
        "f1": 0.030336,
        "accuracy": 0.037556,
        "main_score": 0.030336,
        "hf_subset": "cym_Latn-gle_Latn",
        "languages": [
          "cym-Latn",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.091142,
        "recall": 0.105158,
        "f1": 0.093947,
        "accuracy": 0.105158,
        "main_score": 0.093947,
        "hf_subset": "dan_Latn-afr_Latn",
        "languages": [
          "dan-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.055302,
        "recall": 0.068603,
        "f1": 0.057192,
        "accuracy": 0.068603,
        "main_score": 0.057192,
        "hf_subset": "dan_Latn-deu_Latn",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.045433,
        "recall": 0.054582,
        "f1": 0.046951,
        "accuracy": 0.054582,
        "main_score": 0.046951,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.07592,
        "recall": 0.098648,
        "f1": 0.080002,
        "accuracy": 0.098648,
        "main_score": 0.080002,
        "hf_subset": "dan_Latn-fao_Latn",
        "languages": [
          "dan-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.04559,
        "recall": 0.065098,
        "f1": 0.04939,
        "accuracy": 0.065098,
        "main_score": 0.04939,
        "hf_subset": "dan_Latn-isl_Latn",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.066837,
        "recall": 0.08012,
        "f1": 0.069667,
        "accuracy": 0.08012,
        "main_score": 0.069667,
        "hf_subset": "dan_Latn-ltz_Latn",
        "languages": [
          "dan-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.094501,
        "recall": 0.10666,
        "f1": 0.097045,
        "accuracy": 0.10666,
        "main_score": 0.097045,
        "hf_subset": "dan_Latn-nld_Latn",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.432365,
        "recall": 0.504256,
        "f1": 0.450024,
        "accuracy": 0.504256,
        "main_score": 0.450024,
        "hf_subset": "dan_Latn-nno_Latn",
        "languages": [
          "dan-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.583968,
        "recall": 0.652479,
        "f1": 0.602212,
        "accuracy": 0.652479,
        "main_score": 0.602212,
        "hf_subset": "dan_Latn-nob_Latn",
        "languages": [
          "dan-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.401925,
        "recall": 0.472208,
        "f1": 0.418315,
        "accuracy": 0.472208,
        "main_score": 0.418315,
        "hf_subset": "dan_Latn-swe_Latn",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.06128,
        "recall": 0.071607,
        "f1": 0.062937,
        "accuracy": 0.071607,
        "main_score": 0.062937,
        "hf_subset": "deu_Latn-afr_Latn",
        "languages": [
          "deu-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "deu_Latn-arb_Arab",
        "languages": [
          "deu-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000679,
        "recall": 0.004006,
        "f1": 0.000829,
        "accuracy": 0.004006,
        "main_score": 0.000829,
        "hf_subset": "deu_Latn-ben_Beng",
        "languages": [
          "deu-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.049822,
        "recall": 0.057086,
        "f1": 0.050767,
        "accuracy": 0.057086,
        "main_score": 0.050767,
        "hf_subset": "deu_Latn-dan_Latn",
        "languages": [
          "deu-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.000829,
        "recall": 0.002504,
        "f1": 0.000972,
        "accuracy": 0.002504,
        "main_score": 0.000972,
        "hf_subset": "deu_Latn-ell_Grek",
        "languages": [
          "deu-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.044633,
        "recall": 0.050576,
        "f1": 0.046104,
        "accuracy": 0.050576,
        "main_score": 0.046104,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028384,
        "recall": 0.032549,
        "f1": 0.029254,
        "accuracy": 0.032549,
        "main_score": 0.029254,
        "hf_subset": "deu_Latn-fao_Latn",
        "languages": [
          "deu-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.002003,
        "f1": 0.001169,
        "accuracy": 0.002003,
        "main_score": 0.001169,
        "hf_subset": "deu_Latn-fas_Arab",
        "languages": [
          "deu-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.02395,
        "recall": 0.028543,
        "f1": 0.024605,
        "accuracy": 0.028543,
        "main_score": 0.024605,
        "hf_subset": "deu_Latn-fin_Latn",
        "languages": [
          "deu-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.043319,
        "recall": 0.055083,
        "f1": 0.045169,
        "accuracy": 0.055083,
        "main_score": 0.045169,
        "hf_subset": "deu_Latn-fra_Latn",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000571,
        "recall": 0.002003,
        "f1": 0.000627,
        "accuracy": 0.002003,
        "main_score": 0.000627,
        "hf_subset": "deu_Latn-heb_Hebr",
        "languages": [
          "deu-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "deu_Latn-hin_Deva",
        "languages": [
          "deu-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015431,
        "recall": 0.022534,
        "f1": 0.016502,
        "accuracy": 0.022534,
        "main_score": 0.016502,
        "hf_subset": "deu_Latn-hun_Latn",
        "languages": [
          "deu-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.009961,
        "recall": 0.019029,
        "f1": 0.01111,
        "accuracy": 0.019029,
        "main_score": 0.01111,
        "hf_subset": "deu_Latn-ind_Latn",
        "languages": [
          "deu-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.024907,
        "recall": 0.029544,
        "f1": 0.025793,
        "accuracy": 0.029544,
        "main_score": 0.025793,
        "hf_subset": "deu_Latn-isl_Latn",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.000125,
        "recall": 0.001002,
        "f1": 0.000201,
        "accuracy": 0.001002,
        "main_score": 0.000201,
        "hf_subset": "deu_Latn-jpn_Jpan",
        "languages": [
          "deu-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000264,
        "recall": 0.002003,
        "f1": 0.00036,
        "accuracy": 0.002003,
        "main_score": 0.00036,
        "hf_subset": "deu_Latn-kor_Hang",
        "languages": [
          "deu-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.028794,
        "recall": 0.038558,
        "f1": 0.030045,
        "accuracy": 0.038558,
        "main_score": 0.030045,
        "hf_subset": "deu_Latn-lit_Latn",
        "languages": [
          "deu-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.118457,
        "recall": 0.161242,
        "f1": 0.126546,
        "accuracy": 0.161242,
        "main_score": 0.126546,
        "hf_subset": "deu_Latn-ltz_Latn",
        "languages": [
          "deu-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.070364,
        "recall": 0.080621,
        "f1": 0.072097,
        "accuracy": 0.080621,
        "main_score": 0.072097,
        "hf_subset": "deu_Latn-nld_Latn",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.03609,
        "recall": 0.040561,
        "f1": 0.036704,
        "accuracy": 0.040561,
        "main_score": 0.036704,
        "hf_subset": "deu_Latn-nno_Latn",
        "languages": [
          "deu-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.055827,
        "recall": 0.061092,
        "f1": 0.057017,
        "accuracy": 0.061092,
        "main_score": 0.057017,
        "hf_subset": "deu_Latn-nob_Latn",
        "languages": [
          "deu-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.027138,
        "recall": 0.038057,
        "f1": 0.028949,
        "accuracy": 0.038057,
        "main_score": 0.028949,
        "hf_subset": "deu_Latn-pol_Latn",
        "languages": [
          "deu-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.034089,
        "recall": 0.045568,
        "f1": 0.035638,
        "accuracy": 0.045568,
        "main_score": 0.035638,
        "hf_subset": "deu_Latn-por_Latn",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001796,
        "recall": 0.004006,
        "f1": 0.001919,
        "accuracy": 0.004006,
        "main_score": 0.001919,
        "hf_subset": "deu_Latn-rus_Cyrl",
        "languages": [
          "deu-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.047868,
        "recall": 0.064597,
        "f1": 0.05131,
        "accuracy": 0.064597,
        "main_score": 0.05131,
        "hf_subset": "deu_Latn-spa_Latn",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.006334,
        "recall": 0.011017,
        "f1": 0.006745,
        "accuracy": 0.011017,
        "main_score": 0.006745,
        "hf_subset": "deu_Latn-swa_Latn",
        "languages": [
          "deu-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.080069,
        "recall": 0.095643,
        "f1": 0.082844,
        "accuracy": 0.095643,
        "main_score": 0.082844,
        "hf_subset": "deu_Latn-swe_Latn",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.00051,
        "recall": 0.001502,
        "f1": 0.000519,
        "accuracy": 0.001502,
        "main_score": 0.000519,
        "hf_subset": "deu_Latn-tam_Taml",
        "languages": [
          "deu-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013423,
        "recall": 0.021032,
        "f1": 0.014277,
        "accuracy": 0.021032,
        "main_score": 0.014277,
        "hf_subset": "deu_Latn-tur_Latn",
        "languages": [
          "deu-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.014122,
        "recall": 0.018027,
        "f1": 0.014594,
        "accuracy": 0.018027,
        "main_score": 0.014594,
        "hf_subset": "deu_Latn-vie_Latn",
        "languages": [
          "deu-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001011,
        "recall": 0.003005,
        "f1": 0.00102,
        "accuracy": 0.003005,
        "main_score": 0.00102,
        "hf_subset": "deu_Latn-zho_Hant",
        "languages": [
          "deu-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.016923,
        "recall": 0.022033,
        "f1": 0.017778,
        "accuracy": 0.022033,
        "main_score": 0.017778,
        "hf_subset": "deu_Latn-zul_Latn",
        "languages": [
          "deu-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 4e-06,
        "accuracy": 0.000501,
        "main_score": 4e-06,
        "hf_subset": "div_Thaa-ben_Beng",
        "languages": [
          "div-Thaa",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000506,
        "recall": 0.001502,
        "f1": 0.000511,
        "accuracy": 0.001502,
        "main_score": 0.000511,
        "hf_subset": "div_Thaa-eng_Latn",
        "languages": [
          "div-Thaa",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "div_Thaa-eus_Latn",
        "languages": [
          "div-Thaa",
          "eus-Latn"
        ]
      },
      {
        "precision": 1.2e-05,
        "recall": 0.001002,
        "f1": 2.4e-05,
        "accuracy": 0.001002,
        "main_score": 2.4e-05,
        "hf_subset": "div_Thaa-guj_Gujr",
        "languages": [
          "div-Thaa",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.000501,
        "f1": 3.3e-05,
        "accuracy": 0.000501,
        "main_score": 3.3e-05,
        "hf_subset": "div_Thaa-hin_Deva",
        "languages": [
          "div-Thaa",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001002,
        "f1": 3e-05,
        "accuracy": 0.001002,
        "main_score": 3e-05,
        "hf_subset": "div_Thaa-kan_Knda",
        "languages": [
          "div-Thaa",
          "kan-Knda"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "div_Thaa-mar_Deva",
        "languages": [
          "div-Thaa",
          "mar-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "div_Thaa-nep_Deva",
        "languages": [
          "div-Thaa",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "div_Thaa-pan_Guru",
        "languages": [
          "div-Thaa",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001609,
        "recall": 0.004006,
        "f1": 0.001704,
        "accuracy": 0.004006,
        "main_score": 0.001704,
        "hf_subset": "div_Thaa-sin_Sinh",
        "languages": [
          "div-Thaa",
          "sin-Sinh"
        ]
      },
      {
        "precision": 2e-05,
        "recall": 0.001502,
        "f1": 3.8e-05,
        "accuracy": 0.001502,
        "main_score": 3.8e-05,
        "hf_subset": "div_Thaa-snd_Arab",
        "languages": [
          "div-Thaa",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "div_Thaa-tam_Taml",
        "languages": [
          "div-Thaa",
          "tam-Taml"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "div_Thaa-tel_Telu",
        "languages": [
          "div-Thaa",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000136,
        "recall": 0.001502,
        "f1": 0.000234,
        "accuracy": 0.001502,
        "main_score": 0.000234,
        "hf_subset": "div_Thaa-urd_Arab",
        "languages": [
          "div-Thaa",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.019948,
        "recall": 0.034552,
        "f1": 0.02306,
        "accuracy": 0.034552,
        "main_score": 0.02306,
        "hf_subset": "dzo_Tibt-bod_Tibt",
        "languages": [
          "dzo-Tibt",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.000515,
        "recall": 0.002003,
        "f1": 0.000529,
        "accuracy": 0.002003,
        "main_score": 0.000529,
        "hf_subset": "dzo_Tibt-eng_Latn",
        "languages": [
          "dzo-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000181,
        "recall": 0.001502,
        "f1": 0.000314,
        "accuracy": 0.001502,
        "main_score": 0.000314,
        "hf_subset": "dzo_Tibt-khm_Khmr",
        "languages": [
          "dzo-Tibt",
          "khm-Khmr"
        ]
      },
      {
        "precision": 8.3e-05,
        "recall": 0.000501,
        "f1": 0.000143,
        "accuracy": 0.000501,
        "main_score": 0.000143,
        "hf_subset": "dzo_Tibt-lao_Laoo",
        "languages": [
          "dzo-Tibt",
          "lao-Laoo"
        ]
      },
      {
        "precision": 1.6e-05,
        "recall": 0.001002,
        "f1": 3.1e-05,
        "accuracy": 0.001002,
        "main_score": 3.1e-05,
        "hf_subset": "dzo_Tibt-mon_Mong",
        "languages": [
          "dzo-Tibt",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.000831,
        "recall": 0.002504,
        "f1": 0.001031,
        "accuracy": 0.002504,
        "main_score": 0.001031,
        "hf_subset": "dzo_Tibt-mya_Mymr",
        "languages": [
          "dzo-Tibt",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.000683,
        "recall": 0.002504,
        "f1": 0.000781,
        "accuracy": 0.002504,
        "main_score": 0.000781,
        "hf_subset": "dzo_Tibt-tha_Thai",
        "languages": [
          "dzo-Tibt",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-arb_Arab",
        "languages": [
          "ell-Grek",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000177,
        "recall": 0.003505,
        "f1": 0.000309,
        "accuracy": 0.003505,
        "main_score": 0.000309,
        "hf_subset": "ell_Grek-ben_Beng",
        "languages": [
          "ell-Grek",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.004092,
        "recall": 0.007511,
        "f1": 0.004169,
        "accuracy": 0.007511,
        "main_score": 0.004169,
        "hf_subset": "ell_Grek-deu_Latn",
        "languages": [
          "ell-Grek",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.002244,
        "recall": 0.005008,
        "f1": 0.002387,
        "accuracy": 0.005008,
        "main_score": 0.002387,
        "hf_subset": "ell_Grek-eng_Latn",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000531,
        "recall": 0.001502,
        "f1": 0.000557,
        "accuracy": 0.001502,
        "main_score": 0.000557,
        "hf_subset": "ell_Grek-fas_Arab",
        "languages": [
          "ell-Grek",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.002553,
        "recall": 0.004006,
        "f1": 0.002596,
        "accuracy": 0.004006,
        "main_score": 0.002596,
        "hf_subset": "ell_Grek-fin_Latn",
        "languages": [
          "ell-Grek",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.00334,
        "recall": 0.005008,
        "f1": 0.003508,
        "accuracy": 0.005008,
        "main_score": 0.003508,
        "hf_subset": "ell_Grek-fra_Latn",
        "languages": [
          "ell-Grek",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.004488,
        "recall": 0.00651,
        "f1": 0.00471,
        "accuracy": 0.00651,
        "main_score": 0.00471,
        "hf_subset": "ell_Grek-heb_Hebr",
        "languages": [
          "ell-Grek",
          "heb-Hebr"
        ]
      },
      {
        "precision": 3.2e-05,
        "recall": 0.001002,
        "f1": 6e-05,
        "accuracy": 0.001002,
        "main_score": 6e-05,
        "hf_subset": "ell_Grek-hin_Deva",
        "languages": [
          "ell-Grek",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001753,
        "recall": 0.002504,
        "f1": 0.001837,
        "accuracy": 0.002504,
        "main_score": 0.001837,
        "hf_subset": "ell_Grek-hun_Latn",
        "languages": [
          "ell-Grek",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001734,
        "recall": 0.005008,
        "f1": 0.002058,
        "accuracy": 0.005008,
        "main_score": 0.002058,
        "hf_subset": "ell_Grek-hye_Armn",
        "languages": [
          "ell-Grek",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.002511,
        "recall": 0.004507,
        "f1": 0.002519,
        "accuracy": 0.004507,
        "main_score": 0.002519,
        "hf_subset": "ell_Grek-ind_Latn",
        "languages": [
          "ell-Grek",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.002047,
        "recall": 0.003505,
        "f1": 0.002086,
        "accuracy": 0.003505,
        "main_score": 0.002086,
        "hf_subset": "ell_Grek-jpn_Jpan",
        "languages": [
          "ell-Grek",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001532,
        "recall": 0.002504,
        "f1": 0.001558,
        "accuracy": 0.002504,
        "main_score": 0.001558,
        "hf_subset": "ell_Grek-kat_Geor",
        "languages": [
          "ell-Grek",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.003255,
        "recall": 0.003505,
        "f1": 0.003338,
        "accuracy": 0.003505,
        "main_score": 0.003338,
        "hf_subset": "ell_Grek-kor_Hang",
        "languages": [
          "ell-Grek",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.001168,
        "recall": 0.001502,
        "f1": 0.001252,
        "accuracy": 0.001502,
        "main_score": 0.001252,
        "hf_subset": "ell_Grek-lit_Latn",
        "languages": [
          "ell-Grek",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.003034,
        "recall": 0.005008,
        "f1": 0.00306,
        "accuracy": 0.005008,
        "main_score": 0.00306,
        "hf_subset": "ell_Grek-nld_Latn",
        "languages": [
          "ell-Grek",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.003172,
        "recall": 0.004507,
        "f1": 0.003423,
        "accuracy": 0.004507,
        "main_score": 0.003423,
        "hf_subset": "ell_Grek-pol_Latn",
        "languages": [
          "ell-Grek",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.002313,
        "recall": 0.005008,
        "f1": 0.002488,
        "accuracy": 0.005008,
        "main_score": 0.002488,
        "hf_subset": "ell_Grek-por_Latn",
        "languages": [
          "ell-Grek",
          "por-Latn"
        ]
      },
      {
        "precision": 0.003308,
        "recall": 0.005508,
        "f1": 0.003439,
        "accuracy": 0.005508,
        "main_score": 0.003439,
        "hf_subset": "ell_Grek-rus_Cyrl",
        "languages": [
          "ell-Grek",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.001379,
        "recall": 0.003005,
        "f1": 0.001707,
        "accuracy": 0.003005,
        "main_score": 0.001707,
        "hf_subset": "ell_Grek-spa_Latn",
        "languages": [
          "ell-Grek",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001003,
        "accuracy": 0.001502,
        "main_score": 0.001003,
        "hf_subset": "ell_Grek-sqi_Latn",
        "languages": [
          "ell-Grek",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.001533,
        "recall": 0.004006,
        "f1": 0.001561,
        "accuracy": 0.004006,
        "main_score": 0.001561,
        "hf_subset": "ell_Grek-swa_Latn",
        "languages": [
          "ell-Grek",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.002755,
        "recall": 0.003505,
        "f1": 0.002838,
        "accuracy": 0.003505,
        "main_score": 0.002838,
        "hf_subset": "ell_Grek-swe_Latn",
        "languages": [
          "ell-Grek",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000253,
        "recall": 0.001502,
        "f1": 0.000339,
        "accuracy": 0.001502,
        "main_score": 0.000339,
        "hf_subset": "ell_Grek-tam_Taml",
        "languages": [
          "ell-Grek",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002006,
        "recall": 0.003505,
        "f1": 0.002176,
        "accuracy": 0.003505,
        "main_score": 0.002176,
        "hf_subset": "ell_Grek-tur_Latn",
        "languages": [
          "ell-Grek",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001775,
        "recall": 0.005008,
        "f1": 0.001951,
        "accuracy": 0.005008,
        "main_score": 0.001951,
        "hf_subset": "ell_Grek-vie_Latn",
        "languages": [
          "ell-Grek",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001504,
        "recall": 0.002504,
        "f1": 0.001506,
        "accuracy": 0.002504,
        "main_score": 0.001506,
        "hf_subset": "ell_Grek-zho_Hant",
        "languages": [
          "ell-Grek",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.002797,
        "recall": 0.005508,
        "f1": 0.002921,
        "accuracy": 0.005508,
        "main_score": 0.002921,
        "hf_subset": "ell_Grek-zul_Latn",
        "languages": [
          "ell-Grek",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.025781,
        "recall": 0.04006,
        "f1": 0.028059,
        "accuracy": 0.04006,
        "main_score": 0.028059,
        "hf_subset": "eng_Latn-afr_Latn",
        "languages": [
          "eng-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.001294,
        "recall": 0.002504,
        "f1": 0.001453,
        "accuracy": 0.002504,
        "main_score": 0.001453,
        "hf_subset": "eng_Latn-amh_Ethi",
        "languages": [
          "eng-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.002103,
        "recall": 0.003005,
        "f1": 0.00217,
        "accuracy": 0.003005,
        "main_score": 0.00217,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001282,
        "recall": 0.003505,
        "f1": 0.001471,
        "accuracy": 0.003505,
        "main_score": 0.001471,
        "hf_subset": "eng_Latn-aze_Latn",
        "languages": [
          "eng-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.001089,
        "recall": 0.003005,
        "f1": 0.001153,
        "accuracy": 0.003005,
        "main_score": 0.001153,
        "hf_subset": "eng_Latn-bak_Cyrl",
        "languages": [
          "eng-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.000134,
        "recall": 0.001502,
        "f1": 0.000237,
        "accuracy": 0.001502,
        "main_score": 0.000237,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.009982,
        "recall": 0.016525,
        "f1": 0.010928,
        "accuracy": 0.016525,
        "main_score": 0.010928,
        "hf_subset": "eng_Latn-bem_Latn",
        "languages": [
          "eng-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.001137,
        "recall": 0.003505,
        "f1": 0.001223,
        "accuracy": 0.003505,
        "main_score": 0.001223,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001502,
        "f1": 1.1e-05,
        "accuracy": 0.001502,
        "main_score": 1.1e-05,
        "hf_subset": "eng_Latn-bod_Tibt",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.010056,
        "recall": 0.015523,
        "f1": 0.010793,
        "accuracy": 0.015523,
        "main_score": 0.010793,
        "hf_subset": "eng_Latn-bos_Latn",
        "languages": [
          "eng-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.001002,
        "f1": 0.000251,
        "accuracy": 0.001002,
        "main_score": 0.000251,
        "hf_subset": "eng_Latn-bul_Cyrl",
        "languages": [
          "eng-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.06101,
        "recall": 0.079119,
        "f1": 0.064287,
        "accuracy": 0.079119,
        "main_score": 0.064287,
        "hf_subset": "eng_Latn-cat_Latn",
        "languages": [
          "eng-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.005298,
        "recall": 0.012519,
        "f1": 0.006007,
        "accuracy": 0.012519,
        "main_score": 0.006007,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.001502,
        "f1": 1.7e-05,
        "accuracy": 0.001502,
        "main_score": 1.7e-05,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.014925,
        "recall": 0.023035,
        "f1": 0.016034,
        "accuracy": 0.023035,
        "main_score": 0.016034,
        "hf_subset": "eng_Latn-cym_Latn",
        "languages": [
          "eng-Latn",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.032932,
        "recall": 0.045568,
        "f1": 0.034914,
        "accuracy": 0.045568,
        "main_score": 0.034914,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.022532,
        "recall": 0.032048,
        "f1": 0.023629,
        "accuracy": 0.032048,
        "main_score": 0.023629,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001502,
        "f1": 1.4e-05,
        "accuracy": 0.001502,
        "main_score": 1.4e-05,
        "hf_subset": "eng_Latn-div_Thaa",
        "languages": [
          "eng-Latn",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-dzo_Tibt",
        "languages": [
          "eng-Latn",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-ell_Grek",
        "languages": [
          "eng-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.000787,
        "recall": 0.004507,
        "f1": 0.000969,
        "accuracy": 0.004507,
        "main_score": 0.000969,
        "hf_subset": "eng_Latn-eus_Latn",
        "languages": [
          "eng-Latn",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.013695,
        "recall": 0.021032,
        "f1": 0.014881,
        "accuracy": 0.021032,
        "main_score": 0.014881,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.013667,
        "recall": 0.022033,
        "f1": 0.014895,
        "accuracy": 0.022033,
        "main_score": 0.014895,
        "hf_subset": "eng_Latn-fao_Latn",
        "languages": [
          "eng-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.000603,
        "recall": 0.002003,
        "f1": 0.000672,
        "accuracy": 0.002003,
        "main_score": 0.000672,
        "hf_subset": "eng_Latn-fas_Arab",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.008003,
        "recall": 0.012519,
        "f1": 0.008315,
        "accuracy": 0.012519,
        "main_score": 0.008315,
        "hf_subset": "eng_Latn-fij_Latn",
        "languages": [
          "eng-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.021434,
        "recall": 0.034051,
        "f1": 0.0234,
        "accuracy": 0.034051,
        "main_score": 0.0234,
        "hf_subset": "eng_Latn-fil_Latn",
        "languages": [
          "eng-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.006624,
        "recall": 0.01302,
        "f1": 0.007278,
        "accuracy": 0.01302,
        "main_score": 0.007278,
        "hf_subset": "eng_Latn-fin_Latn",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.214736,
        "recall": 0.251878,
        "f1": 0.222559,
        "accuracy": 0.251878,
        "main_score": 0.222559,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.026306,
        "recall": 0.047071,
        "f1": 0.02888,
        "accuracy": 0.047071,
        "main_score": 0.02888,
        "hf_subset": "eng_Latn-fuc_Latn",
        "languages": [
          "eng-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.009283,
        "recall": 0.015523,
        "f1": 0.010044,
        "accuracy": 0.015523,
        "main_score": 0.010044,
        "hf_subset": "eng_Latn-gle_Latn",
        "languages": [
          "eng-Latn",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.194968,
        "recall": 0.232849,
        "f1": 0.20264,
        "accuracy": 0.232849,
        "main_score": 0.20264,
        "hf_subset": "eng_Latn-glg_Latn",
        "languages": [
          "eng-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 7.4e-05,
        "recall": 0.001502,
        "f1": 0.000133,
        "accuracy": 0.001502,
        "main_score": 0.000133,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.017194,
        "recall": 0.029544,
        "f1": 0.01881,
        "accuracy": 0.029544,
        "main_score": 0.01881,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.001566,
        "recall": 0.003005,
        "f1": 0.001616,
        "accuracy": 0.003005,
        "main_score": 0.001616,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000622,
        "recall": 0.002003,
        "f1": 0.000708,
        "accuracy": 0.002003,
        "main_score": 0.000708,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.013305,
        "recall": 0.024537,
        "f1": 0.014746,
        "accuracy": 0.024537,
        "main_score": 0.014746,
        "hf_subset": "eng_Latn-hmn_Latn",
        "languages": [
          "eng-Latn",
          "hmn-Latn"
        ]
      },
      {
        "precision": 0.007294,
        "recall": 0.01352,
        "f1": 0.007801,
        "accuracy": 0.01352,
        "main_score": 0.007801,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.005805,
        "recall": 0.010516,
        "f1": 0.006246,
        "accuracy": 0.010516,
        "main_score": 0.006246,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "eng_Latn-hye_Armn",
        "languages": [
          "eng-Latn",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.006426,
        "recall": 0.010516,
        "f1": 0.006867,
        "accuracy": 0.010516,
        "main_score": 0.006867,
        "hf_subset": "eng_Latn-ibo_Latn",
        "languages": [
          "eng-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.031314,
        "recall": 0.043065,
        "f1": 0.033255,
        "accuracy": 0.043065,
        "main_score": 0.033255,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.006879,
        "recall": 0.012519,
        "f1": 0.007519,
        "accuracy": 0.012519,
        "main_score": 0.007519,
        "hf_subset": "eng_Latn-isl_Latn",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.128829,
        "recall": 0.163746,
        "f1": 0.136132,
        "accuracy": 0.163746,
        "main_score": 0.136132,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001502,
        "f1": 3e-05,
        "accuracy": 0.001502,
        "main_score": 3e-05,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001002,
        "f1": 1e-05,
        "accuracy": 0.001002,
        "main_score": 1e-05,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000672,
        "recall": 0.002003,
        "f1": 0.000759,
        "accuracy": 0.002003,
        "main_score": 0.000759,
        "hf_subset": "eng_Latn-kat_Geor",
        "languages": [
          "eng-Latn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-kaz_Cyrl",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "eng_Latn-khm_Khmr",
        "languages": [
          "eng-Latn",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.003115,
        "recall": 0.00651,
        "f1": 0.003585,
        "accuracy": 0.00651,
        "main_score": 0.003585,
        "hf_subset": "eng_Latn-kin_Latn",
        "languages": [
          "eng-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.001002,
        "f1": 3.4e-05,
        "accuracy": 0.001002,
        "main_score": 3.4e-05,
        "hf_subset": "eng_Latn-kir_Cyrl",
        "languages": [
          "eng-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.009079,
        "recall": 0.015523,
        "f1": 0.010021,
        "accuracy": 0.015523,
        "main_score": 0.010021,
        "hf_subset": "eng_Latn-kmr_Latn",
        "languages": [
          "eng-Latn",
          "kmr-Latn"
        ]
      },
      {
        "precision": 3e-05,
        "recall": 0.001002,
        "f1": 5.6e-05,
        "accuracy": 0.001002,
        "main_score": 5.6e-05,
        "hf_subset": "eng_Latn-kor_Hang",
        "languages": [
          "eng-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-lao_Laoo",
        "languages": [
          "eng-Latn",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.002742,
        "recall": 0.006009,
        "f1": 0.00313,
        "accuracy": 0.006009,
        "main_score": 0.00313,
        "hf_subset": "eng_Latn-lav_Latn",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.005512,
        "recall": 0.011017,
        "f1": 0.006009,
        "accuracy": 0.011017,
        "main_score": 0.006009,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.025033,
        "recall": 0.037056,
        "f1": 0.027209,
        "accuracy": 0.037056,
        "main_score": 0.027209,
        "hf_subset": "eng_Latn-ltz_Latn",
        "languages": [
          "eng-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 9.6e-05,
        "recall": 0.001502,
        "f1": 0.000175,
        "accuracy": 0.001502,
        "main_score": 0.000175,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 9.7e-05,
        "recall": 0.002003,
        "f1": 0.000169,
        "accuracy": 0.002003,
        "main_score": 0.000169,
        "hf_subset": "eng_Latn-mey_Arab",
        "languages": [
          "eng-Latn",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.000716,
        "recall": 0.003005,
        "f1": 0.000843,
        "accuracy": 0.003005,
        "main_score": 0.000843,
        "hf_subset": "eng_Latn-mkd_Cyrl",
        "languages": [
          "eng-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.012019,
        "recall": 0.021032,
        "f1": 0.013297,
        "accuracy": 0.021032,
        "main_score": 0.013297,
        "hf_subset": "eng_Latn-mlg_Latn",
        "languages": [
          "eng-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.016072,
        "recall": 0.027541,
        "f1": 0.017704,
        "accuracy": 0.027541,
        "main_score": 0.017704,
        "hf_subset": "eng_Latn-mlt_Latn",
        "languages": [
          "eng-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 2e-05,
        "recall": 0.002003,
        "f1": 3.9e-05,
        "accuracy": 0.002003,
        "main_score": 3.9e-05,
        "hf_subset": "eng_Latn-mon_Mong",
        "languages": [
          "eng-Latn",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.00697,
        "recall": 0.010015,
        "f1": 0.007417,
        "accuracy": 0.010015,
        "main_score": 0.007417,
        "hf_subset": "eng_Latn-mri_Latn",
        "languages": [
          "eng-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.023757,
        "recall": 0.034051,
        "f1": 0.025338,
        "accuracy": 0.034051,
        "main_score": 0.025338,
        "hf_subset": "eng_Latn-msa_Latn",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-mya_Mymr",
        "languages": [
          "eng-Latn",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.00825,
        "recall": 0.01302,
        "f1": 0.009003,
        "accuracy": 0.01302,
        "main_score": 0.009003,
        "hf_subset": "eng_Latn-nde_Latn",
        "languages": [
          "eng-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.003481,
        "recall": 0.006009,
        "f1": 0.003862,
        "accuracy": 0.006009,
        "main_score": 0.003862,
        "hf_subset": "eng_Latn-nep_Deva",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.0379,
        "recall": 0.054582,
        "f1": 0.040528,
        "accuracy": 0.054582,
        "main_score": 0.040528,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.031413,
        "recall": 0.049074,
        "f1": 0.03361,
        "accuracy": 0.049074,
        "main_score": 0.03361,
        "hf_subset": "eng_Latn-nno_Latn",
        "languages": [
          "eng-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.030813,
        "recall": 0.04657,
        "f1": 0.033083,
        "accuracy": 0.04657,
        "main_score": 0.033083,
        "hf_subset": "eng_Latn-nob_Latn",
        "languages": [
          "eng-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.019625,
        "recall": 0.030546,
        "f1": 0.020929,
        "accuracy": 0.030546,
        "main_score": 0.020929,
        "hf_subset": "eng_Latn-nso_Latn",
        "languages": [
          "eng-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.010134,
        "recall": 0.018528,
        "f1": 0.011306,
        "accuracy": 0.018528,
        "main_score": 0.011306,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.008762,
        "recall": 0.018027,
        "f1": 0.009858,
        "accuracy": 0.018027,
        "main_score": 0.009858,
        "hf_subset": "eng_Latn-orm_Ethi",
        "languages": [
          "eng-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 2e-05,
        "recall": 0.001002,
        "f1": 3.9e-05,
        "accuracy": 0.001002,
        "main_score": 3.9e-05,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.006141,
        "recall": 0.011517,
        "f1": 0.006629,
        "accuracy": 0.011517,
        "main_score": 0.006629,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.129558,
        "recall": 0.15974,
        "f1": 0.135285,
        "accuracy": 0.15974,
        "main_score": 0.135285,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-prs_Arab",
        "languages": [
          "eng-Latn",
          "prs-Arab"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.3e-05,
        "accuracy": 0.001002,
        "main_score": 1.3e-05,
        "hf_subset": "eng_Latn-pus_Arab",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.045719,
        "recall": 0.066099,
        "f1": 0.049062,
        "accuracy": 0.066099,
        "main_score": 0.049062,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.000565,
        "recall": 0.002003,
        "f1": 0.00062,
        "accuracy": 0.002003,
        "main_score": 0.00062,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-shi_Arab",
        "languages": [
          "eng-Latn",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.000183,
        "recall": 0.002504,
        "f1": 0.000283,
        "accuracy": 0.002504,
        "main_score": 0.000283,
        "hf_subset": "eng_Latn-sin_Sinh",
        "languages": [
          "eng-Latn",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.005576,
        "recall": 0.011517,
        "f1": 0.006339,
        "accuracy": 0.011517,
        "main_score": 0.006339,
        "hf_subset": "eng_Latn-slk_Latn",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.009181,
        "recall": 0.015523,
        "f1": 0.009982,
        "accuracy": 0.015523,
        "main_score": 0.009982,
        "hf_subset": "eng_Latn-slv_Latn",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.012302,
        "recall": 0.020531,
        "f1": 0.013184,
        "accuracy": 0.020531,
        "main_score": 0.013184,
        "hf_subset": "eng_Latn-smo_Latn",
        "languages": [
          "eng-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.008703,
        "recall": 0.01352,
        "f1": 0.009235,
        "accuracy": 0.01352,
        "main_score": 0.009235,
        "hf_subset": "eng_Latn-sna_Latn",
        "languages": [
          "eng-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.000102,
        "recall": 0.001502,
        "f1": 0.00017,
        "accuracy": 0.001502,
        "main_score": 0.00017,
        "hf_subset": "eng_Latn-snd_Arab",
        "languages": [
          "eng-Latn",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.0181,
        "recall": 0.027541,
        "f1": 0.019761,
        "accuracy": 0.027541,
        "main_score": 0.019761,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.247329,
        "recall": 0.288933,
        "f1": 0.256259,
        "accuracy": 0.288933,
        "main_score": 0.256259,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.018352,
        "recall": 0.02654,
        "f1": 0.019471,
        "accuracy": 0.02654,
        "main_score": 0.019471,
        "hf_subset": "eng_Latn-sqi_Latn",
        "languages": [
          "eng-Latn",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.000101,
        "recall": 0.001502,
        "f1": 0.000169,
        "accuracy": 0.001502,
        "main_score": 0.000169,
        "hf_subset": "eng_Latn-srp_Cyrl",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.003298,
        "recall": 0.006009,
        "f1": 0.003692,
        "accuracy": 0.006009,
        "main_score": 0.003692,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.011965,
        "recall": 0.017526,
        "f1": 0.012525,
        "accuracy": 0.017526,
        "main_score": 0.012525,
        "hf_subset": "eng_Latn-ssw_Latn",
        "languages": [
          "eng-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.008456,
        "recall": 0.014021,
        "f1": 0.00915,
        "accuracy": 0.014021,
        "main_score": 0.00915,
        "hf_subset": "eng_Latn-swa_Latn",
        "languages": [
          "eng-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.024938,
        "recall": 0.037056,
        "f1": 0.026548,
        "accuracy": 0.037056,
        "main_score": 0.026548,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.009452,
        "recall": 0.015023,
        "f1": 0.010023,
        "accuracy": 0.015023,
        "main_score": 0.010023,
        "hf_subset": "eng_Latn-tah_Latn",
        "languages": [
          "eng-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 6.1e-05,
        "recall": 0.002003,
        "f1": 0.000115,
        "accuracy": 0.002003,
        "main_score": 0.000115,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001002,
        "f1": 1.4e-05,
        "accuracy": 0.001002,
        "main_score": 1.4e-05,
        "hf_subset": "eng_Latn-tat_Cyrl",
        "languages": [
          "eng-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.000537,
        "recall": 0.002003,
        "f1": 0.000569,
        "accuracy": 0.002003,
        "main_score": 0.000569,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "eng_Latn-tir_Ethi",
        "languages": [
          "eng-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.004594,
        "recall": 0.007511,
        "f1": 0.004941,
        "accuracy": 0.007511,
        "main_score": 0.004941,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.019236,
        "recall": 0.031047,
        "f1": 0.020858,
        "accuracy": 0.031047,
        "main_score": 0.020858,
        "hf_subset": "eng_Latn-tsn_Latn",
        "languages": [
          "eng-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.00445,
        "recall": 0.009514,
        "f1": 0.004912,
        "accuracy": 0.009514,
        "main_score": 0.004912,
        "hf_subset": "eng_Latn-tuk_Latn",
        "languages": [
          "eng-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.003501,
        "recall": 0.008012,
        "f1": 0.003743,
        "accuracy": 0.008012,
        "main_score": 0.003743,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000263,
        "recall": 0.002003,
        "f1": 0.000358,
        "accuracy": 0.002003,
        "main_score": 0.000358,
        "hf_subset": "eng_Latn-uig_Arab",
        "languages": [
          "eng-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 8e-06,
        "recall": 0.001002,
        "f1": 1.6e-05,
        "accuracy": 0.001002,
        "main_score": 1.6e-05,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.005518,
        "recall": 0.011517,
        "f1": 0.006046,
        "accuracy": 0.011517,
        "main_score": 0.006046,
        "hf_subset": "eng_Latn-uzb_Latn",
        "languages": [
          "eng-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.010824,
        "recall": 0.019029,
        "f1": 0.01164,
        "accuracy": 0.019029,
        "main_score": 0.01164,
        "hf_subset": "eng_Latn-ven_Latn",
        "languages": [
          "eng-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.039465,
        "recall": 0.061092,
        "f1": 0.043022,
        "accuracy": 0.061092,
        "main_score": 0.043022,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.011004,
        "recall": 0.018027,
        "f1": 0.011734,
        "accuracy": 0.018027,
        "main_score": 0.011734,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.009032,
        "recall": 0.016024,
        "f1": 0.009902,
        "accuracy": 0.016024,
        "main_score": 0.009902,
        "hf_subset": "eng_Latn-xho_Latn",
        "languages": [
          "eng-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.006391,
        "recall": 0.011017,
        "f1": 0.007057,
        "accuracy": 0.011017,
        "main_score": 0.007057,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "eng_Latn-yue_Hant",
        "languages": [
          "eng-Latn",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.003127,
        "recall": 0.006009,
        "f1": 0.00345,
        "accuracy": 0.006009,
        "main_score": 0.00345,
        "hf_subset": "eng_Latn-zho_Hans",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.001395,
        "recall": 0.004006,
        "f1": 0.001571,
        "accuracy": 0.004006,
        "main_score": 0.001571,
        "hf_subset": "eng_Latn-zho_Hant",
        "languages": [
          "eng-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.010471,
        "recall": 0.019029,
        "f1": 0.011426,
        "accuracy": 0.019029,
        "main_score": 0.011426,
        "hf_subset": "eng_Latn-zul_Latn",
        "languages": [
          "eng-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.004568,
        "recall": 0.010516,
        "f1": 0.005087,
        "accuracy": 0.010516,
        "main_score": 0.005087,
        "hf_subset": "eus_Latn-ben_Beng",
        "languages": [
          "eus-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 3e-05,
        "recall": 0.002003,
        "f1": 5.8e-05,
        "accuracy": 0.002003,
        "main_score": 5.8e-05,
        "hf_subset": "eus_Latn-div_Thaa",
        "languages": [
          "eus-Latn",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.025283,
        "recall": 0.03355,
        "f1": 0.026443,
        "accuracy": 0.03355,
        "main_score": 0.026443,
        "hf_subset": "eus_Latn-eng_Latn",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001831,
        "recall": 0.005008,
        "f1": 0.002025,
        "accuracy": 0.005008,
        "main_score": 0.002025,
        "hf_subset": "eus_Latn-guj_Gujr",
        "languages": [
          "eus-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002076,
        "recall": 0.003505,
        "f1": 0.002131,
        "accuracy": 0.003505,
        "main_score": 0.002131,
        "hf_subset": "eus_Latn-hin_Deva",
        "languages": [
          "eus-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003719,
        "recall": 0.006009,
        "f1": 0.003846,
        "accuracy": 0.006009,
        "main_score": 0.003846,
        "hf_subset": "eus_Latn-kan_Knda",
        "languages": [
          "eus-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00108,
        "recall": 0.002003,
        "f1": 0.001148,
        "accuracy": 0.002003,
        "main_score": 0.001148,
        "hf_subset": "eus_Latn-mar_Deva",
        "languages": [
          "eus-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003509,
        "recall": 0.011517,
        "f1": 0.004224,
        "accuracy": 0.011517,
        "main_score": 0.004224,
        "hf_subset": "eus_Latn-nep_Deva",
        "languages": [
          "eus-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.00466,
        "recall": 0.009014,
        "f1": 0.0052,
        "accuracy": 0.009014,
        "main_score": 0.0052,
        "hf_subset": "eus_Latn-pan_Guru",
        "languages": [
          "eus-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00015,
        "recall": 0.001002,
        "f1": 0.000258,
        "accuracy": 0.001002,
        "main_score": 0.000258,
        "hf_subset": "eus_Latn-sin_Sinh",
        "languages": [
          "eus-Latn",
          "sin-Sinh"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "eus_Latn-snd_Arab",
        "languages": [
          "eus-Latn",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000514,
        "recall": 0.002504,
        "f1": 0.000695,
        "accuracy": 0.002504,
        "main_score": 0.000695,
        "hf_subset": "eus_Latn-tam_Taml",
        "languages": [
          "eus-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000506,
        "accuracy": 0.001502,
        "main_score": 0.000506,
        "hf_subset": "eus_Latn-tel_Telu",
        "languages": [
          "eus-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001698,
        "recall": 0.004507,
        "f1": 0.001809,
        "accuracy": 0.004507,
        "main_score": 0.001809,
        "hf_subset": "eus_Latn-urd_Arab",
        "languages": [
          "eus-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.04506,
        "recall": 0.06009,
        "f1": 0.048079,
        "accuracy": 0.06009,
        "main_score": 0.048079,
        "hf_subset": "ewe_Latn-bem_Latn",
        "languages": [
          "ewe-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.027523,
        "recall": 0.036555,
        "f1": 0.028896,
        "accuracy": 0.036555,
        "main_score": 0.028896,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.074818,
        "recall": 0.088633,
        "f1": 0.07778,
        "accuracy": 0.088633,
        "main_score": 0.07778,
        "hf_subset": "ewe_Latn-fuc_Latn",
        "languages": [
          "ewe-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.011699,
        "recall": 0.018528,
        "f1": 0.012582,
        "accuracy": 0.018528,
        "main_score": 0.012582,
        "hf_subset": "ewe_Latn-kin_Latn",
        "languages": [
          "ewe-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.033899,
        "recall": 0.05358,
        "f1": 0.037089,
        "accuracy": 0.05358,
        "main_score": 0.037089,
        "hf_subset": "ewe_Latn-nde_Latn",
        "languages": [
          "ewe-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.054569,
        "recall": 0.075613,
        "f1": 0.058755,
        "accuracy": 0.075613,
        "main_score": 0.058755,
        "hf_subset": "ewe_Latn-nya_Latn",
        "languages": [
          "ewe-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.052374,
        "recall": 0.078618,
        "f1": 0.057604,
        "accuracy": 0.078618,
        "main_score": 0.057604,
        "hf_subset": "ewe_Latn-sna_Latn",
        "languages": [
          "ewe-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.063719,
        "recall": 0.088132,
        "f1": 0.069713,
        "accuracy": 0.088132,
        "main_score": 0.069713,
        "hf_subset": "ewe_Latn-ven_Latn",
        "languages": [
          "ewe-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.034055,
        "recall": 0.038558,
        "f1": 0.034853,
        "accuracy": 0.038558,
        "main_score": 0.034853,
        "hf_subset": "fao_Latn-afr_Latn",
        "languages": [
          "fao-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.117848,
        "recall": 0.144717,
        "f1": 0.122459,
        "accuracy": 0.144717,
        "main_score": 0.122459,
        "hf_subset": "fao_Latn-dan_Latn",
        "languages": [
          "fao-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.030477,
        "recall": 0.037556,
        "f1": 0.031515,
        "accuracy": 0.037556,
        "main_score": 0.031515,
        "hf_subset": "fao_Latn-deu_Latn",
        "languages": [
          "fao-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.01788,
        "recall": 0.023035,
        "f1": 0.018504,
        "accuracy": 0.023035,
        "main_score": 0.018504,
        "hf_subset": "fao_Latn-eng_Latn",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.295175,
        "recall": 0.363045,
        "f1": 0.311162,
        "accuracy": 0.363045,
        "main_score": 0.311162,
        "hf_subset": "fao_Latn-isl_Latn",
        "languages": [
          "fao-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.028982,
        "recall": 0.034552,
        "f1": 0.029466,
        "accuracy": 0.034552,
        "main_score": 0.029466,
        "hf_subset": "fao_Latn-ltz_Latn",
        "languages": [
          "fao-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.032816,
        "recall": 0.038558,
        "f1": 0.033731,
        "accuracy": 0.038558,
        "main_score": 0.033731,
        "hf_subset": "fao_Latn-nld_Latn",
        "languages": [
          "fao-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.141472,
        "recall": 0.171758,
        "f1": 0.148156,
        "accuracy": 0.171758,
        "main_score": 0.148156,
        "hf_subset": "fao_Latn-nno_Latn",
        "languages": [
          "fao-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.127255,
        "recall": 0.152228,
        "f1": 0.132788,
        "accuracy": 0.152228,
        "main_score": 0.132788,
        "hf_subset": "fao_Latn-nob_Latn",
        "languages": [
          "fao-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.129573,
        "recall": 0.155734,
        "f1": 0.135032,
        "accuracy": 0.155734,
        "main_score": 0.135032,
        "hf_subset": "fao_Latn-swe_Latn",
        "languages": [
          "fao-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.004864,
        "recall": 0.011517,
        "f1": 0.005277,
        "accuracy": 0.011517,
        "main_score": 0.005277,
        "hf_subset": "fas_Arab-arb_Arab",
        "languages": [
          "fas-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001134,
        "recall": 0.002504,
        "f1": 0.001217,
        "accuracy": 0.002504,
        "main_score": 0.001217,
        "hf_subset": "fas_Arab-ben_Beng",
        "languages": [
          "fas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001476,
        "recall": 0.005508,
        "f1": 0.00177,
        "accuracy": 0.005508,
        "main_score": 0.00177,
        "hf_subset": "fas_Arab-ckb_Arab",
        "languages": [
          "fas-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.00875,
        "recall": 0.012519,
        "f1": 0.00923,
        "accuracy": 0.012519,
        "main_score": 0.00923,
        "hf_subset": "fas_Arab-deu_Latn",
        "languages": [
          "fas-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0018,
        "recall": 0.004006,
        "f1": 0.001984,
        "accuracy": 0.004006,
        "main_score": 0.001984,
        "hf_subset": "fas_Arab-ell_Grek",
        "languages": [
          "fas-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.006687,
        "recall": 0.011017,
        "f1": 0.006991,
        "accuracy": 0.011017,
        "main_score": 0.006991,
        "hf_subset": "fas_Arab-eng_Latn",
        "languages": [
          "fas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002066,
        "recall": 0.002504,
        "f1": 0.002114,
        "accuracy": 0.002504,
        "main_score": 0.002114,
        "hf_subset": "fas_Arab-fin_Latn",
        "languages": [
          "fas-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.010658,
        "recall": 0.014522,
        "f1": 0.011192,
        "accuracy": 0.014522,
        "main_score": 0.011192,
        "hf_subset": "fas_Arab-fra_Latn",
        "languages": [
          "fas-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "fas_Arab-heb_Hebr",
        "languages": [
          "fas-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001502,
        "recall": 0.001502,
        "f1": 0.001502,
        "accuracy": 0.001502,
        "main_score": 0.001502,
        "hf_subset": "fas_Arab-hin_Deva",
        "languages": [
          "fas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004404,
        "recall": 0.007011,
        "f1": 0.004584,
        "accuracy": 0.007011,
        "main_score": 0.004584,
        "hf_subset": "fas_Arab-hun_Latn",
        "languages": [
          "fas-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.00757,
        "recall": 0.009514,
        "f1": 0.007828,
        "accuracy": 0.009514,
        "main_score": 0.007828,
        "hf_subset": "fas_Arab-ind_Latn",
        "languages": [
          "fas-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001254,
        "recall": 0.002504,
        "f1": 0.00134,
        "accuracy": 0.002504,
        "main_score": 0.00134,
        "hf_subset": "fas_Arab-jpn_Jpan",
        "languages": [
          "fas-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002086,
        "recall": 0.002504,
        "f1": 0.002146,
        "accuracy": 0.002504,
        "main_score": 0.002146,
        "hf_subset": "fas_Arab-kmr_Latn",
        "languages": [
          "fas-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.002933,
        "recall": 0.005008,
        "f1": 0.003139,
        "accuracy": 0.005008,
        "main_score": 0.003139,
        "hf_subset": "fas_Arab-kor_Hang",
        "languages": [
          "fas-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.004678,
        "recall": 0.007011,
        "f1": 0.004812,
        "accuracy": 0.007011,
        "main_score": 0.004812,
        "hf_subset": "fas_Arab-lit_Latn",
        "languages": [
          "fas-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.00025,
        "recall": 0.000501,
        "f1": 0.000334,
        "accuracy": 0.000501,
        "main_score": 0.000334,
        "hf_subset": "fas_Arab-mey_Arab",
        "languages": [
          "fas-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.009632,
        "recall": 0.012519,
        "f1": 0.009913,
        "accuracy": 0.012519,
        "main_score": 0.009913,
        "hf_subset": "fas_Arab-nld_Latn",
        "languages": [
          "fas-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.007415,
        "recall": 0.009514,
        "f1": 0.007639,
        "accuracy": 0.009514,
        "main_score": 0.007639,
        "hf_subset": "fas_Arab-pol_Latn",
        "languages": [
          "fas-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.011275,
        "recall": 0.015523,
        "f1": 0.011669,
        "accuracy": 0.015523,
        "main_score": 0.011669,
        "hf_subset": "fas_Arab-por_Latn",
        "languages": [
          "fas-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.311829,
        "recall": 0.391587,
        "f1": 0.332405,
        "accuracy": 0.391587,
        "main_score": 0.332405,
        "hf_subset": "fas_Arab-prs_Arab",
        "languages": [
          "fas-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.009403,
        "recall": 0.01352,
        "f1": 0.010094,
        "accuracy": 0.01352,
        "main_score": 0.010094,
        "hf_subset": "fas_Arab-pus_Arab",
        "languages": [
          "fas-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.002733,
        "recall": 0.005508,
        "f1": 0.003091,
        "accuracy": 0.005508,
        "main_score": 0.003091,
        "hf_subset": "fas_Arab-rus_Cyrl",
        "languages": [
          "fas-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "fas_Arab-shi_Arab",
        "languages": [
          "fas-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.009277,
        "recall": 0.012519,
        "f1": 0.009637,
        "accuracy": 0.012519,
        "main_score": 0.009637,
        "hf_subset": "fas_Arab-spa_Latn",
        "languages": [
          "fas-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.004173,
        "recall": 0.005008,
        "f1": 0.004257,
        "accuracy": 0.005008,
        "main_score": 0.004257,
        "hf_subset": "fas_Arab-swa_Latn",
        "languages": [
          "fas-Arab",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.003505,
        "recall": 0.003505,
        "f1": 0.003505,
        "accuracy": 0.003505,
        "main_score": 0.003505,
        "hf_subset": "fas_Arab-swe_Latn",
        "languages": [
          "fas-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001043,
        "recall": 0.002003,
        "f1": 0.001285,
        "accuracy": 0.002003,
        "main_score": 0.001285,
        "hf_subset": "fas_Arab-tam_Taml",
        "languages": [
          "fas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 3.7e-05,
        "recall": 0.001502,
        "f1": 6.9e-05,
        "accuracy": 0.001502,
        "main_score": 6.9e-05,
        "hf_subset": "fas_Arab-tgk_Cyrl",
        "languages": [
          "fas-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.002805,
        "recall": 0.004507,
        "f1": 0.003102,
        "accuracy": 0.004507,
        "main_score": 0.003102,
        "hf_subset": "fas_Arab-tur_Latn",
        "languages": [
          "fas-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.011873,
        "recall": 0.015023,
        "f1": 0.012274,
        "accuracy": 0.015023,
        "main_score": 0.012274,
        "hf_subset": "fas_Arab-vie_Latn",
        "languages": [
          "fas-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.003319,
        "recall": 0.005008,
        "f1": 0.003453,
        "accuracy": 0.005008,
        "main_score": 0.003453,
        "hf_subset": "fas_Arab-zho_Hant",
        "languages": [
          "fas-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.004175,
        "recall": 0.005008,
        "f1": 0.00426,
        "accuracy": 0.005008,
        "main_score": 0.00426,
        "hf_subset": "fas_Arab-zul_Latn",
        "languages": [
          "fas-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.011889,
        "recall": 0.014522,
        "f1": 0.012226,
        "accuracy": 0.014522,
        "main_score": 0.012226,
        "hf_subset": "fij_Latn-eng_Latn",
        "languages": [
          "fij-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016338,
        "recall": 0.025038,
        "f1": 0.017496,
        "accuracy": 0.025038,
        "main_score": 0.017496,
        "hf_subset": "fij_Latn-fil_Latn",
        "languages": [
          "fij-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.00397,
        "recall": 0.007011,
        "f1": 0.004203,
        "accuracy": 0.007011,
        "main_score": 0.004203,
        "hf_subset": "fij_Latn-ind_Latn",
        "languages": [
          "fij-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "fij_Latn-mal_Mlym",
        "languages": [
          "fij-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.022192,
        "recall": 0.029044,
        "f1": 0.023278,
        "accuracy": 0.029044,
        "main_score": 0.023278,
        "hf_subset": "fij_Latn-mlg_Latn",
        "languages": [
          "fij-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.02427,
        "recall": 0.032549,
        "f1": 0.025662,
        "accuracy": 0.032549,
        "main_score": 0.025662,
        "hf_subset": "fij_Latn-mri_Latn",
        "languages": [
          "fij-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.003144,
        "recall": 0.007511,
        "f1": 0.003435,
        "accuracy": 0.007511,
        "main_score": 0.003435,
        "hf_subset": "fij_Latn-msa_Latn",
        "languages": [
          "fij-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.037186,
        "recall": 0.043065,
        "f1": 0.038461,
        "accuracy": 0.043065,
        "main_score": 0.038461,
        "hf_subset": "fij_Latn-smo_Latn",
        "languages": [
          "fij-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.02461,
        "recall": 0.035053,
        "f1": 0.026259,
        "accuracy": 0.035053,
        "main_score": 0.026259,
        "hf_subset": "fij_Latn-tah_Latn",
        "languages": [
          "fij-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.007864,
        "recall": 0.012018,
        "f1": 0.008308,
        "accuracy": 0.012018,
        "main_score": 0.008308,
        "hf_subset": "fij_Latn-ton_Latn",
        "languages": [
          "fij-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.058651,
        "recall": 0.071107,
        "f1": 0.060555,
        "accuracy": 0.071107,
        "main_score": 0.060555,
        "hf_subset": "fil_Latn-eng_Latn",
        "languages": [
          "fil-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022369,
        "recall": 0.032549,
        "f1": 0.02414,
        "accuracy": 0.032549,
        "main_score": 0.02414,
        "hf_subset": "fil_Latn-fij_Latn",
        "languages": [
          "fil-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.020933,
        "recall": 0.034552,
        "f1": 0.022698,
        "accuracy": 0.034552,
        "main_score": 0.022698,
        "hf_subset": "fil_Latn-ind_Latn",
        "languages": [
          "fil-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.3e-05,
        "accuracy": 0.001002,
        "main_score": 1.3e-05,
        "hf_subset": "fil_Latn-mal_Mlym",
        "languages": [
          "fil-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.033735,
        "recall": 0.047571,
        "f1": 0.036019,
        "accuracy": 0.047571,
        "main_score": 0.036019,
        "hf_subset": "fil_Latn-mlg_Latn",
        "languages": [
          "fil-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.029133,
        "recall": 0.038057,
        "f1": 0.030325,
        "accuracy": 0.038057,
        "main_score": 0.030325,
        "hf_subset": "fil_Latn-mri_Latn",
        "languages": [
          "fil-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.016352,
        "recall": 0.024537,
        "f1": 0.017783,
        "accuracy": 0.024537,
        "main_score": 0.017783,
        "hf_subset": "fil_Latn-msa_Latn",
        "languages": [
          "fil-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.022775,
        "recall": 0.030045,
        "f1": 0.024076,
        "accuracy": 0.030045,
        "main_score": 0.024076,
        "hf_subset": "fil_Latn-smo_Latn",
        "languages": [
          "fil-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.025203,
        "recall": 0.032549,
        "f1": 0.026607,
        "accuracy": 0.032549,
        "main_score": 0.026607,
        "hf_subset": "fil_Latn-tah_Latn",
        "languages": [
          "fil-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.013342,
        "recall": 0.018027,
        "f1": 0.014111,
        "accuracy": 0.018027,
        "main_score": 0.014111,
        "hf_subset": "fil_Latn-ton_Latn",
        "languages": [
          "fil-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "fin_Latn-arb_Arab",
        "languages": [
          "fin-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000522,
        "recall": 0.002003,
        "f1": 0.000543,
        "accuracy": 0.002003,
        "main_score": 0.000543,
        "hf_subset": "fin_Latn-ben_Beng",
        "languages": [
          "fin-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.023063,
        "recall": 0.029544,
        "f1": 0.024319,
        "accuracy": 0.029544,
        "main_score": 0.024319,
        "hf_subset": "fin_Latn-deu_Latn",
        "languages": [
          "fin-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 2.7e-05,
        "recall": 0.001502,
        "f1": 5.1e-05,
        "accuracy": 0.001502,
        "main_score": 5.1e-05,
        "hf_subset": "fin_Latn-ell_Grek",
        "languages": [
          "fin-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.01603,
        "recall": 0.023535,
        "f1": 0.017255,
        "accuracy": 0.023535,
        "main_score": 0.017255,
        "hf_subset": "fin_Latn-eng_Latn",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "fin_Latn-fas_Arab",
        "languages": [
          "fin-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.011188,
        "recall": 0.017526,
        "f1": 0.011983,
        "accuracy": 0.017526,
        "main_score": 0.011983,
        "hf_subset": "fin_Latn-fra_Latn",
        "languages": [
          "fin-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000752,
        "recall": 0.002003,
        "f1": 0.000837,
        "accuracy": 0.002003,
        "main_score": 0.000837,
        "hf_subset": "fin_Latn-heb_Hebr",
        "languages": [
          "fin-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "fin_Latn-hin_Deva",
        "languages": [
          "fin-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016037,
        "recall": 0.022033,
        "f1": 0.016914,
        "accuracy": 0.022033,
        "main_score": 0.016914,
        "hf_subset": "fin_Latn-hun_Latn",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.006469,
        "recall": 0.010015,
        "f1": 0.007009,
        "accuracy": 0.010015,
        "main_score": 0.007009,
        "hf_subset": "fin_Latn-ind_Latn",
        "languages": [
          "fin-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "fin_Latn-jpn_Jpan",
        "languages": [
          "fin-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "fin_Latn-kor_Hang",
        "languages": [
          "fin-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.008905,
        "recall": 0.01352,
        "f1": 0.009151,
        "accuracy": 0.01352,
        "main_score": 0.009151,
        "hf_subset": "fin_Latn-lav_Latn",
        "languages": [
          "fin-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.02089,
        "recall": 0.028543,
        "f1": 0.022242,
        "accuracy": 0.028543,
        "main_score": 0.022242,
        "hf_subset": "fin_Latn-lit_Latn",
        "languages": [
          "fin-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.027212,
        "recall": 0.032549,
        "f1": 0.028125,
        "accuracy": 0.032549,
        "main_score": 0.028125,
        "hf_subset": "fin_Latn-nld_Latn",
        "languages": [
          "fin-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.013198,
        "recall": 0.021032,
        "f1": 0.014316,
        "accuracy": 0.021032,
        "main_score": 0.014316,
        "hf_subset": "fin_Latn-pol_Latn",
        "languages": [
          "fin-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.010926,
        "recall": 0.017526,
        "f1": 0.011898,
        "accuracy": 0.017526,
        "main_score": 0.011898,
        "hf_subset": "fin_Latn-por_Latn",
        "languages": [
          "fin-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000506,
        "recall": 0.001502,
        "f1": 0.000511,
        "accuracy": 0.001502,
        "main_score": 0.000511,
        "hf_subset": "fin_Latn-rus_Cyrl",
        "languages": [
          "fin-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.014145,
        "recall": 0.022033,
        "f1": 0.014948,
        "accuracy": 0.022033,
        "main_score": 0.014948,
        "hf_subset": "fin_Latn-spa_Latn",
        "languages": [
          "fin-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.004507,
        "recall": 0.006009,
        "f1": 0.004924,
        "accuracy": 0.006009,
        "main_score": 0.004924,
        "hf_subset": "fin_Latn-swa_Latn",
        "languages": [
          "fin-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.045378,
        "recall": 0.049574,
        "f1": 0.046272,
        "accuracy": 0.049574,
        "main_score": 0.046272,
        "hf_subset": "fin_Latn-swe_Latn",
        "languages": [
          "fin-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001012,
        "recall": 0.002003,
        "f1": 0.001022,
        "accuracy": 0.002003,
        "main_score": 0.001022,
        "hf_subset": "fin_Latn-tam_Taml",
        "languages": [
          "fin-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.017217,
        "recall": 0.024036,
        "f1": 0.018554,
        "accuracy": 0.024036,
        "main_score": 0.018554,
        "hf_subset": "fin_Latn-tur_Latn",
        "languages": [
          "fin-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00527,
        "recall": 0.007511,
        "f1": 0.005599,
        "accuracy": 0.007511,
        "main_score": 0.005599,
        "hf_subset": "fin_Latn-vie_Latn",
        "languages": [
          "fin-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000667,
        "recall": 0.002504,
        "f1": 0.000786,
        "accuracy": 0.002504,
        "main_score": 0.000786,
        "hf_subset": "fin_Latn-zho_Hant",
        "languages": [
          "fin-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.019471,
        "recall": 0.029544,
        "f1": 0.021101,
        "accuracy": 0.029544,
        "main_score": 0.021101,
        "hf_subset": "fin_Latn-zul_Latn",
        "languages": [
          "fin-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.00343,
        "recall": 0.005508,
        "f1": 0.003645,
        "accuracy": 0.005508,
        "main_score": 0.003645,
        "hf_subset": "fra_Latn-arb_Arab",
        "languages": [
          "fra-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001843,
        "recall": 0.004507,
        "f1": 0.001994,
        "accuracy": 0.004507,
        "main_score": 0.001994,
        "hf_subset": "fra_Latn-ben_Beng",
        "languages": [
          "fra-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.081884,
        "recall": 0.102654,
        "f1": 0.085741,
        "accuracy": 0.102654,
        "main_score": 0.085741,
        "hf_subset": "fra_Latn-cat_Latn",
        "languages": [
          "fra-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.023942,
        "recall": 0.034051,
        "f1": 0.025718,
        "accuracy": 0.034051,
        "main_score": 0.025718,
        "hf_subset": "fra_Latn-deu_Latn",
        "languages": [
          "fra-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000306,
        "recall": 0.002003,
        "f1": 0.000435,
        "accuracy": 0.002003,
        "main_score": 0.000435,
        "hf_subset": "fra_Latn-ell_Grek",
        "languages": [
          "fra-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.391897,
        "recall": 0.420631,
        "f1": 0.399604,
        "accuracy": 0.420631,
        "main_score": 0.399604,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000255,
        "recall": 0.002003,
        "f1": 0.000344,
        "accuracy": 0.002003,
        "main_score": 0.000344,
        "hf_subset": "fra_Latn-fas_Arab",
        "languages": [
          "fra-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.007867,
        "recall": 0.011517,
        "f1": 0.008122,
        "accuracy": 0.011517,
        "main_score": 0.008122,
        "hf_subset": "fra_Latn-fin_Latn",
        "languages": [
          "fra-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.311041,
        "recall": 0.345518,
        "f1": 0.319507,
        "accuracy": 0.345518,
        "main_score": 0.319507,
        "hf_subset": "fra_Latn-glg_Latn",
        "languages": [
          "fra-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.000244,
        "recall": 0.002504,
        "f1": 0.000395,
        "accuracy": 0.002504,
        "main_score": 0.000395,
        "hf_subset": "fra_Latn-heb_Hebr",
        "languages": [
          "fra-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "fra_Latn-hin_Deva",
        "languages": [
          "fra-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00822,
        "recall": 0.014522,
        "f1": 0.009213,
        "accuracy": 0.014522,
        "main_score": 0.009213,
        "hf_subset": "fra_Latn-hun_Latn",
        "languages": [
          "fra-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.024756,
        "recall": 0.032549,
        "f1": 0.02637,
        "accuracy": 0.032549,
        "main_score": 0.02637,
        "hf_subset": "fra_Latn-ind_Latn",
        "languages": [
          "fra-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.248838,
        "recall": 0.294942,
        "f1": 0.259172,
        "accuracy": 0.294942,
        "main_score": 0.259172,
        "hf_subset": "fra_Latn-ita_Latn",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.000209,
        "recall": 0.001502,
        "f1": 0.000328,
        "accuracy": 0.001502,
        "main_score": 0.000328,
        "hf_subset": "fra_Latn-jpn_Jpan",
        "languages": [
          "fra-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "fra_Latn-kor_Hang",
        "languages": [
          "fra-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.009254,
        "recall": 0.017526,
        "f1": 0.009974,
        "accuracy": 0.017526,
        "main_score": 0.009974,
        "hf_subset": "fra_Latn-lit_Latn",
        "languages": [
          "fra-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.016585,
        "recall": 0.025038,
        "f1": 0.018004,
        "accuracy": 0.025038,
        "main_score": 0.018004,
        "hf_subset": "fra_Latn-mlt_Latn",
        "languages": [
          "fra-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.034844,
        "recall": 0.046069,
        "f1": 0.036907,
        "accuracy": 0.046069,
        "main_score": 0.036907,
        "hf_subset": "fra_Latn-nld_Latn",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.009555,
        "recall": 0.014522,
        "f1": 0.010213,
        "accuracy": 0.014522,
        "main_score": 0.010213,
        "hf_subset": "fra_Latn-pol_Latn",
        "languages": [
          "fra-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.218383,
        "recall": 0.245869,
        "f1": 0.225109,
        "accuracy": 0.245869,
        "main_score": 0.225109,
        "hf_subset": "fra_Latn-por_Latn",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.055132,
        "recall": 0.071607,
        "f1": 0.057434,
        "accuracy": 0.071607,
        "main_score": 0.057434,
        "hf_subset": "fra_Latn-ron_Latn",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.001033,
        "recall": 0.002003,
        "f1": 0.001061,
        "accuracy": 0.002003,
        "main_score": 0.001061,
        "hf_subset": "fra_Latn-rus_Cyrl",
        "languages": [
          "fra-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.384769,
        "recall": 0.412619,
        "f1": 0.391836,
        "accuracy": 0.412619,
        "main_score": 0.391836,
        "hf_subset": "fra_Latn-spa_Latn",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.011886,
        "recall": 0.018027,
        "f1": 0.012652,
        "accuracy": 0.018027,
        "main_score": 0.012652,
        "hf_subset": "fra_Latn-swa_Latn",
        "languages": [
          "fra-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.029941,
        "recall": 0.040561,
        "f1": 0.03168,
        "accuracy": 0.040561,
        "main_score": 0.03168,
        "hf_subset": "fra_Latn-swe_Latn",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000525,
        "recall": 0.001502,
        "f1": 0.000547,
        "accuracy": 0.001502,
        "main_score": 0.000547,
        "hf_subset": "fra_Latn-tam_Taml",
        "languages": [
          "fra-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.004363,
        "recall": 0.009514,
        "f1": 0.004947,
        "accuracy": 0.009514,
        "main_score": 0.004947,
        "hf_subset": "fra_Latn-tur_Latn",
        "languages": [
          "fra-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.029916,
        "recall": 0.043565,
        "f1": 0.031544,
        "accuracy": 0.043565,
        "main_score": 0.031544,
        "hf_subset": "fra_Latn-vie_Latn",
        "languages": [
          "fra-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.002224,
        "recall": 0.004507,
        "f1": 0.00237,
        "accuracy": 0.004507,
        "main_score": 0.00237,
        "hf_subset": "fra_Latn-zho_Hant",
        "languages": [
          "fra-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.012806,
        "recall": 0.025038,
        "f1": 0.014418,
        "accuracy": 0.025038,
        "main_score": 0.014418,
        "hf_subset": "fra_Latn-zul_Latn",
        "languages": [
          "fra-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.018595,
        "recall": 0.032549,
        "f1": 0.02038,
        "accuracy": 0.032549,
        "main_score": 0.02038,
        "hf_subset": "fuc_Latn-bem_Latn",
        "languages": [
          "fuc-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.02307,
        "recall": 0.032549,
        "f1": 0.024254,
        "accuracy": 0.032549,
        "main_score": 0.024254,
        "hf_subset": "fuc_Latn-eng_Latn",
        "languages": [
          "fuc-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.043114,
        "recall": 0.057086,
        "f1": 0.045802,
        "accuracy": 0.057086,
        "main_score": 0.045802,
        "hf_subset": "fuc_Latn-ewe_Latn",
        "languages": [
          "fuc-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.003923,
        "recall": 0.00651,
        "f1": 0.004311,
        "accuracy": 0.00651,
        "main_score": 0.004311,
        "hf_subset": "fuc_Latn-kin_Latn",
        "languages": [
          "fuc-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.017013,
        "recall": 0.031547,
        "f1": 0.018983,
        "accuracy": 0.031547,
        "main_score": 0.018983,
        "hf_subset": "fuc_Latn-nde_Latn",
        "languages": [
          "fuc-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.026309,
        "recall": 0.043065,
        "f1": 0.029114,
        "accuracy": 0.043065,
        "main_score": 0.029114,
        "hf_subset": "fuc_Latn-nya_Latn",
        "languages": [
          "fuc-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.028173,
        "recall": 0.047571,
        "f1": 0.031084,
        "accuracy": 0.047571,
        "main_score": 0.031084,
        "hf_subset": "fuc_Latn-sna_Latn",
        "languages": [
          "fuc-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.045435,
        "recall": 0.067101,
        "f1": 0.049464,
        "accuracy": 0.067101,
        "main_score": 0.049464,
        "hf_subset": "fuc_Latn-ven_Latn",
        "languages": [
          "fuc-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.036307,
        "recall": 0.042564,
        "f1": 0.037573,
        "accuracy": 0.042564,
        "main_score": 0.037573,
        "hf_subset": "gle_Latn-cym_Latn",
        "languages": [
          "gle-Latn",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.007971,
        "recall": 0.011517,
        "f1": 0.008225,
        "accuracy": 0.011517,
        "main_score": 0.008225,
        "hf_subset": "gle_Latn-eng_Latn",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.058815,
        "recall": 0.076615,
        "f1": 0.061786,
        "accuracy": 0.076615,
        "main_score": 0.061786,
        "hf_subset": "glg_Latn-cat_Latn",
        "languages": [
          "glg-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.283578,
        "recall": 0.318478,
        "f1": 0.290425,
        "accuracy": 0.318478,
        "main_score": 0.290425,
        "hf_subset": "glg_Latn-eng_Latn",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.258632,
        "recall": 0.300951,
        "f1": 0.267822,
        "accuracy": 0.300951,
        "main_score": 0.267822,
        "hf_subset": "glg_Latn-fra_Latn",
        "languages": [
          "glg-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.241012,
        "recall": 0.284927,
        "f1": 0.250354,
        "accuracy": 0.284927,
        "main_score": 0.250354,
        "hf_subset": "glg_Latn-ita_Latn",
        "languages": [
          "glg-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.018533,
        "recall": 0.025538,
        "f1": 0.019815,
        "accuracy": 0.025538,
        "main_score": 0.019815,
        "hf_subset": "glg_Latn-mlt_Latn",
        "languages": [
          "glg-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.592967,
        "recall": 0.641462,
        "f1": 0.605013,
        "accuracy": 0.641462,
        "main_score": 0.605013,
        "hf_subset": "glg_Latn-por_Latn",
        "languages": [
          "glg-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.064587,
        "recall": 0.080621,
        "f1": 0.067331,
        "accuracy": 0.080621,
        "main_score": 0.067331,
        "hf_subset": "glg_Latn-ron_Latn",
        "languages": [
          "glg-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.592887,
        "recall": 0.632449,
        "f1": 0.602975,
        "accuracy": 0.632449,
        "main_score": 0.602975,
        "hf_subset": "glg_Latn-spa_Latn",
        "languages": [
          "glg-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.063503,
        "recall": 0.082624,
        "f1": 0.067085,
        "accuracy": 0.082624,
        "main_score": 0.067085,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 5.8e-05,
        "recall": 0.001502,
        "f1": 0.000108,
        "accuracy": 0.001502,
        "main_score": 0.000108,
        "hf_subset": "guj_Gujr-div_Thaa",
        "languages": [
          "guj-Gujr",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.03563,
        "recall": 0.050576,
        "f1": 0.038231,
        "accuracy": 0.050576,
        "main_score": 0.038231,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.02078,
        "recall": 0.03305,
        "f1": 0.022569,
        "accuracy": 0.03305,
        "main_score": 0.022569,
        "hf_subset": "guj_Gujr-eus_Latn",
        "languages": [
          "guj-Gujr",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.034554,
        "recall": 0.049574,
        "f1": 0.036675,
        "accuracy": 0.049574,
        "main_score": 0.036675,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.034202,
        "recall": 0.040561,
        "f1": 0.03546,
        "accuracy": 0.040561,
        "main_score": 0.03546,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.008159,
        "recall": 0.015023,
        "f1": 0.00869,
        "accuracy": 0.015023,
        "main_score": 0.00869,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.012527,
        "recall": 0.016525,
        "f1": 0.013234,
        "accuracy": 0.016525,
        "main_score": 0.013234,
        "hf_subset": "guj_Gujr-nep_Deva",
        "languages": [
          "guj-Gujr",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.011714,
        "recall": 0.014021,
        "f1": 0.012177,
        "accuracy": 0.014021,
        "main_score": 0.012177,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000533,
        "recall": 0.003005,
        "f1": 0.000782,
        "accuracy": 0.003005,
        "main_score": 0.000782,
        "hf_subset": "guj_Gujr-sin_Sinh",
        "languages": [
          "guj-Gujr",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000674,
        "recall": 0.005008,
        "f1": 0.000795,
        "accuracy": 0.005008,
        "main_score": 0.000795,
        "hf_subset": "guj_Gujr-snd_Arab",
        "languages": [
          "guj-Gujr",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.011231,
        "recall": 0.02003,
        "f1": 0.012368,
        "accuracy": 0.02003,
        "main_score": 0.012368,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.023425,
        "recall": 0.032048,
        "f1": 0.024939,
        "accuracy": 0.032048,
        "main_score": 0.024939,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.011961,
        "recall": 0.019029,
        "f1": 0.012982,
        "accuracy": 0.019029,
        "main_score": 0.012982,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001199,
        "recall": 0.003505,
        "f1": 0.001334,
        "accuracy": 0.003505,
        "main_score": 0.001334,
        "hf_subset": "hau_Latn-amh_Ethi",
        "languages": [
          "hau-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.018494,
        "recall": 0.026039,
        "f1": 0.01964,
        "accuracy": 0.026039,
        "main_score": 0.01964,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004422,
        "recall": 0.010015,
        "f1": 0.005116,
        "accuracy": 0.010015,
        "main_score": 0.005116,
        "hf_subset": "hau_Latn-ibo_Latn",
        "languages": [
          "hau-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.076811,
        "recall": 0.092138,
        "f1": 0.080288,
        "accuracy": 0.092138,
        "main_score": 0.080288,
        "hf_subset": "hau_Latn-nso_Latn",
        "languages": [
          "hau-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.03418,
        "recall": 0.048072,
        "f1": 0.037292,
        "accuracy": 0.048072,
        "main_score": 0.037292,
        "hf_subset": "hau_Latn-orm_Ethi",
        "languages": [
          "hau-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.084369,
        "recall": 0.097146,
        "f1": 0.087382,
        "accuracy": 0.097146,
        "main_score": 0.087382,
        "hf_subset": "hau_Latn-som_Latn",
        "languages": [
          "hau-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.041776,
        "recall": 0.062093,
        "f1": 0.045573,
        "accuracy": 0.062093,
        "main_score": 0.045573,
        "hf_subset": "hau_Latn-ssw_Latn",
        "languages": [
          "hau-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.005043,
        "recall": 0.007511,
        "f1": 0.005658,
        "accuracy": 0.007511,
        "main_score": 0.005658,
        "hf_subset": "hau_Latn-swa_Latn",
        "languages": [
          "hau-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 1.9e-05,
        "recall": 0.001502,
        "f1": 3.6e-05,
        "accuracy": 0.001502,
        "main_score": 3.6e-05,
        "hf_subset": "hau_Latn-tir_Ethi",
        "languages": [
          "hau-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.067761,
        "recall": 0.085128,
        "f1": 0.071777,
        "accuracy": 0.085128,
        "main_score": 0.071777,
        "hf_subset": "hau_Latn-tsn_Latn",
        "languages": [
          "hau-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.054394,
        "recall": 0.072108,
        "f1": 0.058287,
        "accuracy": 0.072108,
        "main_score": 0.058287,
        "hf_subset": "hau_Latn-wol_Latn",
        "languages": [
          "hau-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.022893,
        "recall": 0.031547,
        "f1": 0.024719,
        "accuracy": 0.031547,
        "main_score": 0.024719,
        "hf_subset": "hau_Latn-xho_Latn",
        "languages": [
          "hau-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.010527,
        "recall": 0.015523,
        "f1": 0.011463,
        "accuracy": 0.015523,
        "main_score": 0.011463,
        "hf_subset": "hau_Latn-yor_Latn",
        "languages": [
          "hau-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.025337,
        "recall": 0.037056,
        "f1": 0.02728,
        "accuracy": 0.037056,
        "main_score": 0.02728,
        "hf_subset": "hau_Latn-zul_Latn",
        "languages": [
          "hau-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001002,
        "f1": 0.000835,
        "accuracy": 0.001002,
        "main_score": 0.000835,
        "hf_subset": "heb_Hebr-arb_Arab",
        "languages": [
          "heb-Hebr",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000558,
        "recall": 0.003005,
        "f1": 0.000815,
        "accuracy": 0.003005,
        "main_score": 0.000815,
        "hf_subset": "heb_Hebr-ben_Beng",
        "languages": [
          "heb-Hebr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "heb_Hebr-ckb_Arab",
        "languages": [
          "heb-Hebr",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.004018,
        "recall": 0.005508,
        "f1": 0.00403,
        "accuracy": 0.005508,
        "main_score": 0.00403,
        "hf_subset": "heb_Hebr-deu_Latn",
        "languages": [
          "heb-Hebr",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.003715,
        "recall": 0.006009,
        "f1": 0.004018,
        "accuracy": 0.006009,
        "main_score": 0.004018,
        "hf_subset": "heb_Hebr-ell_Grek",
        "languages": [
          "heb-Hebr",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.003225,
        "recall": 0.00651,
        "f1": 0.003575,
        "accuracy": 0.00651,
        "main_score": 0.003575,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00042,
        "recall": 0.002003,
        "f1": 0.00059,
        "accuracy": 0.002003,
        "main_score": 0.00059,
        "hf_subset": "heb_Hebr-fas_Arab",
        "languages": [
          "heb-Hebr",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.002504,
        "f1": 0.001175,
        "accuracy": 0.002504,
        "main_score": 0.001175,
        "hf_subset": "heb_Hebr-fin_Latn",
        "languages": [
          "heb-Hebr",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.001756,
        "recall": 0.003005,
        "f1": 0.001843,
        "accuracy": 0.003005,
        "main_score": 0.001843,
        "hf_subset": "heb_Hebr-fra_Latn",
        "languages": [
          "heb-Hebr",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000257,
        "recall": 0.001502,
        "f1": 0.000348,
        "accuracy": 0.001502,
        "main_score": 0.000348,
        "hf_subset": "heb_Hebr-hin_Deva",
        "languages": [
          "heb-Hebr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001284,
        "recall": 0.003005,
        "f1": 0.001397,
        "accuracy": 0.003005,
        "main_score": 0.001397,
        "hf_subset": "heb_Hebr-hun_Latn",
        "languages": [
          "heb-Hebr",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001434,
        "recall": 0.003005,
        "f1": 0.001637,
        "accuracy": 0.003005,
        "main_score": 0.001637,
        "hf_subset": "heb_Hebr-ind_Latn",
        "languages": [
          "heb-Hebr",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001566,
        "recall": 0.004006,
        "f1": 0.00162,
        "accuracy": 0.004006,
        "main_score": 0.00162,
        "hf_subset": "heb_Hebr-jpn_Jpan",
        "languages": [
          "heb-Hebr",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002003,
        "recall": 0.002504,
        "f1": 0.002004,
        "accuracy": 0.002504,
        "main_score": 0.002004,
        "hf_subset": "heb_Hebr-kmr_Latn",
        "languages": [
          "heb-Hebr",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.004115,
        "recall": 0.007511,
        "f1": 0.004454,
        "accuracy": 0.007511,
        "main_score": 0.004454,
        "hf_subset": "heb_Hebr-kor_Hang",
        "languages": [
          "heb-Hebr",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.002504,
        "recall": 0.003005,
        "f1": 0.002505,
        "accuracy": 0.003005,
        "main_score": 0.002505,
        "hf_subset": "heb_Hebr-lit_Latn",
        "languages": [
          "heb-Hebr",
          "lit-Latn"
        ]
      },
      {
        "precision": 4.1e-05,
        "recall": 0.002003,
        "f1": 8.1e-05,
        "accuracy": 0.002003,
        "main_score": 8.1e-05,
        "hf_subset": "heb_Hebr-mey_Arab",
        "languages": [
          "heb-Hebr",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.00301,
        "recall": 0.003505,
        "f1": 0.003015,
        "accuracy": 0.003505,
        "main_score": 0.003015,
        "hf_subset": "heb_Hebr-nld_Latn",
        "languages": [
          "heb-Hebr",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.001647,
        "recall": 0.004507,
        "f1": 0.001921,
        "accuracy": 0.004507,
        "main_score": 0.001921,
        "hf_subset": "heb_Hebr-pol_Latn",
        "languages": [
          "heb-Hebr",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001436,
        "recall": 0.005508,
        "f1": 0.001661,
        "accuracy": 0.005508,
        "main_score": 0.001661,
        "hf_subset": "heb_Hebr-por_Latn",
        "languages": [
          "heb-Hebr",
          "por-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "heb_Hebr-prs_Arab",
        "languages": [
          "heb-Hebr",
          "prs-Arab"
        ]
      },
      {
        "precision": 2.7e-05,
        "recall": 0.002003,
        "f1": 5.3e-05,
        "accuracy": 0.002003,
        "main_score": 5.3e-05,
        "hf_subset": "heb_Hebr-pus_Arab",
        "languages": [
          "heb-Hebr",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.003565,
        "recall": 0.007011,
        "f1": 0.003825,
        "accuracy": 0.007011,
        "main_score": 0.003825,
        "hf_subset": "heb_Hebr-rus_Cyrl",
        "languages": [
          "heb-Hebr",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "heb_Hebr-shi_Arab",
        "languages": [
          "heb-Hebr",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.00318,
        "recall": 0.005008,
        "f1": 0.003303,
        "accuracy": 0.005008,
        "main_score": 0.003303,
        "hf_subset": "heb_Hebr-spa_Latn",
        "languages": [
          "heb-Hebr",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001085,
        "recall": 0.002003,
        "f1": 0.001311,
        "accuracy": 0.002003,
        "main_score": 0.001311,
        "hf_subset": "heb_Hebr-swa_Latn",
        "languages": [
          "heb-Hebr",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.002504,
        "recall": 0.003005,
        "f1": 0.002505,
        "accuracy": 0.003005,
        "main_score": 0.002505,
        "hf_subset": "heb_Hebr-swe_Latn",
        "languages": [
          "heb-Hebr",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001616,
        "recall": 0.003005,
        "f1": 0.001696,
        "accuracy": 0.003005,
        "main_score": 0.001696,
        "hf_subset": "heb_Hebr-tam_Taml",
        "languages": [
          "heb-Hebr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002066,
        "recall": 0.004006,
        "f1": 0.002117,
        "accuracy": 0.004006,
        "main_score": 0.002117,
        "hf_subset": "heb_Hebr-tgk_Cyrl",
        "languages": [
          "heb-Hebr",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.001475,
        "recall": 0.003505,
        "f1": 0.001692,
        "accuracy": 0.003505,
        "main_score": 0.001692,
        "hf_subset": "heb_Hebr-tur_Latn",
        "languages": [
          "heb-Hebr",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001955,
        "recall": 0.005008,
        "f1": 0.002189,
        "accuracy": 0.005008,
        "main_score": 0.002189,
        "hf_subset": "heb_Hebr-vie_Latn",
        "languages": [
          "heb-Hebr",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001256,
        "recall": 0.002504,
        "f1": 0.001344,
        "accuracy": 0.002504,
        "main_score": 0.001344,
        "hf_subset": "heb_Hebr-zho_Hant",
        "languages": [
          "heb-Hebr",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.00176,
        "recall": 0.002504,
        "f1": 0.001851,
        "accuracy": 0.002504,
        "main_score": 0.001851,
        "hf_subset": "heb_Hebr-zul_Latn",
        "languages": [
          "heb-Hebr",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.086861,
        "recall": 0.111668,
        "f1": 0.090578,
        "accuracy": 0.111668,
        "main_score": 0.090578,
        "hf_subset": "hin_Deva-arb_Arab",
        "languages": [
          "hin-Deva",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.012701,
        "recall": 0.020531,
        "f1": 0.013596,
        "accuracy": 0.020531,
        "main_score": 0.013596,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.035104,
        "recall": 0.060591,
        "f1": 0.038283,
        "accuracy": 0.060591,
        "main_score": 0.038283,
        "hf_subset": "hin_Deva-deu_Latn",
        "languages": [
          "hin-Deva",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000112,
        "recall": 0.002003,
        "f1": 0.000199,
        "accuracy": 0.002003,
        "main_score": 0.000199,
        "hf_subset": "hin_Deva-div_Thaa",
        "languages": [
          "hin-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.006026,
        "recall": 0.01352,
        "f1": 0.0068,
        "accuracy": 0.01352,
        "main_score": 0.0068,
        "hf_subset": "hin_Deva-ell_Grek",
        "languages": [
          "hin-Deva",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.057818,
        "recall": 0.077616,
        "f1": 0.061258,
        "accuracy": 0.077616,
        "main_score": 0.061258,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020404,
        "recall": 0.03355,
        "f1": 0.022531,
        "accuracy": 0.03355,
        "main_score": 0.022531,
        "hf_subset": "hin_Deva-eus_Latn",
        "languages": [
          "hin-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.001271,
        "recall": 0.005008,
        "f1": 0.001461,
        "accuracy": 0.005008,
        "main_score": 0.001461,
        "hf_subset": "hin_Deva-fas_Arab",
        "languages": [
          "hin-Deva",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.004902,
        "recall": 0.010516,
        "f1": 0.005613,
        "accuracy": 0.010516,
        "main_score": 0.005613,
        "hf_subset": "hin_Deva-fin_Latn",
        "languages": [
          "hin-Deva",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.073023,
        "recall": 0.111167,
        "f1": 0.079169,
        "accuracy": 0.111167,
        "main_score": 0.079169,
        "hf_subset": "hin_Deva-fra_Latn",
        "languages": [
          "hin-Deva",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.004918,
        "recall": 0.009514,
        "f1": 0.005371,
        "accuracy": 0.009514,
        "main_score": 0.005371,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002201,
        "recall": 0.007011,
        "f1": 0.002613,
        "accuracy": 0.007011,
        "main_score": 0.002613,
        "hf_subset": "hin_Deva-heb_Hebr",
        "languages": [
          "hin-Deva",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.005267,
        "recall": 0.009514,
        "f1": 0.006011,
        "accuracy": 0.009514,
        "main_score": 0.006011,
        "hf_subset": "hin_Deva-hun_Latn",
        "languages": [
          "hin-Deva",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.066077,
        "recall": 0.096645,
        "f1": 0.071548,
        "accuracy": 0.096645,
        "main_score": 0.071548,
        "hf_subset": "hin_Deva-ind_Latn",
        "languages": [
          "hin-Deva",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.050778,
        "recall": 0.079119,
        "f1": 0.055049,
        "accuracy": 0.079119,
        "main_score": 0.055049,
        "hf_subset": "hin_Deva-jpn_Jpan",
        "languages": [
          "hin-Deva",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.030176,
        "recall": 0.043565,
        "f1": 0.032754,
        "accuracy": 0.043565,
        "main_score": 0.032754,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004403,
        "recall": 0.00651,
        "f1": 0.004759,
        "accuracy": 0.00651,
        "main_score": 0.004759,
        "hf_subset": "hin_Deva-kor_Hang",
        "languages": [
          "hin-Deva",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.006358,
        "recall": 0.012018,
        "f1": 0.007257,
        "accuracy": 0.012018,
        "main_score": 0.007257,
        "hf_subset": "hin_Deva-lit_Latn",
        "languages": [
          "hin-Deva",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.07089,
        "recall": 0.086129,
        "f1": 0.073383,
        "accuracy": 0.086129,
        "main_score": 0.073383,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.083033,
        "recall": 0.111668,
        "f1": 0.087852,
        "accuracy": 0.111668,
        "main_score": 0.087852,
        "hf_subset": "hin_Deva-nep_Deva",
        "languages": [
          "hin-Deva",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.019945,
        "recall": 0.028543,
        "f1": 0.021481,
        "accuracy": 0.028543,
        "main_score": 0.021481,
        "hf_subset": "hin_Deva-nld_Latn",
        "languages": [
          "hin-Deva",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.014895,
        "recall": 0.024537,
        "f1": 0.015938,
        "accuracy": 0.024537,
        "main_score": 0.015938,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.013119,
        "recall": 0.028543,
        "f1": 0.014906,
        "accuracy": 0.028543,
        "main_score": 0.014906,
        "hf_subset": "hin_Deva-pol_Latn",
        "languages": [
          "hin-Deva",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.05558,
        "recall": 0.081122,
        "f1": 0.05975,
        "accuracy": 0.081122,
        "main_score": 0.05975,
        "hf_subset": "hin_Deva-por_Latn",
        "languages": [
          "hin-Deva",
          "por-Latn"
        ]
      },
      {
        "precision": 0.020205,
        "recall": 0.035053,
        "f1": 0.021837,
        "accuracy": 0.035053,
        "main_score": 0.021837,
        "hf_subset": "hin_Deva-rus_Cyrl",
        "languages": [
          "hin-Deva",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.002446,
        "recall": 0.006009,
        "f1": 0.002897,
        "accuracy": 0.006009,
        "main_score": 0.002897,
        "hf_subset": "hin_Deva-sin_Sinh",
        "languages": [
          "hin-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.001012,
        "recall": 0.002504,
        "f1": 0.001022,
        "accuracy": 0.002504,
        "main_score": 0.001022,
        "hf_subset": "hin_Deva-snd_Arab",
        "languages": [
          "hin-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.036902,
        "recall": 0.054582,
        "f1": 0.040038,
        "accuracy": 0.054582,
        "main_score": 0.040038,
        "hf_subset": "hin_Deva-spa_Latn",
        "languages": [
          "hin-Deva",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.032632,
        "recall": 0.054081,
        "f1": 0.0361,
        "accuracy": 0.054081,
        "main_score": 0.0361,
        "hf_subset": "hin_Deva-swa_Latn",
        "languages": [
          "hin-Deva",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.013938,
        "recall": 0.022534,
        "f1": 0.015074,
        "accuracy": 0.022534,
        "main_score": 0.015074,
        "hf_subset": "hin_Deva-swe_Latn",
        "languages": [
          "hin-Deva",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.019102,
        "recall": 0.035553,
        "f1": 0.021597,
        "accuracy": 0.035553,
        "main_score": 0.021597,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.022566,
        "recall": 0.032048,
        "f1": 0.024324,
        "accuracy": 0.032048,
        "main_score": 0.024324,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010608,
        "recall": 0.018027,
        "f1": 0.011817,
        "accuracy": 0.018027,
        "main_score": 0.011817,
        "hf_subset": "hin_Deva-tur_Latn",
        "languages": [
          "hin-Deva",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001949,
        "recall": 0.004006,
        "f1": 0.00217,
        "accuracy": 0.004006,
        "main_score": 0.00217,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.041348,
        "recall": 0.069604,
        "f1": 0.045447,
        "accuracy": 0.069604,
        "main_score": 0.045447,
        "hf_subset": "hin_Deva-vie_Latn",
        "languages": [
          "hin-Deva",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.070167,
        "recall": 0.10015,
        "f1": 0.07528,
        "accuracy": 0.10015,
        "main_score": 0.07528,
        "hf_subset": "hin_Deva-zho_Hant",
        "languages": [
          "hin-Deva",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.002827,
        "recall": 0.009014,
        "f1": 0.003313,
        "accuracy": 0.009014,
        "main_score": 0.003313,
        "hf_subset": "hin_Deva-zul_Latn",
        "languages": [
          "hin-Deva",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.011316,
        "recall": 0.015023,
        "f1": 0.011875,
        "accuracy": 0.015023,
        "main_score": 0.011875,
        "hf_subset": "hmn_Latn-eng_Latn",
        "languages": [
          "hmn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00058,
        "recall": 0.002003,
        "f1": 0.000641,
        "accuracy": 0.002003,
        "main_score": 0.000641,
        "hf_subset": "hrv_Latn-bel_Cyrl",
        "languages": [
          "hrv-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.697622,
        "recall": 0.764647,
        "f1": 0.716997,
        "accuracy": 0.764647,
        "main_score": 0.716997,
        "hf_subset": "hrv_Latn-bos_Latn",
        "languages": [
          "hrv-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.001514,
        "recall": 0.003505,
        "f1": 0.001525,
        "accuracy": 0.003505,
        "main_score": 0.001525,
        "hf_subset": "hrv_Latn-bul_Cyrl",
        "languages": [
          "hrv-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.097888,
        "recall": 0.122684,
        "f1": 0.102231,
        "accuracy": 0.122684,
        "main_score": 0.102231,
        "hf_subset": "hrv_Latn-ces_Latn",
        "languages": [
          "hrv-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.020908,
        "recall": 0.030546,
        "f1": 0.022111,
        "accuracy": 0.030546,
        "main_score": 0.022111,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001556,
        "recall": 0.004507,
        "f1": 0.001606,
        "accuracy": 0.004507,
        "main_score": 0.001606,
        "hf_subset": "hrv_Latn-mkd_Cyrl",
        "languages": [
          "hrv-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.048499,
        "recall": 0.062093,
        "f1": 0.050898,
        "accuracy": 0.062093,
        "main_score": 0.050898,
        "hf_subset": "hrv_Latn-pol_Latn",
        "languages": [
          "hrv-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001758,
        "recall": 0.003505,
        "f1": 0.001846,
        "accuracy": 0.003505,
        "main_score": 0.001846,
        "hf_subset": "hrv_Latn-rus_Cyrl",
        "languages": [
          "hrv-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.11548,
        "recall": 0.141212,
        "f1": 0.12019,
        "accuracy": 0.141212,
        "main_score": 0.12019,
        "hf_subset": "hrv_Latn-slk_Latn",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.32482,
        "recall": 0.389084,
        "f1": 0.340668,
        "accuracy": 0.389084,
        "main_score": 0.340668,
        "hf_subset": "hrv_Latn-slv_Latn",
        "languages": [
          "hrv-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.001912,
        "recall": 0.004507,
        "f1": 0.002117,
        "accuracy": 0.004507,
        "main_score": 0.002117,
        "hf_subset": "hrv_Latn-srp_Cyrl",
        "languages": [
          "hrv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.566224,
        "recall": 0.649474,
        "f1": 0.589124,
        "accuracy": 0.649474,
        "main_score": 0.589124,
        "hf_subset": "hrv_Latn-srp_Latn",
        "languages": [
          "hrv-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.000619,
        "recall": 0.003005,
        "f1": 0.000712,
        "accuracy": 0.003005,
        "main_score": 0.000712,
        "hf_subset": "hrv_Latn-ukr_Cyrl",
        "languages": [
          "hrv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "hun_Latn-arb_Arab",
        "languages": [
          "hun-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000506,
        "recall": 0.002003,
        "f1": 0.000512,
        "accuracy": 0.002003,
        "main_score": 0.000512,
        "hf_subset": "hun_Latn-ben_Beng",
        "languages": [
          "hun-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.026929,
        "recall": 0.03355,
        "f1": 0.028095,
        "accuracy": 0.03355,
        "main_score": 0.028095,
        "hf_subset": "hun_Latn-deu_Latn",
        "languages": [
          "hun-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000509,
        "recall": 0.001502,
        "f1": 0.000517,
        "accuracy": 0.001502,
        "main_score": 0.000517,
        "hf_subset": "hun_Latn-ell_Grek",
        "languages": [
          "hun-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.016412,
        "recall": 0.022033,
        "f1": 0.017265,
        "accuracy": 0.022033,
        "main_score": 0.017265,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "hun_Latn-fas_Arab",
        "languages": [
          "hun-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.028182,
        "recall": 0.037556,
        "f1": 0.029861,
        "accuracy": 0.037556,
        "main_score": 0.029861,
        "hf_subset": "hun_Latn-fin_Latn",
        "languages": [
          "hun-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.011068,
        "recall": 0.014522,
        "f1": 0.011449,
        "accuracy": 0.014522,
        "main_score": 0.011449,
        "hf_subset": "hun_Latn-fra_Latn",
        "languages": [
          "hun-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000753,
        "recall": 0.002003,
        "f1": 0.000838,
        "accuracy": 0.002003,
        "main_score": 0.000838,
        "hf_subset": "hun_Latn-heb_Hebr",
        "languages": [
          "hun-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000505,
        "accuracy": 0.001502,
        "main_score": 0.000505,
        "hf_subset": "hun_Latn-hin_Deva",
        "languages": [
          "hun-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005299,
        "recall": 0.009014,
        "f1": 0.005834,
        "accuracy": 0.009014,
        "main_score": 0.005834,
        "hf_subset": "hun_Latn-ind_Latn",
        "languages": [
          "hun-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "hun_Latn-jpn_Jpan",
        "languages": [
          "hun-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000254,
        "recall": 0.002003,
        "f1": 0.000342,
        "accuracy": 0.002003,
        "main_score": 0.000342,
        "hf_subset": "hun_Latn-kor_Hang",
        "languages": [
          "hun-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.01202,
        "recall": 0.019029,
        "f1": 0.013108,
        "accuracy": 0.019029,
        "main_score": 0.013108,
        "hf_subset": "hun_Latn-lav_Latn",
        "languages": [
          "hun-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.016251,
        "recall": 0.019529,
        "f1": 0.017109,
        "accuracy": 0.019529,
        "main_score": 0.017109,
        "hf_subset": "hun_Latn-lit_Latn",
        "languages": [
          "hun-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.023895,
        "recall": 0.030546,
        "f1": 0.024961,
        "accuracy": 0.030546,
        "main_score": 0.024961,
        "hf_subset": "hun_Latn-nld_Latn",
        "languages": [
          "hun-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.019391,
        "recall": 0.027541,
        "f1": 0.020875,
        "accuracy": 0.027541,
        "main_score": 0.020875,
        "hf_subset": "hun_Latn-pol_Latn",
        "languages": [
          "hun-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.012399,
        "recall": 0.017526,
        "f1": 0.013058,
        "accuracy": 0.017526,
        "main_score": 0.013058,
        "hf_subset": "hun_Latn-por_Latn",
        "languages": [
          "hun-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000517,
        "recall": 0.001502,
        "f1": 0.000533,
        "accuracy": 0.001502,
        "main_score": 0.000533,
        "hf_subset": "hun_Latn-rus_Cyrl",
        "languages": [
          "hun-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.019298,
        "recall": 0.02654,
        "f1": 0.02025,
        "accuracy": 0.02654,
        "main_score": 0.02025,
        "hf_subset": "hun_Latn-spa_Latn",
        "languages": [
          "hun-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.004417,
        "recall": 0.007511,
        "f1": 0.004809,
        "accuracy": 0.007511,
        "main_score": 0.004809,
        "hf_subset": "hun_Latn-swa_Latn",
        "languages": [
          "hun-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.035682,
        "recall": 0.044066,
        "f1": 0.036832,
        "accuracy": 0.044066,
        "main_score": 0.036832,
        "hf_subset": "hun_Latn-swe_Latn",
        "languages": [
          "hun-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000269,
        "recall": 0.001502,
        "f1": 0.000369,
        "accuracy": 0.001502,
        "main_score": 0.000369,
        "hf_subset": "hun_Latn-tam_Taml",
        "languages": [
          "hun-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.031028,
        "recall": 0.037056,
        "f1": 0.032367,
        "accuracy": 0.037056,
        "main_score": 0.032367,
        "hf_subset": "hun_Latn-tur_Latn",
        "languages": [
          "hun-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.005777,
        "recall": 0.008513,
        "f1": 0.005989,
        "accuracy": 0.008513,
        "main_score": 0.005989,
        "hf_subset": "hun_Latn-vie_Latn",
        "languages": [
          "hun-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000358,
        "recall": 0.002504,
        "f1": 0.00053,
        "accuracy": 0.002504,
        "main_score": 0.00053,
        "hf_subset": "hun_Latn-zho_Hant",
        "languages": [
          "hun-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.015244,
        "recall": 0.019029,
        "f1": 0.01613,
        "accuracy": 0.019029,
        "main_score": 0.01613,
        "hf_subset": "hun_Latn-zul_Latn",
        "languages": [
          "hun-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001507,
        "recall": 0.004006,
        "f1": 0.001805,
        "accuracy": 0.004006,
        "main_score": 0.001805,
        "hf_subset": "hye_Armn-ell_Grek",
        "languages": [
          "hye-Armn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.003762,
        "recall": 0.007011,
        "f1": 0.004101,
        "accuracy": 0.007011,
        "main_score": 0.004101,
        "hf_subset": "hye_Armn-eng_Latn",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007299,
        "recall": 0.011517,
        "f1": 0.007824,
        "accuracy": 0.011517,
        "main_score": 0.007824,
        "hf_subset": "hye_Armn-kat_Geor",
        "languages": [
          "hye-Armn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.002008,
        "recall": 0.003005,
        "f1": 0.002181,
        "accuracy": 0.003005,
        "main_score": 0.002181,
        "hf_subset": "hye_Armn-sqi_Latn",
        "languages": [
          "hye-Armn",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.002621,
        "recall": 0.008012,
        "f1": 0.00316,
        "accuracy": 0.008012,
        "main_score": 0.00316,
        "hf_subset": "ibo_Latn-amh_Ethi",
        "languages": [
          "ibo-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.0483,
        "recall": 0.062093,
        "f1": 0.050496,
        "accuracy": 0.062093,
        "main_score": 0.050496,
        "hf_subset": "ibo_Latn-eng_Latn",
        "languages": [
          "ibo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024837,
        "recall": 0.029544,
        "f1": 0.025549,
        "accuracy": 0.029544,
        "main_score": 0.025549,
        "hf_subset": "ibo_Latn-hau_Latn",
        "languages": [
          "ibo-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.026553,
        "recall": 0.029044,
        "f1": 0.027066,
        "accuracy": 0.029044,
        "main_score": 0.027066,
        "hf_subset": "ibo_Latn-nso_Latn",
        "languages": [
          "ibo-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.011568,
        "recall": 0.014021,
        "f1": 0.012027,
        "accuracy": 0.014021,
        "main_score": 0.012027,
        "hf_subset": "ibo_Latn-orm_Ethi",
        "languages": [
          "ibo-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.016125,
        "recall": 0.019529,
        "f1": 0.016643,
        "accuracy": 0.019529,
        "main_score": 0.016643,
        "hf_subset": "ibo_Latn-som_Latn",
        "languages": [
          "ibo-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.033334,
        "recall": 0.043065,
        "f1": 0.035188,
        "accuracy": 0.043065,
        "main_score": 0.035188,
        "hf_subset": "ibo_Latn-ssw_Latn",
        "languages": [
          "ibo-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.060032,
        "recall": 0.068102,
        "f1": 0.061818,
        "accuracy": 0.068102,
        "main_score": 0.061818,
        "hf_subset": "ibo_Latn-swa_Latn",
        "languages": [
          "ibo-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000733,
        "recall": 0.002504,
        "f1": 0.000889,
        "accuracy": 0.002504,
        "main_score": 0.000889,
        "hf_subset": "ibo_Latn-tir_Ethi",
        "languages": [
          "ibo-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.027362,
        "recall": 0.030045,
        "f1": 0.028084,
        "accuracy": 0.030045,
        "main_score": 0.028084,
        "hf_subset": "ibo_Latn-tsn_Latn",
        "languages": [
          "ibo-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.030686,
        "recall": 0.036054,
        "f1": 0.031397,
        "accuracy": 0.036054,
        "main_score": 0.031397,
        "hf_subset": "ibo_Latn-wol_Latn",
        "languages": [
          "ibo-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.038967,
        "recall": 0.054582,
        "f1": 0.041824,
        "accuracy": 0.054582,
        "main_score": 0.041824,
        "hf_subset": "ibo_Latn-xho_Latn",
        "languages": [
          "ibo-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.036738,
        "recall": 0.049574,
        "f1": 0.03916,
        "accuracy": 0.049574,
        "main_score": 0.03916,
        "hf_subset": "ibo_Latn-yor_Latn",
        "languages": [
          "ibo-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.040514,
        "recall": 0.055583,
        "f1": 0.043372,
        "accuracy": 0.055583,
        "main_score": 0.043372,
        "hf_subset": "ibo_Latn-zul_Latn",
        "languages": [
          "ibo-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002003,
        "f1": 0.001007,
        "accuracy": 0.002003,
        "main_score": 0.001007,
        "hf_subset": "ind_Latn-arb_Arab",
        "languages": [
          "ind-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.001002,
        "f1": 3.3e-05,
        "accuracy": 0.001002,
        "main_score": 3.3e-05,
        "hf_subset": "ind_Latn-ben_Beng",
        "languages": [
          "ind-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.01901,
        "recall": 0.025538,
        "f1": 0.020085,
        "accuracy": 0.025538,
        "main_score": 0.020085,
        "hf_subset": "ind_Latn-deu_Latn",
        "languages": [
          "ind-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "ind_Latn-ell_Grek",
        "languages": [
          "ind-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.051255,
        "recall": 0.054081,
        "f1": 0.051517,
        "accuracy": 0.054081,
        "main_score": 0.051517,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000339,
        "recall": 0.002003,
        "f1": 0.000487,
        "accuracy": 0.002003,
        "main_score": 0.000487,
        "hf_subset": "ind_Latn-fas_Arab",
        "languages": [
          "ind-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.002803,
        "recall": 0.005008,
        "f1": 0.002931,
        "accuracy": 0.005008,
        "main_score": 0.002931,
        "hf_subset": "ind_Latn-fij_Latn",
        "languages": [
          "ind-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.015264,
        "recall": 0.018027,
        "f1": 0.015642,
        "accuracy": 0.018027,
        "main_score": 0.015642,
        "hf_subset": "ind_Latn-fil_Latn",
        "languages": [
          "ind-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.005741,
        "recall": 0.008513,
        "f1": 0.006066,
        "accuracy": 0.008513,
        "main_score": 0.006066,
        "hf_subset": "ind_Latn-fin_Latn",
        "languages": [
          "ind-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.049308,
        "recall": 0.056585,
        "f1": 0.050675,
        "accuracy": 0.056585,
        "main_score": 0.050675,
        "hf_subset": "ind_Latn-fra_Latn",
        "languages": [
          "ind-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.002254,
        "recall": 0.003005,
        "f1": 0.002337,
        "accuracy": 0.003005,
        "main_score": 0.002337,
        "hf_subset": "ind_Latn-heb_Hebr",
        "languages": [
          "ind-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001255,
        "recall": 0.004006,
        "f1": 0.001568,
        "accuracy": 0.004006,
        "main_score": 0.001568,
        "hf_subset": "ind_Latn-hin_Deva",
        "languages": [
          "ind-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004732,
        "recall": 0.00651,
        "f1": 0.005041,
        "accuracy": 0.00651,
        "main_score": 0.005041,
        "hf_subset": "ind_Latn-hun_Latn",
        "languages": [
          "ind-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001506,
        "recall": 0.002504,
        "f1": 0.00151,
        "accuracy": 0.002504,
        "main_score": 0.00151,
        "hf_subset": "ind_Latn-jpn_Jpan",
        "languages": [
          "ind-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000503,
        "accuracy": 0.001502,
        "main_score": 0.000503,
        "hf_subset": "ind_Latn-kor_Hang",
        "languages": [
          "ind-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.005175,
        "recall": 0.00651,
        "f1": 0.005425,
        "accuracy": 0.00651,
        "main_score": 0.005425,
        "hf_subset": "ind_Latn-lit_Latn",
        "languages": [
          "ind-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "ind_Latn-mal_Mlym",
        "languages": [
          "ind-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.006364,
        "recall": 0.009014,
        "f1": 0.006528,
        "accuracy": 0.009014,
        "main_score": 0.006528,
        "hf_subset": "ind_Latn-mlg_Latn",
        "languages": [
          "ind-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.006031,
        "recall": 0.008012,
        "f1": 0.006217,
        "accuracy": 0.008012,
        "main_score": 0.006217,
        "hf_subset": "ind_Latn-mri_Latn",
        "languages": [
          "ind-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.653316,
        "recall": 0.732599,
        "f1": 0.676622,
        "accuracy": 0.732599,
        "main_score": 0.676622,
        "hf_subset": "ind_Latn-msa_Latn",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.014704,
        "recall": 0.017026,
        "f1": 0.014803,
        "accuracy": 0.017026,
        "main_score": 0.014803,
        "hf_subset": "ind_Latn-nld_Latn",
        "languages": [
          "ind-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.007833,
        "recall": 0.010516,
        "f1": 0.008141,
        "accuracy": 0.010516,
        "main_score": 0.008141,
        "hf_subset": "ind_Latn-pol_Latn",
        "languages": [
          "ind-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.06137,
        "recall": 0.075613,
        "f1": 0.06372,
        "accuracy": 0.075613,
        "main_score": 0.06372,
        "hf_subset": "ind_Latn-por_Latn",
        "languages": [
          "ind-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001201,
        "recall": 0.003005,
        "f1": 0.001335,
        "accuracy": 0.003005,
        "main_score": 0.001335,
        "hf_subset": "ind_Latn-rus_Cyrl",
        "languages": [
          "ind-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.00607,
        "recall": 0.009014,
        "f1": 0.006346,
        "accuracy": 0.009014,
        "main_score": 0.006346,
        "hf_subset": "ind_Latn-smo_Latn",
        "languages": [
          "ind-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.023285,
        "recall": 0.024537,
        "f1": 0.023536,
        "accuracy": 0.024537,
        "main_score": 0.023536,
        "hf_subset": "ind_Latn-spa_Latn",
        "languages": [
          "ind-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.009019,
        "recall": 0.012018,
        "f1": 0.009468,
        "accuracy": 0.012018,
        "main_score": 0.009468,
        "hf_subset": "ind_Latn-swa_Latn",
        "languages": [
          "ind-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.012771,
        "recall": 0.014522,
        "f1": 0.013024,
        "accuracy": 0.014522,
        "main_score": 0.013024,
        "hf_subset": "ind_Latn-swe_Latn",
        "languages": [
          "ind-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.004811,
        "recall": 0.00651,
        "f1": 0.004939,
        "accuracy": 0.00651,
        "main_score": 0.004939,
        "hf_subset": "ind_Latn-tah_Latn",
        "languages": [
          "ind-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.000768,
        "recall": 0.003505,
        "f1": 0.000867,
        "accuracy": 0.003505,
        "main_score": 0.000867,
        "hf_subset": "ind_Latn-tam_Taml",
        "languages": [
          "ind-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00223,
        "recall": 0.004507,
        "f1": 0.00254,
        "accuracy": 0.004507,
        "main_score": 0.00254,
        "hf_subset": "ind_Latn-ton_Latn",
        "languages": [
          "ind-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.004912,
        "recall": 0.007011,
        "f1": 0.0053,
        "accuracy": 0.007011,
        "main_score": 0.0053,
        "hf_subset": "ind_Latn-tur_Latn",
        "languages": [
          "ind-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.02806,
        "recall": 0.037556,
        "f1": 0.029962,
        "accuracy": 0.037556,
        "main_score": 0.029962,
        "hf_subset": "ind_Latn-vie_Latn",
        "languages": [
          "ind-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001945,
        "recall": 0.005008,
        "f1": 0.002137,
        "accuracy": 0.005008,
        "main_score": 0.002137,
        "hf_subset": "ind_Latn-zho_Hant",
        "languages": [
          "ind-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.005759,
        "recall": 0.00651,
        "f1": 0.005843,
        "accuracy": 0.00651,
        "main_score": 0.005843,
        "hf_subset": "ind_Latn-zul_Latn",
        "languages": [
          "ind-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.017849,
        "recall": 0.02003,
        "f1": 0.018155,
        "accuracy": 0.02003,
        "main_score": 0.018155,
        "hf_subset": "isl_Latn-afr_Latn",
        "languages": [
          "isl-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.06018,
        "recall": 0.077116,
        "f1": 0.062796,
        "accuracy": 0.077116,
        "main_score": 0.062796,
        "hf_subset": "isl_Latn-dan_Latn",
        "languages": [
          "isl-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.023602,
        "recall": 0.029544,
        "f1": 0.02463,
        "accuracy": 0.029544,
        "main_score": 0.02463,
        "hf_subset": "isl_Latn-deu_Latn",
        "languages": [
          "isl-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.012463,
        "recall": 0.017526,
        "f1": 0.01309,
        "accuracy": 0.017526,
        "main_score": 0.01309,
        "hf_subset": "isl_Latn-eng_Latn",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.24891,
        "recall": 0.310466,
        "f1": 0.262714,
        "accuracy": 0.310466,
        "main_score": 0.262714,
        "hf_subset": "isl_Latn-fao_Latn",
        "languages": [
          "isl-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.017941,
        "recall": 0.020531,
        "f1": 0.018337,
        "accuracy": 0.020531,
        "main_score": 0.018337,
        "hf_subset": "isl_Latn-ltz_Latn",
        "languages": [
          "isl-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.022449,
        "recall": 0.028042,
        "f1": 0.023268,
        "accuracy": 0.028042,
        "main_score": 0.023268,
        "hf_subset": "isl_Latn-nld_Latn",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.06621,
        "recall": 0.077116,
        "f1": 0.068362,
        "accuracy": 0.077116,
        "main_score": 0.068362,
        "hf_subset": "isl_Latn-nno_Latn",
        "languages": [
          "isl-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.065499,
        "recall": 0.076615,
        "f1": 0.067714,
        "accuracy": 0.076615,
        "main_score": 0.067714,
        "hf_subset": "isl_Latn-nob_Latn",
        "languages": [
          "isl-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.071318,
        "recall": 0.087131,
        "f1": 0.073991,
        "accuracy": 0.087131,
        "main_score": 0.073991,
        "hf_subset": "isl_Latn-swe_Latn",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.058274,
        "recall": 0.078117,
        "f1": 0.061839,
        "accuracy": 0.078117,
        "main_score": 0.061839,
        "hf_subset": "ita_Latn-cat_Latn",
        "languages": [
          "ita-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.193437,
        "recall": 0.224837,
        "f1": 0.199258,
        "accuracy": 0.224837,
        "main_score": 0.199258,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.211295,
        "recall": 0.248373,
        "f1": 0.219093,
        "accuracy": 0.248373,
        "main_score": 0.219093,
        "hf_subset": "ita_Latn-fra_Latn",
        "languages": [
          "ita-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.363047,
        "recall": 0.41362,
        "f1": 0.374515,
        "accuracy": 0.41362,
        "main_score": 0.374515,
        "hf_subset": "ita_Latn-glg_Latn",
        "languages": [
          "ita-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.023368,
        "recall": 0.034552,
        "f1": 0.025163,
        "accuracy": 0.034552,
        "main_score": 0.025163,
        "hf_subset": "ita_Latn-mlt_Latn",
        "languages": [
          "ita-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.189496,
        "recall": 0.218327,
        "f1": 0.195593,
        "accuracy": 0.218327,
        "main_score": 0.195593,
        "hf_subset": "ita_Latn-por_Latn",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.113346,
        "recall": 0.143716,
        "f1": 0.119765,
        "accuracy": 0.143716,
        "main_score": 0.119765,
        "hf_subset": "ita_Latn-ron_Latn",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.299392,
        "recall": 0.345018,
        "f1": 0.309127,
        "accuracy": 0.345018,
        "main_score": 0.309127,
        "hf_subset": "ita_Latn-spa_Latn",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "jpn_Jpan-arb_Arab",
        "languages": [
          "jpn-Jpan",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "jpn_Jpan-ben_Beng",
        "languages": [
          "jpn-Jpan",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000574,
        "recall": 0.002003,
        "f1": 0.000637,
        "accuracy": 0.002003,
        "main_score": 0.000637,
        "hf_subset": "jpn_Jpan-deu_Latn",
        "languages": [
          "jpn-Jpan",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "jpn_Jpan-ell_Grek",
        "languages": [
          "jpn-Jpan",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.002588,
        "recall": 0.005508,
        "f1": 0.002658,
        "accuracy": 0.005508,
        "main_score": 0.002658,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "jpn_Jpan-fas_Arab",
        "languages": [
          "jpn-Jpan",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.001044,
        "recall": 0.002003,
        "f1": 0.001079,
        "accuracy": 0.002003,
        "main_score": 0.001079,
        "hf_subset": "jpn_Jpan-fin_Latn",
        "languages": [
          "jpn-Jpan",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.001022,
        "recall": 0.003505,
        "f1": 0.001042,
        "accuracy": 0.003505,
        "main_score": 0.001042,
        "hf_subset": "jpn_Jpan-fra_Latn",
        "languages": [
          "jpn-Jpan",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002003,
        "f1": 0.001006,
        "accuracy": 0.002003,
        "main_score": 0.001006,
        "hf_subset": "jpn_Jpan-heb_Hebr",
        "languages": [
          "jpn-Jpan",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001027,
        "recall": 0.002504,
        "f1": 0.00105,
        "accuracy": 0.002504,
        "main_score": 0.00105,
        "hf_subset": "jpn_Jpan-hin_Deva",
        "languages": [
          "jpn-Jpan",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "jpn_Jpan-hun_Latn",
        "languages": [
          "jpn-Jpan",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.00156,
        "recall": 0.003505,
        "f1": 0.001612,
        "accuracy": 0.003505,
        "main_score": 0.001612,
        "hf_subset": "jpn_Jpan-ind_Latn",
        "languages": [
          "jpn-Jpan",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00121,
        "recall": 0.003505,
        "f1": 0.001354,
        "accuracy": 0.003505,
        "main_score": 0.001354,
        "hf_subset": "jpn_Jpan-kor_Hang",
        "languages": [
          "jpn-Jpan",
          "kor-Hang"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "jpn_Jpan-lit_Latn",
        "languages": [
          "jpn-Jpan",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.001545,
        "recall": 0.002504,
        "f1": 0.001581,
        "accuracy": 0.002504,
        "main_score": 0.001581,
        "hf_subset": "jpn_Jpan-nld_Latn",
        "languages": [
          "jpn-Jpan",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.000557,
        "recall": 0.001502,
        "f1": 0.000602,
        "accuracy": 0.001502,
        "main_score": 0.000602,
        "hf_subset": "jpn_Jpan-pol_Latn",
        "languages": [
          "jpn-Jpan",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001275,
        "recall": 0.002504,
        "f1": 0.001379,
        "accuracy": 0.002504,
        "main_score": 0.001379,
        "hf_subset": "jpn_Jpan-por_Latn",
        "languages": [
          "jpn-Jpan",
          "por-Latn"
        ]
      },
      {
        "precision": 0.002003,
        "recall": 0.003005,
        "f1": 0.002171,
        "accuracy": 0.003005,
        "main_score": 0.002171,
        "hf_subset": "jpn_Jpan-rus_Cyrl",
        "languages": [
          "jpn-Jpan",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "jpn_Jpan-spa_Latn",
        "languages": [
          "jpn-Jpan",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "jpn_Jpan-swa_Latn",
        "languages": [
          "jpn-Jpan",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "jpn_Jpan-swe_Latn",
        "languages": [
          "jpn-Jpan",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000503,
        "accuracy": 0.001502,
        "main_score": 0.000503,
        "hf_subset": "jpn_Jpan-tam_Taml",
        "languages": [
          "jpn-Jpan",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "jpn_Jpan-tur_Latn",
        "languages": [
          "jpn-Jpan",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000727,
        "recall": 0.003505,
        "f1": 0.000863,
        "accuracy": 0.003505,
        "main_score": 0.000863,
        "hf_subset": "jpn_Jpan-vie_Latn",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.037857,
        "recall": 0.055583,
        "f1": 0.040451,
        "accuracy": 0.055583,
        "main_score": 0.040451,
        "hf_subset": "jpn_Jpan-yue_Hant",
        "languages": [
          "jpn-Jpan",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.002098,
        "recall": 0.004006,
        "f1": 0.002179,
        "accuracy": 0.004006,
        "main_score": 0.002179,
        "hf_subset": "jpn_Jpan-zho_Hans",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.041,
        "recall": 0.06009,
        "f1": 0.0442,
        "accuracy": 0.06009,
        "main_score": 0.0442,
        "hf_subset": "jpn_Jpan-zho_Hant",
        "languages": [
          "jpn-Jpan",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "jpn_Jpan-zul_Latn",
        "languages": [
          "jpn-Jpan",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.056795,
        "recall": 0.08663,
        "f1": 0.061738,
        "accuracy": 0.08663,
        "main_score": 0.061738,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 5.2e-05,
        "recall": 0.002504,
        "f1": 0.0001,
        "accuracy": 0.002504,
        "main_score": 0.0001,
        "hf_subset": "kan_Knda-div_Thaa",
        "languages": [
          "kan-Knda",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.055581,
        "recall": 0.075113,
        "f1": 0.058662,
        "accuracy": 0.075113,
        "main_score": 0.058662,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027805,
        "recall": 0.047071,
        "f1": 0.030472,
        "accuracy": 0.047071,
        "main_score": 0.030472,
        "hf_subset": "kan_Knda-eus_Latn",
        "languages": [
          "kan-Knda",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.057893,
        "recall": 0.092639,
        "f1": 0.063285,
        "accuracy": 0.092639,
        "main_score": 0.063285,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.151288,
        "recall": 0.204306,
        "f1": 0.161933,
        "accuracy": 0.204306,
        "main_score": 0.161933,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.097924,
        "recall": 0.134201,
        "f1": 0.10386,
        "accuracy": 0.134201,
        "main_score": 0.10386,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.111954,
        "recall": 0.15974,
        "f1": 0.121184,
        "accuracy": 0.15974,
        "main_score": 0.121184,
        "hf_subset": "kan_Knda-nep_Deva",
        "languages": [
          "kan-Knda",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.092924,
        "recall": 0.135704,
        "f1": 0.100804,
        "accuracy": 0.135704,
        "main_score": 0.100804,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001371,
        "recall": 0.006009,
        "f1": 0.001821,
        "accuracy": 0.006009,
        "main_score": 0.001821,
        "hf_subset": "kan_Knda-sin_Sinh",
        "languages": [
          "kan-Knda",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.001496,
        "recall": 0.005008,
        "f1": 0.001896,
        "accuracy": 0.005008,
        "main_score": 0.001896,
        "hf_subset": "kan_Knda-snd_Arab",
        "languages": [
          "kan-Knda",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.036351,
        "recall": 0.063095,
        "f1": 0.039793,
        "accuracy": 0.063095,
        "main_score": 0.039793,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.101037,
        "recall": 0.143716,
        "f1": 0.108198,
        "accuracy": 0.143716,
        "main_score": 0.108198,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.022089,
        "recall": 0.039559,
        "f1": 0.024543,
        "accuracy": 0.039559,
        "main_score": 0.024543,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002669,
        "recall": 0.006009,
        "f1": 0.003166,
        "accuracy": 0.006009,
        "main_score": 0.003166,
        "hf_subset": "kat_Geor-ell_Grek",
        "languages": [
          "kat-Geor",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.001638,
        "recall": 0.003505,
        "f1": 0.001723,
        "accuracy": 0.003505,
        "main_score": 0.001723,
        "hf_subset": "kat_Geor-eng_Latn",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012403,
        "recall": 0.016024,
        "f1": 0.012997,
        "accuracy": 0.016024,
        "main_score": 0.012997,
        "hf_subset": "kat_Geor-hye_Armn",
        "languages": [
          "kat-Geor",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.004515,
        "recall": 0.006009,
        "f1": 0.004691,
        "accuracy": 0.006009,
        "main_score": 0.004691,
        "hf_subset": "kat_Geor-sqi_Latn",
        "languages": [
          "kat-Geor",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.009521,
        "recall": 0.012018,
        "f1": 0.009695,
        "accuracy": 0.012018,
        "main_score": 0.009695,
        "hf_subset": "kaz_Cyrl-aze_Latn",
        "languages": [
          "kaz-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.096789,
        "recall": 0.132699,
        "f1": 0.103784,
        "accuracy": 0.132699,
        "main_score": 0.103784,
        "hf_subset": "kaz_Cyrl-bak_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.002254,
        "recall": 0.003005,
        "f1": 0.002338,
        "accuracy": 0.003005,
        "main_score": 0.002338,
        "hf_subset": "kaz_Cyrl-eng_Latn",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.157176,
        "recall": 0.188282,
        "f1": 0.164301,
        "accuracy": 0.188282,
        "main_score": 0.164301,
        "hf_subset": "kaz_Cyrl-kir_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.114584,
        "recall": 0.152729,
        "f1": 0.122497,
        "accuracy": 0.152729,
        "main_score": 0.122497,
        "hf_subset": "kaz_Cyrl-tat_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.006515,
        "recall": 0.008012,
        "f1": 0.006686,
        "accuracy": 0.008012,
        "main_score": 0.006686,
        "hf_subset": "kaz_Cyrl-tuk_Latn",
        "languages": [
          "kaz-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.006171,
        "recall": 0.010516,
        "f1": 0.006636,
        "accuracy": 0.010516,
        "main_score": 0.006636,
        "hf_subset": "kaz_Cyrl-tur_Latn",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000185,
        "recall": 0.002504,
        "f1": 0.000324,
        "accuracy": 0.002504,
        "main_score": 0.000324,
        "hf_subset": "kaz_Cyrl-uig_Arab",
        "languages": [
          "kaz-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.002273,
        "recall": 0.004006,
        "f1": 0.002427,
        "accuracy": 0.004006,
        "main_score": 0.002427,
        "hf_subset": "kaz_Cyrl-uzb_Latn",
        "languages": [
          "kaz-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.007665,
        "recall": 0.012519,
        "f1": 0.008264,
        "accuracy": 0.012519,
        "main_score": 0.008264,
        "hf_subset": "khm_Khmr-bod_Tibt",
        "languages": [
          "khm-Khmr",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000335,
        "accuracy": 0.001002,
        "main_score": 0.000335,
        "hf_subset": "khm_Khmr-dzo_Tibt",
        "languages": [
          "khm-Khmr",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.008448,
        "recall": 0.011017,
        "f1": 0.008862,
        "accuracy": 0.011017,
        "main_score": 0.008862,
        "hf_subset": "khm_Khmr-eng_Latn",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021445,
        "recall": 0.028042,
        "f1": 0.022633,
        "accuracy": 0.028042,
        "main_score": 0.022633,
        "hf_subset": "khm_Khmr-lao_Laoo",
        "languages": [
          "khm-Khmr",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.002516,
        "recall": 0.004507,
        "f1": 0.002694,
        "accuracy": 0.004507,
        "main_score": 0.002694,
        "hf_subset": "khm_Khmr-mon_Mong",
        "languages": [
          "khm-Khmr",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.009498,
        "recall": 0.014522,
        "f1": 0.010246,
        "accuracy": 0.014522,
        "main_score": 0.010246,
        "hf_subset": "khm_Khmr-mya_Mymr",
        "languages": [
          "khm-Khmr",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.02581,
        "recall": 0.037056,
        "f1": 0.028005,
        "accuracy": 0.037056,
        "main_score": 0.028005,
        "hf_subset": "khm_Khmr-tha_Thai",
        "languages": [
          "khm-Khmr",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.041303,
        "recall": 0.057586,
        "f1": 0.044449,
        "accuracy": 0.057586,
        "main_score": 0.044449,
        "hf_subset": "kin_Latn-bem_Latn",
        "languages": [
          "kin-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.027024,
        "recall": 0.038558,
        "f1": 0.028766,
        "accuracy": 0.038558,
        "main_score": 0.028766,
        "hf_subset": "kin_Latn-eng_Latn",
        "languages": [
          "kin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016172,
        "recall": 0.019029,
        "f1": 0.016495,
        "accuracy": 0.019029,
        "main_score": 0.016495,
        "hf_subset": "kin_Latn-ewe_Latn",
        "languages": [
          "kin-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.007486,
        "recall": 0.009014,
        "f1": 0.007878,
        "accuracy": 0.009014,
        "main_score": 0.007878,
        "hf_subset": "kin_Latn-fuc_Latn",
        "languages": [
          "kin-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.022802,
        "recall": 0.032048,
        "f1": 0.024333,
        "accuracy": 0.032048,
        "main_score": 0.024333,
        "hf_subset": "kin_Latn-nde_Latn",
        "languages": [
          "kin-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.042006,
        "recall": 0.056084,
        "f1": 0.04487,
        "accuracy": 0.056084,
        "main_score": 0.04487,
        "hf_subset": "kin_Latn-nya_Latn",
        "languages": [
          "kin-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.025655,
        "recall": 0.034552,
        "f1": 0.027531,
        "accuracy": 0.034552,
        "main_score": 0.027531,
        "hf_subset": "kin_Latn-sna_Latn",
        "languages": [
          "kin-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.014683,
        "recall": 0.022033,
        "f1": 0.015957,
        "accuracy": 0.022033,
        "main_score": 0.015957,
        "hf_subset": "kin_Latn-ven_Latn",
        "languages": [
          "kin-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.007826,
        "recall": 0.010516,
        "f1": 0.008172,
        "accuracy": 0.010516,
        "main_score": 0.008172,
        "hf_subset": "kir_Cyrl-aze_Latn",
        "languages": [
          "kir-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.096262,
        "recall": 0.1332,
        "f1": 0.103017,
        "accuracy": 0.1332,
        "main_score": 0.103017,
        "hf_subset": "kir_Cyrl-bak_Cyrl",
        "languages": [
          "kir-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.00344,
        "recall": 0.005508,
        "f1": 0.003675,
        "accuracy": 0.005508,
        "main_score": 0.003675,
        "hf_subset": "kir_Cyrl-eng_Latn",
        "languages": [
          "kir-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.124126,
        "recall": 0.17326,
        "f1": 0.133699,
        "accuracy": 0.17326,
        "main_score": 0.133699,
        "hf_subset": "kir_Cyrl-kaz_Cyrl",
        "languages": [
          "kir-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.13115,
        "recall": 0.176264,
        "f1": 0.140482,
        "accuracy": 0.176264,
        "main_score": 0.140482,
        "hf_subset": "kir_Cyrl-tat_Cyrl",
        "languages": [
          "kir-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.009133,
        "recall": 0.011017,
        "f1": 0.009551,
        "accuracy": 0.011017,
        "main_score": 0.009551,
        "hf_subset": "kir_Cyrl-tuk_Latn",
        "languages": [
          "kir-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.008111,
        "recall": 0.012519,
        "f1": 0.008428,
        "accuracy": 0.012519,
        "main_score": 0.008428,
        "hf_subset": "kir_Cyrl-tur_Latn",
        "languages": [
          "kir-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00189,
        "recall": 0.005508,
        "f1": 0.002086,
        "accuracy": 0.005508,
        "main_score": 0.002086,
        "hf_subset": "kir_Cyrl-uig_Arab",
        "languages": [
          "kir-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.004178,
        "recall": 0.006009,
        "f1": 0.004433,
        "accuracy": 0.006009,
        "main_score": 0.004433,
        "hf_subset": "kir_Cyrl-uzb_Latn",
        "languages": [
          "kir-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "kmr_Latn-arb_Arab",
        "languages": [
          "kmr-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "kmr_Latn-ckb_Arab",
        "languages": [
          "kmr-Latn",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.012578,
        "recall": 0.017526,
        "f1": 0.01306,
        "accuracy": 0.017526,
        "main_score": 0.01306,
        "hf_subset": "kmr_Latn-eng_Latn",
        "languages": [
          "kmr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "kmr_Latn-fas_Arab",
        "languages": [
          "kmr-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000858,
        "recall": 0.002504,
        "f1": 0.001016,
        "accuracy": 0.002504,
        "main_score": 0.001016,
        "hf_subset": "kmr_Latn-heb_Hebr",
        "languages": [
          "kmr-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "kmr_Latn-mey_Arab",
        "languages": [
          "kmr-Latn",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "kmr_Latn-prs_Arab",
        "languages": [
          "kmr-Latn",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000169,
        "recall": 0.001502,
        "f1": 0.000254,
        "accuracy": 0.001502,
        "main_score": 0.000254,
        "hf_subset": "kmr_Latn-pus_Arab",
        "languages": [
          "kmr-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "kmr_Latn-shi_Arab",
        "languages": [
          "kmr-Latn",
          "shi-Arab"
        ]
      },
      {
        "precision": 7.8e-05,
        "recall": 0.001502,
        "f1": 0.000138,
        "accuracy": 0.001502,
        "main_score": 0.000138,
        "hf_subset": "kmr_Latn-tgk_Cyrl",
        "languages": [
          "kmr-Latn",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.000452,
        "recall": 0.003505,
        "f1": 0.000653,
        "accuracy": 0.003505,
        "main_score": 0.000653,
        "hf_subset": "kor_Hang-arb_Arab",
        "languages": [
          "kor-Hang",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.002606,
        "recall": 0.007511,
        "f1": 0.002935,
        "accuracy": 0.007511,
        "main_score": 0.002935,
        "hf_subset": "kor_Hang-ben_Beng",
        "languages": [
          "kor-Hang",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.005165,
        "recall": 0.007511,
        "f1": 0.005437,
        "accuracy": 0.007511,
        "main_score": 0.005437,
        "hf_subset": "kor_Hang-deu_Latn",
        "languages": [
          "kor-Hang",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.00257,
        "recall": 0.006009,
        "f1": 0.003023,
        "accuracy": 0.006009,
        "main_score": 0.003023,
        "hf_subset": "kor_Hang-ell_Grek",
        "languages": [
          "kor-Hang",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.005322,
        "recall": 0.011017,
        "f1": 0.005726,
        "accuracy": 0.011017,
        "main_score": 0.005726,
        "hf_subset": "kor_Hang-eng_Latn",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.002003,
        "f1": 0.000674,
        "accuracy": 0.002003,
        "main_score": 0.000674,
        "hf_subset": "kor_Hang-fas_Arab",
        "languages": [
          "kor-Hang",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.00357,
        "recall": 0.006009,
        "f1": 0.003791,
        "accuracy": 0.006009,
        "main_score": 0.003791,
        "hf_subset": "kor_Hang-fin_Latn",
        "languages": [
          "kor-Hang",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.004306,
        "recall": 0.007011,
        "f1": 0.004652,
        "accuracy": 0.007011,
        "main_score": 0.004652,
        "hf_subset": "kor_Hang-fra_Latn",
        "languages": [
          "kor-Hang",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.00309,
        "recall": 0.006009,
        "f1": 0.003328,
        "accuracy": 0.006009,
        "main_score": 0.003328,
        "hf_subset": "kor_Hang-heb_Hebr",
        "languages": [
          "kor-Hang",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00118,
        "recall": 0.005008,
        "f1": 0.001327,
        "accuracy": 0.005008,
        "main_score": 0.001327,
        "hf_subset": "kor_Hang-hin_Deva",
        "languages": [
          "kor-Hang",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001847,
        "recall": 0.003505,
        "f1": 0.002001,
        "accuracy": 0.003505,
        "main_score": 0.002001,
        "hf_subset": "kor_Hang-hun_Latn",
        "languages": [
          "kor-Hang",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001689,
        "recall": 0.005508,
        "f1": 0.002031,
        "accuracy": 0.005508,
        "main_score": 0.002031,
        "hf_subset": "kor_Hang-ind_Latn",
        "languages": [
          "kor-Hang",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.004768,
        "recall": 0.009014,
        "f1": 0.005278,
        "accuracy": 0.009014,
        "main_score": 0.005278,
        "hf_subset": "kor_Hang-jpn_Jpan",
        "languages": [
          "kor-Hang",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.004234,
        "recall": 0.006009,
        "f1": 0.004379,
        "accuracy": 0.006009,
        "main_score": 0.004379,
        "hf_subset": "kor_Hang-lit_Latn",
        "languages": [
          "kor-Hang",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.004778,
        "recall": 0.007511,
        "f1": 0.005049,
        "accuracy": 0.007511,
        "main_score": 0.005049,
        "hf_subset": "kor_Hang-nld_Latn",
        "languages": [
          "kor-Hang",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.003438,
        "recall": 0.008012,
        "f1": 0.003666,
        "accuracy": 0.008012,
        "main_score": 0.003666,
        "hf_subset": "kor_Hang-pol_Latn",
        "languages": [
          "kor-Hang",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.00438,
        "recall": 0.008513,
        "f1": 0.00473,
        "accuracy": 0.008513,
        "main_score": 0.00473,
        "hf_subset": "kor_Hang-por_Latn",
        "languages": [
          "kor-Hang",
          "por-Latn"
        ]
      },
      {
        "precision": 0.01131,
        "recall": 0.022534,
        "f1": 0.012227,
        "accuracy": 0.022534,
        "main_score": 0.012227,
        "hf_subset": "kor_Hang-rus_Cyrl",
        "languages": [
          "kor-Hang",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.003298,
        "recall": 0.005508,
        "f1": 0.003625,
        "accuracy": 0.005508,
        "main_score": 0.003625,
        "hf_subset": "kor_Hang-spa_Latn",
        "languages": [
          "kor-Hang",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.005649,
        "recall": 0.009014,
        "f1": 0.005754,
        "accuracy": 0.009014,
        "main_score": 0.005754,
        "hf_subset": "kor_Hang-swa_Latn",
        "languages": [
          "kor-Hang",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.004866,
        "recall": 0.00651,
        "f1": 0.005024,
        "accuracy": 0.00651,
        "main_score": 0.005024,
        "hf_subset": "kor_Hang-swe_Latn",
        "languages": [
          "kor-Hang",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.002139,
        "recall": 0.006009,
        "f1": 0.002639,
        "accuracy": 0.006009,
        "main_score": 0.002639,
        "hf_subset": "kor_Hang-tam_Taml",
        "languages": [
          "kor-Hang",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.005392,
        "recall": 0.007511,
        "f1": 0.005574,
        "accuracy": 0.007511,
        "main_score": 0.005574,
        "hf_subset": "kor_Hang-tur_Latn",
        "languages": [
          "kor-Hang",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.005343,
        "recall": 0.010015,
        "f1": 0.005945,
        "accuracy": 0.010015,
        "main_score": 0.005945,
        "hf_subset": "kor_Hang-vie_Latn",
        "languages": [
          "kor-Hang",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.003133,
        "recall": 0.007011,
        "f1": 0.003244,
        "accuracy": 0.007011,
        "main_score": 0.003244,
        "hf_subset": "kor_Hang-yue_Hant",
        "languages": [
          "kor-Hang",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.005619,
        "recall": 0.010015,
        "f1": 0.005929,
        "accuracy": 0.010015,
        "main_score": 0.005929,
        "hf_subset": "kor_Hang-zho_Hans",
        "languages": [
          "kor-Hang",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.009178,
        "recall": 0.01302,
        "f1": 0.009644,
        "accuracy": 0.01302,
        "main_score": 0.009644,
        "hf_subset": "kor_Hang-zho_Hant",
        "languages": [
          "kor-Hang",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.003284,
        "recall": 0.005508,
        "f1": 0.003394,
        "accuracy": 0.005508,
        "main_score": 0.003394,
        "hf_subset": "kor_Hang-zul_Latn",
        "languages": [
          "kor-Hang",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.014522,
        "recall": 0.022534,
        "f1": 0.015332,
        "accuracy": 0.022534,
        "main_score": 0.015332,
        "hf_subset": "lao_Laoo-bod_Tibt",
        "languages": [
          "lao-Laoo",
          "bod-Tibt"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.001002,
        "f1": 1.9e-05,
        "accuracy": 0.001002,
        "main_score": 1.9e-05,
        "hf_subset": "lao_Laoo-dzo_Tibt",
        "languages": [
          "lao-Laoo",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.011632,
        "recall": 0.018528,
        "f1": 0.012404,
        "accuracy": 0.018528,
        "main_score": 0.012404,
        "hf_subset": "lao_Laoo-eng_Latn",
        "languages": [
          "lao-Laoo",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019659,
        "recall": 0.031047,
        "f1": 0.021477,
        "accuracy": 0.031047,
        "main_score": 0.021477,
        "hf_subset": "lao_Laoo-khm_Khmr",
        "languages": [
          "lao-Laoo",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.001385,
        "recall": 0.004006,
        "f1": 0.00158,
        "accuracy": 0.004006,
        "main_score": 0.00158,
        "hf_subset": "lao_Laoo-mon_Mong",
        "languages": [
          "lao-Laoo",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.020649,
        "recall": 0.030546,
        "f1": 0.022322,
        "accuracy": 0.030546,
        "main_score": 0.022322,
        "hf_subset": "lao_Laoo-mya_Mymr",
        "languages": [
          "lao-Laoo",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.030275,
        "recall": 0.038558,
        "f1": 0.031351,
        "accuracy": 0.038558,
        "main_score": 0.031351,
        "hf_subset": "lao_Laoo-tha_Thai",
        "languages": [
          "lao-Laoo",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.006597,
        "recall": 0.011017,
        "f1": 0.006881,
        "accuracy": 0.011017,
        "main_score": 0.006881,
        "hf_subset": "lav_Latn-eng_Latn",
        "languages": [
          "lav-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018479,
        "recall": 0.025538,
        "f1": 0.019399,
        "accuracy": 0.025538,
        "main_score": 0.019399,
        "hf_subset": "lav_Latn-fin_Latn",
        "languages": [
          "lav-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.008223,
        "recall": 0.011517,
        "f1": 0.00856,
        "accuracy": 0.011517,
        "main_score": 0.00856,
        "hf_subset": "lav_Latn-hun_Latn",
        "languages": [
          "lav-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.079362,
        "recall": 0.103155,
        "f1": 0.084202,
        "accuracy": 0.103155,
        "main_score": 0.084202,
        "hf_subset": "lav_Latn-lit_Latn",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "lit_Latn-arb_Arab",
        "languages": [
          "lit-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000263,
        "recall": 0.002003,
        "f1": 0.000359,
        "accuracy": 0.002003,
        "main_score": 0.000359,
        "hf_subset": "lit_Latn-ben_Beng",
        "languages": [
          "lit-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.012601,
        "recall": 0.018528,
        "f1": 0.013474,
        "accuracy": 0.018528,
        "main_score": 0.013474,
        "hf_subset": "lit_Latn-deu_Latn",
        "languages": [
          "lit-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 4e-05,
        "recall": 0.001002,
        "f1": 7.4e-05,
        "accuracy": 0.001002,
        "main_score": 7.4e-05,
        "hf_subset": "lit_Latn-ell_Grek",
        "languages": [
          "lit-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.008719,
        "recall": 0.01302,
        "f1": 0.009261,
        "accuracy": 0.01302,
        "main_score": 0.009261,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "lit_Latn-fas_Arab",
        "languages": [
          "lit-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.025146,
        "recall": 0.037556,
        "f1": 0.026885,
        "accuracy": 0.037556,
        "main_score": 0.026885,
        "hf_subset": "lit_Latn-fin_Latn",
        "languages": [
          "lit-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.005873,
        "recall": 0.009014,
        "f1": 0.006216,
        "accuracy": 0.009014,
        "main_score": 0.006216,
        "hf_subset": "lit_Latn-fra_Latn",
        "languages": [
          "lit-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001255,
        "recall": 0.002504,
        "f1": 0.001342,
        "accuracy": 0.002504,
        "main_score": 0.001342,
        "hf_subset": "lit_Latn-heb_Hebr",
        "languages": [
          "lit-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "lit_Latn-hin_Deva",
        "languages": [
          "lit-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.011084,
        "recall": 0.014021,
        "f1": 0.011313,
        "accuracy": 0.014021,
        "main_score": 0.011313,
        "hf_subset": "lit_Latn-hun_Latn",
        "languages": [
          "lit-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.006314,
        "recall": 0.010015,
        "f1": 0.006666,
        "accuracy": 0.010015,
        "main_score": 0.006666,
        "hf_subset": "lit_Latn-ind_Latn",
        "languages": [
          "lit-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "lit_Latn-jpn_Jpan",
        "languages": [
          "lit-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 3.3e-05,
        "recall": 0.001002,
        "f1": 6.1e-05,
        "accuracy": 0.001002,
        "main_score": 6.1e-05,
        "hf_subset": "lit_Latn-kor_Hang",
        "languages": [
          "lit-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.059978,
        "recall": 0.075113,
        "f1": 0.062801,
        "accuracy": 0.075113,
        "main_score": 0.062801,
        "hf_subset": "lit_Latn-lav_Latn",
        "languages": [
          "lit-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.023079,
        "recall": 0.029544,
        "f1": 0.02409,
        "accuracy": 0.029544,
        "main_score": 0.02409,
        "hf_subset": "lit_Latn-nld_Latn",
        "languages": [
          "lit-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.011323,
        "recall": 0.016525,
        "f1": 0.012079,
        "accuracy": 0.016525,
        "main_score": 0.012079,
        "hf_subset": "lit_Latn-pol_Latn",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.005236,
        "recall": 0.010516,
        "f1": 0.005794,
        "accuracy": 0.010516,
        "main_score": 0.005794,
        "hf_subset": "lit_Latn-por_Latn",
        "languages": [
          "lit-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000753,
        "recall": 0.002003,
        "f1": 0.000838,
        "accuracy": 0.002003,
        "main_score": 0.000838,
        "hf_subset": "lit_Latn-rus_Cyrl",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.008854,
        "recall": 0.01352,
        "f1": 0.009323,
        "accuracy": 0.01352,
        "main_score": 0.009323,
        "hf_subset": "lit_Latn-spa_Latn",
        "languages": [
          "lit-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.002524,
        "recall": 0.003505,
        "f1": 0.002543,
        "accuracy": 0.003505,
        "main_score": 0.002543,
        "hf_subset": "lit_Latn-swa_Latn",
        "languages": [
          "lit-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.031048,
        "recall": 0.041562,
        "f1": 0.032611,
        "accuracy": 0.041562,
        "main_score": 0.032611,
        "hf_subset": "lit_Latn-swe_Latn",
        "languages": [
          "lit-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "lit_Latn-tam_Taml",
        "languages": [
          "lit-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.006083,
        "recall": 0.007511,
        "f1": 0.006139,
        "accuracy": 0.007511,
        "main_score": 0.006139,
        "hf_subset": "lit_Latn-tur_Latn",
        "languages": [
          "lit-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.002921,
        "recall": 0.004006,
        "f1": 0.003088,
        "accuracy": 0.004006,
        "main_score": 0.003088,
        "hf_subset": "lit_Latn-vie_Latn",
        "languages": [
          "lit-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000639,
        "recall": 0.002504,
        "f1": 0.000746,
        "accuracy": 0.002504,
        "main_score": 0.000746,
        "hf_subset": "lit_Latn-zho_Hant",
        "languages": [
          "lit-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.012728,
        "recall": 0.017526,
        "f1": 0.01355,
        "accuracy": 0.017526,
        "main_score": 0.01355,
        "hf_subset": "lit_Latn-zul_Latn",
        "languages": [
          "lit-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.099239,
        "recall": 0.118177,
        "f1": 0.102848,
        "accuracy": 0.118177,
        "main_score": 0.102848,
        "hf_subset": "ltz_Latn-afr_Latn",
        "languages": [
          "ltz-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.065255,
        "recall": 0.076615,
        "f1": 0.067182,
        "accuracy": 0.076615,
        "main_score": 0.067182,
        "hf_subset": "ltz_Latn-dan_Latn",
        "languages": [
          "ltz-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.127861,
        "recall": 0.151227,
        "f1": 0.132266,
        "accuracy": 0.151227,
        "main_score": 0.132266,
        "hf_subset": "ltz_Latn-deu_Latn",
        "languages": [
          "ltz-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.028796,
        "recall": 0.035553,
        "f1": 0.029719,
        "accuracy": 0.035553,
        "main_score": 0.029719,
        "hf_subset": "ltz_Latn-eng_Latn",
        "languages": [
          "ltz-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028648,
        "recall": 0.035553,
        "f1": 0.029754,
        "accuracy": 0.035553,
        "main_score": 0.029754,
        "hf_subset": "ltz_Latn-fao_Latn",
        "languages": [
          "ltz-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.017474,
        "recall": 0.024537,
        "f1": 0.01878,
        "accuracy": 0.024537,
        "main_score": 0.01878,
        "hf_subset": "ltz_Latn-isl_Latn",
        "languages": [
          "ltz-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.087672,
        "recall": 0.107661,
        "f1": 0.091691,
        "accuracy": 0.107661,
        "main_score": 0.091691,
        "hf_subset": "ltz_Latn-nld_Latn",
        "languages": [
          "ltz-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.060063,
        "recall": 0.071607,
        "f1": 0.062135,
        "accuracy": 0.071607,
        "main_score": 0.062135,
        "hf_subset": "ltz_Latn-nno_Latn",
        "languages": [
          "ltz-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.064162,
        "recall": 0.076114,
        "f1": 0.066504,
        "accuracy": 0.076114,
        "main_score": 0.066504,
        "hf_subset": "ltz_Latn-nob_Latn",
        "languages": [
          "ltz-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.070551,
        "recall": 0.086129,
        "f1": 0.073635,
        "accuracy": 0.086129,
        "main_score": 0.073635,
        "hf_subset": "ltz_Latn-swe_Latn",
        "languages": [
          "ltz-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.041123,
        "recall": 0.057586,
        "f1": 0.043847,
        "accuracy": 0.057586,
        "main_score": 0.043847,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002142,
        "recall": 0.003005,
        "f1": 0.002241,
        "accuracy": 0.003005,
        "main_score": 0.002241,
        "hf_subset": "mal_Mlym-fij_Latn",
        "languages": [
          "mal-Mlym",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.008115,
        "recall": 0.014021,
        "f1": 0.008703,
        "accuracy": 0.014021,
        "main_score": 0.008703,
        "hf_subset": "mal_Mlym-fil_Latn",
        "languages": [
          "mal-Mlym",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.012354,
        "recall": 0.020531,
        "f1": 0.013376,
        "accuracy": 0.020531,
        "main_score": 0.013376,
        "hf_subset": "mal_Mlym-ind_Latn",
        "languages": [
          "mal-Mlym",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00154,
        "recall": 0.003005,
        "f1": 0.001741,
        "accuracy": 0.003005,
        "main_score": 0.001741,
        "hf_subset": "mal_Mlym-mlg_Latn",
        "languages": [
          "mal-Mlym",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.001338,
        "recall": 0.004006,
        "f1": 0.001498,
        "accuracy": 0.004006,
        "main_score": 0.001498,
        "hf_subset": "mal_Mlym-mri_Latn",
        "languages": [
          "mal-Mlym",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.006784,
        "recall": 0.012018,
        "f1": 0.007697,
        "accuracy": 0.012018,
        "main_score": 0.007697,
        "hf_subset": "mal_Mlym-msa_Latn",
        "languages": [
          "mal-Mlym",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.002172,
        "recall": 0.004006,
        "f1": 0.002425,
        "accuracy": 0.004006,
        "main_score": 0.002425,
        "hf_subset": "mal_Mlym-smo_Latn",
        "languages": [
          "mal-Mlym",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.001892,
        "recall": 0.005008,
        "f1": 0.002097,
        "accuracy": 0.005008,
        "main_score": 0.002097,
        "hf_subset": "mal_Mlym-tah_Latn",
        "languages": [
          "mal-Mlym",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.003288,
        "recall": 0.005508,
        "f1": 0.003635,
        "accuracy": 0.005508,
        "main_score": 0.003635,
        "hf_subset": "mal_Mlym-ton_Latn",
        "languages": [
          "mal-Mlym",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.044933,
        "recall": 0.068102,
        "f1": 0.048645,
        "accuracy": 0.068102,
        "main_score": 0.048645,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000324,
        "recall": 0.002003,
        "f1": 0.000469,
        "accuracy": 0.002003,
        "main_score": 0.000469,
        "hf_subset": "mar_Deva-div_Thaa",
        "languages": [
          "mar-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.024279,
        "recall": 0.035553,
        "f1": 0.026132,
        "accuracy": 0.035553,
        "main_score": 0.026132,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028142,
        "recall": 0.047571,
        "f1": 0.030568,
        "accuracy": 0.047571,
        "main_score": 0.030568,
        "hf_subset": "mar_Deva-eus_Latn",
        "languages": [
          "mar-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.01488,
        "recall": 0.025538,
        "f1": 0.015961,
        "accuracy": 0.025538,
        "main_score": 0.015961,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.231095,
        "recall": 0.282924,
        "f1": 0.24242,
        "accuracy": 0.282924,
        "main_score": 0.24242,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.039449,
        "recall": 0.056084,
        "f1": 0.042112,
        "accuracy": 0.056084,
        "main_score": 0.042112,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.098679,
        "recall": 0.124687,
        "f1": 0.10444,
        "accuracy": 0.124687,
        "main_score": 0.10444,
        "hf_subset": "mar_Deva-nep_Deva",
        "languages": [
          "mar-Deva",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.046115,
        "recall": 0.072108,
        "f1": 0.050328,
        "accuracy": 0.072108,
        "main_score": 0.050328,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001231,
        "recall": 0.004507,
        "f1": 0.001401,
        "accuracy": 0.004507,
        "main_score": 0.001401,
        "hf_subset": "mar_Deva-sin_Sinh",
        "languages": [
          "mar-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000338,
        "recall": 0.001502,
        "f1": 0.000485,
        "accuracy": 0.001502,
        "main_score": 0.000485,
        "hf_subset": "mar_Deva-snd_Arab",
        "languages": [
          "mar-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.019605,
        "recall": 0.031547,
        "f1": 0.02111,
        "accuracy": 0.031547,
        "main_score": 0.02111,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.0306,
        "recall": 0.047071,
        "f1": 0.033518,
        "accuracy": 0.047071,
        "main_score": 0.033518,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004781,
        "recall": 0.009014,
        "f1": 0.004959,
        "accuracy": 0.009014,
        "main_score": 0.004959,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.403981,
        "recall": 0.463696,
        "f1": 0.418579,
        "accuracy": 0.463696,
        "main_score": 0.418579,
        "hf_subset": "mey_Arab-arb_Arab",
        "languages": [
          "mey-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000601,
        "recall": 0.001502,
        "f1": 0.000668,
        "accuracy": 0.001502,
        "main_score": 0.000668,
        "hf_subset": "mey_Arab-ckb_Arab",
        "languages": [
          "mey-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.003912,
        "recall": 0.009514,
        "f1": 0.004203,
        "accuracy": 0.009514,
        "main_score": 0.004203,
        "hf_subset": "mey_Arab-eng_Latn",
        "languages": [
          "mey-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000763,
        "recall": 0.002003,
        "f1": 0.000857,
        "accuracy": 0.002003,
        "main_score": 0.000857,
        "hf_subset": "mey_Arab-fas_Arab",
        "languages": [
          "mey-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001002,
        "f1": 0.000507,
        "accuracy": 0.001002,
        "main_score": 0.000507,
        "hf_subset": "mey_Arab-heb_Hebr",
        "languages": [
          "mey-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "mey_Arab-kmr_Latn",
        "languages": [
          "mey-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000917,
        "recall": 0.004507,
        "f1": 0.001126,
        "accuracy": 0.004507,
        "main_score": 0.001126,
        "hf_subset": "mey_Arab-prs_Arab",
        "languages": [
          "mey-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000417,
        "recall": 0.001002,
        "f1": 0.000584,
        "accuracy": 0.001002,
        "main_score": 0.000584,
        "hf_subset": "mey_Arab-pus_Arab",
        "languages": [
          "mey-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.077482,
        "recall": 0.116675,
        "f1": 0.084851,
        "accuracy": 0.116675,
        "main_score": 0.084851,
        "hf_subset": "mey_Arab-shi_Arab",
        "languages": [
          "mey-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000507,
        "accuracy": 0.001502,
        "main_score": 0.000507,
        "hf_subset": "mey_Arab-tgk_Cyrl",
        "languages": [
          "mey-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.066326,
        "recall": 0.095143,
        "f1": 0.071133,
        "accuracy": 0.095143,
        "main_score": 0.071133,
        "hf_subset": "mkd_Cyrl-bel_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.017796,
        "recall": 0.027041,
        "f1": 0.018706,
        "accuracy": 0.027041,
        "main_score": 0.018706,
        "hf_subset": "mkd_Cyrl-bos_Latn",
        "languages": [
          "mkd-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.397765,
        "recall": 0.470205,
        "f1": 0.415191,
        "accuracy": 0.470205,
        "main_score": 0.415191,
        "hf_subset": "mkd_Cyrl-bul_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.007575,
        "recall": 0.012018,
        "f1": 0.008327,
        "accuracy": 0.012018,
        "main_score": 0.008327,
        "hf_subset": "mkd_Cyrl-ces_Latn",
        "languages": [
          "mkd-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.012205,
        "recall": 0.019029,
        "f1": 0.012602,
        "accuracy": 0.019029,
        "main_score": 0.012602,
        "hf_subset": "mkd_Cyrl-eng_Latn",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015534,
        "recall": 0.024036,
        "f1": 0.016514,
        "accuracy": 0.024036,
        "main_score": 0.016514,
        "hf_subset": "mkd_Cyrl-hrv_Latn",
        "languages": [
          "mkd-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.008491,
        "recall": 0.016024,
        "f1": 0.009181,
        "accuracy": 0.016024,
        "main_score": 0.009181,
        "hf_subset": "mkd_Cyrl-pol_Latn",
        "languages": [
          "mkd-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.100412,
        "recall": 0.129194,
        "f1": 0.105492,
        "accuracy": 0.129194,
        "main_score": 0.105492,
        "hf_subset": "mkd_Cyrl-rus_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.01095,
        "recall": 0.016024,
        "f1": 0.01147,
        "accuracy": 0.016024,
        "main_score": 0.01147,
        "hf_subset": "mkd_Cyrl-slk_Latn",
        "languages": [
          "mkd-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.010218,
        "recall": 0.019529,
        "f1": 0.011171,
        "accuracy": 0.019529,
        "main_score": 0.011171,
        "hf_subset": "mkd_Cyrl-slv_Latn",
        "languages": [
          "mkd-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.293753,
        "recall": 0.390085,
        "f1": 0.316637,
        "accuracy": 0.390085,
        "main_score": 0.316637,
        "hf_subset": "mkd_Cyrl-srp_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.019715,
        "recall": 0.029544,
        "f1": 0.020992,
        "accuracy": 0.029544,
        "main_score": 0.020992,
        "hf_subset": "mkd_Cyrl-srp_Latn",
        "languages": [
          "mkd-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.138698,
        "recall": 0.175764,
        "f1": 0.146437,
        "accuracy": 0.175764,
        "main_score": 0.146437,
        "hf_subset": "mkd_Cyrl-ukr_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.009629,
        "recall": 0.014522,
        "f1": 0.010006,
        "accuracy": 0.014522,
        "main_score": 0.010006,
        "hf_subset": "mlg_Latn-eng_Latn",
        "languages": [
          "mlg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027027,
        "recall": 0.036555,
        "f1": 0.028873,
        "accuracy": 0.036555,
        "main_score": 0.028873,
        "hf_subset": "mlg_Latn-fij_Latn",
        "languages": [
          "mlg-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.017601,
        "recall": 0.025038,
        "f1": 0.018667,
        "accuracy": 0.025038,
        "main_score": 0.018667,
        "hf_subset": "mlg_Latn-fil_Latn",
        "languages": [
          "mlg-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.004813,
        "recall": 0.008012,
        "f1": 0.005194,
        "accuracy": 0.008012,
        "main_score": 0.005194,
        "hf_subset": "mlg_Latn-ind_Latn",
        "languages": [
          "mlg-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mlg_Latn-mal_Mlym",
        "languages": [
          "mlg-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.026707,
        "recall": 0.036054,
        "f1": 0.02849,
        "accuracy": 0.036054,
        "main_score": 0.02849,
        "hf_subset": "mlg_Latn-mri_Latn",
        "languages": [
          "mlg-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.005201,
        "recall": 0.009014,
        "f1": 0.005359,
        "accuracy": 0.009014,
        "main_score": 0.005359,
        "hf_subset": "mlg_Latn-msa_Latn",
        "languages": [
          "mlg-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.034201,
        "recall": 0.044066,
        "f1": 0.036112,
        "accuracy": 0.044066,
        "main_score": 0.036112,
        "hf_subset": "mlg_Latn-smo_Latn",
        "languages": [
          "mlg-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.038148,
        "recall": 0.051577,
        "f1": 0.041127,
        "accuracy": 0.051577,
        "main_score": 0.041127,
        "hf_subset": "mlg_Latn-tah_Latn",
        "languages": [
          "mlg-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.007709,
        "recall": 0.011517,
        "f1": 0.008287,
        "accuracy": 0.011517,
        "main_score": 0.008287,
        "hf_subset": "mlg_Latn-ton_Latn",
        "languages": [
          "mlg-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.006975,
        "recall": 0.010015,
        "f1": 0.007223,
        "accuracy": 0.010015,
        "main_score": 0.007223,
        "hf_subset": "mlt_Latn-cat_Latn",
        "languages": [
          "mlt-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.020411,
        "recall": 0.026039,
        "f1": 0.021032,
        "accuracy": 0.026039,
        "main_score": 0.021032,
        "hf_subset": "mlt_Latn-eng_Latn",
        "languages": [
          "mlt-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008792,
        "recall": 0.012018,
        "f1": 0.008974,
        "accuracy": 0.012018,
        "main_score": 0.008974,
        "hf_subset": "mlt_Latn-fra_Latn",
        "languages": [
          "mlt-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.009749,
        "recall": 0.014021,
        "f1": 0.01009,
        "accuracy": 0.014021,
        "main_score": 0.01009,
        "hf_subset": "mlt_Latn-glg_Latn",
        "languages": [
          "mlt-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.021584,
        "recall": 0.030546,
        "f1": 0.022795,
        "accuracy": 0.030546,
        "main_score": 0.022795,
        "hf_subset": "mlt_Latn-ita_Latn",
        "languages": [
          "mlt-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.011264,
        "recall": 0.016525,
        "f1": 0.011872,
        "accuracy": 0.016525,
        "main_score": 0.011872,
        "hf_subset": "mlt_Latn-por_Latn",
        "languages": [
          "mlt-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.021699,
        "recall": 0.024537,
        "f1": 0.022354,
        "accuracy": 0.024537,
        "main_score": 0.022354,
        "hf_subset": "mlt_Latn-ron_Latn",
        "languages": [
          "mlt-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.011783,
        "recall": 0.016525,
        "f1": 0.012351,
        "accuracy": 0.016525,
        "main_score": 0.012351,
        "hf_subset": "mlt_Latn-spa_Latn",
        "languages": [
          "mlt-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001012,
        "recall": 0.002003,
        "f1": 0.001023,
        "accuracy": 0.002003,
        "main_score": 0.001023,
        "hf_subset": "mon_Mong-bod_Tibt",
        "languages": [
          "mon-Mong",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "mon_Mong-dzo_Tibt",
        "languages": [
          "mon-Mong",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.003942,
        "recall": 0.00651,
        "f1": 0.004155,
        "accuracy": 0.00651,
        "main_score": 0.004155,
        "hf_subset": "mon_Mong-eng_Latn",
        "languages": [
          "mon-Mong",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002319,
        "recall": 0.004006,
        "f1": 0.002454,
        "accuracy": 0.004006,
        "main_score": 0.002454,
        "hf_subset": "mon_Mong-khm_Khmr",
        "languages": [
          "mon-Mong",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.002661,
        "recall": 0.004507,
        "f1": 0.002765,
        "accuracy": 0.004507,
        "main_score": 0.002765,
        "hf_subset": "mon_Mong-lao_Laoo",
        "languages": [
          "mon-Mong",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.002986,
        "recall": 0.005008,
        "f1": 0.003219,
        "accuracy": 0.005008,
        "main_score": 0.003219,
        "hf_subset": "mon_Mong-mya_Mymr",
        "languages": [
          "mon-Mong",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.003176,
        "recall": 0.005508,
        "f1": 0.003303,
        "accuracy": 0.005508,
        "main_score": 0.003303,
        "hf_subset": "mon_Mong-tha_Thai",
        "languages": [
          "mon-Mong",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.008647,
        "recall": 0.011517,
        "f1": 0.008964,
        "accuracy": 0.011517,
        "main_score": 0.008964,
        "hf_subset": "mri_Latn-eng_Latn",
        "languages": [
          "mri-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022456,
        "recall": 0.028042,
        "f1": 0.023636,
        "accuracy": 0.028042,
        "main_score": 0.023636,
        "hf_subset": "mri_Latn-fij_Latn",
        "languages": [
          "mri-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.01976,
        "recall": 0.024036,
        "f1": 0.020322,
        "accuracy": 0.024036,
        "main_score": 0.020322,
        "hf_subset": "mri_Latn-fil_Latn",
        "languages": [
          "mri-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.003951,
        "recall": 0.007011,
        "f1": 0.004144,
        "accuracy": 0.007011,
        "main_score": 0.004144,
        "hf_subset": "mri_Latn-ind_Latn",
        "languages": [
          "mri-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mri_Latn-mal_Mlym",
        "languages": [
          "mri-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.022453,
        "recall": 0.029044,
        "f1": 0.023327,
        "accuracy": 0.029044,
        "main_score": 0.023327,
        "hf_subset": "mri_Latn-mlg_Latn",
        "languages": [
          "mri-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.004116,
        "recall": 0.008012,
        "f1": 0.00442,
        "accuracy": 0.008012,
        "main_score": 0.00442,
        "hf_subset": "mri_Latn-msa_Latn",
        "languages": [
          "mri-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.031616,
        "recall": 0.037556,
        "f1": 0.032909,
        "accuracy": 0.037556,
        "main_score": 0.032909,
        "hf_subset": "mri_Latn-smo_Latn",
        "languages": [
          "mri-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.033642,
        "recall": 0.042564,
        "f1": 0.035333,
        "accuracy": 0.042564,
        "main_score": 0.035333,
        "hf_subset": "mri_Latn-tah_Latn",
        "languages": [
          "mri-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.049744,
        "recall": 0.065598,
        "f1": 0.052403,
        "accuracy": 0.065598,
        "main_score": 0.052403,
        "hf_subset": "mri_Latn-ton_Latn",
        "languages": [
          "mri-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.037571,
        "recall": 0.040561,
        "f1": 0.037919,
        "accuracy": 0.040561,
        "main_score": 0.037919,
        "hf_subset": "msa_Latn-eng_Latn",
        "languages": [
          "msa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004801,
        "recall": 0.006009,
        "f1": 0.004924,
        "accuracy": 0.006009,
        "main_score": 0.004924,
        "hf_subset": "msa_Latn-fij_Latn",
        "languages": [
          "msa-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.015876,
        "recall": 0.018528,
        "f1": 0.016205,
        "accuracy": 0.018528,
        "main_score": 0.016205,
        "hf_subset": "msa_Latn-fil_Latn",
        "languages": [
          "msa-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.69803,
        "recall": 0.763645,
        "f1": 0.71652,
        "accuracy": 0.763645,
        "main_score": 0.71652,
        "hf_subset": "msa_Latn-ind_Latn",
        "languages": [
          "msa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "msa_Latn-mal_Mlym",
        "languages": [
          "msa-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007408,
        "recall": 0.010015,
        "f1": 0.007613,
        "accuracy": 0.010015,
        "main_score": 0.007613,
        "hf_subset": "msa_Latn-mlg_Latn",
        "languages": [
          "msa-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.006511,
        "recall": 0.007511,
        "f1": 0.006512,
        "accuracy": 0.007511,
        "main_score": 0.006512,
        "hf_subset": "msa_Latn-mri_Latn",
        "languages": [
          "msa-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.006197,
        "recall": 0.009014,
        "f1": 0.006503,
        "accuracy": 0.009014,
        "main_score": 0.006503,
        "hf_subset": "msa_Latn-smo_Latn",
        "languages": [
          "msa-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.005116,
        "recall": 0.007011,
        "f1": 0.005191,
        "accuracy": 0.007011,
        "main_score": 0.005191,
        "hf_subset": "msa_Latn-tah_Latn",
        "languages": [
          "msa-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.003456,
        "recall": 0.005008,
        "f1": 0.003652,
        "accuracy": 0.005008,
        "main_score": 0.003652,
        "hf_subset": "msa_Latn-ton_Latn",
        "languages": [
          "msa-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.005369,
        "recall": 0.007011,
        "f1": 0.005697,
        "accuracy": 0.007011,
        "main_score": 0.005697,
        "hf_subset": "mya_Mymr-bod_Tibt",
        "languages": [
          "mya-Mymr",
          "bod-Tibt"
        ]
      },
      {
        "precision": 6e-05,
        "recall": 0.002504,
        "f1": 0.000116,
        "accuracy": 0.002504,
        "main_score": 0.000116,
        "hf_subset": "mya_Mymr-dzo_Tibt",
        "languages": [
          "mya-Mymr",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.00503,
        "recall": 0.009014,
        "f1": 0.005786,
        "accuracy": 0.009014,
        "main_score": 0.005786,
        "hf_subset": "mya_Mymr-eng_Latn",
        "languages": [
          "mya-Mymr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003437,
        "recall": 0.005508,
        "f1": 0.003619,
        "accuracy": 0.005508,
        "main_score": 0.003619,
        "hf_subset": "mya_Mymr-khm_Khmr",
        "languages": [
          "mya-Mymr",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.010805,
        "recall": 0.015523,
        "f1": 0.011818,
        "accuracy": 0.015523,
        "main_score": 0.011818,
        "hf_subset": "mya_Mymr-lao_Laoo",
        "languages": [
          "mya-Mymr",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.001544,
        "recall": 0.002504,
        "f1": 0.00158,
        "accuracy": 0.002504,
        "main_score": 0.00158,
        "hf_subset": "mya_Mymr-mon_Mong",
        "languages": [
          "mya-Mymr",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.007067,
        "recall": 0.010015,
        "f1": 0.007355,
        "accuracy": 0.010015,
        "main_score": 0.007355,
        "hf_subset": "mya_Mymr-tha_Thai",
        "languages": [
          "mya-Mymr",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.041542,
        "recall": 0.052078,
        "f1": 0.044137,
        "accuracy": 0.052078,
        "main_score": 0.044137,
        "hf_subset": "nde_Latn-bem_Latn",
        "languages": [
          "nde-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.011824,
        "recall": 0.016024,
        "f1": 0.012218,
        "accuracy": 0.016024,
        "main_score": 0.012218,
        "hf_subset": "nde_Latn-eng_Latn",
        "languages": [
          "nde-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025639,
        "recall": 0.030546,
        "f1": 0.026659,
        "accuracy": 0.030546,
        "main_score": 0.026659,
        "hf_subset": "nde_Latn-ewe_Latn",
        "languages": [
          "nde-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.014394,
        "recall": 0.017026,
        "f1": 0.014951,
        "accuracy": 0.017026,
        "main_score": 0.014951,
        "hf_subset": "nde_Latn-fuc_Latn",
        "languages": [
          "nde-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.011815,
        "recall": 0.018528,
        "f1": 0.012867,
        "accuracy": 0.018528,
        "main_score": 0.012867,
        "hf_subset": "nde_Latn-kin_Latn",
        "languages": [
          "nde-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.039689,
        "recall": 0.048573,
        "f1": 0.041639,
        "accuracy": 0.048573,
        "main_score": 0.041639,
        "hf_subset": "nde_Latn-nya_Latn",
        "languages": [
          "nde-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.048031,
        "recall": 0.062594,
        "f1": 0.051071,
        "accuracy": 0.062594,
        "main_score": 0.051071,
        "hf_subset": "nde_Latn-sna_Latn",
        "languages": [
          "nde-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.035671,
        "recall": 0.042564,
        "f1": 0.037088,
        "accuracy": 0.042564,
        "main_score": 0.037088,
        "hf_subset": "nde_Latn-ven_Latn",
        "languages": [
          "nde-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.047173,
        "recall": 0.069604,
        "f1": 0.050729,
        "accuracy": 0.069604,
        "main_score": 0.050729,
        "hf_subset": "nep_Deva-ben_Beng",
        "languages": [
          "nep-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 6.7e-05,
        "recall": 0.001502,
        "f1": 0.000123,
        "accuracy": 0.001502,
        "main_score": 0.000123,
        "hf_subset": "nep_Deva-div_Thaa",
        "languages": [
          "nep-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.048296,
        "recall": 0.064096,
        "f1": 0.051249,
        "accuracy": 0.064096,
        "main_score": 0.051249,
        "hf_subset": "nep_Deva-eng_Latn",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029177,
        "recall": 0.04657,
        "f1": 0.031241,
        "accuracy": 0.04657,
        "main_score": 0.031241,
        "hf_subset": "nep_Deva-eus_Latn",
        "languages": [
          "nep-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.013341,
        "recall": 0.022033,
        "f1": 0.014473,
        "accuracy": 0.022033,
        "main_score": 0.014473,
        "hf_subset": "nep_Deva-guj_Gujr",
        "languages": [
          "nep-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.308452,
        "recall": 0.37306,
        "f1": 0.322815,
        "accuracy": 0.37306,
        "main_score": 0.322815,
        "hf_subset": "nep_Deva-hin_Deva",
        "languages": [
          "nep-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.056199,
        "recall": 0.072108,
        "f1": 0.05899,
        "accuracy": 0.072108,
        "main_score": 0.05899,
        "hf_subset": "nep_Deva-kan_Knda",
        "languages": [
          "nep-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.116934,
        "recall": 0.147221,
        "f1": 0.123209,
        "accuracy": 0.147221,
        "main_score": 0.123209,
        "hf_subset": "nep_Deva-mar_Deva",
        "languages": [
          "nep-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.038307,
        "recall": 0.064096,
        "f1": 0.042557,
        "accuracy": 0.064096,
        "main_score": 0.042557,
        "hf_subset": "nep_Deva-pan_Guru",
        "languages": [
          "nep-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000559,
        "recall": 0.002504,
        "f1": 0.000612,
        "accuracy": 0.002504,
        "main_score": 0.000612,
        "hf_subset": "nep_Deva-sin_Sinh",
        "languages": [
          "nep-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000819,
        "recall": 0.003505,
        "f1": 0.000963,
        "accuracy": 0.003505,
        "main_score": 0.000963,
        "hf_subset": "nep_Deva-snd_Arab",
        "languages": [
          "nep-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.022578,
        "recall": 0.038558,
        "f1": 0.024834,
        "accuracy": 0.038558,
        "main_score": 0.024834,
        "hf_subset": "nep_Deva-tam_Taml",
        "languages": [
          "nep-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.034444,
        "recall": 0.048072,
        "f1": 0.036928,
        "accuracy": 0.048072,
        "main_score": 0.036928,
        "hf_subset": "nep_Deva-tel_Telu",
        "languages": [
          "nep-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005991,
        "recall": 0.01352,
        "f1": 0.006688,
        "accuracy": 0.01352,
        "main_score": 0.006688,
        "hf_subset": "nep_Deva-urd_Arab",
        "languages": [
          "nep-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.354356,
        "recall": 0.424637,
        "f1": 0.371745,
        "accuracy": 0.424637,
        "main_score": 0.371745,
        "hf_subset": "nld_Latn-afr_Latn",
        "languages": [
          "nld-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "nld_Latn-arb_Arab",
        "languages": [
          "nld-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "nld_Latn-ben_Beng",
        "languages": [
          "nld-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.124677,
        "recall": 0.148723,
        "f1": 0.128692,
        "accuracy": 0.148723,
        "main_score": 0.128692,
        "hf_subset": "nld_Latn-dan_Latn",
        "languages": [
          "nld-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.091052,
        "recall": 0.116675,
        "f1": 0.095441,
        "accuracy": 0.116675,
        "main_score": 0.095441,
        "hf_subset": "nld_Latn-deu_Latn",
        "languages": [
          "nld-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "nld_Latn-ell_Grek",
        "languages": [
          "nld-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.058474,
        "recall": 0.066099,
        "f1": 0.060017,
        "accuracy": 0.066099,
        "main_score": 0.060017,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032891,
        "recall": 0.044567,
        "f1": 0.035061,
        "accuracy": 0.044567,
        "main_score": 0.035061,
        "hf_subset": "nld_Latn-fao_Latn",
        "languages": [
          "nld-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001502,
        "f1": 0.000668,
        "accuracy": 0.001502,
        "main_score": 0.000668,
        "hf_subset": "nld_Latn-fas_Arab",
        "languages": [
          "nld-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.018004,
        "recall": 0.026039,
        "f1": 0.019185,
        "accuracy": 0.026039,
        "main_score": 0.019185,
        "hf_subset": "nld_Latn-fin_Latn",
        "languages": [
          "nld-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.032632,
        "recall": 0.041562,
        "f1": 0.034013,
        "accuracy": 0.041562,
        "main_score": 0.034013,
        "hf_subset": "nld_Latn-fra_Latn",
        "languages": [
          "nld-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001269,
        "recall": 0.002504,
        "f1": 0.001419,
        "accuracy": 0.002504,
        "main_score": 0.001419,
        "hf_subset": "nld_Latn-heb_Hebr",
        "languages": [
          "nld-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "nld_Latn-hin_Deva",
        "languages": [
          "nld-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012457,
        "recall": 0.019029,
        "f1": 0.013139,
        "accuracy": 0.019029,
        "main_score": 0.013139,
        "hf_subset": "nld_Latn-hun_Latn",
        "languages": [
          "nld-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.008871,
        "recall": 0.015523,
        "f1": 0.009699,
        "accuracy": 0.015523,
        "main_score": 0.009699,
        "hf_subset": "nld_Latn-ind_Latn",
        "languages": [
          "nld-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.019419,
        "recall": 0.029044,
        "f1": 0.021082,
        "accuracy": 0.029044,
        "main_score": 0.021082,
        "hf_subset": "nld_Latn-isl_Latn",
        "languages": [
          "nld-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.001002,
        "f1": 3.5e-05,
        "accuracy": 0.001002,
        "main_score": 3.5e-05,
        "hf_subset": "nld_Latn-jpn_Jpan",
        "languages": [
          "nld-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000508,
        "accuracy": 0.001502,
        "main_score": 0.000508,
        "hf_subset": "nld_Latn-kor_Hang",
        "languages": [
          "nld-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.022416,
        "recall": 0.034051,
        "f1": 0.023847,
        "accuracy": 0.034051,
        "main_score": 0.023847,
        "hf_subset": "nld_Latn-lit_Latn",
        "languages": [
          "nld-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.087367,
        "recall": 0.108663,
        "f1": 0.091476,
        "accuracy": 0.108663,
        "main_score": 0.091476,
        "hf_subset": "nld_Latn-ltz_Latn",
        "languages": [
          "nld-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.091908,
        "recall": 0.117176,
        "f1": 0.096875,
        "accuracy": 0.117176,
        "main_score": 0.096875,
        "hf_subset": "nld_Latn-nno_Latn",
        "languages": [
          "nld-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.123019,
        "recall": 0.15323,
        "f1": 0.128941,
        "accuracy": 0.15323,
        "main_score": 0.128941,
        "hf_subset": "nld_Latn-nob_Latn",
        "languages": [
          "nld-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.014516,
        "recall": 0.021532,
        "f1": 0.015706,
        "accuracy": 0.021532,
        "main_score": 0.015706,
        "hf_subset": "nld_Latn-pol_Latn",
        "languages": [
          "nld-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.022215,
        "recall": 0.030546,
        "f1": 0.023032,
        "accuracy": 0.030546,
        "main_score": 0.023032,
        "hf_subset": "nld_Latn-por_Latn",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000503,
        "accuracy": 0.001502,
        "main_score": 0.000503,
        "hf_subset": "nld_Latn-rus_Cyrl",
        "languages": [
          "nld-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.041823,
        "recall": 0.05358,
        "f1": 0.043957,
        "accuracy": 0.05358,
        "main_score": 0.043957,
        "hf_subset": "nld_Latn-spa_Latn",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.004752,
        "recall": 0.008012,
        "f1": 0.005132,
        "accuracy": 0.008012,
        "main_score": 0.005132,
        "hf_subset": "nld_Latn-swa_Latn",
        "languages": [
          "nld-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.098592,
        "recall": 0.129695,
        "f1": 0.104035,
        "accuracy": 0.129695,
        "main_score": 0.104035,
        "hf_subset": "nld_Latn-swe_Latn",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001128,
        "recall": 0.002504,
        "f1": 0.001204,
        "accuracy": 0.002504,
        "main_score": 0.001204,
        "hf_subset": "nld_Latn-tam_Taml",
        "languages": [
          "nld-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.005419,
        "recall": 0.010015,
        "f1": 0.006072,
        "accuracy": 0.010015,
        "main_score": 0.006072,
        "hf_subset": "nld_Latn-tur_Latn",
        "languages": [
          "nld-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.006155,
        "recall": 0.009514,
        "f1": 0.006744,
        "accuracy": 0.009514,
        "main_score": 0.006744,
        "hf_subset": "nld_Latn-vie_Latn",
        "languages": [
          "nld-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000508,
        "recall": 0.002504,
        "f1": 0.000515,
        "accuracy": 0.002504,
        "main_score": 0.000515,
        "hf_subset": "nld_Latn-zho_Hant",
        "languages": [
          "nld-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.016143,
        "recall": 0.023535,
        "f1": 0.01766,
        "accuracy": 0.023535,
        "main_score": 0.01766,
        "hf_subset": "nld_Latn-zul_Latn",
        "languages": [
          "nld-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.086155,
        "recall": 0.098648,
        "f1": 0.088829,
        "accuracy": 0.098648,
        "main_score": 0.088829,
        "hf_subset": "nno_Latn-afr_Latn",
        "languages": [
          "nno-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.501399,
        "recall": 0.576865,
        "f1": 0.521715,
        "accuracy": 0.576865,
        "main_score": 0.521715,
        "hf_subset": "nno_Latn-dan_Latn",
        "languages": [
          "nno-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.045177,
        "recall": 0.059089,
        "f1": 0.047283,
        "accuracy": 0.059089,
        "main_score": 0.047283,
        "hf_subset": "nno_Latn-deu_Latn",
        "languages": [
          "nno-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.038432,
        "recall": 0.047071,
        "f1": 0.039661,
        "accuracy": 0.047071,
        "main_score": 0.039661,
        "hf_subset": "nno_Latn-eng_Latn",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.108013,
        "recall": 0.136204,
        "f1": 0.113847,
        "accuracy": 0.136204,
        "main_score": 0.113847,
        "hf_subset": "nno_Latn-fao_Latn",
        "languages": [
          "nno-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.057777,
        "recall": 0.082123,
        "f1": 0.061825,
        "accuracy": 0.082123,
        "main_score": 0.061825,
        "hf_subset": "nno_Latn-isl_Latn",
        "languages": [
          "nno-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.0753,
        "recall": 0.088132,
        "f1": 0.078135,
        "accuracy": 0.088132,
        "main_score": 0.078135,
        "hf_subset": "nno_Latn-ltz_Latn",
        "languages": [
          "nno-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.081931,
        "recall": 0.095643,
        "f1": 0.084586,
        "accuracy": 0.095643,
        "main_score": 0.084586,
        "hf_subset": "nno_Latn-nld_Latn",
        "languages": [
          "nno-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.65399,
        "recall": 0.720581,
        "f1": 0.673255,
        "accuracy": 0.720581,
        "main_score": 0.673255,
        "hf_subset": "nno_Latn-nob_Latn",
        "languages": [
          "nno-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.425388,
        "recall": 0.497246,
        "f1": 0.443172,
        "accuracy": 0.497246,
        "main_score": 0.443172,
        "hf_subset": "nno_Latn-swe_Latn",
        "languages": [
          "nno-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.091288,
        "recall": 0.103155,
        "f1": 0.093822,
        "accuracy": 0.103155,
        "main_score": 0.093822,
        "hf_subset": "nob_Latn-afr_Latn",
        "languages": [
          "nob-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.623875,
        "recall": 0.695543,
        "f1": 0.644159,
        "accuracy": 0.695543,
        "main_score": 0.644159,
        "hf_subset": "nob_Latn-dan_Latn",
        "languages": [
          "nob-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.051774,
        "recall": 0.064597,
        "f1": 0.053654,
        "accuracy": 0.064597,
        "main_score": 0.053654,
        "hf_subset": "nob_Latn-deu_Latn",
        "languages": [
          "nob-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.041676,
        "recall": 0.052579,
        "f1": 0.043416,
        "accuracy": 0.052579,
        "main_score": 0.043416,
        "hf_subset": "nob_Latn-eng_Latn",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.091902,
        "recall": 0.118177,
        "f1": 0.096679,
        "accuracy": 0.118177,
        "main_score": 0.096679,
        "hf_subset": "nob_Latn-fao_Latn",
        "languages": [
          "nob-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.05619,
        "recall": 0.077116,
        "f1": 0.059587,
        "accuracy": 0.077116,
        "main_score": 0.059587,
        "hf_subset": "nob_Latn-isl_Latn",
        "languages": [
          "nob-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.075214,
        "recall": 0.089134,
        "f1": 0.078122,
        "accuracy": 0.089134,
        "main_score": 0.078122,
        "hf_subset": "nob_Latn-ltz_Latn",
        "languages": [
          "nob-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.089749,
        "recall": 0.103155,
        "f1": 0.092688,
        "accuracy": 0.103155,
        "main_score": 0.092688,
        "hf_subset": "nob_Latn-nld_Latn",
        "languages": [
          "nob-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.614647,
        "recall": 0.696044,
        "f1": 0.637796,
        "accuracy": 0.696044,
        "main_score": 0.637796,
        "hf_subset": "nob_Latn-nno_Latn",
        "languages": [
          "nob-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.471541,
        "recall": 0.538808,
        "f1": 0.487605,
        "accuracy": 0.538808,
        "main_score": 0.487605,
        "hf_subset": "nob_Latn-swe_Latn",
        "languages": [
          "nob-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.00173,
        "recall": 0.003505,
        "f1": 0.001874,
        "accuracy": 0.003505,
        "main_score": 0.001874,
        "hf_subset": "nso_Latn-amh_Ethi",
        "languages": [
          "nso-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.026828,
        "recall": 0.036555,
        "f1": 0.028565,
        "accuracy": 0.036555,
        "main_score": 0.028565,
        "hf_subset": "nso_Latn-eng_Latn",
        "languages": [
          "nso-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.083468,
        "recall": 0.108663,
        "f1": 0.088779,
        "accuracy": 0.108663,
        "main_score": 0.088779,
        "hf_subset": "nso_Latn-hau_Latn",
        "languages": [
          "nso-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.008023,
        "recall": 0.01352,
        "f1": 0.00885,
        "accuracy": 0.01352,
        "main_score": 0.00885,
        "hf_subset": "nso_Latn-ibo_Latn",
        "languages": [
          "nso-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.03592,
        "recall": 0.051077,
        "f1": 0.039047,
        "accuracy": 0.051077,
        "main_score": 0.039047,
        "hf_subset": "nso_Latn-orm_Ethi",
        "languages": [
          "nso-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.084731,
        "recall": 0.105158,
        "f1": 0.089154,
        "accuracy": 0.105158,
        "main_score": 0.089154,
        "hf_subset": "nso_Latn-som_Latn",
        "languages": [
          "nso-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.048831,
        "recall": 0.074111,
        "f1": 0.053673,
        "accuracy": 0.074111,
        "main_score": 0.053673,
        "hf_subset": "nso_Latn-ssw_Latn",
        "languages": [
          "nso-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.008438,
        "recall": 0.011517,
        "f1": 0.009091,
        "accuracy": 0.011517,
        "main_score": 0.009091,
        "hf_subset": "nso_Latn-swa_Latn",
        "languages": [
          "nso-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.001502,
        "f1": 2.5e-05,
        "accuracy": 0.001502,
        "main_score": 2.5e-05,
        "hf_subset": "nso_Latn-tir_Ethi",
        "languages": [
          "nso-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.278736,
        "recall": 0.345518,
        "f1": 0.295918,
        "accuracy": 0.345518,
        "main_score": 0.295918,
        "hf_subset": "nso_Latn-tsn_Latn",
        "languages": [
          "nso-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.059754,
        "recall": 0.076114,
        "f1": 0.062811,
        "accuracy": 0.076114,
        "main_score": 0.062811,
        "hf_subset": "nso_Latn-wol_Latn",
        "languages": [
          "nso-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.032436,
        "recall": 0.045568,
        "f1": 0.034449,
        "accuracy": 0.045568,
        "main_score": 0.034449,
        "hf_subset": "nso_Latn-xho_Latn",
        "languages": [
          "nso-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.010502,
        "recall": 0.016024,
        "f1": 0.011585,
        "accuracy": 0.016024,
        "main_score": 0.011585,
        "hf_subset": "nso_Latn-yor_Latn",
        "languages": [
          "nso-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.039996,
        "recall": 0.054582,
        "f1": 0.042704,
        "accuracy": 0.054582,
        "main_score": 0.042704,
        "hf_subset": "nso_Latn-zul_Latn",
        "languages": [
          "nso-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.090763,
        "recall": 0.114171,
        "f1": 0.096304,
        "accuracy": 0.114171,
        "main_score": 0.096304,
        "hf_subset": "nya_Latn-bem_Latn",
        "languages": [
          "nya-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.02505,
        "recall": 0.032549,
        "f1": 0.026251,
        "accuracy": 0.032549,
        "main_score": 0.026251,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045813,
        "recall": 0.05308,
        "f1": 0.047405,
        "accuracy": 0.05308,
        "main_score": 0.047405,
        "hf_subset": "nya_Latn-ewe_Latn",
        "languages": [
          "nya-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.036526,
        "recall": 0.04006,
        "f1": 0.037331,
        "accuracy": 0.04006,
        "main_score": 0.037331,
        "hf_subset": "nya_Latn-fuc_Latn",
        "languages": [
          "nya-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.019466,
        "recall": 0.029544,
        "f1": 0.021074,
        "accuracy": 0.029544,
        "main_score": 0.021074,
        "hf_subset": "nya_Latn-kin_Latn",
        "languages": [
          "nya-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.042674,
        "recall": 0.059089,
        "f1": 0.045658,
        "accuracy": 0.059089,
        "main_score": 0.045658,
        "hf_subset": "nya_Latn-nde_Latn",
        "languages": [
          "nya-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.085642,
        "recall": 0.110165,
        "f1": 0.090722,
        "accuracy": 0.110165,
        "main_score": 0.090722,
        "hf_subset": "nya_Latn-sna_Latn",
        "languages": [
          "nya-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.052839,
        "recall": 0.071107,
        "f1": 0.056772,
        "accuracy": 0.071107,
        "main_score": 0.056772,
        "hf_subset": "nya_Latn-ven_Latn",
        "languages": [
          "nya-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.001002,
        "f1": 0.000251,
        "accuracy": 0.001002,
        "main_score": 0.000251,
        "hf_subset": "orm_Ethi-amh_Ethi",
        "languages": [
          "orm-Ethi",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.010851,
        "recall": 0.016525,
        "f1": 0.011492,
        "accuracy": 0.016525,
        "main_score": 0.011492,
        "hf_subset": "orm_Ethi-eng_Latn",
        "languages": [
          "orm-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028777,
        "recall": 0.037556,
        "f1": 0.030756,
        "accuracy": 0.037556,
        "main_score": 0.030756,
        "hf_subset": "orm_Ethi-hau_Latn",
        "languages": [
          "orm-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.00226,
        "recall": 0.003505,
        "f1": 0.002351,
        "accuracy": 0.003505,
        "main_score": 0.002351,
        "hf_subset": "orm_Ethi-ibo_Latn",
        "languages": [
          "orm-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.029641,
        "recall": 0.037056,
        "f1": 0.030941,
        "accuracy": 0.037056,
        "main_score": 0.030941,
        "hf_subset": "orm_Ethi-nso_Latn",
        "languages": [
          "orm-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.054561,
        "recall": 0.067601,
        "f1": 0.057535,
        "accuracy": 0.067601,
        "main_score": 0.057535,
        "hf_subset": "orm_Ethi-som_Latn",
        "languages": [
          "orm-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.016838,
        "recall": 0.025538,
        "f1": 0.018,
        "accuracy": 0.025538,
        "main_score": 0.018,
        "hf_subset": "orm_Ethi-ssw_Latn",
        "languages": [
          "orm-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.001205,
        "recall": 0.002504,
        "f1": 0.001321,
        "accuracy": 0.002504,
        "main_score": 0.001321,
        "hf_subset": "orm_Ethi-swa_Latn",
        "languages": [
          "orm-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.000501,
        "f1": 1.8e-05,
        "accuracy": 0.000501,
        "main_score": 1.8e-05,
        "hf_subset": "orm_Ethi-tir_Ethi",
        "languages": [
          "orm-Ethi",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.026922,
        "recall": 0.03305,
        "f1": 0.028128,
        "accuracy": 0.03305,
        "main_score": 0.028128,
        "hf_subset": "orm_Ethi-tsn_Latn",
        "languages": [
          "orm-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.026234,
        "recall": 0.034051,
        "f1": 0.027699,
        "accuracy": 0.034051,
        "main_score": 0.027699,
        "hf_subset": "orm_Ethi-wol_Latn",
        "languages": [
          "orm-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.009995,
        "recall": 0.015023,
        "f1": 0.010485,
        "accuracy": 0.015023,
        "main_score": 0.010485,
        "hf_subset": "orm_Ethi-xho_Latn",
        "languages": [
          "orm-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.004633,
        "recall": 0.00651,
        "f1": 0.004877,
        "accuracy": 0.00651,
        "main_score": 0.004877,
        "hf_subset": "orm_Ethi-yor_Latn",
        "languages": [
          "orm-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.01192,
        "recall": 0.019029,
        "f1": 0.0126,
        "accuracy": 0.019029,
        "main_score": 0.0126,
        "hf_subset": "orm_Ethi-zul_Latn",
        "languages": [
          "orm-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.018322,
        "recall": 0.032549,
        "f1": 0.020419,
        "accuracy": 0.032549,
        "main_score": 0.020419,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001254,
        "recall": 0.002003,
        "f1": 0.00134,
        "accuracy": 0.002003,
        "main_score": 0.00134,
        "hf_subset": "pan_Guru-div_Thaa",
        "languages": [
          "pan-Guru",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.031029,
        "recall": 0.042564,
        "f1": 0.033144,
        "accuracy": 0.042564,
        "main_score": 0.033144,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014057,
        "recall": 0.021532,
        "f1": 0.015196,
        "accuracy": 0.021532,
        "main_score": 0.015196,
        "hf_subset": "pan_Guru-eus_Latn",
        "languages": [
          "pan-Guru",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.034286,
        "recall": 0.059089,
        "f1": 0.037037,
        "accuracy": 0.059089,
        "main_score": 0.037037,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.198018,
        "recall": 0.234852,
        "f1": 0.205867,
        "accuracy": 0.234852,
        "main_score": 0.205867,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.078261,
        "recall": 0.101152,
        "f1": 0.082431,
        "accuracy": 0.101152,
        "main_score": 0.082431,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.109355,
        "recall": 0.139209,
        "f1": 0.115446,
        "accuracy": 0.139209,
        "main_score": 0.115446,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.104368,
        "recall": 0.141212,
        "f1": 0.111028,
        "accuracy": 0.141212,
        "main_score": 0.111028,
        "hf_subset": "pan_Guru-nep_Deva",
        "languages": [
          "pan-Guru",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.001351,
        "recall": 0.003505,
        "f1": 0.001508,
        "accuracy": 0.003505,
        "main_score": 0.001508,
        "hf_subset": "pan_Guru-sin_Sinh",
        "languages": [
          "pan-Guru",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.002152,
        "recall": 0.004507,
        "f1": 0.002272,
        "accuracy": 0.004507,
        "main_score": 0.002272,
        "hf_subset": "pan_Guru-snd_Arab",
        "languages": [
          "pan-Guru",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.012325,
        "recall": 0.022534,
        "f1": 0.013719,
        "accuracy": 0.022534,
        "main_score": 0.013719,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.030096,
        "recall": 0.047071,
        "f1": 0.032846,
        "accuracy": 0.047071,
        "main_score": 0.032846,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.012132,
        "recall": 0.022033,
        "f1": 0.013347,
        "accuracy": 0.022033,
        "main_score": 0.013347,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "pol_Latn-arb_Arab",
        "languages": [
          "pol-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00053,
        "recall": 0.002003,
        "f1": 0.000556,
        "accuracy": 0.002003,
        "main_score": 0.000556,
        "hf_subset": "pol_Latn-bel_Cyrl",
        "languages": [
          "pol-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.000514,
        "recall": 0.002003,
        "f1": 0.000527,
        "accuracy": 0.002003,
        "main_score": 0.000527,
        "hf_subset": "pol_Latn-ben_Beng",
        "languages": [
          "pol-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0545,
        "recall": 0.064597,
        "f1": 0.056462,
        "accuracy": 0.064597,
        "main_score": 0.056462,
        "hf_subset": "pol_Latn-bos_Latn",
        "languages": [
          "pol-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.001174,
        "recall": 0.003005,
        "f1": 0.001264,
        "accuracy": 0.003005,
        "main_score": 0.001264,
        "hf_subset": "pol_Latn-bul_Cyrl",
        "languages": [
          "pol-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.068259,
        "recall": 0.079119,
        "f1": 0.070409,
        "accuracy": 0.079119,
        "main_score": 0.070409,
        "hf_subset": "pol_Latn-ces_Latn",
        "languages": [
          "pol-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.031568,
        "recall": 0.041562,
        "f1": 0.033125,
        "accuracy": 0.041562,
        "main_score": 0.033125,
        "hf_subset": "pol_Latn-deu_Latn",
        "languages": [
          "pol-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000258,
        "recall": 0.002003,
        "f1": 0.000348,
        "accuracy": 0.002003,
        "main_score": 0.000348,
        "hf_subset": "pol_Latn-ell_Grek",
        "languages": [
          "pol-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.021014,
        "recall": 0.027541,
        "f1": 0.021919,
        "accuracy": 0.027541,
        "main_score": 0.021919,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "pol_Latn-fas_Arab",
        "languages": [
          "pol-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.01975,
        "recall": 0.026039,
        "f1": 0.02077,
        "accuracy": 0.026039,
        "main_score": 0.02077,
        "hf_subset": "pol_Latn-fin_Latn",
        "languages": [
          "pol-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.013579,
        "recall": 0.018528,
        "f1": 0.014298,
        "accuracy": 0.018528,
        "main_score": 0.014298,
        "hf_subset": "pol_Latn-fra_Latn",
        "languages": [
          "pol-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001127,
        "recall": 0.002504,
        "f1": 0.001369,
        "accuracy": 0.002504,
        "main_score": 0.001369,
        "hf_subset": "pol_Latn-heb_Hebr",
        "languages": [
          "pol-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000113,
        "recall": 0.001502,
        "f1": 0.000191,
        "accuracy": 0.001502,
        "main_score": 0.000191,
        "hf_subset": "pol_Latn-hin_Deva",
        "languages": [
          "pol-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.055984,
        "recall": 0.066099,
        "f1": 0.058074,
        "accuracy": 0.066099,
        "main_score": 0.058074,
        "hf_subset": "pol_Latn-hrv_Latn",
        "languages": [
          "pol-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.016322,
        "recall": 0.02003,
        "f1": 0.016721,
        "accuracy": 0.02003,
        "main_score": 0.016721,
        "hf_subset": "pol_Latn-hun_Latn",
        "languages": [
          "pol-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.006144,
        "recall": 0.011517,
        "f1": 0.006683,
        "accuracy": 0.011517,
        "main_score": 0.006683,
        "hf_subset": "pol_Latn-ind_Latn",
        "languages": [
          "pol-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "pol_Latn-jpn_Jpan",
        "languages": [
          "pol-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001003,
        "recall": 0.002003,
        "f1": 0.001004,
        "accuracy": 0.002003,
        "main_score": 0.001004,
        "hf_subset": "pol_Latn-kor_Hang",
        "languages": [
          "pol-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.01085,
        "recall": 0.012519,
        "f1": 0.010999,
        "accuracy": 0.012519,
        "main_score": 0.010999,
        "hf_subset": "pol_Latn-lit_Latn",
        "languages": [
          "pol-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.000319,
        "recall": 0.003505,
        "f1": 0.000463,
        "accuracy": 0.003505,
        "main_score": 0.000463,
        "hf_subset": "pol_Latn-mkd_Cyrl",
        "languages": [
          "pol-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.039155,
        "recall": 0.045568,
        "f1": 0.039864,
        "accuracy": 0.045568,
        "main_score": 0.039864,
        "hf_subset": "pol_Latn-nld_Latn",
        "languages": [
          "pol-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.017651,
        "recall": 0.025038,
        "f1": 0.018387,
        "accuracy": 0.025038,
        "main_score": 0.018387,
        "hf_subset": "pol_Latn-por_Latn",
        "languages": [
          "pol-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002504,
        "f1": 0.001504,
        "accuracy": 0.002504,
        "main_score": 0.001504,
        "hf_subset": "pol_Latn-rus_Cyrl",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.05986,
        "recall": 0.069104,
        "f1": 0.061781,
        "accuracy": 0.069104,
        "main_score": 0.061781,
        "hf_subset": "pol_Latn-slk_Latn",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.057674,
        "recall": 0.067101,
        "f1": 0.059371,
        "accuracy": 0.067101,
        "main_score": 0.059371,
        "hf_subset": "pol_Latn-slv_Latn",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.018216,
        "recall": 0.025538,
        "f1": 0.019018,
        "accuracy": 0.025538,
        "main_score": 0.019018,
        "hf_subset": "pol_Latn-spa_Latn",
        "languages": [
          "pol-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.0018,
        "recall": 0.005008,
        "f1": 0.001927,
        "accuracy": 0.005008,
        "main_score": 0.001927,
        "hf_subset": "pol_Latn-srp_Cyrl",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.029745,
        "recall": 0.040561,
        "f1": 0.031238,
        "accuracy": 0.040561,
        "main_score": 0.031238,
        "hf_subset": "pol_Latn-srp_Latn",
        "languages": [
          "pol-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.005133,
        "recall": 0.006009,
        "f1": 0.005208,
        "accuracy": 0.006009,
        "main_score": 0.005208,
        "hf_subset": "pol_Latn-swa_Latn",
        "languages": [
          "pol-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.033408,
        "recall": 0.037556,
        "f1": 0.034013,
        "accuracy": 0.037556,
        "main_score": 0.034013,
        "hf_subset": "pol_Latn-swe_Latn",
        "languages": [
          "pol-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000397,
        "recall": 0.002003,
        "f1": 0.000589,
        "accuracy": 0.002003,
        "main_score": 0.000589,
        "hf_subset": "pol_Latn-tam_Taml",
        "languages": [
          "pol-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009014,
        "recall": 0.010516,
        "f1": 0.009241,
        "accuracy": 0.010516,
        "main_score": 0.009241,
        "hf_subset": "pol_Latn-tur_Latn",
        "languages": [
          "pol-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000922,
        "recall": 0.003005,
        "f1": 0.001093,
        "accuracy": 0.003005,
        "main_score": 0.001093,
        "hf_subset": "pol_Latn-ukr_Cyrl",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.006335,
        "recall": 0.008513,
        "f1": 0.006559,
        "accuracy": 0.008513,
        "main_score": 0.006559,
        "hf_subset": "pol_Latn-vie_Latn",
        "languages": [
          "pol-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001047,
        "recall": 0.003005,
        "f1": 0.001088,
        "accuracy": 0.003005,
        "main_score": 0.001088,
        "hf_subset": "pol_Latn-zho_Hant",
        "languages": [
          "pol-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.019144,
        "recall": 0.024537,
        "f1": 0.019926,
        "accuracy": 0.024537,
        "main_score": 0.019926,
        "hf_subset": "pol_Latn-zul_Latn",
        "languages": [
          "pol-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.003859,
        "recall": 0.006009,
        "f1": 0.004031,
        "accuracy": 0.006009,
        "main_score": 0.004031,
        "hf_subset": "por_Latn-arb_Arab",
        "languages": [
          "por-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001817,
        "recall": 0.005508,
        "f1": 0.002196,
        "accuracy": 0.005508,
        "main_score": 0.002196,
        "hf_subset": "por_Latn-ben_Beng",
        "languages": [
          "por-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.074426,
        "recall": 0.092138,
        "f1": 0.077916,
        "accuracy": 0.092138,
        "main_score": 0.077916,
        "hf_subset": "por_Latn-cat_Latn",
        "languages": [
          "por-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.02864,
        "recall": 0.039559,
        "f1": 0.030471,
        "accuracy": 0.039559,
        "main_score": 0.030471,
        "hf_subset": "por_Latn-deu_Latn",
        "languages": [
          "por-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 7.2e-05,
        "recall": 0.001002,
        "f1": 0.000126,
        "accuracy": 0.001002,
        "main_score": 0.000126,
        "hf_subset": "por_Latn-ell_Grek",
        "languages": [
          "por-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.295993,
        "recall": 0.328993,
        "f1": 0.3028,
        "accuracy": 0.328993,
        "main_score": 0.3028,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000582,
        "recall": 0.002003,
        "f1": 0.000651,
        "accuracy": 0.002003,
        "main_score": 0.000651,
        "hf_subset": "por_Latn-fas_Arab",
        "languages": [
          "por-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.011332,
        "recall": 0.016525,
        "f1": 0.011763,
        "accuracy": 0.016525,
        "main_score": 0.011763,
        "hf_subset": "por_Latn-fin_Latn",
        "languages": [
          "por-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.339272,
        "recall": 0.384577,
        "f1": 0.349343,
        "accuracy": 0.384577,
        "main_score": 0.349343,
        "hf_subset": "por_Latn-fra_Latn",
        "languages": [
          "por-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.545385,
        "recall": 0.628443,
        "f1": 0.566601,
        "accuracy": 0.628443,
        "main_score": 0.566601,
        "hf_subset": "por_Latn-glg_Latn",
        "languages": [
          "por-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.000518,
        "recall": 0.002003,
        "f1": 0.000752,
        "accuracy": 0.002003,
        "main_score": 0.000752,
        "hf_subset": "por_Latn-heb_Hebr",
        "languages": [
          "por-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "por_Latn-hin_Deva",
        "languages": [
          "por-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.007546,
        "recall": 0.014522,
        "f1": 0.008339,
        "accuracy": 0.014522,
        "main_score": 0.008339,
        "hf_subset": "por_Latn-hun_Latn",
        "languages": [
          "por-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.033596,
        "recall": 0.048573,
        "f1": 0.035768,
        "accuracy": 0.048573,
        "main_score": 0.035768,
        "hf_subset": "por_Latn-ind_Latn",
        "languages": [
          "por-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.186932,
        "recall": 0.215323,
        "f1": 0.193176,
        "accuracy": 0.215323,
        "main_score": 0.193176,
        "hf_subset": "por_Latn-ita_Latn",
        "languages": [
          "por-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "por_Latn-jpn_Jpan",
        "languages": [
          "por-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001502,
        "f1": 0.000752,
        "accuracy": 0.001502,
        "main_score": 0.000752,
        "hf_subset": "por_Latn-kor_Hang",
        "languages": [
          "por-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.009741,
        "recall": 0.012519,
        "f1": 0.010242,
        "accuracy": 0.012519,
        "main_score": 0.010242,
        "hf_subset": "por_Latn-lit_Latn",
        "languages": [
          "por-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.017539,
        "recall": 0.024036,
        "f1": 0.018655,
        "accuracy": 0.024036,
        "main_score": 0.018655,
        "hf_subset": "por_Latn-mlt_Latn",
        "languages": [
          "por-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.035159,
        "recall": 0.043065,
        "f1": 0.036681,
        "accuracy": 0.043065,
        "main_score": 0.036681,
        "hf_subset": "por_Latn-nld_Latn",
        "languages": [
          "por-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.010748,
        "recall": 0.015523,
        "f1": 0.011444,
        "accuracy": 0.015523,
        "main_score": 0.011444,
        "hf_subset": "por_Latn-pol_Latn",
        "languages": [
          "por-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.057699,
        "recall": 0.072108,
        "f1": 0.060118,
        "accuracy": 0.072108,
        "main_score": 0.060118,
        "hf_subset": "por_Latn-ron_Latn",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.00101,
        "recall": 0.002504,
        "f1": 0.001019,
        "accuracy": 0.002504,
        "main_score": 0.001019,
        "hf_subset": "por_Latn-rus_Cyrl",
        "languages": [
          "por-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.586943,
        "recall": 0.624937,
        "f1": 0.596591,
        "accuracy": 0.624937,
        "main_score": 0.596591,
        "hf_subset": "por_Latn-spa_Latn",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.015343,
        "recall": 0.022033,
        "f1": 0.016436,
        "accuracy": 0.022033,
        "main_score": 0.016436,
        "hf_subset": "por_Latn-swa_Latn",
        "languages": [
          "por-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.026712,
        "recall": 0.035053,
        "f1": 0.027945,
        "accuracy": 0.035053,
        "main_score": 0.027945,
        "hf_subset": "por_Latn-swe_Latn",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000557,
        "recall": 0.002003,
        "f1": 0.000603,
        "accuracy": 0.002003,
        "main_score": 0.000603,
        "hf_subset": "por_Latn-tam_Taml",
        "languages": [
          "por-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.006085,
        "recall": 0.009014,
        "f1": 0.006154,
        "accuracy": 0.009014,
        "main_score": 0.006154,
        "hf_subset": "por_Latn-tur_Latn",
        "languages": [
          "por-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.032024,
        "recall": 0.050576,
        "f1": 0.034354,
        "accuracy": 0.050576,
        "main_score": 0.034354,
        "hf_subset": "por_Latn-vie_Latn",
        "languages": [
          "por-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001771,
        "recall": 0.004006,
        "f1": 0.001872,
        "accuracy": 0.004006,
        "main_score": 0.001872,
        "hf_subset": "por_Latn-zho_Hant",
        "languages": [
          "por-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.014616,
        "recall": 0.026039,
        "f1": 0.015996,
        "accuracy": 0.026039,
        "main_score": 0.015996,
        "hf_subset": "por_Latn-zul_Latn",
        "languages": [
          "por-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.0045,
        "recall": 0.01352,
        "f1": 0.005376,
        "accuracy": 0.01352,
        "main_score": 0.005376,
        "hf_subset": "prs_Arab-arb_Arab",
        "languages": [
          "prs-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.004403,
        "recall": 0.009014,
        "f1": 0.004783,
        "accuracy": 0.009014,
        "main_score": 0.004783,
        "hf_subset": "prs_Arab-ckb_Arab",
        "languages": [
          "prs-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.001049,
        "recall": 0.004507,
        "f1": 0.001319,
        "accuracy": 0.004507,
        "main_score": 0.001319,
        "hf_subset": "prs_Arab-eng_Latn",
        "languages": [
          "prs-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.317889,
        "recall": 0.399099,
        "f1": 0.338394,
        "accuracy": 0.399099,
        "main_score": 0.338394,
        "hf_subset": "prs_Arab-fas_Arab",
        "languages": [
          "prs-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "prs_Arab-heb_Hebr",
        "languages": [
          "prs-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 3.9e-05,
        "recall": 0.001002,
        "f1": 7.2e-05,
        "accuracy": 0.001002,
        "main_score": 7.2e-05,
        "hf_subset": "prs_Arab-kmr_Latn",
        "languages": [
          "prs-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "prs_Arab-mey_Arab",
        "languages": [
          "prs-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.01044,
        "recall": 0.017026,
        "f1": 0.011511,
        "accuracy": 0.017026,
        "main_score": 0.011511,
        "hf_subset": "prs_Arab-pus_Arab",
        "languages": [
          "prs-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.001753,
        "recall": 0.002504,
        "f1": 0.001837,
        "accuracy": 0.002504,
        "main_score": 0.001837,
        "hf_subset": "prs_Arab-shi_Arab",
        "languages": [
          "prs-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 5e-05,
        "recall": 0.000501,
        "f1": 9.1e-05,
        "accuracy": 0.000501,
        "main_score": 9.1e-05,
        "hf_subset": "prs_Arab-tgk_Cyrl",
        "languages": [
          "prs-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.001351,
        "recall": 0.004507,
        "f1": 0.001687,
        "accuracy": 0.004507,
        "main_score": 0.001687,
        "hf_subset": "pus_Arab-arb_Arab",
        "languages": [
          "pus-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.003239,
        "recall": 0.008012,
        "f1": 0.003644,
        "accuracy": 0.008012,
        "main_score": 0.003644,
        "hf_subset": "pus_Arab-ckb_Arab",
        "languages": [
          "pus-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.000607,
        "recall": 0.003005,
        "f1": 0.000689,
        "accuracy": 0.003005,
        "main_score": 0.000689,
        "hf_subset": "pus_Arab-eng_Latn",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014142,
        "recall": 0.024537,
        "f1": 0.015893,
        "accuracy": 0.024537,
        "main_score": 0.015893,
        "hf_subset": "pus_Arab-fas_Arab",
        "languages": [
          "pus-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "pus_Arab-heb_Hebr",
        "languages": [
          "pus-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000255,
        "recall": 0.001002,
        "f1": 0.000342,
        "accuracy": 0.001002,
        "main_score": 0.000342,
        "hf_subset": "pus_Arab-kmr_Latn",
        "languages": [
          "pus-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001002,
        "f1": 0.000835,
        "accuracy": 0.001002,
        "main_score": 0.000835,
        "hf_subset": "pus_Arab-mey_Arab",
        "languages": [
          "pus-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.027202,
        "recall": 0.038558,
        "f1": 0.029018,
        "accuracy": 0.038558,
        "main_score": 0.029018,
        "hf_subset": "pus_Arab-prs_Arab",
        "languages": [
          "pus-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "pus_Arab-shi_Arab",
        "languages": [
          "pus-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.000126,
        "recall": 0.001002,
        "f1": 0.000201,
        "accuracy": 0.001002,
        "main_score": 0.000201,
        "hf_subset": "pus_Arab-tgk_Cyrl",
        "languages": [
          "pus-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.012709,
        "recall": 0.02003,
        "f1": 0.013742,
        "accuracy": 0.02003,
        "main_score": 0.013742,
        "hf_subset": "ron_Latn-cat_Latn",
        "languages": [
          "ron-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.062582,
        "recall": 0.084126,
        "f1": 0.066578,
        "accuracy": 0.084126,
        "main_score": 0.066578,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.050069,
        "recall": 0.058588,
        "f1": 0.051553,
        "accuracy": 0.058588,
        "main_score": 0.051553,
        "hf_subset": "ron_Latn-fra_Latn",
        "languages": [
          "ron-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.0708,
        "recall": 0.086129,
        "f1": 0.073298,
        "accuracy": 0.086129,
        "main_score": 0.073298,
        "hf_subset": "ron_Latn-glg_Latn",
        "languages": [
          "ron-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.166334,
        "recall": 0.2003,
        "f1": 0.173393,
        "accuracy": 0.2003,
        "main_score": 0.173393,
        "hf_subset": "ron_Latn-ita_Latn",
        "languages": [
          "ron-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.031102,
        "recall": 0.043065,
        "f1": 0.032964,
        "accuracy": 0.043065,
        "main_score": 0.032964,
        "hf_subset": "ron_Latn-mlt_Latn",
        "languages": [
          "ron-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.03516,
        "recall": 0.045568,
        "f1": 0.036786,
        "accuracy": 0.045568,
        "main_score": 0.036786,
        "hf_subset": "ron_Latn-por_Latn",
        "languages": [
          "ron-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.074796,
        "recall": 0.097146,
        "f1": 0.079414,
        "accuracy": 0.097146,
        "main_score": 0.079414,
        "hf_subset": "ron_Latn-spa_Latn",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.013034,
        "recall": 0.020531,
        "f1": 0.013829,
        "accuracy": 0.020531,
        "main_score": 0.013829,
        "hf_subset": "rus_Cyrl-arb_Arab",
        "languages": [
          "rus-Cyrl",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.139825,
        "recall": 0.201803,
        "f1": 0.151712,
        "accuracy": 0.201803,
        "main_score": 0.151712,
        "hf_subset": "rus_Cyrl-bel_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.002605,
        "recall": 0.00651,
        "f1": 0.002908,
        "accuracy": 0.00651,
        "main_score": 0.002908,
        "hf_subset": "rus_Cyrl-ben_Beng",
        "languages": [
          "rus-Cyrl",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.017333,
        "recall": 0.030045,
        "f1": 0.01888,
        "accuracy": 0.030045,
        "main_score": 0.01888,
        "hf_subset": "rus_Cyrl-bos_Latn",
        "languages": [
          "rus-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.354531,
        "recall": 0.43315,
        "f1": 0.373275,
        "accuracy": 0.43315,
        "main_score": 0.373275,
        "hf_subset": "rus_Cyrl-bul_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.015903,
        "recall": 0.021532,
        "f1": 0.016757,
        "accuracy": 0.021532,
        "main_score": 0.016757,
        "hf_subset": "rus_Cyrl-ces_Latn",
        "languages": [
          "rus-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.020854,
        "recall": 0.03305,
        "f1": 0.022441,
        "accuracy": 0.03305,
        "main_score": 0.022441,
        "hf_subset": "rus_Cyrl-deu_Latn",
        "languages": [
          "rus-Cyrl",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.007613,
        "recall": 0.016024,
        "f1": 0.008625,
        "accuracy": 0.016024,
        "main_score": 0.008625,
        "hf_subset": "rus_Cyrl-ell_Grek",
        "languages": [
          "rus-Cyrl",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.026111,
        "recall": 0.041562,
        "f1": 0.028311,
        "accuracy": 0.041562,
        "main_score": 0.028311,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000163,
        "recall": 0.002504,
        "f1": 0.000271,
        "accuracy": 0.002504,
        "main_score": 0.000271,
        "hf_subset": "rus_Cyrl-fas_Arab",
        "languages": [
          "rus-Cyrl",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.006394,
        "recall": 0.012519,
        "f1": 0.007252,
        "accuracy": 0.012519,
        "main_score": 0.007252,
        "hf_subset": "rus_Cyrl-fin_Latn",
        "languages": [
          "rus-Cyrl",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.043972,
        "recall": 0.058087,
        "f1": 0.046602,
        "accuracy": 0.058087,
        "main_score": 0.046602,
        "hf_subset": "rus_Cyrl-fra_Latn",
        "languages": [
          "rus-Cyrl",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.005077,
        "recall": 0.010015,
        "f1": 0.00561,
        "accuracy": 0.010015,
        "main_score": 0.00561,
        "hf_subset": "rus_Cyrl-heb_Hebr",
        "languages": [
          "rus-Cyrl",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00451,
        "recall": 0.008513,
        "f1": 0.004779,
        "accuracy": 0.008513,
        "main_score": 0.004779,
        "hf_subset": "rus_Cyrl-hin_Deva",
        "languages": [
          "rus-Cyrl",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.014334,
        "recall": 0.022033,
        "f1": 0.015654,
        "accuracy": 0.022033,
        "main_score": 0.015654,
        "hf_subset": "rus_Cyrl-hrv_Latn",
        "languages": [
          "rus-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.006324,
        "recall": 0.012018,
        "f1": 0.006876,
        "accuracy": 0.012018,
        "main_score": 0.006876,
        "hf_subset": "rus_Cyrl-hun_Latn",
        "languages": [
          "rus-Cyrl",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.004657,
        "recall": 0.012018,
        "f1": 0.005249,
        "accuracy": 0.012018,
        "main_score": 0.005249,
        "hf_subset": "rus_Cyrl-ind_Latn",
        "languages": [
          "rus-Cyrl",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.003784,
        "recall": 0.007511,
        "f1": 0.004062,
        "accuracy": 0.007511,
        "main_score": 0.004062,
        "hf_subset": "rus_Cyrl-jpn_Jpan",
        "languages": [
          "rus-Cyrl",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.01198,
        "recall": 0.022534,
        "f1": 0.013609,
        "accuracy": 0.022534,
        "main_score": 0.013609,
        "hf_subset": "rus_Cyrl-kor_Hang",
        "languages": [
          "rus-Cyrl",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.008518,
        "recall": 0.018027,
        "f1": 0.009576,
        "accuracy": 0.018027,
        "main_score": 0.009576,
        "hf_subset": "rus_Cyrl-lit_Latn",
        "languages": [
          "rus-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.169005,
        "recall": 0.228343,
        "f1": 0.180518,
        "accuracy": 0.228343,
        "main_score": 0.180518,
        "hf_subset": "rus_Cyrl-mkd_Cyrl",
        "languages": [
          "rus-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.011948,
        "recall": 0.017026,
        "f1": 0.0126,
        "accuracy": 0.017026,
        "main_score": 0.0126,
        "hf_subset": "rus_Cyrl-nld_Latn",
        "languages": [
          "rus-Cyrl",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.014016,
        "recall": 0.024537,
        "f1": 0.015345,
        "accuracy": 0.024537,
        "main_score": 0.015345,
        "hf_subset": "rus_Cyrl-pol_Latn",
        "languages": [
          "rus-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.025701,
        "recall": 0.038558,
        "f1": 0.026886,
        "accuracy": 0.038558,
        "main_score": 0.026886,
        "hf_subset": "rus_Cyrl-por_Latn",
        "languages": [
          "rus-Cyrl",
          "por-Latn"
        ]
      },
      {
        "precision": 0.012395,
        "recall": 0.022033,
        "f1": 0.014167,
        "accuracy": 0.022033,
        "main_score": 0.014167,
        "hf_subset": "rus_Cyrl-slk_Latn",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.014825,
        "recall": 0.025038,
        "f1": 0.016304,
        "accuracy": 0.025038,
        "main_score": 0.016304,
        "hf_subset": "rus_Cyrl-slv_Latn",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.042026,
        "recall": 0.056084,
        "f1": 0.044179,
        "accuracy": 0.056084,
        "main_score": 0.044179,
        "hf_subset": "rus_Cyrl-spa_Latn",
        "languages": [
          "rus-Cyrl",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.090028,
        "recall": 0.135203,
        "f1": 0.097692,
        "accuracy": 0.135203,
        "main_score": 0.097692,
        "hf_subset": "rus_Cyrl-srp_Cyrl",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.013969,
        "recall": 0.028543,
        "f1": 0.015444,
        "accuracy": 0.028543,
        "main_score": 0.015444,
        "hf_subset": "rus_Cyrl-srp_Latn",
        "languages": [
          "rus-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.017653,
        "recall": 0.030045,
        "f1": 0.018902,
        "accuracy": 0.030045,
        "main_score": 0.018902,
        "hf_subset": "rus_Cyrl-swa_Latn",
        "languages": [
          "rus-Cyrl",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.013725,
        "recall": 0.023035,
        "f1": 0.015037,
        "accuracy": 0.023035,
        "main_score": 0.015037,
        "hf_subset": "rus_Cyrl-swe_Latn",
        "languages": [
          "rus-Cyrl",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.003007,
        "recall": 0.01302,
        "f1": 0.003902,
        "accuracy": 0.01302,
        "main_score": 0.003902,
        "hf_subset": "rus_Cyrl-tam_Taml",
        "languages": [
          "rus-Cyrl",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009751,
        "recall": 0.016525,
        "f1": 0.010883,
        "accuracy": 0.016525,
        "main_score": 0.010883,
        "hf_subset": "rus_Cyrl-tur_Latn",
        "languages": [
          "rus-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.315193,
        "recall": 0.385578,
        "f1": 0.331159,
        "accuracy": 0.385578,
        "main_score": 0.331159,
        "hf_subset": "rus_Cyrl-ukr_Cyrl",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.011029,
        "recall": 0.021032,
        "f1": 0.011836,
        "accuracy": 0.021032,
        "main_score": 0.011836,
        "hf_subset": "rus_Cyrl-vie_Latn",
        "languages": [
          "rus-Cyrl",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.002807,
        "recall": 0.005508,
        "f1": 0.002939,
        "accuracy": 0.005508,
        "main_score": 0.002939,
        "hf_subset": "rus_Cyrl-zho_Hant",
        "languages": [
          "rus-Cyrl",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.006235,
        "recall": 0.010516,
        "f1": 0.006847,
        "accuracy": 0.010516,
        "main_score": 0.006847,
        "hf_subset": "rus_Cyrl-zul_Latn",
        "languages": [
          "rus-Cyrl",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.0289,
        "recall": 0.037056,
        "f1": 0.030402,
        "accuracy": 0.037056,
        "main_score": 0.030402,
        "hf_subset": "shi_Arab-arb_Arab",
        "languages": [
          "shi-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 7.2e-05,
        "recall": 0.001002,
        "f1": 0.000126,
        "accuracy": 0.001002,
        "main_score": 0.000126,
        "hf_subset": "shi_Arab-ckb_Arab",
        "languages": [
          "shi-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.000871,
        "recall": 0.004006,
        "f1": 0.001051,
        "accuracy": 0.004006,
        "main_score": 0.001051,
        "hf_subset": "shi_Arab-eng_Latn",
        "languages": [
          "shi-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000557,
        "recall": 0.001502,
        "f1": 0.000602,
        "accuracy": 0.001502,
        "main_score": 0.000602,
        "hf_subset": "shi_Arab-fas_Arab",
        "languages": [
          "shi-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "shi_Arab-heb_Hebr",
        "languages": [
          "shi-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "shi_Arab-kmr_Latn",
        "languages": [
          "shi-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.071542,
        "recall": 0.092138,
        "f1": 0.07564,
        "accuracy": 0.092138,
        "main_score": 0.07564,
        "hf_subset": "shi_Arab-mey_Arab",
        "languages": [
          "shi-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.000681,
        "recall": 0.002003,
        "f1": 0.000777,
        "accuracy": 0.002003,
        "main_score": 0.000777,
        "hf_subset": "shi_Arab-prs_Arab",
        "languages": [
          "shi-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000791,
        "recall": 0.003005,
        "f1": 0.001129,
        "accuracy": 0.003005,
        "main_score": 0.001129,
        "hf_subset": "shi_Arab-pus_Arab",
        "languages": [
          "shi-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000795,
        "recall": 0.002504,
        "f1": 0.000956,
        "accuracy": 0.002504,
        "main_score": 0.000956,
        "hf_subset": "shi_Arab-tgk_Cyrl",
        "languages": [
          "shi-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.000334,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "sin_Sinh-ben_Beng",
        "languages": [
          "sin-Sinh",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.00051,
        "recall": 0.002003,
        "f1": 0.00052,
        "accuracy": 0.002003,
        "main_score": 0.00052,
        "hf_subset": "sin_Sinh-div_Thaa",
        "languages": [
          "sin-Sinh",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001502,
        "f1": 0.000337,
        "accuracy": 0.001502,
        "main_score": 0.000337,
        "hf_subset": "sin_Sinh-eng_Latn",
        "languages": [
          "sin-Sinh",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "sin_Sinh-eus_Latn",
        "languages": [
          "sin-Sinh",
          "eus-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "sin_Sinh-guj_Gujr",
        "languages": [
          "sin-Sinh",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "sin_Sinh-hin_Deva",
        "languages": [
          "sin-Sinh",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000259,
        "recall": 0.001502,
        "f1": 0.000351,
        "accuracy": 0.001502,
        "main_score": 0.000351,
        "hf_subset": "sin_Sinh-kan_Knda",
        "languages": [
          "sin-Sinh",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "sin_Sinh-mar_Deva",
        "languages": [
          "sin-Sinh",
          "mar-Deva"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.1e-05,
        "accuracy": 0.001002,
        "main_score": 1.1e-05,
        "hf_subset": "sin_Sinh-nep_Deva",
        "languages": [
          "sin-Sinh",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "sin_Sinh-pan_Guru",
        "languages": [
          "sin-Sinh",
          "pan-Guru"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001002,
        "f1": 1.4e-05,
        "accuracy": 0.001002,
        "main_score": 1.4e-05,
        "hf_subset": "sin_Sinh-snd_Arab",
        "languages": [
          "sin-Sinh",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "sin_Sinh-tam_Taml",
        "languages": [
          "sin-Sinh",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "sin_Sinh-tel_Telu",
        "languages": [
          "sin-Sinh",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "sin_Sinh-urd_Arab",
        "languages": [
          "sin-Sinh",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000541,
        "recall": 0.002504,
        "f1": 0.000579,
        "accuracy": 0.002504,
        "main_score": 0.000579,
        "hf_subset": "slk_Latn-bel_Cyrl",
        "languages": [
          "slk-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.135152,
        "recall": 0.164246,
        "f1": 0.1411,
        "accuracy": 0.164246,
        "main_score": 0.1411,
        "hf_subset": "slk_Latn-bos_Latn",
        "languages": [
          "slk-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.001016,
        "recall": 0.003005,
        "f1": 0.001031,
        "accuracy": 0.003005,
        "main_score": 0.001031,
        "hf_subset": "slk_Latn-bul_Cyrl",
        "languages": [
          "slk-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.537988,
        "recall": 0.611918,
        "f1": 0.558071,
        "accuracy": 0.611918,
        "main_score": 0.558071,
        "hf_subset": "slk_Latn-ces_Latn",
        "languages": [
          "slk-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.017857,
        "recall": 0.025538,
        "f1": 0.018645,
        "accuracy": 0.025538,
        "main_score": 0.018645,
        "hf_subset": "slk_Latn-eng_Latn",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.150789,
        "recall": 0.183275,
        "f1": 0.157078,
        "accuracy": 0.183275,
        "main_score": 0.157078,
        "hf_subset": "slk_Latn-hrv_Latn",
        "languages": [
          "slk-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.000135,
        "recall": 0.003505,
        "f1": 0.00024,
        "accuracy": 0.003505,
        "main_score": 0.00024,
        "hf_subset": "slk_Latn-mkd_Cyrl",
        "languages": [
          "slk-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.06428,
        "recall": 0.081622,
        "f1": 0.067567,
        "accuracy": 0.081622,
        "main_score": 0.067567,
        "hf_subset": "slk_Latn-pol_Latn",
        "languages": [
          "slk-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001011,
        "recall": 0.002504,
        "f1": 0.00102,
        "accuracy": 0.002504,
        "main_score": 0.00102,
        "hf_subset": "slk_Latn-rus_Cyrl",
        "languages": [
          "slk-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.174803,
        "recall": 0.200801,
        "f1": 0.181,
        "accuracy": 0.200801,
        "main_score": 0.181,
        "hf_subset": "slk_Latn-slv_Latn",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.000906,
        "recall": 0.003005,
        "f1": 0.001092,
        "accuracy": 0.003005,
        "main_score": 0.001092,
        "hf_subset": "slk_Latn-srp_Cyrl",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.074805,
        "recall": 0.094642,
        "f1": 0.078243,
        "accuracy": 0.094642,
        "main_score": 0.078243,
        "hf_subset": "slk_Latn-srp_Latn",
        "languages": [
          "slk-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.001068,
        "recall": 0.004006,
        "f1": 0.001127,
        "accuracy": 0.004006,
        "main_score": 0.001127,
        "hf_subset": "slk_Latn-ukr_Cyrl",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.000554,
        "recall": 0.003005,
        "f1": 0.0006,
        "accuracy": 0.003005,
        "main_score": 0.0006,
        "hf_subset": "slv_Latn-bel_Cyrl",
        "languages": [
          "slv-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.307538,
        "recall": 0.371057,
        "f1": 0.323231,
        "accuracy": 0.371057,
        "main_score": 0.323231,
        "hf_subset": "slv_Latn-bos_Latn",
        "languages": [
          "slv-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.000759,
        "recall": 0.003005,
        "f1": 0.00085,
        "accuracy": 0.003005,
        "main_score": 0.00085,
        "hf_subset": "slv_Latn-bul_Cyrl",
        "languages": [
          "slv-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.107958,
        "recall": 0.128192,
        "f1": 0.111968,
        "accuracy": 0.128192,
        "main_score": 0.111968,
        "hf_subset": "slv_Latn-ces_Latn",
        "languages": [
          "slv-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.015116,
        "recall": 0.022033,
        "f1": 0.01586,
        "accuracy": 0.022033,
        "main_score": 0.01586,
        "hf_subset": "slv_Latn-eng_Latn",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.324374,
        "recall": 0.390586,
        "f1": 0.340137,
        "accuracy": 0.390586,
        "main_score": 0.340137,
        "hf_subset": "slv_Latn-hrv_Latn",
        "languages": [
          "slv-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.001052,
        "recall": 0.004006,
        "f1": 0.001098,
        "accuracy": 0.004006,
        "main_score": 0.001098,
        "hf_subset": "slv_Latn-mkd_Cyrl",
        "languages": [
          "slv-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.040129,
        "recall": 0.051077,
        "f1": 0.041975,
        "accuracy": 0.051077,
        "main_score": 0.041975,
        "hf_subset": "slv_Latn-pol_Latn",
        "languages": [
          "slv-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001032,
        "recall": 0.003005,
        "f1": 0.00106,
        "accuracy": 0.003005,
        "main_score": 0.00106,
        "hf_subset": "slv_Latn-rus_Cyrl",
        "languages": [
          "slv-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.125777,
        "recall": 0.156735,
        "f1": 0.131365,
        "accuracy": 0.156735,
        "main_score": 0.131365,
        "hf_subset": "slv_Latn-slk_Latn",
        "languages": [
          "slv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.000567,
        "recall": 0.002504,
        "f1": 0.000627,
        "accuracy": 0.002504,
        "main_score": 0.000627,
        "hf_subset": "slv_Latn-srp_Cyrl",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.227358,
        "recall": 0.284927,
        "f1": 0.240147,
        "accuracy": 0.284927,
        "main_score": 0.240147,
        "hf_subset": "slv_Latn-srp_Latn",
        "languages": [
          "slv-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.000532,
        "recall": 0.002504,
        "f1": 0.000561,
        "accuracy": 0.002504,
        "main_score": 0.000561,
        "hf_subset": "slv_Latn-ukr_Cyrl",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.019688,
        "recall": 0.026039,
        "f1": 0.020694,
        "accuracy": 0.026039,
        "main_score": 0.020694,
        "hf_subset": "smo_Latn-eng_Latn",
        "languages": [
          "smo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037833,
        "recall": 0.052078,
        "f1": 0.040395,
        "accuracy": 0.052078,
        "main_score": 0.040395,
        "hf_subset": "smo_Latn-fij_Latn",
        "languages": [
          "smo-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.013117,
        "recall": 0.02003,
        "f1": 0.014319,
        "accuracy": 0.02003,
        "main_score": 0.014319,
        "hf_subset": "smo_Latn-fil_Latn",
        "languages": [
          "smo-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.003261,
        "recall": 0.00651,
        "f1": 0.003768,
        "accuracy": 0.00651,
        "main_score": 0.003768,
        "hf_subset": "smo_Latn-ind_Latn",
        "languages": [
          "smo-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "smo_Latn-mal_Mlym",
        "languages": [
          "smo-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.028355,
        "recall": 0.040561,
        "f1": 0.030266,
        "accuracy": 0.040561,
        "main_score": 0.030266,
        "hf_subset": "smo_Latn-mlg_Latn",
        "languages": [
          "smo-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.027327,
        "recall": 0.039559,
        "f1": 0.029634,
        "accuracy": 0.039559,
        "main_score": 0.029634,
        "hf_subset": "smo_Latn-mri_Latn",
        "languages": [
          "smo-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.003091,
        "recall": 0.008012,
        "f1": 0.00345,
        "accuracy": 0.008012,
        "main_score": 0.00345,
        "hf_subset": "smo_Latn-msa_Latn",
        "languages": [
          "smo-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.077513,
        "recall": 0.099149,
        "f1": 0.082584,
        "accuracy": 0.099149,
        "main_score": 0.082584,
        "hf_subset": "smo_Latn-tah_Latn",
        "languages": [
          "smo-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.018831,
        "recall": 0.026039,
        "f1": 0.020308,
        "accuracy": 0.026039,
        "main_score": 0.020308,
        "hf_subset": "smo_Latn-ton_Latn",
        "languages": [
          "smo-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.062545,
        "recall": 0.081122,
        "f1": 0.066483,
        "accuracy": 0.081122,
        "main_score": 0.066483,
        "hf_subset": "sna_Latn-bem_Latn",
        "languages": [
          "sna-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.015876,
        "recall": 0.021032,
        "f1": 0.016674,
        "accuracy": 0.021032,
        "main_score": 0.016674,
        "hf_subset": "sna_Latn-eng_Latn",
        "languages": [
          "sna-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036422,
        "recall": 0.042063,
        "f1": 0.037714,
        "accuracy": 0.042063,
        "main_score": 0.037714,
        "hf_subset": "sna_Latn-ewe_Latn",
        "languages": [
          "sna-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.038393,
        "recall": 0.048573,
        "f1": 0.040313,
        "accuracy": 0.048573,
        "main_score": 0.040313,
        "hf_subset": "sna_Latn-fuc_Latn",
        "languages": [
          "sna-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.016531,
        "recall": 0.024537,
        "f1": 0.017727,
        "accuracy": 0.024537,
        "main_score": 0.017727,
        "hf_subset": "sna_Latn-kin_Latn",
        "languages": [
          "sna-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.041757,
        "recall": 0.058588,
        "f1": 0.044854,
        "accuracy": 0.058588,
        "main_score": 0.044854,
        "hf_subset": "sna_Latn-nde_Latn",
        "languages": [
          "sna-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.078484,
        "recall": 0.10015,
        "f1": 0.083203,
        "accuracy": 0.10015,
        "main_score": 0.083203,
        "hf_subset": "sna_Latn-nya_Latn",
        "languages": [
          "sna-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.061149,
        "recall": 0.076114,
        "f1": 0.064195,
        "accuracy": 0.076114,
        "main_score": 0.064195,
        "hf_subset": "sna_Latn-ven_Latn",
        "languages": [
          "sna-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "snd_Arab-ben_Beng",
        "languages": [
          "snd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "snd_Arab-div_Thaa",
        "languages": [
          "snd-Arab",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.002015,
        "recall": 0.004006,
        "f1": 0.002026,
        "accuracy": 0.004006,
        "main_score": 0.002026,
        "hf_subset": "snd_Arab-eng_Latn",
        "languages": [
          "snd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000506,
        "accuracy": 0.001502,
        "main_score": 0.000506,
        "hf_subset": "snd_Arab-eus_Latn",
        "languages": [
          "snd-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "snd_Arab-guj_Gujr",
        "languages": [
          "snd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "snd_Arab-hin_Deva",
        "languages": [
          "snd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "snd_Arab-kan_Knda",
        "languages": [
          "snd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "snd_Arab-mar_Deva",
        "languages": [
          "snd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001256,
        "recall": 0.003005,
        "f1": 0.001344,
        "accuracy": 0.003005,
        "main_score": 0.001344,
        "hf_subset": "snd_Arab-nep_Deva",
        "languages": [
          "snd-Arab",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "snd_Arab-pan_Guru",
        "languages": [
          "snd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 4.2e-05,
        "recall": 0.000501,
        "f1": 7.7e-05,
        "accuracy": 0.000501,
        "main_score": 7.7e-05,
        "hf_subset": "snd_Arab-sin_Sinh",
        "languages": [
          "snd-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "snd_Arab-tam_Taml",
        "languages": [
          "snd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000871,
        "recall": 0.003005,
        "f1": 0.001049,
        "accuracy": 0.003005,
        "main_score": 0.001049,
        "hf_subset": "snd_Arab-tel_Telu",
        "languages": [
          "snd-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001502,
        "f1": 5e-06,
        "accuracy": 0.001502,
        "main_score": 5e-06,
        "hf_subset": "snd_Arab-urd_Arab",
        "languages": [
          "snd-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 9.5e-05,
        "recall": 0.002003,
        "f1": 0.000173,
        "accuracy": 0.002003,
        "main_score": 0.000173,
        "hf_subset": "som_Latn-amh_Ethi",
        "languages": [
          "som-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.01689,
        "recall": 0.022534,
        "f1": 0.017551,
        "accuracy": 0.022534,
        "main_score": 0.017551,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.07994,
        "recall": 0.099649,
        "f1": 0.083556,
        "accuracy": 0.099649,
        "main_score": 0.083556,
        "hf_subset": "som_Latn-hau_Latn",
        "languages": [
          "som-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.00657,
        "recall": 0.010015,
        "f1": 0.006997,
        "accuracy": 0.010015,
        "main_score": 0.006997,
        "hf_subset": "som_Latn-ibo_Latn",
        "languages": [
          "som-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.060649,
        "recall": 0.075113,
        "f1": 0.063197,
        "accuracy": 0.075113,
        "main_score": 0.063197,
        "hf_subset": "som_Latn-nso_Latn",
        "languages": [
          "som-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.048663,
        "recall": 0.0666,
        "f1": 0.052161,
        "accuracy": 0.0666,
        "main_score": 0.052161,
        "hf_subset": "som_Latn-orm_Ethi",
        "languages": [
          "som-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.032479,
        "recall": 0.051077,
        "f1": 0.035286,
        "accuracy": 0.051077,
        "main_score": 0.035286,
        "hf_subset": "som_Latn-ssw_Latn",
        "languages": [
          "som-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.005878,
        "recall": 0.007011,
        "f1": 0.006046,
        "accuracy": 0.007011,
        "main_score": 0.006046,
        "hf_subset": "som_Latn-swa_Latn",
        "languages": [
          "som-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001002,
        "f1": 1.5e-05,
        "accuracy": 0.001002,
        "main_score": 1.5e-05,
        "hf_subset": "som_Latn-tir_Ethi",
        "languages": [
          "som-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.045248,
        "recall": 0.059589,
        "f1": 0.047843,
        "accuracy": 0.059589,
        "main_score": 0.047843,
        "hf_subset": "som_Latn-tsn_Latn",
        "languages": [
          "som-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.047335,
        "recall": 0.061592,
        "f1": 0.050553,
        "accuracy": 0.061592,
        "main_score": 0.050553,
        "hf_subset": "som_Latn-wol_Latn",
        "languages": [
          "som-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.01834,
        "recall": 0.027541,
        "f1": 0.019812,
        "accuracy": 0.027541,
        "main_score": 0.019812,
        "hf_subset": "som_Latn-xho_Latn",
        "languages": [
          "som-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.008133,
        "recall": 0.011017,
        "f1": 0.008394,
        "accuracy": 0.011017,
        "main_score": 0.008394,
        "hf_subset": "som_Latn-yor_Latn",
        "languages": [
          "som-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.021135,
        "recall": 0.031547,
        "f1": 0.022838,
        "accuracy": 0.031547,
        "main_score": 0.022838,
        "hf_subset": "som_Latn-zul_Latn",
        "languages": [
          "som-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.002215,
        "recall": 0.006009,
        "f1": 0.002658,
        "accuracy": 0.006009,
        "main_score": 0.002658,
        "hf_subset": "spa_Latn-arb_Arab",
        "languages": [
          "spa-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00109,
        "recall": 0.003505,
        "f1": 0.001346,
        "accuracy": 0.003505,
        "main_score": 0.001346,
        "hf_subset": "spa_Latn-ben_Beng",
        "languages": [
          "spa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.091213,
        "recall": 0.114171,
        "f1": 0.095245,
        "accuracy": 0.114171,
        "main_score": 0.095245,
        "hf_subset": "spa_Latn-cat_Latn",
        "languages": [
          "spa-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.023791,
        "recall": 0.039059,
        "f1": 0.026124,
        "accuracy": 0.039059,
        "main_score": 0.026124,
        "hf_subset": "spa_Latn-deu_Latn",
        "languages": [
          "spa-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 5e-05,
        "recall": 0.001002,
        "f1": 9.2e-05,
        "accuracy": 0.001002,
        "main_score": 9.2e-05,
        "hf_subset": "spa_Latn-ell_Grek",
        "languages": [
          "spa-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.357433,
        "recall": 0.391087,
        "f1": 0.365514,
        "accuracy": 0.391087,
        "main_score": 0.365514,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000517,
        "recall": 0.002003,
        "f1": 0.000532,
        "accuracy": 0.002003,
        "main_score": 0.000532,
        "hf_subset": "spa_Latn-fas_Arab",
        "languages": [
          "spa-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.007971,
        "recall": 0.014522,
        "f1": 0.008469,
        "accuracy": 0.014522,
        "main_score": 0.008469,
        "hf_subset": "spa_Latn-fin_Latn",
        "languages": [
          "spa-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.333524,
        "recall": 0.370556,
        "f1": 0.342061,
        "accuracy": 0.370556,
        "main_score": 0.342061,
        "hf_subset": "spa_Latn-fra_Latn",
        "languages": [
          "spa-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.395468,
        "recall": 0.454682,
        "f1": 0.408356,
        "accuracy": 0.454682,
        "main_score": 0.408356,
        "hf_subset": "spa_Latn-glg_Latn",
        "languages": [
          "spa-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.000647,
        "recall": 0.002003,
        "f1": 0.000742,
        "accuracy": 0.002003,
        "main_score": 0.000742,
        "hf_subset": "spa_Latn-heb_Hebr",
        "languages": [
          "spa-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "spa_Latn-hin_Deva",
        "languages": [
          "spa-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.007685,
        "recall": 0.014522,
        "f1": 0.008272,
        "accuracy": 0.014522,
        "main_score": 0.008272,
        "hf_subset": "spa_Latn-hun_Latn",
        "languages": [
          "spa-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.029571,
        "recall": 0.039559,
        "f1": 0.03086,
        "accuracy": 0.039559,
        "main_score": 0.03086,
        "hf_subset": "spa_Latn-ind_Latn",
        "languages": [
          "spa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.198539,
        "recall": 0.230846,
        "f1": 0.204879,
        "accuracy": 0.230846,
        "main_score": 0.204879,
        "hf_subset": "spa_Latn-ita_Latn",
        "languages": [
          "spa-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "spa_Latn-jpn_Jpan",
        "languages": [
          "spa-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000564,
        "recall": 0.001502,
        "f1": 0.000613,
        "accuracy": 0.001502,
        "main_score": 0.000613,
        "hf_subset": "spa_Latn-kor_Hang",
        "languages": [
          "spa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.008257,
        "recall": 0.015523,
        "f1": 0.008995,
        "accuracy": 0.015523,
        "main_score": 0.008995,
        "hf_subset": "spa_Latn-lit_Latn",
        "languages": [
          "spa-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.016383,
        "recall": 0.023035,
        "f1": 0.017422,
        "accuracy": 0.023035,
        "main_score": 0.017422,
        "hf_subset": "spa_Latn-mlt_Latn",
        "languages": [
          "spa-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.033735,
        "recall": 0.042063,
        "f1": 0.03513,
        "accuracy": 0.042063,
        "main_score": 0.03513,
        "hf_subset": "spa_Latn-nld_Latn",
        "languages": [
          "spa-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.009209,
        "recall": 0.01302,
        "f1": 0.009653,
        "accuracy": 0.01302,
        "main_score": 0.009653,
        "hf_subset": "spa_Latn-pol_Latn",
        "languages": [
          "spa-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.337068,
        "recall": 0.377566,
        "f1": 0.346177,
        "accuracy": 0.377566,
        "main_score": 0.346177,
        "hf_subset": "spa_Latn-por_Latn",
        "languages": [
          "spa-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.063567,
        "recall": 0.088132,
        "f1": 0.067929,
        "accuracy": 0.088132,
        "main_score": 0.067929,
        "hf_subset": "spa_Latn-ron_Latn",
        "languages": [
          "spa-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000507,
        "accuracy": 0.001502,
        "main_score": 0.000507,
        "hf_subset": "spa_Latn-rus_Cyrl",
        "languages": [
          "spa-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.012686,
        "recall": 0.02003,
        "f1": 0.013684,
        "accuracy": 0.02003,
        "main_score": 0.013684,
        "hf_subset": "spa_Latn-swa_Latn",
        "languages": [
          "spa-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.029587,
        "recall": 0.044066,
        "f1": 0.031494,
        "accuracy": 0.044066,
        "main_score": 0.031494,
        "hf_subset": "spa_Latn-swe_Latn",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001223,
        "recall": 0.003005,
        "f1": 0.001352,
        "accuracy": 0.003005,
        "main_score": 0.001352,
        "hf_subset": "spa_Latn-tam_Taml",
        "languages": [
          "spa-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.005198,
        "recall": 0.009514,
        "f1": 0.005667,
        "accuracy": 0.009514,
        "main_score": 0.005667,
        "hf_subset": "spa_Latn-tur_Latn",
        "languages": [
          "spa-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.035081,
        "recall": 0.052579,
        "f1": 0.038188,
        "accuracy": 0.052579,
        "main_score": 0.038188,
        "hf_subset": "spa_Latn-vie_Latn",
        "languages": [
          "spa-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.00127,
        "recall": 0.003505,
        "f1": 0.001372,
        "accuracy": 0.003505,
        "main_score": 0.001372,
        "hf_subset": "spa_Latn-zho_Hant",
        "languages": [
          "spa-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.011022,
        "recall": 0.020531,
        "f1": 0.012087,
        "accuracy": 0.020531,
        "main_score": 0.012087,
        "hf_subset": "spa_Latn-zul_Latn",
        "languages": [
          "spa-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001502,
        "f1": 0.000337,
        "accuracy": 0.001502,
        "main_score": 0.000337,
        "hf_subset": "sqi_Latn-ell_Grek",
        "languages": [
          "sqi-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.027006,
        "recall": 0.036054,
        "f1": 0.02848,
        "accuracy": 0.036054,
        "main_score": 0.02848,
        "hf_subset": "sqi_Latn-eng_Latn",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 4e-05,
        "recall": 0.001502,
        "f1": 7.6e-05,
        "accuracy": 0.001502,
        "main_score": 7.6e-05,
        "hf_subset": "sqi_Latn-hye_Armn",
        "languages": [
          "sqi-Latn",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.000815,
        "recall": 0.002504,
        "f1": 0.000948,
        "accuracy": 0.002504,
        "main_score": 0.000948,
        "hf_subset": "sqi_Latn-kat_Geor",
        "languages": [
          "sqi-Latn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.055029,
        "recall": 0.072108,
        "f1": 0.057892,
        "accuracy": 0.072108,
        "main_score": 0.057892,
        "hf_subset": "srp_Cyrl-bel_Cyrl",
        "languages": [
          "srp-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.018693,
        "recall": 0.027541,
        "f1": 0.019539,
        "accuracy": 0.027541,
        "main_score": 0.019539,
        "hf_subset": "srp_Cyrl-bos_Latn",
        "languages": [
          "srp-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.162636,
        "recall": 0.201803,
        "f1": 0.170152,
        "accuracy": 0.201803,
        "main_score": 0.170152,
        "hf_subset": "srp_Cyrl-bul_Cyrl",
        "languages": [
          "srp-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.010386,
        "recall": 0.017026,
        "f1": 0.01123,
        "accuracy": 0.017026,
        "main_score": 0.01123,
        "hf_subset": "srp_Cyrl-ces_Latn",
        "languages": [
          "srp-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.007782,
        "recall": 0.011517,
        "f1": 0.008126,
        "accuracy": 0.011517,
        "main_score": 0.008126,
        "hf_subset": "srp_Cyrl-eng_Latn",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016706,
        "recall": 0.023535,
        "f1": 0.017484,
        "accuracy": 0.023535,
        "main_score": 0.017484,
        "hf_subset": "srp_Cyrl-hrv_Latn",
        "languages": [
          "srp-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.271982,
        "recall": 0.328993,
        "f1": 0.284727,
        "accuracy": 0.328993,
        "main_score": 0.284727,
        "hf_subset": "srp_Cyrl-mkd_Cyrl",
        "languages": [
          "srp-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.006654,
        "recall": 0.01352,
        "f1": 0.007375,
        "accuracy": 0.01352,
        "main_score": 0.007375,
        "hf_subset": "srp_Cyrl-pol_Latn",
        "languages": [
          "srp-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.051015,
        "recall": 0.069104,
        "f1": 0.05368,
        "accuracy": 0.069104,
        "main_score": 0.05368,
        "hf_subset": "srp_Cyrl-rus_Cyrl",
        "languages": [
          "srp-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.009496,
        "recall": 0.014522,
        "f1": 0.010154,
        "accuracy": 0.014522,
        "main_score": 0.010154,
        "hf_subset": "srp_Cyrl-slk_Latn",
        "languages": [
          "srp-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.009952,
        "recall": 0.016525,
        "f1": 0.0107,
        "accuracy": 0.016525,
        "main_score": 0.0107,
        "hf_subset": "srp_Cyrl-slv_Latn",
        "languages": [
          "srp-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.029949,
        "recall": 0.044066,
        "f1": 0.031741,
        "accuracy": 0.044066,
        "main_score": 0.031741,
        "hf_subset": "srp_Cyrl-srp_Latn",
        "languages": [
          "srp-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.110469,
        "recall": 0.145719,
        "f1": 0.117264,
        "accuracy": 0.145719,
        "main_score": 0.117264,
        "hf_subset": "srp_Cyrl-ukr_Cyrl",
        "languages": [
          "srp-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 8.1e-05,
        "recall": 0.001502,
        "f1": 0.000143,
        "accuracy": 0.001502,
        "main_score": 0.000143,
        "hf_subset": "srp_Latn-bel_Cyrl",
        "languages": [
          "srp-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.612743,
        "recall": 0.692038,
        "f1": 0.63438,
        "accuracy": 0.692038,
        "main_score": 0.63438,
        "hf_subset": "srp_Latn-bos_Latn",
        "languages": [
          "srp-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.000515,
        "recall": 0.002504,
        "f1": 0.000529,
        "accuracy": 0.002504,
        "main_score": 0.000529,
        "hf_subset": "srp_Latn-bul_Cyrl",
        "languages": [
          "srp-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.041087,
        "recall": 0.058588,
        "f1": 0.043421,
        "accuracy": 0.058588,
        "main_score": 0.043421,
        "hf_subset": "srp_Latn-ces_Latn",
        "languages": [
          "srp-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.008457,
        "recall": 0.014522,
        "f1": 0.008908,
        "accuracy": 0.014522,
        "main_score": 0.008908,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.520028,
        "recall": 0.605408,
        "f1": 0.542873,
        "accuracy": 0.605408,
        "main_score": 0.542873,
        "hf_subset": "srp_Latn-hrv_Latn",
        "languages": [
          "srp-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.001031,
        "recall": 0.003505,
        "f1": 0.001059,
        "accuracy": 0.003505,
        "main_score": 0.001059,
        "hf_subset": "srp_Latn-mkd_Cyrl",
        "languages": [
          "srp-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.017438,
        "recall": 0.023035,
        "f1": 0.018321,
        "accuracy": 0.023035,
        "main_score": 0.018321,
        "hf_subset": "srp_Latn-pol_Latn",
        "languages": [
          "srp-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001008,
        "recall": 0.002504,
        "f1": 0.001014,
        "accuracy": 0.002504,
        "main_score": 0.001014,
        "hf_subset": "srp_Latn-rus_Cyrl",
        "languages": [
          "srp-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.053127,
        "recall": 0.074612,
        "f1": 0.056677,
        "accuracy": 0.074612,
        "main_score": 0.056677,
        "hf_subset": "srp_Latn-slk_Latn",
        "languages": [
          "srp-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.197597,
        "recall": 0.256385,
        "f1": 0.210551,
        "accuracy": 0.256385,
        "main_score": 0.210551,
        "hf_subset": "srp_Latn-slv_Latn",
        "languages": [
          "srp-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.002899,
        "recall": 0.006009,
        "f1": 0.003102,
        "accuracy": 0.006009,
        "main_score": 0.003102,
        "hf_subset": "srp_Latn-srp_Cyrl",
        "languages": [
          "srp-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.000674,
        "recall": 0.003005,
        "f1": 0.000763,
        "accuracy": 0.003005,
        "main_score": 0.000763,
        "hf_subset": "srp_Latn-ukr_Cyrl",
        "languages": [
          "srp-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.001343,
        "recall": 0.003505,
        "f1": 0.001553,
        "accuracy": 0.003505,
        "main_score": 0.001553,
        "hf_subset": "ssw_Latn-amh_Ethi",
        "languages": [
          "ssw-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.015198,
        "recall": 0.022033,
        "f1": 0.015994,
        "accuracy": 0.022033,
        "main_score": 0.015994,
        "hf_subset": "ssw_Latn-eng_Latn",
        "languages": [
          "ssw-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.044269,
        "recall": 0.054081,
        "f1": 0.046014,
        "accuracy": 0.054081,
        "main_score": 0.046014,
        "hf_subset": "ssw_Latn-hau_Latn",
        "languages": [
          "ssw-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.01186,
        "recall": 0.02003,
        "f1": 0.012928,
        "accuracy": 0.02003,
        "main_score": 0.012928,
        "hf_subset": "ssw_Latn-ibo_Latn",
        "languages": [
          "ssw-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.052935,
        "recall": 0.059589,
        "f1": 0.054658,
        "accuracy": 0.059589,
        "main_score": 0.054658,
        "hf_subset": "ssw_Latn-nso_Latn",
        "languages": [
          "ssw-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.024738,
        "recall": 0.029044,
        "f1": 0.025805,
        "accuracy": 0.029044,
        "main_score": 0.025805,
        "hf_subset": "ssw_Latn-orm_Ethi",
        "languages": [
          "ssw-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.047704,
        "recall": 0.057086,
        "f1": 0.049524,
        "accuracy": 0.057086,
        "main_score": 0.049524,
        "hf_subset": "ssw_Latn-som_Latn",
        "languages": [
          "ssw-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.009853,
        "recall": 0.01302,
        "f1": 0.010401,
        "accuracy": 0.01302,
        "main_score": 0.010401,
        "hf_subset": "ssw_Latn-swa_Latn",
        "languages": [
          "ssw-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 1.9e-05,
        "recall": 0.001502,
        "f1": 3.6e-05,
        "accuracy": 0.001502,
        "main_score": 3.6e-05,
        "hf_subset": "ssw_Latn-tir_Ethi",
        "languages": [
          "ssw-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.051872,
        "recall": 0.062093,
        "f1": 0.054006,
        "accuracy": 0.062093,
        "main_score": 0.054006,
        "hf_subset": "ssw_Latn-tsn_Latn",
        "languages": [
          "ssw-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.037066,
        "recall": 0.044567,
        "f1": 0.038969,
        "accuracy": 0.044567,
        "main_score": 0.038969,
        "hf_subset": "ssw_Latn-wol_Latn",
        "languages": [
          "ssw-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.093137,
        "recall": 0.128693,
        "f1": 0.100239,
        "accuracy": 0.128693,
        "main_score": 0.100239,
        "hf_subset": "ssw_Latn-xho_Latn",
        "languages": [
          "ssw-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.007836,
        "recall": 0.01302,
        "f1": 0.008683,
        "accuracy": 0.01302,
        "main_score": 0.008683,
        "hf_subset": "ssw_Latn-yor_Latn",
        "languages": [
          "ssw-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.134027,
        "recall": 0.172759,
        "f1": 0.142674,
        "accuracy": 0.172759,
        "main_score": 0.142674,
        "hf_subset": "ssw_Latn-zul_Latn",
        "languages": [
          "ssw-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.002335,
        "recall": 0.007011,
        "f1": 0.002748,
        "accuracy": 0.007011,
        "main_score": 0.002748,
        "hf_subset": "swa_Latn-amh_Ethi",
        "languages": [
          "swa-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.010763,
        "recall": 0.019029,
        "f1": 0.011723,
        "accuracy": 0.019029,
        "main_score": 0.011723,
        "hf_subset": "swa_Latn-arb_Arab",
        "languages": [
          "swa-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000178,
        "recall": 0.003005,
        "f1": 0.000313,
        "accuracy": 0.003005,
        "main_score": 0.000313,
        "hf_subset": "swa_Latn-ben_Beng",
        "languages": [
          "swa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.048416,
        "recall": 0.07311,
        "f1": 0.052463,
        "accuracy": 0.07311,
        "main_score": 0.052463,
        "hf_subset": "swa_Latn-deu_Latn",
        "languages": [
          "swa-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000547,
        "recall": 0.004507,
        "f1": 0.000839,
        "accuracy": 0.004507,
        "main_score": 0.000839,
        "hf_subset": "swa_Latn-ell_Grek",
        "languages": [
          "swa-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.097576,
        "recall": 0.125689,
        "f1": 0.102599,
        "accuracy": 0.125689,
        "main_score": 0.102599,
        "hf_subset": "swa_Latn-eng_Latn",
        "languages": [
          "swa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000124,
        "recall": 0.002504,
        "f1": 0.000214,
        "accuracy": 0.002504,
        "main_score": 0.000214,
        "hf_subset": "swa_Latn-fas_Arab",
        "languages": [
          "swa-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.023301,
        "recall": 0.031047,
        "f1": 0.02486,
        "accuracy": 0.031047,
        "main_score": 0.02486,
        "hf_subset": "swa_Latn-fin_Latn",
        "languages": [
          "swa-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.081617,
        "recall": 0.101652,
        "f1": 0.08519,
        "accuracy": 0.101652,
        "main_score": 0.08519,
        "hf_subset": "swa_Latn-fra_Latn",
        "languages": [
          "swa-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.021081,
        "recall": 0.027041,
        "f1": 0.021959,
        "accuracy": 0.027041,
        "main_score": 0.021959,
        "hf_subset": "swa_Latn-hau_Latn",
        "languages": [
          "swa-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.00029,
        "recall": 0.002504,
        "f1": 0.00041,
        "accuracy": 0.002504,
        "main_score": 0.00041,
        "hf_subset": "swa_Latn-heb_Hebr",
        "languages": [
          "swa-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00188,
        "recall": 0.004006,
        "f1": 0.002251,
        "accuracy": 0.004006,
        "main_score": 0.002251,
        "hf_subset": "swa_Latn-hin_Deva",
        "languages": [
          "swa-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018869,
        "recall": 0.029044,
        "f1": 0.020912,
        "accuracy": 0.029044,
        "main_score": 0.020912,
        "hf_subset": "swa_Latn-hun_Latn",
        "languages": [
          "swa-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.047829,
        "recall": 0.063095,
        "f1": 0.050924,
        "accuracy": 0.063095,
        "main_score": 0.050924,
        "hf_subset": "swa_Latn-ibo_Latn",
        "languages": [
          "swa-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.047525,
        "recall": 0.068603,
        "f1": 0.050834,
        "accuracy": 0.068603,
        "main_score": 0.050834,
        "hf_subset": "swa_Latn-ind_Latn",
        "languages": [
          "swa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000515,
        "recall": 0.001502,
        "f1": 0.000528,
        "accuracy": 0.001502,
        "main_score": 0.000528,
        "hf_subset": "swa_Latn-jpn_Jpan",
        "languages": [
          "swa-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002606,
        "recall": 0.00651,
        "f1": 0.002851,
        "accuracy": 0.00651,
        "main_score": 0.002851,
        "hf_subset": "swa_Latn-kor_Hang",
        "languages": [
          "swa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.01802,
        "recall": 0.022033,
        "f1": 0.018618,
        "accuracy": 0.022033,
        "main_score": 0.018618,
        "hf_subset": "swa_Latn-lit_Latn",
        "languages": [
          "swa-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.017097,
        "recall": 0.018528,
        "f1": 0.017485,
        "accuracy": 0.018528,
        "main_score": 0.017485,
        "hf_subset": "swa_Latn-nld_Latn",
        "languages": [
          "swa-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.028428,
        "recall": 0.035053,
        "f1": 0.029519,
        "accuracy": 0.035053,
        "main_score": 0.029519,
        "hf_subset": "swa_Latn-nso_Latn",
        "languages": [
          "swa-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.00948,
        "recall": 0.012519,
        "f1": 0.009896,
        "accuracy": 0.012519,
        "main_score": 0.009896,
        "hf_subset": "swa_Latn-orm_Ethi",
        "languages": [
          "swa-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.017294,
        "recall": 0.030546,
        "f1": 0.019265,
        "accuracy": 0.030546,
        "main_score": 0.019265,
        "hf_subset": "swa_Latn-pol_Latn",
        "languages": [
          "swa-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.08589,
        "recall": 0.109664,
        "f1": 0.090262,
        "accuracy": 0.109664,
        "main_score": 0.090262,
        "hf_subset": "swa_Latn-por_Latn",
        "languages": [
          "swa-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.006965,
        "recall": 0.012018,
        "f1": 0.007786,
        "accuracy": 0.012018,
        "main_score": 0.007786,
        "hf_subset": "swa_Latn-rus_Cyrl",
        "languages": [
          "swa-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.01623,
        "recall": 0.019529,
        "f1": 0.016914,
        "accuracy": 0.019529,
        "main_score": 0.016914,
        "hf_subset": "swa_Latn-som_Latn",
        "languages": [
          "swa-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.099126,
        "recall": 0.129194,
        "f1": 0.1047,
        "accuracy": 0.129194,
        "main_score": 0.1047,
        "hf_subset": "swa_Latn-spa_Latn",
        "languages": [
          "swa-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.024978,
        "recall": 0.035553,
        "f1": 0.026853,
        "accuracy": 0.035553,
        "main_score": 0.026853,
        "hf_subset": "swa_Latn-ssw_Latn",
        "languages": [
          "swa-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.043633,
        "recall": 0.063595,
        "f1": 0.046967,
        "accuracy": 0.063595,
        "main_score": 0.046967,
        "hf_subset": "swa_Latn-swe_Latn",
        "languages": [
          "swa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001778,
        "recall": 0.004006,
        "f1": 0.001944,
        "accuracy": 0.004006,
        "main_score": 0.001944,
        "hf_subset": "swa_Latn-tam_Taml",
        "languages": [
          "swa-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000354,
        "recall": 0.002003,
        "f1": 0.000508,
        "accuracy": 0.002003,
        "main_score": 0.000508,
        "hf_subset": "swa_Latn-tir_Ethi",
        "languages": [
          "swa-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.028528,
        "recall": 0.039059,
        "f1": 0.030352,
        "accuracy": 0.039059,
        "main_score": 0.030352,
        "hf_subset": "swa_Latn-tsn_Latn",
        "languages": [
          "swa-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.025537,
        "recall": 0.034051,
        "f1": 0.027059,
        "accuracy": 0.034051,
        "main_score": 0.027059,
        "hf_subset": "swa_Latn-tur_Latn",
        "languages": [
          "swa-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.035171,
        "recall": 0.056585,
        "f1": 0.038447,
        "accuracy": 0.056585,
        "main_score": 0.038447,
        "hf_subset": "swa_Latn-vie_Latn",
        "languages": [
          "swa-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.026174,
        "recall": 0.031547,
        "f1": 0.027193,
        "accuracy": 0.031547,
        "main_score": 0.027193,
        "hf_subset": "swa_Latn-wol_Latn",
        "languages": [
          "swa-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.019268,
        "recall": 0.026039,
        "f1": 0.020492,
        "accuracy": 0.026039,
        "main_score": 0.020492,
        "hf_subset": "swa_Latn-xho_Latn",
        "languages": [
          "swa-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.021239,
        "recall": 0.036555,
        "f1": 0.024102,
        "accuracy": 0.036555,
        "main_score": 0.024102,
        "hf_subset": "swa_Latn-yor_Latn",
        "languages": [
          "swa-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.000946,
        "recall": 0.004006,
        "f1": 0.00114,
        "accuracy": 0.004006,
        "main_score": 0.00114,
        "hf_subset": "swa_Latn-zho_Hant",
        "languages": [
          "swa-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.021658,
        "recall": 0.027541,
        "f1": 0.022741,
        "accuracy": 0.027541,
        "main_score": 0.022741,
        "hf_subset": "swa_Latn-zul_Latn",
        "languages": [
          "swa-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.077971,
        "recall": 0.085628,
        "f1": 0.079668,
        "accuracy": 0.085628,
        "main_score": 0.079668,
        "hf_subset": "swe_Latn-afr_Latn",
        "languages": [
          "swe-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "swe_Latn-arb_Arab",
        "languages": [
          "swe-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00057,
        "recall": 0.002504,
        "f1": 0.000628,
        "accuracy": 0.002504,
        "main_score": 0.000628,
        "hf_subset": "swe_Latn-ben_Beng",
        "languages": [
          "swe-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.433984,
        "recall": 0.493741,
        "f1": 0.44869,
        "accuracy": 0.493741,
        "main_score": 0.44869,
        "hf_subset": "swe_Latn-dan_Latn",
        "languages": [
          "swe-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.066253,
        "recall": 0.081122,
        "f1": 0.068791,
        "accuracy": 0.081122,
        "main_score": 0.068791,
        "hf_subset": "swe_Latn-deu_Latn",
        "languages": [
          "swe-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000511,
        "recall": 0.002504,
        "f1": 0.000688,
        "accuracy": 0.002504,
        "main_score": 0.000688,
        "hf_subset": "swe_Latn-ell_Grek",
        "languages": [
          "swe-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.037894,
        "recall": 0.047071,
        "f1": 0.039322,
        "accuracy": 0.047071,
        "main_score": 0.039322,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.110816,
        "recall": 0.134702,
        "f1": 0.11551,
        "accuracy": 0.134702,
        "main_score": 0.11551,
        "hf_subset": "swe_Latn-fao_Latn",
        "languages": [
          "swe-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "swe_Latn-fas_Arab",
        "languages": [
          "swe-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.030672,
        "recall": 0.047571,
        "f1": 0.03354,
        "accuracy": 0.047571,
        "main_score": 0.03354,
        "hf_subset": "swe_Latn-fin_Latn",
        "languages": [
          "swe-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.017571,
        "recall": 0.021032,
        "f1": 0.017946,
        "accuracy": 0.021032,
        "main_score": 0.017946,
        "hf_subset": "swe_Latn-fra_Latn",
        "languages": [
          "swe-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001127,
        "recall": 0.002003,
        "f1": 0.001202,
        "accuracy": 0.002003,
        "main_score": 0.001202,
        "hf_subset": "swe_Latn-heb_Hebr",
        "languages": [
          "swe-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "swe_Latn-hin_Deva",
        "languages": [
          "swe-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.01688,
        "recall": 0.025038,
        "f1": 0.018162,
        "accuracy": 0.025038,
        "main_score": 0.018162,
        "hf_subset": "swe_Latn-hun_Latn",
        "languages": [
          "swe-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.009531,
        "recall": 0.016024,
        "f1": 0.01025,
        "accuracy": 0.016024,
        "main_score": 0.01025,
        "hf_subset": "swe_Latn-ind_Latn",
        "languages": [
          "swe-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.06349,
        "recall": 0.087631,
        "f1": 0.067787,
        "accuracy": 0.087631,
        "main_score": 0.067787,
        "hf_subset": "swe_Latn-isl_Latn",
        "languages": [
          "swe-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 1.2e-05,
        "recall": 0.001002,
        "f1": 2.3e-05,
        "accuracy": 0.001002,
        "main_score": 2.3e-05,
        "hf_subset": "swe_Latn-jpn_Jpan",
        "languages": [
          "swe-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001502,
        "f1": 0.000752,
        "accuracy": 0.001502,
        "main_score": 0.000752,
        "hf_subset": "swe_Latn-kor_Hang",
        "languages": [
          "swe-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.023494,
        "recall": 0.034051,
        "f1": 0.024794,
        "accuracy": 0.034051,
        "main_score": 0.024794,
        "hf_subset": "swe_Latn-lit_Latn",
        "languages": [
          "swe-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.078862,
        "recall": 0.091137,
        "f1": 0.08097,
        "accuracy": 0.091137,
        "main_score": 0.08097,
        "hf_subset": "swe_Latn-ltz_Latn",
        "languages": [
          "swe-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.08365,
        "recall": 0.094141,
        "f1": 0.086041,
        "accuracy": 0.094141,
        "main_score": 0.086041,
        "hf_subset": "swe_Latn-nld_Latn",
        "languages": [
          "swe-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.41577,
        "recall": 0.481723,
        "f1": 0.432462,
        "accuracy": 0.481723,
        "main_score": 0.432462,
        "hf_subset": "swe_Latn-nno_Latn",
        "languages": [
          "swe-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.461719,
        "recall": 0.527792,
        "f1": 0.478098,
        "accuracy": 0.527792,
        "main_score": 0.478098,
        "hf_subset": "swe_Latn-nob_Latn",
        "languages": [
          "swe-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.019667,
        "recall": 0.025038,
        "f1": 0.020761,
        "accuracy": 0.025038,
        "main_score": 0.020761,
        "hf_subset": "swe_Latn-pol_Latn",
        "languages": [
          "swe-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.017081,
        "recall": 0.024036,
        "f1": 0.017853,
        "accuracy": 0.024036,
        "main_score": 0.017853,
        "hf_subset": "swe_Latn-por_Latn",
        "languages": [
          "swe-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000503,
        "accuracy": 0.001502,
        "main_score": 0.000503,
        "hf_subset": "swe_Latn-rus_Cyrl",
        "languages": [
          "swe-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.028236,
        "recall": 0.036555,
        "f1": 0.029529,
        "accuracy": 0.036555,
        "main_score": 0.029529,
        "hf_subset": "swe_Latn-spa_Latn",
        "languages": [
          "swe-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.005089,
        "recall": 0.007011,
        "f1": 0.005384,
        "accuracy": 0.007011,
        "main_score": 0.005384,
        "hf_subset": "swe_Latn-swa_Latn",
        "languages": [
          "swe-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000752,
        "recall": 0.002003,
        "f1": 0.000837,
        "accuracy": 0.002003,
        "main_score": 0.000837,
        "hf_subset": "swe_Latn-tam_Taml",
        "languages": [
          "swe-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009017,
        "recall": 0.011517,
        "f1": 0.009421,
        "accuracy": 0.011517,
        "main_score": 0.009421,
        "hf_subset": "swe_Latn-tur_Latn",
        "languages": [
          "swe-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.006861,
        "recall": 0.009514,
        "f1": 0.007404,
        "accuracy": 0.009514,
        "main_score": 0.007404,
        "hf_subset": "swe_Latn-vie_Latn",
        "languages": [
          "swe-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000183,
        "recall": 0.002504,
        "f1": 0.000283,
        "accuracy": 0.002504,
        "main_score": 0.000283,
        "hf_subset": "swe_Latn-zho_Hant",
        "languages": [
          "swe-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.019864,
        "recall": 0.029544,
        "f1": 0.021123,
        "accuracy": 0.029544,
        "main_score": 0.021123,
        "hf_subset": "swe_Latn-zul_Latn",
        "languages": [
          "swe-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.0105,
        "recall": 0.015523,
        "f1": 0.011114,
        "accuracy": 0.015523,
        "main_score": 0.011114,
        "hf_subset": "tah_Latn-eng_Latn",
        "languages": [
          "tah-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019003,
        "recall": 0.026039,
        "f1": 0.020146,
        "accuracy": 0.026039,
        "main_score": 0.020146,
        "hf_subset": "tah_Latn-fij_Latn",
        "languages": [
          "tah-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.007524,
        "recall": 0.01352,
        "f1": 0.008446,
        "accuracy": 0.01352,
        "main_score": 0.008446,
        "hf_subset": "tah_Latn-fil_Latn",
        "languages": [
          "tah-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.002778,
        "recall": 0.005008,
        "f1": 0.002883,
        "accuracy": 0.005008,
        "main_score": 0.002883,
        "hf_subset": "tah_Latn-ind_Latn",
        "languages": [
          "tah-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "tah_Latn-mal_Mlym",
        "languages": [
          "tah-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.013856,
        "recall": 0.021532,
        "f1": 0.01529,
        "accuracy": 0.021532,
        "main_score": 0.01529,
        "hf_subset": "tah_Latn-mlg_Latn",
        "languages": [
          "tah-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.019537,
        "recall": 0.031047,
        "f1": 0.021288,
        "accuracy": 0.031047,
        "main_score": 0.021288,
        "hf_subset": "tah_Latn-mri_Latn",
        "languages": [
          "tah-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.001679,
        "recall": 0.004507,
        "f1": 0.001999,
        "accuracy": 0.004507,
        "main_score": 0.001999,
        "hf_subset": "tah_Latn-msa_Latn",
        "languages": [
          "tah-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.051812,
        "recall": 0.067601,
        "f1": 0.055316,
        "accuracy": 0.067601,
        "main_score": 0.055316,
        "hf_subset": "tah_Latn-smo_Latn",
        "languages": [
          "tah-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.008593,
        "recall": 0.011517,
        "f1": 0.009159,
        "accuracy": 0.011517,
        "main_score": 0.009159,
        "hf_subset": "tah_Latn-ton_Latn",
        "languages": [
          "tah-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.030342,
        "recall": 0.051077,
        "f1": 0.03274,
        "accuracy": 0.051077,
        "main_score": 0.03274,
        "hf_subset": "tam_Taml-arb_Arab",
        "languages": [
          "tam-Taml",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.016621,
        "recall": 0.025538,
        "f1": 0.018203,
        "accuracy": 0.025538,
        "main_score": 0.018203,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.012664,
        "recall": 0.019529,
        "f1": 0.013786,
        "accuracy": 0.019529,
        "main_score": 0.013786,
        "hf_subset": "tam_Taml-deu_Latn",
        "languages": [
          "tam-Taml",
          "deu-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "tam_Taml-div_Thaa",
        "languages": [
          "tam-Taml",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.00152,
        "recall": 0.003505,
        "f1": 0.001538,
        "accuracy": 0.003505,
        "main_score": 0.001538,
        "hf_subset": "tam_Taml-ell_Grek",
        "languages": [
          "tam-Taml",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.024919,
        "recall": 0.038057,
        "f1": 0.026975,
        "accuracy": 0.038057,
        "main_score": 0.026975,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01138,
        "recall": 0.02003,
        "f1": 0.01251,
        "accuracy": 0.02003,
        "main_score": 0.01251,
        "hf_subset": "tam_Taml-eus_Latn",
        "languages": [
          "tam-Taml",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.001814,
        "recall": 0.005008,
        "f1": 0.002183,
        "accuracy": 0.005008,
        "main_score": 0.002183,
        "hf_subset": "tam_Taml-fas_Arab",
        "languages": [
          "tam-Taml",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.00384,
        "recall": 0.005508,
        "f1": 0.003994,
        "accuracy": 0.005508,
        "main_score": 0.003994,
        "hf_subset": "tam_Taml-fin_Latn",
        "languages": [
          "tam-Taml",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.035843,
        "recall": 0.055083,
        "f1": 0.038597,
        "accuracy": 0.055083,
        "main_score": 0.038597,
        "hf_subset": "tam_Taml-fra_Latn",
        "languages": [
          "tam-Taml",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.005377,
        "recall": 0.010015,
        "f1": 0.00602,
        "accuracy": 0.010015,
        "main_score": 0.00602,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000891,
        "recall": 0.004006,
        "f1": 0.001079,
        "accuracy": 0.004006,
        "main_score": 0.001079,
        "hf_subset": "tam_Taml-heb_Hebr",
        "languages": [
          "tam-Taml",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.045302,
        "recall": 0.068603,
        "f1": 0.049204,
        "accuracy": 0.068603,
        "main_score": 0.049204,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003153,
        "recall": 0.00651,
        "f1": 0.003524,
        "accuracy": 0.00651,
        "main_score": 0.003524,
        "hf_subset": "tam_Taml-hun_Latn",
        "languages": [
          "tam-Taml",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.021801,
        "recall": 0.035053,
        "f1": 0.023519,
        "accuracy": 0.035053,
        "main_score": 0.023519,
        "hf_subset": "tam_Taml-ind_Latn",
        "languages": [
          "tam-Taml",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.012355,
        "recall": 0.024036,
        "f1": 0.013521,
        "accuracy": 0.024036,
        "main_score": 0.013521,
        "hf_subset": "tam_Taml-jpn_Jpan",
        "languages": [
          "tam-Taml",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.014223,
        "recall": 0.017526,
        "f1": 0.014701,
        "accuracy": 0.017526,
        "main_score": 0.014701,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003976,
        "recall": 0.008513,
        "f1": 0.004297,
        "accuracy": 0.008513,
        "main_score": 0.004297,
        "hf_subset": "tam_Taml-kor_Hang",
        "languages": [
          "tam-Taml",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.003948,
        "recall": 0.010015,
        "f1": 0.004752,
        "accuracy": 0.010015,
        "main_score": 0.004752,
        "hf_subset": "tam_Taml-lit_Latn",
        "languages": [
          "tam-Taml",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.024969,
        "recall": 0.040561,
        "f1": 0.027212,
        "accuracy": 0.040561,
        "main_score": 0.027212,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.035465,
        "recall": 0.050576,
        "f1": 0.037572,
        "accuracy": 0.050576,
        "main_score": 0.037572,
        "hf_subset": "tam_Taml-nep_Deva",
        "languages": [
          "tam-Taml",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.011395,
        "recall": 0.017526,
        "f1": 0.012133,
        "accuracy": 0.017526,
        "main_score": 0.012133,
        "hf_subset": "tam_Taml-nld_Latn",
        "languages": [
          "tam-Taml",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.016681,
        "recall": 0.02654,
        "f1": 0.017847,
        "accuracy": 0.02654,
        "main_score": 0.017847,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.005877,
        "recall": 0.011517,
        "f1": 0.006495,
        "accuracy": 0.011517,
        "main_score": 0.006495,
        "hf_subset": "tam_Taml-pol_Latn",
        "languages": [
          "tam-Taml",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.039942,
        "recall": 0.068102,
        "f1": 0.04417,
        "accuracy": 0.068102,
        "main_score": 0.04417,
        "hf_subset": "tam_Taml-por_Latn",
        "languages": [
          "tam-Taml",
          "por-Latn"
        ]
      },
      {
        "precision": 0.013437,
        "recall": 0.019529,
        "f1": 0.014469,
        "accuracy": 0.019529,
        "main_score": 0.014469,
        "hf_subset": "tam_Taml-rus_Cyrl",
        "languages": [
          "tam-Taml",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.003317,
        "recall": 0.008012,
        "f1": 0.003777,
        "accuracy": 0.008012,
        "main_score": 0.003777,
        "hf_subset": "tam_Taml-sin_Sinh",
        "languages": [
          "tam-Taml",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.001509,
        "recall": 0.004507,
        "f1": 0.001756,
        "accuracy": 0.004507,
        "main_score": 0.001756,
        "hf_subset": "tam_Taml-snd_Arab",
        "languages": [
          "tam-Taml",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.026559,
        "recall": 0.039059,
        "f1": 0.02844,
        "accuracy": 0.039059,
        "main_score": 0.02844,
        "hf_subset": "tam_Taml-spa_Latn",
        "languages": [
          "tam-Taml",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.016707,
        "recall": 0.028543,
        "f1": 0.018394,
        "accuracy": 0.028543,
        "main_score": 0.018394,
        "hf_subset": "tam_Taml-swa_Latn",
        "languages": [
          "tam-Taml",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.008211,
        "recall": 0.014522,
        "f1": 0.008979,
        "accuracy": 0.014522,
        "main_score": 0.008979,
        "hf_subset": "tam_Taml-swe_Latn",
        "languages": [
          "tam-Taml",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.011255,
        "recall": 0.018027,
        "f1": 0.01246,
        "accuracy": 0.018027,
        "main_score": 0.01246,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007008,
        "recall": 0.012018,
        "f1": 0.007674,
        "accuracy": 0.012018,
        "main_score": 0.007674,
        "hf_subset": "tam_Taml-tur_Latn",
        "languages": [
          "tam-Taml",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.008372,
        "recall": 0.018027,
        "f1": 0.00915,
        "accuracy": 0.018027,
        "main_score": 0.00915,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.015667,
        "recall": 0.023535,
        "f1": 0.017011,
        "accuracy": 0.023535,
        "main_score": 0.017011,
        "hf_subset": "tam_Taml-vie_Latn",
        "languages": [
          "tam-Taml",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.023065,
        "recall": 0.034552,
        "f1": 0.024823,
        "accuracy": 0.034552,
        "main_score": 0.024823,
        "hf_subset": "tam_Taml-zho_Hant",
        "languages": [
          "tam-Taml",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.003093,
        "recall": 0.006009,
        "f1": 0.003175,
        "accuracy": 0.006009,
        "main_score": 0.003175,
        "hf_subset": "tam_Taml-zul_Latn",
        "languages": [
          "tam-Taml",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.010365,
        "recall": 0.01302,
        "f1": 0.010528,
        "accuracy": 0.01302,
        "main_score": 0.010528,
        "hf_subset": "tat_Cyrl-aze_Latn",
        "languages": [
          "tat-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.251491,
        "recall": 0.329494,
        "f1": 0.26963,
        "accuracy": 0.329494,
        "main_score": 0.26963,
        "hf_subset": "tat_Cyrl-bak_Cyrl",
        "languages": [
          "tat-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.002527,
        "recall": 0.005008,
        "f1": 0.002778,
        "accuracy": 0.005008,
        "main_score": 0.002778,
        "hf_subset": "tat_Cyrl-eng_Latn",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.120653,
        "recall": 0.16675,
        "f1": 0.130144,
        "accuracy": 0.16675,
        "main_score": 0.130144,
        "hf_subset": "tat_Cyrl-kaz_Cyrl",
        "languages": [
          "tat-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.189102,
        "recall": 0.238358,
        "f1": 0.201455,
        "accuracy": 0.238358,
        "main_score": 0.201455,
        "hf_subset": "tat_Cyrl-kir_Cyrl",
        "languages": [
          "tat-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.004597,
        "recall": 0.007511,
        "f1": 0.004902,
        "accuracy": 0.007511,
        "main_score": 0.004902,
        "hf_subset": "tat_Cyrl-tuk_Latn",
        "languages": [
          "tat-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.007709,
        "recall": 0.011517,
        "f1": 0.008037,
        "accuracy": 0.011517,
        "main_score": 0.008037,
        "hf_subset": "tat_Cyrl-tur_Latn",
        "languages": [
          "tat-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000257,
        "recall": 0.001502,
        "f1": 0.000348,
        "accuracy": 0.001502,
        "main_score": 0.000348,
        "hf_subset": "tat_Cyrl-uig_Arab",
        "languages": [
          "tat-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.002715,
        "recall": 0.005008,
        "f1": 0.003043,
        "accuracy": 0.005008,
        "main_score": 0.003043,
        "hf_subset": "tat_Cyrl-uzb_Latn",
        "languages": [
          "tat-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.057558,
        "recall": 0.078117,
        "f1": 0.061084,
        "accuracy": 0.078117,
        "main_score": 0.061084,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 2e-05,
        "recall": 0.001502,
        "f1": 3.8e-05,
        "accuracy": 0.001502,
        "main_score": 3.8e-05,
        "hf_subset": "tel_Telu-div_Thaa",
        "languages": [
          "tel-Telu",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.016692,
        "recall": 0.023035,
        "f1": 0.017503,
        "accuracy": 0.023035,
        "main_score": 0.017503,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006552,
        "recall": 0.011517,
        "f1": 0.006894,
        "accuracy": 0.011517,
        "main_score": 0.006894,
        "hf_subset": "tel_Telu-eus_Latn",
        "languages": [
          "tel-Telu",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.022408,
        "recall": 0.038057,
        "f1": 0.024309,
        "accuracy": 0.038057,
        "main_score": 0.024309,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.071542,
        "recall": 0.102654,
        "f1": 0.076412,
        "accuracy": 0.102654,
        "main_score": 0.076412,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.067751,
        "recall": 0.095143,
        "f1": 0.072882,
        "accuracy": 0.095143,
        "main_score": 0.072882,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.04817,
        "recall": 0.068102,
        "f1": 0.051309,
        "accuracy": 0.068102,
        "main_score": 0.051309,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.053243,
        "recall": 0.075113,
        "f1": 0.05683,
        "accuracy": 0.075113,
        "main_score": 0.05683,
        "hf_subset": "tel_Telu-nep_Deva",
        "languages": [
          "tel-Telu",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.036902,
        "recall": 0.062093,
        "f1": 0.040263,
        "accuracy": 0.062093,
        "main_score": 0.040263,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001142,
        "recall": 0.004507,
        "f1": 0.001261,
        "accuracy": 0.004507,
        "main_score": 0.001261,
        "hf_subset": "tel_Telu-sin_Sinh",
        "languages": [
          "tel-Telu",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.002692,
        "recall": 0.005508,
        "f1": 0.002796,
        "accuracy": 0.005508,
        "main_score": 0.002796,
        "hf_subset": "tel_Telu-snd_Arab",
        "languages": [
          "tel-Telu",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.02383,
        "recall": 0.038057,
        "f1": 0.026103,
        "accuracy": 0.038057,
        "main_score": 0.026103,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.026247,
        "recall": 0.045568,
        "f1": 0.02847,
        "accuracy": 0.045568,
        "main_score": 0.02847,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002003,
        "f1": 0.001006,
        "accuracy": 0.002003,
        "main_score": 0.001006,
        "hf_subset": "tgk_Cyrl-arb_Arab",
        "languages": [
          "tgk-Cyrl",
          "arb-Arab"
        ]
      },
      {
        "precision": 8.2e-05,
        "recall": 0.002003,
        "f1": 0.00015,
        "accuracy": 0.002003,
        "main_score": 0.00015,
        "hf_subset": "tgk_Cyrl-ckb_Arab",
        "languages": [
          "tgk-Cyrl",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.001373,
        "recall": 0.005008,
        "f1": 0.001615,
        "accuracy": 0.005008,
        "main_score": 0.001615,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.001502,
        "f1": 3.4e-05,
        "accuracy": 0.001502,
        "main_score": 3.4e-05,
        "hf_subset": "tgk_Cyrl-fas_Arab",
        "languages": [
          "tgk-Cyrl",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000293,
        "recall": 0.002504,
        "f1": 0.000413,
        "accuracy": 0.002504,
        "main_score": 0.000413,
        "hf_subset": "tgk_Cyrl-heb_Hebr",
        "languages": [
          "tgk-Cyrl",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000939,
        "recall": 0.003005,
        "f1": 0.001126,
        "accuracy": 0.003005,
        "main_score": 0.001126,
        "hf_subset": "tgk_Cyrl-kmr_Latn",
        "languages": [
          "tgk-Cyrl",
          "kmr-Latn"
        ]
      },
      {
        "precision": 9.6e-05,
        "recall": 0.002504,
        "f1": 0.00018,
        "accuracy": 0.002504,
        "main_score": 0.00018,
        "hf_subset": "tgk_Cyrl-mey_Arab",
        "languages": [
          "tgk-Cyrl",
          "mey-Arab"
        ]
      },
      {
        "precision": 5.1e-05,
        "recall": 0.001502,
        "f1": 9.5e-05,
        "accuracy": 0.001502,
        "main_score": 9.5e-05,
        "hf_subset": "tgk_Cyrl-prs_Arab",
        "languages": [
          "tgk-Cyrl",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.00078,
        "recall": 0.002504,
        "f1": 0.00089,
        "accuracy": 0.002504,
        "main_score": 0.00089,
        "hf_subset": "tgk_Cyrl-pus_Arab",
        "languages": [
          "tgk-Cyrl",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.001508,
        "recall": 0.002504,
        "f1": 0.001514,
        "accuracy": 0.002504,
        "main_score": 0.001514,
        "hf_subset": "tgk_Cyrl-shi_Arab",
        "languages": [
          "tgk-Cyrl",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.009978,
        "recall": 0.01352,
        "f1": 0.010601,
        "accuracy": 0.01352,
        "main_score": 0.010601,
        "hf_subset": "tha_Thai-bod_Tibt",
        "languages": [
          "tha-Thai",
          "bod-Tibt"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "tha_Thai-dzo_Tibt",
        "languages": [
          "tha-Thai",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.01497,
        "recall": 0.021032,
        "f1": 0.015932,
        "accuracy": 0.021032,
        "main_score": 0.015932,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012286,
        "recall": 0.018528,
        "f1": 0.013567,
        "accuracy": 0.018528,
        "main_score": 0.013567,
        "hf_subset": "tha_Thai-khm_Khmr",
        "languages": [
          "tha-Thai",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.031376,
        "recall": 0.039559,
        "f1": 0.033151,
        "accuracy": 0.039559,
        "main_score": 0.033151,
        "hf_subset": "tha_Thai-lao_Laoo",
        "languages": [
          "tha-Thai",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.00098,
        "recall": 0.004006,
        "f1": 0.001257,
        "accuracy": 0.004006,
        "main_score": 0.001257,
        "hf_subset": "tha_Thai-mon_Mong",
        "languages": [
          "tha-Thai",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.012138,
        "recall": 0.019029,
        "f1": 0.013226,
        "accuracy": 0.019029,
        "main_score": 0.013226,
        "hf_subset": "tha_Thai-mya_Mymr",
        "languages": [
          "tha-Thai",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.07126,
        "recall": 0.107161,
        "f1": 0.079099,
        "accuracy": 0.107161,
        "main_score": 0.079099,
        "hf_subset": "tir_Ethi-amh_Ethi",
        "languages": [
          "tir-Ethi",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001502,
        "f1": 0.000752,
        "accuracy": 0.001502,
        "main_score": 0.000752,
        "hf_subset": "tir_Ethi-eng_Latn",
        "languages": [
          "tir-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00162,
        "recall": 0.003005,
        "f1": 0.001704,
        "accuracy": 0.003005,
        "main_score": 0.001704,
        "hf_subset": "tir_Ethi-hau_Latn",
        "languages": [
          "tir-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.001041,
        "recall": 0.002003,
        "f1": 0.001074,
        "accuracy": 0.002003,
        "main_score": 0.001074,
        "hf_subset": "tir_Ethi-ibo_Latn",
        "languages": [
          "tir-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.002576,
        "recall": 0.003505,
        "f1": 0.00263,
        "accuracy": 0.003505,
        "main_score": 0.00263,
        "hf_subset": "tir_Ethi-nso_Latn",
        "languages": [
          "tir-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.000267,
        "recall": 0.001502,
        "f1": 0.000367,
        "accuracy": 0.001502,
        "main_score": 0.000367,
        "hf_subset": "tir_Ethi-orm_Ethi",
        "languages": [
          "tir-Ethi",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.001603,
        "recall": 0.002504,
        "f1": 0.00167,
        "accuracy": 0.002504,
        "main_score": 0.00167,
        "hf_subset": "tir_Ethi-som_Latn",
        "languages": [
          "tir-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.002221,
        "recall": 0.005008,
        "f1": 0.002393,
        "accuracy": 0.005008,
        "main_score": 0.002393,
        "hf_subset": "tir_Ethi-ssw_Latn",
        "languages": [
          "tir-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.000538,
        "recall": 0.002504,
        "f1": 0.000574,
        "accuracy": 0.002504,
        "main_score": 0.000574,
        "hf_subset": "tir_Ethi-swa_Latn",
        "languages": [
          "tir-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.002462,
        "recall": 0.004507,
        "f1": 0.002665,
        "accuracy": 0.004507,
        "main_score": 0.002665,
        "hf_subset": "tir_Ethi-tsn_Latn",
        "languages": [
          "tir-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.000206,
        "recall": 0.002504,
        "f1": 0.000346,
        "accuracy": 0.002504,
        "main_score": 0.000346,
        "hf_subset": "tir_Ethi-wol_Latn",
        "languages": [
          "tir-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.001837,
        "recall": 0.004507,
        "f1": 0.002037,
        "accuracy": 0.004507,
        "main_score": 0.002037,
        "hf_subset": "tir_Ethi-xho_Latn",
        "languages": [
          "tir-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.001574,
        "recall": 0.002504,
        "f1": 0.001629,
        "accuracy": 0.002504,
        "main_score": 0.001629,
        "hf_subset": "tir_Ethi-yor_Latn",
        "languages": [
          "tir-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.002008,
        "recall": 0.002504,
        "f1": 0.002013,
        "accuracy": 0.002504,
        "main_score": 0.002013,
        "hf_subset": "tir_Ethi-zul_Latn",
        "languages": [
          "tir-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.00765,
        "recall": 0.010516,
        "f1": 0.008072,
        "accuracy": 0.010516,
        "main_score": 0.008072,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012197,
        "recall": 0.016525,
        "f1": 0.012864,
        "accuracy": 0.016525,
        "main_score": 0.012864,
        "hf_subset": "ton_Latn-fij_Latn",
        "languages": [
          "ton-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.013645,
        "recall": 0.017526,
        "f1": 0.014147,
        "accuracy": 0.017526,
        "main_score": 0.014147,
        "hf_subset": "ton_Latn-fil_Latn",
        "languages": [
          "ton-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.002598,
        "recall": 0.005008,
        "f1": 0.002835,
        "accuracy": 0.005008,
        "main_score": 0.002835,
        "hf_subset": "ton_Latn-ind_Latn",
        "languages": [
          "ton-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.001002,
        "f1": 2.6e-05,
        "accuracy": 0.001002,
        "main_score": 2.6e-05,
        "hf_subset": "ton_Latn-mal_Mlym",
        "languages": [
          "ton-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.017919,
        "recall": 0.021032,
        "f1": 0.018428,
        "accuracy": 0.021032,
        "main_score": 0.018428,
        "hf_subset": "ton_Latn-mlg_Latn",
        "languages": [
          "ton-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.055135,
        "recall": 0.069604,
        "f1": 0.058114,
        "accuracy": 0.069604,
        "main_score": 0.058114,
        "hf_subset": "ton_Latn-mri_Latn",
        "languages": [
          "ton-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.002388,
        "recall": 0.004507,
        "f1": 0.00257,
        "accuracy": 0.004507,
        "main_score": 0.00257,
        "hf_subset": "ton_Latn-msa_Latn",
        "languages": [
          "ton-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.013312,
        "recall": 0.019029,
        "f1": 0.014093,
        "accuracy": 0.019029,
        "main_score": 0.014093,
        "hf_subset": "ton_Latn-smo_Latn",
        "languages": [
          "ton-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.009426,
        "recall": 0.01352,
        "f1": 0.010031,
        "accuracy": 0.01352,
        "main_score": 0.010031,
        "hf_subset": "ton_Latn-tah_Latn",
        "languages": [
          "ton-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.001824,
        "recall": 0.004006,
        "f1": 0.002009,
        "accuracy": 0.004006,
        "main_score": 0.002009,
        "hf_subset": "tsn_Latn-amh_Ethi",
        "languages": [
          "tsn-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.027974,
        "recall": 0.038558,
        "f1": 0.029617,
        "accuracy": 0.038558,
        "main_score": 0.029617,
        "hf_subset": "tsn_Latn-eng_Latn",
        "languages": [
          "tsn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.063647,
        "recall": 0.083125,
        "f1": 0.067551,
        "accuracy": 0.083125,
        "main_score": 0.067551,
        "hf_subset": "tsn_Latn-hau_Latn",
        "languages": [
          "tsn-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.010459,
        "recall": 0.017526,
        "f1": 0.011484,
        "accuracy": 0.017526,
        "main_score": 0.011484,
        "hf_subset": "tsn_Latn-ibo_Latn",
        "languages": [
          "tsn-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.264731,
        "recall": 0.321983,
        "f1": 0.279423,
        "accuracy": 0.321983,
        "main_score": 0.279423,
        "hf_subset": "tsn_Latn-nso_Latn",
        "languages": [
          "tsn-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.028591,
        "recall": 0.039559,
        "f1": 0.030728,
        "accuracy": 0.039559,
        "main_score": 0.030728,
        "hf_subset": "tsn_Latn-orm_Ethi",
        "languages": [
          "tsn-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.068579,
        "recall": 0.084627,
        "f1": 0.071791,
        "accuracy": 0.084627,
        "main_score": 0.071791,
        "hf_subset": "tsn_Latn-som_Latn",
        "languages": [
          "tsn-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.052635,
        "recall": 0.071107,
        "f1": 0.056338,
        "accuracy": 0.071107,
        "main_score": 0.056338,
        "hf_subset": "tsn_Latn-ssw_Latn",
        "languages": [
          "tsn-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.007965,
        "recall": 0.010516,
        "f1": 0.008527,
        "accuracy": 0.010516,
        "main_score": 0.008527,
        "hf_subset": "tsn_Latn-swa_Latn",
        "languages": [
          "tsn-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "tsn_Latn-tir_Ethi",
        "languages": [
          "tsn-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.051531,
        "recall": 0.066099,
        "f1": 0.05418,
        "accuracy": 0.066099,
        "main_score": 0.05418,
        "hf_subset": "tsn_Latn-wol_Latn",
        "languages": [
          "tsn-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.031306,
        "recall": 0.045068,
        "f1": 0.033558,
        "accuracy": 0.045068,
        "main_score": 0.033558,
        "hf_subset": "tsn_Latn-xho_Latn",
        "languages": [
          "tsn-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.009183,
        "recall": 0.014522,
        "f1": 0.01024,
        "accuracy": 0.014522,
        "main_score": 0.01024,
        "hf_subset": "tsn_Latn-yor_Latn",
        "languages": [
          "tsn-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.034102,
        "recall": 0.04657,
        "f1": 0.036325,
        "accuracy": 0.04657,
        "main_score": 0.036325,
        "hf_subset": "tsn_Latn-zul_Latn",
        "languages": [
          "tsn-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.062416,
        "recall": 0.082624,
        "f1": 0.066194,
        "accuracy": 0.082624,
        "main_score": 0.066194,
        "hf_subset": "tuk_Latn-aze_Latn",
        "languages": [
          "tuk-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.00084,
        "recall": 0.004006,
        "f1": 0.001003,
        "accuracy": 0.004006,
        "main_score": 0.001003,
        "hf_subset": "tuk_Latn-bak_Cyrl",
        "languages": [
          "tuk-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.009653,
        "recall": 0.01302,
        "f1": 0.01012,
        "accuracy": 0.01302,
        "main_score": 0.01012,
        "hf_subset": "tuk_Latn-eng_Latn",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001013,
        "recall": 0.004507,
        "f1": 0.001263,
        "accuracy": 0.004507,
        "main_score": 0.001263,
        "hf_subset": "tuk_Latn-kaz_Cyrl",
        "languages": [
          "tuk-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.001722,
        "recall": 0.005508,
        "f1": 0.00189,
        "accuracy": 0.005508,
        "main_score": 0.00189,
        "hf_subset": "tuk_Latn-kir_Cyrl",
        "languages": [
          "tuk-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.000769,
        "recall": 0.003505,
        "f1": 0.00087,
        "accuracy": 0.003505,
        "main_score": 0.00087,
        "hf_subset": "tuk_Latn-tat_Cyrl",
        "languages": [
          "tuk-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.120435,
        "recall": 0.147221,
        "f1": 0.126091,
        "accuracy": 0.147221,
        "main_score": 0.126091,
        "hf_subset": "tuk_Latn-tur_Latn",
        "languages": [
          "tuk-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000685,
        "recall": 0.002003,
        "f1": 0.000811,
        "accuracy": 0.002003,
        "main_score": 0.000811,
        "hf_subset": "tuk_Latn-uig_Arab",
        "languages": [
          "tuk-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.025972,
        "recall": 0.038558,
        "f1": 0.027993,
        "accuracy": 0.038558,
        "main_score": 0.027993,
        "hf_subset": "tuk_Latn-uzb_Latn",
        "languages": [
          "tuk-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "tur_Latn-arb_Arab",
        "languages": [
          "tur-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.104905,
        "recall": 0.13971,
        "f1": 0.111957,
        "accuracy": 0.13971,
        "main_score": 0.111957,
        "hf_subset": "tur_Latn-aze_Latn",
        "languages": [
          "tur-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.001073,
        "recall": 0.005008,
        "f1": 0.001383,
        "accuracy": 0.005008,
        "main_score": 0.001383,
        "hf_subset": "tur_Latn-bak_Cyrl",
        "languages": [
          "tur-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.000559,
        "recall": 0.002003,
        "f1": 0.000607,
        "accuracy": 0.002003,
        "main_score": 0.000607,
        "hf_subset": "tur_Latn-ben_Beng",
        "languages": [
          "tur-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.032381,
        "recall": 0.040561,
        "f1": 0.033982,
        "accuracy": 0.040561,
        "main_score": 0.033982,
        "hf_subset": "tur_Latn-deu_Latn",
        "languages": [
          "tur-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001515,
        "recall": 0.003505,
        "f1": 0.001527,
        "accuracy": 0.003505,
        "main_score": 0.001527,
        "hf_subset": "tur_Latn-ell_Grek",
        "languages": [
          "tur-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.015407,
        "recall": 0.02003,
        "f1": 0.016315,
        "accuracy": 0.02003,
        "main_score": 0.016315,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "tur_Latn-fas_Arab",
        "languages": [
          "tur-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.023991,
        "recall": 0.028042,
        "f1": 0.024913,
        "accuracy": 0.028042,
        "main_score": 0.024913,
        "hf_subset": "tur_Latn-fin_Latn",
        "languages": [
          "tur-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.01593,
        "recall": 0.023035,
        "f1": 0.017082,
        "accuracy": 0.023035,
        "main_score": 0.017082,
        "hf_subset": "tur_Latn-fra_Latn",
        "languages": [
          "tur-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000261,
        "recall": 0.002003,
        "f1": 0.000356,
        "accuracy": 0.002003,
        "main_score": 0.000356,
        "hf_subset": "tur_Latn-heb_Hebr",
        "languages": [
          "tur-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000289,
        "recall": 0.003005,
        "f1": 0.00047,
        "accuracy": 0.003005,
        "main_score": 0.00047,
        "hf_subset": "tur_Latn-hin_Deva",
        "languages": [
          "tur-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.028406,
        "recall": 0.035553,
        "f1": 0.029769,
        "accuracy": 0.035553,
        "main_score": 0.029769,
        "hf_subset": "tur_Latn-hun_Latn",
        "languages": [
          "tur-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.006159,
        "recall": 0.011517,
        "f1": 0.006919,
        "accuracy": 0.011517,
        "main_score": 0.006919,
        "hf_subset": "tur_Latn-ind_Latn",
        "languages": [
          "tur-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001172,
        "recall": 0.002504,
        "f1": 0.00126,
        "accuracy": 0.002504,
        "main_score": 0.00126,
        "hf_subset": "tur_Latn-jpn_Jpan",
        "languages": [
          "tur-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00205,
        "recall": 0.007011,
        "f1": 0.002496,
        "accuracy": 0.007011,
        "main_score": 0.002496,
        "hf_subset": "tur_Latn-kaz_Cyrl",
        "languages": [
          "tur-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.001241,
        "recall": 0.004507,
        "f1": 0.001421,
        "accuracy": 0.004507,
        "main_score": 0.001421,
        "hf_subset": "tur_Latn-kir_Cyrl",
        "languages": [
          "tur-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001018,
        "recall": 0.003005,
        "f1": 0.001033,
        "accuracy": 0.003005,
        "main_score": 0.001033,
        "hf_subset": "tur_Latn-kor_Hang",
        "languages": [
          "tur-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.022702,
        "recall": 0.028042,
        "f1": 0.023773,
        "accuracy": 0.028042,
        "main_score": 0.023773,
        "hf_subset": "tur_Latn-lit_Latn",
        "languages": [
          "tur-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.035499,
        "recall": 0.043065,
        "f1": 0.036741,
        "accuracy": 0.043065,
        "main_score": 0.036741,
        "hf_subset": "tur_Latn-nld_Latn",
        "languages": [
          "tur-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.02471,
        "recall": 0.037556,
        "f1": 0.026813,
        "accuracy": 0.037556,
        "main_score": 0.026813,
        "hf_subset": "tur_Latn-pol_Latn",
        "languages": [
          "tur-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.011524,
        "recall": 0.017026,
        "f1": 0.012249,
        "accuracy": 0.017026,
        "main_score": 0.012249,
        "hf_subset": "tur_Latn-por_Latn",
        "languages": [
          "tur-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001192,
        "recall": 0.003005,
        "f1": 0.001297,
        "accuracy": 0.003005,
        "main_score": 0.001297,
        "hf_subset": "tur_Latn-rus_Cyrl",
        "languages": [
          "tur-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.015139,
        "recall": 0.021032,
        "f1": 0.016224,
        "accuracy": 0.021032,
        "main_score": 0.016224,
        "hf_subset": "tur_Latn-spa_Latn",
        "languages": [
          "tur-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.007766,
        "recall": 0.011017,
        "f1": 0.008463,
        "accuracy": 0.011017,
        "main_score": 0.008463,
        "hf_subset": "tur_Latn-swa_Latn",
        "languages": [
          "tur-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.03305,
        "recall": 0.036555,
        "f1": 0.033944,
        "accuracy": 0.036555,
        "main_score": 0.033944,
        "hf_subset": "tur_Latn-swe_Latn",
        "languages": [
          "tur-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.0002,
        "recall": 0.002003,
        "f1": 0.000342,
        "accuracy": 0.002003,
        "main_score": 0.000342,
        "hf_subset": "tur_Latn-tam_Taml",
        "languages": [
          "tur-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001769,
        "recall": 0.006009,
        "f1": 0.002107,
        "accuracy": 0.006009,
        "main_score": 0.002107,
        "hf_subset": "tur_Latn-tat_Cyrl",
        "languages": [
          "tur-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.103767,
        "recall": 0.14021,
        "f1": 0.111539,
        "accuracy": 0.14021,
        "main_score": 0.111539,
        "hf_subset": "tur_Latn-tuk_Latn",
        "languages": [
          "tur-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.00039,
        "recall": 0.002504,
        "f1": 0.000585,
        "accuracy": 0.002504,
        "main_score": 0.000585,
        "hf_subset": "tur_Latn-uig_Arab",
        "languages": [
          "tur-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.01497,
        "recall": 0.021532,
        "f1": 0.015937,
        "accuracy": 0.021532,
        "main_score": 0.015937,
        "hf_subset": "tur_Latn-uzb_Latn",
        "languages": [
          "tur-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.007225,
        "recall": 0.011517,
        "f1": 0.007621,
        "accuracy": 0.011517,
        "main_score": 0.007621,
        "hf_subset": "tur_Latn-vie_Latn",
        "languages": [
          "tur-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000486,
        "recall": 0.003005,
        "f1": 0.000753,
        "accuracy": 0.003005,
        "main_score": 0.000753,
        "hf_subset": "tur_Latn-zho_Hant",
        "languages": [
          "tur-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.012331,
        "recall": 0.016024,
        "f1": 0.012952,
        "accuracy": 0.016024,
        "main_score": 0.012952,
        "hf_subset": "tur_Latn-zul_Latn",
        "languages": [
          "tur-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000676,
        "recall": 0.002504,
        "f1": 0.000767,
        "accuracy": 0.002504,
        "main_score": 0.000767,
        "hf_subset": "uig_Arab-aze_Latn",
        "languages": [
          "uig-Arab",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.001671,
        "recall": 0.002504,
        "f1": 0.001756,
        "accuracy": 0.002504,
        "main_score": 0.001756,
        "hf_subset": "uig_Arab-bak_Cyrl",
        "languages": [
          "uig-Arab",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.001502,
        "f1": 2.2e-05,
        "accuracy": 0.001502,
        "main_score": 2.2e-05,
        "hf_subset": "uig_Arab-eng_Latn",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000519,
        "recall": 0.002003,
        "f1": 0.000537,
        "accuracy": 0.002003,
        "main_score": 0.000537,
        "hf_subset": "uig_Arab-kaz_Cyrl",
        "languages": [
          "uig-Arab",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001002,
        "f1": 1e-05,
        "accuracy": 0.001002,
        "main_score": 1e-05,
        "hf_subset": "uig_Arab-kir_Cyrl",
        "languages": [
          "uig-Arab",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001028,
        "recall": 0.002504,
        "f1": 0.001053,
        "accuracy": 0.002504,
        "main_score": 0.001053,
        "hf_subset": "uig_Arab-tat_Cyrl",
        "languages": [
          "uig-Arab",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.000501,
        "f1": 3.2e-05,
        "accuracy": 0.000501,
        "main_score": 3.2e-05,
        "hf_subset": "uig_Arab-tuk_Latn",
        "languages": [
          "uig-Arab",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.000691,
        "recall": 0.002504,
        "f1": 0.000797,
        "accuracy": 0.002504,
        "main_score": 0.000797,
        "hf_subset": "uig_Arab-tur_Latn",
        "languages": [
          "uig-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001502,
        "f1": 1e-05,
        "accuracy": 0.001502,
        "main_score": 1e-05,
        "hf_subset": "uig_Arab-uzb_Latn",
        "languages": [
          "uig-Arab",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.216904,
        "recall": 0.278918,
        "f1": 0.230152,
        "accuracy": 0.278918,
        "main_score": 0.230152,
        "hf_subset": "ukr_Cyrl-bel_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.010233,
        "recall": 0.018528,
        "f1": 0.011073,
        "accuracy": 0.018528,
        "main_score": 0.011073,
        "hf_subset": "ukr_Cyrl-bos_Latn",
        "languages": [
          "ukr-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.135857,
        "recall": 0.174762,
        "f1": 0.143095,
        "accuracy": 0.174762,
        "main_score": 0.143095,
        "hf_subset": "ukr_Cyrl-bul_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.012378,
        "recall": 0.017026,
        "f1": 0.013214,
        "accuracy": 0.017026,
        "main_score": 0.013214,
        "hf_subset": "ukr_Cyrl-ces_Latn",
        "languages": [
          "ukr-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.007972,
        "recall": 0.014522,
        "f1": 0.008633,
        "accuracy": 0.014522,
        "main_score": 0.008633,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012085,
        "recall": 0.018027,
        "f1": 0.012818,
        "accuracy": 0.018027,
        "main_score": 0.012818,
        "hf_subset": "ukr_Cyrl-hrv_Latn",
        "languages": [
          "ukr-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.086759,
        "recall": 0.114672,
        "f1": 0.092564,
        "accuracy": 0.114672,
        "main_score": 0.092564,
        "hf_subset": "ukr_Cyrl-mkd_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.01219,
        "recall": 0.019529,
        "f1": 0.012929,
        "accuracy": 0.019529,
        "main_score": 0.012929,
        "hf_subset": "ukr_Cyrl-pol_Latn",
        "languages": [
          "ukr-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.138476,
        "recall": 0.17977,
        "f1": 0.1465,
        "accuracy": 0.17977,
        "main_score": 0.1465,
        "hf_subset": "ukr_Cyrl-rus_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.01035,
        "recall": 0.017026,
        "f1": 0.011261,
        "accuracy": 0.017026,
        "main_score": 0.011261,
        "hf_subset": "ukr_Cyrl-slk_Latn",
        "languages": [
          "ukr-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.011094,
        "recall": 0.016024,
        "f1": 0.011871,
        "accuracy": 0.016024,
        "main_score": 0.011871,
        "hf_subset": "ukr_Cyrl-slv_Latn",
        "languages": [
          "ukr-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.050517,
        "recall": 0.076114,
        "f1": 0.055019,
        "accuracy": 0.076114,
        "main_score": 0.055019,
        "hf_subset": "ukr_Cyrl-srp_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.014798,
        "recall": 0.021532,
        "f1": 0.015821,
        "accuracy": 0.021532,
        "main_score": 0.015821,
        "hf_subset": "ukr_Cyrl-srp_Latn",
        "languages": [
          "ukr-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.03533,
        "recall": 0.052078,
        "f1": 0.038306,
        "accuracy": 0.052078,
        "main_score": 0.038306,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000646,
        "recall": 0.002504,
        "f1": 0.000761,
        "accuracy": 0.002504,
        "main_score": 0.000761,
        "hf_subset": "urd_Arab-div_Thaa",
        "languages": [
          "urd-Arab",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.020514,
        "recall": 0.028543,
        "f1": 0.021758,
        "accuracy": 0.028543,
        "main_score": 0.021758,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009272,
        "recall": 0.01352,
        "f1": 0.009699,
        "accuracy": 0.01352,
        "main_score": 0.009699,
        "hf_subset": "urd_Arab-eus_Latn",
        "languages": [
          "urd-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.017069,
        "recall": 0.02654,
        "f1": 0.018269,
        "accuracy": 0.02654,
        "main_score": 0.018269,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.083304,
        "recall": 0.109664,
        "f1": 0.088289,
        "accuracy": 0.109664,
        "main_score": 0.088289,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018351,
        "recall": 0.027041,
        "f1": 0.019845,
        "accuracy": 0.027041,
        "main_score": 0.019845,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.014085,
        "recall": 0.022534,
        "f1": 0.015046,
        "accuracy": 0.022534,
        "main_score": 0.015046,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.030523,
        "recall": 0.041562,
        "f1": 0.032464,
        "accuracy": 0.041562,
        "main_score": 0.032464,
        "hf_subset": "urd_Arab-nep_Deva",
        "languages": [
          "urd-Arab",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.01651,
        "recall": 0.024036,
        "f1": 0.017434,
        "accuracy": 0.024036,
        "main_score": 0.017434,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000599,
        "recall": 0.003505,
        "f1": 0.000852,
        "accuracy": 0.003505,
        "main_score": 0.000852,
        "hf_subset": "urd_Arab-sin_Sinh",
        "languages": [
          "urd-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000508,
        "recall": 0.002003,
        "f1": 0.000515,
        "accuracy": 0.002003,
        "main_score": 0.000515,
        "hf_subset": "urd_Arab-snd_Arab",
        "languages": [
          "urd-Arab",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.017676,
        "recall": 0.028543,
        "f1": 0.019138,
        "accuracy": 0.028543,
        "main_score": 0.019138,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.021726,
        "recall": 0.035053,
        "f1": 0.023243,
        "accuracy": 0.035053,
        "main_score": 0.023243,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009489,
        "recall": 0.017026,
        "f1": 0.010298,
        "accuracy": 0.017026,
        "main_score": 0.010298,
        "hf_subset": "uzb_Latn-aze_Latn",
        "languages": [
          "uzb-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.001174,
        "recall": 0.002504,
        "f1": 0.001263,
        "accuracy": 0.002504,
        "main_score": 0.001263,
        "hf_subset": "uzb_Latn-bak_Cyrl",
        "languages": [
          "uzb-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.007033,
        "recall": 0.010015,
        "f1": 0.007323,
        "accuracy": 0.010015,
        "main_score": 0.007323,
        "hf_subset": "uzb_Latn-eng_Latn",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000761,
        "recall": 0.003005,
        "f1": 0.000855,
        "accuracy": 0.003005,
        "main_score": 0.000855,
        "hf_subset": "uzb_Latn-kaz_Cyrl",
        "languages": [
          "uzb-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.000525,
        "recall": 0.002003,
        "f1": 0.000547,
        "accuracy": 0.002003,
        "main_score": 0.000547,
        "hf_subset": "uzb_Latn-kir_Cyrl",
        "languages": [
          "uzb-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "uzb_Latn-tat_Cyrl",
        "languages": [
          "uzb-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.020595,
        "recall": 0.029044,
        "f1": 0.021817,
        "accuracy": 0.029044,
        "main_score": 0.021817,
        "hf_subset": "uzb_Latn-tuk_Latn",
        "languages": [
          "uzb-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.010042,
        "recall": 0.014021,
        "f1": 0.010508,
        "accuracy": 0.014021,
        "main_score": 0.010508,
        "hf_subset": "uzb_Latn-tur_Latn",
        "languages": [
          "uzb-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000508,
        "recall": 0.002003,
        "f1": 0.000514,
        "accuracy": 0.002003,
        "main_score": 0.000514,
        "hf_subset": "uzb_Latn-uig_Arab",
        "languages": [
          "uzb-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.034871,
        "recall": 0.049574,
        "f1": 0.037501,
        "accuracy": 0.049574,
        "main_score": 0.037501,
        "hf_subset": "ven_Latn-bem_Latn",
        "languages": [
          "ven-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.016073,
        "recall": 0.022534,
        "f1": 0.017049,
        "accuracy": 0.022534,
        "main_score": 0.017049,
        "hf_subset": "ven_Latn-eng_Latn",
        "languages": [
          "ven-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039024,
        "recall": 0.047571,
        "f1": 0.040957,
        "accuracy": 0.047571,
        "main_score": 0.040957,
        "hf_subset": "ven_Latn-ewe_Latn",
        "languages": [
          "ven-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.040676,
        "recall": 0.047071,
        "f1": 0.042192,
        "accuracy": 0.047071,
        "main_score": 0.042192,
        "hf_subset": "ven_Latn-fuc_Latn",
        "languages": [
          "ven-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.006957,
        "recall": 0.011517,
        "f1": 0.007439,
        "accuracy": 0.011517,
        "main_score": 0.007439,
        "hf_subset": "ven_Latn-kin_Latn",
        "languages": [
          "ven-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.029866,
        "recall": 0.042564,
        "f1": 0.032298,
        "accuracy": 0.042564,
        "main_score": 0.032298,
        "hf_subset": "ven_Latn-nde_Latn",
        "languages": [
          "ven-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.0549,
        "recall": 0.071107,
        "f1": 0.057813,
        "accuracy": 0.071107,
        "main_score": 0.057813,
        "hf_subset": "ven_Latn-nya_Latn",
        "languages": [
          "ven-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.047252,
        "recall": 0.068603,
        "f1": 0.051019,
        "accuracy": 0.068603,
        "main_score": 0.051019,
        "hf_subset": "ven_Latn-sna_Latn",
        "languages": [
          "ven-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.004957,
        "recall": 0.010015,
        "f1": 0.005418,
        "accuracy": 0.010015,
        "main_score": 0.005418,
        "hf_subset": "vie_Latn-arb_Arab",
        "languages": [
          "vie-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001783,
        "recall": 0.007011,
        "f1": 0.002203,
        "accuracy": 0.007011,
        "main_score": 0.002203,
        "hf_subset": "vie_Latn-ben_Beng",
        "languages": [
          "vie-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.015276,
        "recall": 0.021032,
        "f1": 0.016054,
        "accuracy": 0.021032,
        "main_score": 0.016054,
        "hf_subset": "vie_Latn-deu_Latn",
        "languages": [
          "vie-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "vie_Latn-ell_Grek",
        "languages": [
          "vie-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.495357,
        "recall": 0.553831,
        "f1": 0.510163,
        "accuracy": 0.553831,
        "main_score": 0.510163,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000545,
        "recall": 0.002504,
        "f1": 0.000586,
        "accuracy": 0.002504,
        "main_score": 0.000586,
        "hf_subset": "vie_Latn-fas_Arab",
        "languages": [
          "vie-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.006096,
        "recall": 0.01302,
        "f1": 0.006865,
        "accuracy": 0.01302,
        "main_score": 0.006865,
        "hf_subset": "vie_Latn-fin_Latn",
        "languages": [
          "vie-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.079808,
        "recall": 0.101152,
        "f1": 0.084211,
        "accuracy": 0.101152,
        "main_score": 0.084211,
        "hf_subset": "vie_Latn-fra_Latn",
        "languages": [
          "vie-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.00059,
        "recall": 0.002504,
        "f1": 0.000663,
        "accuracy": 0.002504,
        "main_score": 0.000663,
        "hf_subset": "vie_Latn-heb_Hebr",
        "languages": [
          "vie-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.002993,
        "recall": 0.006009,
        "f1": 0.003424,
        "accuracy": 0.006009,
        "main_score": 0.003424,
        "hf_subset": "vie_Latn-hin_Deva",
        "languages": [
          "vie-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005712,
        "recall": 0.011017,
        "f1": 0.006104,
        "accuracy": 0.011017,
        "main_score": 0.006104,
        "hf_subset": "vie_Latn-hun_Latn",
        "languages": [
          "vie-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.064174,
        "recall": 0.085128,
        "f1": 0.068901,
        "accuracy": 0.085128,
        "main_score": 0.068901,
        "hf_subset": "vie_Latn-ind_Latn",
        "languages": [
          "vie-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "vie_Latn-jpn_Jpan",
        "languages": [
          "vie-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000601,
        "recall": 0.001502,
        "f1": 0.000668,
        "accuracy": 0.001502,
        "main_score": 0.000668,
        "hf_subset": "vie_Latn-kor_Hang",
        "languages": [
          "vie-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.00567,
        "recall": 0.008513,
        "f1": 0.006194,
        "accuracy": 0.008513,
        "main_score": 0.006194,
        "hf_subset": "vie_Latn-lit_Latn",
        "languages": [
          "vie-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.030021,
        "recall": 0.041062,
        "f1": 0.031572,
        "accuracy": 0.041062,
        "main_score": 0.031572,
        "hf_subset": "vie_Latn-nld_Latn",
        "languages": [
          "vie-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.008203,
        "recall": 0.016525,
        "f1": 0.009176,
        "accuracy": 0.016525,
        "main_score": 0.009176,
        "hf_subset": "vie_Latn-pol_Latn",
        "languages": [
          "vie-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.100921,
        "recall": 0.129194,
        "f1": 0.106147,
        "accuracy": 0.129194,
        "main_score": 0.106147,
        "hf_subset": "vie_Latn-por_Latn",
        "languages": [
          "vie-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.003252,
        "recall": 0.008012,
        "f1": 0.003817,
        "accuracy": 0.008012,
        "main_score": 0.003817,
        "hf_subset": "vie_Latn-rus_Cyrl",
        "languages": [
          "vie-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.160768,
        "recall": 0.198798,
        "f1": 0.168155,
        "accuracy": 0.198798,
        "main_score": 0.168155,
        "hf_subset": "vie_Latn-spa_Latn",
        "languages": [
          "vie-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.018708,
        "recall": 0.027041,
        "f1": 0.020111,
        "accuracy": 0.027041,
        "main_score": 0.020111,
        "hf_subset": "vie_Latn-swa_Latn",
        "languages": [
          "vie-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.022067,
        "recall": 0.032048,
        "f1": 0.023421,
        "accuracy": 0.032048,
        "main_score": 0.023421,
        "hf_subset": "vie_Latn-swe_Latn",
        "languages": [
          "vie-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000325,
        "recall": 0.003005,
        "f1": 0.000473,
        "accuracy": 0.003005,
        "main_score": 0.000473,
        "hf_subset": "vie_Latn-tam_Taml",
        "languages": [
          "vie-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.004087,
        "recall": 0.007511,
        "f1": 0.004496,
        "accuracy": 0.007511,
        "main_score": 0.004496,
        "hf_subset": "vie_Latn-tur_Latn",
        "languages": [
          "vie-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.002003,
        "recall": 0.002504,
        "f1": 0.002004,
        "accuracy": 0.002504,
        "main_score": 0.002004,
        "hf_subset": "vie_Latn-yue_Hant",
        "languages": [
          "vie-Latn",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.018942,
        "recall": 0.02654,
        "f1": 0.019724,
        "accuracy": 0.02654,
        "main_score": 0.019724,
        "hf_subset": "vie_Latn-zho_Hans",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.003467,
        "recall": 0.007511,
        "f1": 0.003938,
        "accuracy": 0.007511,
        "main_score": 0.003938,
        "hf_subset": "vie_Latn-zho_Hant",
        "languages": [
          "vie-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.012375,
        "recall": 0.02003,
        "f1": 0.013475,
        "accuracy": 0.02003,
        "main_score": 0.013475,
        "hf_subset": "vie_Latn-zul_Latn",
        "languages": [
          "vie-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001122,
        "recall": 0.003005,
        "f1": 0.001222,
        "accuracy": 0.003005,
        "main_score": 0.001222,
        "hf_subset": "wol_Latn-amh_Ethi",
        "languages": [
          "wol-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.023126,
        "recall": 0.034051,
        "f1": 0.024834,
        "accuracy": 0.034051,
        "main_score": 0.024834,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.082222,
        "recall": 0.107661,
        "f1": 0.087658,
        "accuracy": 0.107661,
        "main_score": 0.087658,
        "hf_subset": "wol_Latn-hau_Latn",
        "languages": [
          "wol-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.006464,
        "recall": 0.01302,
        "f1": 0.007332,
        "accuracy": 0.01302,
        "main_score": 0.007332,
        "hf_subset": "wol_Latn-ibo_Latn",
        "languages": [
          "wol-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.080921,
        "recall": 0.103655,
        "f1": 0.085815,
        "accuracy": 0.103655,
        "main_score": 0.085815,
        "hf_subset": "wol_Latn-nso_Latn",
        "languages": [
          "wol-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.041473,
        "recall": 0.061092,
        "f1": 0.045733,
        "accuracy": 0.061092,
        "main_score": 0.045733,
        "hf_subset": "wol_Latn-orm_Ethi",
        "languages": [
          "wol-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.090482,
        "recall": 0.114672,
        "f1": 0.095896,
        "accuracy": 0.114672,
        "main_score": 0.095896,
        "hf_subset": "wol_Latn-som_Latn",
        "languages": [
          "wol-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.042887,
        "recall": 0.068603,
        "f1": 0.047791,
        "accuracy": 0.068603,
        "main_score": 0.047791,
        "hf_subset": "wol_Latn-ssw_Latn",
        "languages": [
          "wol-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.006439,
        "recall": 0.009514,
        "f1": 0.00693,
        "accuracy": 0.009514,
        "main_score": 0.00693,
        "hf_subset": "wol_Latn-swa_Latn",
        "languages": [
          "wol-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.001002,
        "f1": 2.5e-05,
        "accuracy": 0.001002,
        "main_score": 2.5e-05,
        "hf_subset": "wol_Latn-tir_Ethi",
        "languages": [
          "wol-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.071194,
        "recall": 0.090135,
        "f1": 0.07577,
        "accuracy": 0.090135,
        "main_score": 0.07577,
        "hf_subset": "wol_Latn-tsn_Latn",
        "languages": [
          "wol-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.024536,
        "recall": 0.036054,
        "f1": 0.026533,
        "accuracy": 0.036054,
        "main_score": 0.026533,
        "hf_subset": "wol_Latn-xho_Latn",
        "languages": [
          "wol-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.008233,
        "recall": 0.01302,
        "f1": 0.009118,
        "accuracy": 0.01302,
        "main_score": 0.009118,
        "hf_subset": "wol_Latn-yor_Latn",
        "languages": [
          "wol-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.029137,
        "recall": 0.042063,
        "f1": 0.031404,
        "accuracy": 0.042063,
        "main_score": 0.031404,
        "hf_subset": "wol_Latn-zul_Latn",
        "languages": [
          "wol-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000813,
        "recall": 0.003005,
        "f1": 0.001009,
        "accuracy": 0.003005,
        "main_score": 0.001009,
        "hf_subset": "xho_Latn-amh_Ethi",
        "languages": [
          "xho-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.015035,
        "recall": 0.021532,
        "f1": 0.015914,
        "accuracy": 0.021532,
        "main_score": 0.015914,
        "hf_subset": "xho_Latn-eng_Latn",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031022,
        "recall": 0.037556,
        "f1": 0.032899,
        "accuracy": 0.037556,
        "main_score": 0.032899,
        "hf_subset": "xho_Latn-hau_Latn",
        "languages": [
          "xho-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.012524,
        "recall": 0.018528,
        "f1": 0.013437,
        "accuracy": 0.018528,
        "main_score": 0.013437,
        "hf_subset": "xho_Latn-ibo_Latn",
        "languages": [
          "xho-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.032813,
        "recall": 0.038057,
        "f1": 0.034022,
        "accuracy": 0.038057,
        "main_score": 0.034022,
        "hf_subset": "xho_Latn-nso_Latn",
        "languages": [
          "xho-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.018337,
        "recall": 0.022534,
        "f1": 0.019398,
        "accuracy": 0.022534,
        "main_score": 0.019398,
        "hf_subset": "xho_Latn-orm_Ethi",
        "languages": [
          "xho-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.032926,
        "recall": 0.04006,
        "f1": 0.034283,
        "accuracy": 0.04006,
        "main_score": 0.034283,
        "hf_subset": "xho_Latn-som_Latn",
        "languages": [
          "xho-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.107381,
        "recall": 0.143215,
        "f1": 0.115876,
        "accuracy": 0.143215,
        "main_score": 0.115876,
        "hf_subset": "xho_Latn-ssw_Latn",
        "languages": [
          "xho-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.007751,
        "recall": 0.010516,
        "f1": 0.008105,
        "accuracy": 0.010516,
        "main_score": 0.008105,
        "hf_subset": "xho_Latn-swa_Latn",
        "languages": [
          "xho-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 2.9e-05,
        "recall": 0.002003,
        "f1": 5.6e-05,
        "accuracy": 0.002003,
        "main_score": 5.6e-05,
        "hf_subset": "xho_Latn-tir_Ethi",
        "languages": [
          "xho-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.029496,
        "recall": 0.034552,
        "f1": 0.030665,
        "accuracy": 0.034552,
        "main_score": 0.030665,
        "hf_subset": "xho_Latn-tsn_Latn",
        "languages": [
          "xho-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.02703,
        "recall": 0.032048,
        "f1": 0.028344,
        "accuracy": 0.032048,
        "main_score": 0.028344,
        "hf_subset": "xho_Latn-wol_Latn",
        "languages": [
          "xho-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.00895,
        "recall": 0.01302,
        "f1": 0.009572,
        "accuracy": 0.01302,
        "main_score": 0.009572,
        "hf_subset": "xho_Latn-yor_Latn",
        "languages": [
          "xho-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.220233,
        "recall": 0.277917,
        "f1": 0.233701,
        "accuracy": 0.277917,
        "main_score": 0.233701,
        "hf_subset": "xho_Latn-zul_Latn",
        "languages": [
          "xho-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.003142,
        "recall": 0.008012,
        "f1": 0.003653,
        "accuracy": 0.008012,
        "main_score": 0.003653,
        "hf_subset": "yor_Latn-amh_Ethi",
        "languages": [
          "yor-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.01783,
        "recall": 0.02654,
        "f1": 0.018968,
        "accuracy": 0.02654,
        "main_score": 0.018968,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0231,
        "recall": 0.027041,
        "f1": 0.023865,
        "accuracy": 0.027041,
        "main_score": 0.023865,
        "hf_subset": "yor_Latn-hau_Latn",
        "languages": [
          "yor-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.039601,
        "recall": 0.04657,
        "f1": 0.040944,
        "accuracy": 0.04657,
        "main_score": 0.040944,
        "hf_subset": "yor_Latn-ibo_Latn",
        "languages": [
          "yor-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.024454,
        "recall": 0.026039,
        "f1": 0.024788,
        "accuracy": 0.026039,
        "main_score": 0.024788,
        "hf_subset": "yor_Latn-nso_Latn",
        "languages": [
          "yor-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.01242,
        "recall": 0.014522,
        "f1": 0.012785,
        "accuracy": 0.014522,
        "main_score": 0.012785,
        "hf_subset": "yor_Latn-orm_Ethi",
        "languages": [
          "yor-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.027712,
        "recall": 0.030546,
        "f1": 0.028466,
        "accuracy": 0.030546,
        "main_score": 0.028466,
        "hf_subset": "yor_Latn-som_Latn",
        "languages": [
          "yor-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.021781,
        "recall": 0.02654,
        "f1": 0.022778,
        "accuracy": 0.02654,
        "main_score": 0.022778,
        "hf_subset": "yor_Latn-ssw_Latn",
        "languages": [
          "yor-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.029094,
        "recall": 0.032048,
        "f1": 0.029678,
        "accuracy": 0.032048,
        "main_score": 0.029678,
        "hf_subset": "yor_Latn-swa_Latn",
        "languages": [
          "yor-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000528,
        "recall": 0.002003,
        "f1": 0.000554,
        "accuracy": 0.002003,
        "main_score": 0.000554,
        "hf_subset": "yor_Latn-tir_Ethi",
        "languages": [
          "yor-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.026285,
        "recall": 0.030546,
        "f1": 0.027023,
        "accuracy": 0.030546,
        "main_score": 0.027023,
        "hf_subset": "yor_Latn-tsn_Latn",
        "languages": [
          "yor-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.026708,
        "recall": 0.032549,
        "f1": 0.027962,
        "accuracy": 0.032549,
        "main_score": 0.027962,
        "hf_subset": "yor_Latn-wol_Latn",
        "languages": [
          "yor-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.018955,
        "recall": 0.024036,
        "f1": 0.020043,
        "accuracy": 0.024036,
        "main_score": 0.020043,
        "hf_subset": "yor_Latn-xho_Latn",
        "languages": [
          "yor-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.022381,
        "recall": 0.030546,
        "f1": 0.024053,
        "accuracy": 0.030546,
        "main_score": 0.024053,
        "hf_subset": "yor_Latn-zul_Latn",
        "languages": [
          "yor-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000651,
        "recall": 0.004006,
        "f1": 0.000765,
        "accuracy": 0.004006,
        "main_score": 0.000765,
        "hf_subset": "yue_Hant-eng_Latn",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009848,
        "recall": 0.020531,
        "f1": 0.010813,
        "accuracy": 0.020531,
        "main_score": 0.010813,
        "hf_subset": "yue_Hant-jpn_Jpan",
        "languages": [
          "yue-Hant",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000664,
        "recall": 0.002504,
        "f1": 0.000782,
        "accuracy": 0.002504,
        "main_score": 0.000782,
        "hf_subset": "yue_Hant-kor_Hang",
        "languages": [
          "yue-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.001169,
        "recall": 0.003505,
        "f1": 0.001294,
        "accuracy": 0.003505,
        "main_score": 0.001294,
        "hf_subset": "yue_Hant-vie_Latn",
        "languages": [
          "yue-Hant",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.012518,
        "recall": 0.014522,
        "f1": 0.012765,
        "accuracy": 0.014522,
        "main_score": 0.012765,
        "hf_subset": "yue_Hant-zho_Hans",
        "languages": [
          "yue-Hant",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.601793,
        "recall": 0.678518,
        "f1": 0.623459,
        "accuracy": 0.678518,
        "main_score": 0.623459,
        "hf_subset": "yue_Hant-zho_Hant",
        "languages": [
          "yue-Hant",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.006242,
        "recall": 0.011017,
        "f1": 0.006794,
        "accuracy": 0.011017,
        "main_score": 0.006794,
        "hf_subset": "zho_Hans-eng_Latn",
        "languages": [
          "zho-Hans",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003092,
        "recall": 0.010015,
        "f1": 0.003789,
        "accuracy": 0.010015,
        "main_score": 0.003789,
        "hf_subset": "zho_Hans-jpn_Jpan",
        "languages": [
          "zho-Hans",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001002,
        "f1": 1e-05,
        "accuracy": 0.001002,
        "main_score": 1e-05,
        "hf_subset": "zho_Hans-kor_Hang",
        "languages": [
          "zho-Hans",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.004358,
        "recall": 0.007511,
        "f1": 0.004595,
        "accuracy": 0.007511,
        "main_score": 0.004595,
        "hf_subset": "zho_Hans-vie_Latn",
        "languages": [
          "zho-Hans",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.005296,
        "recall": 0.011517,
        "f1": 0.005676,
        "accuracy": 0.011517,
        "main_score": 0.005676,
        "hf_subset": "zho_Hans-yue_Hant",
        "languages": [
          "zho-Hans",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.006596,
        "recall": 0.01302,
        "f1": 0.007321,
        "accuracy": 0.01302,
        "main_score": 0.007321,
        "hf_subset": "zho_Hans-zho_Hant",
        "languages": [
          "zho-Hans",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.000596,
        "recall": 0.002504,
        "f1": 0.000672,
        "accuracy": 0.002504,
        "main_score": 0.000672,
        "hf_subset": "zho_Hant-arb_Arab",
        "languages": [
          "zho-Hant",
          "arb-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "zho_Hant-ben_Beng",
        "languages": [
          "zho-Hant",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.002472,
        "recall": 0.004507,
        "f1": 0.002681,
        "accuracy": 0.004507,
        "main_score": 0.002681,
        "hf_subset": "zho_Hant-deu_Latn",
        "languages": [
          "zho-Hant",
          "deu-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "zho_Hant-ell_Grek",
        "languages": [
          "zho-Hant",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.005908,
        "recall": 0.009014,
        "f1": 0.006091,
        "accuracy": 0.009014,
        "main_score": 0.006091,
        "hf_subset": "zho_Hant-eng_Latn",
        "languages": [
          "zho-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000289,
        "recall": 0.001502,
        "f1": 0.000406,
        "accuracy": 0.001502,
        "main_score": 0.000406,
        "hf_subset": "zho_Hant-fas_Arab",
        "languages": [
          "zho-Hant",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.003056,
        "recall": 0.004507,
        "f1": 0.0031,
        "accuracy": 0.004507,
        "main_score": 0.0031,
        "hf_subset": "zho_Hant-fin_Latn",
        "languages": [
          "zho-Hant",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.005457,
        "recall": 0.009014,
        "f1": 0.005699,
        "accuracy": 0.009014,
        "main_score": 0.005699,
        "hf_subset": "zho_Hant-fra_Latn",
        "languages": [
          "zho-Hant",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.002024,
        "recall": 0.005008,
        "f1": 0.002211,
        "accuracy": 0.005008,
        "main_score": 0.002211,
        "hf_subset": "zho_Hant-heb_Hebr",
        "languages": [
          "zho-Hant",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000603,
        "recall": 0.002003,
        "f1": 0.000673,
        "accuracy": 0.002003,
        "main_score": 0.000673,
        "hf_subset": "zho_Hant-hin_Deva",
        "languages": [
          "zho-Hant",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "zho_Hant-hun_Latn",
        "languages": [
          "zho-Hant",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.005351,
        "recall": 0.008513,
        "f1": 0.005695,
        "accuracy": 0.008513,
        "main_score": 0.005695,
        "hf_subset": "zho_Hant-ind_Latn",
        "languages": [
          "zho-Hant",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.011945,
        "recall": 0.021032,
        "f1": 0.012818,
        "accuracy": 0.021032,
        "main_score": 0.012818,
        "hf_subset": "zho_Hant-jpn_Jpan",
        "languages": [
          "zho-Hant",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001725,
        "recall": 0.003505,
        "f1": 0.002021,
        "accuracy": 0.003505,
        "main_score": 0.002021,
        "hf_subset": "zho_Hant-kor_Hang",
        "languages": [
          "zho-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.002493,
        "recall": 0.005008,
        "f1": 0.002726,
        "accuracy": 0.005008,
        "main_score": 0.002726,
        "hf_subset": "zho_Hant-lit_Latn",
        "languages": [
          "zho-Hant",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.004277,
        "recall": 0.00651,
        "f1": 0.004381,
        "accuracy": 0.00651,
        "main_score": 0.004381,
        "hf_subset": "zho_Hant-nld_Latn",
        "languages": [
          "zho-Hant",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.001879,
        "recall": 0.004006,
        "f1": 0.002063,
        "accuracy": 0.004006,
        "main_score": 0.002063,
        "hf_subset": "zho_Hant-pol_Latn",
        "languages": [
          "zho-Hant",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.006238,
        "recall": 0.008513,
        "f1": 0.006383,
        "accuracy": 0.008513,
        "main_score": 0.006383,
        "hf_subset": "zho_Hant-por_Latn",
        "languages": [
          "zho-Hant",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000824,
        "recall": 0.002504,
        "f1": 0.000963,
        "accuracy": 0.002504,
        "main_score": 0.000963,
        "hf_subset": "zho_Hant-rus_Cyrl",
        "languages": [
          "zho-Hant",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.002504,
        "recall": 0.003005,
        "f1": 0.002504,
        "accuracy": 0.003005,
        "main_score": 0.002504,
        "hf_subset": "zho_Hant-spa_Latn",
        "languages": [
          "zho-Hant",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001916,
        "recall": 0.003505,
        "f1": 0.002152,
        "accuracy": 0.003505,
        "main_score": 0.002152,
        "hf_subset": "zho_Hant-swa_Latn",
        "languages": [
          "zho-Hant",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.003437,
        "recall": 0.005008,
        "f1": 0.003618,
        "accuracy": 0.005008,
        "main_score": 0.003618,
        "hf_subset": "zho_Hant-swe_Latn",
        "languages": [
          "zho-Hant",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000774,
        "recall": 0.002003,
        "f1": 0.000879,
        "accuracy": 0.002003,
        "main_score": 0.000879,
        "hf_subset": "zho_Hant-tam_Taml",
        "languages": [
          "zho-Hant",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002214,
        "recall": 0.004006,
        "f1": 0.002337,
        "accuracy": 0.004006,
        "main_score": 0.002337,
        "hf_subset": "zho_Hant-tur_Latn",
        "languages": [
          "zho-Hant",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001605,
        "recall": 0.004006,
        "f1": 0.001689,
        "accuracy": 0.004006,
        "main_score": 0.001689,
        "hf_subset": "zho_Hant-vie_Latn",
        "languages": [
          "zho-Hant",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.60465,
        "recall": 0.681522,
        "f1": 0.626411,
        "accuracy": 0.681522,
        "main_score": 0.626411,
        "hf_subset": "zho_Hant-yue_Hant",
        "languages": [
          "zho-Hant",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.016213,
        "recall": 0.02003,
        "f1": 0.017036,
        "accuracy": 0.02003,
        "main_score": 0.017036,
        "hf_subset": "zho_Hant-zho_Hans",
        "languages": [
          "zho-Hant",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.001521,
        "recall": 0.004006,
        "f1": 0.001705,
        "accuracy": 0.004006,
        "main_score": 0.001705,
        "hf_subset": "zho_Hant-zul_Latn",
        "languages": [
          "zho-Hant",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001064,
        "recall": 0.002003,
        "f1": 0.001113,
        "accuracy": 0.002003,
        "main_score": 0.001113,
        "hf_subset": "zul_Latn-amh_Ethi",
        "languages": [
          "zul-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "zul_Latn-arb_Arab",
        "languages": [
          "zul-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 2.7e-05,
        "recall": 0.001502,
        "f1": 5.3e-05,
        "accuracy": 0.001502,
        "main_score": 5.3e-05,
        "hf_subset": "zul_Latn-ben_Beng",
        "languages": [
          "zul-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.013402,
        "recall": 0.021532,
        "f1": 0.0143,
        "accuracy": 0.021532,
        "main_score": 0.0143,
        "hf_subset": "zul_Latn-deu_Latn",
        "languages": [
          "zul-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 3.4e-05,
        "recall": 0.001502,
        "f1": 6.4e-05,
        "accuracy": 0.001502,
        "main_score": 6.4e-05,
        "hf_subset": "zul_Latn-ell_Grek",
        "languages": [
          "zul-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.020191,
        "recall": 0.027541,
        "f1": 0.021051,
        "accuracy": 0.027541,
        "main_score": 0.021051,
        "hf_subset": "zul_Latn-eng_Latn",
        "languages": [
          "zul-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "zul_Latn-fas_Arab",
        "languages": [
          "zul-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.018141,
        "recall": 0.026039,
        "f1": 0.019203,
        "accuracy": 0.026039,
        "main_score": 0.019203,
        "hf_subset": "zul_Latn-fin_Latn",
        "languages": [
          "zul-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.01128,
        "recall": 0.016525,
        "f1": 0.011895,
        "accuracy": 0.016525,
        "main_score": 0.011895,
        "hf_subset": "zul_Latn-fra_Latn",
        "languages": [
          "zul-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.032783,
        "recall": 0.039059,
        "f1": 0.034121,
        "accuracy": 0.039059,
        "main_score": 0.034121,
        "hf_subset": "zul_Latn-hau_Latn",
        "languages": [
          "zul-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.000262,
        "recall": 0.002003,
        "f1": 0.000357,
        "accuracy": 0.002003,
        "main_score": 0.000357,
        "hf_subset": "zul_Latn-heb_Hebr",
        "languages": [
          "zul-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 2.3e-05,
        "recall": 0.001502,
        "f1": 4.4e-05,
        "accuracy": 0.001502,
        "main_score": 4.4e-05,
        "hf_subset": "zul_Latn-hin_Deva",
        "languages": [
          "zul-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.011915,
        "recall": 0.016525,
        "f1": 0.012436,
        "accuracy": 0.016525,
        "main_score": 0.012436,
        "hf_subset": "zul_Latn-hun_Latn",
        "languages": [
          "zul-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.01414,
        "recall": 0.021532,
        "f1": 0.015142,
        "accuracy": 0.021532,
        "main_score": 0.015142,
        "hf_subset": "zul_Latn-ibo_Latn",
        "languages": [
          "zul-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.00506,
        "recall": 0.010015,
        "f1": 0.005592,
        "accuracy": 0.010015,
        "main_score": 0.005592,
        "hf_subset": "zul_Latn-ind_Latn",
        "languages": [
          "zul-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "zul_Latn-jpn_Jpan",
        "languages": [
          "zul-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001502,
        "f1": 1.3e-05,
        "accuracy": 0.001502,
        "main_score": 1.3e-05,
        "hf_subset": "zul_Latn-kor_Hang",
        "languages": [
          "zul-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.015305,
        "recall": 0.021032,
        "f1": 0.01629,
        "accuracy": 0.021032,
        "main_score": 0.01629,
        "hf_subset": "zul_Latn-lit_Latn",
        "languages": [
          "zul-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.020409,
        "recall": 0.023535,
        "f1": 0.02113,
        "accuracy": 0.023535,
        "main_score": 0.02113,
        "hf_subset": "zul_Latn-nld_Latn",
        "languages": [
          "zul-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.042377,
        "recall": 0.049574,
        "f1": 0.043879,
        "accuracy": 0.049574,
        "main_score": 0.043879,
        "hf_subset": "zul_Latn-nso_Latn",
        "languages": [
          "zul-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.023014,
        "recall": 0.02654,
        "f1": 0.023957,
        "accuracy": 0.02654,
        "main_score": 0.023957,
        "hf_subset": "zul_Latn-orm_Ethi",
        "languages": [
          "zul-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.011445,
        "recall": 0.017026,
        "f1": 0.012262,
        "accuracy": 0.017026,
        "main_score": 0.012262,
        "hf_subset": "zul_Latn-pol_Latn",
        "languages": [
          "zul-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.008772,
        "recall": 0.016024,
        "f1": 0.009237,
        "accuracy": 0.016024,
        "main_score": 0.009237,
        "hf_subset": "zul_Latn-por_Latn",
        "languages": [
          "zul-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "zul_Latn-rus_Cyrl",
        "languages": [
          "zul-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.037346,
        "recall": 0.045068,
        "f1": 0.038413,
        "accuracy": 0.045068,
        "main_score": 0.038413,
        "hf_subset": "zul_Latn-som_Latn",
        "languages": [
          "zul-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.01318,
        "recall": 0.02003,
        "f1": 0.014028,
        "accuracy": 0.02003,
        "main_score": 0.014028,
        "hf_subset": "zul_Latn-spa_Latn",
        "languages": [
          "zul-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.162799,
        "recall": 0.211317,
        "f1": 0.174581,
        "accuracy": 0.211317,
        "main_score": 0.174581,
        "hf_subset": "zul_Latn-ssw_Latn",
        "languages": [
          "zul-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.01101,
        "recall": 0.015023,
        "f1": 0.011582,
        "accuracy": 0.015023,
        "main_score": 0.011582,
        "hf_subset": "zul_Latn-swa_Latn",
        "languages": [
          "zul-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.029571,
        "recall": 0.039559,
        "f1": 0.031227,
        "accuracy": 0.039559,
        "main_score": 0.031227,
        "hf_subset": "zul_Latn-swe_Latn",
        "languages": [
          "zul-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000334,
        "recall": 0.001502,
        "f1": 0.000477,
        "accuracy": 0.001502,
        "main_score": 0.000477,
        "hf_subset": "zul_Latn-tam_Taml",
        "languages": [
          "zul-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 2.3e-05,
        "recall": 0.001002,
        "f1": 4.4e-05,
        "accuracy": 0.001002,
        "main_score": 4.4e-05,
        "hf_subset": "zul_Latn-tir_Ethi",
        "languages": [
          "zul-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.047134,
        "recall": 0.055583,
        "f1": 0.04895,
        "accuracy": 0.055583,
        "main_score": 0.04895,
        "hf_subset": "zul_Latn-tsn_Latn",
        "languages": [
          "zul-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.008816,
        "recall": 0.01302,
        "f1": 0.009292,
        "accuracy": 0.01302,
        "main_score": 0.009292,
        "hf_subset": "zul_Latn-tur_Latn",
        "languages": [
          "zul-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.004754,
        "recall": 0.009014,
        "f1": 0.005302,
        "accuracy": 0.009014,
        "main_score": 0.005302,
        "hf_subset": "zul_Latn-vie_Latn",
        "languages": [
          "zul-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.039772,
        "recall": 0.045068,
        "f1": 0.040884,
        "accuracy": 0.045068,
        "main_score": 0.040884,
        "hf_subset": "zul_Latn-wol_Latn",
        "languages": [
          "zul-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.22834,
        "recall": 0.284927,
        "f1": 0.242908,
        "accuracy": 0.284927,
        "main_score": 0.242908,
        "hf_subset": "zul_Latn-xho_Latn",
        "languages": [
          "zul-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.01212,
        "recall": 0.017526,
        "f1": 0.012995,
        "accuracy": 0.017526,
        "main_score": 0.012995,
        "hf_subset": "zul_Latn-yor_Latn",
        "languages": [
          "zul-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.001295,
        "recall": 0.003005,
        "f1": 0.001415,
        "accuracy": 0.003005,
        "main_score": 0.001415,
        "hf_subset": "zul_Latn-zho_Hant",
        "languages": [
          "zul-Latn",
          "zho-Hant"
        ]
      }
    ]
  },
  "evaluation_time": 2661.3767817020416,
  "kg_co2_emissions": 0.21820365514051107
}