{
  "dataset_revision": "0dccb383ee26c90c99d03c8674cf40de642f099a",
  "task_name": "ImdbVNClassification",
  "mteb_version": "1.38.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.789779,
        "f1": 0.788479,
        "f1_weighted": 0.788481,
        "ap": 0.733674,
        "ap_weighted": 0.733674,
        "scores_per_experiment": [
          {
            "accuracy": 0.82066,
            "f1": 0.819627,
            "f1_weighted": 0.819546,
            "ap": 0.785177,
            "ap_weighted": 0.785177
          },
          {
            "accuracy": 0.802953,
            "f1": 0.801936,
            "f1_weighted": 0.80202,
            "ap": 0.734244,
            "ap_weighted": 0.734244
          },
          {
            "accuracy": 0.7828,
            "f1": 0.782589,
            "f1_weighted": 0.782549,
            "ap": 0.729909,
            "ap_weighted": 0.729909
          },
          {
            "accuracy": 0.81903,
            "f1": 0.817116,
            "f1_weighted": 0.817227,
            "ap": 0.746285,
            "ap_weighted": 0.746285
          },
          {
            "accuracy": 0.779856,
            "f1": 0.778967,
            "f1_weighted": 0.778884,
            "ap": 0.733118,
            "ap_weighted": 0.733118
          },
          {
            "accuracy": 0.790227,
            "f1": 0.788884,
            "f1_weighted": 0.788984,
            "ap": 0.720212,
            "ap_weighted": 0.720212
          },
          {
            "accuracy": 0.776822,
            "f1": 0.776709,
            "f1_weighted": 0.776738,
            "ap": 0.714571,
            "ap_weighted": 0.714571
          },
          {
            "accuracy": 0.767628,
            "f1": 0.765043,
            "f1_weighted": 0.76519,
            "ap": 0.695357,
            "ap_weighted": 0.695357
          },
          {
            "accuracy": 0.771025,
            "f1": 0.768965,
            "f1_weighted": 0.768836,
            "ap": 0.72984,
            "ap_weighted": 0.72984
          },
          {
            "accuracy": 0.786785,
            "f1": 0.784955,
            "f1_weighted": 0.784837,
            "ap": 0.748033,
            "ap_weighted": 0.748033
          }
        ],
        "main_score": 0.789779,
        "hf_subset": "default",
        "languages": [
          "vie-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 160.90997672080994,
  "kg_co2_emissions": null
}