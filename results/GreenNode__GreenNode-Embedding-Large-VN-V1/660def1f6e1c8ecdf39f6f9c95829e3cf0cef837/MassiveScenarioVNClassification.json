{
  "dataset_revision": "a82e282d9f5aec1a8cf7d868ce40f70669c16b89",
  "task_name": "MassiveScenarioVNClassification",
  "mteb_version": "1.38.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.702573,
        "f1": 0.673471,
        "f1_weighted": 0.699021,
        "scores_per_experiment": [
          {
            "accuracy": 0.719799,
            "f1": 0.694121,
            "f1_weighted": 0.715664
          },
          {
            "accuracy": 0.729306,
            "f1": 0.704602,
            "f1_weighted": 0.726734
          },
          {
            "accuracy": 0.695749,
            "f1": 0.670997,
            "f1_weighted": 0.692642
          },
          {
            "accuracy": 0.690716,
            "f1": 0.667434,
            "f1_weighted": 0.683041
          },
          {
            "accuracy": 0.680649,
            "f1": 0.637841,
            "f1_weighted": 0.674521
          },
          {
            "accuracy": 0.699105,
            "f1": 0.661455,
            "f1_weighted": 0.692969
          },
          {
            "accuracy": 0.701902,
            "f1": 0.666822,
            "f1_weighted": 0.696838
          },
          {
            "accuracy": 0.703579,
            "f1": 0.682712,
            "f1_weighted": 0.703543
          },
          {
            "accuracy": 0.716443,
            "f1": 0.689544,
            "f1_weighted": 0.714985
          },
          {
            "accuracy": 0.688479,
            "f1": 0.659183,
            "f1_weighted": 0.689274
          }
        ],
        "main_score": 0.702573,
        "hf_subset": "default",
        "languages": [
          "vie-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5.00214695930481,
  "kg_co2_emissions": null
}