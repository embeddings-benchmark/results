{
  "dataset_revision": "6d4225271da423e791e16770d335cfa351cdf88e",
  "task_name": "IEMOCAPGender",
  "mteb_version": "2.4.2",
  "scores": {
    "train": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.666335,
            "f1": 0.662054,
            "f1_weighted": 0.660084,
            "precision": 0.687912,
            "precision_weighted": 0.691948,
            "recall": 0.673972,
            "recall_weighted": 0.666335,
            "ap": 0.65223,
            "ap_weighted": 0.65223
          },
          {
            "accuracy": 0.659861,
            "f1": 0.659032,
            "f1_weighted": 0.65801,
            "precision": 0.668994,
            "precision_weighted": 0.672476,
            "recall": 0.665312,
            "recall_weighted": 0.659861,
            "ap": 0.64315,
            "ap_weighted": 0.64315
          },
          {
            "accuracy": 0.655378,
            "f1": 0.652949,
            "f1_weighted": 0.654742,
            "precision": 0.653833,
            "precision_weighted": 0.654737,
            "recall": 0.652701,
            "recall_weighted": 0.655378,
            "ap": 0.626649,
            "ap_weighted": 0.626649
          },
          {
            "accuracy": 0.636454,
            "f1": 0.635237,
            "f1_weighted": 0.634922,
            "precision": 0.639809,
            "precision_weighted": 0.640193,
            "recall": 0.63746,
            "recall_weighted": 0.636454,
            "ap": 0.578205,
            "ap_weighted": 0.578205
          },
          {
            "accuracy": 0.673642,
            "f1": 0.672862,
            "f1_weighted": 0.673809,
            "precision": 0.672759,
            "precision_weighted": 0.674124,
            "recall": 0.673113,
            "recall_weighted": 0.673642,
            "ap": 0.642953,
            "ap_weighted": 0.642953
          }
        ],
        "accuracy": 0.658334,
        "f1": 0.656427,
        "f1_weighted": 0.656314,
        "precision": 0.664661,
        "precision_weighted": 0.666696,
        "recall": 0.660512,
        "recall_weighted": 0.658334,
        "ap": 0.628637,
        "ap_weighted": 0.628637,
        "main_score": 0.658334,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 38.2778160572052,
  "kg_co2_emissions": null
}