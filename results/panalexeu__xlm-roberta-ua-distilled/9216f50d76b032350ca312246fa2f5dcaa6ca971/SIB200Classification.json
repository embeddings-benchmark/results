{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "task_name": "SIB200Classification",
  "mteb_version": "1.36.41",
  "scores": {
    "train": [
      {
        "accuracy": 0.766762,
        "f1": 0.758818,
        "f1_weighted": 0.76672,
        "scores_per_experiment": [
          {
            "accuracy": 0.780314,
            "f1": 0.772839,
            "f1_weighted": 0.781145
          },
          {
            "accuracy": 0.724679,
            "f1": 0.715152,
            "f1_weighted": 0.723346
          },
          {
            "accuracy": 0.761769,
            "f1": 0.756989,
            "f1_weighted": 0.76268
          },
          {
            "accuracy": 0.798859,
            "f1": 0.77737,
            "f1_weighted": 0.795361
          },
          {
            "accuracy": 0.793153,
            "f1": 0.78818,
            "f1_weighted": 0.794866
          },
          {
            "accuracy": 0.747504,
            "f1": 0.750708,
            "f1_weighted": 0.749371
          },
          {
            "accuracy": 0.777461,
            "f1": 0.771134,
            "f1_weighted": 0.780922
          },
          {
            "accuracy": 0.740371,
            "f1": 0.734428,
            "f1_weighted": 0.741551
          },
          {
            "accuracy": 0.746077,
            "f1": 0.733919,
            "f1_weighted": 0.741464
          },
          {
            "accuracy": 0.797432,
            "f1": 0.787461,
            "f1_weighted": 0.796492
          }
        ],
        "main_score": 0.766762,
        "hf_subset": "ukr_Cyrl",
        "languages": [
          "ukr-Cyrl"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.716162,
        "f1": 0.70586,
        "f1_weighted": 0.720159,
        "scores_per_experiment": [
          {
            "accuracy": 0.717172,
            "f1": 0.706997,
            "f1_weighted": 0.723183
          },
          {
            "accuracy": 0.676768,
            "f1": 0.674352,
            "f1_weighted": 0.68303
          },
          {
            "accuracy": 0.727273,
            "f1": 0.719848,
            "f1_weighted": 0.734867
          },
          {
            "accuracy": 0.777778,
            "f1": 0.765927,
            "f1_weighted": 0.783544
          },
          {
            "accuracy": 0.787879,
            "f1": 0.767907,
            "f1_weighted": 0.785741
          },
          {
            "accuracy": 0.686869,
            "f1": 0.67698,
            "f1_weighted": 0.695244
          },
          {
            "accuracy": 0.737374,
            "f1": 0.731444,
            "f1_weighted": 0.74
          },
          {
            "accuracy": 0.686869,
            "f1": 0.676347,
            "f1_weighted": 0.69031
          },
          {
            "accuracy": 0.69697,
            "f1": 0.682142,
            "f1_weighted": 0.692339
          },
          {
            "accuracy": 0.666667,
            "f1": 0.656653,
            "f1_weighted": 0.673333
          }
        ],
        "main_score": 0.716162,
        "hf_subset": "ukr_Cyrl",
        "languages": [
          "ukr-Cyrl"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.797059,
        "f1": 0.791295,
        "f1_weighted": 0.79636,
        "scores_per_experiment": [
          {
            "accuracy": 0.813725,
            "f1": 0.801945,
            "f1_weighted": 0.814968
          },
          {
            "accuracy": 0.745098,
            "f1": 0.742712,
            "f1_weighted": 0.742112
          },
          {
            "accuracy": 0.818627,
            "f1": 0.819047,
            "f1_weighted": 0.816762
          },
          {
            "accuracy": 0.818627,
            "f1": 0.797041,
            "f1_weighted": 0.815056
          },
          {
            "accuracy": 0.838235,
            "f1": 0.838129,
            "f1_weighted": 0.837809
          },
          {
            "accuracy": 0.808824,
            "f1": 0.802151,
            "f1_weighted": 0.81109
          },
          {
            "accuracy": 0.784314,
            "f1": 0.782326,
            "f1_weighted": 0.786232
          },
          {
            "accuracy": 0.735294,
            "f1": 0.732411,
            "f1_weighted": 0.737172
          },
          {
            "accuracy": 0.77451,
            "f1": 0.768805,
            "f1_weighted": 0.768468
          },
          {
            "accuracy": 0.833333,
            "f1": 0.82838,
            "f1_weighted": 0.833933
          }
        ],
        "main_score": 0.797059,
        "hf_subset": "ukr_Cyrl",
        "languages": [
          "ukr-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 17.802814483642578,
  "kg_co2_emissions": null
}