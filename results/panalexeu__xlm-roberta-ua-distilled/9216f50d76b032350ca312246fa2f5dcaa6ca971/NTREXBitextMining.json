{
  "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
  "task_name": "NTREXBitextMining",
  "mteb_version": "1.36.41",
  "scores": {
    "test": [
      {
        "precision": 0.911653,
        "recall": 0.935904,
        "f1": 0.919246,
        "accuracy": 0.935904,
        "main_score": 0.919246,
        "hf_subset": "bel_Cyrl-ukr_Cyrl",
        "languages": [
          "bel-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.254996,
        "recall": 0.274412,
        "f1": 0.258861,
        "accuracy": 0.274412,
        "main_score": 0.258861,
        "hf_subset": "bos_Latn-ukr_Cyrl",
        "languages": [
          "bos-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.935834,
        "recall": 0.952429,
        "f1": 0.941128,
        "accuracy": 0.952429,
        "main_score": 0.941128,
        "hf_subset": "bul_Cyrl-ukr_Cyrl",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.473592,
        "recall": 0.50025,
        "f1": 0.480333,
        "accuracy": 0.50025,
        "main_score": 0.480333,
        "hf_subset": "ces_Latn-ukr_Cyrl",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.973377,
        "recall": 0.981973,
        "f1": 0.976214,
        "accuracy": 0.981973,
        "main_score": 0.976214,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.273023,
        "recall": 0.295443,
        "f1": 0.277899,
        "accuracy": 0.295443,
        "main_score": 0.277899,
        "hf_subset": "hrv_Latn-ukr_Cyrl",
        "languages": [
          "hrv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.92543,
        "recall": 0.944417,
        "f1": 0.931178,
        "accuracy": 0.944417,
        "main_score": 0.931178,
        "hf_subset": "mkd_Cyrl-ukr_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.675066,
        "recall": 0.704557,
        "f1": 0.683195,
        "accuracy": 0.704557,
        "main_score": 0.683195,
        "hf_subset": "pol_Latn-ukr_Cyrl",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.948957,
        "recall": 0.962444,
        "f1": 0.953263,
        "accuracy": 0.962444,
        "main_score": 0.953263,
        "hf_subset": "rus_Cyrl-ukr_Cyrl",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.378975,
        "recall": 0.401602,
        "f1": 0.384196,
        "accuracy": 0.401602,
        "main_score": 0.384196,
        "hf_subset": "slk_Latn-ukr_Cyrl",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.139225,
        "recall": 0.153731,
        "f1": 0.142012,
        "accuracy": 0.153731,
        "main_score": 0.142012,
        "hf_subset": "slv_Latn-ukr_Cyrl",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.681534,
        "recall": 0.710566,
        "f1": 0.689937,
        "accuracy": 0.710566,
        "main_score": 0.689937,
        "hf_subset": "srp_Cyrl-ukr_Cyrl",
        "languages": [
          "srp-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.14935,
        "recall": 0.165749,
        "f1": 0.152616,
        "accuracy": 0.165749,
        "main_score": 0.152616,
        "hf_subset": "srp_Latn-ukr_Cyrl",
        "languages": [
          "srp-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.897596,
        "recall": 0.928893,
        "f1": 0.907661,
        "accuracy": 0.928893,
        "main_score": 0.907661,
        "hf_subset": "ukr_Cyrl-bel_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.36087,
        "recall": 0.462694,
        "f1": 0.384369,
        "accuracy": 0.462694,
        "main_score": 0.384369,
        "hf_subset": "ukr_Cyrl-bos_Latn",
        "languages": [
          "ukr-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.93557,
        "recall": 0.952929,
        "f1": 0.941245,
        "accuracy": 0.952929,
        "main_score": 0.941245,
        "hf_subset": "ukr_Cyrl-bul_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.480643,
        "recall": 0.581873,
        "f1": 0.50633,
        "accuracy": 0.581873,
        "main_score": 0.50633,
        "hf_subset": "ukr_Cyrl-ces_Latn",
        "languages": [
          "ukr-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.963946,
        "recall": 0.974962,
        "f1": 0.967535,
        "accuracy": 0.974962,
        "main_score": 0.967535,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.379677,
        "recall": 0.481723,
        "f1": 0.403593,
        "accuracy": 0.481723,
        "main_score": 0.403593,
        "hf_subset": "ukr_Cyrl-hrv_Latn",
        "languages": [
          "ukr-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.912427,
        "recall": 0.938408,
        "f1": 0.920831,
        "accuracy": 0.938408,
        "main_score": 0.920831,
        "hf_subset": "ukr_Cyrl-mkd_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.623523,
        "recall": 0.714071,
        "f1": 0.648916,
        "accuracy": 0.714071,
        "main_score": 0.648916,
        "hf_subset": "ukr_Cyrl-pol_Latn",
        "languages": [
          "ukr-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.94087,
        "recall": 0.958438,
        "f1": 0.94662,
        "accuracy": 0.958438,
        "main_score": 0.94662,
        "hf_subset": "ukr_Cyrl-rus_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.470166,
        "recall": 0.568853,
        "f1": 0.495015,
        "accuracy": 0.568853,
        "main_score": 0.495015,
        "hf_subset": "ukr_Cyrl-slk_Latn",
        "languages": [
          "ukr-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.273682,
        "recall": 0.37306,
        "f1": 0.295325,
        "accuracy": 0.37306,
        "main_score": 0.295325,
        "hf_subset": "ukr_Cyrl-slv_Latn",
        "languages": [
          "ukr-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.629609,
        "recall": 0.722584,
        "f1": 0.656204,
        "accuracy": 0.722584,
        "main_score": 0.656204,
        "hf_subset": "ukr_Cyrl-srp_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.28929,
        "recall": 0.385078,
        "f1": 0.310069,
        "accuracy": 0.385078,
        "main_score": 0.310069,
        "hf_subset": "ukr_Cyrl-srp_Latn",
        "languages": [
          "ukr-Cyrl",
          "srp-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 87.85017442703247,
  "kg_co2_emissions": null
}