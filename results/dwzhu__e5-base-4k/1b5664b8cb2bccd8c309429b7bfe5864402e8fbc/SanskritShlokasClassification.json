{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.663708,
        "f1": 0.66346,
        "f1_weighted": 0.663975,
        "scores_per_experiment": [
          {
            "accuracy": 0.652742,
            "f1": 0.654594,
            "f1_weighted": 0.653642
          },
          {
            "accuracy": 0.699739,
            "f1": 0.697439,
            "f1_weighted": 0.696945
          },
          {
            "accuracy": 0.697128,
            "f1": 0.69855,
            "f1_weighted": 0.699907
          },
          {
            "accuracy": 0.616188,
            "f1": 0.612718,
            "f1_weighted": 0.610241
          },
          {
            "accuracy": 0.665796,
            "f1": 0.670688,
            "f1_weighted": 0.669235
          },
          {
            "accuracy": 0.637076,
            "f1": 0.642793,
            "f1_weighted": 0.643517
          },
          {
            "accuracy": 0.697128,
            "f1": 0.697878,
            "f1_weighted": 0.698733
          },
          {
            "accuracy": 0.657963,
            "f1": 0.651921,
            "f1_weighted": 0.653376
          },
          {
            "accuracy": 0.671018,
            "f1": 0.670694,
            "f1_weighted": 0.672561
          },
          {
            "accuracy": 0.642298,
            "f1": 0.637325,
            "f1_weighted": 0.641595
          }
        ],
        "main_score": 0.663708,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.673958,
        "f1": 0.680054,
        "f1_weighted": 0.671385,
        "scores_per_experiment": [
          {
            "accuracy": 0.604167,
            "f1": 0.61903,
            "f1_weighted": 0.606579
          },
          {
            "accuracy": 0.697917,
            "f1": 0.701664,
            "f1_weighted": 0.691734
          },
          {
            "accuracy": 0.645833,
            "f1": 0.659855,
            "f1_weighted": 0.647213
          },
          {
            "accuracy": 0.71875,
            "f1": 0.72736,
            "f1_weighted": 0.718155
          },
          {
            "accuracy": 0.625,
            "f1": 0.640242,
            "f1_weighted": 0.621631
          },
          {
            "accuracy": 0.572917,
            "f1": 0.583182,
            "f1_weighted": 0.574618
          },
          {
            "accuracy": 0.739583,
            "f1": 0.747947,
            "f1_weighted": 0.738931
          },
          {
            "accuracy": 0.6875,
            "f1": 0.681559,
            "f1_weighted": 0.679719
          },
          {
            "accuracy": 0.822917,
            "f1": 0.826841,
            "f1_weighted": 0.822337
          },
          {
            "accuracy": 0.625,
            "f1": 0.61286,
            "f1_weighted": 0.612928
          }
        ],
        "main_score": 0.673958,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 13.563729286193848,
  "kg_co2_emissions": 0.0003910991119333431
}