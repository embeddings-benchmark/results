{
  "dataset_revision": "cf24d44e517efa534f048e5fc5981f399ed25bee",
  "task_name": "CataloniaTweetClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.480794,
        "f1": 0.491955,
        "f1_weighted": 0.477402,
        "scores_per_experiment": [
          {
            "accuracy": 0.515633,
            "f1": 0.52558,
            "f1_weighted": 0.515339
          },
          {
            "accuracy": 0.507196,
            "f1": 0.517115,
            "f1_weighted": 0.50712
          },
          {
            "accuracy": 0.454094,
            "f1": 0.455974,
            "f1_weighted": 0.444746
          },
          {
            "accuracy": 0.469479,
            "f1": 0.493323,
            "f1_weighted": 0.474024
          },
          {
            "accuracy": 0.474442,
            "f1": 0.48638,
            "f1_weighted": 0.472774
          },
          {
            "accuracy": 0.530521,
            "f1": 0.546032,
            "f1_weighted": 0.530895
          },
          {
            "accuracy": 0.453598,
            "f1": 0.462419,
            "f1_weighted": 0.445525
          },
          {
            "accuracy": 0.452605,
            "f1": 0.451239,
            "f1_weighted": 0.439441
          },
          {
            "accuracy": 0.470471,
            "f1": 0.482935,
            "f1_weighted": 0.468249
          },
          {
            "accuracy": 0.479901,
            "f1": 0.498549,
            "f1_weighted": 0.475907
          }
        ],
        "main_score": 0.480794,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ]
      },
      {
        "accuracy": 0.460945,
        "f1": 0.45487,
        "f1_weighted": 0.459472,
        "scores_per_experiment": [
          {
            "accuracy": 0.459701,
            "f1": 0.45682,
            "f1_weighted": 0.457595
          },
          {
            "accuracy": 0.447264,
            "f1": 0.44084,
            "f1_weighted": 0.448146
          },
          {
            "accuracy": 0.448756,
            "f1": 0.445093,
            "f1_weighted": 0.445458
          },
          {
            "accuracy": 0.501493,
            "f1": 0.499327,
            "f1_weighted": 0.49858
          },
          {
            "accuracy": 0.458706,
            "f1": 0.446167,
            "f1_weighted": 0.458274
          },
          {
            "accuracy": 0.455224,
            "f1": 0.449399,
            "f1_weighted": 0.455798
          },
          {
            "accuracy": 0.423881,
            "f1": 0.418962,
            "f1_weighted": 0.42314
          },
          {
            "accuracy": 0.441294,
            "f1": 0.442428,
            "f1_weighted": 0.43688
          },
          {
            "accuracy": 0.479602,
            "f1": 0.469187,
            "f1_weighted": 0.481351
          },
          {
            "accuracy": 0.493532,
            "f1": 0.480478,
            "f1_weighted": 0.489493
          }
        ],
        "main_score": 0.460945,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.490526,
        "f1": 0.505258,
        "f1_weighted": 0.487236,
        "scores_per_experiment": [
          {
            "accuracy": 0.499504,
            "f1": 0.510203,
            "f1_weighted": 0.498821
          },
          {
            "accuracy": 0.50744,
            "f1": 0.51801,
            "f1_weighted": 0.506903
          },
          {
            "accuracy": 0.456845,
            "f1": 0.45699,
            "f1_weighted": 0.446682
          },
          {
            "accuracy": 0.468254,
            "f1": 0.498955,
            "f1_weighted": 0.47397
          },
          {
            "accuracy": 0.482143,
            "f1": 0.500188,
            "f1_weighted": 0.480087
          },
          {
            "accuracy": 0.525298,
            "f1": 0.550784,
            "f1_weighted": 0.526455
          },
          {
            "accuracy": 0.487599,
            "f1": 0.499884,
            "f1_weighted": 0.478036
          },
          {
            "accuracy": 0.462798,
            "f1": 0.467063,
            "f1_weighted": 0.452765
          },
          {
            "accuracy": 0.491567,
            "f1": 0.504521,
            "f1_weighted": 0.488093
          },
          {
            "accuracy": 0.52381,
            "f1": 0.545979,
            "f1_weighted": 0.520545
          }
        ],
        "main_score": 0.490526,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ]
      },
      {
        "accuracy": 0.464478,
        "f1": 0.458195,
        "f1_weighted": 0.462148,
        "scores_per_experiment": [
          {
            "accuracy": 0.474627,
            "f1": 0.46639,
            "f1_weighted": 0.470951
          },
          {
            "accuracy": 0.447761,
            "f1": 0.445445,
            "f1_weighted": 0.447932
          },
          {
            "accuracy": 0.469652,
            "f1": 0.465969,
            "f1_weighted": 0.467087
          },
          {
            "accuracy": 0.504975,
            "f1": 0.497368,
            "f1_weighted": 0.499925
          },
          {
            "accuracy": 0.454229,
            "f1": 0.445643,
            "f1_weighted": 0.455378
          },
          {
            "accuracy": 0.463682,
            "f1": 0.456463,
            "f1_weighted": 0.463544
          },
          {
            "accuracy": 0.423881,
            "f1": 0.415112,
            "f1_weighted": 0.425133
          },
          {
            "accuracy": 0.438806,
            "f1": 0.441177,
            "f1_weighted": 0.431725
          },
          {
            "accuracy": 0.470149,
            "f1": 0.467645,
            "f1_weighted": 0.470799
          },
          {
            "accuracy": 0.497015,
            "f1": 0.480737,
            "f1_weighted": 0.489006
          }
        ],
        "main_score": 0.464478,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.99094533920288,
  "kg_co2_emissions": 0.0008204593630431642
}