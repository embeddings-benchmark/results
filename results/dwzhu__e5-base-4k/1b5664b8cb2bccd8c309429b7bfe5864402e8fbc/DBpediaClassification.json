{
  "dataset_revision": "9abd46cf7fc8b4c64290f26993c540b92aa145ac",
  "task_name": "DBpediaClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.920605,
        "f1": 0.918994,
        "f1_weighted": 0.91899,
        "scores_per_experiment": [
          {
            "accuracy": 0.930176,
            "f1": 0.928823,
            "f1_weighted": 0.92883
          },
          {
            "accuracy": 0.934082,
            "f1": 0.933359,
            "f1_weighted": 0.933351
          },
          {
            "accuracy": 0.922852,
            "f1": 0.921986,
            "f1_weighted": 0.921981
          },
          {
            "accuracy": 0.910645,
            "f1": 0.909686,
            "f1_weighted": 0.909656
          },
          {
            "accuracy": 0.932617,
            "f1": 0.931951,
            "f1_weighted": 0.931966
          },
          {
            "accuracy": 0.928223,
            "f1": 0.926337,
            "f1_weighted": 0.926322
          },
          {
            "accuracy": 0.913574,
            "f1": 0.911905,
            "f1_weighted": 0.911919
          },
          {
            "accuracy": 0.90918,
            "f1": 0.906841,
            "f1_weighted": 0.906851
          },
          {
            "accuracy": 0.90625,
            "f1": 0.903061,
            "f1_weighted": 0.903046
          },
          {
            "accuracy": 0.918457,
            "f1": 0.915992,
            "f1_weighted": 0.915982
          }
        ],
        "main_score": 0.920605,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.28165578842163,
  "kg_co2_emissions": 0.0003835831501650339
}