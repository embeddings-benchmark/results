{
  "dataset_revision": "f333c1fcfa3ab43f008a327c8bd0140441354d34",
  "task_name": "BrazilianToxicTweetsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.191113,
        "f1": 0.164857,
        "lrap": 0.796332,
        "scores_per_experiment": [
          {
            "accuracy": 0.172363,
            "f1": 0.169354,
            "lrap": 0.812826
          },
          {
            "accuracy": 0.134766,
            "f1": 0.142788,
            "lrap": 0.785889
          },
          {
            "accuracy": 0.148438,
            "f1": 0.160251,
            "lrap": 0.812039
          },
          {
            "accuracy": 0.144531,
            "f1": 0.149956,
            "lrap": 0.819539
          },
          {
            "accuracy": 0.262695,
            "f1": 0.179123,
            "lrap": 0.807739
          },
          {
            "accuracy": 0.17041,
            "f1": 0.140473,
            "lrap": 0.783529
          },
          {
            "accuracy": 0.307617,
            "f1": 0.154615,
            "lrap": 0.746419
          },
          {
            "accuracy": 0.094238,
            "f1": 0.201643,
            "lrap": 0.803507
          },
          {
            "accuracy": 0.223633,
            "f1": 0.162121,
            "lrap": 0.78772
          },
          {
            "accuracy": 0.252441,
            "f1": 0.188246,
            "lrap": 0.804118
          }
        ],
        "main_score": 0.191113,
        "hf_subset": "default",
        "languages": [
          "por-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 3.8550562858581543,
  "kg_co2_emissions": 0.00014308252861953895
}