{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.131804,
        "mrr": 0.115086,
        "nAUC_map_max": 0.147051,
        "nAUC_map_std": -0.023265,
        "nAUC_map_diff1": 0.165218,
        "nAUC_mrr_max": 0.142577,
        "nAUC_mrr_std": -0.031414,
        "nAUC_mrr_diff1": 0.159066,
        "main_score": 0.115086,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.104195,
        "mrr": 0.087856,
        "nAUC_map_max": 0.094601,
        "nAUC_map_std": 0.06334,
        "nAUC_map_diff1": 0.096919,
        "nAUC_mrr_max": 0.106426,
        "nAUC_mrr_std": 0.050825,
        "nAUC_mrr_diff1": 0.104404,
        "main_score": 0.087856,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.085516,
        "mrr": 0.070771,
        "nAUC_map_max": 0.181811,
        "nAUC_map_std": 0.291664,
        "nAUC_map_diff1": 0.235699,
        "nAUC_mrr_max": 0.184997,
        "nAUC_mrr_std": 0.280483,
        "nAUC_mrr_diff1": 0.225121,
        "main_score": 0.070771,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.09566,
        "mrr": 0.076215,
        "nAUC_map_max": 0.035405,
        "nAUC_map_std": 0.014815,
        "nAUC_map_diff1": 0.140464,
        "nAUC_mrr_max": 0.043017,
        "nAUC_mrr_std": 0.013208,
        "nAUC_mrr_diff1": 0.144728,
        "main_score": 0.076215,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.110854,
        "mrr": 0.093643,
        "nAUC_map_max": 0.083088,
        "nAUC_map_std": 0.128126,
        "nAUC_map_diff1": 0.142684,
        "nAUC_mrr_max": 0.088443,
        "nAUC_mrr_std": 0.110204,
        "nAUC_mrr_diff1": 0.149979,
        "main_score": 0.093643,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.091896,
        "mrr": 0.077724,
        "nAUC_map_max": 0.052453,
        "nAUC_map_std": -0.001686,
        "nAUC_map_diff1": 0.137478,
        "nAUC_mrr_max": 0.074116,
        "nAUC_mrr_std": -0.010764,
        "nAUC_mrr_diff1": 0.147317,
        "main_score": 0.077724,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 2495.3218824863434,
  "kg_co2_emissions": 0.21381573197421008
}