{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.119624,
        "mrr": 0.10201,
        "nAUC_map_max": 0.044333,
        "nAUC_map_std": -0.066821,
        "nAUC_map_diff1": 0.179344,
        "nAUC_mrr_max": 0.045005,
        "nAUC_mrr_std": -0.073401,
        "nAUC_mrr_diff1": 0.183794,
        "main_score": 0.10201,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.12011,
        "mrr": 0.099733,
        "nAUC_map_max": 0.078307,
        "nAUC_map_std": 0.161815,
        "nAUC_map_diff1": 0.116219,
        "nAUC_mrr_max": 0.088109,
        "nAUC_mrr_std": 0.153451,
        "nAUC_mrr_diff1": 0.113191,
        "main_score": 0.099733,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.105877,
        "mrr": 0.092423,
        "nAUC_map_max": 0.013543,
        "nAUC_map_std": 0.219811,
        "nAUC_map_diff1": 0.161609,
        "nAUC_mrr_max": 0.005095,
        "nAUC_mrr_std": 0.223955,
        "nAUC_mrr_diff1": 0.163984,
        "main_score": 0.092423,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.121674,
        "mrr": 0.105208,
        "nAUC_map_max": -0.056219,
        "nAUC_map_std": 0.007306,
        "nAUC_map_diff1": 0.002888,
        "nAUC_mrr_max": -0.053719,
        "nAUC_mrr_std": 0.005313,
        "nAUC_mrr_diff1": -0.004451,
        "main_score": 0.105208,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.118079,
        "mrr": 0.101237,
        "nAUC_map_max": -0.102777,
        "nAUC_map_std": 0.158476,
        "nAUC_map_diff1": 0.129507,
        "nAUC_mrr_max": -0.103403,
        "nAUC_mrr_std": 0.161052,
        "nAUC_mrr_diff1": 0.130034,
        "main_score": 0.101237,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.096257,
        "mrr": 0.079688,
        "nAUC_map_max": 0.028385,
        "nAUC_map_std": 0.0666,
        "nAUC_map_diff1": 0.082697,
        "nAUC_mrr_max": 0.0276,
        "nAUC_mrr_std": 0.066723,
        "nAUC_mrr_diff1": 0.082547,
        "main_score": 0.079688,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 593.5479531288147,
  "kg_co2_emissions": 0.026526040125882368
}