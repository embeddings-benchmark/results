{
  "dataset_revision": "0c47583c9d339b3b6f89e4db76088af5f1ec8d39",
  "task_name": "SlovakMovieReviewSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.531006,
        "f1": 0.524384,
        "f1_weighted": 0.530103,
        "ap": 0.425535,
        "ap_weighted": 0.425535,
        "scores_per_experiment": [
          {
            "accuracy": 0.555176,
            "f1": 0.544257,
            "f1_weighted": 0.55769,
            "ap": 0.429395,
            "ap_weighted": 0.429395
          },
          {
            "accuracy": 0.458008,
            "f1": 0.458006,
            "f1_weighted": 0.457804,
            "ap": 0.393611,
            "ap_weighted": 0.393611
          },
          {
            "accuracy": 0.5,
            "f1": 0.494163,
            "f1_weighted": 0.50451,
            "ap": 0.40363,
            "ap_weighted": 0.40363
          },
          {
            "accuracy": 0.571289,
            "f1": 0.55762,
            "f1_weighted": 0.572428,
            "ap": 0.437368,
            "ap_weighted": 0.437368
          },
          {
            "accuracy": 0.547363,
            "f1": 0.536253,
            "f1_weighted": 0.549922,
            "ap": 0.424614,
            "ap_weighted": 0.424614
          },
          {
            "accuracy": 0.549805,
            "f1": 0.5402,
            "f1_weighted": 0.552855,
            "ap": 0.42723,
            "ap_weighted": 0.42723
          },
          {
            "accuracy": 0.508301,
            "f1": 0.508287,
            "f1_weighted": 0.507784,
            "ap": 0.419288,
            "ap_weighted": 0.419288
          },
          {
            "accuracy": 0.57959,
            "f1": 0.574454,
            "f1_weighted": 0.583356,
            "ap": 0.450691,
            "ap_weighted": 0.450691
          },
          {
            "accuracy": 0.510742,
            "f1": 0.501287,
            "f1_weighted": 0.48821,
            "ap": 0.434891,
            "ap_weighted": 0.434891
          },
          {
            "accuracy": 0.529785,
            "f1": 0.529311,
            "f1_weighted": 0.526466,
            "ap": 0.434634,
            "ap_weighted": 0.434634
          }
        ],
        "main_score": 0.531006,
        "hf_subset": "default",
        "languages": [
          "svk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.861545085906982,
  "kg_co2_emissions": 0.00023078668980487457
}