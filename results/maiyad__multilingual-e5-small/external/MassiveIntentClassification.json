{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.5706792199058508,
                "f1": 0.5409492185750229,
                "main_score": 0.5706792199058508
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.5196032279757903,
                "f1": 0.48547371223370944,
                "main_score": 0.5196032279757903
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.544250168123739,
                "f1": 0.5047069202054312,
                "main_score": 0.544250168123739
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.5979825151311365,
                "f1": 0.5705013069086649,
                "main_score": 0.5979825151311365
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.5937794216543376,
                "f1": 0.563607992649805,
                "main_score": 0.5937794216543376
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.4656018829858777,
                "f1": 0.4387319715715134,
                "main_score": 0.4656018829858777
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.629724277067922,
                "f1": 0.5936480066245562,
                "main_score": 0.629724277067922
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.6272696704774715,
                "f1": 0.5914359596661586,
                "main_score": 0.6272696704774715
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.615971755211836,
                "f1": 0.5916944572494672,
                "main_score": 0.615971755211836
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.7029589778076665,
                "f1": 0.677577001808977,
                "main_score": 0.7029589778076665
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.6631136516476126,
                "f1": 0.6452032955983242,
                "main_score": 0.6631136516476126
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.6554472091459315,
                "f1": 0.6147903120066317,
                "main_score": 0.6554472091459315
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.6145595158036314,
                "f1": 0.5808918460246371,
                "main_score": 0.6145595158036314
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.6547074646940149,
                "f1": 0.6284830858877575,
                "main_score": 0.6547074646940149
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.5804640215198386,
                "f1": 0.5526907443053319,
                "main_score": 0.5804640215198386
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.6406523201075991,
                "f1": 0.6135339643021369,
                "main_score": 0.6406523201075991
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.6095494283792873,
                "f1": 0.5707035922704846,
                "main_score": 0.6095494283792873
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.5740416946872899,
                "f1": 0.5394259011839138,
                "main_score": 0.5740416946872899
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.6416610625420308,
                "f1": 0.6133710343149936,
                "main_score": 0.6416610625420308
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.5226294552790853,
                "f1": 0.497610691598921,
                "main_score": 0.5226294552790853
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.6554472091459315,
                "f1": 0.6346909901844016,
                "main_score": 0.6554472091459315
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.6822797579018157,
                "f1": 0.6489098471083001,
                "main_score": 0.6822797579018157
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.5084734364492267,
                "f1": 0.47853696316839295,
                "main_score": 0.5084734364492267
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.48453261600537995,
                "f1": 0.4637007804580556,
                "main_score": 0.48453261600537995
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.4283120376597175,
                "f1": 0.39689485215999815,
                "main_score": 0.4283120376597175
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.575084061869536,
                "f1": 0.5396187616040155,
                "main_score": 0.575084061869536
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.637895090786819,
                "f1": 0.61134223684676,
                "main_score": 0.637895090786819
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.5498991257565569,
                "f1": 0.525798628628263,
                "main_score": 0.5498991257565569
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.6190316072629456,
                "f1": 0.5820302453829034,
                "main_score": 0.6190316072629456
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.5709818426361802,
                "f1": 0.5422718458445455,
                "main_score": 0.5709818426361802
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.5899125756556826,
                "f1": 0.5584892781767421,
                "main_score": 0.5899125756556826
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.5590114324142569,
                "f1": 0.5225264332199797,
                "main_score": 0.5590114324142569
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.6196368527236047,
                "f1": 0.5892724387615346,
                "main_score": 0.6196368527236047
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.6564223268325489,
                "f1": 0.6234045371837971,
                "main_score": 0.6564223268325489
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.6452589105581709,
                "f1": 0.6166111318702218,
                "main_score": 0.6452589105581709
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.668459986550101,
                "f1": 0.6459342572873006,
                "main_score": 0.668459986550101
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.6081035642232684,
                "f1": 0.575169089806797,
                "main_score": 0.6081035642232684
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.6575991930060525,
                "f1": 0.6289531115787937,
                "main_score": 0.6575991930060525
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.5651647612642906,
                "f1": 0.5433154780100043,
                "main_score": 0.5651647612642906
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.5798587760591796,
                "f1": 0.5446187524463802,
                "main_score": 0.5798587760591796
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.6503026227303296,
                "f1": 0.6234377392877748,
                "main_score": 0.6503026227303296
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.5356758574310693,
                "f1": 0.5073770655983206,
                "main_score": 0.5356758574310693
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.572595830531271,
                "f1": 0.5365732729170862,
                "main_score": 0.572595830531271
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.5782784129119032,
                "f1": 0.5482518072665301,
                "main_score": 0.5782784129119032
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.6406859448554136,
                "f1": 0.6300185280500495,
                "main_score": 0.6406859448554136
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.5891055817081371,
                "f1": 0.5554116301224262,
                "main_score": 0.5891055817081371
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.6354404841963686,
                "f1": 0.5957650946030184,
                "main_score": 0.6354404841963686
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.5927706792199059,
                "f1": 0.5650010066083435,
                "main_score": 0.5927706792199059
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.640719569603228,
                "f1": 0.6181707592564796,
                "main_score": 0.640719569603228
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.6823806321452591,
                "f1": 0.6524917026029748,
                "main_score": 0.6823806321452591
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6253530598520511,
                "f1": 0.6171131132295767,
                "main_score": 0.6253530598520511
            }
        ]
    }
}