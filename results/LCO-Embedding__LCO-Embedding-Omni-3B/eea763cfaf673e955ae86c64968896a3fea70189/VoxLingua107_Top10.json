{
  "dataset_revision": "d934546d059e16c9a4669adbd518e0fa86a69ff0",
  "task_name": "VoxLingua107_Top10",
  "mteb_version": "2.4.2",
  "scores": {
    "train": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.651282,
            "f1": 0.64425,
            "f1_weighted": 0.654847,
            "precision": 0.654795,
            "precision_weighted": 0.67317,
            "recall": 0.649187,
            "recall_weighted": 0.651282,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.538462,
            "f1": 0.524156,
            "f1_weighted": 0.537721,
            "precision": 0.569843,
            "precision_weighted": 0.585186,
            "recall": 0.525578,
            "recall_weighted": 0.538462,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.675258,
            "f1": 0.663808,
            "f1_weighted": 0.677404,
            "precision": 0.681008,
            "precision_weighted": 0.691965,
            "recall": 0.658983,
            "recall_weighted": 0.675258,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.582474,
            "f1": 0.579041,
            "f1_weighted": 0.588142,
            "precision": 0.60791,
            "precision_weighted": 0.61708,
            "recall": 0.574351,
            "recall_weighted": 0.582474,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.613402,
            "f1": 0.587471,
            "f1_weighted": 0.622059,
            "precision": 0.608375,
            "precision_weighted": 0.648388,
            "recall": 0.584692,
            "recall_weighted": 0.613402,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.612176,
        "f1": 0.599745,
        "f1_weighted": 0.616035,
        "precision": 0.624386,
        "precision_weighted": 0.643158,
        "recall": 0.598558,
        "recall_weighted": 0.612176,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.612176,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 252.79410791397095,
  "kg_co2_emissions": null
}