{
  "dataset_revision": "3ac713aa0829eeadda73182f38bbbd788d21254b",
  "task_name": "SpeechCommands",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.945808,
            "f1": 0.891121,
            "f1_weighted": 0.955869,
            "precision": 0.892609,
            "precision_weighted": 0.98119,
            "recall": 0.94821,
            "recall_weighted": 0.945808,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.969325,
            "f1": 0.929365,
            "f1_weighted": 0.973208,
            "precision": 0.919515,
            "precision_weighted": 0.979606,
            "recall": 0.962232,
            "recall_weighted": 0.969325,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.941309,
            "f1": 0.908154,
            "f1_weighted": 0.942145,
            "precision": 0.890253,
            "precision_weighted": 0.956244,
            "recall": 0.955939,
            "recall_weighted": 0.941309,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.953783,
            "f1": 0.892198,
            "f1_weighted": 0.961959,
            "precision": 0.868924,
            "precision_weighted": 0.977779,
            "recall": 0.961469,
            "recall_weighted": 0.953783,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.935787,
            "f1": 0.871733,
            "f1_weighted": 0.941185,
            "precision": 0.856285,
            "precision_weighted": 0.96408,
            "recall": 0.948644,
            "recall_weighted": 0.935787,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.946217,
            "f1": 0.930145,
            "f1_weighted": 0.94471,
            "precision": 0.925744,
            "precision_weighted": 0.957696,
            "recall": 0.953818,
            "recall_weighted": 0.946217,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.924335,
            "f1": 0.869244,
            "f1_weighted": 0.940346,
            "precision": 0.861541,
            "precision_weighted": 0.984951,
            "recall": 0.956735,
            "recall_weighted": 0.924335,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.940286,
            "f1": 0.883365,
            "f1_weighted": 0.953322,
            "precision": 0.86809,
            "precision_weighted": 0.981849,
            "recall": 0.957148,
            "recall_weighted": 0.940286,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.954192,
            "f1": 0.918509,
            "f1_weighted": 0.955437,
            "precision": 0.899391,
            "precision_weighted": 0.964019,
            "recall": 0.961822,
            "recall_weighted": 0.954192,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.929243,
            "f1": 0.905078,
            "f1_weighted": 0.932316,
            "precision": 0.892751,
            "precision_weighted": 0.958204,
            "recall": 0.953533,
            "recall_weighted": 0.929243,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.944029,
        "f1": 0.899891,
        "f1_weighted": 0.95005,
        "precision": 0.88751,
        "precision_weighted": 0.970562,
        "recall": 0.955955,
        "recall_weighted": 0.944029,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.944029,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 691.4700577259064,
  "kg_co2_emissions": null
}