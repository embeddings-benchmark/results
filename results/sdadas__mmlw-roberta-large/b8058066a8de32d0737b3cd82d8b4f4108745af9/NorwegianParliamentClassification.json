{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.536333,
        "f1": 0.53142,
        "f1_weighted": 0.53142,
        "ap": 0.520012,
        "ap_weighted": 0.520012,
        "scores_per_experiment": [
          {
            "accuracy": 0.530833,
            "f1": 0.529453,
            "f1_weighted": 0.529453,
            "ap": 0.516483,
            "ap_weighted": 0.516483
          },
          {
            "accuracy": 0.539167,
            "f1": 0.539025,
            "f1_weighted": 0.539025,
            "ap": 0.521173,
            "ap_weighted": 0.521173
          },
          {
            "accuracy": 0.574167,
            "f1": 0.572497,
            "f1_weighted": 0.572497,
            "ap": 0.541973,
            "ap_weighted": 0.541973
          },
          {
            "accuracy": 0.5075,
            "f1": 0.504261,
            "f1_weighted": 0.504261,
            "ap": 0.503817,
            "ap_weighted": 0.503817
          },
          {
            "accuracy": 0.566667,
            "f1": 0.566647,
            "f1_weighted": 0.566647,
            "ap": 0.537719,
            "ap_weighted": 0.537719
          },
          {
            "accuracy": 0.52,
            "f1": 0.503927,
            "f1_weighted": 0.503927,
            "ap": 0.510294,
            "ap_weighted": 0.510294
          },
          {
            "accuracy": 0.506667,
            "f1": 0.504464,
            "f1_weighted": 0.504464,
            "ap": 0.503373,
            "ap_weighted": 0.503373
          },
          {
            "accuracy": 0.499167,
            "f1": 0.496641,
            "f1_weighted": 0.496641,
            "ap": 0.499584,
            "ap_weighted": 0.499584
          },
          {
            "accuracy": 0.579167,
            "f1": 0.571256,
            "f1_weighted": 0.571256,
            "ap": 0.544512,
            "ap_weighted": 0.544512
          },
          {
            "accuracy": 0.54,
            "f1": 0.526032,
            "f1_weighted": 0.526032,
            "ap": 0.521191,
            "ap_weighted": 0.521191
          }
        ],
        "main_score": 0.536333,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.538083,
        "f1": 0.534233,
        "f1_weighted": 0.534233,
        "ap": 0.522133,
        "ap_weighted": 0.522133,
        "scores_per_experiment": [
          {
            "accuracy": 0.541667,
            "f1": 0.537493,
            "f1_weighted": 0.537493,
            "ap": 0.522977,
            "ap_weighted": 0.522977
          },
          {
            "accuracy": 0.530833,
            "f1": 0.530285,
            "f1_weighted": 0.530285,
            "ap": 0.516437,
            "ap_weighted": 0.516437
          },
          {
            "accuracy": 0.580833,
            "f1": 0.580784,
            "f1_weighted": 0.580784,
            "ap": 0.546812,
            "ap_weighted": 0.546812
          },
          {
            "accuracy": 0.5125,
            "f1": 0.510787,
            "f1_weighted": 0.510787,
            "ap": 0.506427,
            "ap_weighted": 0.506427
          },
          {
            "accuracy": 0.5975,
            "f1": 0.597231,
            "f1_weighted": 0.597231,
            "ap": 0.558774,
            "ap_weighted": 0.558774
          },
          {
            "accuracy": 0.510833,
            "f1": 0.501172,
            "f1_weighted": 0.501172,
            "ap": 0.505508,
            "ap_weighted": 0.505508
          },
          {
            "accuracy": 0.511667,
            "f1": 0.508779,
            "f1_weighted": 0.508779,
            "ap": 0.505951,
            "ap_weighted": 0.505951
          },
          {
            "accuracy": 0.465833,
            "f1": 0.462464,
            "f1_weighted": 0.462464,
            "ap": 0.484304,
            "ap_weighted": 0.484304
          },
          {
            "accuracy": 0.603333,
            "f1": 0.600094,
            "f1_weighted": 0.600094,
            "ap": 0.560716,
            "ap_weighted": 0.560716
          },
          {
            "accuracy": 0.525833,
            "f1": 0.513242,
            "f1_weighted": 0.513242,
            "ap": 0.513422,
            "ap_weighted": 0.513422
          }
        ],
        "main_score": 0.538083,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 30.80148983001709,
  "kg_co2_emissions": 0.002068404203846988
}