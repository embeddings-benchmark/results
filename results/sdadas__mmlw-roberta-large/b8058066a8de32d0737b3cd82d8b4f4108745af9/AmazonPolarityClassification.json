{
  "dataset_revision": "e2d317d38cd51312af73b3d32a06d1a08b442046",
  "task_name": "AmazonPolarityClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.915097,
        "f1": 0.914843,
        "f1_weighted": 0.914843,
        "ap": 0.875143,
        "ap_weighted": 0.875143,
        "scores_per_experiment": [
          {
            "accuracy": 0.912013,
            "f1": 0.911986,
            "f1_weighted": 0.911986,
            "ap": 0.88182,
            "ap_weighted": 0.88182
          },
          {
            "accuracy": 0.931257,
            "f1": 0.931184,
            "f1_weighted": 0.931184,
            "ap": 0.890229,
            "ap_weighted": 0.890229
          },
          {
            "accuracy": 0.933192,
            "f1": 0.933162,
            "f1_weighted": 0.933162,
            "ap": 0.912625,
            "ap_weighted": 0.912625
          },
          {
            "accuracy": 0.929898,
            "f1": 0.929838,
            "f1_weighted": 0.929838,
            "ap": 0.911195,
            "ap_weighted": 0.911195
          },
          {
            "accuracy": 0.91154,
            "f1": 0.911522,
            "f1_weighted": 0.911522,
            "ap": 0.880127,
            "ap_weighted": 0.880127
          },
          {
            "accuracy": 0.924277,
            "f1": 0.924179,
            "f1_weighted": 0.924179,
            "ap": 0.88007,
            "ap_weighted": 0.88007
          },
          {
            "accuracy": 0.920415,
            "f1": 0.920318,
            "f1_weighted": 0.920318,
            "ap": 0.875429,
            "ap_weighted": 0.875429
          },
          {
            "accuracy": 0.922545,
            "f1": 0.922334,
            "f1_weighted": 0.922334,
            "ap": 0.872967,
            "ap_weighted": 0.872967
          },
          {
            "accuracy": 0.894783,
            "f1": 0.894774,
            "f1_weighted": 0.894774,
            "ap": 0.850566,
            "ap_weighted": 0.850566
          },
          {
            "accuracy": 0.871047,
            "f1": 0.869136,
            "f1_weighted": 0.869136,
            "ap": 0.796399,
            "ap_weighted": 0.796399
          }
        ],
        "main_score": 0.915097,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1110.7713181972504,
  "kg_co2_emissions": 0.09799722722709865
}