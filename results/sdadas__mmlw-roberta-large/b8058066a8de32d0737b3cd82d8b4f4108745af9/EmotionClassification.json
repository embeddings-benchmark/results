{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.53425,
        "f1": 0.497444,
        "f1_weighted": 0.551383,
        "scores_per_experiment": [
          {
            "accuracy": 0.5655,
            "f1": 0.520254,
            "f1_weighted": 0.58111
          },
          {
            "accuracy": 0.5535,
            "f1": 0.510717,
            "f1_weighted": 0.565447
          },
          {
            "accuracy": 0.539,
            "f1": 0.492147,
            "f1_weighted": 0.556882
          },
          {
            "accuracy": 0.5275,
            "f1": 0.497751,
            "f1_weighted": 0.547819
          },
          {
            "accuracy": 0.5335,
            "f1": 0.507037,
            "f1_weighted": 0.549202
          },
          {
            "accuracy": 0.5345,
            "f1": 0.499998,
            "f1_weighted": 0.551283
          },
          {
            "accuracy": 0.54,
            "f1": 0.501507,
            "f1_weighted": 0.558887
          },
          {
            "accuracy": 0.506,
            "f1": 0.470686,
            "f1_weighted": 0.522327
          },
          {
            "accuracy": 0.5475,
            "f1": 0.501967,
            "f1_weighted": 0.561903
          },
          {
            "accuracy": 0.4955,
            "f1": 0.472378,
            "f1_weighted": 0.518972
          }
        ],
        "main_score": 0.53425,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.53175,
        "f1": 0.484723,
        "f1_weighted": 0.552207,
        "scores_per_experiment": [
          {
            "accuracy": 0.55,
            "f1": 0.494421,
            "f1_weighted": 0.57096
          },
          {
            "accuracy": 0.5415,
            "f1": 0.485492,
            "f1_weighted": 0.558267
          },
          {
            "accuracy": 0.543,
            "f1": 0.487001,
            "f1_weighted": 0.563993
          },
          {
            "accuracy": 0.512,
            "f1": 0.475875,
            "f1_weighted": 0.536837
          },
          {
            "accuracy": 0.531,
            "f1": 0.492556,
            "f1_weighted": 0.55059
          },
          {
            "accuracy": 0.524,
            "f1": 0.4718,
            "f1_weighted": 0.546005
          },
          {
            "accuracy": 0.548,
            "f1": 0.500548,
            "f1_weighted": 0.570279
          },
          {
            "accuracy": 0.513,
            "f1": 0.474857,
            "f1_weighted": 0.526315
          },
          {
            "accuracy": 0.554,
            "f1": 0.498498,
            "f1_weighted": 0.571451
          },
          {
            "accuracy": 0.501,
            "f1": 0.46618,
            "f1_weighted": 0.527374
          }
        ],
        "main_score": 0.53175,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 20.839083194732666,
  "kg_co2_emissions": 0.0008457599338047658
}