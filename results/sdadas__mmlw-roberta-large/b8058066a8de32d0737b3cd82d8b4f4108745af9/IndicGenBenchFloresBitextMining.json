{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.015047,
        "recall": 0.017051,
        "f1": 0.015383,
        "accuracy": 0.017051,
        "main_score": 0.015383,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.053798,
        "recall": 0.107322,
        "f1": 0.064012,
        "accuracy": 0.107322,
        "main_score": 0.064012,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.010783,
        "recall": 0.014042,
        "f1": 0.011436,
        "accuracy": 0.014042,
        "main_score": 0.011436,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.078855,
        "recall": 0.102307,
        "f1": 0.083329,
        "accuracy": 0.102307,
        "main_score": 0.083329,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.016384,
        "recall": 0.019057,
        "f1": 0.016887,
        "accuracy": 0.019057,
        "main_score": 0.016887,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.064984,
        "recall": 0.106319,
        "f1": 0.074,
        "accuracy": 0.106319,
        "main_score": 0.074,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.024742,
        "recall": 0.028084,
        "f1": 0.025364,
        "accuracy": 0.028084,
        "main_score": 0.025364,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.074992,
        "recall": 0.10331,
        "f1": 0.080293,
        "accuracy": 0.10331,
        "main_score": 0.080293,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.022268,
        "recall": 0.026078,
        "f1": 0.023071,
        "accuracy": 0.026078,
        "main_score": 0.023071,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.080631,
        "recall": 0.104313,
        "f1": 0.085588,
        "accuracy": 0.104313,
        "main_score": 0.085588,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.014939,
        "recall": 0.018054,
        "f1": 0.015365,
        "accuracy": 0.018054,
        "main_score": 0.015365,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.055478,
        "recall": 0.086259,
        "f1": 0.061725,
        "accuracy": 0.086259,
        "main_score": 0.061725,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.027417,
        "recall": 0.03009,
        "f1": 0.027919,
        "accuracy": 0.03009,
        "main_score": 0.027919,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.076553,
        "recall": 0.111334,
        "f1": 0.083328,
        "accuracy": 0.111334,
        "main_score": 0.083328,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.052158,
        "recall": 0.056169,
        "f1": 0.053162,
        "accuracy": 0.056169,
        "main_score": 0.053162,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.085938,
        "recall": 0.14343,
        "f1": 0.096973,
        "accuracy": 0.14343,
        "main_score": 0.096973,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.01324,
        "recall": 0.015045,
        "f1": 0.013708,
        "accuracy": 0.015045,
        "main_score": 0.013708,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.098403,
        "recall": 0.150451,
        "f1": 0.10808,
        "accuracy": 0.150451,
        "main_score": 0.10808,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.012123,
        "recall": 0.016048,
        "f1": 0.012945,
        "accuracy": 0.016048,
        "main_score": 0.012945,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.066319,
        "recall": 0.119358,
        "f1": 0.075764,
        "accuracy": 0.119358,
        "main_score": 0.075764,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.020896,
        "recall": 0.023069,
        "f1": 0.021565,
        "accuracy": 0.023069,
        "main_score": 0.021565,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.071845,
        "recall": 0.107322,
        "f1": 0.078853,
        "accuracy": 0.107322,
        "main_score": 0.078853,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.028672,
        "recall": 0.033099,
        "f1": 0.02966,
        "accuracy": 0.033099,
        "main_score": 0.02966,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.1044,
        "recall": 0.16349,
        "f1": 0.115525,
        "accuracy": 0.16349,
        "main_score": 0.115525,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.018725,
        "recall": 0.023069,
        "f1": 0.019682,
        "accuracy": 0.023069,
        "main_score": 0.019682,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.106428,
        "recall": 0.162487,
        "f1": 0.116078,
        "accuracy": 0.162487,
        "main_score": 0.116078,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.014378,
        "recall": 0.017051,
        "f1": 0.014881,
        "accuracy": 0.017051,
        "main_score": 0.014881,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0997,
        "recall": 0.150451,
        "f1": 0.109281,
        "accuracy": 0.150451,
        "main_score": 0.109281,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.076432,
        "recall": 0.082247,
        "f1": 0.077705,
        "accuracy": 0.082247,
        "main_score": 0.077705,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.11405,
        "recall": 0.212638,
        "f1": 0.13316,
        "accuracy": 0.212638,
        "main_score": 0.13316,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.032306,
        "recall": 0.036108,
        "f1": 0.032783,
        "accuracy": 0.036108,
        "main_score": 0.032783,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.092355,
        "recall": 0.15346,
        "f1": 0.104014,
        "accuracy": 0.15346,
        "main_score": 0.104014,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.01279,
        "recall": 0.015045,
        "f1": 0.013109,
        "accuracy": 0.015045,
        "main_score": 0.013109,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.116187,
        "recall": 0.162487,
        "f1": 0.124263,
        "accuracy": 0.162487,
        "main_score": 0.124263,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.014796,
        "recall": 0.017051,
        "f1": 0.015115,
        "accuracy": 0.017051,
        "main_score": 0.015115,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.106453,
        "recall": 0.15346,
        "f1": 0.115445,
        "accuracy": 0.15346,
        "main_score": 0.115445,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.03611,
        "recall": 0.042126,
        "f1": 0.037582,
        "accuracy": 0.042126,
        "main_score": 0.037582,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.099819,
        "recall": 0.15346,
        "f1": 0.110685,
        "accuracy": 0.15346,
        "main_score": 0.110685,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.012293,
        "recall": 0.017051,
        "f1": 0.013118,
        "accuracy": 0.017051,
        "main_score": 0.013118,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.102144,
        "recall": 0.150451,
        "f1": 0.111521,
        "accuracy": 0.150451,
        "main_score": 0.111521,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.013793,
        "recall": 0.016048,
        "f1": 0.014112,
        "accuracy": 0.016048,
        "main_score": 0.014112,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.096263,
        "recall": 0.141424,
        "f1": 0.104777,
        "accuracy": 0.141424,
        "main_score": 0.104777,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.028838,
        "recall": 0.033099,
        "f1": 0.029825,
        "accuracy": 0.033099,
        "main_score": 0.029825,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.09275,
        "recall": 0.125376,
        "f1": 0.100034,
        "accuracy": 0.125376,
        "main_score": 0.100034,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.007858,
        "recall": 0.01003,
        "f1": 0.008194,
        "accuracy": 0.01003,
        "main_score": 0.008194,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.08956,
        "recall": 0.1334,
        "f1": 0.09825,
        "accuracy": 0.1334,
        "main_score": 0.09825,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.016752,
        "recall": 0.02006,
        "f1": 0.017389,
        "accuracy": 0.02006,
        "main_score": 0.017389,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.095514,
        "recall": 0.155466,
        "f1": 0.106634,
        "accuracy": 0.155466,
        "main_score": 0.106634,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.014493,
        "recall": 0.018054,
        "f1": 0.015446,
        "accuracy": 0.018054,
        "main_score": 0.015446,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.108623,
        "recall": 0.164493,
        "f1": 0.118807,
        "accuracy": 0.164493,
        "main_score": 0.118807,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.025663,
        "recall": 0.029087,
        "f1": 0.026317,
        "accuracy": 0.029087,
        "main_score": 0.026317,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.109473,
        "recall": 0.169509,
        "f1": 0.120883,
        "accuracy": 0.169509,
        "main_score": 0.120883,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.009029,
        "recall": 0.011033,
        "f1": 0.009365,
        "accuracy": 0.011033,
        "main_score": 0.009365,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.107154,
        "recall": 0.148445,
        "f1": 0.115552,
        "accuracy": 0.148445,
        "main_score": 0.115552,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.013375,
        "recall": 0.016048,
        "f1": 0.013878,
        "accuracy": 0.016048,
        "main_score": 0.013878,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.1049,
        "recall": 0.146439,
        "f1": 0.111978,
        "accuracy": 0.146439,
        "main_score": 0.111978,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.001505,
        "recall": 0.002006,
        "f1": 0.001672,
        "accuracy": 0.002006,
        "main_score": 0.001672,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00597,
        "recall": 0.02006,
        "f1": 0.007599,
        "accuracy": 0.02006,
        "main_score": 0.007599,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.006375,
        "recall": 0.008893,
        "f1": 0.006656,
        "accuracy": 0.008893,
        "main_score": 0.006656,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.057546,
        "recall": 0.105731,
        "f1": 0.066572,
        "accuracy": 0.105731,
        "main_score": 0.066572,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.011988,
        "recall": 0.017787,
        "f1": 0.012923,
        "accuracy": 0.017787,
        "main_score": 0.012923,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.067887,
        "recall": 0.088933,
        "f1": 0.071907,
        "accuracy": 0.088933,
        "main_score": 0.071907,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.008861,
        "recall": 0.014822,
        "f1": 0.010094,
        "accuracy": 0.014822,
        "main_score": 0.010094,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060353,
        "recall": 0.092885,
        "f1": 0.06648,
        "accuracy": 0.092885,
        "main_score": 0.06648,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016008,
        "recall": 0.022727,
        "f1": 0.016918,
        "accuracy": 0.022727,
        "main_score": 0.016918,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.072575,
        "recall": 0.099802,
        "f1": 0.077759,
        "accuracy": 0.099802,
        "main_score": 0.077759,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.008871,
        "recall": 0.014822,
        "f1": 0.009429,
        "accuracy": 0.014822,
        "main_score": 0.009429,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.08135,
        "recall": 0.110672,
        "f1": 0.086509,
        "accuracy": 0.110672,
        "main_score": 0.086509,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007051,
        "recall": 0.011858,
        "f1": 0.007924,
        "accuracy": 0.011858,
        "main_score": 0.007924,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060567,
        "recall": 0.083004,
        "f1": 0.064488,
        "accuracy": 0.083004,
        "main_score": 0.064488,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.013839,
        "recall": 0.019763,
        "f1": 0.014469,
        "accuracy": 0.019763,
        "main_score": 0.014469,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.080908,
        "recall": 0.114625,
        "f1": 0.086436,
        "accuracy": 0.114625,
        "main_score": 0.086436,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.035863,
        "recall": 0.046443,
        "f1": 0.037948,
        "accuracy": 0.046443,
        "main_score": 0.037948,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.103622,
        "recall": 0.162055,
        "f1": 0.1148,
        "accuracy": 0.162055,
        "main_score": 0.1148,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007515,
        "recall": 0.012846,
        "f1": 0.008307,
        "accuracy": 0.012846,
        "main_score": 0.008307,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.085804,
        "recall": 0.130435,
        "f1": 0.093515,
        "accuracy": 0.130435,
        "main_score": 0.093515,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.009694,
        "recall": 0.013834,
        "f1": 0.010389,
        "accuracy": 0.013834,
        "main_score": 0.010389,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.051643,
        "recall": 0.097826,
        "f1": 0.059517,
        "accuracy": 0.097826,
        "main_score": 0.059517,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.01026,
        "recall": 0.016798,
        "f1": 0.011343,
        "accuracy": 0.016798,
        "main_score": 0.011343,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.06204,
        "recall": 0.096838,
        "f1": 0.068539,
        "accuracy": 0.096838,
        "main_score": 0.068539,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.023803,
        "recall": 0.029644,
        "f1": 0.024748,
        "accuracy": 0.029644,
        "main_score": 0.024748,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.105322,
        "recall": 0.159091,
        "f1": 0.115296,
        "accuracy": 0.159091,
        "main_score": 0.115296,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.011859,
        "recall": 0.017787,
        "f1": 0.01277,
        "accuracy": 0.017787,
        "main_score": 0.01277,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.098493,
        "recall": 0.147233,
        "f1": 0.106907,
        "accuracy": 0.147233,
        "main_score": 0.106907,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010776,
        "recall": 0.016798,
        "f1": 0.011686,
        "accuracy": 0.016798,
        "main_score": 0.011686,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.096507,
        "recall": 0.142292,
        "f1": 0.104452,
        "accuracy": 0.142292,
        "main_score": 0.104452,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.051249,
        "recall": 0.063241,
        "f1": 0.053739,
        "accuracy": 0.063241,
        "main_score": 0.053739,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.101588,
        "recall": 0.162055,
        "f1": 0.112669,
        "accuracy": 0.162055,
        "main_score": 0.112669,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.021861,
        "recall": 0.029644,
        "f1": 0.023488,
        "accuracy": 0.029644,
        "main_score": 0.023488,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.088453,
        "recall": 0.143281,
        "f1": 0.098801,
        "accuracy": 0.143281,
        "main_score": 0.098801,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006958,
        "recall": 0.012846,
        "f1": 0.007903,
        "accuracy": 0.012846,
        "main_score": 0.007903,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.098641,
        "recall": 0.140316,
        "f1": 0.106398,
        "accuracy": 0.140316,
        "main_score": 0.106398,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.004074,
        "recall": 0.008893,
        "f1": 0.00472,
        "accuracy": 0.008893,
        "main_score": 0.00472,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.084192,
        "recall": 0.117589,
        "f1": 0.091457,
        "accuracy": 0.117589,
        "main_score": 0.091457,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.023961,
        "recall": 0.030632,
        "f1": 0.02483,
        "accuracy": 0.030632,
        "main_score": 0.02483,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.082495,
        "recall": 0.133399,
        "f1": 0.09258,
        "accuracy": 0.133399,
        "main_score": 0.09258,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.009295,
        "recall": 0.01581,
        "f1": 0.010418,
        "accuracy": 0.01581,
        "main_score": 0.010418,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.099791,
        "recall": 0.146245,
        "f1": 0.108206,
        "accuracy": 0.146245,
        "main_score": 0.108206,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.007318,
        "recall": 0.012846,
        "f1": 0.00831,
        "accuracy": 0.012846,
        "main_score": 0.00831,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0928,
        "recall": 0.132411,
        "f1": 0.100051,
        "accuracy": 0.132411,
        "main_score": 0.100051,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.014788,
        "recall": 0.022727,
        "f1": 0.016381,
        "accuracy": 0.022727,
        "main_score": 0.016381,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.098748,
        "recall": 0.134387,
        "f1": 0.106284,
        "accuracy": 0.134387,
        "main_score": 0.106284,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.002554,
        "recall": 0.006917,
        "f1": 0.003315,
        "accuracy": 0.006917,
        "main_score": 0.003315,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.081105,
        "recall": 0.110672,
        "f1": 0.086985,
        "accuracy": 0.110672,
        "main_score": 0.086985,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.009075,
        "recall": 0.014822,
        "f1": 0.010009,
        "accuracy": 0.014822,
        "main_score": 0.010009,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.102131,
        "recall": 0.146245,
        "f1": 0.109657,
        "accuracy": 0.146245,
        "main_score": 0.109657,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.01015,
        "recall": 0.016798,
        "f1": 0.011239,
        "accuracy": 0.016798,
        "main_score": 0.011239,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.109454,
        "recall": 0.157115,
        "f1": 0.118308,
        "accuracy": 0.157115,
        "main_score": 0.118308,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.013298,
        "recall": 0.019763,
        "f1": 0.014425,
        "accuracy": 0.019763,
        "main_score": 0.014425,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.109511,
        "recall": 0.162055,
        "f1": 0.119053,
        "accuracy": 0.162055,
        "main_score": 0.119053,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.004978,
        "recall": 0.009881,
        "f1": 0.005804,
        "accuracy": 0.009881,
        "main_score": 0.005804,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.094946,
        "recall": 0.126482,
        "f1": 0.101853,
        "accuracy": 0.126482,
        "main_score": 0.101853,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.006904,
        "recall": 0.011858,
        "f1": 0.007712,
        "accuracy": 0.011858,
        "main_score": 0.007712,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.099715,
        "recall": 0.141304,
        "f1": 0.10634,
        "accuracy": 0.141304,
        "main_score": 0.10634,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.002471,
        "recall": 0.003953,
        "f1": 0.002637,
        "accuracy": 0.003953,
        "main_score": 0.002637,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00971,
        "recall": 0.025692,
        "f1": 0.011662,
        "accuracy": 0.025692,
        "main_score": 0.011662,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 241.48235487937927,
  "kg_co2_emissions": 0.019347400495593407
}