{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.759708,
        "f1": 0.641849,
        "f1_weighted": 0.794193,
        "ap": 0.265994,
        "ap_weighted": 0.265994,
        "scores_per_experiment": [
          {
            "accuracy": 0.629725,
            "f1": 0.538727,
            "f1_weighted": 0.692209,
            "ap": 0.192108,
            "ap_weighted": 0.192108
          },
          {
            "accuracy": 0.841065,
            "f1": 0.699454,
            "f1_weighted": 0.854004,
            "ap": 0.301441,
            "ap_weighted": 0.301441
          },
          {
            "accuracy": 0.801546,
            "f1": 0.685533,
            "f1_weighted": 0.828622,
            "ap": 0.309569,
            "ap_weighted": 0.309569
          },
          {
            "accuracy": 0.813574,
            "f1": 0.693258,
            "f1_weighted": 0.837175,
            "ap": 0.313367,
            "ap_weighted": 0.313367
          },
          {
            "accuracy": 0.769759,
            "f1": 0.610722,
            "f1_weighted": 0.797121,
            "ap": 0.204523,
            "ap_weighted": 0.204523
          },
          {
            "accuracy": 0.781787,
            "f1": 0.657048,
            "f1_weighted": 0.811994,
            "ap": 0.27052,
            "ap_weighted": 0.27052
          },
          {
            "accuracy": 0.789519,
            "f1": 0.663118,
            "f1_weighted": 0.817707,
            "ap": 0.275185,
            "ap_weighted": 0.275185
          },
          {
            "accuracy": 0.652062,
            "f1": 0.571386,
            "f1_weighted": 0.710692,
            "ap": 0.231669,
            "ap_weighted": 0.231669
          },
          {
            "accuracy": 0.725086,
            "f1": 0.611188,
            "f1_weighted": 0.768837,
            "ap": 0.235613,
            "ap_weighted": 0.235613
          },
          {
            "accuracy": 0.792955,
            "f1": 0.688054,
            "f1_weighted": 0.823571,
            "ap": 0.325941,
            "ap_weighted": 0.325941
          }
        ],
        "main_score": 0.759708,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 9.655453443527222,
  "kg_co2_emissions": 0.00043961023356574585
}