{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.707129,
        "f1": 0.701255,
        "f1_weighted": 0.701144,
        "ap": 0.664271,
        "ap_weighted": 0.664271,
        "scores_per_experiment": [
          {
            "accuracy": 0.690918,
            "f1": 0.683429,
            "f1_weighted": 0.683286,
            "ap": 0.650116,
            "ap_weighted": 0.650116
          },
          {
            "accuracy": 0.6875,
            "f1": 0.67432,
            "f1_weighted": 0.674128,
            "ap": 0.654826,
            "ap_weighted": 0.654826
          },
          {
            "accuracy": 0.756348,
            "f1": 0.754756,
            "f1_weighted": 0.754698,
            "ap": 0.708288,
            "ap_weighted": 0.708288
          },
          {
            "accuracy": 0.697266,
            "f1": 0.680586,
            "f1_weighted": 0.680372,
            "ap": 0.672773,
            "ap_weighted": 0.672773
          },
          {
            "accuracy": 0.73584,
            "f1": 0.734582,
            "f1_weighted": 0.734528,
            "ap": 0.684133,
            "ap_weighted": 0.684133
          },
          {
            "accuracy": 0.728027,
            "f1": 0.722423,
            "f1_weighted": 0.722308,
            "ap": 0.688682,
            "ap_weighted": 0.688682
          },
          {
            "accuracy": 0.699707,
            "f1": 0.697128,
            "f1_weighted": 0.697046,
            "ap": 0.650534,
            "ap_weighted": 0.650534
          },
          {
            "accuracy": 0.68457,
            "f1": 0.684088,
            "f1_weighted": 0.684052,
            "ap": 0.63082,
            "ap_weighted": 0.63082
          },
          {
            "accuracy": 0.705078,
            "f1": 0.69692,
            "f1_weighted": 0.696775,
            "ap": 0.66723,
            "ap_weighted": 0.66723
          },
          {
            "accuracy": 0.686035,
            "f1": 0.684319,
            "f1_weighted": 0.684251,
            "ap": 0.635305,
            "ap_weighted": 0.635305
          }
        ],
        "main_score": 0.707129,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.698096,
        "f1": 0.691526,
        "f1_weighted": 0.691446,
        "ap": 0.654755,
        "ap_weighted": 0.654755,
        "scores_per_experiment": [
          {
            "accuracy": 0.684082,
            "f1": 0.674965,
            "f1_weighted": 0.674859,
            "ap": 0.644369,
            "ap_weighted": 0.644369
          },
          {
            "accuracy": 0.677734,
            "f1": 0.662582,
            "f1_weighted": 0.662442,
            "ap": 0.645215,
            "ap_weighted": 0.645215
          },
          {
            "accuracy": 0.737305,
            "f1": 0.73512,
            "f1_weighted": 0.735073,
            "ap": 0.688665,
            "ap_weighted": 0.688665
          },
          {
            "accuracy": 0.686035,
            "f1": 0.669124,
            "f1_weighted": 0.668978,
            "ap": 0.657793,
            "ap_weighted": 0.657793
          },
          {
            "accuracy": 0.719238,
            "f1": 0.717621,
            "f1_weighted": 0.717579,
            "ap": 0.667407,
            "ap_weighted": 0.667407
          },
          {
            "accuracy": 0.715332,
            "f1": 0.707885,
            "f1_weighted": 0.707794,
            "ap": 0.677183,
            "ap_weighted": 0.677183
          },
          {
            "accuracy": 0.695801,
            "f1": 0.692151,
            "f1_weighted": 0.692085,
            "ap": 0.64813,
            "ap_weighted": 0.64813
          },
          {
            "accuracy": 0.684082,
            "f1": 0.683457,
            "f1_weighted": 0.68343,
            "ap": 0.630296,
            "ap_weighted": 0.630296
          },
          {
            "accuracy": 0.695312,
            "f1": 0.687688,
            "f1_weighted": 0.687592,
            "ap": 0.654497,
            "ap_weighted": 0.654497
          },
          {
            "accuracy": 0.686035,
            "f1": 0.684665,
            "f1_weighted": 0.684624,
            "ap": 0.633992,
            "ap_weighted": 0.633992
          }
        ],
        "main_score": 0.698096,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 14.84715223312378,
  "kg_co2_emissions": 0.0003390954223536215
}