{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.1.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.629179,
            "f1": 0.516176,
            "f1_weighted": 0.691722,
            "precision": 0.550523,
            "precision_weighted": 0.824158,
            "recall": 0.610391,
            "recall_weighted": 0.629179,
            "ap": 0.160577,
            "ap_weighted": 0.160577
          },
          {
            "accuracy": 0.653495,
            "f1": 0.561025,
            "f1_weighted": 0.712284,
            "precision": 0.593351,
            "precision_weighted": 0.863455,
            "recall": 0.707952,
            "recall_weighted": 0.653495,
            "ap": 0.209659,
            "ap_weighted": 0.209659
          },
          {
            "accuracy": 0.683891,
            "f1": 0.563081,
            "f1_weighted": 0.735566,
            "precision": 0.577997,
            "precision_weighted": 0.842197,
            "recall": 0.662559,
            "recall_weighted": 0.683891,
            "ap": 0.188965,
            "ap_weighted": 0.188965
          },
          {
            "accuracy": 0.556231,
            "f1": 0.466384,
            "f1_weighted": 0.630771,
            "precision": 0.530136,
            "precision_weighted": 0.810374,
            "recall": 0.568725,
            "recall_weighted": 0.556231,
            "ap": 0.143494,
            "ap_weighted": 0.143494
          },
          {
            "accuracy": 0.6231,
            "f1": 0.544036,
            "f1_weighted": 0.686582,
            "precision": 0.59292,
            "precision_weighted": 0.869015,
            "recall": 0.711509,
            "recall_weighted": 0.6231,
            "ap": 0.207999,
            "ap_weighted": 0.207999
          },
          {
            "accuracy": 0.507599,
            "f1": 0.433482,
            "f1_weighted": 0.587321,
            "precision": 0.517881,
            "precision_weighted": 0.800068,
            "recall": 0.540947,
            "recall_weighted": 0.507599,
            "ap": 0.134801,
            "ap_weighted": 0.134801
          },
          {
            "accuracy": 0.568389,
            "f1": 0.487066,
            "f1_weighted": 0.6404,
            "precision": 0.551381,
            "precision_weighted": 0.831443,
            "recall": 0.617505,
            "recall_weighted": 0.568389,
            "ap": 0.16131,
            "ap_weighted": 0.16131
          },
          {
            "accuracy": 0.56231,
            "f1": 0.479842,
            "f1_weighted": 0.635335,
            "precision": 0.54529,
            "precision_weighted": 0.82556,
            "recall": 0.603574,
            "recall_weighted": 0.56231,
            "ap": 0.155805,
            "ap_weighted": 0.155805
          },
          {
            "accuracy": 0.541033,
            "f1": 0.46786,
            "f1_weighted": 0.616006,
            "precision": 0.54446,
            "precision_weighted": 0.826585,
            "recall": 0.60188,
            "recall_weighted": 0.541033,
            "ap": 0.154706,
            "ap_weighted": 0.154706
          },
          {
            "accuracy": 0.620061,
            "f1": 0.509862,
            "f1_weighted": 0.684343,
            "precision": 0.547762,
            "precision_weighted": 0.822498,
            "recall": 0.605183,
            "recall_weighted": 0.620061,
            "ap": 0.158102,
            "ap_weighted": 0.158102
          }
        ],
        "accuracy": 0.594529,
        "f1": 0.502882,
        "f1_weighted": 0.662033,
        "precision": 0.55517,
        "precision_weighted": 0.831535,
        "recall": 0.623023,
        "recall_weighted": 0.594529,
        "ap": 0.167542,
        "ap_weighted": 0.167542,
        "main_score": 0.594529,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1.7965848445892334,
  "kg_co2_emissions": null
}