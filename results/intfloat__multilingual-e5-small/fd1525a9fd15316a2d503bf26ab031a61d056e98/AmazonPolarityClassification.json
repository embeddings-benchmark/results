{
  "dataset_revision": "e2d317d38cd51312af73b3d32a06d1a08b442046",
  "task_name": "AmazonPolarityClassification",
  "mteb_version": "1.36.26",
  "scores": {
    "test": [
      {
        "accuracy": 0.874122,
        "f1": 0.87354,
        "f1_weighted": 0.87354,
        "ap": 0.836866,
        "ap_weighted": 0.836866,
        "scores_per_experiment": [
          {
            "accuracy": 0.881565,
            "f1": 0.881347,
            "f1_weighted": 0.881347,
            "ap": 0.850033,
            "ap_weighted": 0.850033
          },
          {
            "accuracy": 0.881768,
            "f1": 0.881699,
            "f1_weighted": 0.881699,
            "ap": 0.829945,
            "ap_weighted": 0.829945
          },
          {
            "accuracy": 0.895432,
            "f1": 0.895196,
            "f1_weighted": 0.895196,
            "ap": 0.870517,
            "ap_weighted": 0.870517
          },
          {
            "accuracy": 0.860315,
            "f1": 0.859069,
            "f1_weighted": 0.859069,
            "ap": 0.840057,
            "ap_weighted": 0.840057
          },
          {
            "accuracy": 0.84448,
            "f1": 0.842577,
            "f1_weighted": 0.842577,
            "ap": 0.824355,
            "ap_weighted": 0.824355
          },
          {
            "accuracy": 0.875903,
            "f1": 0.875897,
            "f1_weighted": 0.875897,
            "ap": 0.827454,
            "ap_weighted": 0.827454
          },
          {
            "accuracy": 0.865797,
            "f1": 0.86509,
            "f1_weighted": 0.86509,
            "ap": 0.839365,
            "ap_weighted": 0.839365
          },
          {
            "accuracy": 0.894745,
            "f1": 0.894496,
            "f1_weighted": 0.894496,
            "ap": 0.869956,
            "ap_weighted": 0.869956
          },
          {
            "accuracy": 0.883115,
            "f1": 0.882956,
            "f1_weighted": 0.882956,
            "ap": 0.82827,
            "ap_weighted": 0.82827
          },
          {
            "accuracy": 0.858102,
            "f1": 0.857077,
            "f1_weighted": 0.857077,
            "ap": 0.788709,
            "ap_weighted": 0.788709
          }
        ],
        "main_score": 0.874122,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 261.6263530254364,
  "kg_co2_emissions": null
}