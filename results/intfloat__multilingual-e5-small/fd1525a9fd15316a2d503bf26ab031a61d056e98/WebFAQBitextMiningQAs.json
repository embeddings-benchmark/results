{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQAs",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.995074,
        "recall": 0.996716,
        "f1": 0.995621,
        "accuracy": 0.996716,
        "main_score": 0.995621,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.929594,
        "recall": 0.948875,
        "f1": 0.935464,
        "accuracy": 0.948875,
        "main_score": 0.935464,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.979729,
        "recall": 0.985892,
        "f1": 0.981685,
        "accuracy": 0.985892,
        "main_score": 0.981685,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.97591,
        "recall": 0.983776,
        "f1": 0.978491,
        "accuracy": 0.983776,
        "main_score": 0.978491,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.986304,
        "recall": 0.990741,
        "f1": 0.987751,
        "accuracy": 0.990741,
        "main_score": 0.987751,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.966691,
        "recall": 0.977633,
        "f1": 0.970298,
        "accuracy": 0.977633,
        "main_score": 0.970298,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.983901,
        "recall": 0.98804,
        "f1": 0.985083,
        "accuracy": 0.98804,
        "main_score": 0.985083,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.988906,
        "recall": 0.99226,
        "f1": 0.989938,
        "accuracy": 0.99226,
        "main_score": 0.989938,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.925641,
        "recall": 0.938462,
        "f1": 0.92967,
        "accuracy": 0.938462,
        "main_score": 0.92967,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.996032,
        "recall": 0.997354,
        "f1": 0.996473,
        "accuracy": 0.997354,
        "main_score": 0.996473,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.956658,
        "recall": 0.966614,
        "f1": 0.959601,
        "accuracy": 0.966614,
        "main_score": 0.959601,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.981841,
        "recall": 0.987205,
        "f1": 0.983502,
        "accuracy": 0.987205,
        "main_score": 0.983502,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.987324,
        "recall": 0.991549,
        "f1": 0.988732,
        "accuracy": 0.991549,
        "main_score": 0.988732,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.980386,
        "recall": 0.986301,
        "f1": 0.982233,
        "accuracy": 0.986301,
        "main_score": 0.982233,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.983894,
        "recall": 0.988991,
        "f1": 0.985525,
        "accuracy": 0.988991,
        "main_score": 0.985525,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.987805,
        "recall": 0.99187,
        "f1": 0.98916,
        "accuracy": 0.99187,
        "main_score": 0.98916,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.987291,
        "recall": 0.991334,
        "f1": 0.98859,
        "accuracy": 0.991334,
        "main_score": 0.98859,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.975822,
        "recall": 0.983559,
        "f1": 0.978401,
        "accuracy": 0.983559,
        "main_score": 0.978401,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.965653,
        "recall": 0.976351,
        "f1": 0.969032,
        "accuracy": 0.976351,
        "main_score": 0.969032,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.982154,
        "recall": 0.987896,
        "f1": 0.984016,
        "accuracy": 0.987896,
        "main_score": 0.984016,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.971238,
        "recall": 0.980571,
        "f1": 0.974286,
        "accuracy": 0.980571,
        "main_score": 0.974286,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.961743,
        "recall": 0.974052,
        "f1": 0.965735,
        "accuracy": 0.974052,
        "main_score": 0.965735,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.993317,
        "recall": 0.995545,
        "f1": 0.99406,
        "accuracy": 0.995545,
        "main_score": 0.99406,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.98041,
        "recall": 0.98694,
        "f1": 0.982587,
        "accuracy": 0.98694,
        "main_score": 0.982587,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.996668,
        "recall": 0.997648,
        "f1": 0.996995,
        "accuracy": 0.997648,
        "main_score": 0.996995,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.979197,
        "recall": 0.986131,
        "f1": 0.981509,
        "accuracy": 0.986131,
        "main_score": 0.981509,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.983425,
        "recall": 0.98895,
        "f1": 0.985267,
        "accuracy": 0.98895,
        "main_score": 0.985267,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.973281,
        "recall": 0.981323,
        "f1": 0.975875,
        "accuracy": 0.981323,
        "main_score": 0.975875,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.990415,
        "recall": 0.99361,
        "f1": 0.99148,
        "accuracy": 0.99361,
        "main_score": 0.99148,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.98869,
        "recall": 0.99246,
        "f1": 0.989947,
        "accuracy": 0.99246,
        "main_score": 0.989947,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.988959,
        "recall": 0.992639,
        "f1": 0.990186,
        "accuracy": 0.992639,
        "main_score": 0.990186,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.977101,
        "recall": 0.984419,
        "f1": 0.979462,
        "accuracy": 0.984419,
        "main_score": 0.979462,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.97951,
        "recall": 0.986058,
        "f1": 0.981622,
        "accuracy": 0.986058,
        "main_score": 0.981622,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.97973,
        "recall": 0.986486,
        "f1": 0.981982,
        "accuracy": 0.986486,
        "main_score": 0.981982,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.997409,
        "recall": 0.998273,
        "f1": 0.997697,
        "accuracy": 0.998273,
        "main_score": 0.997697,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.979857,
        "recall": 0.986355,
        "f1": 0.981969,
        "accuracy": 0.986355,
        "main_score": 0.981969,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.98283,
        "recall": 0.988554,
        "f1": 0.984738,
        "accuracy": 0.988554,
        "main_score": 0.984738,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.979045,
        "recall": 0.98603,
        "f1": 0.981374,
        "accuracy": 0.98603,
        "main_score": 0.981374,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.960461,
        "recall": 0.971993,
        "f1": 0.964305,
        "accuracy": 0.971993,
        "main_score": 0.964305,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.98409,
        "recall": 0.989045,
        "f1": 0.985655,
        "accuracy": 0.989045,
        "main_score": 0.985655,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.98466,
        "recall": 0.98943,
        "f1": 0.986185,
        "accuracy": 0.98943,
        "main_score": 0.986185,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.992961,
        "recall": 0.995308,
        "f1": 0.993743,
        "accuracy": 0.995308,
        "main_score": 0.993743,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.966112,
        "recall": 0.976845,
        "f1": 0.969609,
        "accuracy": 0.976845,
        "main_score": 0.969609,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.952575,
        "recall": 0.965447,
        "f1": 0.95664,
        "accuracy": 0.965447,
        "main_score": 0.95664,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.988608,
        "recall": 0.992405,
        "f1": 0.989873,
        "accuracy": 0.992405,
        "main_score": 0.989873,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.986408,
        "recall": 0.990499,
        "f1": 0.987728,
        "accuracy": 0.990499,
        "main_score": 0.987728,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.962439,
        "recall": 0.974453,
        "f1": 0.966393,
        "accuracy": 0.974453,
        "main_score": 0.966393,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.948352,
        "recall": 0.964835,
        "f1": 0.953846,
        "accuracy": 0.964835,
        "main_score": 0.953846,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.994137,
        "recall": 0.995672,
        "f1": 0.994614,
        "accuracy": 0.995672,
        "main_score": 0.994614,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.985703,
        "recall": 0.990469,
        "f1": 0.987292,
        "accuracy": 0.990469,
        "main_score": 0.987292,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.949198,
        "recall": 0.966132,
        "f1": 0.954843,
        "accuracy": 0.966132,
        "main_score": 0.954843,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.992055,
        "recall": 0.994703,
        "f1": 0.992938,
        "accuracy": 0.994703,
        "main_score": 0.992938,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.948564,
        "recall": 0.963928,
        "f1": 0.953574,
        "accuracy": 0.963928,
        "main_score": 0.953574,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.976353,
        "recall": 0.983629,
        "f1": 0.978627,
        "accuracy": 0.983629,
        "main_score": 0.978627,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.995033,
        "recall": 0.996689,
        "f1": 0.995585,
        "accuracy": 0.996689,
        "main_score": 0.995585,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.992475,
        "recall": 0.994983,
        "f1": 0.993311,
        "accuracy": 0.994983,
        "main_score": 0.993311,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.996411,
        "recall": 0.997608,
        "f1": 0.99681,
        "accuracy": 0.997608,
        "main_score": 0.99681,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.995946,
        "recall": 0.997297,
        "f1": 0.996396,
        "accuracy": 0.997297,
        "main_score": 0.996396,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.998426,
        "recall": 0.998867,
        "f1": 0.998552,
        "accuracy": 0.998867,
        "main_score": 0.998552,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.991776,
        "recall": 0.994466,
        "f1": 0.99266,
        "accuracy": 0.994466,
        "main_score": 0.99266,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.987594,
        "recall": 0.991583,
        "f1": 0.988909,
        "accuracy": 0.991583,
        "main_score": 0.988909,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.949541,
        "recall": 0.966361,
        "f1": 0.955148,
        "accuracy": 0.966361,
        "main_score": 0.955148,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.986948,
        "recall": 0.990833,
        "f1": 0.988201,
        "accuracy": 0.990833,
        "main_score": 0.988201,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.994877,
        "recall": 0.996585,
        "f1": 0.995446,
        "accuracy": 0.996585,
        "main_score": 0.995446,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.994622,
        "recall": 0.996158,
        "f1": 0.995134,
        "accuracy": 0.996158,
        "main_score": 0.995134,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.984456,
        "recall": 0.989395,
        "f1": 0.986068,
        "accuracy": 0.989395,
        "main_score": 0.986068,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.979776,
        "recall": 0.986355,
        "f1": 0.981969,
        "accuracy": 0.986355,
        "main_score": 0.981969,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.986978,
        "recall": 0.991039,
        "f1": 0.988332,
        "accuracy": 0.991039,
        "main_score": 0.988332,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.997891,
        "recall": 0.998594,
        "f1": 0.998126,
        "accuracy": 0.998594,
        "main_score": 0.998126,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.987638,
        "recall": 0.991561,
        "f1": 0.988911,
        "accuracy": 0.991561,
        "main_score": 0.988911,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.919501,
        "recall": 0.945578,
        "f1": 0.928005,
        "accuracy": 0.945578,
        "main_score": 0.928005,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.986943,
        "recall": 0.991004,
        "f1": 0.98826,
        "accuracy": 0.991004,
        "main_score": 0.98826,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.993391,
        "recall": 0.995496,
        "f1": 0.994082,
        "accuracy": 0.995496,
        "main_score": 0.994082,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.991915,
        "recall": 0.99461,
        "f1": 0.992814,
        "accuracy": 0.99461,
        "main_score": 0.992814,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.990385,
        "recall": 0.993551,
        "f1": 0.99143,
        "accuracy": 0.993551,
        "main_score": 0.99143,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.988003,
        "recall": 0.99194,
        "f1": 0.9893,
        "accuracy": 0.99194,
        "main_score": 0.9893,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.986731,
        "recall": 0.990932,
        "f1": 0.988098,
        "accuracy": 0.990932,
        "main_score": 0.988098,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.993243,
        "recall": 0.995495,
        "f1": 0.993994,
        "accuracy": 0.995495,
        "main_score": 0.993994,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.913064,
        "recall": 0.939481,
        "f1": 0.92171,
        "accuracy": 0.939481,
        "main_score": 0.92171,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.992355,
        "recall": 0.994801,
        "f1": 0.993154,
        "accuracy": 0.994801,
        "main_score": 0.993154,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.98554,
        "recall": 0.990125,
        "f1": 0.987036,
        "accuracy": 0.990125,
        "main_score": 0.987036,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.992963,
        "recall": 0.995309,
        "f1": 0.993745,
        "accuracy": 0.995309,
        "main_score": 0.993745,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.993002,
        "recall": 0.995251,
        "f1": 0.993743,
        "accuracy": 0.995251,
        "main_score": 0.993743,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.992008,
        "recall": 0.994537,
        "f1": 0.992817,
        "accuracy": 0.994537,
        "main_score": 0.992817,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.993615,
        "recall": 0.995667,
        "f1": 0.994295,
        "accuracy": 0.995667,
        "main_score": 0.994295,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.983753,
        "recall": 0.989013,
        "f1": 0.985484,
        "accuracy": 0.989013,
        "main_score": 0.985484,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.921516,
        "recall": 0.942993,
        "f1": 0.928081,
        "accuracy": 0.942993,
        "main_score": 0.928081,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.938371,
        "recall": 0.958199,
        "f1": 0.944802,
        "accuracy": 0.958199,
        "main_score": 0.944802,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.947214,
        "recall": 0.964809,
        "f1": 0.953079,
        "accuracy": 0.964809,
        "main_score": 0.953079,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.946721,
        "recall": 0.964481,
        "f1": 0.952641,
        "accuracy": 0.964481,
        "main_score": 0.952641,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.957799,
        "recall": 0.971154,
        "f1": 0.962073,
        "accuracy": 0.971154,
        "main_score": 0.962073,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.991882,
        "recall": 0.994432,
        "f1": 0.992713,
        "accuracy": 0.994432,
        "main_score": 0.992713,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.985692,
        "recall": 0.990461,
        "f1": 0.987281,
        "accuracy": 0.990461,
        "main_score": 0.987281,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.993018,
        "recall": 0.995148,
        "f1": 0.993697,
        "accuracy": 0.995148,
        "main_score": 0.993697,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.988244,
        "recall": 0.991667,
        "f1": 0.989325,
        "accuracy": 0.991667,
        "main_score": 0.989325,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.991195,
        "recall": 0.993891,
        "f1": 0.992059,
        "accuracy": 0.993891,
        "main_score": 0.992059,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.986993,
        "recall": 0.99093,
        "f1": 0.988251,
        "accuracy": 0.99093,
        "main_score": 0.988251,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.995214,
        "recall": 0.996622,
        "f1": 0.995646,
        "accuracy": 0.996622,
        "main_score": 0.995646,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.990861,
        "recall": 0.993733,
        "f1": 0.991787,
        "accuracy": 0.993733,
        "main_score": 0.991787,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.987823,
        "recall": 0.99169,
        "f1": 0.989093,
        "accuracy": 0.99169,
        "main_score": 0.989093,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.989255,
        "recall": 0.992674,
        "f1": 0.990372,
        "accuracy": 0.992674,
        "main_score": 0.990372,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.992081,
        "recall": 0.994677,
        "f1": 0.992935,
        "accuracy": 0.994677,
        "main_score": 0.992935,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.982824,
        "recall": 0.988073,
        "f1": 0.984494,
        "accuracy": 0.988073,
        "main_score": 0.984494,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.984065,
        "recall": 0.989377,
        "f1": 0.985836,
        "accuracy": 0.989377,
        "main_score": 0.985836,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.988475,
        "recall": 0.992317,
        "f1": 0.989755,
        "accuracy": 0.992317,
        "main_score": 0.989755,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.998684,
        "recall": 0.999052,
        "f1": 0.998789,
        "accuracy": 0.999052,
        "main_score": 0.998789,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.984121,
        "recall": 0.988764,
        "f1": 0.985592,
        "accuracy": 0.988764,
        "main_score": 0.985592,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.994435,
        "recall": 0.996207,
        "f1": 0.995026,
        "accuracy": 0.996207,
        "main_score": 0.995026,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.988863,
        "recall": 0.992444,
        "f1": 0.990043,
        "accuracy": 0.992444,
        "main_score": 0.990043,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.99117,
        "recall": 0.993481,
        "f1": 0.991901,
        "accuracy": 0.993481,
        "main_score": 0.991901,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.985067,
        "recall": 0.989786,
        "f1": 0.986614,
        "accuracy": 0.989786,
        "main_score": 0.986614,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.991605,
        "recall": 0.994267,
        "f1": 0.992458,
        "accuracy": 0.994267,
        "main_score": 0.992458,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.998722,
        "recall": 0.999148,
        "f1": 0.998864,
        "accuracy": 0.999148,
        "main_score": 0.998864,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.997248,
        "recall": 0.998165,
        "f1": 0.997554,
        "accuracy": 0.998165,
        "main_score": 0.997554,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.989078,
        "recall": 0.992718,
        "f1": 0.990291,
        "accuracy": 0.992718,
        "main_score": 0.990291,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.984536,
        "recall": 0.989691,
        "f1": 0.986254,
        "accuracy": 0.989691,
        "main_score": 0.986254,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.995588,
        "recall": 0.997059,
        "f1": 0.996078,
        "accuracy": 0.997059,
        "main_score": 0.996078,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.979114,
        "recall": 0.986076,
        "f1": 0.981435,
        "accuracy": 0.986076,
        "main_score": 0.981435,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.975519,
        "recall": 0.98368,
        "f1": 0.978239,
        "accuracy": 0.98368,
        "main_score": 0.978239,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.955469,
        "recall": 0.970169,
        "f1": 0.960333,
        "accuracy": 0.970169,
        "main_score": 0.960333,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.97827,
        "recall": 0.983327,
        "f1": 0.979823,
        "accuracy": 0.983327,
        "main_score": 0.979823,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995025,
        "recall": 0.996683,
        "f1": 0.995578,
        "accuracy": 0.996683,
        "main_score": 0.995578,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.996952,
        "recall": 0.997805,
        "f1": 0.997196,
        "accuracy": 0.997805,
        "main_score": 0.997196,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989178,
        "recall": 0.99203,
        "f1": 0.990007,
        "accuracy": 0.99203,
        "main_score": 0.990007,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.99349,
        "recall": 0.99566,
        "f1": 0.994213,
        "accuracy": 0.99566,
        "main_score": 0.994213,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.993333,
        "recall": 0.995497,
        "f1": 0.99404,
        "accuracy": 0.995497,
        "main_score": 0.99404,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986783,
        "recall": 0.99047,
        "f1": 0.987914,
        "accuracy": 0.99047,
        "main_score": 0.987914,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.993415,
        "recall": 0.995368,
        "f1": 0.99403,
        "accuracy": 0.995368,
        "main_score": 0.99403,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.988941,
        "recall": 0.991398,
        "f1": 0.989618,
        "accuracy": 0.991398,
        "main_score": 0.989618,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986093,
        "recall": 0.990728,
        "f1": 0.987638,
        "accuracy": 0.990728,
        "main_score": 0.987638,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.997302,
        "recall": 0.998201,
        "f1": 0.997602,
        "accuracy": 0.998201,
        "main_score": 0.997602,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.965626,
        "recall": 0.976184,
        "f1": 0.96899,
        "accuracy": 0.976184,
        "main_score": 0.96899,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.992276,
        "recall": 0.994544,
        "f1": 0.993003,
        "accuracy": 0.994544,
        "main_score": 0.993003,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.938851,
        "recall": 0.953515,
        "f1": 0.942857,
        "accuracy": 0.953515,
        "main_score": 0.942857,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.996845,
        "recall": 0.997747,
        "f1": 0.997146,
        "accuracy": 0.997747,
        "main_score": 0.997146,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991071,
        "recall": 0.994048,
        "f1": 0.992063,
        "accuracy": 0.994048,
        "main_score": 0.992063,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.977498,
        "recall": 0.984439,
        "f1": 0.979695,
        "accuracy": 0.984439,
        "main_score": 0.979695,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.98277,
        "recall": 0.985814,
        "f1": 0.983652,
        "accuracy": 0.985814,
        "main_score": 0.983652,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.958101,
        "recall": 0.972067,
        "f1": 0.962756,
        "accuracy": 0.972067,
        "main_score": 0.962756,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.991489,
        "recall": 0.993744,
        "f1": 0.992187,
        "accuracy": 0.993744,
        "main_score": 0.992187,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.991354,
        "recall": 0.993696,
        "f1": 0.99205,
        "accuracy": 0.993696,
        "main_score": 0.99205,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.986994,
        "recall": 0.991329,
        "f1": 0.988439,
        "accuracy": 0.991329,
        "main_score": 0.988439,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.993159,
        "recall": 0.995309,
        "f1": 0.993875,
        "accuracy": 0.995309,
        "main_score": 0.993875,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.974977,
        "recall": 0.983318,
        "f1": 0.977757,
        "accuracy": 0.983318,
        "main_score": 0.977757,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.968636,
        "recall": 0.978903,
        "f1": 0.972011,
        "accuracy": 0.978903,
        "main_score": 0.972011,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.93559,
        "recall": 0.944563,
        "f1": 0.937828,
        "accuracy": 0.944563,
        "main_score": 0.937828,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.991954,
        "recall": 0.994172,
        "f1": 0.992664,
        "accuracy": 0.994172,
        "main_score": 0.992664,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.991239,
        "recall": 0.993623,
        "f1": 0.991967,
        "accuracy": 0.993623,
        "main_score": 0.991967,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.98602,
        "recall": 0.989662,
        "f1": 0.987132,
        "accuracy": 0.989662,
        "main_score": 0.987132,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.994183,
        "recall": 0.995405,
        "f1": 0.994546,
        "accuracy": 0.995405,
        "main_score": 0.994546,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.990498,
        "recall": 0.992432,
        "f1": 0.991006,
        "accuracy": 0.992432,
        "main_score": 0.991006,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.989677,
        "recall": 0.992201,
        "f1": 0.990439,
        "accuracy": 0.992201,
        "main_score": 0.990439,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.990309,
        "recall": 0.993417,
        "f1": 0.991315,
        "accuracy": 0.993417,
        "main_score": 0.991315,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.959708,
        "recall": 0.969655,
        "f1": 0.962627,
        "accuracy": 0.969655,
        "main_score": 0.962627,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.991062,
        "recall": 0.993427,
        "f1": 0.991809,
        "accuracy": 0.993427,
        "main_score": 0.991809,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.976348,
        "recall": 0.983498,
        "f1": 0.978548,
        "accuracy": 0.983498,
        "main_score": 0.978548,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.99016,
        "recall": 0.992839,
        "f1": 0.991004,
        "accuracy": 0.992839,
        "main_score": 0.991004,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.970721,
        "recall": 0.979115,
        "f1": 0.973178,
        "accuracy": 0.979115,
        "main_score": 0.973178,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.982765,
        "recall": 0.988059,
        "f1": 0.984455,
        "accuracy": 0.988059,
        "main_score": 0.984455,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.981825,
        "recall": 0.985971,
        "f1": 0.983053,
        "accuracy": 0.985971,
        "main_score": 0.983053,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.988806,
        "recall": 0.992537,
        "f1": 0.99005,
        "accuracy": 0.992537,
        "main_score": 0.99005,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.99288,
        "recall": 0.995253,
        "f1": 0.993671,
        "accuracy": 0.995253,
        "main_score": 0.993671,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.979683,
        "recall": 0.985683,
        "f1": 0.981562,
        "accuracy": 0.985683,
        "main_score": 0.981562,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 4679.698405981064,
  "kg_co2_emissions": null
}