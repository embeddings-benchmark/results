{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQuestions",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.936836,
        "recall": 0.955665,
        "f1": 0.942802,
        "accuracy": 0.955665,
        "main_score": 0.942802,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.813599,
        "recall": 0.867076,
        "f1": 0.830198,
        "accuracy": 0.867076,
        "main_score": 0.830198,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.920944,
        "recall": 0.943776,
        "f1": 0.928144,
        "accuracy": 0.943776,
        "main_score": 0.928144,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.887642,
        "recall": 0.919617,
        "f1": 0.897529,
        "accuracy": 0.919617,
        "main_score": 0.897529,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.948351,
        "recall": 0.964699,
        "f1": 0.953646,
        "accuracy": 0.964699,
        "main_score": 0.953646,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.889935,
        "recall": 0.920635,
        "f1": 0.899254,
        "accuracy": 0.920635,
        "main_score": 0.899254,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.914903,
        "recall": 0.940202,
        "f1": 0.922846,
        "accuracy": 0.940202,
        "main_score": 0.922846,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.947884,
        "recall": 0.964396,
        "f1": 0.953302,
        "accuracy": 0.964396,
        "main_score": 0.953302,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.924689,
        "recall": 0.936264,
        "f1": 0.927839,
        "accuracy": 0.936264,
        "main_score": 0.927839,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.980159,
        "recall": 0.986772,
        "f1": 0.982363,
        "accuracy": 0.986772,
        "main_score": 0.982363,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.893071,
        "recall": 0.923688,
        "f1": 0.902358,
        "accuracy": 0.923688,
        "main_score": 0.902358,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.914703,
        "recall": 0.941414,
        "f1": 0.923345,
        "accuracy": 0.941414,
        "main_score": 0.923345,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.891831,
        "recall": 0.922535,
        "f1": 0.901362,
        "accuracy": 0.922535,
        "main_score": 0.901362,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.855397,
        "recall": 0.890411,
        "f1": 0.865484,
        "accuracy": 0.890411,
        "main_score": 0.865484,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.932161,
        "recall": 0.952294,
        "f1": 0.938442,
        "accuracy": 0.952294,
        "main_score": 0.938442,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.959575,
        "recall": 0.9729,
        "f1": 0.963979,
        "accuracy": 0.9729,
        "main_score": 0.963979,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.896404,
        "recall": 0.928076,
        "f1": 0.906326,
        "accuracy": 0.928076,
        "main_score": 0.906326,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.893166,
        "recall": 0.926499,
        "f1": 0.903772,
        "accuracy": 0.926499,
        "main_score": 0.903772,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.920045,
        "recall": 0.945946,
        "f1": 0.928491,
        "accuracy": 0.945946,
        "main_score": 0.928491,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.933814,
        "recall": 0.954376,
        "f1": 0.940472,
        "accuracy": 0.954376,
        "main_score": 0.940472,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.84781,
        "recall": 0.891429,
        "f1": 0.861469,
        "accuracy": 0.891429,
        "main_score": 0.861469,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.83311,
        "recall": 0.878244,
        "f1": 0.84699,
        "accuracy": 0.878244,
        "main_score": 0.84699,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.939355,
        "recall": 0.957232,
        "f1": 0.945056,
        "accuracy": 0.957232,
        "main_score": 0.945056,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.927293,
        "recall": 0.948694,
        "f1": 0.934011,
        "accuracy": 0.948694,
        "main_score": 0.934011,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.98236,
        "recall": 0.98824,
        "f1": 0.98432,
        "accuracy": 0.98824,
        "main_score": 0.98432,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.909124,
        "recall": 0.937226,
        "f1": 0.918005,
        "accuracy": 0.937226,
        "main_score": 0.918005,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.948204,
        "recall": 0.964088,
        "f1": 0.953223,
        "accuracy": 0.964088,
        "main_score": 0.953223,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.915629,
        "recall": 0.940856,
        "f1": 0.923632,
        "accuracy": 0.940856,
        "main_score": 0.923632,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.903887,
        "recall": 0.932907,
        "f1": 0.912886,
        "accuracy": 0.932907,
        "main_score": 0.912886,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.957061,
        "recall": 0.969466,
        "f1": 0.960814,
        "accuracy": 0.969466,
        "main_score": 0.960814,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.838776,
        "recall": 0.880302,
        "f1": 0.851325,
        "accuracy": 0.880302,
        "main_score": 0.851325,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.897389,
        "recall": 0.927445,
        "f1": 0.906625,
        "accuracy": 0.927445,
        "main_score": 0.906625,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.88878,
        "recall": 0.921388,
        "f1": 0.899056,
        "accuracy": 0.921388,
        "main_score": 0.899056,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.850993,
        "recall": 0.891001,
        "f1": 0.863033,
        "accuracy": 0.891001,
        "main_score": 0.863033,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.871943,
        "recall": 0.907336,
        "f1": 0.882819,
        "accuracy": 0.907336,
        "main_score": 0.882819,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.910535,
        "recall": 0.936097,
        "f1": 0.91825,
        "accuracy": 0.936097,
        "main_score": 0.91825,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.901153,
        "recall": 0.931774,
        "f1": 0.911046,
        "accuracy": 0.931774,
        "main_score": 0.911046,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.917422,
        "recall": 0.941727,
        "f1": 0.925165,
        "accuracy": 0.941727,
        "main_score": 0.925165,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.84612,
        "recall": 0.888242,
        "f1": 0.858556,
        "accuracy": 0.888242,
        "main_score": 0.858556,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.814594,
        "recall": 0.868204,
        "f1": 0.831173,
        "accuracy": 0.868204,
        "main_score": 0.831173,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.838524,
        "recall": 0.884194,
        "f1": 0.852403,
        "accuracy": 0.884194,
        "main_score": 0.852403,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.916693,
        "recall": 0.940965,
        "f1": 0.92426,
        "accuracy": 0.940965,
        "main_score": 0.92426,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.93243,
        "recall": 0.952555,
        "f1": 0.938721,
        "accuracy": 0.952555,
        "main_score": 0.938721,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.923119,
        "recall": 0.947178,
        "f1": 0.930945,
        "accuracy": 0.947178,
        "main_score": 0.930945,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.895054,
        "recall": 0.922764,
        "f1": 0.903388,
        "accuracy": 0.922764,
        "main_score": 0.903388,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.91831,
        "recall": 0.941772,
        "f1": 0.925756,
        "accuracy": 0.941772,
        "main_score": 0.925756,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.908163,
        "recall": 0.933492,
        "f1": 0.915811,
        "accuracy": 0.933492,
        "main_score": 0.915811,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.895082,
        "recall": 0.925182,
        "f1": 0.904425,
        "accuracy": 0.925182,
        "main_score": 0.904425,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.932601,
        "recall": 0.953846,
        "f1": 0.93956,
        "accuracy": 0.953846,
        "main_score": 0.93956,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.966525,
        "recall": 0.976788,
        "f1": 0.969829,
        "accuracy": 0.976788,
        "main_score": 0.969829,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.915078,
        "recall": 0.942017,
        "f1": 0.923802,
        "accuracy": 0.942017,
        "main_score": 0.923802,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.897356,
        "recall": 0.928699,
        "f1": 0.907427,
        "accuracy": 0.928699,
        "main_score": 0.907427,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.913136,
        "recall": 0.939619,
        "f1": 0.921398,
        "accuracy": 0.939619,
        "main_score": 0.921398,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.882098,
        "recall": 0.91984,
        "f1": 0.894456,
        "accuracy": 0.91984,
        "main_score": 0.894456,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.893929,
        "recall": 0.923602,
        "f1": 0.902664,
        "accuracy": 0.923602,
        "main_score": 0.902664,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.898691,
        "recall": 0.913907,
        "f1": 0.90205,
        "accuracy": 0.913907,
        "main_score": 0.90205,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.958473,
        "recall": 0.9699,
        "f1": 0.962096,
        "accuracy": 0.9699,
        "main_score": 0.962096,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.959729,
        "recall": 0.971292,
        "f1": 0.963317,
        "accuracy": 0.971292,
        "main_score": 0.963317,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.967568,
        "recall": 0.978378,
        "f1": 0.971171,
        "accuracy": 0.978378,
        "main_score": 0.971171,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.976869,
        "recall": 0.983761,
        "f1": 0.979048,
        "accuracy": 0.983761,
        "main_score": 0.979048,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.922722,
        "recall": 0.942356,
        "f1": 0.928649,
        "accuracy": 0.942356,
        "main_score": 0.928649,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.924391,
        "recall": 0.947396,
        "f1": 0.931782,
        "accuracy": 0.947396,
        "main_score": 0.931782,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.749592,
        "recall": 0.82263,
        "f1": 0.771764,
        "accuracy": 0.82263,
        "main_score": 0.771764,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.896665,
        "recall": 0.922472,
        "f1": 0.9043,
        "accuracy": 0.922472,
        "main_score": 0.9043,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.936188,
        "recall": 0.954135,
        "f1": 0.941702,
        "accuracy": 0.954135,
        "main_score": 0.941702,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.969907,
        "recall": 0.979255,
        "f1": 0.97298,
        "accuracy": 0.979255,
        "main_score": 0.97298,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.93067,
        "recall": 0.951029,
        "f1": 0.93718,
        "accuracy": 0.951029,
        "main_score": 0.93718,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.917191,
        "recall": 0.940546,
        "f1": 0.92424,
        "accuracy": 0.940546,
        "main_score": 0.92424,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.911192,
        "recall": 0.937272,
        "f1": 0.919398,
        "accuracy": 0.937272,
        "main_score": 0.919398,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.943899,
        "recall": 0.959466,
        "f1": 0.948637,
        "accuracy": 0.959466,
        "main_score": 0.948637,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.89354,
        "recall": 0.923324,
        "f1": 0.902887,
        "accuracy": 0.923324,
        "main_score": 0.902887,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.698526,
        "recall": 0.782313,
        "f1": 0.723129,
        "accuracy": 0.782313,
        "main_score": 0.723129,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.893021,
        "recall": 0.922553,
        "f1": 0.902111,
        "accuracy": 0.922553,
        "main_score": 0.902111,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.923261,
        "recall": 0.945606,
        "f1": 0.930254,
        "accuracy": 0.945606,
        "main_score": 0.930254,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.928671,
        "recall": 0.950054,
        "f1": 0.935449,
        "accuracy": 0.950054,
        "main_score": 0.935449,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.921293,
        "recall": 0.944871,
        "f1": 0.928856,
        "accuracy": 0.944871,
        "main_score": 0.928856,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.925848,
        "recall": 0.948305,
        "f1": 0.933009,
        "accuracy": 0.948305,
        "main_score": 0.933009,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.893145,
        "recall": 0.922843,
        "f1": 0.902314,
        "accuracy": 0.922843,
        "main_score": 0.902314,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.928009,
        "recall": 0.949757,
        "f1": 0.934963,
        "accuracy": 0.949757,
        "main_score": 0.934963,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.70469,
        "recall": 0.769452,
        "f1": 0.722021,
        "accuracy": 0.769452,
        "main_score": 0.722021,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.903314,
        "recall": 0.927657,
        "f1": 0.910429,
        "accuracy": 0.927657,
        "main_score": 0.910429,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.851974,
        "recall": 0.888722,
        "f1": 0.862649,
        "accuracy": 0.888722,
        "main_score": 0.862649,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.893584,
        "recall": 0.918686,
        "f1": 0.900646,
        "accuracy": 0.918686,
        "main_score": 0.900646,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.939924,
        "recall": 0.95801,
        "f1": 0.945709,
        "accuracy": 0.95801,
        "main_score": 0.945709,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.935559,
        "recall": 0.954476,
        "f1": 0.941386,
        "accuracy": 0.954476,
        "main_score": 0.941386,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.910821,
        "recall": 0.934494,
        "f1": 0.9179,
        "accuracy": 0.934494,
        "main_score": 0.9179,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.864731,
        "recall": 0.89173,
        "f1": 0.87181,
        "accuracy": 0.89173,
        "main_score": 0.87181,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.700395,
        "recall": 0.750594,
        "f1": 0.714046,
        "accuracy": 0.750594,
        "main_score": 0.714046,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.760289,
        "recall": 0.81672,
        "f1": 0.775639,
        "accuracy": 0.81672,
        "main_score": 0.775639,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.776491,
        "recall": 0.83871,
        "f1": 0.795406,
        "accuracy": 0.83871,
        "main_score": 0.795406,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.809745,
        "recall": 0.860656,
        "f1": 0.825284,
        "accuracy": 0.860656,
        "main_score": 0.825284,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.821879,
        "recall": 0.865385,
        "f1": 0.834348,
        "accuracy": 0.865385,
        "main_score": 0.834348,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.916256,
        "recall": 0.941048,
        "f1": 0.924083,
        "accuracy": 0.941048,
        "main_score": 0.924083,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.910132,
        "recall": 0.93601,
        "f1": 0.918157,
        "accuracy": 0.93601,
        "main_score": 0.918157,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.954999,
        "recall": 0.968693,
        "f1": 0.959443,
        "accuracy": 0.968693,
        "main_score": 0.959443,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.948639,
        "recall": 0.963988,
        "f1": 0.953517,
        "accuracy": 0.963988,
        "main_score": 0.953517,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.929,
        "recall": 0.9498,
        "f1": 0.935547,
        "accuracy": 0.9498,
        "main_score": 0.935547,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.912497,
        "recall": 0.937144,
        "f1": 0.919991,
        "accuracy": 0.937144,
        "main_score": 0.919991,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.932526,
        "recall": 0.953453,
        "f1": 0.939202,
        "accuracy": 0.953453,
        "main_score": 0.939202,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.938458,
        "recall": 0.957413,
        "f1": 0.944576,
        "accuracy": 0.957413,
        "main_score": 0.944576,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.935422,
        "recall": 0.95464,
        "f1": 0.941512,
        "accuracy": 0.95464,
        "main_score": 0.941512,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.912558,
        "recall": 0.937729,
        "f1": 0.920433,
        "accuracy": 0.937729,
        "main_score": 0.920433,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.930383,
        "recall": 0.949724,
        "f1": 0.936356,
        "accuracy": 0.949724,
        "main_score": 0.936356,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.921597,
        "recall": 0.946088,
        "f1": 0.929532,
        "accuracy": 0.946088,
        "main_score": 0.929532,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.912004,
        "recall": 0.937677,
        "f1": 0.919928,
        "accuracy": 0.937677,
        "main_score": 0.919928,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.913542,
        "recall": 0.938917,
        "f1": 0.921349,
        "accuracy": 0.938917,
        "main_score": 0.921349,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.962264,
        "recall": 0.973144,
        "f1": 0.965603,
        "accuracy": 0.973144,
        "main_score": 0.965603,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.93337,
        "recall": 0.952082,
        "f1": 0.939073,
        "accuracy": 0.952082,
        "main_score": 0.939073,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.947256,
        "recall": 0.963255,
        "f1": 0.952353,
        "accuracy": 0.963255,
        "main_score": 0.952353,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.878383,
        "recall": 0.909327,
        "f1": 0.887202,
        "accuracy": 0.909327,
        "main_score": 0.887202,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.955654,
        "recall": 0.969481,
        "f1": 0.960148,
        "accuracy": 0.969481,
        "main_score": 0.960148,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.912841,
        "recall": 0.93779,
        "f1": 0.920512,
        "accuracy": 0.93779,
        "main_score": 0.920512,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.908057,
        "recall": 0.93407,
        "f1": 0.916015,
        "accuracy": 0.93407,
        "main_score": 0.916015,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.973169,
        "recall": 0.982112,
        "f1": 0.97615,
        "accuracy": 0.982112,
        "main_score": 0.97615,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.989399,
        "recall": 0.992933,
        "f1": 0.990577,
        "accuracy": 0.992933,
        "main_score": 0.990577,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.984631,
        "recall": 0.989754,
        "f1": 0.986339,
        "accuracy": 0.989754,
        "main_score": 0.986339,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.990244,
        "recall": 0.993496,
        "f1": 0.991328,
        "accuracy": 0.993496,
        "main_score": 0.991328,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.994495,
        "recall": 0.99633,
        "f1": 0.995107,
        "accuracy": 0.99633,
        "main_score": 0.995107,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.966667,
        "recall": 0.977778,
        "f1": 0.97037,
        "accuracy": 0.977778,
        "main_score": 0.97037,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.980583,
        "recall": 0.985437,
        "f1": 0.982201,
        "accuracy": 0.985437,
        "main_score": 0.982201,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.943729,
        "recall": 0.96134,
        "f1": 0.949313,
        "accuracy": 0.96134,
        "main_score": 0.949313,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.901499,
        "recall": 0.926471,
        "f1": 0.908578,
        "accuracy": 0.926471,
        "main_score": 0.908578,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.844662,
        "recall": 0.887342,
        "f1": 0.857637,
        "accuracy": 0.887342,
        "main_score": 0.857637,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.823333,
        "recall": 0.87092,
        "f1": 0.837413,
        "accuracy": 0.87092,
        "main_score": 0.837413,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.836014,
        "recall": 0.880026,
        "f1": 0.849364,
        "accuracy": 0.880026,
        "main_score": 0.849364,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.885408,
        "recall": 0.915584,
        "f1": 0.894524,
        "accuracy": 0.915584,
        "main_score": 0.894524,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.9801,
        "recall": 0.986733,
        "f1": 0.982311,
        "accuracy": 0.986733,
        "main_score": 0.982311,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.985126,
        "recall": 0.989759,
        "f1": 0.986589,
        "accuracy": 0.989759,
        "main_score": 0.986589,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.959677,
        "recall": 0.971402,
        "f1": 0.963302,
        "accuracy": 0.971402,
        "main_score": 0.963302,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.930006,
        "recall": 0.952257,
        "f1": 0.937211,
        "accuracy": 0.952257,
        "main_score": 0.937211,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.940706,
        "recall": 0.958675,
        "f1": 0.946393,
        "accuracy": 0.958675,
        "main_score": 0.946393,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.943935,
        "recall": 0.96055,
        "f1": 0.949147,
        "accuracy": 0.96055,
        "main_score": 0.949147,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.931038,
        "recall": 0.950252,
        "f1": 0.937032,
        "accuracy": 0.950252,
        "main_score": 0.937032,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.941273,
        "recall": 0.958423,
        "f1": 0.946638,
        "accuracy": 0.958423,
        "main_score": 0.946638,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.78826,
        "recall": 0.84106,
        "f1": 0.803215,
        "accuracy": 0.84106,
        "main_score": 0.803215,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.943945,
        "recall": 0.96223,
        "f1": 0.94994,
        "accuracy": 0.96223,
        "main_score": 0.94994,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.824898,
        "recall": 0.860006,
        "f1": 0.834995,
        "accuracy": 0.860006,
        "main_score": 0.834995,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.925241,
        "recall": 0.947243,
        "f1": 0.932215,
        "accuracy": 0.947243,
        "main_score": 0.932215,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.859551,
        "recall": 0.895692,
        "f1": 0.870052,
        "accuracy": 0.895692,
        "main_score": 0.870052,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.982425,
        "recall": 0.988283,
        "f1": 0.984377,
        "accuracy": 0.988283,
        "main_score": 0.984377,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.960813,
        "recall": 0.973214,
        "f1": 0.964782,
        "accuracy": 0.973214,
        "main_score": 0.964782,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.90311,
        "recall": 0.929062,
        "f1": 0.911033,
        "accuracy": 0.929062,
        "main_score": 0.911033,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.96094,
        "recall": 0.972496,
        "f1": 0.964616,
        "accuracy": 0.972496,
        "main_score": 0.964616,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.762779,
        "recall": 0.824022,
        "f1": 0.77995,
        "accuracy": 0.824022,
        "main_score": 0.77995,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.915857,
        "recall": 0.938965,
        "f1": 0.922903,
        "accuracy": 0.938965,
        "main_score": 0.922903,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.945162,
        "recall": 0.960074,
        "f1": 0.949612,
        "accuracy": 0.960074,
        "main_score": 0.949612,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.960983,
        "recall": 0.973988,
        "f1": 0.965318,
        "accuracy": 0.973988,
        "main_score": 0.965318,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.948052,
        "recall": 0.963253,
        "f1": 0.952776,
        "accuracy": 0.963253,
        "main_score": 0.952776,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.871795,
        "recall": 0.907322,
        "f1": 0.882501,
        "accuracy": 0.907322,
        "main_score": 0.882501,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.835753,
        "recall": 0.878481,
        "f1": 0.848066,
        "accuracy": 0.878481,
        "main_score": 0.848066,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.994643,
        "recall": 0.996429,
        "f1": 0.995238,
        "accuracy": 0.996429,
        "main_score": 0.995238,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.955295,
        "recall": 0.965885,
        "f1": 0.958422,
        "accuracy": 0.965885,
        "main_score": 0.958422,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.916022,
        "recall": 0.939602,
        "f1": 0.923182,
        "accuracy": 0.939602,
        "main_score": 0.923182,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.93861,
        "recall": 0.957239,
        "f1": 0.944461,
        "accuracy": 0.957239,
        "main_score": 0.944461,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.933885,
        "recall": 0.952242,
        "f1": 0.939593,
        "accuracy": 0.952242,
        "main_score": 0.939593,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.969675,
        "recall": 0.979365,
        "f1": 0.972841,
        "accuracy": 0.979365,
        "main_score": 0.972841,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.949929,
        "recall": 0.964791,
        "f1": 0.954568,
        "accuracy": 0.964791,
        "main_score": 0.954568,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.941445,
        "recall": 0.958654,
        "f1": 0.946841,
        "accuracy": 0.958654,
        "main_score": 0.946841,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.896815,
        "recall": 0.924301,
        "f1": 0.904859,
        "accuracy": 0.924301,
        "main_score": 0.904859,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.860276,
        "recall": 0.90069,
        "f1": 0.87268,
        "accuracy": 0.90069,
        "main_score": 0.87268,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.923789,
        "recall": 0.945607,
        "f1": 0.930573,
        "accuracy": 0.945607,
        "main_score": 0.930573,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.935479,
        "recall": 0.950495,
        "f1": 0.939714,
        "accuracy": 0.950495,
        "main_score": 0.939714,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.92214,
        "recall": 0.943381,
        "f1": 0.928516,
        "accuracy": 0.943381,
        "main_score": 0.928516,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.986388,
        "recall": 0.990926,
        "f1": 0.987901,
        "accuracy": 0.990926,
        "main_score": 0.987901,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.940827,
        "recall": 0.959459,
        "f1": 0.946765,
        "accuracy": 0.959459,
        "main_score": 0.946765,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.9093,
        "recall": 0.933999,
        "f1": 0.916761,
        "accuracy": 0.933999,
        "main_score": 0.916761,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.914289,
        "recall": 0.938327,
        "f1": 0.921543,
        "accuracy": 0.938327,
        "main_score": 0.921543,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.977612,
        "recall": 0.985075,
        "f1": 0.9801,
        "accuracy": 0.985075,
        "main_score": 0.9801,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.964926,
        "recall": 0.976266,
        "f1": 0.968618,
        "accuracy": 0.976266,
        "main_score": 0.968618,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.873168,
        "recall": 0.902803,
        "f1": 0.881349,
        "accuracy": 0.902803,
        "main_score": 0.881349,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 4061.471436738968,
  "kg_co2_emissions": null
}