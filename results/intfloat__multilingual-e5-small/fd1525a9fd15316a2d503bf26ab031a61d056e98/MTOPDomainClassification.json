{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "task_name": "MTOPDomainClassification",
  "mteb_version": "1.36.26",
  "scores": {
    "validation": [
      {
        "accuracy": 0.860661,
        "f1": 0.84838,
        "f1_weighted": 0.860317,
        "scores_per_experiment": [
          {
            "accuracy": 0.873829,
            "f1": 0.862083,
            "f1_weighted": 0.873636
          },
          {
            "accuracy": 0.839669,
            "f1": 0.829691,
            "f1_weighted": 0.839844
          },
          {
            "accuracy": 0.854545,
            "f1": 0.837422,
            "f1_weighted": 0.854302
          },
          {
            "accuracy": 0.869972,
            "f1": 0.857268,
            "f1_weighted": 0.868732
          },
          {
            "accuracy": 0.872176,
            "f1": 0.85866,
            "f1_weighted": 0.871064
          },
          {
            "accuracy": 0.857851,
            "f1": 0.838354,
            "f1_weighted": 0.855244
          },
          {
            "accuracy": 0.863912,
            "f1": 0.854162,
            "f1_weighted": 0.863789
          },
          {
            "accuracy": 0.842975,
            "f1": 0.835944,
            "f1_weighted": 0.844849
          },
          {
            "accuracy": 0.860055,
            "f1": 0.851354,
            "f1_weighted": 0.860699
          },
          {
            "accuracy": 0.871625,
            "f1": 0.858866,
            "f1_weighted": 0.871011
          }
        ],
        "main_score": 0.860661,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.862468,
        "f1": 0.847967,
        "f1_weighted": 0.861675,
        "scores_per_experiment": [
          {
            "accuracy": 0.873204,
            "f1": 0.8603,
            "f1_weighted": 0.872062
          },
          {
            "accuracy": 0.840518,
            "f1": 0.826207,
            "f1_weighted": 0.840088
          },
          {
            "accuracy": 0.861651,
            "f1": 0.839463,
            "f1_weighted": 0.860128
          },
          {
            "accuracy": 0.872077,
            "f1": 0.859522,
            "f1_weighted": 0.871429
          },
          {
            "accuracy": 0.871231,
            "f1": 0.856149,
            "f1_weighted": 0.869944
          },
          {
            "accuracy": 0.857706,
            "f1": 0.835122,
            "f1_weighted": 0.854029
          },
          {
            "accuracy": 0.86785,
            "f1": 0.8532,
            "f1_weighted": 0.867412
          },
          {
            "accuracy": 0.84869,
            "f1": 0.840454,
            "f1_weighted": 0.850568
          },
          {
            "accuracy": 0.857988,
            "f1": 0.848332,
            "f1_weighted": 0.85862
          },
          {
            "accuracy": 0.873767,
            "f1": 0.860924,
            "f1_weighted": 0.872476
          }
        ],
        "main_score": 0.862468,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "accuracy": 0.891268,
        "f1": 0.889342,
        "f1_weighted": 0.891016,
        "scores_per_experiment": [
          {
            "accuracy": 0.893525,
            "f1": 0.889279,
            "f1_weighted": 0.893068
          },
          {
            "accuracy": 0.906065,
            "f1": 0.903372,
            "f1_weighted": 0.905469
          },
          {
            "accuracy": 0.882125,
            "f1": 0.878881,
            "f1_weighted": 0.881288
          },
          {
            "accuracy": 0.888281,
            "f1": 0.88795,
            "f1_weighted": 0.890343
          },
          {
            "accuracy": 0.891245,
            "f1": 0.888304,
            "f1_weighted": 0.891191
          },
          {
            "accuracy": 0.883493,
            "f1": 0.885121,
            "f1_weighted": 0.882575
          },
          {
            "accuracy": 0.885317,
            "f1": 0.881736,
            "f1_weighted": 0.884242
          },
          {
            "accuracy": 0.906065,
            "f1": 0.904771,
            "f1_weighted": 0.906593
          },
          {
            "accuracy": 0.885317,
            "f1": 0.886153,
            "f1_weighted": 0.884991
          },
          {
            "accuracy": 0.891245,
            "f1": 0.88785,
            "f1_weighted": 0.890398
          }
        ],
        "main_score": 0.891268,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 28.34384322166443,
  "kg_co2_emissions": null
}