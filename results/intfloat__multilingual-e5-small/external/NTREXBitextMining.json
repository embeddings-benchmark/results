{
    "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
    "task_name": "NTREXBitextMining",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "arb_Arab-rus_Cyrl",
                "languages": [
                    "arb-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8647971957936904,
                "f1": 0.8279864240805653,
                "main_score": 0.8279864240805653,
                "precision": 0.8121485800128767,
                "recall": 0.8647971957936904
            },
            {
                "hf_subset": "bel_Cyrl-rus_Cyrl",
                "languages": [
                    "bel-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9484226339509264,
                "f1": 0.9356399067465666,
                "main_score": 0.9356399067465666,
                "precision": 0.9301619095309631,
                "recall": 0.9484226339509264
            },
            {
                "hf_subset": "ben_Beng-rus_Cyrl",
                "languages": [
                    "ben-Beng",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9218828242363544,
                "f1": 0.9042393889620612,
                "main_score": 0.9042393889620612,
                "precision": 0.8967904925153297,
                "recall": 0.9218828242363544
            },
            {
                "hf_subset": "bos_Latn-rus_Cyrl",
                "languages": [
                    "bos-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9469203805708563,
                "f1": 0.9337172425304624,
                "main_score": 0.9337172425304624,
                "precision": 0.9279204521067315,
                "recall": 0.9469203805708563
            },
            {
                "hf_subset": "bul_Cyrl-rus_Cyrl",
                "languages": [
                    "bul-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9699549323985979,
                "f1": 0.9613086296110833,
                "main_score": 0.9613086296110833,
                "precision": 0.9572441996327826,
                "recall": 0.9699549323985979
            },
            {
                "hf_subset": "ces_Latn-rus_Cyrl",
                "languages": [
                    "ces-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9594391587381071,
                "f1": 0.9490680465142156,
                "main_score": 0.9490680465142156,
                "precision": 0.9444541812719079,
                "recall": 0.9594391587381071
            },
            {
                "hf_subset": "deu_Latn-rus_Cyrl",
                "languages": [
                    "deu-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9609414121181773,
                "f1": 0.9494408279085295,
                "main_score": 0.9494408279085295,
                "precision": 0.9441245201135037,
                "recall": 0.9609414121181773
            },
            {
                "hf_subset": "ell_Grek-rus_Cyrl",
                "languages": [
                    "ell-Grek",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9619429143715572,
                "f1": 0.9512101485561676,
                "main_score": 0.9512101485561676,
                "precision": 0.9460440660991487,
                "recall": 0.9619429143715572
            },
            {
                "hf_subset": "eng_Latn-rus_Cyrl",
                "languages": [
                    "eng-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9649474211316975,
                "f1": 0.9546581777428045,
                "main_score": 0.9546581777428045,
                "precision": 0.9498414288098814,
                "recall": 0.9649474211316975
            },
            {
                "hf_subset": "fas_Arab-rus_Cyrl",
                "languages": [
                    "fas-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9444166249374061,
                "f1": 0.9292383018972905,
                "main_score": 0.9292383018972905,
                "precision": 0.9221957936905357,
                "recall": 0.9444166249374061
            },
            {
                "hf_subset": "fin_Latn-rus_Cyrl",
                "languages": [
                    "fin-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9218828242363544,
                "f1": 0.9029806614683931,
                "main_score": 0.9029806614683931,
                "precision": 0.8942580537472877,
                "recall": 0.9218828242363544
            },
            {
                "hf_subset": "fra_Latn-rus_Cyrl",
                "languages": [
                    "fra-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9584376564847271,
                "f1": 0.9481054915706895,
                "main_score": 0.9481054915706895,
                "precision": 0.9431369276136427,
                "recall": 0.9584376564847271
            },
            {
                "hf_subset": "heb_Hebr-rus_Cyrl",
                "languages": [
                    "heb-Hebr",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9489233850776163,
                "f1": 0.9342513770655985,
                "main_score": 0.9342513770655985,
                "precision": 0.9273493573693875,
                "recall": 0.9489233850776163
            },
            {
                "hf_subset": "hin_Deva-rus_Cyrl",
                "languages": [
                    "hin-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9323985978968453,
                "f1": 0.9152816526376867,
                "main_score": 0.9152816526376867,
                "precision": 0.9076745946425465,
                "recall": 0.9323985978968453
            },
            {
                "hf_subset": "hrv_Latn-rus_Cyrl",
                "languages": [
                    "hrv-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9399098647971958,
                "f1": 0.9236354531797697,
                "main_score": 0.9236354531797697,
                "precision": 0.9163228970439787,
                "recall": 0.9399098647971958
            },
            {
                "hf_subset": "hun_Latn-rus_Cyrl",
                "languages": [
                    "hun-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9364046069103655,
                "f1": 0.9205224503421799,
                "main_score": 0.9205224503421799,
                "precision": 0.9133998616973079,
                "recall": 0.9364046069103655
            },
            {
                "hf_subset": "ind_Latn-rus_Cyrl",
                "languages": [
                    "ind-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9168753129694541,
                "f1": 0.8926222667334335,
                "main_score": 0.8926222667334335,
                "precision": 0.8814638624603571,
                "recall": 0.9168753129694541
            },
            {
                "hf_subset": "jpn_Jpan-rus_Cyrl",
                "languages": [
                    "jpn-Jpan",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9128693039559339,
                "f1": 0.8921161763348957,
                "main_score": 0.8921161763348957,
                "precision": 0.8831188340952988,
                "recall": 0.9128693039559339
            },
            {
                "hf_subset": "kor_Hang-rus_Cyrl",
                "languages": [
                    "kor-Hang",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8953430145217827,
                "f1": 0.8688322165788365,
                "main_score": 0.8688322165788365,
                "precision": 0.8573950211030831,
                "recall": 0.8953430145217827
            },
            {
                "hf_subset": "lit_Latn-rus_Cyrl",
                "languages": [
                    "lit-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9028542814221332,
                "f1": 0.8810249103814453,
                "main_score": 0.8810249103814453,
                "precision": 0.8717689323973752,
                "recall": 0.9028542814221332
            },
            {
                "hf_subset": "mkd_Cyrl-rus_Cyrl",
                "languages": [
                    "mkd-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9504256384576866,
                "f1": 0.9365643703650712,
                "main_score": 0.9365643703650712,
                "precision": 0.9302036387915207,
                "recall": 0.9504256384576866
            },
            {
                "hf_subset": "nld_Latn-rus_Cyrl",
                "languages": [
                    "nld-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9539308963445169,
                "f1": 0.9416207644800535,
                "main_score": 0.9416207644800535,
                "precision": 0.93582516632091,
                "recall": 0.9539308963445169
            },
            {
                "hf_subset": "pol_Latn-rus_Cyrl",
                "languages": [
                    "pol-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.957436154231347,
                "f1": 0.945067601402103,
                "main_score": 0.945067601402103,
                "precision": 0.9391587381071608,
                "recall": 0.957436154231347
            },
            {
                "hf_subset": "por_Latn-rus_Cyrl",
                "languages": [
                    "por-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.6589884827240862,
                "f1": 0.6461805459419219,
                "main_score": 0.6461805459419219,
                "precision": 0.6407119451106484,
                "recall": 0.6589884827240862
            },
            {
                "hf_subset": "rus_Cyrl-arb_Arab",
                "languages": [
                    "rus-Cyrl",
                    "arb-Arab"
                ],
                "accuracy": 0.942413620430646,
                "f1": 0.9267663399861698,
                "main_score": 0.9267663399861698,
                "precision": 0.9194625271240193,
                "recall": 0.942413620430646
            },
            {
                "hf_subset": "rus_Cyrl-bel_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "bel-Cyrl"
                ],
                "accuracy": 0.9489233850776163,
                "f1": 0.9340343849106993,
                "main_score": 0.9340343849106993,
                "precision": 0.9274077783341679,
                "recall": 0.9489233850776163
            },
            {
                "hf_subset": "rus_Cyrl-ben_Beng",
                "languages": [
                    "rus-Cyrl",
                    "ben-Beng"
                ],
                "accuracy": 0.942914371557336,
                "f1": 0.9262226673343348,
                "main_score": 0.9262226673343348,
                "precision": 0.9184610248706393,
                "recall": 0.942914371557336
            },
            {
                "hf_subset": "rus_Cyrl-bos_Latn",
                "languages": [
                    "rus-Cyrl",
                    "bos-Latn"
                ],
                "accuracy": 0.956935403104657,
                "f1": 0.9450418051319402,
                "main_score": 0.9450418051319402,
                "precision": 0.9395843765648473,
                "recall": 0.956935403104657
            },
            {
                "hf_subset": "rus_Cyrl-bul_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "bul-Cyrl"
                ],
                "accuracy": 0.9589384076114171,
                "f1": 0.9466199298948423,
                "main_score": 0.9466199298948423,
                "precision": 0.9408028709731263,
                "recall": 0.9589384076114171
            },
            {
                "hf_subset": "rus_Cyrl-ces_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ces-Latn"
                ],
                "accuracy": 0.9394091136705057,
                "f1": 0.9237467312079229,
                "main_score": 0.9237467312079229,
                "precision": 0.9166207644800535,
                "recall": 0.9394091136705057
            },
            {
                "hf_subset": "rus_Cyrl-deu_Latn",
                "languages": [
                    "rus-Cyrl",
                    "deu-Latn"
                ],
                "accuracy": 0.9594391587381071,
                "f1": 0.9476214321482224,
                "main_score": 0.9476214321482224,
                "precision": 0.9420380570856285,
                "recall": 0.9594391587381071
            },
            {
                "hf_subset": "rus_Cyrl-ell_Grek",
                "languages": [
                    "rus-Cyrl",
                    "ell-Grek"
                ],
                "accuracy": 0.9544316474712068,
                "f1": 0.9414788849941579,
                "main_score": 0.9414788849941579,
                "precision": 0.9354197963612084,
                "recall": 0.9544316474712068
            },
            {
                "hf_subset": "rus_Cyrl-eng_Latn",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 0.9814722083124687,
                "f1": 0.9757135703555333,
                "main_score": 0.9757135703555333,
                "precision": 0.9729594391587381,
                "recall": 0.9814722083124687
            },
            {
                "hf_subset": "rus_Cyrl-fas_Arab",
                "languages": [
                    "rus-Cyrl",
                    "fas-Arab"
                ],
                "accuracy": 0.9464196294441662,
                "f1": 0.9324653647137372,
                "main_score": 0.9324653647137372,
                "precision": 0.9260724419963279,
                "recall": 0.9464196294441662
            },
            {
                "hf_subset": "rus_Cyrl-fin_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fin-Latn"
                ],
                "accuracy": 0.8798197295943916,
                "f1": 0.8523368385912201,
                "main_score": 0.8523368385912201,
                "precision": 0.8408159858835873,
                "recall": 0.8798197295943916
            },
            {
                "hf_subset": "rus_Cyrl-fra_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fra-Latn"
                ],
                "accuracy": 0.9624436654982473,
                "f1": 0.9507093974294775,
                "main_score": 0.9507093974294775,
                "precision": 0.9449591053246535,
                "recall": 0.9624436654982473
            },
            {
                "hf_subset": "rus_Cyrl-heb_Hebr",
                "languages": [
                    "rus-Cyrl",
                    "heb-Hebr"
                ],
                "accuracy": 0.9108662994491737,
                "f1": 0.8851610749457519,
                "main_score": 0.8851610749457519,
                "precision": 0.8736187614755466,
                "recall": 0.9108662994491737
            },
            {
                "hf_subset": "rus_Cyrl-hin_Deva",
                "languages": [
                    "rus-Cyrl",
                    "hin-Deva"
                ],
                "accuracy": 0.9504256384576866,
                "f1": 0.9366382907694876,
                "main_score": 0.9366382907694876,
                "precision": 0.9305291270238691,
                "recall": 0.9504256384576866
            },
            {
                "hf_subset": "rus_Cyrl-hrv_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hrv-Latn"
                ],
                "accuracy": 0.9514271407110667,
                "f1": 0.9374812218327491,
                "main_score": 0.9374812218327491,
                "precision": 0.9310930681736892,
                "recall": 0.9514271407110667
            },
            {
                "hf_subset": "rus_Cyrl-hun_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hun-Latn"
                ],
                "accuracy": 0.9018527791687532,
                "f1": 0.8761415933423946,
                "main_score": 0.8761415933423946,
                "precision": 0.8651664003942421,
                "recall": 0.9018527791687532
            },
            {
                "hf_subset": "rus_Cyrl-ind_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ind-Latn"
                ],
                "accuracy": 0.9369053580370555,
                "f1": 0.9183608746453013,
                "main_score": 0.9183608746453013,
                "precision": 0.9097145718577867,
                "recall": 0.9369053580370555
            },
            {
                "hf_subset": "rus_Cyrl-jpn_Jpan",
                "languages": [
                    "rus-Cyrl",
                    "jpn-Jpan"
                ],
                "accuracy": 0.8948422633950927,
                "f1": 0.8691271033534429,
                "main_score": 0.8691271033534429,
                "precision": 0.8582671626487351,
                "recall": 0.8948422633950927
            },
            {
                "hf_subset": "rus_Cyrl-kor_Hang",
                "languages": [
                    "rus-Cyrl",
                    "kor-Hang"
                ],
                "accuracy": 0.8848272408612919,
                "f1": 0.8535080398375342,
                "main_score": 0.8535080398375342,
                "precision": 0.839588549490903,
                "recall": 0.8848272408612919
            },
            {
                "hf_subset": "rus_Cyrl-lit_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lit-Latn"
                ],
                "accuracy": 0.9033550325488232,
                "f1": 0.8768831819157308,
                "main_score": 0.8768831819157308,
                "precision": 0.8651524906407231,
                "recall": 0.9033550325488232
            },
            {
                "hf_subset": "rus_Cyrl-mkd_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "mkd-Cyrl"
                ],
                "accuracy": 0.9594391587381071,
                "f1": 0.9490402270071775,
                "main_score": 0.9490402270071775,
                "precision": 0.9443915873810715,
                "recall": 0.9594391587381071
            },
            {
                "hf_subset": "rus_Cyrl-nld_Latn",
                "languages": [
                    "rus-Cyrl",
                    "nld-Latn"
                ],
                "accuracy": 0.9298948422633951,
                "f1": 0.9104323151393756,
                "main_score": 0.9104323151393756,
                "precision": 0.9014688699716241,
                "recall": 0.9298948422633951
            },
            {
                "hf_subset": "rus_Cyrl-pol_Latn",
                "languages": [
                    "rus-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 0.943415122684026,
                "f1": 0.928726422967785,
                "main_score": 0.928726422967785,
                "precision": 0.9219829744616925,
                "recall": 0.943415122684026
            },
            {
                "hf_subset": "rus_Cyrl-por_Latn",
                "languages": [
                    "rus-Cyrl",
                    "por-Latn"
                ],
                "accuracy": 0.8617926890335503,
                "f1": 0.827304882287356,
                "main_score": 0.827304882287356,
                "precision": 0.8128162481817963,
                "recall": 0.8617926890335503
            },
            {
                "hf_subset": "rus_Cyrl-slk_Latn",
                "languages": [
                    "rus-Cyrl",
                    "slk-Latn"
                ],
                "accuracy": 0.927391086629945,
                "f1": 0.9075112669003507,
                "main_score": 0.9075112669003507,
                "precision": 0.898564513436822,
                "recall": 0.927391086629945
            },
            {
                "hf_subset": "rus_Cyrl-slv_Latn",
                "languages": [
                    "rus-Cyrl",
                    "slv-Latn"
                ],
                "accuracy": 0.928893340010015,
                "f1": 0.9105992321816058,
                "main_score": 0.9105992321816058,
                "precision": 0.9022589439715127,
                "recall": 0.928893340010015
            },
            {
                "hf_subset": "rus_Cyrl-spa_Latn",
                "languages": [
                    "rus-Cyrl",
                    "spa-Latn"
                ],
                "accuracy": 0.9649474211316975,
                "f1": 0.9547154064429979,
                "main_score": 0.9547154064429979,
                "precision": 0.949799699549324,
                "recall": 0.9649474211316975
            },
            {
                "hf_subset": "rus_Cyrl-srp_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "srp-Cyrl"
                ],
                "accuracy": 0.8107160741111668,
                "f1": 0.7655687285507016,
                "main_score": 0.7655687285507016,
                "precision": 0.7471886401030116,
                "recall": 0.8107160741111668
            },
            {
                "hf_subset": "rus_Cyrl-srp_Latn",
                "languages": [
                    "rus-Cyrl",
                    "srp-Latn"
                ],
                "accuracy": 0.9514271407110667,
                "f1": 0.9373302377809138,
                "main_score": 0.9373302377809138,
                "precision": 0.9306960440660991,
                "recall": 0.9514271407110667
            },
            {
                "hf_subset": "rus_Cyrl-swa_Latn",
                "languages": [
                    "rus-Cyrl",
                    "swa-Latn"
                ],
                "accuracy": 0.9479218828242364,
                "f1": 0.9325988983475212,
                "main_score": 0.9325988983475212,
                "precision": 0.9253463528626272,
                "recall": 0.9479218828242364
            },
            {
                "hf_subset": "rus_Cyrl-swe_Latn",
                "languages": [
                    "rus-Cyrl",
                    "swe-Latn"
                ],
                "accuracy": 0.9504256384576866,
                "f1": 0.9358704723752296,
                "main_score": 0.9358704723752296,
                "precision": 0.9291437155733601,
                "recall": 0.9504256384576866
            },
            {
                "hf_subset": "rus_Cyrl-tam_Taml",
                "languages": [
                    "rus-Cyrl",
                    "tam-Taml"
                ],
                "accuracy": 0.9328993490235353,
                "f1": 0.9163912535469873,
                "main_score": 0.9163912535469873,
                "precision": 0.9087738750983617,
                "recall": 0.9328993490235353
            },
            {
                "hf_subset": "rus_Cyrl-tur_Latn",
                "languages": [
                    "rus-Cyrl",
                    "tur-Latn"
                ],
                "accuracy": 0.9374061091637457,
                "f1": 0.9196628275746953,
                "main_score": 0.9196628275746953,
                "precision": 0.9115923885828743,
                "recall": 0.9374061091637457
            },
            {
                "hf_subset": "rus_Cyrl-ukr_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "ukr-Cyrl"
                ],
                "accuracy": 0.9599399098647972,
                "f1": 0.9489567684860625,
                "main_score": 0.9489567684860625,
                "precision": 0.9437072275079287,
                "recall": 0.9599399098647972
            },
            {
                "hf_subset": "rus_Cyrl-vie_Latn",
                "languages": [
                    "rus-Cyrl",
                    "vie-Latn"
                ],
                "accuracy": 0.9143715573360041,
                "f1": 0.8898681355366382,
                "main_score": 0.8898681355366382,
                "precision": 0.8789183775663496,
                "recall": 0.9143715573360041
            },
            {
                "hf_subset": "rus_Cyrl-zho_Hant",
                "languages": [
                    "rus-Cyrl",
                    "zho-Hant"
                ],
                "accuracy": 0.927891837756635,
                "f1": 0.9079047142141783,
                "main_score": 0.9079047142141783,
                "precision": 0.8986980470706059,
                "recall": 0.927891837756635
            },
            {
                "hf_subset": "rus_Cyrl-zul_Latn",
                "languages": [
                    "rus-Cyrl",
                    "zul-Latn"
                ],
                "accuracy": 0.8743114672008012,
                "f1": 0.8404618833011422,
                "main_score": 0.8404618833011422,
                "precision": 0.8252259341393041,
                "recall": 0.8743114672008012
            },
            {
                "hf_subset": "slk_Latn-rus_Cyrl",
                "languages": [
                    "slk-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9534301452178268,
                "f1": 0.9420392493502158,
                "main_score": 0.9420392493502158,
                "precision": 0.9367384409948256,
                "recall": 0.9534301452178268
            },
            {
                "hf_subset": "slv_Latn-rus_Cyrl",
                "languages": [
                    "slv-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9223835753630446,
                "f1": 0.905061759305625,
                "main_score": 0.905061759305625,
                "precision": 0.8974231188051918,
                "recall": 0.9223835753630446
            },
            {
                "hf_subset": "spa_Latn-rus_Cyrl",
                "languages": [
                    "spa-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9654481722583875,
                "f1": 0.9554665331330328,
                "main_score": 0.9554665331330328,
                "precision": 0.950634284760474,
                "recall": 0.9654481722583875
            },
            {
                "hf_subset": "srp_Cyrl-rus_Cyrl",
                "languages": [
                    "srp-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8362543815723584,
                "f1": 0.8077095672699817,
                "main_score": 0.8077095672699817,
                "precision": 0.7974674313056886,
                "recall": 0.8362543815723584
            },
            {
                "hf_subset": "srp_Latn-rus_Cyrl",
                "languages": [
                    "srp-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9444166249374061,
                "f1": 0.9300733206591993,
                "main_score": 0.9300733206591993,
                "precision": 0.9237203026762366,
                "recall": 0.9444166249374061
            },
            {
                "hf_subset": "swa_Latn-rus_Cyrl",
                "languages": [
                    "swa-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9023535302954432,
                "f1": 0.8789596482636042,
                "main_score": 0.8789596482636042,
                "precision": 0.8687060227370693,
                "recall": 0.9023535302954432
            },
            {
                "hf_subset": "swe_Latn-rus_Cyrl",
                "languages": [
                    "swe-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9544316474712068,
                "f1": 0.941896177599733,
                "main_score": 0.941896177599733,
                "precision": 0.9361542313470206,
                "recall": 0.9544316474712068
            },
            {
                "hf_subset": "tam_Taml-rus_Cyrl",
                "languages": [
                    "tam-Taml",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8968452679018529,
                "f1": 0.8737341160650037,
                "main_score": 0.8737341160650037,
                "precision": 0.8638389402285247,
                "recall": 0.8968452679018529
            },
            {
                "hf_subset": "tur_Latn-rus_Cyrl",
                "languages": [
                    "tur-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9389083625438157,
                "f1": 0.9233892505424803,
                "main_score": 0.9233892505424803,
                "precision": 0.9163125640842216,
                "recall": 0.9389083625438157
            },
            {
                "hf_subset": "ukr_Cyrl-rus_Cyrl",
                "languages": [
                    "ukr-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9614421632448673,
                "f1": 0.9511028447433054,
                "main_score": 0.9511028447433054,
                "precision": 0.9462944416624937,
                "recall": 0.9614421632448673
            },
            {
                "hf_subset": "vie_Latn-rus_Cyrl",
                "languages": [
                    "vie-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9379068602904357,
                "f1": 0.9214989150392257,
                "main_score": 0.9214989150392257,
                "precision": 0.9139292271740945,
                "recall": 0.9379068602904357
            },
            {
                "hf_subset": "zho_Hant-rus_Cyrl",
                "languages": [
                    "zho-Hant",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8913370055082624,
                "f1": 0.8651514618639218,
                "main_score": 0.8651514618639218,
                "precision": 0.85383920035898,
                "recall": 0.8913370055082624
            },
            {
                "hf_subset": "zul_Latn-rus_Cyrl",
                "languages": [
                    "zul-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.8117175763645467,
                "f1": 0.7772331766047338,
                "main_score": 0.7772331766047338,
                "precision": 0.7624629555848075,
                "recall": 0.8117175763645467
            }
        ]
    }
}