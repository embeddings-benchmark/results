{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "task_name": "MassiveIntentClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.642892,
            "f1": 0.591653,
            "f1_weighted": 0.638392,
            "precision": 0.618946,
            "precision_weighted": 0.732099,
            "recall": 0.664225,
            "recall_weighted": 0.642892,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.642892,
            "f1": 0.590903,
            "f1_weighted": 0.639689,
            "precision": 0.599514,
            "precision_weighted": 0.73189,
            "recall": 0.669612,
            "recall_weighted": 0.642892,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.621741,
            "f1": 0.557428,
            "f1_weighted": 0.611871,
            "precision": 0.550258,
            "precision_weighted": 0.676081,
            "recall": 0.657101,
            "recall_weighted": 0.621741,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.606001,
            "f1": 0.552841,
            "f1_weighted": 0.600412,
            "precision": 0.578116,
            "precision_weighted": 0.705184,
            "recall": 0.626486,
            "recall_weighted": 0.606001,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.623217,
            "f1": 0.557556,
            "f1_weighted": 0.607249,
            "precision": 0.560399,
            "precision_weighted": 0.669806,
            "recall": 0.648036,
            "recall_weighted": 0.623217,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.606493,
            "f1": 0.56527,
            "f1_weighted": 0.589411,
            "precision": 0.572491,
            "precision_weighted": 0.705747,
            "recall": 0.665766,
            "recall_weighted": 0.606493,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.596163,
            "f1": 0.552153,
            "f1_weighted": 0.579296,
            "precision": 0.54786,
            "precision_weighted": 0.649838,
            "recall": 0.656609,
            "recall_weighted": 0.596163,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.605509,
            "f1": 0.556683,
            "f1_weighted": 0.590838,
            "precision": 0.577384,
            "precision_weighted": 0.70279,
            "recall": 0.664917,
            "recall_weighted": 0.605509,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.591244,
            "f1": 0.548106,
            "f1_weighted": 0.581304,
            "precision": 0.57752,
            "precision_weighted": 0.715187,
            "recall": 0.648955,
            "recall_weighted": 0.591244,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.625184,
            "f1": 0.579263,
            "f1_weighted": 0.616472,
            "precision": 0.601139,
            "precision_weighted": 0.717271,
            "recall": 0.658228,
            "recall_weighted": 0.625184,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.616134,
        "f1": 0.565186,
        "f1_weighted": 0.605493,
        "precision": 0.578363,
        "precision_weighted": 0.700589,
        "recall": 0.655994,
        "recall_weighted": 0.616134,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.616134,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.651984,
            "f1": 0.609691,
            "f1_weighted": 0.644479,
            "precision": 0.605978,
            "precision_weighted": 0.718285,
            "recall": 0.693253,
            "recall_weighted": 0.651984,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.641224,
            "f1": 0.613646,
            "f1_weighted": 0.638914,
            "precision": 0.613895,
            "precision_weighted": 0.714771,
            "recall": 0.695606,
            "recall_weighted": 0.641224,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.605918,
            "f1": 0.560178,
            "f1_weighted": 0.594029,
            "precision": 0.551263,
            "precision_weighted": 0.665982,
            "recall": 0.682343,
            "recall_weighted": 0.605918,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.616342,
            "f1": 0.591581,
            "f1_weighted": 0.609132,
            "precision": 0.607122,
            "precision_weighted": 0.70934,
            "recall": 0.676264,
            "recall_weighted": 0.616342,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.612307,
            "f1": 0.560861,
            "f1_weighted": 0.594843,
            "precision": 0.561487,
            "precision_weighted": 0.659408,
            "recall": 0.672725,
            "recall_weighted": 0.612307,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.604237,
            "f1": 0.583314,
            "f1_weighted": 0.58697,
            "precision": 0.578488,
            "precision_weighted": 0.695319,
            "recall": 0.697898,
            "recall_weighted": 0.604237,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.594822,
            "f1": 0.567285,
            "f1_weighted": 0.577485,
            "precision": 0.575672,
            "precision_weighted": 0.684939,
            "recall": 0.666691,
            "recall_weighted": 0.594822,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.60659,
            "f1": 0.575241,
            "f1_weighted": 0.589642,
            "precision": 0.581887,
            "precision_weighted": 0.702913,
            "recall": 0.694554,
            "recall_weighted": 0.60659,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.605918,
            "f1": 0.566113,
            "f1_weighted": 0.589623,
            "precision": 0.57339,
            "precision_weighted": 0.701652,
            "recall": 0.684696,
            "recall_weighted": 0.605918,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.61735,
            "f1": 0.583689,
            "f1_weighted": 0.612863,
            "precision": 0.592463,
            "precision_weighted": 0.716746,
            "recall": 0.675009,
            "recall_weighted": 0.61735,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.615669,
        "f1": 0.58116,
        "f1_weighted": 0.603798,
        "precision": 0.584165,
        "precision_weighted": 0.696935,
        "recall": 0.683904,
        "recall_weighted": 0.615669,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.615669,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 10.954301118850708,
  "kg_co2_emissions": null
}