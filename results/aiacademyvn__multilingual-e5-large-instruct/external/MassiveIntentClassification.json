{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.676630800268998,
                "f1": 0.6500996668051691,
                "main_score": 0.676630800268998
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.607128446536651,
                "f1": 0.5795860594874963,
                "main_score": 0.607128446536651
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.6361129791526563,
                "f1": 0.5975328290206483,
                "main_score": 0.6361129791526563
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.6900134498991257,
                "f1": 0.670230483991802,
                "main_score": 0.6900134498991257
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.6854068594485541,
                "f1": 0.6554604628946976,
                "main_score": 0.6854068594485541
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.630329522528581,
                "f1": 0.587157418570571,
                "main_score": 0.630329522528581
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.7180901143241427,
                "f1": 0.6833963989243876,
                "main_score": 0.7180901143241427
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.7247141896435777,
                "f1": 0.6956765020308262,
                "main_score": 0.7247141896435777
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.712373907195696,
                "f1": 0.6904529836036467,
                "main_score": 0.712373907195696
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.7705783456624076,
                "f1": 0.7469430584708173,
                "main_score": 0.7705783456624076
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.7282111634162745,
                "f1": 0.7077228952803761,
                "main_score": 0.7282111634162745
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.7425353059852051,
                "f1": 0.7105310103416411,
                "main_score": 0.7425353059852051
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.7228648285137861,
                "f1": 0.6908020473732226,
                "main_score": 0.7228648285137861
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.7331540013449899,
                "f1": 0.709426355465791,
                "main_score": 0.7331540013449899
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.702151983860121,
                "f1": 0.6752541755908859,
                "main_score": 0.702151983860121
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.7158372562205784,
                "f1": 0.6949769064229827,
                "main_score": 0.7158372562205784
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.7192333557498319,
                "f1": 0.6936311548259593,
                "main_score": 0.7192333557498319
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.6807330195023538,
                "f1": 0.6499882022345572,
                "main_score": 0.6807330195023538
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.7262273032952252,
                "f1": 0.706394885471001,
                "main_score": 0.7262273032952252
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.6577000672494957,
                "f1": 0.629368944815065,
                "main_score": 0.6577000672494957
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.73453261600538,
                "f1": 0.7085069934666681,
                "main_score": 0.73453261600538
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.746906523201076,
                "f1": 0.7203249740074217,
                "main_score": 0.746906523201076
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.6303631472763953,
                "f1": 0.593165215571852,
                "main_score": 0.6303631472763953
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.5891392064559515,
                "f1": 0.5736733771161129,
                "main_score": 0.5891392064559515
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.5442837928715535,
                "f1": 0.5260527294970906,
                "main_score": 0.5442837928715535
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.6633490248823135,
                "f1": 0.6321334096940406,
                "main_score": 0.6633490248823135
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.7058507061197041,
                "f1": 0.6840256628040485,
                "main_score": 0.7058507061197041
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.6911230665770006,
                "f1": 0.6644863577842305,
                "main_score": 0.6911230665770006
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.6970073974445192,
                "f1": 0.6721291337273702,
                "main_score": 0.6970073974445192
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.6643913920645594,
                "f1": 0.6409838087422806,
                "main_score": 0.6643913920645594
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.7080026899798252,
                "f1": 0.6876986742962444,
                "main_score": 0.7080026899798252
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.6478816408876934,
                "f1": 0.6218781873428972,
                "main_score": 0.6478816408876934
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.716577000672495,
                "f1": 0.6875171511133003,
                "main_score": 0.716577000672495
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.7442501681237391,
                "f1": 0.7118434963451544,
                "main_score": 0.7442501681237391
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.7364828513786147,
                "f1": 0.7067741914007422,
                "main_score": 0.7364828513786147
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.7362811028917284,
                "f1": 0.7136402039740959,
                "main_score": 0.7362811028917284
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.7188634835238736,
                "f1": 0.6923701923480676,
                "main_score": 0.7188634835238736
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.7415938130464022,
                "f1": 0.7187792218993388,
                "main_score": 0.7415938130464022
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.6996301277740415,
                "f1": 0.6729584200202983,
                "main_score": 0.6996301277740415
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.6949562878278412,
                "f1": 0.6691716685679431,
                "main_score": 0.6949562878278412
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.746805648957633,
                "f1": 0.7202723592594374,
                "main_score": 0.746805648957633
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.6300605245460659,
                "f1": 0.6016716669482932,
                "main_score": 0.6300605245460659
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.6690988567585743,
                "f1": 0.6399405488777784,
                "main_score": 0.6690988567585743
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.6762273032952253,
                "f1": 0.6517213906909481,
                "main_score": 0.6762273032952253
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.6950907868190989,
                "f1": 0.6915165697194853,
                "main_score": 0.6950907868190989
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.6930733019502352,
                "f1": 0.6669024007380474,
                "main_score": 0.6930733019502352
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.7224277067921989,
                "f1": 0.6880515408492947,
                "main_score": 0.7224277067921989
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.6749831876260929,
                "f1": 0.6483778567111116,
                "main_score": 0.6749831876260929
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.7128782784129118,
                "f1": 0.693294186700733,
                "main_score": 0.7128782784129118
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.73315400134499,
                "f1": 0.7122674385243206,
                "main_score": 0.73315400134499
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6937794216543377,
                "f1": 0.6896962492838231,
                "main_score": 0.6937794216543377
            }
        ]
    }
}