{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.558083,
        "f1": 0.552713,
        "f1_weighted": 0.552713,
        "ap": 0.534954,
        "ap_weighted": 0.534954,
        "scores_per_experiment": [
          {
            "accuracy": 0.556667,
            "f1": 0.554378,
            "f1_weighted": 0.554378,
            "ap": 0.532082,
            "ap_weighted": 0.532082
          },
          {
            "accuracy": 0.495833,
            "f1": 0.491482,
            "f1_weighted": 0.491482,
            "ap": 0.497931,
            "ap_weighted": 0.497931
          },
          {
            "accuracy": 0.619167,
            "f1": 0.615384,
            "f1_weighted": 0.615384,
            "ap": 0.577297,
            "ap_weighted": 0.577297
          },
          {
            "accuracy": 0.555833,
            "f1": 0.555764,
            "f1_weighted": 0.555764,
            "ap": 0.531114,
            "ap_weighted": 0.531114
          },
          {
            "accuracy": 0.62,
            "f1": 0.619822,
            "f1_weighted": 0.619822,
            "ap": 0.573802,
            "ap_weighted": 0.573802
          },
          {
            "accuracy": 0.5125,
            "f1": 0.496947,
            "f1_weighted": 0.496947,
            "ap": 0.506491,
            "ap_weighted": 0.506491
          },
          {
            "accuracy": 0.5075,
            "f1": 0.50156,
            "f1_weighted": 0.50156,
            "ap": 0.503796,
            "ap_weighted": 0.503796
          },
          {
            "accuracy": 0.571667,
            "f1": 0.571362,
            "f1_weighted": 0.571362,
            "ap": 0.540709,
            "ap_weighted": 0.540709
          },
          {
            "accuracy": 0.553333,
            "f1": 0.549548,
            "f1_weighted": 0.549548,
            "ap": 0.52907,
            "ap_weighted": 0.52907
          },
          {
            "accuracy": 0.588333,
            "f1": 0.570881,
            "f1_weighted": 0.570881,
            "ap": 0.557244,
            "ap_weighted": 0.557244
          }
        ],
        "main_score": 0.558083,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.548167,
        "f1": 0.542012,
        "f1_weighted": 0.542012,
        "ap": 0.529246,
        "ap_weighted": 0.529246,
        "scores_per_experiment": [
          {
            "accuracy": 0.5475,
            "f1": 0.543157,
            "f1_weighted": 0.543157,
            "ap": 0.526553,
            "ap_weighted": 0.526553
          },
          {
            "accuracy": 0.470833,
            "f1": 0.465578,
            "f1_weighted": 0.465578,
            "ap": 0.486127,
            "ap_weighted": 0.486127
          },
          {
            "accuracy": 0.6175,
            "f1": 0.611673,
            "f1_weighted": 0.611673,
            "ap": 0.577036,
            "ap_weighted": 0.577036
          },
          {
            "accuracy": 0.580833,
            "f1": 0.580705,
            "f1_weighted": 0.580705,
            "ap": 0.547188,
            "ap_weighted": 0.547188
          },
          {
            "accuracy": 0.606667,
            "f1": 0.606597,
            "f1_weighted": 0.606597,
            "ap": 0.564416,
            "ap_weighted": 0.564416
          },
          {
            "accuracy": 0.488333,
            "f1": 0.472797,
            "f1_weighted": 0.472797,
            "ap": 0.494374,
            "ap_weighted": 0.494374
          },
          {
            "accuracy": 0.505,
            "f1": 0.500167,
            "f1_weighted": 0.500167,
            "ap": 0.502521,
            "ap_weighted": 0.502521
          },
          {
            "accuracy": 0.535,
            "f1": 0.534917,
            "f1_weighted": 0.534917,
            "ap": 0.518693,
            "ap_weighted": 0.518693
          },
          {
            "accuracy": 0.571667,
            "f1": 0.569022,
            "f1_weighted": 0.569022,
            "ap": 0.540274,
            "ap_weighted": 0.540274
          },
          {
            "accuracy": 0.558333,
            "f1": 0.53551,
            "f1_weighted": 0.53551,
            "ap": 0.535279,
            "ap_weighted": 0.535279
          }
        ],
        "main_score": 0.548167,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 730.3117470741272,
  "kg_co2_emissions": 0.06835819817779254
}