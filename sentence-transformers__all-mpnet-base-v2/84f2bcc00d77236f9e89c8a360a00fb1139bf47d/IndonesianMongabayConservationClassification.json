{
  "dataset_revision": "c9e9f2c09836bfec57c543ab65983f3398e9657a",
  "evaluation_time": 19.798123836517334,
  "kg_co2_emissions": 0.0031792327228738837,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.29467758444216996,
        "f1": 0.2896799972392997,
        "f1_weighted": 0.29020434350606444,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.2896799972392997,
        "scores_per_experiment": [
          {
            "accuracy": 0.28454452405322417,
            "f1": 0.2734663710273466,
            "f1_weighted": 0.268106000896774
          },
          {
            "accuracy": 0.3091095189355169,
            "f1": 0.2984980136802093,
            "f1_weighted": 0.30534748625736363
          },
          {
            "accuracy": 0.345957011258956,
            "f1": 0.34509718338696355,
            "f1_weighted": 0.3448550473552671
          },
          {
            "accuracy": 0.28863868986693964,
            "f1": 0.28242418397181085,
            "f1_weighted": 0.29232045074197865
          },
          {
            "accuracy": 0.28454452405322417,
            "f1": 0.2834107827656214,
            "f1_weighted": 0.2864183737812688
          },
          {
            "accuracy": 0.23336745138178097,
            "f1": 0.22847862215957046,
            "f1_weighted": 0.2281602286729504
          },
          {
            "accuracy": 0.32139201637666326,
            "f1": 0.32237107805932647,
            "f1_weighted": 0.31763443946837217
          },
          {
            "accuracy": 0.2917093142272262,
            "f1": 0.2734295674779927,
            "f1_weighted": 0.2787623789569765
          },
          {
            "accuracy": 0.30194472876151485,
            "f1": 0.30429767481899034,
            "f1_weighted": 0.29534028566657067
          },
          {
            "accuracy": 0.28556806550665303,
            "f1": 0.2853264950451651,
            "f1_weighted": 0.28509874326312246
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.2965447154471545,
        "f1": 0.2882068079401062,
        "f1_weighted": 0.2900747181913021,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.2882068079401062,
        "scores_per_experiment": [
          {
            "accuracy": 0.26422764227642276,
            "f1": 0.24346255596255598,
            "f1_weighted": 0.24774381557918146
          },
          {
            "accuracy": 0.32926829268292684,
            "f1": 0.3152543686998939,
            "f1_weighted": 0.32842120961357324
          },
          {
            "accuracy": 0.3353658536585366,
            "f1": 0.3341599511599512,
            "f1_weighted": 0.3338508144971559
          },
          {
            "accuracy": 0.2804878048780488,
            "f1": 0.27104377104377103,
            "f1_weighted": 0.28517081382935044
          },
          {
            "accuracy": 0.2845528455284553,
            "f1": 0.28387862328952557,
            "f1_weighted": 0.2783562617850041
          },
          {
            "accuracy": 0.2073170731707317,
            "f1": 0.20419686469215828,
            "f1_weighted": 0.19872696656835895
          },
          {
            "accuracy": 0.32926829268292684,
            "f1": 0.3294609058869599,
            "f1_weighted": 0.3176657917585199
          },
          {
            "accuracy": 0.31097560975609756,
            "f1": 0.28048691318232005,
            "f1_weighted": 0.298179921632684
          },
          {
            "accuracy": 0.31910569105691056,
            "f1": 0.3191747779160267,
            "f1_weighted": 0.3104543471176474
          },
          {
            "accuracy": 0.3048780487804878,
            "f1": 0.30094934756789954,
            "f1_weighted": 0.3021772395315458
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianMongabayConservationClassification"
}